<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 16 Jul 2020 20:17:45 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 16 Jul 2020 20:17:44 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Privacytools.io – Toxic Endorsements]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845319">thread link</a>) | @realpanzer
<br/>
July 15, 2020 | https://dev.lemmy.ml/post/31434 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/31434">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dev.lemmy.ml/post/31434</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845319</guid>
            <pubDate>Wed, 15 Jul 2020 14:02:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SML Dev Setup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845306">thread link</a>) | @vyuh
<br/>
July 15, 2020 | https://blog.jez.io/sml-dev-setup/ | <a href="https://web.archive.org/web/*/https://blog.jez.io/sml-dev-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
  <article>
    <p>When it comes right down to it, SML is a pretty great language. It’s clear that
extensive thought has gone into its design and implementation. I quite enjoy
programming in SML, due in no small part to my collection of workflow hacks that
make editing and developing with SML responsive and interactive.</p>

<!-- more -->


<p>We’re going to be walking through a couple easy steps to make developing SML
feel more fluid. I have a slight preference for Vim (Neovim) on macOS, but many
of these steps are platform agnostic.</p>

<p><strong>Note</strong>: I updated this post to more accurately reflect my SML dev setup in
December 2019.</p>

<h2>Installing SML Locally</h2>

<p>While developing SML in a remote environment like the shared Andrew Unix
machines makes it easy to dive right in, I prefer doing development on my
laptop—it doesn’t get slow when there are many people logged in, there’s no
nightly reboots, and it doesn’t matter whether I have a strong WiFi connection.</p>

<p>On macOS and Ubuntu, the two most popular implementations of SML are already
packaged. Take the time to install a version of SML right now:</p>

<ul>
<li><p>At CMU we use <a href="http://smlnj.org/">SML/NJ</a>, which is convenient because it has a REPL that
for playing around with SML interactively.</p></li>
<li><p>To play around with releasing programs written in SML to other people, install
<a href="http://www.mlton.org/">MLton</a>. It has better support for compiling SML programs to standalone
executables which can be shared from one machine to another. (I have a
separate post on <a href="https://blog.jez.io/sml-travis-ci/">using SML to release software publically</a>
with more details).</p></li>
</ul>


<figure><figcaption><span>Install SML from your package manager</span></figcaption><div><div><pre><code><span><span># macOS -- one or both of:</span>
</span><span>brew install smlnj
</span><span>brew install mlton
</span><span>
</span><span><span># Ubuntu -- one or both of:</span>
</span><span>sudo apt-get install smlnj
</span><span>sudo apt-get install mlton</span></code></pre></div></div></figure>


<p>Feel free to install both; they’ll play nicely with each other, and each offers
advantages over the other.</p>

<p>Note for macOS users: if you’ve never used <a href="https://brew.sh/">Homebrew</a> before, you’ll need
to <a href="https://brew.sh/">install it first</a>.</p>

<p>Note for Ubuntu users: the versions of these two that ship in the default
package distribution are frequently out of date. If that matters to you,
consider following the the <a href="http://smlnj.org/">SML/NJ</a> and <a href="http://www.mlton.org/">MLton</a> installation
instructions directly.</p>

<h2>Getting Comfortable with SML/NJ</h2>

<p>The rest of these steps should apply regardless of whether you’re working on SML
locally or remotely.</p>

<p>One thing that I’ve seen far too many times from course documentation is that
they tell students to run their code like this:</p>

<ol>
<li>Run <code>sml</code></li>
<li>Type <code>use "foo.sml";</code> or <code>CM.make "sources.cm";</code> at the REPL</li>
</ol>


<p>Don’t get me wrong; this works, but there’s a better way. Being responsible
CLI-citizens, we should always be looking for ways to tab-complete. We can
easily get tab-completion on the filename by changing our workflow:</p>

<ol>
<li>Run <code>sml foo.sml</code> or <code>sml -m sources.cm</code></li>
</ol>


<p>Look at that! We’ve,</p>

<ul>
<li>dropped a step (having to launch the REPL first), and</li>
<li>introduced tab completion (because the shell has filename completion)</li>
</ul>


<p>It’s the little things, but they add up.</p>

<h2>Enhancing the REPL</h2>

<p>Speaking of the little things, when using the SML REPL, you don’t have access to
all the usual command line niceties like command history and access to arrow
keys for editing, let alone Vi-like keybindings. To get started, you’ll have to
change how you launch the SML/NJ REPL. In particular, we’re going to preface our
commands with <code>rlwrap</code>:</p>

<figure><div><div><pre><code><span><span># instead of this...</span>
</span><span><span>$ </span>sml
</span><span>
</span><span><span># use this:</span>
</span><span><span>$ </span>rlwrap sml</span></code></pre></div></div></figure>


<p><code>rlwrap</code> stands for “readline wrap.” Readline is a library that adds all the
features mentioned above to any REPL program:</p>

<ul>
<li>Command history tracking (up arrow keys)</li>
<li>Line editing with arrow keys</li>
<li>Configuration through the <code>~/.inputrc</code> file

<ul>
<li>We can use this to get fancy features like Vi keybindings</li>
</ul>
</li>
</ul>


<p>For more information, see <a href="https://github.com/jez/dotfiles/blob/ed8e531eebe43a8aef05fc4cb768157d03408cea/inputrc#L12-L14">these lines</a> of my inputrc, a small part of
my <a href="https://github.com/jez/dotfiles">dotfiles repo</a> on GitHub.</p>

<h2>Setting Up Vim</h2>

<p>Programming is so much more enjoyable when you’re not fighting your editor. For
me, this means striving to get the most out of Vim. In this section, I’ll
outline all the cool tips and tricks I have for developing SML in Vim.</p>

<p>But first, if you’ve never taken a look into how to configure Vim, I suggest you
start out by walking through this quick workshop called <a href="https://github.com/jez/vim-as-an-ide">Vim as an
IDE</a>. It’ll teach you where to start when configuring Vim and get
you set up with a bunch of standard plugins that improve on the standard Vim
experience tenfold.</p>

<p>No actually, take a second and <a href="https://github.com/jez/vim-as-an-ide">walk through it</a>. We’ll still be
here when you’re done, and you’ll appreciate Vim more when you’re done.</p>

<h3>ALE</h3>

<p><a href="https://github.com/dense-analysis/ale">ALE</a> is a Vim plugin that provides what it calls “asynchronous linting.”
That’s a fancy way of saying that it can show little red x’s on all the lines
that have errors. It works for many languages out of the box, including Standard
ML.</p>

<p>It’s super simple to set up. The <a href="https://github.com/dense-analysis/ale">ALE homepage</a> should have all the
instructions.</p>

<p>With ALE set up, try writing this into a file called <code>test.sml</code>:</p>

<figure><figcaption><span>test.sml</span></figcaption><div><div><pre><code><span><span>val</span> <span>foo</span> <span>:</span> <span>string</span> <span>=</span> <span>42</span></span></code></pre></div></div></figure>


<p>While typing, any errors should appear as markers to the left of the line
numbers. Super handy!</p>

<p>If nothing shows up, check <code>:ALEInfo</code> which dumps a bunch of information
about whether ALE was set up correctly. In particular, SML support requires
having <a href="http://smlnj.org/">SML/NJ</a> installed (i.e., installing it on your laptop or working
on a server where it’s already installed).</p>

<h3>Extra ALE Setup</h3>

<p>While the default settings for ALE work well enough, there’s plenty of reasons
to tweak them. For example, here are <a href="https://github.com/jez/dotfiles/blob/b942b6336ee968c9d94a9ea363c1cbcdb44b9846/vim/plug-settings.vim#L227-L239">all my ALE settings</a>.</p>

<p>The key changes I make:</p>

<ul>
<li>I ask ALE to show a list of all errors if there were any.</li>
<li>I ask ALE to only run when the file was saved (not when it was opened or
edited).</li>
</ul>


<p>(You’ll also see a bunch of settings for other languages, but you won’t find any
SML-specific config… it’s not needed!)</p>

<p>Also, a tip for those who’ve never used Vim’s location list: you can close the
list of errors with <code>:lclose</code>.</p>

<h3>Using ALE with CM files</h3>

<p>Sometimes a single SML file is self-contained enough to type check on it’s own.
But most of the time, we’re working with multi-file SML projects. With SML/NJ,
multi-file SML projects are managed using CM files (<code>*.cm</code> files) which declare
groups of SML files that must be compiled together to make sense.</p>

<p>ALE’s support for SML handles both of these scenarios. When opening an SML file,
ALE will search up the folder hierarchy for any <code>*.cm</code> file, stopping when it
finds the first one. When there are multiple in a single folder, it takes the
alphabetically first option.</p>

<p>Usually this works fine but sometimes ALE picks the wrong one. There are
instructions for how to manually fix this by setting some variables in the ALE
help:</p>

<figure><div><div><pre><code><span>:help ale-sml-options</span></code></pre></div></div></figure>


<h3><code>vim-better-sml</code></h3>

<p>After all that, I still wasn’t satisfied with developing SML in Vim, so I wrote
a plugin to make it even better: <a href="https://github.com/jez/vim-better-sml">vim-better-sml</a>. Here’s a
quick rundown of its features:</p>

<ul>
<li>It supports for embedding a REPL directly inside Vim.</li>
<li>It supports asking for the type of a variable under the cursor.</li>
<li>It supports jump to definition, even into the Standard Basis Library.</li>
<li><code>*.sig</code> files are properly detected as SML signature files.</li>
<li>Many small annoyances with syntax highlighting and indentation are fixed.</li>
</ul>


<p>For more information, including how to install it, check out the homepage:
<a href="https://github.com/jez/vim-better-sml">vim-better-sml</a>. For the most part, the plugin itself will
guide you through the installation, declaring any dependencies that might be
missing.</p>

<p>I recorded a screencast of all those features above in action, which you might
want to check out:</p>

<p><a href="https://youtu.be/Z5FsPZ5cm8Y"><img src="https://blog.jez.io/images/vim-better-sml-demo-thumbnail.png" alt="thumbnail"></a></p>

<h2>General Vim Settings</h2>

<p>As a quick addendum, one common complaint people have when editing SML is that
it forces the line to wrap if it extends past 80 characters. Some people don’t
like that, and others don’t like that it doesn’t do it frequently enough
(namely, it only wraps the line if your <strong>cursor</strong> extends past 80 characters,
not the end of the line).</p>

<p>If you don’t want Vim to do any of this wrapping, run this:</p>

<figure><figcaption><span>Disable hard line wrapping</span></figcaption><div><div><pre><code><span><span>setlocal</span> textwidth<span>=</span><span>0</span></span></code></pre></div></div></figure>


<p>If you’d like this change to persist between Vim sessions, add it to
<code>~/.vim/after/ftplugin/sml.vim</code>. These folders and file likely don’t exist
yet; you’ll have to create them. The <code>after</code> folder in Vim is used to override
settings loaded from plugins.</p>

<p>Alternatively, if you’d like a little better idea when Vim’s going to hard wrap
your line, you can add one of these lines to your vimrc:</p>

<figure><figcaption><span>Show a color column</span></figcaption><div><div><pre><code><span><span>" Always draw the line at 80 characters</span>
</span><span><span>set</span> colorcolumn<span>=</span><span>80</span>
</span><span>
</span><span><span>" Draw the line at whatever the current value of textwidth is</span>
</span><span><span>set</span> colorcolumn<span>+=</span><span>0</span></span></code></pre></div></div></figure>


<p>That way, it’s easier to see when a line is getting long.</p>

<h2>TL;DR</h2>

<p>We covered a lot, so here’s a quick recap:</p>

<ul>
<li>Install SML locally. It’s super easy to do on macOS and Linux (use your
package manager), and means you don’t have to have a Wi-Fi connection to
develop SML.</li>
<li>Invest time into learning Vim. Here’s a reference: <a href="https://github.com/jez/vim-as-an-ide">Vim as an
IDE</a>.</li>
<li>Install <a href="https://github.com/dense-analysis/ale">ALE</a>. It tells you what lines your errors are on.</li>
<li>Install <a href="https://github.com/jez/vim-better-sml">vim-better-sml</a>. It includes a whole host of added
power features.</li>
</ul>


<p>And as always, you can see even more Vim settings in my <a href="https://github.com/jez/dotfiles">dotfiles
repo</a> on GitHub.</p>

    
  </article></div></div>]]>
            </description>
            <link>https://blog.jez.io/sml-dev-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845306</guid>
            <pubDate>Wed, 15 Jul 2020 14:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Roll your own Ngrok with Nginx, Letsencrypt, and SSH reverse tunnelling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845294">thread link</a>) | @flipchart
<br/>
July 15, 2020 | https://jerrington.me/posts/2019-01-29-self-hosted-ngrok.html | <a href="https://web.archive.org/web/*/https://jerrington.me/posts/2019-01-29-self-hosted-ngrok.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on January 29, 2019
    
</p>

<p>Ngrok is a fantastic tool for creating a secure tunnel from the public web to a machine behind NAT or a firewall. Sadly, it costs money and it’s proprietary. If you’re a developer, odds are that you’re already renting a server in the public cloud, so why not roll your own ngrok?</p>
<p>It turns out that you can do it using free, off-the-shelf tools, with no sophisticated scripting required! In this article, I’ll show you how.</p>
<h2 id="step-1.-configuring-nginx">Step 1. Configuring Nginx</h2>
<p>Use a server block like this, so that incoming HTTP connections to <code>tunnel.yourdomain</code> are reverse proxied into the application listening on port <code>3333</code>.</p>
<pre><code>server {
    server_name tunnel.yourdomain;

    access_log /var/log/nginx/$host;

    location / {
	    proxy_pass http://localhost:3333/;
	    proxy_set_header X-Real-IP $remote_addr;
	    proxy_set_header Host $host;
	    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto https;
	    proxy_redirect off;
    }

    error_page 502 /50x.html;
    location = /50x.html {
	    root /usr/share/nginx/html;
    }
}</code></pre>
<p>With this configuration in place, suppose I visited <code>tunnel.yourdomain</code>. Nginx will receive the connection, and see that it should reverse proxy it. It will effectively pass the connection on to whatever application is listening on port <code>3333</code>. Currently, there is nothing listening on this port, so we will get a <code>502 Bad Gateway</code> or <code>404 Not Found</code> error from Nginx.</p>
<p>Let’s fix that.</p>
<h2 id="step-2.-using-an-ssh-reverse-tunnel">Step 2. Using an SSH reverse tunnel</h2>
<p>SSH reverse tunnelling port <code>N</code> to port <code>K</code> means making sshd listen on port <code>N</code> and effectively transfer incoming connections over the SSH connection to the SSH client. The SSH client will then transfer the connection to the application listening on port <code>K</code> on the client machine.</p>
<p>Here’s the command to run on your client machine: <code>ssh -R N:localhost:K yourdomain</code></p>
<p>An interactive session on your server should begin; while it is open, the reverse tunnel from port <code>N</code> to port <code>K</code> is active, and sshd will allow connections originating only from <code>localhost</code>, i.e.&nbsp;your server.</p>
<p>Choosing <code>N</code> = <code>3333</code> will make it so Nginx reverse proxies incoming connections on <code>tunnel.yourdomain</code> into sshd, over the SSH connection, and into the application running on your local machine on port <code>K</code>.</p>
<p>To test this out, on your local machine, in one shell run <code>python -m http.server 8888</code> and in another shell run <code>ssh -R 3333:localhost:8888 yourdomain</code>. Visit <code>tunnel.yourdomain</code>. You should see a directory listing for whatever directory you were in when you ran the Python command!</p>
<p>However, there’s a glaring problem with this setup.</p>
<h2 id="step-3.-securing-the-connection-in-the-browser">Step 3. Securing the connection in the browser</h2>
<p>The connection the browser is making to Nginx is at the moment not secure: it was a plain HTTP connection. You can fix this by obtaining a free TLS certificate with Letsencrypt, and using it to secure the connection the browser is making.</p>
<p>There are already excellent tutorials available on setting up Letsencrypt, so I won’t repeat that here. I recommend consulting the ArchWiki article <a href="https://wiki.archlinux.org/index.php/Certbot">here</a>. Letsencrypt is a self-hosters dream-come-true since it is truly a set-it-and-forget-it type of thing. With the appropriate setup, (namely a simple systemd timer,) the certificate you get will renew itself when it its expiry is approaching.</p>
<p>Once you have a certificate, it suffices to adjust the Nginx server block above so it looks like this.</p>
<pre><code>server {
    server_name tunnel.yourdomain;

    access_log /var/log/nginx/$host;
    
    # These three lines are new.
    listen 443 ssl;
    ssl_certificate /path/to/tls/cert/fullchain.pem;
    ssl_certificate_key /path/to/tls/cert/privkey.pem;

    location / {
	    proxy_pass http://localhost:3333/;
	    proxy_set_header X-Real-IP $remote_addr;
	    proxy_set_header Host $host;
	    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto https;
	    proxy_redirect off;
    }

    error_page 502 /50x.html;
    location = /50x.html {
	    root /usr/share/nginx/html;
    }
}</code></pre>
<p>Only <em>three lines</em> need to be added!</p>
<h3 id="conclusion">Conclusion</h3>
<p>With very little setup, we saw how to configure Nginx to act as a reverse proxy, and how to use an SSH reverse tunnel. By combining these off-the-shelf tools, we essentially replicated the core functionality of the fantastic tool Ngrok. Using this double-reverse-proxy technique, web applications running on a machine behind NAT or a firewall can be accessed easily and securely from a public domain or IP address.</p>
<p>If you have any comments or concerns, <a href="https://github.com/tsani/jerrington.me/issues">open an issue</a> on Github.</p>

        </div></div>]]>
            </description>
            <link>https://jerrington.me/posts/2019-01-29-self-hosted-ngrok.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845294</guid>
            <pubDate>Wed, 15 Jul 2020 13:59:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficient Navigation in Vim]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845213">thread link</a>) | @lvht
<br/>
July 15, 2020 | https://blog.bespinian.io/posts/efficient-navigation-in-vim/ | <a href="https://web.archive.org/web/*/https://blog.bespinian.io/posts/efficient-navigation-in-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>When editing a file, it’s quite crucial that you can navigate your cursor around rather quickly. <a href="https://www.vim.org/">Vim</a> and <a href="https://neovim.io/">NeoVim</a> allow for many different ways of doing so which, depending on the situation, can be more or less efficient and useful. This article examines the different ways of moving the cursor and compares them. Here, the term “efficiency” refers to navigating the cursor with as little time and effort (i.e. the number of keystrokes) as possible.</p>
<h2 id="using-the-mouse">Using the Mouse</h2>
<p><strong>TL;DR: Not recommended</strong></p>
<p>Using the mouse pointer to navigate Vim may seem like an obvious choice for users coming from a GUI editor like <a href="https://code.visualstudio.com/">Visual Studio Code</a> or similar. However, in Vim, the goal is to keep your fingers on the “home row” of the keyboard (the row where the <code>F</code> and the <code>J</code> keys reside) and not having to move them greatly towards the touchpad or even the mouse. This should reduce the strain on your hands and wrists and make editing more efficient. Therefore, navigating with the mouse should be highly discouraged in most situations and is even disabled by default.</p>
<p>It can be helpful to enable it for users transitioning from one of the aforementioned editors who would like to have a smooth transition by allowing themselves to use the mouse initially and switching it back off again later in their learning journey. To turn on mouse navigation, add the following to your configuration file (either <code>~/.vimrc</code> or <code>~/.config/nvim/init.vim</code>):</p>
<div><pre><code data-lang="vim"><span>" Temporarily enable mouse support</span><span>
</span><span></span><span>set</span> <span>mouse</span>=<span>a</span><span>
</span></code></pre></div><p>This will allow you to point and click to move the cursor and to scroll through the current buffer.</p>
<h2 id="using-the-arrow-keys">Using the Arrow Keys</h2>
<p><strong>TL;DR: Not recommended</strong></p>
<p>Again, for users used to other text editors or even word processing software like <a href="https://www.libreoffice.org/discover/writer/">LibreOffice Writer</a>, it may be tempting to use what they know. In these programs, you mostly use the arrow keys for keyboard-based navigation. This is not recommended because… you guessed it: They require the user to move their fingers away from the home row.</p>
<p>The alternative is, as described in the next section, to use the <code>h</code>, <code>j</code>, <code>k</code> and <code>l</code> keys on the keyboard which are conveniently placed at the center and where you most likely have your fingers most of the time.</p>
<h2 id="using-hjkl">Using h,j,k,l</h2>
<p><strong>TL;DR: Use for small navigations. Use in combination with relative line numbers.</strong></p>
<p><code>h</code>, <code>j</code>, <code>k</code> and <code>l</code> are the basic movement keys in Vim. They should be used instead of the usual arrow keys on the keyboard to, as discussed above, keep your fingers on the home row as much as possible. It takes a little practice but will pay off in the long run.</p>
<p>One hugely important thing to do with these keys is to not press them multiple times in sequence or even hold them down to move several columns or rows. As with many commands in Vim, they can be prefixed with numbers to move multiple times. For example, <code>12j</code> can be used rather than pressing the <code>j</code> key twelve times which is, obviously, much more efficient (3 vs. 12 keystrokes). However, it is recommendable to only use these keys for small movements and mostly to move lines up or down because there are more efficient ways of moving longer vertical distances or horizontal distances in general.</p>
<p>It can be very useful to enable relative line numbers to see at a glance what number to prefix <code>j</code> or <code>k</code> with to move to a certain line. They can be enabled by adding the following two lines to your configuration file:</p>
<div><pre><code data-lang="vim"><span>" Enable relative line numbers</span><span>
</span><span></span><span>set</span> <span>relativenumber</span><span>
</span><span></span><span>set</span> <span>number</span><span>
</span></code></pre></div><p>This will always show the absolute number of the line the cursor is currently on and relative numbers for all others.</p>
<h2 id="navigation-within-a-line">Navigation Within a Line</h2>
<p><strong>TL;DR: Mostly use <code>f</code>. Also consider <code>w</code>,<code>b</code>,<code>e</code>,<code>^</code> and <code>$</code>.</strong></p>
<p>So far, we’ve mostly looked at navigating from one line to another. The next step is to navigate within a line. In many cases, the straight forward thing to do is to use <code>w</code> or <code>W</code> to move to the next word, <code>b</code> or <code>B</code> to move to the previous word or even <code>e</code> or <code>E</code> to move directly to the end of the next word. For all of them, the lowercase variant considers a “word” to be what we intuitively see as one using delimiters like <code>-</code>, <code>/</code> or <code>.</code> to separate one word from another. The uppercase variant considers anything a word that is delimited by whitespace. Obviously, any of these commands can be prefixed with a number to jump multiple words in one go (e.g. <code>7w</code>). Other useful commands are <code>^</code> which moves to the first non-whitespace character of the line and <code>$</code> to move to the last character of a line. Considering the following line</p>
<p>with the cursor currently on the <code>g</code> character, pressing the following commands is the most efficient way to get to a specific target character:</p>
<table>
<thead>
<tr>
<th>Target Character</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>j</code></td>
<td><code>2w</code></td>
</tr>
<tr>
<td><code>m</code></td>
<td><code>W</code></td>
</tr>
<tr>
<td><code>d</code></td>
<td><code>B</code></td>
</tr>
<tr>
<td><code>i</code></td>
<td><code>e</code></td>
</tr>
<tr>
<td><code>l</code></td>
<td><code>E</code></td>
</tr>
<tr>
<td><code>a</code></td>
<td><code>^</code> or <code>0</code></td>
</tr>
<tr>
<td><code>o</code></td>
<td><code>$</code></td>
</tr>
</tbody>
</table>
<p>When moving multiple words back and forth or to a specific place within a word, <code>t</code> and <code>f</code> are incredibly helpful. Especially <code>f</code> moves to the next occurrence of a specific character which lets you make big jumps within a line. The difference is that <code>f</code> moves to a character and <code>t</code> moves to right before a character. So <code>t</code> is mostly useful for deleting everything to a character. These commands’ uppercase variants <code>F</code> and <code>T</code> do the same thing but backwards. All of these commands can be “repeated” with the <code>;</code> command which jumps to the next occurrence of the targeted character while <code>,</code> jumps to the previous one.</p>
<h2 id="search">Search</h2>
<p><strong>TL;DR: Great for moving larger distances vertically and horizontally</strong></p>
<p>By far one of the most efficient ways of moving longer distances horizontally and vertically in a buffer is to use the search. The <code>/</code> key lets you search for a term and conveniently jump to its location. Pressing the <code>n</code> and <code>N</code> keys jumps to the next and previous occurrence of the search term respectively. The <code>?</code> key searches backwards from the current cursor position (which inverts <code>n</code> and <code>N</code>). Even though, the main purpose of the search command is obviously to search, it is an incredibly powerful tool to navigate quickly and efficiently.</p>
<p>The user experience of the search command can be vastly improved by adding the following settings to your configuration file:</p>
<div><pre><code data-lang="vim"><span>" Incrementally search while typing</span><span>
</span><span></span><span>set</span> <span>incsearch</span><span>
</span><span></span><span>" Use smart case for searching</span><span>
</span><span></span><span>set</span> <span>ignorecase</span><span>
</span><span></span><span>set</span> <span>smartcase</span><span>
</span><span></span><span>" Highlight searches</span><span>
</span><span></span><span>set</span> <span>hlsearch</span><span>
</span><span></span><span>" Use &lt;C-L&gt; to clear the highlighting of :set hlsearch.</span><span>
</span><span></span><span>if</span> <span>maparg</span>(<span>'&lt;C-L&gt;'</span>, <span>'n'</span>) ==# <span>''</span><span>
</span><span></span>  <span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>C</span>-<span>L</span>&gt; :<span>nohlsearch</span>&lt;<span>C</span>-<span>R</span>&gt;=<span>has</span>(<span>'diff'</span>)?<span>'&lt;Bar&gt;diffupdate'</span>:<span>''</span>&lt;<span>CR</span>&gt;&lt;<span>CR</span>&gt;&lt;<span>C</span>-<span>L</span>&gt;<span>
</span><span></span><span>endif</span><span>
</span></code></pre></div><p><code>incsearch</code> will make sure that the search pattern is applied incrementally while typing instead of only after pressing the enter key. The combination of <code>ignorecase</code> and <code>smartcase</code> ignores the case of the search term when not using any uppercase letters and doesn’t ignore it when using at least one uppercase letter which is quite convenient and surprisingly intuitive. <code>hlsearch</code> highlights any matches for the search term allowing to easily jump between them using <code>n</code> and <code>N</code>. The last statement lets you clear the highlighted search results by pressing <code>ctrl+l</code> to unclutter your view once done searching and jumping.</p>
<p>All in all, search is one of the powerful tools for intuitive and efficient navigation. It covers the common use case of knowing the word or part of a word to navigate to but not having your eyes directly pointed there yet. Furthermore, it’s simply the fastest way of jumping somewhere in many cases and beats other methods of navigation quite often in that regard.</p>
<h2 id="clunky-movements">Clunky Movements</h2>
<p><strong>TL;DR: Use for very specific use cases only. Consider <code>gg</code> and <code>G</code> for getting to know a file.</strong></p>
<p>In this section we’ll discuss what can be referred to as “clunky movements”. They let the user navigate larger distances in the buffer while sacrificing precision. These commands are less useful for exactly that reason. Vim can be a very efficient text editor by letting the user think about what they want to change, jumping precisely there with very few keystrokes, entering insert mode, performing a change with scalpel-like precision and finally exiting insert mode as soon as it’s done. The movement commands in this section however, get the cursor around the document as a whole while it’s hard for the user to predict at a glance, which line and column exactly they will land on.</p>
<p>A good example are the <code>H</code>, <code>M</code> and <code>L</code> keys which take the cursor to the top, the middle or the bottom of the current view port respectively. While this is a very big movement with just one keystroke, it’s highly likely that they won’t exactly get the cursor to the line needed but rather will have to be accompanied by pressing <code>j</code> or <code>k</code> multiple times which will result in much more thinking and many more keystrokes than what can be achieved with other methods. Similar are the <code>{</code> and <code>}</code> keys which take the cursor to the next paragraph (a block of text delimited by blank lines).</p>
<p>A useful exception to that are the <code>gg</code> and <code>G</code> commands which take the cursor to the first or the last line of a buffer respectively. It’s easy and effortless to predict where these movements will take you. Especially the <code>G</code> command can be quite useful because it allows to append to a file with just two keystrokes (<code>G</code> followed by <code>o</code>).</p>
<h2 id="plugins">Plugins</h2>
<p><strong>TL;DR: Install only the necessary plugins. Check out fzf!</strong></p>
<p>So far, we’ve only talked about features that are built into Vim or that can be configured on a vanilla installation. However, there are many useful plugins which can make navigating Vim even more efficient. It is important to carefully pick them though as any plugin can make Vim slower and/or less stable.</p>
<h3 id="fzf">fzf</h3>
<p>One of the most useful plugins is <a href="https://github.com/junegunn/fzf.vim">fzf</a> which is a great one to have in general. It offers many helpful commands like <code>:BLines</code> for searching the current buffer with intelligent fuzzy matching or <code>:Rg</code> for even searching the whole project for specific patterns which, in contrast to the other methods we’ve looked at so far, lets the user navigate between files. fzf is a tool that can be used for jumping between files and buffers but also between different locations within them. I highly recommend to check it out and add the following lines to your configuration file:</p>
<div><pre><code data-lang="vim"><span>" Jump to specific file</span><span>
</span><span></span><span>nnoremap</span> &lt;<span>C</span>-<span>P</span>&gt; :<span>Files</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>" Search whole project</span><span>
</span><span></span><span>nnoremap</span> \ :<span>Rg</span>&lt;<span>space</span>&gt;<span>
</span></code></pre></div><p>The first line lets you open …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.bespinian.io/posts/efficient-navigation-in-vim/">https://blog.bespinian.io/posts/efficient-navigation-in-vim/</a></em></p>]]>
            </description>
            <link>https://blog.bespinian.io/posts/efficient-navigation-in-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845213</guid>
            <pubDate>Wed, 15 Jul 2020 13:52:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keybase - stay away from it, seriously.]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23845180">thread link</a>) | @realpanzer
<br/>
July 15, 2020 | https://dev.lemmy.ml/post/31190 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/31190">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dev.lemmy.ml/post/31190</link>
            <guid isPermaLink="false">hacker-news-small-sites-23845180</guid>
            <pubDate>Wed, 15 Jul 2020 13:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$0-$1M ARR in 12 Months Bootsrapped]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23844894">thread link</a>) | @sabbakeynejad
<br/>
July 15, 2020 | https://www.veed.io/blog/0-1m-arr-12-months/ | <a href="https://web.archive.org/web/*/https://www.veed.io/blog/0-1m-arr-12-months/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 300w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 600w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 1000w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png" alt="0-1M ARR in 12 Months Bootsrapped">
            </figure>

            <section>
                <div>
                    <p>VEED.IO has grown fast.</p><p>12 months ago we turned on our paywall and made our first ever SaaS $1.</p><p>For any entrepreneur, this is a moment that they will never forget. Tim and I could not control our excitement.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG_0318.jpeg"><figcaption>Our first ever $1 - 12 months ago</figcaption></figure><p>You achieved the impossible, there is light at the end of the tunnel and everything you have been dreaming about and working towards might come true!</p><p>Exactly 12 months after this first payment, we have managed to cross the seemingly impossible task of hitting $83,333 MRR / $1M ARR.</p><p>And the best part is we did it 100% self-funded, with no external funding.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG-20200703-WA0015-1.jpg"><figcaption>1M ARR - Tim &amp; Sabba - VEED.IO</figcaption></figure><p>In this post, I would like to share relevant financial data that might give other founders insights into how to build their own bootstrapped SaaS to $1M ARR.</p><p>I would also like to share some insights into our attitudes and believes that have got us to where we are. Such as our bullish attitude towards growth, how we build the product and how we think about the future of VEED.</p><h3 id="the-numbers">The Numbers</h3><p>First off, we are aware that we did this very fast and we also go lucky (I talk about this more below) From the outside, VEED might look like an overnight success, however it was 10 years in the making!</p><p>Before we look at the numbers, I would like to provide some context. When we started charging, we already had about 30,000 MAU. However, pretty much none of those users would speak to us and we were unsure that if we added the paywall any of the users would upgrade.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Accounts-Copy-149.png"><figcaption>1M ARR in 12 Months</figcaption></figure><p>Growth starts slow, but having a product that is scalable and can we assessed globally from day one really means the sky is the limit. 6 months in, our projection for 1M ARR was December, then August and due to increasing demand influenced by the pandemic, we hit 1M ARR in June. </p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Accounts-Copy-150.png"><figcaption>ARR Milestones</figcaption></figure><p>As you can see, the first $100K ARR took 171 days to reach and the following $100K took just 48 days. The reason why the 2nd was much quicker than the first is because we were learning from users and building the required product features. We were also learning more about our acquisition channels and were able to double down on them. </p><p>Although 171 days is not a very long period of time, turning up to the office and putting in 12 hours every day can be really draining. The stress of getting to profitability was really real. For bootstrapped startup, be aware that it can really take some time.</p><p>Like with anything with compounding growth your first 100K takes ages, but the next comes a lot quicker. It took 12 months for us to hit 1M ARR, however we are projected to hit 2M in just 4 months!</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Accounts-Copy-151.png"><figcaption>1M ARR Traffic Growth</figcaption></figure><p>Bootstrapping is hard work, but as you grow it gets a lot easier. The speed in which you grow makes a HUGE difference to the bootstrapping experience. You need to get the flywheel moving super fast to keep everyone motivated and to get you to ramen profitability.</p><p>6 months after our first-ever paid users, we reached $10K MRR. Although a relatively small sum, it was enough to support the founding team.</p><p>This is important as it means you can donate 100% of your time building and growing your product.</p><p>However, if it took 18 months to reach this goal, the market would have moved on, our attitudes towards the product would have changed and maybe we would have been disillusioned. Otherwise known as the "Long, Slow, SaaS Ramp of Death"</p><p>From our experience, there are three keys to successfully bootstrapping.</p><h3 id="your-ideas-at-the-core-"><br>Your ideas at the core.</h3><p>A common mistake I often see is founders building way too much!</p><p>Building any app is hard work. If you set out to build a fully-fledged product you might never finish and more importantly, you are not getting valuable feedback from your users to help shape your product.</p><p>Setting the bar too high will also delay your launch and also make responding to feedback much harder due to a bloated codebase and feature set.</p><p>After years of building VEED, we don't even think we are at version 1.0.</p><p>We believe the best thing to do is to build your MVP and get it out into the world as soon as possible. The first version of VEED had only 4 features, Trim, Crop, Draw and Text. There was no login, no accounts, just a simple web app. Looking back, I think we made way too much, we should have launched with just a really good crop tool.</p><p>After we saw that users were responding well to your app, we started building new features that they had requested. This kickstarted our build measure learn process. So you need to find the minimum set of features that represents your idea.</p><h3 id="validate-your-ideas-fast-">Validate your ideas fast.</h3><p>When I first entered the startup world, I was under the impression that you needed a new and original idea. For many years I tried that approach with little to no success.</p><p>In my opinion, the best way to validate an idea is to look to see if this is a product people are already willing to pay for.</p><p>For example, I would feel comfortable that people are willing to pay for an email marketing tool. Why? Because Mailchimp has proven this for us!</p><p>This questions now is, how are you different or what subset of users do you believe they are undeserving?</p><p>For us at VEED, we knew people where the will to pay for video editing software (I know because I had an Adobe subscription myself). What we did differently is we just put it online and targeted, short-form content creators.</p><p>Why? Because we believe they were being underserved by legacy video editing platform. One of my fave tutors from art school once told me "An original idea is not something completely new, it just 10% different"</p><p>If it feels like you are pushing a boulder uphill and struggling to get traction, it might be time to move to the next idea. Seriously, the faster you can get to this realisation, the better. Don't let a "sunk cost" fallacy keep you working on the same idea.<br></p><h3 id="work-out-how-to-charge-for-your-product-early-on-">Work out how to charge for your product early on.</h3><p>Your funds will not last forever. We ran out of money before and had to go back to contract jobs. This ultimately set us back 6 months. To give your startup the best opportunity for success (I believe this both applies to Boostrapped &amp; VC backed startups, with some exceptions*) it has to generate revenue, a clear sign that you are creating value.</p><p>And charging for your product early on does a few things.</p><ol><li>Proves that users are willing to pay for it.</li><li>Provides you with better feedback (users care more if they are paying)</li><li>Lowers your burn rate and gets your closer to profitability.</li></ol><p>If you can't avoid writing a lot of code before you get your basic product live, you can follow the real estate showroom strategy!</p><p>When a property developer is building a new block of flats, the first thing they do is build a showroom and start selling! Then once someone is interested and buys, you can ask them what colour they want the walls and ask them what taps they would like in the bathroom.</p><p>Overall we have been laser-focused over the last 12 months. We have not gone to any conferences, pitched investors, built pointless pitch decks, entertained any partnerships. We have just been 100% focused on building VEED, learning from our users and growing the company.</p><h3 id="product">Product </h3><p>Our product development strategies are user-centric. Every user who signs up for VEED can book an on-boarding call with us. This process is time-consuming but provided incredible insight into who our users are, what they don't understand and what they need from VEED.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG_20200714_174440.jpg"><figcaption>User calls every day of the week</figcaption></figure><p>We have built new features fast and scrapped useless features even quicker. Overall we have put a lot of time into UX, but I must admit consistency with the design is sometimes lacking. But that is the cost we are willing to pay to move fast.</p><p>New paid users are also prompted to let us know why they chose VEED. We have collected over 500 of these responses and use them to inform our copy and also our focus.</p><h3 id="marketing">Marketing</h3><div><p>For the first 8 months, Tim has spent all of his time building the product and I (Sabba) have spent all of my time working on marketing. Admittedly, we were shameless and scrappy and had varying levels of success.</p><p>When starting VEED we knew nothing about marketing, so we made it our full-time job to learn and execute on our findings.</p></div><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG_20200714_174857.jpg"><figcaption>58 users a day was HUGE!!!</figcaption></figure><p>For first time founders, growth and marketing are often overlooked. The majority of the time, this is because it can appear confusing and complex. Another big reason why technical founder shies away from marketing is that they feel a lot more comfortable coding a new feature because that is what they know.</p><p>You need to understand what acquisition channels are the most relevant for your startup and go deep on understanding them. The book "Traction" by Gabriel Weinberg, founder of DuckDuckGo is a great starting point.</p><p>If you would like to lean more about the exact tactics we used to grow VEED, please check an older post on how we <a href="https://www.veed.io/blog/startup-growth-no-budget/">grew to 50,000 MAU</a></p><p>As entrepreneurs, we like to believe there as a playbook and a recipe to build a successful business.</p><p>The truth is there kinda is, but one of the largest factors of a successful business is luck. A topic topic that many founders like to admit.</p><p>Yes, we worked hard, we made educated decisions, learnt as much as we could and applied our knowledge the best as we could. But looking back on how we got here, I just can't kick the feeling that we got lucky.</p><p>This is my imposter syndrome kicking in again</p><p>The good news is that luck is not 100% out of control and there are things we can do to make ourselves luckier. Two important things happened during our journey that we were smart enough to capitalise on and make ourselves more lucky.</p><blockquote>Example 1<br><strong>We got lucky: </strong>Finding our first two engineers, Mate and Veljko. Without these two we would not be here today. Period.<p><strong>We made our luck: </strong>Posting the job posts everywhere, interviewing as many candidates as possible, not settling for ok. We wouldn't stop until we found the right people, the 100% yes's.</p></blockquote><blockquote>Example 2<br><strong>We got lucky: </strong>Tim …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.veed.io/blog/0-1m-arr-12-months/">https://www.veed.io/blog/0-1m-arr-12-months/</a></em></p>]]>
            </description>
            <link>https://www.veed.io/blog/0-1m-arr-12-months/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844894</guid>
            <pubDate>Wed, 15 Jul 2020 13:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paper Mario: The Origami King is a laugh-out-loud funny RPG on the Switch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23844806">thread link</a>) | @suleaty
<br/>
July 15, 2020 | https://newsworthy.to/article/2020/07/15/paper-mario-origami-king-is-a-laugh-out-loud-funny-rpg-on-switch | <a href="https://web.archive.org/web/*/https://newsworthy.to/article/2020/07/15/paper-mario-origami-king-is-a-laugh-out-loud-funny-rpg-on-switch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><p><time datetime="2020-07-15T13:00:00">July 15, 2020</time> by <a href="https://www.theverge.com/21324614/paper-mario-the-origami-king-review-nintendo-switch">The Verge</a> | <a href="https://newsworthy.to/category/entertainment">Entertainment</a></p><p>A great comedy that also happens to be a great game</p><p>Super Mario’s roleplaying adventures have always been playful twists on the genre. RPGs can be uptight, all melodrama and end-of-the-world theatrics. But games like <em>Super Mario RPG</em> and the <em>Mario &amp; Luigi</em> series took what made RPGs great — the strategic battles, lengthy adventures, and vast stories — and infused them with humor and charm. <em>Paper Mario: The Origami King</em> continues this tradition but updates it in lots of clever ways. It’s the rare game where being funny is its biggest strength.</p><p>As with most Mario adventures, <em>The Origami King</em> involves trouble with Princess Peach, but not in the typical damsel in distress way. At the outset, Mario and his brother arrive at Toad Town for an origami festival, only to discover the city is mostly deserted. Inside the castle, they find a disturbing — and origami-fied — version of the princess. “Why haven’t you joined me in folding glory?” she asks. As it turns out, the princess, and much of the Mushroom Kingdom, are under the control of an evil origami wizard bent on reshaping the world in his image.</p><p>It’s an admittedly silly premise, but it works; the villains and their intentions feel appropriately evil, and it’s a great excuse to venture across the world. As part of his scheme, the origami king uses five gigantic pieces of ribbon to rip Peach’s castle out of the ground and transport it to a remote mountaintop. The goal is simple: destroy the ribbons to get into the castle. Your destination is almost always in view; when you’re out in the world, you can see the ribbons stretching across the landscape until you finally manage to remove them.</p><p><em>The Origami King</em> plays out sort of like an open-world RPG. You play as a flat rendition of Mario venturing across the world — to ancient deserts, underwater dungeons, and abandoned theme parks — all while solving often arcane brain teasers to open up new areas, eliminate the origami menace, and dispose of the ribbons. There are RPG-like mechanics like equippable weapons and additional party members, including an amnesiac Bob-omb and a Toad archaeologist. Battles are clever turn-based affairs that are essentially puzzles: you have to spin enemies around on a wheel to line them up so you can get the right attack in before a timer runs out. In most RPGs, I mash the attack button through random battles, but here, I had to actually pay attention.</p><p>Many of the elements streamline what can often be a tedious and fiddly genre. The battles, outside of bosses, are snappy and fun, and you only have to worry about a few items and skills to succeed. If you get stuck, a helpful origami friend named Olivia is available at any time to give you helpful hints, sort of like a less annoying version of Navi from <em>Ocarina of Time</em>. <em>The Origami King</em> strikes a nice balance between being approachable but still having depth. It’s also wonderfully tactile. While Mario can jump, he also has a hammer to smash everything and anything around him, which he does to open up secret areas, solve puzzles, and rescue flattened toads hidden almost anywhere you look.</p><p>The game looks and plays wonderfully, but really, the star is its sense of humor. It’s downright silly. There are copious puns and visual jokes and all kinds of things that don’t make sense but are delightful regardless. For instance, since you’re made of paper, you can travel around the world via fax machine; the game calls this “fax travel.” At one point, after wandering through a forest of talking trees, I came across firewood chanting “light me!” and “we must burn!”</p><p>Everything is goofy: the most difficult bosses are sentient office supplies, and there are multiple surprise musical numbers and performances, including a multipart stage play that ends in a Shy Guy ballet. Much like <a href="https://www.theverge.com/2019/10/31/20942003/luigis-mansion-3-review-nintendo-switch-gooigi-comedy">the most recent <em>Luigi’s Mansion</em></a>, a lot of the silliness comes from slapstick comedy, as you take your hammer and smash things to see what happens. It could be an unusual toad unfolding after previously being disguised as an origami frog or butterfly, or a secret cafe full of grumbling Bowser minions. At the very least, you’ll see colorful confetti rain down from the tree you just bonked. The story even has rare moments of poignant drama to round out the experience; <em>Paper Mario</em> is not a game where I expected to be shocked by a character’s death, but the team at Nintendo pulled it off masterfully.</p><p>The fact that <em>The Origami King</em> is a great game almost feels like a bonus. It could’ve simply been a vehicle for Nintendo’s goofs, and I would’ve enjoyed it, such is the rarity of truly funny comedy games. But it also happens to be a fantastic example of how to freshen up the classic RPG formula with a few new ideas and clever simplification. In virtually every regard, the latest <em>Paper Mario</em> is anything but flat.</p><p><small>Paper Mario: The Origami King </small><small><em>launches on July 17th on the Nintendo Switch.</em></small></p></article></div></div></div>]]>
            </description>
            <link>https://newsworthy.to/article/2020/07/15/paper-mario-origami-king-is-a-laugh-out-loud-funny-rpg-on-switch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844806</guid>
            <pubDate>Wed, 15 Jul 2020 13:21:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Runnaroo claims to be a privacy-respecting search engine – but they got issues]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23844748">thread link</a>) | @realpanzer
<br/>
July 15, 2020 | https://dev.lemmy.ml/post/37504 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/37504">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dev.lemmy.ml/post/37504</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844748</guid>
            <pubDate>Wed, 15 Jul 2020 13:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developers can't fix bad management]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23844701">thread link</a>) | @replyifuagree
<br/>
July 15, 2020 | https://iism.org/article/developers-can-t-fix-bad-management-57 | <a href="https://web.archive.org/web/*/https://iism.org/article/developers-can-t-fix-bad-management-57">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iism.org/article/developers-can-t-fix-bad-management-57</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844701</guid>
            <pubDate>Wed, 15 Jul 2020 13:14:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book: Writing Maintainable Unit Tests]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23844534">thread link</a>) | @JanVanRyswyck
<br/>
July 15, 2020 | https://principal-it.eu/2020/07/writing-maintainable-unit-tests/ | <a href="https://web.archive.org/web/*/https://principal-it.eu/2020/07/writing-maintainable-unit-tests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<h2>
						Announcing Book: Writing Maintainable Unit Tests
					</h2>
					<p><span>
						July 15, 2020
					</span>
				</p></div>

				
<p>I’m very happy to announce that the first draft of my book <a href="https://leanpub.com/writing-maintainable-unit-tests" target="_blank" rel="noopener noreferrer nofollow">Writing Maintainable Unit Tests</a> has been published on LeanPub. 
It’s the written counterpart of my <a href="https://www.udemy.com/course/writing-maintainable-unit-tests" target="_blank" rel="noopener noreferrer nofollow">video course</a>, with some significant revisions as well as additional content and 
examples.</p>

<p>The book currently contains the first three chapters. I’m still working on the final two chapters which I expect to be 
finished somewhere in autumn.</p>

<p>
    <a href="https://leanpub.com/writing-maintainable-unit-tests" target="_blank" rel="noopener noreferrer nofollow">
        <img src="https://principal-it.eu/assets/img/writing-maintainable-unit-tests-book.jpg" alt="Book cover of 'Writing Maintainable Unit Tests'" width="300">
    </a>
</p>

<p>The book, as well as the video course, is my attempt to teach software developers how to 
<a href="https://principal-it.eu/2020/03/why-write-maintainable-unit-tests/">write maintainable and readable unit tests</a>.
Have a look at the <a href="https://leanpub.com/writing-maintainable-unit-tests" target="_blank" rel="noopener noreferrer nofollow">table of contents</a> and let me know what you think. All feedback is very much 
appreciated.</p>


				<p>
						<em>
							If you're interested in an in-person or online course that teaches you and your team
							how to <u>write maintainable unit tests</u> and <u>get the most out of TDD practices</u>,
							make sure to have a look at our
							<a href="https://principal-it.eu/training.html">trainings and workshops</a>
							or contact us at <span>info@principal-it.be</span>.
						</em>
					</p>

				

				<div>
					<div>
						<div>
							<p><img src="https://principal-it.eu/assets/img/profile-picture-thumbnail.jpg" alt="Profile picture of Jan Van Ryswyck"></p>
						</div>
					</div>
				</div>

				
			</div></div>]]>
            </description>
            <link>https://principal-it.eu/2020/07/writing-maintainable-unit-tests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844534</guid>
            <pubDate>Wed, 15 Jul 2020 13:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook faces another privacy issues]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23844183">thread link</a>) | @UtopiaFans
<br/>
July 15, 2020 | https://saidit.net/s/SocialMedia/comments/5fc9/another_privacy_issue_of_facebook_is_there_any/ | <a href="https://web.archive.org/web/*/https://saidit.net/s/SocialMedia/comments/5fc9/another_privacy_issue_of_facebook_is_there_any/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><hr>



<p>Centralized corporate technocracy monopolies mine users data while providing controlled divisive propaganda narratives without context to social engineer speech, thought, subservience, and manufacture consent for endless war and illusory unjust systems, all the while addicting, isolating, and weakening us.  </p>



<hr>

<p>See also:  </p>

<p><a href="https://saidit.net/s/AlternativeMedia">/s/AlternativeMedia</a> aka Independent Media = Anything other than "mainstream" legacy media or centralized social media propaganda tools of the corporatocracy.  </p>

<p><a href="https://saidit.net/s/censorship">/s/censorship</a>  </p>

<p><a href="https://saidit.net/s/CorporateMedia">/s/CorporateMedia</a> = Legacy "mainstream" media of only 6 companies produce propaganda to deceive, divide, manipulate, and socially engineer all of humanity to be easily governed, exploited, and exterminated by psychotic Machiavellian elite for full spectrum dominance under their techno-corporatocracy.  </p>

<p><a href="https://saidit.net/s/MediaAnalysis">/s/MediaAnalysis</a>  </p>

<p><a href="https://saidit.net/s/propaganda">/s/propaganda</a>  </p>

<p><a href="https://saidit.net/s/ZOG">/s/ZOG</a> (Zionist Occupied Government)  </p>



<hr>

<p>Social media:  </p>

<p><a href="https://saidit.net/s/AntiFacebook">/s/AntiFacebook</a><br>
<a href="https://saidit.net/s/CorporateMedia">/s/CorporateMedia</a><br>
<a href="https://saidit.net/s/DecentralizeAllThings">/s/DecentralizeAllThings</a><br>
<a href="https://saidit.net/s/Facebook">/s/Facebook</a><br>
<a href="https://saidit.net/s/InfoGalactic">/s/InfoGalactic</a><br>
<a href="https://saidit.net/s/MeanwhileOnReddit">/s/MeanwhileOnReddit</a><br>
<a href="https://saidit.net/s/MeanwhileOnVoat">/s/MeanwhileOnVoat</a><br>
<a href="https://saidit.net/s/MediaAnalysis">/s/MediaAnalysis</a><br>
<a href="https://saidit.net/s/newSubreddit">/s/newSubreddit</a><br>
<a href="https://saidit.net/s/Reddit">/s/Reddit</a><br>
<a href="https://saidit.net/s/SaidIt">/s/SaidIt</a><br>
<a href="https://saidit.net/s/SaidItBots">/s/SaidItBots</a><br>
<a href="https://saidit.net/s/ShitRedditorsSay">/s/ShitRedditorsSay</a><br>
<a href="https://saidit.net/s/Twitter">/s/Twitter</a><br>
<a href="https://saidit.net/s/youtube">/s/youtube</a>  </p>


</div>
</div></div>]]>
            </description>
            <link>https://saidit.net/s/SocialMedia/comments/5fc9/another_privacy_issue_of_facebook_is_there_any/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844183</guid>
            <pubDate>Wed, 15 Jul 2020 12:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Simple Workflow Service (SWF)]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23844177">thread link</a>) | @adrianancona
<br/>
July 15, 2020 | https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In this post I’m going to explore Simple Workflow Service (SWF) available in AWS.</p>

<p>To understand what SWF is good for, we need to first understand what a workflow is. <a href="https://en.wikipedia.org/wiki/Workflow">Wikipedia defines it</a> as follows:</p>

<blockquote>
  <p>A workflow consists of an orchestrated and repeatable pattern of activity, enabled by the systematic organization of resources into processes that transform materials, provide services, or process information. It can be depicted as a sequence of operations, the work of a person or group, the work of an organization of staff, or one or more simple or complex mechanisms.</p>
</blockquote>

<p>In computer systems we care about the part about processing information. Some things that could be modeled as workflows:</p>

<ul>
  <li><strong>Deployment pipeline</strong>: We could receive some code as input and then build it in a worker machine. We can run tests in parallel in different machines. If all tests pass we can deploy the binaries to another set of machines.</li>
  <li><strong>Coordinate shipments</strong>: A user buys a product on an online store and the order is placed on a system. A human monitors this system and takes care of finding the products in a warehouse and shipping them to the correct address. When the shipment is made, the information is entered in a system. The workflow notices this information an e-mails the user the shipping details.</li>
  <li><strong>Asynchronous image processing</strong>: A system uploads files to a system for processing (let’s say, create thumbnails). A workflow uses multiple workers to execute the task. If any of the machines fails while processing a set of files, they same work can be taken over by another worker.</li>
</ul>

<!--more-->

<p>Those are some high level examples. In this post I’m going to go over one example in more detail.</p>

<h2 id="components">Components</h2>

<p>Before we start building a workflow, let’s learn a little about the components of an SWF:</p>

<ul>
  <li><strong>Workflow</strong>: A set of activities, and some logic that defines how these work together to achieve some objective</li>
  <li><strong>Domain</strong>: A workflow lives in a domain. A Domain can contain multiple workflows. Workflows in different domains can’t interact</li>
  <li><strong>Execution</strong>: An instance of the workflow with its associated state</li>
  <li><strong>Event</strong>: Represents a change on the state of an execution</li>
  <li><strong>Starter</strong>: A program, or person that starts and execution</li>
  <li><strong>Activity</strong>: A type of task that needs to be performed, such as: resizing images, running tests, etc</li>
  <li><strong>Task</strong>: An invocation of an activity</li>
  <li><strong>Worker</strong>: Program that performs tasks</li>
  <li><strong>Decider</strong>: Program that defines the logic for the workflow</li>
</ul>

<h2 id="machine-repair-workflow">Machine repair workflow</h2>

<p>To help us get familiar with SWF, we are going to create a workflow to model the process for fixing a broken machine in a fleet. It will look something like this:</p>

<p><a href="https://ncona.com/images/posts/fixing-broken-machine-workflow.png"><img src="https://ncona.com/images/posts/fixing-broken-machine-workflow.png" alt="Fixing broken machine workflow"></a></p>

<p>This workflow can be used in a datacenter that runs a lot of machines. We can have the workflow probe machines to see if they are working well. If it notices something wrong, it sets the machine state as <code>maintenance</code> in a database. If it doesn’t find anything wrong, it finishes the execution.</p>

<p>Once a machine is drained we’ll do two things. We’ll have a person take a look at the machine and fix it and we’ll take the oportunity to reimage the machine so we have clean machine when it comes back.</p>

<p>Once the repair and the reimage are done, we can set the state back to <code>available</code> and finish the execution.</p>

<h2 id="getting-ready">Getting ready</h2>

<p>For our activities and the decider, we are going to need the AWS SDK. In this section I’m going to show how to get it ready.</p>

<p>We’ll use Ruby for our examples, since it’s easy to run and it’s very well supported. The latest version of the Ruby SDK at the time of this writing is version 3. We’ll create a <code>Gemfile</code> with dependencies:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>source</span> <span>'https://rubygems.org'</span>

<span>gem</span> <span>'aws-sdk-swf'</span><span>,</span> <span>'~&gt; 1'</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can then install them using:</p>



<p>The AWS SDK will need to communicate with AWS, so we’ll need some credentials, these credentials can be set in environment variables like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span>export </span><span>AWS_ACCESS_KEY_ID</span><span>=</span>&lt;your key <span>id</span><span>&gt;</span>
<span>export </span><span>AWS_SECRET_ACCESS_KEY</span><span>=</span>&lt;your secret&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="activities">Activities</h2>

<p>Each of the boxes in the diagram above is an <code>activity</code>. Activities can be pretty self contained, so we’ll start building those.</p>

<p>An activity works by polling the workflow for pending tasks. If it finds that there is a task it can perform, it does so, and returns a result back. Polling then continues until there is more work to do.</p>

<p>Our activities will share some code with the decider, so let’s create a base class that will be shared between them (<code>workflow_base.rb</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>require</span> <span>'aws-sdk-swf'</span>

<span>class</span> <span>WorkflowBase</span>
  <span>DOMAIN_NAME</span> <span>=</span> <span>'datacenter-domain'</span>
  <span>REGION</span> <span>=</span> <span>'ap-southeast-2'</span>
  <span>TASK_LIST_NAME</span> <span>=</span> <span>'repairs-workflow-task-list'</span>
  <span>VERSION</span> <span>=</span> <span>'14'</span>

  <span>def</span> <span>initialize</span>
    <span>@swf</span> <span>=</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Client</span><span>.</span><span>new</span><span>(</span><span>region: </span><span>REGION</span><span>)</span>
    <span>register_domain</span><span>(</span><span>REGION</span><span>,</span> <span>DOMAIN_NAME</span><span>)</span>
  <span>end</span>

  <span># Register a domain for our workflow (if it doesn't already exist)</span>
  <span>def</span> <span>register_domain</span><span>(</span><span>region</span><span>,</span> <span>domain_name</span><span>)</span>
    <span>swf</span> <span>=</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Client</span><span>.</span><span>new</span><span>(</span><span>region: </span><span>region</span><span>)</span>
    <span>begin</span>
      <span>swf</span><span>.</span><span>register_domain</span><span>({</span>
        <span>name: </span><span>domain_name</span><span>,</span>
        <span>workflow_execution_retention_period_in_days: </span><span>'3'</span>
      <span>})</span>
      <span>puts</span> <span>"Domain </span><span>#{</span><span>domain_name</span><span>}</span><span> registered"</span>
    <span>rescue</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Errors</span><span>::</span><span>DomainAlreadyExistsFault</span>
      <span>puts</span> <span>"Domain </span><span>#{</span><span>domain_name</span><span>}</span><span> already exists"</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This class defines some constants that are shared between the decider and activities. It also initializes the SWF client and register the domain if it doesn’t yet exist.</p>

<p>Because of the way SWF works, it is best if the code for all our activities is handled by a single program. This program will poll for any new tasks in the domain. Every time it sees a task it will execute it and send the result back to SWF. Because each task is blocking, we could spin many copies of this program to allow tasks to be executed in parallel if we wanted to.</p>

<p>The activities handler (<code>activities.rb</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
</pre></td><td><pre><span>require</span> <span>'aws-sdk-swf'</span>
<span>require_relative</span> <span>'workflow_base.rb'</span>

<span>class</span> <span>Activities</span> <span>&lt;</span> <span>WorkflowBase</span>
  <span>ACTIVITIES</span> <span>=</span> <span>[</span>
    <span>'probe_machines'</span><span>,</span>
    <span>'drain_machine'</span><span>,</span>
    <span>'fix_machine'</span><span>,</span>
    <span>'reimage_machine'</span><span>,</span>
    <span>'enable_machine'</span>
  <span>]</span>

  <span>def</span> <span>initialize</span>
    <span>super</span><span>()</span>
    <span>register_activities</span>
    <span>poll</span>
  <span>end</span>

  <span># Register the activities with the domain</span>
  <span>def</span> <span>register_activities</span><span>()</span>
    <span>ACTIVITIES</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>activity</span><span>|</span>
      <span>begin</span>
        <span>@swf</span><span>.</span><span>register_activity_type</span><span>({</span>
          <span>domain: </span><span>DOMAIN_NAME</span><span>,</span>
          <span>name: </span><span>activity</span><span>,</span>
          <span>version: </span><span>VERSION</span><span>,</span>
          <span># Maximum time it can take to process an activity</span>
          <span>default_task_start_to_close_timeout: </span><span>'60'</span>
        <span>})</span>
        <span>puts</span> <span>"Activity </span><span>#{</span><span>activity</span><span>}</span><span> registered"</span>
      <span>rescue</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Errors</span><span>::</span><span>TypeAlreadyExistsFault</span>
        <span>puts</span> <span>"Activity </span><span>#{</span><span>activity</span><span>}</span><span> already exists"</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>

  <span># Poll the domain for tasks for this activity</span>
  <span>def</span> <span>poll</span>
    <span>while</span> <span>true</span>
      <span>options</span> <span>=</span> <span>{</span>
        <span>domain: </span><span>DOMAIN_NAME</span><span>,</span>
        <span>task_list: </span><span>{</span>
          <span>name: </span><span>TASK_LIST_NAME</span>
        <span>}</span>
      <span>}</span>
      <span>task</span> <span>=</span> <span>@swf</span><span>.</span><span>poll_for_activity_task</span><span>(</span><span>options</span><span>)</span>

      <span>if</span> <span>task</span><span>.</span><span>task_token</span> <span>==</span> <span>nil</span>
        <span>puts</span> <span>'Polling expired for activities expired. Trying again'</span>
        <span>next</span>
      <span>end</span>

      <span>if</span> <span>!</span><span>ACTIVITIES</span><span>.</span><span>include?</span><span>(</span><span>task</span><span>.</span><span>activity_id</span><span>)</span>
        <span>raise</span> <span>"Activity </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span> unknown"</span>
      <span>end</span>

      <span># If execute is successfull, it will return the result, otherwise ti will</span>
      <span># throw</span>
      <span>puts</span> <span>"Executing </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>"</span>
      <span>begin</span>
        <span># Call the method for the activity</span>
        <span>result</span> <span>=</span> <span>send</span><span>(</span><span>task</span><span>.</span><span>activity_id</span><span>,</span> <span>task</span><span>,</span> <span>task</span><span>.</span><span>input</span><span>)</span>

        <span>puts</span> <span>"Completing </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>"</span>
        <span>@swf</span><span>.</span><span>respond_activity_task_completed</span><span>({</span>
          <span>task_token: </span><span>task</span><span>.</span><span>task_token</span><span>,</span>
          <span># SWF doesn't provide a way to know which activity this result</span>
          <span># belongs to, so we'll prepend the result with it</span>
          <span>result: </span><span>"</span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>:</span><span>#{</span><span>result</span><span>}</span><span>"</span>
        <span>})</span>
      <span>rescue</span> <span>=&gt;</span> <span>e</span>
        <span>puts</span> <span>e</span>
        <span>puts</span> <span>"Failing </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>"</span>
        <span>@swf</span><span>.</span><span>respond_activity_task_failed</span><span>({</span>
          <span>task_token: </span><span>task</span><span>.</span><span>task_token</span><span>,</span>
          <span>reason: </span><span>@failure</span>
        <span>})</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>

  <span>def</span> <span>probe_machines</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span># Because this is just an example and I don't actually have machines to test,</span>
    <span># I'm going to use some mock data</span>
    <span>machines</span> <span>=</span> <span>[</span>
      <span>'machine-A459Z'</span><span>,</span>
      <span>'machine-M3992'</span><span>,</span>
      <span>'machine-A873R'</span>
    <span>]</span>

    <span>machines</span><span>.</span><span>each</span> <span>do</span> <span>|</span> <span>machine</span> <span>|</span>
      <span># A machine is bad, set it to maintenance</span>
      <span>if</span> <span>check_machine</span><span>(</span><span>machine</span><span>)</span> <span>==</span> <span>'FAIL'</span>
        <span># In a real scenario we would update the database with the new state</span>
        <span>puts</span> <span>"Set machine </span><span>#{</span><span>machine</span><span>}</span><span> to maintenance"</span>
        <span>return</span> <span>machine</span>
      <span>end</span>
    <span>end</span>

    <span>puts</span> <span>'No bad machines found'</span>
    <span>return</span> <span>''</span>
  <span>end</span>

  <span># Randomly decide if it's drained. In a real scenario we would communicate with</span>
  <span># the machine, or check a database</span>
  <span>def</span> <span>drain_machine</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span>puts</span> <span>"Draining machine </span><span>#{</span><span>input</span><span>}</span><span>"</span>
    <span>random_number</span> <span>=</span> <span>rand</span><span>(</span><span>5</span><span>)</span>
    <span>if</span> <span>random_number</span> <span>==</span> <span>4</span>
      <span>puts</span> <span>'Machine is drained'</span>
      <span>return</span>
    <span>end</span>

    <span>raise</span> <span>"</span><span>#{</span><span>input</span><span>}</span><span> is not drained"</span>
  <span>end</span>

  <span># In real life we would check if a human has marked the task as fixed. In this</span>
  <span># case, we'll just sleep and use a random number</span>
  <span>def</span> <span>fix_machine</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span>puts</span> <span>"Check if machine </span><span>#{</span><span>input</span><span>}</span><span> is fixed"</span>
    <span>sleep</span><span>(</span><span>1</span><span>)</span>
    <span>random_number</span> <span>=</span> <span>rand</span><span>(</span><span>2</span><span>)</span>
    <span>if</span> <span>random_number</span> <span>==</span> <span>1</span>
      <span>puts</span> <span>"Machine </span><span>#{</span><span>input</span><span>}</span><span> has been fixed"</span>
      <span>return</span>
    <span>end</span>

    <span>raise</span> <span>"</span><span>#{</span><span>input</span><span>}</span><span> is not fixed yet"</span>
  <span>end</span>

  <span># In real life we would use something like chef to re-image the machine here</span>
  <span># we'll just sleep and use a random number</span>
  <span>def</span> <span>reimage_machine</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span>puts</span> <span>"Reimaging </span><span>#{</span><span>input</span><span>}</span><span>"</span>
    <span>sleep</span><span>(</span><span>1</span><span>)</span>
    <span>random_number</span> <span>=</span> <span>rand</span><span>(</span><span>2</span><span>)</span>
    <span>if</span> <span>random_number</span> <span>==</span> <span>1</span>
 …</pre></td></tr></tbody></table></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/">https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/</a></em></p>]]>
            </description>
            <link>https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844177</guid>
            <pubDate>Wed, 15 Jul 2020 12:26:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mining and Exploring Reddit Data Using Python, Easy]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843902">thread link</a>) | @klarahorton
<br/>
July 15, 2020 | https://beta.deepnote.com/article/mining-and-exploring-reddit-data-using-python | <a href="https://web.archive.org/web/*/https://beta.deepnote.com/article/mining-and-exploring-reddit-data-using-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p>

Reddit <span>is</span> a social network which <span>is</span> mainly organized <span>in</span> communities<span>,</span> also called <span>*</span>subreddit<span>*</span><span>.</span> Each subreddit can be topic<span>-</span>oriented<span>,</span> e<span>.</span>g<span>.</span><span>,</span> <span>[</span><span>/</span>r<span>/</span>gaming<span>]</span><span>(</span>http<span>:</span><span>//</span>reddit<span>.</span>com<span>/</span>r<span>/</span>gaming<span>)</span><span>,</span> <span>or</span> more general<span>,</span> e<span>.</span>g<span>.</span><span>,</span> <span>[</span><span>/</span>r<span>/</span>iama<span>]</span><span>(</span>https<span>:</span><span>//</span>www<span>.</span>reddit<span>.</span>com<span>/</span>r<span>/</span>IAmA<span>/</span><span>)</span><span>,</span> <span>and</span> <span>is</span> populated of submissions posted by users<span>.</span> Each submission can be commented by other users <span>and</span> can be upvoted <span>or</span> downvote<span>,</span> marginally similar to a like <span>or</span> dislike<span>.</span> <span>[</span>At the time of writing<span>]</span><span>(</span>https<span>:</span><span>//</span>www<span>.</span>redditinc<span>.</span>com<span>/</span><span>)</span><span>,</span> Reddit <span>is</span> the <span>5</span><span>-</span>th most visited website <span>in</span> the US <span>and</span> has 430M<span>+</span> average monthly active users<span>.</span>

To explore <span>and</span> mine Reddit<span>,</span> we need a way to access <span>all</span> of its exposed data<span>,</span> such <span>as</span> submissions<span>,</span> comments <span>and</span> users' information<span>.</span> The more brutal <span>and</span> straightforward way obviously <span>is</span> that of scrape the website itself<span>.</span> In particular<span>,</span> scraping Reddit would require a scraper<span>,</span> that <span>is</span> a software which should request one <span>or</span> more webpages<span>,</span> parse them <span>and</span> extract the information of interest<span>.</span> However<span>,</span> this <span>is</span> marginally doable <span>and</span> there are cases <span>in</span> which scraping a website would violate the Term of Service <span>(</span>ToS<span>)</span> of the website itself<span>.</span> Thus<span>,</span> we surely need another way to do it<span>.</span>

Luckily <span>for</span> us<span>,</span> there <span>is</span> a service called <span>[</span>pushshift<span>.</span>io<span>]</span><span>(</span>http<span>:</span><span>//</span>pushshift<span>.</span>io<span>)</span> that provides Reddit data by allowing users to access it via two different forms<span>,</span> that are the direct download of datasets containing Reddit data <span>and</span> the usage of an Application Programming Interface <span>(</span>API<span>)</span><span>.</span> In our case<span>,</span> we resort on the latter by using <span>**</span>psaw<span>**</span><span>,</span> an API wrapper <span>for</span> pushshift<span>.</span>io<span>.</span> To install it<span>,</span> just <span>open</span> up your favourite shell <span>and</span> <span>type</span>

```bash
pip install psaw
```

Having psaw installed<span>,</span> we are now able to query pushshift<span>.</span>io’s API by using the library itself<span>.</span>

To use the library<span>,</span> we need an instance of `PushshiftAPI`<span>.</span> It will be the <span>*</span>entry point<span>*</span> <span>for</span> <span>any</span> request<span>.</span> We can find `PushshiftAPI` within psaw<span>,</span> thus we can <span>import</span> it <span>and</span> define an instance<span>:</span></p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://beta.deepnote.com/article/mining-and-exploring-reddit-data-using-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843902</guid>
            <pubDate>Wed, 15 Jul 2020 11:53:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steve Jobs Interview – Moving to Ireland (1980)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843862">thread link</a>) | @Irishsteve
<br/>
July 15, 2020 | https://www.rte.ie/archives/2014/0124/499863-30-years-since-the-1st-apple-mac-went-on-sale/ | <a href="https://web.archive.org/web/*/https://www.rte.ie/archives/2014/0124/499863-30-years-since-the-1st-apple-mac-went-on-sale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Apple founder Steve Jobs talks to reporter Pat Kenny at the company's Cork plant in 1980.</p>
<p>On 24 January 1984 the first Apple Macintosh computer went on sale.&nbsp;The Apple prided itself on its user-friendly interface, came in a nine inch black and white monitor, accommodated one 3.5 inch floppy disc, and ran the Mac OS 1.0.</p>
<p>Apple has long been synonymous with Ireland and set up a manufacturing plant in Hollyhill Industrial Estate overlooking Cork city. On 25 November 1980 the programme 'Public Account' broadcast a report by Pat Kenny from the Apple plant in Cork, when Pat met up with self-made millionaire and Apple founder Steve Jobs.</p>
<p><img alt="Steve Jobs (1980)" src="https://img.rasset.ie/00086923-622.jpg"><br>
<small>Steve Jobs chats to Pat Kenny at the newly opened Apple plant in Cork (1980)</small></p>
<p>Pat Kenny speaks to Steve Jobs about the origins of Apple and how they came to set up their manufacturing plant in Cork. Steve comments</p>
<blockquote>
<p>We started off building a computer because we couldn't afford to buy one.</p>
</blockquote>
<p>Then all their friends wanted one which gave them the initial market indication that there was a demand for computers. Steve differentiates Apple computers as more "sophisticated" than other computers. Steve predicts that computers will be used extensively in the home, in education and in business. When questioned about the usability of the Apple, Steve comments that the computer weighs about 12lbs, so</p>
<blockquote>
<p>if you don't like what it's doing, you can throw it out the window.</p>
</blockquote>
<p>When the Apple plant opened it was somewhat unconventional in its treatment of its workers. Apple operated a "no clock-in" policy opting instead to trust their employees.</p>
<p>This episode of the programme 'Public Account' was broadcast on 26 November, 1980.</p>

</div></div>]]>
            </description>
            <link>https://www.rte.ie/archives/2014/0124/499863-30-years-since-the-1st-apple-mac-went-on-sale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843862</guid>
            <pubDate>Wed, 15 Jul 2020 11:48:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding up similarity search in recommender systems using FAISS]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23843752">thread link</a>) | @drishya
<br/>
July 15, 2020 | https://caboom.ai/blog/speeding-up-similarity-search-in-recommender-systems-using-faiss-basics-part-i | <a href="https://web.archive.org/web/*/https://caboom.ai/blog/speeding-up-similarity-search-in-recommender-systems-using-faiss-basics-part-i">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Measuring the similarity between vectors or arrays is a calculation that we encounter often while developing recommendation systems or other machine learning models. This often involves performing similarity searches on entire datasets that can be computationally expensive. For systems that require such calculations to happen online in real-time, this can be a major issue and is something we often have to deal with at Caboom.</p><p><br>Luckily, we are not the only ones faced with this problem and there are open-source libraries like <a href="https://github.com/facebookresearch/faiss">FAISS</a> that have been developed to solve this exact problem by the Facebook AI Research team.</p><p>‍</p><p>FAISS or <strong>F</strong>acebook <strong>AI</strong> <strong>S</strong>imilarity <strong>S</strong>earch is a library written in the C++ language with GPU support. It also has Python bindings so that it can be used with Numpy, Pandas, and other Python-based libraries. Its algorithmic enhancements that vastly narrow down the search space for a vector's k-nearest neighbors allow it to have much faster similarity search between vectors as compared to existing libraries like Scikit Learn. This technique is called Approximate Nearest Neighbours (ANN) search, and sacrifices some precision to obtain the vast speedups.&nbsp;</p><p>Compared to other ANN libraries FAISS implements various vector compression, partitioning, and indexing techniques, especially by making use of the parallelism enabled by GPUs to make similarity search lookups more efficient. We will mostly be focusing on its indexing features and how that leads to fast similarity search in recommender systems. There are several other methods and optimizations in FAISS which can’t be covered by this blog alone. For a detailed overview of how its internal mechanism works, different&nbsp; and the previous work it builds upon please refer <a href="https://github.com/facebookresearch/faiss/wiki">here</a>.</p><p>To show the speed gains obtained from using FAISS, we did a comparison of bulk cosine similarity calculation between the FlatL2 and IVFFlat indexes in FAISS and the brute-force similarity search used by one of the most popular Python machine learning frameworks Scikit-learn.&nbsp;</p><p>A dataset of 20k movies was used for this comparison, with the similarity search performed on vectors obtained from the various genres of the movie.The task was to select the top 10 most similar movies for each of the 20k movies from a candidate pool ranging from 0 to 1000 movies. </p><p>‍</p><figure id="w-node-0ec5b7e06d99-2fefdd35"><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0c174333f77039795e2d8a_Screen%20Shot%202020-07-13%20at%2013.56.15.png" alt="Speed comparison between two FAISS indexes"></p></figure><figure id="w-node-cf497c7d8071-2fefdd35"><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0c17886b4272e3e7bd2790_Screen%20Shot%202020-07-13%20at%2013.56.35.png" alt=""></p></figure><p>As seen from the plots above, the time taken to perform the similarity search increases linearly for Scikit-learn to a few seconds, while that for the Flat index based search is an order of magnitude faster.&nbsp;</p><h2>Basic Indexes</h2><p>As stated above the main strength of FAISS is the speed with which it can perform similarity searches on billions of vectors at the cost of some precision. This is possible because of the implementation of indexes in FAISS that the whole package is optimized for. These indexes store a set of vectors and provide search functions in these sets with various vector comparison algorithms. One good way of understanding them is to think of them like the indexes used in databases to make queries faster.&nbsp;</p><p>We will now go through an example implementation of creating a FAISS index.&nbsp;</p><h3>Flat Index</h3><p>The simplest implementation of the index in FAISS is the <strong>IndexFlatL2 index</strong>. It is an exact search index that encodes the vectors into fixed-size codes. As the name suggests it is an index that compares the L2 (euclidean) distance between vectors and returns the top-k similar vectors. During the search, all the indexed vectors are decoded sequentially, and compared to the vector whose nearest neighbors we are being calculated. This vector is also called the <strong>query vector</strong>.&nbsp;</p><p>This is different from how similarity search is done in libraries like Scikit-learn, as we have to choose the kind of similarity we are measuring and select the index accordingly. FAISS also optimizes how the index vectors are stored in memory or disk by using a tree data structure that hugely improves the search time.</p><p>The following code shows the process of defining the index vector size, initiating the IndexFlatL2 index, adding vectors to the index and saving the index into disk.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8a67e212a15625c1ca46_Image1.png" alt=""></p></figure><p>‍</p><p>We can reuse the saved index later for searching a vector's nearest neighbors. The following code snippet shows how to load the index and perform nearest neighbor search on it.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8a7a898b077ff2c73e44_image%202.png" alt=""></p></figure><p>‍</p><p>Output:<br>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8a87898b072b2ac73e45_image%203.png" alt=""></p></figure><p>‍</p><p>‍</p><p>The output shows the resulting indexes and distances for the first five vectors of an index. In the second “distances” matrix we can see that the vectors have their nearest neighbors at the beginning of the array row, with a distance of 0 with itself and increasing in value as we move towards the end.&nbsp;</p><p>Another thing to remember is that in this case the index of the arrays is set automatically by FAISS in increasing order like the "auto_increment" column in SQL databases. It is advisable to use either a mapper with FAISS to real indexes or use a FAISS provided index setting which will come up further along.</p><h3>Cosine Similarity Measurement</h3><p>Although calculating Euclidean distance for vector similarity search is quite common, in many cases <strong>cosine similarity</strong> is preferred. In FAISS we don't have a cosine similarity method but we do have indexes that calculate the inner or dot product between vectors. For example, the <strong>IndexFlatIP</strong> <strong>index</strong>. We can then take advantage of the fact that cosine similarity is simply the dot product between normalized vectors.&nbsp;</p><p>The code snippet below shows how this can be implemented. Partition-based Index</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8aa4dd31940e941cddbd_image%204.png" alt=""></p></figure><p>Another class of indexes in FAISS are partition-based indexes that speed up searches by partitioning the index into clusters and limiting the search to only a few clusters. This method however is not exact as there is no guarantee that the nearest neighbors will be in the clusters searched in.&nbsp;&nbsp;</p><p><br>An example of an index that uses partitioning techniques to make the search space a lot less and far more efficient is <strong>IndexIVFFlat index</strong>.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8aaf04e10128d6d54b3c_image%205.png" alt=""></p></figure><p>‍</p><p>The search operation can be carried out in the same way as earlier indexes. However, in the IVFFlat index we define the “nprobe” hyperparameter to limit the search to only the defined number of clusters nearest to the query vector. This is also an example of how different indexes can be compounded to form a single index.</p><h3>Principal Component Analysis (PCA)</h3><p>We’ve looked at the use cases for some of the basic algorithms in FAISS. This section looks at a method called PCA. It is an algorithm that is popular in unsupervised machine learning that is used to reduce the vector dimensions using <strong>Principal Components</strong> of the vector space.</p><p>In FAISS, PCA is generally followed by indexes like IndexFlatL2 or IndexIVFFlat and they are linked with the help of the <strong>IndexPreTransform</strong> function.&nbsp;One requirement of this method is that the dimension of a vector needs to be a multiple of 4.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8ab9ec95620e8410fb11_image%206.png" alt=""></p></figure><h3>Dimension Remapping</h3><p>PCA allows us to reduce the dimensions but what if we want to increase the dimensionality of the vectors? We may encounter this scenario if we want to use an IndexIVFFlat index for instance. In this case, the dimensionality should ideally be a multiple of 4. FAISS allows us to do this through the <strong>RemapDimensionTransform </strong>method.As an example, let us suppose we have a vector of size 150 that we need to use with an IndexIVFFlat index. The way we transform this to a size that is a multiple of 4 (152) is given below.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8ac81fd412abe2e2dab8_image%207.png" alt=""></p></figure><p>‍</p><div><p>What next?This brings us to the end of Part 1 of this discussion on using the FAISS library from Facebook. Here we looked at the speedup it provides when compared to the similar methods used in Scikit-learn, and how FAISS optimizes this through various indexes. In Part 2 we will go beyond the basic indexing methods and look at more advanced versions. We will also look at the GPU support in FAISS, and how to make the calculations even faster by leveraging them.</p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://caboom.ai/blog/speeding-up-similarity-search-in-recommender-systems-using-faiss-basics-part-i</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843752</guid>
            <pubDate>Wed, 15 Jul 2020 11:32:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hungary's Leading Outlet Became the Target of Political Control]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843605">thread link</a>) | @pabo
<br/>
July 15, 2020 | https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control | <a href="https://web.archive.org/web/*/https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-main">
<article>
<ul><li>Stay updated on the latest news from Hungary by signing up for the free InsightHungary newsletter:</li></ul><p>Vice President of the European Commission for Values and Transparency Věra Jourová sent a <a href="https://index.hu/kultur/media/2020/07/07/aggodik_az_index_fuggetlensegeert_az_europai_bizottsag_alelnoke/">letter</a> on July 7 to Index.hu, Hungary’s largest online news portal, expressing her solidarity with its staff which she said “has been working under very difficult conditions”.<br></p><p>Jourová wrote that while media revenues have been heavily hit by the coronavirus pandemic, “economic pressure should not turn into political pressure...I have been following the situation of Index with concern. What you are doing, the values you are fighting for, media freedom and pluralism, are essential for democracy.”</p><p>The letter came amid what Index considered a fight for its existence. In late June, an urgent <a href="https://index.hu/english/2020/06/21/independence_of_index_in_danger_hungary_press_freedom_media/">public statement</a> signed by around 100 editors and journalists raised the alarm that the site's independence had come under attack, and that the outlet was in "grave danger".&nbsp;</p><p>To many observers of Hungary's media environment, the news came as little surprise. It was widely considered only a matter of time before the outlet faced attacks on its editorial independence, an expectation engendered by years of other Hungarian websites, newspapers, television networks and radio stations being shuttered or suddenly transformed under political and financial pressure.</p><p>This year, media watchdog Reporters Without Borders, which has described the level of media control in Hungary as "unprecedented" in the European Union, <a href="https://rsf.org/en/hungary">ranked </a>the country 89th in the world for media freedom, down 33 places from when the organization began its rankings in 2013. Additionally, the U.S.-based non governmental organization <a href="https://freedomhouse.org/country/hungary/freedom-world/2020">Freedom House</a> gave Hungary a score of two out of four for media freedom and plurality this year.</p><p>Despite this media environment and a perpetual struggle to preserve its independence, Index has, somewhat paradoxically, managed to remain the <a href="https://reutersinstitute.politics.ox.ac.uk/sites/default/files/2020-06/DNR_2020_FINAL.pdf">most-read and one of the most trusted news sources in Hungary</a>&nbsp;for the past 20 years. It has maintained its critical reporting even as government-tied businesspeople were embedded in its ownership structure, and has walked a tightrope between its journalistic principles and a deep uncertainty over when, and how, they might be curtailed.</p><p>This constant vulnerability, and the ways Index’s newsroom has successfully struggled to retain its independence while so many other Hungarian outlets could not, are illustrative of the broader mechanisms that have undermined media plurality and freedom in Hungary for the past decade.</p><h2>“Index Is In Danger”</h2><p>Two years ago, staff at the outlet established an <a href="https://szabadindex.eu/">online independence barometer</a>, a means of directly addressing readers on the status of Index's editorial independence. The barometer was set up after a government-tied figure purchased a stake in the company that controls Index’s revenue stream, and was emblematic of the perceived inevitability of an attack on the site. At the time, a <a href="https://index.hu/english/2018/09/18/index_independence_press_freedom/">letter to readers</a> said that staff felt they were “stuck on the frontline of a world war. Sometimes it’s the Red Army, sometimes it’s the Wehrmacht that marches over us.”<br></p><p>For the two years since its inception, the barometer read “Independent”. But on June 21, for the first time, staff moved the dial to "In Danger".</p><figure><a rel="nofollow" href="https://4cdn.hu/kraken/image/upload/s--axVjxGbd--/7T9PtAkyhooMBj7ps.jpeg"></a><figcaption><svg xmlns="http://www.w3.org/2000/svg" version="1.1" preserveAspectRatio="xMidYMid">
<use xlink:href="/assets/blog/static/icon-defs.svg#icon-photocamera"></use>
</svg><span>Index's "independence barometer"</span><span>Fotó: index.hu</span></figcaption></figure><p>The change came after a series of board meetings of Index’s parent foundation, where a recommendation was made by an outside advisor to break up the site and outsource its content creation to external, newly-formed companies.<br></p><p>The proposal, ostensibly a response to economic pressure caused by the coronavirus pandemic, alarmed several members of the board of directors, including editor-in-chief Szabolcs Dull and CEO András Pusztay. In a <a href="https://index.hu/english/2020/06/21/independence_of_index_in_danger_hungary_press_freedom_media/">statement</a>, Dull wrote that Index was “under such external pressure that could spell out the end of our editorial staff as we know it. We are concerned that with the proposed organisational overhaul, we will lose those values that made Index.hu the biggest and most-read news site in Hungary.”<br></p><p>When news of the proposal leaked in the media, Dull was suspended from the board of directors. A few days later, Pusztay resigned as CEO, saying he could not in good conscience carry out the orders which had been placed on him. Since then, the newly-appointed CEO <a href="https://index.hu/kultur/media/2020/06/30/lemondott_az_index_vezerigazgatoja_zodi_zsolt/">resigned</a> after less than a week on the job, and another <a href="https://index.hu/english/2020/07/07/index_indamedia_hungary_press_freedom_editor_in_chief_advisor/">external advisor</a> has <a href="https://444.hu/2020/07/07/az-indamedia-tanacsadoja-az-index-foszerkesztojenek-levaltasat-surgeti">recommended Dull’s removal</a> as editor-in-chief.</p><p>These disruptive events and proposals by government-tied advisors alarmed Dull, Pusztay and many staff members on their own merits, but the circumstances’ similarities to earlier takeovers of critical media outlets likely added fuel to their suspicions. The events at Index, and some of the actors involved, fit a pattern going back years that illustrates a cohesive strategy for building a media environment that can be managed from the highest levels of political power.</p><h2>The Usual Suspects</h2><p>In March, an influential figure in pro-government media enterprises purchased a 50 percent stake in Indamedia, the company which controls all of Index's revenue streams and has exclusive rights to manage its advertising. The arrival of Miklós Vaszily in Index’s innermost circumference caused new concerns that government-tied figures were closing in on the outlet, evoking alarming memories of an earlier event involving Vaszily that sent shockwaves through the Hungarian media market.</p><p>In 2014, Vaszily oversaw the <a href="https://444.hu/2014/06/05/deutsche-telekom-hungarian-government-collude-to-silence-independent-media">dramatic takeover</a> of Hungary’s then-largest online news outlet Origo, where he served as CEO. Origo’s reporting on cases of corruption within the government, especially concerning two high-level ministers from the governing Fidesz party, reportedly angered party officials and led to political pressure being placed on the outlet’s parent company.&nbsp;</p><p>Vaszily is widely thought to have acted on the government’s behalf to facilitate changes at Origo that resulted in the <a href="https://444.hu/2014/06/02/varatlanul-kirugtak-az-origo-foszerkesztojet/">dismissal of the site’s editor-in-chief</a> and the <a href="https://444.hu/2014/06/04/petho-andras-a-lazar-utazasairol-szolo-cikk-szerzoje-felmond-az-origonal/">resignation</a> of more than 30 journalists over what they considered a pro-government shift in editorial direction. Once a producer of quality investigative journalism and reportage, Origo is now considered by many to be a government mouthpiece.</p><figure><a rel="nofollow" href="https://4cdn.hu/kraken/image/upload/s--RGLOgiES--/6rMVTtlrB1zC1F5pJs.jpeg"></a><figcaption><svg xmlns="http://www.w3.org/2000/svg" version="1.1" preserveAspectRatio="xMidYMid">
<use xlink:href="/assets/blog/static/icon-defs.svg#icon-photocamera"></use>
</svg><span>Miklós Vaszily (center), the joint owner of Indamedia.</span><span>Fotó: Koszticsák Szilárd</span></figcaption></figure><p>Following the takeover of Origo, Vaszily quickly rose through the ranks of government-tied media. He was appointed CEO of Hungary's public broadcasting organization MTVA (itself deeply loyal to the Fidesz-led government), and later became the CEO of Echo TV and the chairman of TV2, both owned by Lőrinc Mészáros, an oligarch and personal childhood friend of Prime Minister Viktor Orbán. According to <a href="https://tldr.444.hu/2020/07/02/csendben-fojtana-meg-az-indexet-a-kormany-de-a-szerkesztoseg-nem-hagyja-magat">reporting by 444’s Pál Dániel Rényi</a>, Vaszily is known to have connections with the highest levels of government, and meets personally with Mr. Orbán to discuss important issues.<br></p><p>His important role in the government-tied media landscape and involvement in the Origo affair made Vaszily’s entrance in the ownership structure of Index seem to portend a future for the outlet which could echo Origo’s fate.&nbsp;</p><p>Origo’s 180-degree turn serves as a template for how government loyalists have repurposed critical media in the service of political interests. Often, rather than hostile legislation or direct intervention being used to transform an outlet, changes in ownership and financial pressure have been applied to indirectly shift outlets’ editorial direction, insulating the government from direct involvement. Financial "reforms" are thus used to justify takeovers under the banner of simple commercial efficiency.&nbsp;</p><p>These same arguments are now being used to account for changes at Index: Vaszily has <a href="https://tldr.444.hu/2020/07/02/csendben-fojtana-meg-az-indexet-a-kormany-de-a-szerkesztoseg-nem-hagyja-magat">denied</a> he intends to muzzle the outlet, but insists economic problems must be addressed – despite the site’s position as the leader on the Hungarian media market.&nbsp;</p><p>Undermining media independence using financial “reforms” is a model that has been frequently used since 2010, although more aggressive methods including outright closure have also been employed. In 2016, Hungary's most-read daily newspaper Népszabadság was <a href="https://www.nytimes.com/2016/10/12/world/europe/hungary-newspaper-nepszabadsag.html">suddenly shut down</a> following the acquisition of the paper’s publisher by an Austrian businessman with ties to Fidesz. Staff arrived one morning to find they had been locked out of the building, and could access neither their company email accounts nor the paper’s website. The closure, which staff described as a “coup”, made international headlines and resulted in a wave of <a href="https://www.theguardian.com/world/2016/oct/09/protests-in-hungary-at-closure-of-main-leftwing-opposition-newspaper">street protests</a> for media freedom, but the paper’s publisher insisted the decision was purely economic, and that the paper had been struggling financially.</p><figure><a rel="nofollow" href="https://4cdn.hu/kraken/image/upload/s--MT582P6T--/6vATDH0v0K1lghSTs.jpeg"></a><figcaption><svg xmlns="http://www.w3.org/2000/svg" version="1.1" preserveAspectRatio="xMidYMid">
<use xlink:href="/assets/blog/static/icon-defs.svg#icon-photocamera"></use>
</svg><span>A protester holds a copy of Népszabadság at a protest against the paper's closure.</span><span>Fotó: Zoltan Tuba.www.tubazoltan.com</span></figcaption></figure><p>Another means for seizing control of the media has been the generous use of <a href="https://www.tandfonline.com/doi/full/10.1080/21599165.2019.1662398?fbclid=IwAR0dDqMkZUlLipK1vS_QqWTEN1qm99Iupb4qde-vj1IW4BVx8kW9vv1LLDE&amp;">government advertising</a> in friendly publications and the withholding of ads in critical ones, heavily distorting the media market and putting financial pressure on independent outlets. Nearly 90 percent of ad revenues in the Fidesz-tied newspaper Magyar Idők came from <a href="https://www.tandfonline.com/doi/full/10.1080/21599165.2019.1662398#F0002">ads paid for by the government</a> in 2017, compared with 3 percent in the conservative Magyar Nemzet (which was government-critical at the time but has since been recaptured). According to editor-in-chief Dull, Index receives practically none of its ad revenue from the government.<br></p><p>Such methods for media control, which have now become commonplace, first began with Fidesz’s entrance to power in 2010, and represented a dramatic interruption of some 20 years of relative balance and development in Hungary’s media market following the collapse of socialism in 1990.</p><h2>Paradise Lost</h2><p>At the time of Index’s founding in the late 1990s, Hungary was entering a period of hopeful optimism following a decade of uncertainty and economic decay that came after what Hungarians call “the system change”, the country’s democratic transition after 1989. The internet was just taking off in the country, and for many, Index was symbolic …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control">https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control</a></em></p>]]>
            </description>
            <link>https://insighthungary.444.hu/2020/07/14/index-and-independence-how-hungarys-leading-outlet-became-the-target-of-political-control</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843605</guid>
            <pubDate>Wed, 15 Jul 2020 11:08:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Online Screen Recorder]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843467">thread link</a>) | @sabbakeynejad
<br/>
July 15, 2020 | https://www.veed.io/screen-recorder | <a href="https://web.archive.org/web/*/https://www.veed.io/screen-recorder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.veed.io/screen-recorder</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843467</guid>
            <pubDate>Wed, 15 Jul 2020 10:49:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rewriting Fortran Software in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843434">thread link</a>) | @fanf2
<br/>
July 15, 2020 | https://mckeogh.tech/post/shallow-water/ | <a href="https://web.archive.org/web/*/https://mckeogh.tech/post/shallow-water/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section></section><section><section id="articleHero"><div><header><div><div><p>
July 14, 2020
• 9 min read</p></div></div></header><p><img src="https://mckeogh.tech/images/shallow-water.png"></p></div></section><article id="articleContent"><h3 id="githubcomrse-standrewscsshallow-waterhttpsgithubcomrse-standrewscsshallow-water"><a href="https://github.com/rse-standrewscs/shallow-water">github.com/rse-standrewscs/shallow-water</a></h3><p>TL;DR: Rewriting isn’t <em>always</em> bad, <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s Law</a> is important and memory bandwidth is a potential bottleneck when doing many simple double precision math operations</p><h2 id="introduction">Introduction</h2><p>As part of an Undergraduate Research Assistant Scheme in my first year of university I was tasked with parallelising a piece of shallow water simulation software written in FORTRAN by Dr David Dritschel of the Vortex Dynamics Research Group, under supervision of Dr. Alexander Konovalov, at the University of St Andrews. There were secondary goals such as improving the testing infrastructure, setting up CI/CD, estimating progress and allowing the computation to be paused and resumed.</p><p>Forewarning: I have essentially zero domain knowledge in this project (and fluid dynamics simulation isn’t exactly the kind of topic you can catch up to research level on over a weekend) so I approached this project from a purely software engineering perspective. As for my Rust experience, I’ve been using it for personal projects since ~2016 and I worked as a Rust software engineer at a startup in Berlin for a year after leaving high school.</p><h2 id="dont-rewrite">Don’t Rewrite</h2><p><a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">Don’t.</a></p><p><a href="https://understandlegacycode.com/blog/avoid-rewriting-a-legacy-system-from-scratch-by-strangling-it/">Rewrite.</a></p><p><a href="https://medium.com/better-programming/how-i-failed-to-deal-with-legacy-code-8e123cff5bce">Legacy.</a></p><p><a href="https://daedtech.com/the-myth-of-the-software-rewrite/">Code.</a></p><p>Not too hard a concept to grasp, is it? Not much ambiguity and a clear line of reasoning to follow as to why legacy software should not be rewritten. Well I read the articles written by people far more experienced and knowledgable than myself and thought:</p><p><img src="https://mckeogh.tech/post/shallow-water/0e1.png" alt="https://knowyourmeme.com/memes/that-sign-cant-stop-me-because-i-cant-read"></p><h2 id="why-my-situation-is-different">Why <em>My</em> Situation is Different</h2><p>All jokes aside, there are situations where a re-implementation is a reasonable option and I did have several factors to back me up.</p><p>FORTRAN is undoubtably <em>very</em> fast and highly suited to HPC problems with decades-optimised compilers and debugging tooling but it does lack certain features, namely memory safety, thread safety, data race guarantees and ergonomic GPU/CLI/TUI libraries.</p><p>Having written parallel software in both C and Rust, the memory safety guarantees and easy parallelisation with Rayon offered by Rust contrasts quite sharply with my poor experience using OpenMP. Replacing <code>.iter()</code> with <code>.par_iter()</code> and having the compiler automatically throw errors for any code that isn’t thread safe is amazing compared with adding OpenMP directive sentinels (designed to be hidden from a non OpenMP-compliant FORTRAN compiler) and manually determining thread and memory safety. Here seems a good a place as any to mention that <a href="https://msrc-blog.microsoft.com/2019/07/16/a-proactive-approach-to-more-secure-code/">“~70% of the vulnerabilities Microsoft assigns a CVE each year continue to be memory safety issues”</a>.</p><p>It was believed initially that GPUs could be used to accelerate the computation, ~another place where Rust’s (while not mature) ecosystem also shines above those offered for FORTRAN~ EDIT: completely untrue, FORTRAN’s GPU acceleratin libraries are very mature and production ready. Additionally when it came to the additional requirements building a <code>ncurses</code> interface in FORTRAN isn’t exactly ergonomic compared with the libraries available in Rust. I spent some time reading through the original implementation and attempted some basic parallelisation with little success due to small errors being hard to diagnose across long executions without snapshot testing across multiple modules.</p><p>Not only was there several “pull” factors, but there was also the absence of the typical reasons you shouldn’t rewrite: I was working as a one-person team, the software was finalised and so never needed to be modified again, it was relatively small so could be rewritten in a matter of months (part time) and is not a live business component so uptime and upkeep of the original implementation are irrelevant.</p><p>Given all of this I decided it would be faster to rewrite in Rust, then be able parallelise it and add features quickly than it would be to plough through with the FORTRAN, and with a go-ahead from my supervisor I got to work.</p><h2 id="translating-fortran-to-rust">Translating FORTRAN to Rust</h2><p><em>Relatively</em> straightforward translation of existing codebases in compiled languages to Rust is a noted benefit due to the combination of software like <a href="https://c2rust.com/">C2Rust</a> to perform automatic translation of C source into Rust, <a href="https://github.com/rust-lang/rust-bindgen">bindgen</a> for automatically generating FFI bindings and of Cargo’s ability to compile code in other languages as part of a Rust project. While there are plenty examples of large projects successfully migrating to Rust this way, the issue I faced was that it would have required a two-step process, first translating from FORTRAN to C and then from C to Rust. I assumed the likelihood that the resulting code would be remotely parsable was very low and I couldn’t even get either of the most popular FORTRAN to C conversion tools to work.</p><p>Since the original implementation was only 6,000 lines total I decided to go with a manual translation. This involved starting at the base of the module tree with the Fast Fourier Transform routines and working upwards. I kept my process simple by inserting small pieces of FORTRAN to dump state at the beginning and end of routines which was then used for snapshot tests for the Rust implementation. This resulted in a thorough, robust testing suite which was invaluble during the optimization period. I really only made one bad design decision (please don’t read through the git history to confirm this 😅) during the translation phase which was thinking that nested <code>Vec</code>s would be easier than using <code>ndarray</code> from the start. This was a Bad Decision™️ and wasted so much time, not only in the abysmal execution speeds slowing down <code>cargo test</code>, but also in that it significantly increased development time. I would replace a statement such as</p><p>with</p><div><pre><code data-lang="rust"><span>// Awful, awful Rust
</span><span></span><span>for</span> i <span>in</span> <span>0</span>..x {
	<span>for</span> j <span>in</span> <span>0</span>..y {
		a[i][j] <span>=</span> a[i][j] <span>*</span> b[i][j]
	}
}
</code></pre></div><p>when the final <code>ndarray</code> version would look like</p><div><pre><code data-lang="rust"><span>// Ergonomic Rust
</span><span></span>a <span>*=</span> <span>&amp;</span>b;
</code></pre></div><p>Clearly the intermediary step could have been skipped and a more direct translation was possible. I wrote a regex to replace FORTRAN array indexing syntax (<code>array(x,y,z)</code>) to nested <code>Vec</code>s in Rust (<code>array[x][y][z]</code>), when <code>ndarray</code> syntax (<code>array[[x,y,z]]</code>) would have been a far simpler conversion. If this decision wasn’t bad enough, I also wasted time writing several functions to convert between a byte slice and the nested <code>Vec</code>s with the FORTRAN memory layout when <code>ndarray</code> has a built-in preset for FORTRAN shape and strides.</p><p>One issue that arose during testing was that due to the accumulation of small errors in floating point math, results would be slightly different between operating systems and hardware configurations which made the fantastic snapshot testing tool <code>insta</code> unsuitable. Instead <code>ndarray</code>’s <code>serde</code> and <code>approx</code> feature flags are used to read serialised arrays from disk to compare approximately during tests which has been working well.</p><h2 id="optimizing">Optimizing</h2><h3 id="parallelisation">Parallelisation</h3><p>Fundamentally the problem is not one that may be described as “embarrassingly parallel”, which was the assumption made going into the project (early discussions involved expectations of a 100x improvement on the university cluster). Ideally we would be want many large chunks of independent computation operating on a small amount of data, making it easy to distribute work across threads, GPUs and potentially different machines, but unfortunately I learned this problem is quite far from that ideal.</p><p>The outermost loop advances through time and is therefore strictly sequential, and in the primary function of the program (<code>src/nhswps/advance.rs:advance</code>) a large portion is iterated over twice, also strictly sequential. Some other lower-level functions perform operations on individual layers and so can be parallelised completely, but these are not generally very complex functions and so finish quickly before returning to sequential execution. <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s Law</a> comes into affect here, describing how even if everything that can be parallelised is, there are fundamental limits to the scaling we can ever achieve.</p><h3 id="memory-bandwidth-issues">Memory Bandwidth Issues</h3><p>Throughout the program there are several kinds of operations being performed on the 2- and 3-dimensional arrays. Transformations between physical and spectral is common, involving calling the Fourier transform functions and swapping axes. Other than those, many operations are simple additions, subtractions and multiplications between arrays, sometimes including constants. The result of this is that these simple operations are being performed on some very large amounts of data which I believe is resulting in a memory bandwidth bottleneck. This hypothesis explains why SIMD did not improve performance and performance is not significantly improved by parallelisation. It only takes several cycles to perform a floating point ADD or MUL instruction, so even at tens of gigabytes per second of memory bandwidth it will be insufficient to keep the CPU “fed”. Performing the operations with AVX-2 instructions does not improve performance because even though the same operation may now be performed on several floats simultaneously the limit is still how quickly they may be read from memory. It is slightly more complicated in the multithreaded context because there is an improvement in performance; perhaps due to multiple threads being able to increase the amount of data read from memory. The program is also very cache-unfriendly, reading large amounts of data in only to perform a simple, fast operation before reading in new data. At several gigabytes in size even individual layers aren’t even close to being able to reside in on-die cache. I am unsure of how I might collect proof of my hypothesis but I believe it explains a great deal of the behaviours I’ve witnessed throughout this project.</p><h3 id="gpu-unsuitability">GPU Unsuitability</h3><p>There was also some hope at the beginning of the project that GPUs could be used but there are two main reasons they are unsuitable.</p><p>Firstly, ~GPUs with large amounts of VRAM (128GB+) simply aren’t available~ EDIT: I was wrong, <em>commercial</em> gaming and workstation GPUs don’t get that large, but there are plenty of datacentre options, like the <a href="https://cloud.google.com/blog/products/compute/announcing-google-cloud-a2-vm-family-based-on-nvidia-a100-gpu">A100</a>. There is the <a href="https://www.amd.com/en/products/professional-graphics/radeon-pro-ssg">Radeon Pro SSG</a> which is a really interesting product but the memory bandwidth of …</p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mckeogh.tech/post/shallow-water/">https://mckeogh.tech/post/shallow-water/</a></em></p>]]>
            </description>
            <link>https://mckeogh.tech/post/shallow-water/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843434</guid>
            <pubDate>Wed, 15 Jul 2020 10:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pavel Durov wants a law to make Apple allow iPhone users install other app store]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23843296">thread link</a>) | @vvpvijay
<br/>
July 15, 2020 | https://androidrookies.com/telegram-developer-wants-a-law-to-make-apple-allow-iphone-users-to-install-apps-from-other-app-stores/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/telegram-developer-wants-a-law-to-make-apple-allow-iphone-users-to-install-apps-from-other-app-stores/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8890"><div><div><div><p>VK social networking website and Telegram messenger App founder and developer, Pavel Durov wants Apple to let iPhone users install different App stores other than Apple App Store. Not only that, but he also wants legislation to make this happen.</p><p>Speaking at the panel discussion with Russian Prime Minister Mikhail Mishustin and representatives of the IT industry in Innopolis, Telegram Manager and Vice President, Ilya Perekopsky said that Apple and Google are holding back the development of startups by charging a tax of 30 percent commission from app developers. Immediately after Perekopsky’s speech,&nbsp;Durov published an article in which he called for legislation mandating Apple to be legally obliged to allow users to install an alternative App Store on the iPhone. Durov says that Tim Cook, Apple CEO should be obligated to this at the legislative level.</p><p>Durov is taking the bull by its horn. Apple has been successful because of its closed technology. It not only does not allow any other App store to be installed on iPhones but it also takes action against any iPhone jailbreaks that happen. We all know that the <a href="https://androidrookies.com/unc0ver-jailbreak-tool-for-iphone-released-works-on-all-ios-versions-including-ios-13-5/">uc0ver team released a jailbreak</a> exploiting the previously unknown vulnerability in iOS just hours after Apple released iOS 13.5. The <a href="https://androidrookies.com/kernel-vulnerability-unc0ver-jailbreak-patched-as-apple-releases-ios-13-5-1/">iPhone jailbreak was shut down in iOS 13.5.1</a> within days by Apple. Many private iPhone App stores exist like Cydia, Xabsi, etc but they work only on jailbroken iPhones.</p><p>Much of Apple’s profit is from selling content on its App stores. In fact, Apple’s App Store platform grossed around $50 billion for App store in 2019, according to an analysis by CNBC. Apple takes 30 percent commission from App developers to make their apps available on Apple Store. Last year it paid $35 billion to developers from the App store revenue and kept $15 billion for itself.</p><p>Durov has reasons for being mad at Apple for not allowing other App stores. Durov says that Russian startups fail to make money by paying 30% to Apple. “Preventing two supranational corporations from collecting taxes from all of humanity is not an easy task. Corporations employ thousands of lobbyists, lawyers, and PR agents, and their budgets are unlimited. At the same time, app developers are scattered and scared, as the fate of their projects depends entirely on the favor of Apple and Google,” wrote Pavel Durov.</p><p>Durov also has a personal bias for wanting Apple to open up its iOS for alternative App stores. In 2016, Apple banned the Telegram team from launching its own game platform. This hurt Durov and Telegram’s ambitions, “We had to remove the telegram games catalog that we had already created and almost the entire platform interface, otherwise Apple threatened to remove Telegram from the AppStore.”</p><p>Recently, <a href="https://androidrookies.com/apple-threatens-to-remove-hey-com-email-app-unless-it-pays-outrageous-cuts-to-them/">email client, Hey.com</a> had a similar experience with Apple regarding publishing their App on the Apple App store.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/telegram-developer-wants-a-law-to-make-apple-allow-iphone-users-to-install-apps-from-other-app-stores/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843296</guid>
            <pubDate>Wed, 15 Jul 2020 10:21:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The hardship of SaaS in the video games industry]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843282">thread link</a>) | @philippz
<br/>
July 15, 2020 | https://philippzentner.com/hardship-saas-video-games-industry | <a href="https://web.archive.org/web/*/https://philippzentner.com/hardship-saas-video-games-industry">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block="true" data-editor="gn18" data-offset-key="m69q-0-0"><p><span data-offset-key="m69q-0-0">At </span><a href="https://www.stomt.com/"><span data-offset-key="m69q-1-0">STOMT</span></a><span data-offset-key="m69q-2-0"> we've been focusing on the video games industry. And let me tell you, it's been a ride. When we started out, we tried to approach the industry from the bottom-up. </span><span><span data-offset-key="m69q-3-0">We got feedback and love from independent developers first and then started to approach bigger companies</span></span><span data-offset-key="m69q-4-0">. It became difficult right here.</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="1b2ek-0-0"><p><span data-offset-key="1b2ek-0-0">Roughly 50% of that <a href="https://newzoo.com/insights/trend-reports/newzoo-global-games-market-report-2020-light-version/" rel="nofollow">~$160 billion revenue market (2020, Newzoo)</a> </span><span><span data-offset-key="1b2ek-1-0">is made by</span></span> <span><span data-offset-key="1b2ek-3-0">just</span></span><span data-offset-key="1b2ek-4-0"> 10-15 companies. The rest </span><span><span data-offset-key="1b2ek-5-0">is distributed</span></span><span data-offset-key="1b2ek-6-0"> across many small studios and publishers across the world. But what does that </span><span><span data-offset-key="1b2ek-7-0">really</span></span><span data-offset-key="1b2ek-8-0"> mean? </span><span><span data-offset-key="1b2ek-9-0">The gaming industry works like this: game developers have a vision, which then gets financed and marketed by publishers</span></span><span data-offset-key="1b2ek-10-0">. </span><span><span data-offset-key="1b2ek-11-0">When we talk about the biggest 10-15 companies, we're actually talking about publishers, which in return work with dozens of globally distributed teams of game development studios to create the next hit</span></span><span data-offset-key="1b2ek-12-0">. </span><span><span data-offset-key="1b2ek-13-0">When you aim to sell a service to the gaming industry, make sure to target either 100% publishers or a 100% game developers, which is hard as the line is blurry</span></span><span data-offset-key="1b2ek-14-0">. Depending on their deal, certain responsibilities are shifting. For STOMT it was especially difficult: Who cares about feedback? Customer service (publisher)? The producer (developer)? The developer? Marketing (publisher)? Finding someone who cares about it is easy, finding someone who wants to make it part of their budget not.&nbsp;</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="a3hni-0-0"><p><span><span data-offset-key="a3hni-0-0">For publishers it's the classic venture capital rule of thumb, that one success out of ten investments have to outweigh the rest</span></span><span data-offset-key="a3hni-1-0">. And it's a risky business. Most games fail. </span><span><span data-offset-key="a3hni-2-0">Platforms and app stores </span></span><span><span data-offset-key="a3hni-3-0">are saturated</span></span><span><span data-offset-key="a3hni-4-0"> and games, as part of the entertainment industry, are competing for consumer's attention</span></span><span data-offset-key="a3hni-5-0">. By the end of each year we see massive amounts of layoffs, shutdowns and M&amp;As. It </span><span><span data-offset-key="a3hni-6-0">easily</span></span><span data-offset-key="a3hni-7-0"> cuts your deal flow by 30%.</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="eed00-0-0"><p><span data-offset-key="eed00-0-0">And that is expensive. </span><span><span data-offset-key="eed00-1-0">Due to the very globally distributed publisher-developer relationship, you spend a lot of money on going to conferences and meeting people face to face, building up relationships</span></span><span data-offset-key="eed00-2-0">. In 2018 I did sale and business development in 14 countries. In fact, if you'd want to attend all gaming industry events, you could be on the road almost every day. </span><span><span data-offset-key="eed00-3-0">In between</span></span><span><span data-offset-key="eed00-4-0"> you try to figure out who your buyer persona / decision-maker is and if that person is part of the developer or part of the publisher side</span></span><span data-offset-key="eed00-5-0">. </span><span><span data-offset-key="eed00-6-0">You better build</span></span><span><span data-offset-key="eed00-8-0">&nbsp;something that </span></span><span><span data-offset-key="eed00-9-0">is needed</span></span><span><span data-offset-key="eed00-10-0"> all the time</span></span><span data-offset-key="eed00-11-0">.</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="f3998-0-0"><p><span data-offset-key="f3998-0-0">Timing also plays a huge role. The development of a game takes 2-4 years. </span><span><span data-offset-key="f3998-1-0">If you're too early, you're not relevant, if you're too late, you won't end up on the roadmap, assuming you're a middleware provider</span></span><span data-offset-key="f3998-2-0">. The sales process is lengthy. So you better have huge pipeline and try to be present in people's head all the time.</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="v7i9-0-0"><p><span><span data-offset-key="v7i9-0-0">As an industry of passion, you're also confronted with certain paradigms, that won't fit your McKinsey brain</span></span><span data-offset-key="v7i9-1-0">. </span><span><span data-offset-key="v7i9-2-0">There's often a lack of ownership, process or transparency and that makes it hard to keep up with your deal-flow</span></span><span data-offset-key="v7i9-3-0">. We also see it in the high fluctuation within teams. Fluctuation seems to be much higher than elsewhere. </span><span><span data-offset-key="v7i9-4-0">This is still the creative industry and people are not only passioned about what they are doing but also much more emotional when it comes to decisions</span></span><span data-offset-key="v7i9-5-0">. So don't even try to sell to indies (referring to small &lt;10 people teams). They often have very limited budgets and are not very business minded. With the availability of <a href="https://www.game.de/wp-content/uploads/2017/02/2019_Guide-to-the-German-Games-Industry_web.pdf" rel="nofollow">more and more grants for the creative gaming industry,</a> this is changing as considerations about the underlying business model have to be made much earlier</span><span data-offset-key="v7i9-7-0">.&nbsp;</span></p></div><div data-block="true" data-editor="gn18" data-offset-key="ech92-0-0"><p><span data-offset-key="ech92-0-0">Another cost-block is the development and maintenance of relevant integrations. </span><span><span data-offset-key="ech92-1-0">The ecosystem of the gaming industry is currently based on certain game engines like Unity, Unreal, GameMaker, Cocos2D and the proprietary ones, often written in C++, of the big ones</span></span><span data-offset-key="ech92-2-0">. On top we have unique to the gaming industry relevant platforms like Twitch and Discord. Most platforms are still young and have frequent releases containing breaking changes. Have fun trying to find a passioned game developer that likes to work on middleware. It's expensive. </span><span><span data-offset-key="ech92-3-0">We're happy to have a capable CTO (shoutout to <a href="https://www.linkedin.com/in/maxklenk/">Max Klenk</a>), who is flexible enough to solve any problem in any language on any system</span></span><span data-offset-key="ech92-4-0">. I mean, look at </span><a href="https://www.stomt.com/integrations"><span data-offset-key="ech92-5-0">that</span></a><span data-offset-key="ech92-6-0">.&nbsp;</span></p></div></div></div>]]>
            </description>
            <link>https://philippzentner.com/hardship-saas-video-games-industry</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843282</guid>
            <pubDate>Wed, 15 Jul 2020 10:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Education 2.0 – A brand new education system]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843235">thread link</a>) | @aryankashyap
<br/>
July 15, 2020 | https://aryankashyap.com/education-2-dot-0 | <a href="https://web.archive.org/web/*/https://aryankashyap.com/education-2-dot-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_body_1570553">
    
      <div><p>What this essay does is that it introduces a brand new education system. This education system is way more effective than the current education system we have in place. And unlike the current education system, which has been the same for a long time. This one is constantly getting better with time and data, thanks to AI.<br></p><p>The best thing about it is that it's totally free of cost. So anyone in the world with access to a basic smartphone+Internet can access Education 2.0. Meaning, now everyone has the same educational opportunities as a Harvard/Stanford student.<br></p><p>You see, education is the most fundamental thing to human progress. And once you deploy something like Education 2.0 on a global scale, it will have huge positive implications on economic growth, life quality, and human progress. And to emphasise what I just said, the collective intelligence of humanity is the best predictor of future progress.Â&nbsp;<a href="https://ourworldindata.org/global-education#education-outcomes-predict-economic-growth" target="_blank">Here</a>Â&nbsp;is some empirical data to prove this statement. Nevertheless, you don't need empirical evidence; look around, education is what drives societal growth.<br></p><p>Looking at the current education system we have in place. It would be unfair to say that it hasn't done an excellent job in aiding human progress. Resolving the COVID-19 Pandemic, the Apollo Program, the iPhone, Tesla, SpaceX, the Internet, All of Science etc. are a prime example.<br></p><p>But it certainly hasn't been able to keep up with the growing human population, and the challenges raised by it. Looking at all the pressing issues, we face today like global poverty, climate change, and war. The incapability of civilisation to solve these problems stems from the fact that it's not educated enough as a whole. There is conclusive evidence to prove this â€”Â&nbsp;<a href="https://ourworldindata.org/global-education#social-returns-to-education" target="_blank">Education correlates with prosocial behaviour</a>. Prosocial behaviour is behaviour, which affects society as a whole.<br></p><p>So the best way to ensure that we progress into a brighter future is by rewiring the current education system. So it can keep up with the ever-growing population and the challenges we face, which will then eventually increase the collective wisdom and prosocial behaviour of humans at a much faster rate.<br></p><p>There are 3 main issues with the current education system, which dramatically lowers its potential.<br></p><ol>
<li>Its inability to reach a large population of the world.</li>
<li>The unequal distribution of resources.</li>
<li>The low efficacy of the current learning environments (i.e. lectures/books).</li>
</ol><p>And Education 2.0 fixes all of these issues.<br></p><p><strong><u>No access to education</u></strong></p><p>The biggest problem with the current education system is that it's unable to reach an unfairly enormous number of the global population. People say that education is a human right, but looking at the current situation â€” that doesn't seem so.</p><p>According to Humanium.org,Â&nbsp;<strong>72 million</strong>Â&nbsp;children of primary education age are not in school, andÂ&nbsp;<strong>759 million</strong>Â&nbsp;adults are illiterate.<strong>Â&nbsp;</strong>And we haven't even considered the inconsistency in educational outcomes yet.<br></p><p>Now I would like to explain the enormous implications this has on the economy. But first, I would like toÂ&nbsp;<a href="https://ourworldindata.org/grapher/correlation-between-mean-years-of-schooling-and-gdp-per-capita" target="_blank">establish a conclusive link between Education and GDP per capita</a>.<br></p><p>Now doing the math:<br></p><ul><li>
<strong>$18,381</strong>Â&nbsp;is the global average GDP per capita (a measure of economic output per person), and we haveÂ&nbsp;<strong>831 million peopleÂ&nbsp;</strong>with no access to education at all.</li></ul><ul><li>
<strong>831 million people * $18,381 ~ $15 Trillion</strong>Â&nbsp;worth of economic output wasted. And it has a growth rate of ~<strong>Â&nbsp;1.8% per year</strong>Â&nbsp;(Taking into account the growth rates of global GDP &amp; global population).</li></ul><ul><li>To put this number in perspective, this is more than the GDP of<strong>Â&nbsp;China</strong>,Â&nbsp;<strong>India,</strong>Â&nbsp;andÂ&nbsp;<strong>the UK</strong>Â&nbsp;separately, andÂ&nbsp;<strong>$5 TrillionÂ&nbsp;</strong>less than the USA.</li></ul><p>There is no doubt that the current model of the education system is responsible for this issue. An education system is basically a collection of what we call "learning environment.". And a learning environment is an environment where learning takes place (i.e. classroom).</p><p>You see, the major problem with the current system is the high relative cost of setting up that learning environment (i.e. a classroom with qualified teachers, furniture, and students, etc.). So when you scale the education system, the setup + maintenance costs increase with it. And some countries just don't have the resources to scale. This can be due to many factors like large population, not enough teachers, etc. All of these issues then boil down to one primary issue â€” lack of economic resources, aka no money.</p><p>Scaling requires huge costs, which then dramatically lowers the potential for impact. Due to which, a significant amount of people in the world don't have access to basic education.</p><p>To beat this issue, what we need to do is switch to a new model of the education system. One which can scale cheaply and effectively. The best way to do this is by moving to a more digitalised education system.</p><p>One way to go about doing this is by leveraging Software, AI, and low-cost smartphones. Software and AI can be leveraged to create digital learning environments, which are more effective than the current learning environments we have, and its efficacy improves with time &amp; data. These AI-taught lessons will be way better than attending a Stanford/Harvard lecture.<br>
</p><p>Once this works, the next thing to do is to ensure it supports low-cost smartphones, which will then allow for distribution at an enormous scale, while keeping the costs minimal. This will go a really long way in closing the educational gap. The best thing is that now anyone in the world will be able to have the same educational opportunities as an Ivy-League student.</p><p>In the long-term, you will see substantial positive implications on collective prosocial behaviour, economy, and quality of life. And redundancy in the current education system.<br>
</p><p><strong><u>Unequal distribution of educational resources</u></strong><br>
</p><p>First, we looked at inequality in terms of access to education. Now, we're going to look at inequality inside the people with access to education (in terms of the quality of educational resources). Turns out that this has huge negative implications on the overall learning outcome of the education system.</p><p>It is implausible to sustain the quality of educational resources (e.g. teachers, books, etc.) as you scale (make it available for a larger population) the education system. Due to which, a major side-effect of scaling is that it induces a widely unequal distribution of educational resources, which varies by economic demographic. Which then leads to variation in educational outcomes.</p><p>This is why the number of high-school graduates who attend prestigious colleges tends to be higher in private high-schools, relative to a public high-schools. The quality &amp; quantity of educational resources (quality of teachers, study material, support, etc.) available to students at the private school is more elevated. Which then leads to higher success.Â&nbsp;<br></p><p>Inequality in educational resources leads to a variation in educational outcomes, which then lowers the average output of the education system.</p><p>Now, coming around to solve this issue. We need to create a system where the quality of educational resources is the best on earth. And it's available to everyone, no matter their economic situation. And finally, as it scales, its overall effectiveness doesn't reduce.Â&nbsp;<br></p><p><strong><u>Low efficacy of current learning environments</u></strong></p><p>The final issue I would like to talk about is regarding the teaching methods used currently. Teaching methods are ways in which teachers teach the student. Â&nbsp;<br></p><p>The problem is that the current teaching methods, which are used around the world, are scientifically flawed. This then makes the process of learning inefficient and ineffective. And on a large scale, it reduces the learning output (the product of learning) of the education system.<br></p><p>You might think that sitting in a classroom, while a teacher speaks out everything, and you note it down is an excellent way to learn. But in fact, this method is flawed. The reason it's flawed because it bears no consideration whatsoever to how our brain operates during learning. Due to which, the conversion rate from auditory + visual perception to long-term memory is low. This dramatically lowers the learning potential of the student.<br></p><p>The modern K-12 education system was established back in the 19th century to prepare the population to participate in the Industrial Revolution. At the time, not a lot of thought was given to the science of how we learn; they just wanted a cheap way to deliver information to a large number of students. And surprisingly, this factory model of the education system hasn't changed since then.<br></p><p>What we need to do now is to build a digital learning environment, which makes learning way more effective &amp; efficient. Leading to a dramatic increase in learning output of the education system. And leverage AI, to make it so that it improves its efficacy with time &amp; data.<br></p><p>The way to do this is by understanding thoroughly, how the human brain operates while learning. And then using those scientific principles to design the learning environment.Â&nbsp;<br></p><p>Here is a fantastic essay by Andy Matuschak, which explains what I just said above better. You can read itÂ&nbsp;<a href="https://andymatuschak.org/books/" target="_blank">here</a>.</p><p>The starting point for this digital learning environment should be something, which is way more effective than any learning environment present today. Deploying this on a global scale will yield dramatically higher overall learning output than today. Making the current education systems redundant.Â&nbsp;</p><p>This would be the first step in accelerating the advent of Education 2.0. A world where high-quality education is free of cost to anyone and the quality of education is increasing over time. In the long term, this will mitigate all forms of inequality, and help humanity get onto a path of something bigger and brighter, thanks to its more immense collective wisdom.</p><p><b><u>Education 2.0Â&nbsp;</u></b></p><p><b><u></u></b>We have now talked about the major issues our education system faces and potential solutions to them. I would now like to introduce a brand new education system â€” Education 2.0.<b><u><br></u></b></p><p>Introducing …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aryankashyap.com/education-2-dot-0">https://aryankashyap.com/education-2-dot-0</a></em></p>]]>
            </description>
            <link>https://aryankashyap.com/education-2-dot-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843235</guid>
            <pubDate>Wed, 15 Jul 2020 10:11:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple and Ireland have won their appeal against the EU €13B tax ruling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843150">thread link</a>) | @benoitg
<br/>
July 15, 2020 | https://www.thejournal.ie/apple-tax-fine-gael-fianna-fail-government-eu-5149993-Jul2020/ | <a href="https://web.archive.org/web/*/https://www.thejournal.ie/apple-tax-fine-gael-fianna-fail-government-eu-5149993-Jul2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="articleContent">

                    <p title="Wednesday 15 Jul 2020, 3:25 PM"><span></span>Updated Wed 3:25 PM</p>                <p>A TOP EU court has ruled in favour of Ireland and Apple in their appeal against the European Commission’s finding that the country breached state aid rules in its dealings with the multinational.</p>
<p>The European Commission previously ordered the US company to hand back €13 billion in unpaid tax and over €1 billion in interest payments to the Irish government.</p>
<p>Both Ireland and Apple appealed that ruling and the General Court of the European Union has now found in their favour.</p>
<p>It is widely expected that this ruling will be appealed to the European Court of Justice, with parties having a little over two months to file an appeal.</p>
<p>In its judgement, the General Court of the European Union said:
</p>
<blockquote>
<p>By today’s judgement, the General Court annuls the contested decision because the Commission did not succeed in showing to the requisite legal standard that there was an advantage for the purposes of Article 107(1) TFEU.According to the General Court, the Commission was wrong to declare that Apple Sales International (ASI) and Apple Operations Europe (AOE) had been granted a selective economic advantage and, by extension, State aid.The General Court endorses the Commission’s assessments relating to normal taxation under the Irish tax law applicable in the present instance, in particular having regard to the tools developed within the OECD, such as the arm’s length principle, in order to check whether the level of chargeable profits endorsed by the Irish tax authorities corresponds to that which would have been obtained under market conditions.However, the General Court considers that the Commission incorrectly concluded, in its primary line of reasoning, that the Irish tax authorities had granted ASI and AOE an advantage.
</p>
</blockquote>
<p>Apple Operations International (AOI) and Apple Sales International (ASO) were two Apple subsidiaries that were based in Ireland.&nbsp;</p>
<p>The General Court of Justice went on to say: “The Commission did not prove, in its alternative line of reasoning, that the contested tax rulings were the result of discretion exercised by the Irish tax authorities and that, accordingly, ASI and AOE had been granted a selective advantage.”</p>

<p><strong>Reaction</strong></p>
<p>Both Apple and the Irish government have welcomed the judgement.</p>
<p>“This case was not about how much tax we pay, but where we are required to pay it,” an Apple spokesman said in a statement.</p>
<p>“We’re proud to be the largest taxpayer in the world as we know the important role tax payments play in society,” Apple added.</p>
<p>The government has welcomed the judgement, stating in a statement that Ireland has “always been clear that, based on Irish law, the correct amount of Irish tax was charged and that Ireland provided no State aid to Apple”.&nbsp;</p>
<p>“Ireland appealed to the Commission decision on that basis and the judgement today from teh court vindicates this stance.”</p>
<p>The Department of Finance said the decision showed there had been “no special treatment” for the tech giant.</p>
<p>“We welcome the judgment by the General Court of the European Union annulling the Decision of the European Commission of August 2016, which alleged Ireland provided State aid to Apple,” the department said in a statement.</p>
<blockquote>
<p>Ireland has always been clear that there was no special treatment provided to the two Apple companies – ASI and AOE. The correct amount of Irish tax was charged taxation in line with normal Irish taxation rules. Ireland appealed the Commission decision on the basis that Ireland granted no state aid and the decision today from the Court supports that view.</p>
</blockquote>
<p>Finance Minister Paschal Donohoe said the judgement “proves Ireland was correct to pursue this case in the European courts”.&nbsp;</p>


<p>The court was asked to determine whether two tax rulings delivered by Revenue in 1991 and 2007 allowed Apple to funnel profits through Irish-anchored structures without paying tax in any jurisdiction.</p>
<p>It is the first legal ruling in a case that formally kicked off in 2014 when the Commission opened an investigation into the matter, which concluded in 2016. The decision could have major implications for the European Commission’s plans to harmonise tax regimes across member states.&nbsp;</p>
<p>The Commission had found that the two rulings had breached EU state aid rules designed to prevent individual companies from receiving favourable treatment from member state governments. As then-commissioner for competition Margrethe Vestager put it at the time, “Ireland had granted illegal tax benefits to Apple”.</p>
<p>After concluding that Apple had been paying corporation tax at an effective rate of just 0.005%, the Commission ordered the US company to hand back €13 billion in unpaid tax and over €1 billion in interest payments to the Irish government.&nbsp;</p>
<p>Apple denied that it had ever sought special deals with any government and accused the Commission of selectively quoting “tiny figures”.&nbsp;</p>
<p><a href="https://ec.europa.eu/commission/presscorner/detail/en/statement_20_1356">In a statement this morning</a> Vestager, who is now Executive Vice-President of the Commision, said that the body will “carefully study the judgment and reflect on possible next steps”.</p>
<p>“The Commission stands fully behind the objective that all companies should pay their fair share of tax,” she said.&nbsp;</p>
<blockquote>
<p>If member states give certain multinational companies tax advantages not available to their rivals, this harms fair competition in the EU. It also deprives the public purse and citizens of funds for much needed investments the need for which is even more acute during times of crisis.</p>
</blockquote>
<p><strong>Political reaction</strong></p>
<p>Following Apple’s appeal of the 2016 Commission finding, the Fine Gael minority government at the time, supported by Fianna Fáil, decided to join the appeal – prompting significant political and public opposition.</p>
<section id="contribution-prompt-article">
    <div>
        <p><span>#Open journalism</span>

        <span>No news is bad news</span>
        <span>Support The Journal</span></p><p>
            Your <b>contributions</b> will help us continue
            to deliver the stories that are important to you
        </p>
    </div>

    <a href="https://www.thejournal.ie/contribute">
        Support us now
    </a>
</section>

<p>Responding to the ruling this morning, former minister Charlie Flanagan said: “Important EU court ruling vindicates actions of Enda Kenny, Michael Noonan and government despite incessant hostility at home and abroad.”</p>
<p>Sinn Féin’s finance spokesperson Pearse Doherty TD said that “morally this is a terrible day” because Apple was allowed to avoid paying a “fair amount of tax”</p>
<p>“Apple had three stateless companies here, ‘we shouldn’t pay tax here, or anywhere in the world’. So, while the Department of Finance may be thinking that this is a good day for themselves, morally this is a terrible day,” Doherty told RTÉ’s Today with Sarah McInerney.</p>
<p>“The richest company in the world was able to generate over €100 billion of profits and not pay tax anywhere in the world on those profits despite the fact that the companies are incorporated here in Ireland. “&nbsp;</p>
<p><em>With reporting from Ian Curran and Dominic McGrath</em></p>

            </div></div>]]>
            </description>
            <link>https://www.thejournal.ie/apple-tax-fine-gael-fianna-fail-government-eu-5149993-Jul2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843150</guid>
            <pubDate>Wed, 15 Jul 2020 09:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Trillion Connections – Nebula Graph Database at WeChat]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843038">thread link</a>) | @jamie-vesoft
<br/>
July 15, 2020 | https://nebula-graph.io/posts/nebula-graph-for-large-social-network/ | <a href="https://web.archive.org/web/*/https://nebula-graph.io/posts/nebula-graph-for-large-social-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p><img src="https://nebula-graph.io/images/writer.png" width="16px" height="16px">
<span>Li Benli</span></p><p><img src="https://nebula-graph.io/images/calendar.png" width="16px" height="16px">
<span>2020-07-02</span></p></div><p><img src="https://user-images.githubusercontent.com/57335825/87518187-cdb4d200-c634-11ea-9dc4-264001420b55.png" alt="Nebula Graph for Large Social Network: Practices at WeChat"></p><p>WeChat is one of the social network apps in the world that deals with large scale heterogeneous graphs. The dataset to be processed has:</p><ul><li>One trillion edges/connections</li><li>A total dataset of 150TB</li><li>An hourly update of 100 billion connections,</li></ul><p>And it is a huge challenge. The team at WeChat encountered problems when using <a href="https://github.com/vesoft-inc/nebula">Nebula Graph</a>, an open source distributed graph database.</p><p>However, through deep customization capabilities in the database, the team has realized some useful on-demand features. They include big data storage, data import for large data sets with a fast performance, version control, rollback at the second level, and access to the database at millisecond level.</p><h2 id="the-challenges-facing-large-internet-companies">The Challenges Facing Large Internet Companies</h2><p>Most well-known graph databases are not capable of dealing with truly big data. For example, the community version of <a href="https://neo4j.com/">Neo4j</a> provides single-host service and is widely adopted in the knowledge graph area. However, when it comes to a very large data set this solution misses the mark. And large data sets are increasingly common in today’s business world.</p><p>Plus, there are issues like data consistency and disaster recovery to consider if you choose a multi-copy implementation. <a href="https://janusgraph.org/">Janus Graph</a> has solved the big data storage problem by using external metadata management, kv storage and indexes. Yet the performance has been widely criticized. As a result, most graph database solutions that the WeChat team evaluated are many times better than Janus Graph in terms of performance.</p><p>Some Internet companies build their own databases. These self-developed solutions are catering to their own business requirements, rather than for general graph scenarios. So, they support only a limited proportion of query syntaxes.</p><h3 id="geabase-from-ant-financial">GeaBase from Ant Financial</h3><p><a href="https://tech.antfin.com/products/GEABASE">GeaBase</a> is another option, mainly used in the finance industry. It features a self-developed query language, pushdown computation and millisecond latency. The main scenarios for its usage include risk management in financial organizations. To this end, it supports a transaction network with trillions of edges/relationships, storing real-time transaction data, real-time fraud detection.</p><p>It is also useful for recommendation engines. This includes applications like stocks and securities recommendations. Its Ant Forest features the capability to store trillions of nodes, strong data consistency, and low latency querying. It also has a GNN feature for Dynamic Graph CNN, for online inference based on dynamic graphs.</p><h3 id="igraph-from-alibaba">iGraph from Alibaba</h3><p>There is also iGraph, a graph indexing and query system. It stores user behavior information and serves as one of the four backbone middle platforms in Alibaba. iGraph has adopted Gremlin as its graph query language for real-time queries of e-commerce relationships.</p><h3 id="bytegraph-from-bytedance-aka-tiktok">ByteGraph from ByteDance (a.k.a TikTok)</h3><p>By adding a cache layer to the kv layer, ByteGraph splits the relationships into B+ trees for efficient access to edges and data sampling. The structure is like the TAO of Facebook.</p><h2 id="architecture-of-the-wechat-big-data-solution">Architecture of the WeChat Big Data Solution</h2><p>The WeChat team has come up with the following architecture to solve the big data storage and processing problem.</p><p><img src="https://user-images.githubusercontent.com/57335825/86352447-a87a9980-bc1a-11ea-83c6-47a481675e9e.png" alt="Architecture of the WeChat Big Data Solution"></p><h2 id="why-nebula-graph">Why Nebula Graph?</h2><p>As seen in the architecture above, a graph database is the main component of the solution. WeChat ended up selecting Nebula Graph as the starting point of its journey in exploring graph databases.</p><p>WeChat found Nebula Graph had the most potential for handling huge dataset storage needs based on the capability of dataset partitioning and an independent relationship storage. It also had pushdown computation and MPP optimization based on the strong consistency storage engine. Finally, the team had extensive experience in the graph database field and a proven model for abstraction for big data.</p><h2 id="problems-in-practice-nebula-graph">Problems in Practice Nebula Graph</h2><h3 id="insufficient-memory">Insufficient Memory</h3><p>The WeChat team encountered memory issues. At its essence, it was a problem of performance versus resources. Memory occupation is an un-neglectable issue in an application dealing with large scale datasets.
There are a couple of components in RocksDB that contribute to memory usage. There are Block cache, Indexes and bloom filters. There are also Memtables and Blocks pinned by iterators.
So, the WeChat team moved to optimize memory utilization. It began with block cache optimization. To do this, it adopted a global LRU cache to control the cache occupation of all RocksDB instances in a machine.</p><p>Then the team did a bloom filter optimization. An edge is designed as a key-value pair and stored in RocksDB. If all keys are stored in a bloom filter and each key occupies 10bit, then the memory required by the entire filter will exceed the machine memory by a large margin.</p><p>The team observed that most of the time the requests are to acquire a list of edges for a specific node. Therefore, the team adopted a prefix bloom filter. Another optimization was made to create indexes for properties on vertices, which enables acceleration for most requests. Finally, the memory occupation of a single-host filter is at the gigabyte level without sacrificing the speed of most requests.</p><h3 id="version-control">Version Control</h3><p>There are several business requirements in practice for version control. It offers graph data fast rollback, periodic full data import, and automatic access to the latest versioning data. The team has classified data sources into two categories.</p><p>Recurring data, for example, generates a list of similar users by day and the data takes effect after being successfully imported. Then there is History data and real-time data. For example, there is refresh history data by day and the team combines the history data with real-time data as full data to be imported.</p><p>Following is the data storage model in RockDB.</p><p>Vertex Storage Model:</p><p><img src="https://user-images.githubusercontent.com/57335825/86352518-c516d180-bc1a-11ea-9ea3-25a774e6478c.png" alt="Vertex Storage Model in RocksDB"></p><p>Edge Storage Model:</p><p><img src="https://user-images.githubusercontent.com/57335825/86352600-e2e43680-bc1a-11ea-819c-6161cdf719b3.png" alt="Edge Storage Model in RocksDB"></p><p>Timestamp is used as the versioning method for real-time data. The version of imported data is specified manually. In practice, the team has three options for version control. First, reverse_versions, where the list of versions is to be kept for rollback. Second is active_version, where the version is accessed by users’ requests. And finally, max_version, where data is reversed after a certain version. The reversed data is the combination of the history data and the real-time data.</p><p>Using the three options, the team can manage offline data and online data efficiently. The data that is no longer used is cleared from the disk during the next compaction.
In this way, the application can update the data version without in the background. And the data rollback can be completed within seconds.</p><p>Below are some examples:</p><ul><li>Keep three versions of data and activate one of them</li></ul><p><code>alter edge friend reserve_versions = 1 2 3 active_version = 1</code></p><ul><li>Data sources are history data and real-time write data</li></ul><p><code>alter edge friend max_version = 1592147484</code></p><h2 id="fast-full-data-import">Fast Full Data Import</h2><p>Conducting data imports at a large scale is a common practice. The import requests, without any optimization, would not only affect requests in production, but take longer than a day to complete. So, it became an urgent requirement to improve import speed. SST Ingest is a commonly adopted method to achieve fast import. The WeChat team adopted something similar.</p><p>The team generated SST files offline via scheduling Spark tasks. Storage nodes pull the data required and ingest the data to the graph database. And, then there is access to the latest versioning data via the version control request. The import process takes several hours to complete, which is fast. And it does not affect requests to the graph database because the computation is mainly offline.</p><p>The shared-nothing architecture is a widely discussed method for ensuring horizontal scalability. It requires programming skills to implement the architecture in practice. The meta cache is encapsulated with <code>shared_ptr</code> and is frequently accessed, making it a warm bed for atomic operation clashing. To realize shared-nothing, the WeChat team copied each meta cache as a local thread. This <a href="https://github.com/vesoft-inc/nebula/pull/2165">pull request</a> provides details.</p><p>It has been a long journey to achieve graph database utilization. And it is one that continues with success in large part by overcoming obstacles.</p><h2 id="you-might-also-like">You Might Also Like</h2><ul><li><a href="https://nebula-graph.io/posts/detect-corona-virus-spreading-with-graph-database/">Detect Corona Virus Spreading With Graph Database Based on a Real Case</a></li><li><a href="https://nebula-graph.io/posts/review-on-graph-databases/">A Review of Graph Databases</a></li></ul><blockquote><span>Like what we do ? Star us on GitHub.</span>
<a href="https://github.com/vesoft-inc/nebula" onclick="gtag('event','Link Click',{event_category:'Engagement',event_label:'Star via blogbody'});">https://github.com/vesoft-inc/nebula</a></blockquote></section></div>]]>
            </description>
            <link>https://nebula-graph.io/posts/nebula-graph-for-large-social-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843038</guid>
            <pubDate>Wed, 15 Jul 2020 09:41:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google is investing Rs 33,737 crore for a 7.7% stake in India's Jio Platforms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843004">thread link</a>) | @hacknoid
<br/>
July 15, 2020 | https://mythreadreader.com/ETtech/1283321850412412928 | <a href="https://web.archive.org/web/*/https://mythreadreader.com/ETtech/1283321850412412928">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  
                  <div>
                    <a href="https://twitter.com/ETtech/status/1283327519253344257"><p>A new JioTV+ platform would aggregate content from over 12 video streaming services such as Netflix, Amazon Prime, Disney+ Hotstar, Voot, SonyLiv, Zee5, JioCinema, JioSaavn and YouTube among others #RILAGM</p></a>
                    
                    
                    

                    
                  </div>    
                </div></div>]]>
            </description>
            <link>https://mythreadreader.com/ETtech/1283321850412412928</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843004</guid>
            <pubDate>Wed, 15 Jul 2020 09:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Zealand: Next steps in Covid response]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842977">thread link</a>) | @sohkamyung
<br/>
July 15, 2020 | https://www.beehive.govt.nz/speech/next-steps-covid-response | <a href="https://web.archive.org/web/*/https://www.beehive.govt.nz/speech/next-steps-covid-response">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Kia ora tatou</p>
<p><span><span><span><span>Today I am setting out our plan in the event we have a new case of community transmission of COVID-19 in New Zealand. </span></span></span></span></p>
<p><span><span><span><span>I will take a bit of time to do that, and then I’ll be happy to take questions at the end. </span></span></span></span></p>
<p><span><span><span><span>Since we moved to level one, we have continued work to ensure we have an ongoing level of preparedness for resurgence in New Zealand. </span></span></span></span></p>
<p><span><span><span><span>The framework I will be speaking to today has been through a Cabinet process, and is more important than ever. </span></span></span></span></p>
<p><span><span><span><span>It is designed to give the public, and our business community as much certainty as we can around what to expect if new cases inside our borders are found. And that is something we all must prepare for. </span></span></span></span></p>
<p><span><span><span><span>We have been 75 days without community transmission here in New Zealand, but COVID is now exploding outside our borders and every country we have sought to replicate or have drawn from in the fight against COVID has now experienced further community outbreaks.</span></span></span></span></p>
<p><span><span><span><span>We only need to look to Victoria, New South Wales, Hong Kong, Singapore and Korea to see examples of other places that like us had the virus under control at a point in time only to see it emerge again. </span></span></span></span></p>
<p><span><span><span><span>This does not mean anyone has failed- it means perfection in the response to a virus, and a pandemic, is just not possible. That is certainly the case as we see this pandemic continue to grow.&nbsp;&nbsp; </span></span></span></span></p>
<p><span><span><span><span>The World Health Organisation this week reported the global infection rate is nearing 13 million cases, with over 215,000 cases reported globally on Tuesday. </span></span></span></span></p>
<p><span><span><span><span>To put that into perspective when we closed our borders on the 19th of March there were 240,000 cases in the world in total. It’s fifty times worse than that now. </span></span></span></span></p>
<p><span><span><span><span>We see this growth in cases around the world reflected in the steady stream of New Zealanders returning from overseas, some of whom are bringing the virus back with them, which we continue to contain at our borders. </span></span></span></span></p>
<p><span><span><span><span>In the main the pattern of returnees carrying the virus reflects the state of COVID in the world, with our cases coming from places like India, the US and the UK. </span></span></span></span></p>
<p><span><span><span><span>New modelling by Rodney Jones indicates there will be over 100,000 new cases a day in the US by the end of the month, nearly 70,000 cases a day in India and nearly 10,000 cases a day across Europe by early August. </span></span></span></span></p>
<p><span><span><span><span>We will continue to welcome home New Zealanders from these places as citizens, as they have a right to come home to their legal place of residence. But with that right comes risk, and the need to continue ongoing stringent measures to keep them, and everyone around them, safe. </span></span></span></span></p>
<p><span><span><span><span>Victoria in particular is a cautionary tale for New Zealand that we must learn from. </span></span></span></span></p>
<p><span><span><span><span>It appears their current outbreak is linked to a managed isolation facility similar to the ones we run here and that the entire outbreak was seeded by just two cases. </span></span></span></span></p>
<p><span><span><span><span>That goes to show how quickly the virus can spread and it can move from being under control to out of control, and that even the best plans still carry risk in a pandemic. </span></span></span></span></p>
<p><span><span><span><span>It’s important to remember that our border facilities have served us well so far. </span></span></span></span></p>
<p><span><span><span><span>Our testing regime is picking up cases amongst new arrivals who are in quarantine and nearly 30,000 people have been through a facility without a case of COVID transferring to the community. But there is limited room for error.</span></span></span></span></p>
<p><span><span><span><span>Just as many of our frontline health workers like nurses who were in contact with COVID patients got the virus from those patients during level 4 lockdown, our frontline border and airline staff and staff in our managed isolation facilities are in daily contact with returnees carrying the virus. Even our most experienced and trained support workers have picked up COVID.</span></span></span></span></p>
<p><span><span><span><span>Experts tell us that even with the best precautions possible, the chances of the virus passing from a surface, or contact with someone who is a carrier are high. </span></span></span></span></p>
<p><span><span><span><span>We must prepare now for that eventuality and have a plan at the ready in the event that it does. </span></span></span></span></p>
<p><span><span><span><span>The first thing we need to do is continue to ensure our border and our managed isolation facilities stay as tight as they can be. </span></span></span></span></p>
<p><span><span><span><span>We have ensured our frontline workers at the border are safe by wearing appropriate PPE, getting regularly tested and that our systems for managing returnees are robust and limit the risk of spread. As I say the system has done the job it was set up to do to date. </span></span></span></span></p>
<p><span><span><span><span>The work done by Minister Woods and Air Commodore Webb in recent weeks have made significant additional improvements in this space, and we will continue to improve the system. Australia is currently conducting an audit of its quarantine system and I’ve asked Prime Minister Morrison to share any insights so we can continually learn and improve on what we do here. </span></span></span></span></p>
<p><span><span><span><span>But again, no system is 100% fool proof and around the world we are seeing even the most rigorous measures being tested by the virus. </span></span></span></span></p>
<p><span><span><span><span>And so today I am setting out the next stage in our COVID plan in the event we have new cases in the community. </span></span></span></span></p>
<p><span><span><span><span>The first thing to note is that the Government’s strategy for responding to the COVID-19 pandemic remains elimination. That has not and will not change. </span></span></span></span></p>
<p><span><span><span><span>Allowing our hospitals to be overrun, further deaths and the economy to close down again for an indefinite period of time is not a strategy.</span></span></span></span></p>
<p><span><span><span><span>We have seen overseas the toll that that takes on lives and economies.</span></span></span></span></p>
<p><span><span><span><span>We have said from the start that the best approach for the economy is a strong health response, and the evidence has supported that approach throughout.</span></span></span></span></p>
<p><span><span><span><span>We can already see that with New Zealand’s economy more open than nearly anywhere in the world because of the steps we took to break the chain of transmission under lockdown. </span></span></span></span></p>
<p><span><span><span><span>Our plan moving forward seeks to protect that position and minimise any economic impact of future cases. </span></span></span></span></p>
<p><span><span><span><span>So in the event of new community cases we would move immediately to implement our “Stamp it Out” approach again.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>There are two key things to remember.</span></span></span></span></p>
<p><span><span><span><span>Firstly, the simple approach of limiting the ability for the virus to move from human to human to break the chain of transmission remains the foundation of our response no matter what. </span></span></span></span></p>
<p><span><span><span><span>That’s why our key public health measures remain important for protecting ourselves and each other from the spread of disease. They are: </span></span></span></span></p>
<p><span><span><span><span>-&nbsp; wash your hands regularly and thoroughly </span></span></span></span></p>
<p><span><span><span><span>- cough or sneeze into your elbow </span></span></span></span></p>
<p><span><span><span><span>- don’t go to work, socialise, or be out in public if you are sick </span></span></span></span></p>
<p><span><span><span><span>- Keep a digital diary of your whereabouts by downloading and using the COVID Tracer app. </span></span></span></span></p>
<p><span><span><span><span>These principles are key to the second ongoing tool in our response. </span></span></span></span></p>
<p><span><span><span><span>Rapid contact tracing, testing, and use of isolation and quarantine for those exposed to COVID. That is why the Covid tracer app, and whatever other means of recording where you have been remains vital. Every time you step into the world I want you to ask this question “if I come into contact with COVID today, how will I know, and how will others know”. </span></span></span></span></p>
<p><span><span><span><span>If you are in or near a situation of community transmission this will be an exceptionally important tool for contact tracing, and for finding you. </span></span></span></span></p>
<p><span><span><span><span>In this area we are constantly looking at how we can use new technology to strengthen our response, the same goes for testing. </span></span></span></span></p>
<p><span><span><span><span>But these are the principles we are all familiar with. Now I want to touch on what would be different.</span></span></span></span></p>
<p><span><span><span><span>The alert level system and framework remains in place. But in the event of cases, rather than apply the framework nationally, we would look to apply our Alert Level system at a localised or regional level in the first instance.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>Our priority will be to control any cases with the least intrusive measures, and over the smallest area we can.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>In practical terms that means doing absolutely everything possible to avoid the entire country returning to Alert Levels 3 or 4 as a measure of last resort.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>“Our ‘Stamp it Out’ approach is scenario specific meaning that our actions will depend on the severity of the situation. </span></span></span></span></p>
<p><span><span><span><span>And of course when we see the first COVID-19 case beyond the border, you can expect us to move very quickly and very firmly to contain it while we gather information on the situation we are facing. </span></span></span></span></p>
<p><span><span><span><span>However there are three broad starting scenarios we can plan around. </span></span></span></span></p>
<p><span><span><span><span>1. A case or a number of cases in a community. </span></span></span></span></p>
<p><span><span><span><span>2. A larger number of cases or cluster in a region</span></span></span></span></p>
<p><span><span><span><span>3. Multiple clusters that have spread nationally</span></span></span></span></p>
<p><span><span><span><span>Let me run through what each scenario might look like. </span></span></span></span></p>
<p><span><span><span><span>First a contained case or cases within a community.</span></span></span></span></p>
<p><span><span><span><span>We would be looking at applying strong restrictions but only applied locally in a neighbourhood, town or city to contain the virus and stopping it spread. </span></span></span></span></p>
<p><span><span><span><span>We would likely remain at Alert Level 1 nationally. </span></span></span></span></p>
<p><span><span><span><span>The local measures to contain the case would involve rapid contact tracing and isolation of cases and their contacts, scaled up and targeted testing of people connected to the case, such as workmates, those they live with or those in their neighbourhood. </span></span></span></span></p>
<p><span><span><span><span>The point with this scenario is we would look at act hard and fast, but local in an attempt to ring fence the virus.&nbsp; </span></span></span></span></p>
<p><span><span><span><span>The second scenario is a large cluster within a region. </span></span></span></span></p>
<p><span><span><span><span>Here, a significant increase in testing would be the priority. We would look to undertake much wider community testing, on top of testing any contacts or potential contact of those with the virus. This could look like it did in Victoria where health staff went door to door to test people in affected areas. </span></span></span></span></p>
<p><span><span><span><span>We would also take steps to stop the spread to other parts of the country so a regional shift in Alert Level would likely be applied that restricted travel. This would mean travel in or out of the city, town or region could be stopped, people in that place asked to work from home, and local restrictions on gatherings implemented. </span></span></span></span></p>
<p><span><span><span><span>The aim here is to contain the spread away from other areas to avoid the whole country having to put in place restrictions so we can remain at Alert Level 1 nationally, depending on the evidence of risk of spread outside the region. </span></span></span></span></p>
<p><span><span><span><span>The final scenario is if multiple clusters, spread nationally. </span></span></span></span></p>
<p><span><span><span><span>In this scenario we would …</span></span></span></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.beehive.govt.nz/speech/next-steps-covid-response">https://www.beehive.govt.nz/speech/next-steps-covid-response</a></em></p>]]>
            </description>
            <link>https://www.beehive.govt.nz/speech/next-steps-covid-response</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842977</guid>
            <pubDate>Wed, 15 Jul 2020 09:31:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux 4K Demo Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842875">thread link</a>) | @onidaito
<br/>
July 15, 2020 | https://benjamin.computer/posts/2020-07-15-nova.html | <a href="https://web.archive.org/web/*/https://benjamin.computer/posts/2020-07-15-nova.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

	<a href="https://benjamin.computer/"><img src="https://benjamin.computer/images/bcpu_04_flat.png" alt="benjamin.computer"></a>
  
	<ul>
	<li><a href="https://benjamin.computer/about.html">ABOUT</a></li>
	<li><a href="https://benjamin.computer/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide Atom feed">RSS</a></li>
	<li><a href="https://mastodon.social/web/accounts/220949">MASTODON</a></li>
	<li><a href="https://www.github.com/onidaito">GITHUB</a></li>
	<li><a href="mailto:me@benjamin.computer">EMAIL</a></li>
	</ul>
 

<hr>

<p><h2>My First Demoscene production</h2></p> 
<em>15-07-2020</em> 
<p>This year, I made my first ever demo! I've been threatening to do so for ages now, but since the lockdown hit, I've really had no excuse not to. For these of you unfamiliar with the demoscene, it's a small, yet internationally recognised[^0] subculture revolving around computer art. Some of the best programmers and artists produce works for all sorts of computers and electronic equipment, pushing the machines and themselves to the very limit! There are demoscene parties taking place all over Europe (and some further afield). I entered <a href="http://novaparty.org/">NOVA</a> this year - the UK's main demoscene party, and had great fun doing so.</p>
<h3>Demos and the Demoscene</h3>
<p>The demoscene has been around for a while now. It started out when crackers learned to break the copy protection on games. To show off their prowess, these expert programmer-pirates would leave messages at the beginning of the game. These messages often had music, scrollers, custom art. You can draw quite a few parallels to graffiti work, and I mean <em>really good</em> graffitti work! Some of these <em>'cracktros'</em> are incredible! The crackros became the main event, and the demoscene was born.</p>
<p>Back in these days, before the internet, demos were distributed via disk or bulletin boards. You could swap disks with folks you knew, dial into a modem and download, get disks in the mail, or go to a demoparty. Demo parties are still going today, stronger than ever one could argue. The largest Demoscene party is <a href="https://2019.revision-party.net/">Revision</a>, held in Saarbrucken, Germany. I've been a couple of times - you'll see some of the finest computer art in the world at this event! </p>
<p>Parties tend to be built around competitions. There are several categories and you can enter as many as you like. The competitions range from oldschool demos, such as these written for the <a href="https://en.wikipedia.org/wiki/Amiga">Amiga</a> or the <a href="https://en.wikipedia.org/wiki/ZX_Spectrum">ZX Spectrum</a>, to 64K PC Demos - where the size limit is 64K. There are competitions for music, ranging from new school to tracked, and also competitions for Pixel Art and digital photography. Something for everyone.</p>
<p>Quite often, folks will get together to form a demoscene group. Musicians, teaming up with programmers and illustrators to create entries none of them could do on their own. Some of these groups have been going for decades, albeit with different members.</p>
<p>In the past, computers were a bit more restrictive than they are now. 3D rendering on the Amiga is quite the task whereas it's quite trivial on a modern PC. To keep up the challenge, a set of size-coding competitions were devised. The idea is fairly simple - see how much you can do with 64K, 8K or 4K. Some competitions even go as far down as 256 Bytes[^3]! For reference, an average email is around 400 Kilobytes.</p>
<iframe width="881" height="496" src="https://www.youtube.com/embed/JZ6ZzJeWgpY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Some of these competition entries are absolutely fabulous. One of my favourites is <a href="http://www.pouet.net/prod.php?which=67113">Fermi Paradox</a>; a 64k entry by the demogroup <a href="https://mercury.sexy/">Mercury</a>. I'm still amazed that not only can so much be packed into such a small space, but that so much can be <em>said</em> in a short space of time. The programming skill is only matched by the art.</p>
<h3>Linux 4K</h3>
<p>One of the things I've noticed is there are very few Linux demos. This sounds odd to me as Linux is quite the open platform, at least compared to Windows. However, Windows has been the mainstay of the PC demoscene for much of the scene's history. I think this is because the graphics drivers tend to be better, Windows setups are much more homogeneous (you can generally rely on certain libraries being around), and more of a history of the kinds of hacking techniques often used in demo production. As more demos were released for Windows, more demotools became available. Tools such as <a href="http://crinkler.net/">crinkler</a>, which compresses your demos down to a tiny size, to the <a href="https://github.com/laurentlb/Shader_Minifier">shader minifier</a>. Linux hasn't got there yet with it's tooling, until recently.</p>
<p>Thanks to the efforts of <a href="https://bitbucket.org/blackle_mori/scalemark/src/master/">Blackle</a> and <a href="https://gitlab.com/PoroCYon/linux-4k-intro-template">poroCyon</a>, we now have a starting template for Linux 4K entries. I took a look at how the template was built up. There seems to be the following processes:</p>
<ul>
<li>Compress the shaders into a header file with shader minifier</li>
<li>Build the object files with some embedded assembly (which I don't understand!)</li>
<li>Strip out any of the bits of the ELF Header we don't need. </li>
<li>Link everything together with the <a href="https://github.com/Shizmob/smol">Shoddy minsize-oriented linker (SMOL)</a></li>
<li>Compress everything with the <a href="https://in4k.github.io/wiki/lsc-wiki-vondehi.html">vondehi</a> program.</li>
</ul>
<p>Vondhehi is quite funky! The decompressor itself is loaded into your program and decompresses the rest of the program once the program is run. </p>
<p>There are no doubt other subtle things going on. If you want to know more, <a href="https://www.youtube.com/watch?v=a03HXo8a_Io">there is a talk from Revision you can watch</a> that explains the process in more detail. The code-base itself seems a little complicated but some of that is down to the tools being made for windows; there is a dependency on <a href="https://www.mono-project.com/">Mono</a> (among other things) for example. Nevertheless, it's quite possible to get down to an executable of 4K or smaller.</p>
<figure><img src="https://shutr.benjamin.computer/inpost/numenera1.jpg" alt="Generating protein images."><figcaption>Screenshot from within the mysterious Menger Sponge!</figcaption></figure>

<p>This demo runs on every Linux setup I've tested it on. The de-facto standard for demoparties seems to be Ubuntu (at the time of writing, Ubuntu 18 for Revision). All size coding demos rely on some libraries being pre-installed. Unlike Windows, there is no guarantee you'll have the library you want installed under Linux, so this template comes with three options for the OpenGL context: SDL2 and GTK3. I went with SDL2 in the end, as it resulted in a slightly smaller filesize.</p>
<h3>Music</h3>
<p>Definitely my weakest area this one. I had no idea where to begin. Thankfully the template is setup to use a tracker or synthesizer. I honestly don't know how this bit works but after looking around briefly, I found a program called <a href="https://www.renoise.com/">Renoise</a>. Apparently, there are set of instruments made by demosceners that can be loaded into renoise, whereupon you can make your soundtrack. These instruments tend to compress rather well it is claimed. <a href="https://github.com/askeksa/Oidos">Oidos</a>, <a href="http://4klang.untergrund.net/">4KLang</a> and <a href="http://www.pouet.net/prod.php?which=61592">Clinkster</a> are recommended in the template. I decided to go with Clinkster for no real reason at all. </p>
<p>Renoise is a Windows program unfortunately, but it seems to run well enough under <a href="https://www.winehq.org/">Wine</a>. I could create a tracked piece of music fairly quickly (I use music in the loosest possible sense of the word!). With the file placed in the right directory, the template makefile rolls it in quite easily.</p>
<p>If you want to know more about demoscene music and listen to the work of someone who really knows what they are doing, check out <a href="https://soundcloud.com/h0ffman">h0ffman</a>. He has <a href="https://hoffman.home.blog/2019/04/27/eon/">a good write-up on his site</a> about the kinds of hoops a demoscener composer needs to jump through.</p>
<h3>Raymarching Menger Sponges</h3>
<p>With everything in place, I set to. I'd wanted to learn a bit more about fractals and how they are rendered. I started with the <a href="https://en.wikipedia.org/wiki/Menger_sponge">Menger sponge</a> -  a classic fractal. I like the look of it! Something weirdly alien yet constructed. I thought I'd use this as the main feature around which this intro would be based.</p>
<p>Normally, fractals are described using <a href="https://en.wikipedia.org/wiki/Recursion">recursion</a>. It's an elegant way of of generating an image as fractals are self similar. However, in a fragment shader, this isn't possible.</p>
<p>It's worth mentioning what a <a href="https://www.khronos.org/opengl/wiki/Fragment_Shader">fragment shader</a> is. In early 3D graphics, the pipeline that took your triangles and spat out pixels on your screen was fixed; you couldn't really tweak it. Nowadays, you can alter the functionality of many different sections of the pipeline using small programs called <em>shaders</em>. The fragment shader is the last shader in the line before the pixels appear. It's sometimes called a pixel shader too, though you aren't manipulating pixels at this point (well, you are close enough I guess). </p>
<p>The fragment shader is where all the graphics magic happens. You are given a fragment and you output a colour for that fragment. The in-between step is where the fun is. We can use a technique known as raymarching. </p>
<p>Raymarching (or Volume Ray Casting) is used all over the place in a lot of demos; it's a powerful technique. Similar to raytracing, you shoot a ray from your camera through the screen at the fragment position. You then need to find out what this ray hits. To do that, you use a <a href="https://prideout.net/blog/distance_fields/">distance field</a>.</p>
<p>Distance fields are a parametric way of defining a scene. The simplest example is a sphere. A sphere can be defined as a 3D point and a radius - 4 numbers. From these four numbers you can figure out the distance from where your ray is, to the sphere, even figuring out where on the sphere your ray will intersect. The next step is to <em>march the ray</em> that distance and then check again how far away you are. </p>
<p>You can build up an entire scene this way, with multiple objects, creating realistic lighting, special effects and more! It's a really powerful technique made famous by the website <a href="https://www.shadertoy.com/">Shadertoy</a> and it's creator, <a href="https://iquilezles.org/">Iniqgo Quilez</a>. His site details a number of <a href="https://iquilezles.org/www/articles/distfunctions/distfunctions.htm">mathematical formulas for distance fields</a> though I can't claim to understand most of them. However, we can do all this in a single pixel shader.</p>
<p>Back to our Menger sponge then. If we can do it recursively, we'll have to go iteratively. One way we can create the sponge is to start with a field for a large cube and effectively carve out the holes using smaller cuboids and a subtraction function. Turns out all of these are easy to do in a fragment shader if you have the right functions. An excellent set of such functions can be found on <a href="https://mercury.sexy/">Mercury's homepage</a>.</p>
<h3>Numenera</h3>
<p>Back to our demo. I had the idea of using a Menger Sponge but no idea on the actual <em>art</em>. Where to begin? What was a trying to say? I must admit, this bit really took me by surprise how hard it was! I suppose that's a bit of a cliche right - the engineer trying to do an art? Still, undeterred, I'd been reading a little about the roleplay game <a href="https://en.wikipedia.org/wiki/Numenera">Numenera</a>. I liked the idea of long lost advanced technology. I pictured a desert, with an ancient and worn down artefact, suddenly coming alive as we observe it. I had an idea, so off I went!</p>
<p>The desert part is quite easy - it's just a plane with a noise offset on the distance field. I used Iq's lighting model for the shadows and the ambient occlusion. With …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjamin.computer/posts/2020-07-15-nova.html">https://benjamin.computer/posts/2020-07-15-nova.html</a></em></p>]]>
            </description>
            <link>https://benjamin.computer/posts/2020-07-15-nova.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842875</guid>
            <pubDate>Wed, 15 Jul 2020 09:13:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft have no intentions of paying for submitted vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23842758">thread link</a>) | @pabs3
<br/>
July 15, 2020 | https://twitter.net/jonasLyk/status/1282945750746509313 | <a href="https://web.archive.org/web/*/https://twitter.net/jonasLyk/status/1282945750746509313">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://twitter.net/jonasLyk/status/1282945750746509313</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842758</guid>
            <pubDate>Wed, 15 Jul 2020 08:51:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Late-life restoration of mitochondria reverses cardiac dysfunction in old mice]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842748">thread link</a>) | @JPLeRouzic
<br/>
July 15, 2020 | https://padiracinnovation.org/News/2020/07/late-life-restoration-of-mitochondrial-function | <a href="https://web.archive.org/web/*/https://padiracinnovation.org/News/2020/07/late-life-restoration-of-mitochondrial-function">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    						
					                    <p>
                        <span itemprop="datePublished">15 July 2020</span> - Posted in 
                        <span itemprop="articleSection"><a href="https://padiracinnovation.org/News/category/english">English</a></span> by 
                        
                    </p>
                </div><div itemprop="articleBody">                                   
                    <p><a href="https://elifesciences.org/articles/55513">The article discussed here</a> is not related to neurodegeneration diseases, it discusses about heart failure, however it might have implications for ALS.
While most ALS targeting therapies might aim at reducing TDP-43 aggregates (and similar protein aggregates in other neurodegenerative diseases), humans are indeed more than bags of identical cells, they are first living because they are composed of a multitude of physiological systems that interact to maintain homeostasis.
So even if a therapy was invented that would efficiently remove TDP-43 aggregates, ALS patients would still be unable to recover health as motor neurons do not rejuvenate nor are replaced with newer cells. As this heart failure treatment improves heart muscle cells, it should also to some degree improve motor neuron cells.
This article is also interesting as it mentions some drugs that are discusses ALS online internet forums, such as glutathione, N-Acetyl Cysteine (NAC) and Glycine.</p>

<p>This article explains precisely how some muscle cells seem to rejuvenate when a specific peptide is administrated. Very roughly: With this peptide, metabolism is rejuvenated at cellular level, so cells can use more energy, something which is clearly lacking in ALS cells which are characterized by hypermetabolism.  Humans produce and consume about 65 kg of ATP every day. Because ATP cannot be stored, it is critical that the rate of ATP synthesis matches the rate of ATP consumption. The primary role of mitochondria is the generation of adenosine triphosphate (ATP) from adenosine diphosphate (ADP) using macromolecular complexes that form the electron transport chain.</p>

<p><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7000886/bin/gr3.jpg" alt="enter image description here"></p>

<p>Mitochondrial dysfunction is one of the hallmarks of aging. While mitochondria generate the
bulk of cellular ATP, they are also the major source of reactive oxygen species (ROS) in most
cells. ROS are sub-products inherent to ATP metabolism.</p>

<p>Aging is the strongest risk factor for cardiovascular diseases. It is also accompanied by a
decline in cardiac function, especially diastolic dysfunction and hypertrophy of the left ventricle
and left atrium. The heart is rich in mitochondria and has a high metabolic demand; therefore,
it is highly susceptible to oxidative damage and the effects of mitochondrial dysfunction.
Increasing evidence suggests that mitochondrial oxidative stress and mitochondrial dysfunction
play critical roles in cardiovascular diseases and cardiac aging.</p>

<p>The mitochondrial-targeted tetrapeptide SS-31 (elamipretide), is a pharmacologic intervention that selectively concentrates in mitochondria, suppressing mitochondrial ROS and increasing skeletal muscle ATP production. Elamipretide (also named SS-31, MTP-131, Bendavia) is sold by Stealth BioTherapeutics, Newton, Massachusetts. It is a water-soluble, aromatic-cationic mitochondria-targeting tetrapeptide that readily penetrates and transiently localizes to the inner mitochondrial membrane and associates with cardiolipin to restore mitochondrial bioenergetics</p>

<p>it has not been established whether delivering such interventions in later life can rescue pre-existing mitochondrial and cardiac dysfunction. In this study, the authors demonstrate that mitochondrial-targeted interventions can improve mitochondrial function and reverse pre-existing cardiac dysfunction in old mice.</p>

<p>To determine the effects of SS-31 treatment on cardiac function in old mice, the scientists treated 24-month-old mice with the SS-31 peptide or saline control and examined cardiac function by echocardiography after 4 and 8 weeks of treatment.</p>

<p>SS-31 treatment was effective in aged hearts with pre-existing mitochondrial dysfunction but had little effects in young hearts with normal functioning mitochondria.</p>

<p>The authors acknowledge that the persistence of SS-31 induced functional benefit varied between individual mice. Other studies have reported negative effects of targeting mitochondrial ROS. In another study, suppression of mitochondrial ROS in mice resulted in impaired macrophage bactericidal activity.</p>

<p>However not everything is rosy, elamipretide is known since quite some time and had been tested in several different diseases. Recently it did not meet expectations stemming from promising early trial results in patients with primary mitochondrial myopathy (PMM), data from a Phase 3 (NCT03323749) trial show.</p>
                </div></div>]]>
            </description>
            <link>https://padiracinnovation.org/News/2020/07/late-life-restoration-of-mitochondrial-function</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842748</guid>
            <pubDate>Wed, 15 Jul 2020 08:50:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Return on Investment for Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842652">thread link</a>) | @arauhala
<br/>
July 15, 2020 | https://aito.ai/blog/return-on-investment-for-machine-learning/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/return-on-investment-for-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This post appeared first on <a href="https://towardsdatascience.com/return-on-investment-for-machine-learning-1a0c431509e">Towards Data Science</a> on July 8th, 2020.</p></blockquote><p>Machine learning deals with probabilities, which means there’s always a chance for mistakes. This inherent uncertainty causes many decision makers feel uncomfortable with implementing machine learning and traps them in an endless chase for the magical 100% accuracy. The fear of mistakes nearly always pops up when I’m working with companies taking their first steps towards intelligent automation, and I get asked “What if the algorithm makes a wrong prediction?”</p><p>If this issue is not addressed, the company will very likely spend a hefty amount of resources and years of development time on machine learning without ever getting returns for their investment. In this article, I’ll show you the simple equation I use to relieve these concerns and get decision makers more comfortable with the uncertainty.</p><h3>When is machine learning worth it</h3><p>Just like with any investment, the feasibility of machine learning comes down to whether it generates more value than it costs. It’s a normal Return on Investment (ROI) calculation which, in the context of machine learning, weighs the generated value against the cost of mistakes and accuracy. So instead of asking “How do we get 100% accuracy?”, the right question is “How do we maximize ROI?”</p><p>Determining the expected returns is quite straightforward. I usually begin opening up the business case for machine learning implementation by comparing its benefits against the potential costs in mathematical terms. This can be formalized in an equation which basically says “What’s left of the generated value after the cost of mistakes is accounted for?” Solving this simple equation allows us to estimate the profits for different scenarios.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_simple.png" alt="returns = value - (1 - accuracy) * cost of a mistake"></p></div></div><p>Let’s look at the variables:</p><ul><li><strong>returns</strong>: Generated net value or profit per prediction  </li><li><strong>value</strong>: The new value generated by every prediction (e.g. assigning a document to the right category now takes 0.01 seconds instead of 5 minutes, so the value is 5 minutes saved)  </li><li><strong>accuracy</strong>: The accuracy of predictions made by the algorithm  </li><li><strong>cost of a mistake</strong>: The additional costs incurred by a wrong prediction (e.g. it takes 20 minutes for someone to correct the mistake in the system)  </li></ul><p>By flipping the equation around and setting returns to zero, we get the minimum accuracy required to generate net value. This is called <strong>break-even accuracy</strong>:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_simple_flip.png" alt="accuracy = 1 - (value / cost of a mistake)"></p></div></div><p>The equation gets more intuitive when plotted in a graph:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_simple_graph.png" alt="Break-even point visualized"></p></div></div><p>So let’s say each prediction saves you 5 minutes of work but it takes 20 minutes of extra work to fix a wrong prediction. We can now calculate the break-even accuracy to be 1–5/20 = <strong>75%</strong>. Any improvement after this point brings concrete profits.</p><p>The above equation assumes us to blindly accept any prediction the algorithm makes and fix the errors afterwards. Sounds risky? We can do much better by extending the equation with confidence scores to lower the risks.</p><h3>Optimizing ROI</h3><p>A machine learning algorithm (done right) does not only spew out predictions, it also tells us how confident it is in every prediction. The majority of mistakes happen when the algorithm is unsure of its answer, allowing us to focus automation on the highest certainty predictions while manually reviewing the lowest few. Even though manual review does cost a bit of labor, it’s normally much cheaper than fixing a mistake later on.</p><p>Let’s choose a threshold which picks out 10% of the least confident predictions for manual review. The rest 90% will be handled automatically. This ratio is called confidence split. The accuracy in the high confidence bracket will now be considerably better since many of the mistakes are caught in the small unconfident bracket. This leads us to the extended equation. It says “What’s left of the generated value after the costs of mistakes and manual review are accounted for?”</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_extended.png" alt="returns = (value - (1 - confident accuracy) * cost of a mistake) * confidence split - (1 - confidence split) * cost of manual review"></p></div></div><p>Let’s look at the variables:</p><ul><li><strong>returns</strong>: Generated net value or profit per prediction  </li><li><strong>value</strong>: The new value generated by every prediction  </li><li><strong>confident accuracy</strong>: The accuracy of predictions in the high confidence bracket  </li><li><strong>cost of a mistake</strong>: The additional costs incurred by a wrong prediction  </li><li><strong>confidence split</strong>: The ratio of high confidence predictions (90% in our case)  </li><li><strong>cost of manual review</strong>: The costs of manually reviewing the prediction  </li></ul><p>We can again flip the equation to calculate the break-even accuracy by setting returns to zero, like so:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_extended_flip.png" alt="confident accuracy = ((1 - confidence split) * cost of manual review) / (confidence split * cost of a mistake) - value / cost of a mistake + 1"></p></div></div><p>We’ll solve it using the following variables:</p><ul><li>value = 5 minutes saved  </li><li>cost of a mistake = 20 minutes  </li><li>cost of manual review = 5 minutes  </li><li>confidence split = 0.9  </li></ul><p>Now the new break-even accuracy is 78%. Wait a minute, that’s higher than with the simpler equation, did it just get worse? Not quite! Remember that many of the mistakes are caught in the low confidence bracket, which significantly boosts the accuracy in the high confidence bracket. Even though the minimum accuracy requirement for break-even got higher, it is now much easier to achieve.</p><p>The ability to calculate the profitability of a machine learning algorithm in operation allows you to find the optimal accuracy. And no, it’s not 100%. As I discussed in my previous article, the development cost of any system increases exponentially while providing diminishing returns. With the above equations, you can estimate a realistic ROI and calculate the point where accuracy improvements incur more development costs than increase in returns in a time-frame of your choice. That’s the ROI-optimized accuracy.</p><h3>Practical example</h3><p>Let’s take a real world scenario and run through the whole thing. Imagine your Accounts Payable team handles 5000 invoices every month, and you’ve been presented the idea of automating a part of the process. More specifically, the proposed automation would categorize incoming invoices to match complex internal vendor codes, which is currently done manually. You need to figure out whether a machine learning approach is worth the effort to solve this task.</p><p>In terms of data, below is what you’ll be working with. You have a history of previously processed invoices and the correct “Vendor_Code” value for each. The task is to predict the right “Vendor_Code” for any new invoice. You can find the original dataset <a href="https://www.kaggle.com/nikhil1011/predict-product-category-from-given-invoice/data#Train.csv">here</a>.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_data.png" alt="Sneak peet at the data"></p></div><p><span>Sneak peet at the data</span></p></div><p>To start off, use any machine learning library or tool you prefer and run a basic accuracy test for the data. I’m using aito.ai which gives me an accuracy of 78% after training with 4000 rows and testing with 1500 rows. If we use the same values and costs as before, we can calculate the monthly returns with the first equation:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_calc_simple.png" alt="returns = 5 minutes - (1 - 0.78) * 20 minutes = 0.59 minutes"></p></div></div><p>Using the simple approach which ignores the confidence scores, every prediction made by the algorithm with 78% accuracy saves you on average 0.59 minutes of work, or 35 seconds. That means almost <strong>50 hours of work saved every month</strong> from processing 5000 invoices. Not bad.</p><p>Now let’s look at the equation which considers confidence scores. I compiled the results and confidence scores for each prediction into a neat table like below which allows us to divide them into high and low confidence brackets. In this case, any prediction with confidence lower than 0.21 will be reviewed manually. This threshold gives us the 90/10 confidence split.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_conf_table.png" alt="Prediction results, including confidence scores"></p></div><p><span>Prediction results</span></p></div><p>The accuracy in our high confidence bracket is an impressive 84%, and a measly 22% in the low confidence bracket. This makes the impact of utilizing confidence scores crystal clear. Now we can calculate the new returns when confidence and manual review costs are a part of the equation:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/roi_calc_extended.png" alt="returns = (5 minutes - (1 - 0.84) * 20 minutes) * 0.9 - (1- 0.9) * 5 minutes = 1.15 minutes"></p></div></div><p>The extended approach nearly doubles the returns! Every prediction saves, on average, 1.15 minutes. Processing your 5000 monthly invoices now involves <strong>95 hours less work</strong> even when the cost of mistakes and manually reviewing 10% of the predictions are accounted for. That’s pretty great!</p><p>Now you know the level of profitability you can currently achieve. And even better, you now have a tool to determine the feasibility of further machine learning development. For example, with the equation, you may calculate the returns for a hypothetical 90% accuracy and find the returns to be <strong>183 hours saved monthly</strong>. Compare it to the estimated development costs of reaching the 90% accuracy and you’ll have factual data for deciding if further development is worth the investment.</p><h3>Summing it up</h3><p>As you’ve seen, machine learning should be approached just like any other investment. The inevitable mistakes are just a cost of doing business and they’re normal variables in our calculations. Armed with these equations, you know exactly when to start reaping the benefits of machine learning without playing a guessing game, and you can put the algorithms into production way earlier. Be freed from the endless grind towards 100% accuracy and start generating value already.</p><p><strong>Done is better than perfect.</strong></p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/return-on-investment-for-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842652</guid>
            <pubDate>Wed, 15 Jul 2020 08:33:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re: Garden of Forking Memes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842509">thread link</a>) | @severine
<br/>
July 15, 2020 | http://subpixel.space/entries/re-garden-of-forking-memes/ | <a href="https://web.archive.org/web/*/http://subpixel.space/entries/re-garden-of-forking-memes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Aaron, I’ve been reflecting on your <a href="https://aaronzlewis.com/blog/2020/07/07/the-garden-of-forking-memes/">Garden of Forking Memes</a> essay. I’m so glad you’ve written such a comprehensive piece on this topic of subculture and history, and I’m honored you asked me to provide feedback on it. It gave me a lot of thoughts that I wanted to flesh out, so I’m responding here. I’m most interested to talk with you about something we’ve discussed a bit before, something which is left implicit in your essay: the disappearance and now reappearance of the future as an idea, and the question of from where the <em>actual</em> future will come.</p>

<blockquote darkmode="" data-title="The%20Garden%20of%20Forking%20Memes%3A%20How%20Digital%20Media%20Distorts%20Our%20Sense%20of%20Time" data-author="Aaron Z. Lewis" cite="https://aaronzlewis.com/blog/2020/07/07/the-garden-of-forking-memes">
The conversations of internet subcultures often feel substantive and expansive compared to the shallow discourse of presidential debates, op-ed pages, and cable TV shows. Mainstream news cycles rarely last more than a few hours, and their narratives are constantly shifting. They don’t tend to give a big-picture sense of where we came from or where we’re going. Internet subcultures, by contrast, are building grand narratives and <a href="https://www.ecosophia.net/the-kek-wars-part-one-aristocracy-and-its-discontents/" target="_blank" rel="noopener">meme worlds</a> that help people feel their way through the chaos that’s currently unfolding. These stories cut deep,&nbsp;down to the most foundational questions of race and religion and destiny. We shouldn’t be too surprised that complex conspiracy theories, intergenerational trauma, and age-old <a href="https://www.scribd.com/document/431359952/Peter-Thiel-The-Straussian-Moment" target="_blank" rel="noopener">religious</a> fervor are coming to the fore — in a contest of narrative memes, deep history is a serious competitive advantage.

</blockquote>


<p>This part of your essay recalled me to our last in-person conversation. In January, you and I were sitting in A/D/O, talking about all manner of things, when you pointed out that every trace of the future seems to have been vanished from popular media. Perhaps this observation was inspired by this sterile piece of public art, whose ceaseless revolutions into new, forgettable arrangements of panels we watched as we conversed.</p>

<p><img src="http://subpixel.space/uploads/ado-panels.jpg" alt="image of rotating panels"></p>

<p>Your observation certainly held true for prestige television: the most popular shows of the last decade have been either gritty realist tragedies (e.g. The Wire, Breaking Bad, even the family politics of Game of Thrones) and unimaginative alternative-now dystopias (e.g. Black Mirror, Handmaid’s Tale, Man in the High Castle). The same could be said for movies, with the addition of campy fantasy, and here I’m sure I showed you this classic David Rudnick tweet. And of course, it’s been said by many that contemporary critical theory seems to have abandoned a progressive agenda beyond enumerating endless variations of capitalism&nbsp;—&nbsp;the carceral, communicative, surveillance…. Even fiction appears to have lost its edge, with last year’s most lauded sci-fi-adjacent novels, Oval and Infinite Detail, failing to render a meaningful vision of the future in any way.</p>

<blockquote><p lang="en" dir="ltr">A training program to acclimatize the citizen under late capitalism to learn and love humanity's new role as spectator and occasional collateral damage in a society consisting of godlike megacorporations and their chaotic interactions? That would be The Marvel Cinematic Universe</p>— ཊལབསརངཧ (@David_Rudnick) <a href="https://twitter.com/David_Rudnick/status/1122271106805719040?ref_src=twsrc%5Etfw">April 27, 2019</a></blockquote>


<p>On the other hand, when optimistic ideas for the future <em>do</em> get proposed (such as carless cities or 100% renewable energy) they are often deemed either unrealistic, delusional, or fiction by mainstream media. I recall coming to the hilarious and grim conclusion that the only type of pop media where a vision of the future is taken seriously is the “request for startup” variety of venture capitalist blog posts. Unfortunately this half-joke was borne out later this year with Marc Andreessen’s TIME TO BUILD essay managing to inspire and invigorate thousands, despite containing no plan for what specifically we should be building towards.</p>

<p>Returning to your essay, it seems that history actually <em>has</em> ended in some meaningful way within mainstream consciousness. While the entire media environment today operates under stream logic — involving&nbsp;the continuous production of new pseudo-events —&nbsp;what is different about legacy 20th-century media institutions is that their discursive progression is wholly ignorant of the past. The evolving discourse of new internet native subcultures, on the other hand, <em>continues to produce history by incorporating new historical facts into themselves.</em> I hope readers take your line “deep history is a serious competitive advantage” literally. Internet-native groups seek out historical events not only because they are politically aware, but because they are in competition with other ideological streams. To combine with Louise Druhle’s analogy, they are under selective pressure to increase their gravitational pull, and in doing so are producing significantly more compelling narratives than mainstream media.</p>

<p>One thing I’m unclear on is why history disappeared from mainstream consciousness in the way it did. Mark Fisher would say that neoliberal subjectivity corrodes one’s imaginary capabilities&nbsp;—&nbsp;the “slow cancellation of the future.” Philip Mirowski would be more explicit, arguing that neoliberal doctrine has had such patently devastating consquences for the working person that it has needed to obscure the origin of its crises and actively shape public discourse to protect itself. I’d also speculate about the separation of public and private spheres we currently tend to make, and the separation of home life, public life, and civic life, both of which also go back to the 70s, but I know little about those things. I guess a good generalization inclusive of all of the above would be that culture is in many ways downstream of capital.</p>

<p>On the other hand, mainstream media may have become ignorant of history as a psychological defense. The development of <a href="https://twitter.com/tobyshorin/status/1273296665416515585">multihistories</a> and memetic competition is just another way of saying the culture war. While we’ve all gotten used to living in a persistent conflict zone, it’s not exactly fun. Under these conditions, the mainstream world of lukewarm takes and forever-breaking news cycles, this Disneyfied universe of crossover events, characterized by the ambient listlessness of memory lapse, provides a sort of dull respite for the mind strained by ideological battle. Do you think this purgatory can last? What is its relationship with centrism? Personally, I’d guess any relief mainstream consciousness provides is illusory. The mainstream is under attack from all sides, with groups of all types attempting to seize its ideological ground. The best defense against ideology remains ideology.</p>

<p>Then there are nomadic anthropologists like you and I. So far, we haven’t declared a side. Up until now I’ve preferred to play the merchant, traveling from tribe to tribe, here selling a rare gem, there performing a clever trick learned far away, collecting oddities and fragments of wisdom as I make my living on the spice route.</p>

<hr>

<blockquote><p lang="en" dir="ltr">The futures we envision never appear, receding into memory like dreams... The real future merges fluidly into the present, forcing revisions, mergers, and forks of historical streams of consciousness....</p>— Toby (@tobyshorin) <a href="https://twitter.com/tobyshorin/status/1273297245853663235?ref_src=twsrc%5Etfw">June 17, 2020</a></blockquote>


<hr>

<p>You ask:</p>

<blockquote darkmode="" data-title="The%20Garden%20of%20Forking%20Memes%3A%20How%20Digital%20Media%20Distorts%20Our%20Sense%20of%20Time" data-author="Aaron Z. Lewis" cite="https://aaronzlewis.com/blog/2020/07/07/the-garden-of-forking-memes"> How does the immediate accessibility of so many alt histories undermine our ability to create shared futures?

</blockquote>


<p>But if all we’ve said before is true, doesn’t it follow that the actual future of humanity will develop not out of mainstream consciousness but out of one or more of these subcultures with a view of big history. In his New Models interview, Venkat mentioned something along these lines: that while inventing the future once took the ambition and charisma of an Elon Musk or an Edison, it’s now realistic to be able to invent the future for a few thousand citizens of one’s small-scale subjective reality.</p>

<p>That’s one reason why at some point, I think it’s more virtuous to choose the future we want to live in than to arbitrage from culture to another. Personally, I’ve never been able to avoid writing moralizing conclusions to my own essays, and these days I’m inclined to push myself further in that direction. I think that’s my biggest difference from Venkat, and the source of my biggest disagreement with him. What’s the point of developing Correct Opinions if you don’t use them to actualize the future you believe in? That’s one reason I’ve been addressing my writing slightly more toward a business audience. We <em>are</em> living in a liminal time, a time with high tolerance (outside the mainstream) for new ideas and experiments with new ways of living. We have higher leverage than we think.</p>

<p>One area I’m investing time into thinking about is new ownership models and ways of dealing with capital. I don’t understand monetary policy and I’m not particularly knowledgeable about economics, but it’s clear to me that we need new ways of understanding and allocating value the networked 21st century. I believe many of the co-ownership experiments happening in cryptocurrency communities can be made less esoteric and ported to areas outside. Capital ownership is a counterbalance to wage stagnation. Economists say that wealth has universal	 power laws, but designable economic models can surely make the curve more equitable. That’s a future worth working towards, IMO.</p>

<p>To what groups and ideas have you been hitching your camel? What history do you believe everyone should acknowledge? And what future? Your essay left me with questions about the role of the individual. Identity has never been ahistorical, and history has never been apolitical, but now more than ever, our identity is a decision of historical politics. With a self awareness unmatched by any historical subject, we see who we walk alongside, and can choose our caravan. We may not all be history-makers, we are all at least history selectors.</p>

</div></div>]]>
            </description>
            <link>http://subpixel.space/entries/re-garden-of-forking-memes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842509</guid>
            <pubDate>Wed, 15 Jul 2020 08:07:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tech vs. Media: We Need a New Model of Truth]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23842362">thread link</a>) | @mehdiyac
<br/>
July 15, 2020 | https://www.mehdiyacoubi.com/post/iterative-model-of-truth | <a href="https://web.archive.org/web/*/https://www.mehdiyacoubi.com/post/iterative-model-of-truth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.2"><div dir="ltr"><div><p id="viewer-foo"><em>New times call for new ways of finding the truth</em></p><div id="viewer-1i4li"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_b809e6bb440e4a3881f817c2c94d0ca2~mv2.jpg/v1/fit/w_1600,h_1538,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_b809e6bb440e4a3881f817c2c94d0ca2~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div><p><span>Veritas, goddess of truth in Roman mythology</span></p></div></div></div><p id="viewer-e9mbk"><span>We’re in January 2020. A new virus just appeared in China. What is going to happen in the following months will reveal everything that is wrong with one of the pillars of our societies: Truth.</span></p><div id="viewer-3sk6m"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_ec5b098f28b04fecb0bccd5a2c761745~mv2.jpeg/v1/fit/w_5000,h_1332,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_ec5b098f28b04fecb0bccd5a2c761745~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div><p><span>Coronavirus headlines in January</span></p></div></div></div><p id="viewer-8gj82">The COVID-19 crisis showed our society isn’t equipped with the right systems to find the truth. Our current model is broken and we need to reinvent it!</p><p id="viewer-asqnc">In his <a href="https://en.wikipedia.org/wiki/Metaphysics_(Aristotle)" target="_blank" rel="noopener">Metaphysics</a>, Aristotle wrote:</p><blockquote id="viewer-3njpj"><p>“To say of what is that it is not, or of what is not that it is, is false, while to say of what is that it is, and of what is not that it is not, is true”.</p></blockquote><p id="viewer-1hd5d">Truth played many different roles throughout history. It served as a source of political authority, religious doctrine, cultural common ground, and scientific thinking.</p><p id="viewer-aro6r">With the development of science and scientific thinking, Truth became intrinsically related to scientific and factual knowledge.</p><p id="viewer-a987q">The German philosopher Enrich Fromm said:</p><blockquote id="viewer-bb6ml"><p>“The history of thought is the history of an ever-increasing approximation to the truth. Scientific knowledge is not absolute but optimal; it contains the optimum of truth attainable in a given historical period.”</p></blockquote><p id="viewer-c6tf1">Truth is what makes us understand things and progress. It helps us make the right decisions, act without prejudice or bias, and achieve optimal outcomes. Without Truth, we live in darkness, and society can’t thrive in the long term.</p><p id="viewer-avtn3">For example, in January, knowing the truth would have meant understanding the gravity of the virus in China which would have pushed us to act fast and potentially prevent it from spreading globally. That is not what happened, was it?</p><p id="viewer-eumsn"><a href="https://membership.theguardian.com/event/are-we-living-in-a-posttruth-era-34826634401" target="_blank" rel="noopener">Many argue</a> that we live in a “post-truth” era. It feels as if the concept of truth had lost its importance. But which truths are we talking about? There are personal truths, community truths, cultural truths, scientific truths… Some of these do not have anything to do one with another, scientific truths are very different from cultural truths. Here I will focus on scientific and factual truths.</p><p id="viewer-ad34j">If you take a look at the institutions people rely upon as a source of truth, you’ll discover that, at best, the information they provide is distorted, biased, or simply unreliable. At worst, you’ll immediately think “that’s a lie”.</p><h2 id="viewer-7bhim">Legacy Media</h2><p id="viewer-95upa">Media companies market themselves as “the source of infallible truth.” They aren’t seeking truth as a primary goal. How could we expect the truth from an entity that isn’t incentivized to produce it?</p><div id="viewer-fgr36"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_740801898c4b4244b36b13f4e956e522~mv2.jpg/v1/fit/w_1000,h_562,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_740801898c4b4244b36b13f4e956e522~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-butea">The other problem with media comes from the new subscription business model they implemented. With an increasing polarization, media outlets must stay in their political leaning. If they don’t, they face a massive loss of subscriptions. An example of this happened recently with the NYT. By publishing “<a href="https://www.nytimes.com/2020/06/03/opinion/tom-cotton-protests-military.html" target="_blank" rel="noopener">Send in the Troops</a>,” the company faced one of its biggest subscription losses ever.</p><p id="viewer-50a3q">The following picture shows the evolution of word usage frequency at the New York Times. As <a href="https://twitter.com/paulg/status/1136962504343662592" target="_blank" rel="noopener">mentioned</a> by Paul Graham, it seems that in our current world, if you want people to subscribe, you must pick a side. Truth doesn’t have side, however. It makes it impossible to rely on media corporations to find it.</p><div id="viewer-87avr"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_f2246ffcdc69493baf77ec5bf5f1b9b0~mv2.jpeg/v1/fit/w_1855,h_2048,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_f2246ffcdc69493baf77ec5bf5f1b9b0~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h2 id="viewer-eg9dc">Social Media</h2><p id="viewer-daoe">Social networks users <a href="https://www.emarketer.com/content/us-adults-are-spending-more-time-on-social-media-during-the-pandemic#:~:text=Social%20network%20users%20will%20spend,minutes%20from%20our%20previous%20forecast" target="_blank" rel="noopener">spend</a> an average of 1h 22minutes on social media per day. This number is increasing very fast, and it shows no signs of slowing down. Most of the content we consume we get on social media. This makes social media a critical protagonist in our search for truth.</p><p id="viewer-d3dka">The problem with this is that social media value engagement, and this doesn’t align generally with the truth. The number of retweets and likes has nothing to do with what’s true.</p><p id="viewer-669lp">Social media has increased our tendency to rely on tribal truth. It has become the realm of tribal truth. Identity is an essential part of who we are and when we base our identity on a set of ideologies that prevent people from accepting facts, there’s a clear problem. We learn and accept facts from people we like and trust. It’s obvious that this can’t be a way to find the truth.</p><p id="viewer-9pbaa">What if social media curated information and made the real facts more visible?</p><p id="viewer-9srt6">In that case, we’re back to the “Media” point above. If social media had become the new “guardian of truth,” we did not solve the problem. If Youtube bans what isn’t explicitly compliant with WHO’s recommendations, and if Twitter can edit the Times, it means there is one version of the truth. History already showed this isn’t a good idea.</p><p id="viewer-8quv5">Social media shouldn’t become the new “guardian of truth”.</p><h2 id="viewer-ajc89">Government Institutions</h2><p id="viewer-ee82t">The third entity where we usually get information from is institutions, from governments to global organizations. These entities have a lot of power but as they are political and strategic entities, they aren’t always incentivized to tell us the truth.</p><p id="viewer-7nopo">For example, a significant turning point may have happened during the current COVID-19 pandemic where science transformed from a tool of discovering the truth into a political tool of institutions.</p><p id="viewer-bq8u0">If science is used by big institutions to push their ideas or to justify their actions, we are lost.

</p><div id="viewer-915ga"><a href="https://twitter.com/joshmich/status/1235201253296263169?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1235201253296263169%7Ctwgr%5E&amp;ref_url=https%3A%2F%2Fcdn.embedly.com%2Fwidgets%2Fmedia.html%3Ftype%3Dtext2Fhtmlkey%3Da19fcc184b9711e1b4764040d3dc5c07schema%3Dtwitterurl%3Dhttps3A%2F%2Ftwitter.com%2Fjoshmich%2Fstatus%2F1235201253296263169image%3D" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/iterative-model-of-truth" data-pin-media="https://static.wixstatic.com/media/caefc6_ce4dda2309e84c33aeb0102a5c63b67f~mv2.png/v1/fit/w_1170,h_504,al_c,q_80/file.png" src="https://static.wixstatic.com/media/caefc6_ce4dda2309e84c33aeb0102a5c63b67f~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></a></div><h2 id="viewer-20f8p">A Lost sense of Truth</h2><p id="viewer-7t4ga">With all these shortcomings, it’s getting really hard to find the truth these days. Social media is weaponized, and while people spend more and more time online, they are being influenced by ideas turned into ideologies that may factually be wrong.</p><p id="viewer-bv41a"><a href="https://www.hilltimes.com/author/matt-mcmanus" target="_blank" rel="noopener">Matt McManus</a>, coined the term “<a href="https://www.hilltimes.com/2018/08/27/trump-age-bullshit-roots-knowledge-crisis/155316" target="_blank" rel="noopener">age of bullshit</a>” to express the knowledge crisis we are going through. It’s a dangerous time we live in, and in order to solve many of the challenges we face, we need, first, to focus on the meta-problems.</p><h2 id="viewer-83re0">A solution: the iterative model of truth</h2><h3 id="viewer-b8q47">The COVID19 Tracking Project</h3><p id="viewer-hnvv">As said, the press coverage of COVID-19 was disastrous early on. It led to most people and governments not taking the pandemic seriously. A counterexample of this is the <a href="https://covidtracking.com/" target="_blank" rel="noopener">COVID19 Tracking Project</a>.</p><p id="viewer-a7kdk">This tracking project was not presented as “the Truth” in the way the New York Times does. It shows the most accurate data, with revision history.</p><p id="viewer-544ku">Truth is a process; it’s not something set in stone; it changes. The problem with media corporations is that they present the truth as something fixed — the truth is what they publish. When they mistake, it’s difficult for them to admit that they have mistaken, because they would risk losing their positions as the guardians of the truth.</p><p id="viewer-dl914">It’s not a problem to be incorrect; the problem is not to admit it and build your whole legitimacy on being the truth.</p><h2 id="viewer-a80de">The GitHub Model of Truth</h2><p id="viewer-1vh0c">When’s the last time you heard a politician admitting he or she was wrong? I can’t think of an example. Conversely, if an app crashes, its developers will have no choice but to admit they made a mistake.</p><p id="viewer-fk3m8">It’s the GitHub model of truth. You know there will be mistakes, and you’re okay with it. As soon as you discover a problem, you correct it, and everyone can submit corrections.</p><p id="viewer-4ida7">Truth should follow the Github model. As soon as something is factually wrong, it should be easy to correct it and make the mistake visible to everyone.</p><p id="viewer-4l7ld">But how could we make it a reality outside of the tech world?</p><p id="viewer-e8tjf">For something to work, it must be created in a way that incentives are correctly aligned. Here, we want a collaborative system that gives us the best version of the truth.</p><h2 id="viewer-5otrr">How to Align the Incentives</h2><p id="viewer-a8302">The first idea that comes in mind to align the incentives is to make it financially attractive to be correct. What if “being right” meant earning money? An idea to fix this problem is to modify social media engagement metrics with social features based on a prediction market. Imagine if instead of liking or retweeting a tweet about an economically impactful statement, you could “bet” financially on it.</p><p id="viewer-46ogj">This approach would change the nature of the attention you give to the truth. You wouldn’t want to back the false claims, right? So before “betting” on a tweet, you would do your due diligence of fact-checking it and make sure it’s correct.</p><p id="viewer-c3726">No one should have the ability to say what’s right or wrong. It’s a collective process of multiple people fact-checking the statements and sourcing the information that can lead to the best version of the truth. The era of decentralized media must start if we want the truth.</p><p id="viewer-4djfj">In academia (I know a lot of things are wrong with academia), when a paper is published, it gets reviewed. We should do the same, but, unlike academia, we should do it in a decentralized way.</p><p id="viewer-b9dgk">For example, The <strong>Reproducibility Project: Psychology</strong> was a <a href="https://en.wikipedia.org/wiki/Crowdsourced_psychological_science" target="_blank" rel="noopener">crowdsourced</a> collaboration of 270 contributing authors to repeat 100 published experimental and correlational psychological studies. This idea of reproducing a finding must be transferred outside of the research world. What if independent reporters were doing the same with major stories?</p><p id="viewer-d2436">How would they get paid? The rise of independent journalism is happening now; Substack is an excellent example of it. An increasing amount of people are ready to subscribe to independent journalists to receive their work. It could be a solution to the problem. The <a href="https://taibbi.substack.com/" target="_blank" rel="noopener">newsletter</a> of Matt Taibbi is a great example of this, and another example is the excellent reporting of <a href="https://twitter.com/DellAnnaLuca" target="_blank" rel="noopener">Luca Dellanna</a> during the COVID-19 pandemic. To get the best information on the coronavirus, you had to follow the right people on Twitter, not the prominent publications.</p><p id="viewer-foc37">Decentralized and independent sources of information is also a way to promote <a href="https://marginalrevolution.com/marginalrevolution/2003/11/metarational_an.html" target="_blank" rel="noopener">meta-rationality</a>, a concept <a href="https://twitter.com/tylercowen" target="_blank" rel="noopener">Tyler Cowen</a> brings up a lot. It’s the concept of being aware of your cognitive limitations and know how to trust in topics where you don’t have the expertise to understand.</p><h2 id="viewer-4l0pi">New Social Media</h2><p id="viewer-5g9m7">Is it possible to have this approach to the truth using the existing social media? It seems hard. The social media were built with different motivations at the core. What we need is social media made entirely for the purpose of revealing the truth. As the French investor Xavier Faure <a href="https://twitter.com/XFaure/status/1092444972635303936" target="_blank" rel="noopener">said</a>:</p><blockquote id="viewer-ah70t"><p>“We need a trust social network. Where we don’t signal what we like, but what we vouch for.”</p></blockquote><p id="viewer-aiqju">It …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mehdiyacoubi.com/post/iterative-model-of-truth">https://www.mehdiyacoubi.com/post/iterative-model-of-truth</a></em></p>]]>
            </description>
            <link>https://www.mehdiyacoubi.com/post/iterative-model-of-truth</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842362</guid>
            <pubDate>Wed, 15 Jul 2020 07:41:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Your Own ColecoVision at Home – Part 2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842351">thread link</a>) | @kyleee
<br/>
July 15, 2020 | https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html | <a href="https://web.archive.org/web/*/https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>The boards for the homemade ColecoVision clone project have arrived. It’s been a long haul of finger-burning fun to get the console assembled, but will it ever be able to play a cartridge?</p>

<h2 id="parting-with-cash">Parting, with Cash</h2>
<p>Almost immediately after the Gerbers were sent off to JLCPCB, I ordered the entire BOM from Digi-Key. A huge bag of crap arrived within a few days.</p>

<p>It’s easy to lose scale on how big things really are when you’re constantly fighting for those fractions of a millimeter to route traces. At human-scale, I was a little shocked by how small a lot of the components were. All the SOT-23 stuff is smaller than a pinky fingernail and has teeny-tiny pins that don’t stick out very far. There’s no better way than this to get better at surface-mount soldering!</p>

<p>There were a couple problems with the order, but that’s to be expected. This was definitely the biggest parts-count board I’ve ever done, and I learned a lot. Things like, don’t leave making the BOM until the very last minute, because it takes an entire morning and four cups of coffee. And that you should always do the BOM <em>before</em> you order the board, in case your footprints aren’t right.</p>

<p>One big problem was that I wasn’t able to find a bi-polar 68µF capacitor in 0805. You’d think that would be easy, but it appears the laws of physics forbid it. I changed the footprint (<em>after</em> ordering the board, of course) to a larger 1206 and then ordered some through-hole ceramic caps that I could bodge onto the pad. Said 68µF capacitor is for the clock circuit, so I think its value was quite important:</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-68uf-cap.png" alt="The 68µF capacitor in question, nestled between a 2n3904 transistor and some flip-flops."></p>

<p>You might be asking yourself why I need such a big capacitor for a clock circuit. Aren’t clock circuits usually using <em>pico</em>-Farads? Well…….</p>

<p>A few hours after I ordered the parts, I got an email from Digi-Key saying that there was an inventory discrepancy and that they actually only had one 2kΩ 0805 surface-mount resistor in stock, not two. This was a pretty funny idea to me, that their inventory robots would constantly be shuttling past a sad bin that only contains one minuscule resistor in an extremely common capacitance.</p>

<p>What was even funnier is that the part was now <em>discontinued</em> - as if a bunch of people working at the resistor factory got told by their boss that he doesn’t think anyone’s going to really want 2kΩ resistors anymore. “No, what customers want now is <em>capacitors</em>,” he’ll chuckle at his business acumen, while the resistor department’s hated rival, Bob Dielectric, rubs his hands in glee. I ordered literally one hundred 2kΩ 0805s from a different manufacturer for a buck instead.</p>

<p>What’s not as funny is that the cartridge slot I had paid six bucks for came without pins. When I saw it on Digi-Key, it had been listed without an image, but I figured there was no way it wouldn’t come without pins. After cursing myself, I ordered up another bunch of 0.1” 30-pin edge connector slots, except this time with pins. The new Sullins-branded ones came in a fetching shade of blue and - just to rub it in - cost a little less. However, they still weren’t what I was looking for…</p>

<p>Another small opposition to the project came in the form of some local scumbag, who stole one of the DigiKey orders off my porch, tore it open, presumably found nothing that they could fence or snort, and then threw the opened box into my backyard. Everything was still there, but clearly the forces of “I’d really like some drugs” are aligned against the Leako Initiative.</p>

<p>And, yes, the clock circuit did ask for 68 <em>pF</em>. I made a mistake reading it off the schematic, which changed between notations of capacitors depending on which sheet you were looking at. I figured this out a while later, which I’m not very proud of.</p>

<h2 id="sound-off">Sound Off</h2>
<p>Another mistake I made was not reversing the data bus on the 76489 sound chip. Like the TMS9918, this TI sound chip is also ‘backwards’ from the Z80’s data pin convention: pin D<sub>0</sub> on the Z80 goes to D<sub>7</sub> on the 76489 and so on.</p>

<p>I resolved to bodge wire this onto a piece of protoboard, and just live with the shame for now. Unfortunately, the sound chips took several months to arrive (coronavirus again,) so I ended up just going ahead with the v0.2 board, where I made this change. Despite the counterfeits and recaps, it is great to ride the “80s grey-market sound chip” market until something like this happens to screw it up.</p>

<p>When one of the orders of SN78649s arrived, I built a breadboard tester for it powered by an Arduino. I had heard that the reliability of these chips was very low, so I expected not very many of them would work. The first chip I tested worked great - except that my code was terrible and didn’t produce a reliable result due to bad timing.</p>

<center><iframe width="560" height="315" src="https://www.youtube.com/embed/ZMITqYnvz-A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></center>

<p>After a few hours of bodging and reading <a href="https://www.smspower.org/Development/SN76489">documentation on SMSPower</a>, I managed to figure out how to test the chip. Here it is cycling through channels 0, 1, 2 and the two kinds of noise supported by the chip. At least we’ve got <em>one</em> known-good salvage part!</p>

<h2 id="controller-prep">Controller Prep</h2>
<p>The controller I ordered as part of a lot from Quebec in the previous entry arrived almost immediately, and I set about tearing it down and cleaning it. It was really gross! The plastics got washed in my kitchen sink, the coiled cord scrubbed <a href="https://www.leadedsolder.com/2019/10/29/pc8801mh-keyboard-clean.html">with the flossing method</a>, and the (delaminating) matrix keypad got a once-over with some disinfecting wipes.</p>

<p>It had one missing coarse-thread Phillips screw, which I replaced with another from my junk drawer. I still haven’t figured out how to get a new shiny ‘grip disc’ for the top of the joystick - maybe I’ll make something with hockey tape.</p>

<p>Cleaning and servicing controllers doesn’t need a whole lot of focus or technical skill, which makes it the perfect task to say you’ve actually done <em>something</em> on a project today.</p>

<p>The wires that go from the DE9 cable onto the PCB are just crimped onto the pads on the PCB. A bunch of these crimps were super loose and probably not making good contact, which might be the reason why this controller was getting sold with the other junky parts. I tried to tighten them up, but one tragically snapped as soon as I applied any force:</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-controller-dead-crimp.jpg" alt="A good and a bad crimp. The red one (bottom) has lost one of its little crimpy 'wings'."></p>

<p>I decided I would cut off all the crimps and solder the wires directly to the board. This worked okay, except that the insulation on the wires was definitely not solder-heat proof and melted. Since the pads had never been used for solder in 37 years, I decided it would also be prudent to put a little liquid flux on them in order to prep them for the solder.</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-controller-crimps-cut.jpg" alt="The cut crimps in a pile."></p>

<p>The joints weren’t pretty since I had to work fast. That’s my excuse. Also, I had to desolder the entire thing and do it again after I realized the wires have to slip through the back plastic case and so should be soldered only <em>after</em> threading them through…</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-controller-soldered-wires.jpg" alt="The wires soldered to the ColecoVision controller PCB. The PCB calls out the colour of each wire."></p>

<p>Finally, after some fighting, I was able to reassemble the controller. It wasn’t a great fit, even with the new screw, because the lower plastics that clip together had broken from age and abuse. Also, I didn’t do a great job of actually cleaning the top plastic for fear of rusting the spring, so I went back and did another quick scrubbing with a q-tip and isopropyl alcohol.</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-controller-reassembled.jpg" alt="The re-assembled controller."></p>

<p>That was a lot of work for an ugly controller that doesn’t feel that great in the end… I hoped it would at least work. I can always buy or build a nicer one later.</p>

<h2 id="get-onboard">Get Onboard</h2>
<p>Eventually, the boards shipped from the fab. One of them had been ‘scratched’ during the assembly process, so I was fully refunded on it. It’s still nice enough to use for a practice board in the future.</p>

<p>And as soon as they shipped, I noticed something a little weird. Remember last episode, where I told you about how to wire up a clock divider? Well, the new clock divider I added to go from 14MHz down to 7MHz was done correctly, but not the “original” clock divider from the schematic that I blindly copied.</p>

<p>Here are the two dividers in different schematics:</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-bad-clock-divider.png" alt="The schematic that was sent off to fab. The not-Q output is not connected to anything."></p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-good-clock-divider.png" alt="The schematic that I discovered after fabrication. The not-Q output is connected to the D-input."></p>

<p><a href="https://atariage.com/forums/topic/285656-new-colecovision-schematics/">The latter schematics, by an Atari Age user known as ChildOfCv</a>, were meticulously double-checked. Had I known there were errors in the original schematic, I probably would have gone from the start with ChildOfCv’s. I have a huge debt to the original schematics, of course, as that is an immense amount of work. One or two errors here isn’t surprising in a task like that. It was only here that I discovered my 68pF clock circuit error, in case you’re keeping track.</p>

<p>Clearly, it was time to rework my clock circuit and spin a v0.2 with all the other problems I’d noticed. This made the board a little uglier in some spots, as I tried to reintroduce chips into the same general location they had once occupied but ran new traces. My timing circuit got split up when I put it on the board originally (since I left it for almost last), so changing it isn’t necessarily a matter of removing one chunk of the board and laying a new one down. I’ll try to get better at keeping physical space for “zones of responsibility” on future projects. Still, though, the re-routing took less than an hour and I was able to send the v0.2 board off:</p>

<p><img src="https://www.leadedsolder.com/assets/colecovision-v0.2.png" alt="The ColecoVision v0.2 board as viewed by the JLCPCB gerber viewer."></p>

<p>Why yes, I <em>did</em> put Q3, a through-hole transistor, right in the way of the plastic shell of the cartridge when it is inserted into the slot. Good thing they have bendy legs…</p>

<h2 id="v01-arrives">v0.1 Arrives</h2>
<p>Even though I knew that my first-born clone board had some flaws, it was hard not to smile when I unpacked the boards. They’re so <em>tiny</em>, but they (will) do so much!</p>

<p><img src="https://www.leadedsolder.com/assets/leako-v0.1.jpg" alt="The (red) v0.1 boards, front and back."></p>

<p>That RAM chip next to the Z80 being so far north really bugs me now, although I hardly noticed it before. If it works…</p>

<p><img src="https://www.leadedsolder.com/assets/leako-v0.1-posed.jpg" alt="The v0.1 board on some improvised standoffs"></p>

<p>I used some of <a href="https://en.wikipedia.org/wiki/Spacers_and_standoffs">those little jackscrew standoff retainers that hold on VGA cables</a> to stand the board up off the table. This is important not just for looks, avoiding shorts, and cooling, but because there are chips on both sides. They weren’t a perfect fit for an M3 hole, but when screwed tightly together they don’t wobble. At last, the junk-bin investment is paying off.</p>

<p>Even though I had already ordered the v0.2 boards, I started doing some of the test-fitting that I should have done on paper. That’s right, I’m once again …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html">https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html</a></em></p>]]>
            </description>
            <link>https://www.leadedsolder.com/2020/07/10/colecovision-diy-part-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842351</guid>
            <pubDate>Wed, 15 Jul 2020 07:39:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not Recommending Purism]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842347">thread link</a>) | @varbhat
<br/>
July 15, 2020 | https://anarc.at/blog/2020-07-13-not-recommending-purism/ | <a href="https://web.archive.org/web/*/https://anarc.at/blog/2020-07-13-not-recommending-purism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>This is just a quick note to mention that I have updated my <a href="https://anarc.at/hardware/laptop/purism-librem13v4">hardware
documentation on the Librem 13v4 laptop</a>. It has unfortunately
turned into a rather lengthy (and ranty) piece about Purism. Let's
just say that waiting weeks for your replacement laptop (yes, it died
again) does wonders for creativity. To quote the full review:</p>

<blockquote><p>TL;DR: I recommend people avoid the Purism brand and products. I
find they have questionable politics, operate in a "libre-washing"
fashion, and produce unreliable hardware. Will not buy again.</p></blockquote>

<p>People who have read the article might want to jump directly to the
new sections:</p>

<ul>
<li><a href="https://anarc.at/hardware/laptop/purism-librem13v4/#libre-washing">Libre washing</a></li>
<li><a href="https://anarc.at/hardware/laptop/purism-librem13v4/#bullshit-anti-interdiction">Bullshit anti-interdiction</a></li>
<li><a href="https://anarc.at/hardware/laptop/purism-librem13v4/#bullshit-crowdfunding">Bullshit crowdfunding</a></li>
<li><a href="https://anarc.at/hardware/laptop/purism-librem13v4/#hardware-reliability">Hardware reliability</a> (or lack thereof)</li>
</ul>


<p>I have also added the minor section of the <a href="https://anarc.at/hardware/laptop/purism-librem13v4/#no-mic-jack">missing mic jack</a>.</p>

<p>I realize that some folks (particularly at Debian) might still work at
Purism, and that this article might be demoralizing for their work. If
that is the case, I am sorry this article triggered you in any way and
I hope this can act as a disclaimer. But I feel it is my duty to
document the issues I am going through, as a user, and to call
bullshit when I see it (let's face it, the anti-interdiction stuff and
the Purism 5 crowd-funding campaign were total bullshit).</p>

<p>I also understand that the pandemic makes life hard for everyone, and
probably makes a bad situation at Purism worse. But those problems
existed before the pandemic happened. They were issues I had
identified in 2019 and that I simply never got around to document.</p>

<p>I wish that people wishing to support the free software movement would
spend their energy towards organisations that actually do honest work
in that direction, like <a href="https://system76.com/">System76</a> and <a href="https://www.pine64.org/">Pine64</a>. And if you're
going to go crazy with an experimental free hardware design, why not
go retro with the <a href="https://www.crowdsupply.com/mnt/reform">MNT Reform</a>.</p>

<p>In the meantime, if you're looking for a phone, I recommend you give
the <a href="https://www.fairphone.com/">Fairphone</a> a fair chance. It really is a "fair" (as in, not
the best, but okay) phone that you can moderately liberate, and it
actually frigging works. See also my <a href="https://anarc.at/hardware/phone/fairphone2">hardware review of the FP2</a>.</p>

<p>Update: this kind of blew up, for my standards: 10k visitors in ~24h
while I usually get about 1k visitors after a week on any regular blog
post. There were more discussions on the subject here:</p>

<ul>
<li><a href="https://lobste.rs/s/ecyjq2/not_recommending_purism">Lobsters</a></li>
<li><a href="http://www.reddit.com/r/linux/comments/hr8hvi/not_recommending_purism">Reddit /r/linux</a>, <a href="https://www.reddit.com/r/linuxhardware/comments/hqs48i/debian_developer_not_recommending_purism/">/r/linuxhardware</a>, <a href="https://www.reddit.com/r/Purism/comments/hqs0vz/debian_developer_not_recommending_purism/">r/purism</a></li>
<li><a href="https://news.ycombinator.com/item?id=23842347">Hacker news</a></li>
</ul>


<p>Trigger warning: some of those threads include personal insults and
explicitly venture into the <a href="https://anarc.at/blog/2019-05-13-free-speech/">free speech
discussion</a>, with predictable (sad)
consequences...</p>


            

            
              
  
  <nav>
    
  </nav>
  


            

            
            
            
            

            

            <nav>
                
            
            
            </nav>
            

            
    </div></div>]]>
            </description>
            <link>https://anarc.at/blog/2020-07-13-not-recommending-purism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842347</guid>
            <pubDate>Wed, 15 Jul 2020 07:38:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a new app for practicing keyboard shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842339">thread link</a>) | @jacobedawson
<br/>
July 15, 2020 | https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>I have always wanted to build a software product as a side project. Something that I could gradually improve and work on for years without deadlines and technology restrictions. Something that was <em>my</em> side-project.
Fortunately, I was never short of ideas. In my post on <a href="https://tkainrad.dev/posts/managing-my-personal-knowledge-base/#shortcut-database">managing my personal knowledge base</a>, I have mentioned that I keep a Notion database of project ideas. It has plenty of entries.</p>
<p>In the same post, I also described my shortcut database use case. It was a spreadsheet to keep track of all the keyboard shortcuts I was using. Something about this motivated me much more than all the Slack bots and browser extensions lurking around in my ideas list. So, I started to work and expand on the concept in the form of a new web application. Initially, I thought It would take me until the end of 2020 to have anything that I could share with the world. Then, the Corona-lockdown came, and suddenly most of my other free time activities were no longer possible.</p>
<p>Long story short, <a href="http://keycombiner.com/">keycombiner.com</a> is now available for everyone to use.
This post covers how it compares to existing tools, what it tries to do, how it does it, and the road ahead.</p>
<p>KeyCombiner is completely free to use, with no strings attached. For a demo of the <em>Practice</em> mode or browsing <a href="https://keycombiner.com/collecting/collections/public/">public shortcut collections</a>, you don’t even need to create an account.</p>

<p>There are a lot of typing practice tools available. However, KeyCombiner is quite different from all of them.</p>
<p>The vast majority of existing tools focus on text typing. These applications will show you automatically generated pieces of text that you are supposed to type as fast and as correct as possible.
Usually, you will get a report at the end about your speed and accuracy. I do like this a lot and often test my typing speed. It is a fun thing to do once in a while, and if you realize that your typing speed is low, you might want to work on it.
Of course, these tools have nothing to do with keyboard shortcuts. They will not help with learning them and also do not include them in their typing practice.</p>
<p>When looking at practicing keyboard shortcuts, there are far fewer alternatives to choose from. But still, there are a couple of existing apps.
To my knowledge, all of them work with pre-defined lessons, which is very unintuitive for me. I don’t want to learn <em>all</em> keyboard shortcuts of a particular app. Also, they are focused solely on learning keyboard shortcuts, not with your typing skills per se. Therefore, they do not record typing speed, accuracy, or any other such metrics. For me, this alone removes most of the motivation for using such a tool. I don’t want to only learn shortcuts, I also want to become faster and more accurate at using them.</p>
<p>KeyCombiner aims to bridge this gap between typing training software and shortcut learning apps. Besides, it goes to great lengths to make it easy to learn and practice not just any shortcuts but precisely the ones you want to use.
If you like to look at Venn diagrams that probably shouldn’t be Venn diagrams, I have just the thing for you:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/typing-trainers-venn.svg">
</figure>

<p>Developing KeyCombiner, I had and still have the following goals:</p>
<p><strong>Enable efficient creation of keyboard shortcut collections</strong></p>
<p>The first goal is, of course, to cover the original use case described in my <a href="https://tkainrad.dev/posts/managing-my-personal-knowledge-base/#shortcut-database">knowledge management post</a>.
Having an overview of all the keyboard shortcuts you are using and intend to learn is already useful in itself. However, it is clear that most people don’t want to spend a lot of time with this task, so it has to be possible in a couple of minutes to build meaningful collections.</p>
<p><strong>Facilitate learning of keyboard shortcuts</strong></p>
<p>Generally, I want to provide as much value on top of a user’s shortcut collections as possible. Learning new keyboard shortcuts is probably the most powerful thing that can be done. It is therefore the second fundamental goal of KeyCombiner.</p>
<p><strong>Allow to practice also text snippets</strong></p>
<p>As developers, we have many short text snippets that we need to remember. Think of <em>git</em> commands or language syntax. These feel similar to keyboard shortcuts, and I would like to be able to practice them together.</p>
<p><strong>Help to improve typing speed and accuracy</strong></p>
<p>Going beyond mere memorization of keyboard shortcuts is an important aspect and one thing that sets KeyCombiner apart from other software. The goal is not just to learn keyboard shortcuts, but to be able to type them fast and accurately, too.</p>

<p>This section covers KeyCombiner’s three main areas. However, those are very much connected, as illustrated in the following figure:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/tirangle-of-col-stat-train.svg">
</figure>
<h2 id="create-shortcut-collections">Create shortcut collections</h2>
<p>A core idea of KeyCombiner is to learn and practice <em>exactly</em> the shortcuts you need or want to use. The only way to achieve this is if you choose them yourself.</p>
<p>I thought a lot about how to make this collection building process as efficient as possible. From the start, it was apparent that it would need to be possible to import keyboard shortcuts and text snippets from a public database of popular application shortcuts. This mechanic can be used to build the bulk of your collections quickly. They can then be completed by manually adding entries.</p>
<p>I like to compare my approach to how you build playlists in music software. Instead of browsing your favorite artists’ albums, KeyCombiner allows you to browse categories of your favorite applications. Instead of adding songs to your playlists, you can add keyboard shortcuts and text snippets to your collections:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collecting.gif" alt="KeyCombiner&amp;rsquo;s combination tables support all popular multi-selection patterns, i.e. drag selecting, Shift-selection and maintaining selection via Ctrl"> <figcaption>
<p>KeyCombiner’s combination tables support all popular multi-selection patterns, i.e. drag selecting, <kbd>Shift</kbd>-selection and maintaining selection via <kbd>Ctrl</kbd></p>
</figcaption>
</figure>
<p>KeyCombiner’s <a href="https://keycombiner.com/collecting/collections/public/">public collections</a> already contain thousands of keyboard shortcuts. Each collection can be filtered and searched quickly.</p>
<p>Creating collections of keyboard shortcuts is already a use case in itself. It can help to answer a variety of questions:</p>
<ul>
<li>How many shortcuts am I using?</li>
<li>Are my key bindings logical and consistent or am I using completely different combinations for similar things?</li>
<li>For which applications am I using my shortcuts?</li>
<li>I am setting up a new machine and want to set up my key bindings. What were those exactly?</li>
</ul>
<p>When combining personal shortcut collections with the other two main areas of KeyCombiner, we can answer even more interesting questions:</p>
<ul>
<li>How well do I actually know the shortcuts in my collections?</li>
<li>How fast can I type them?</li>
<li>How often do I make an error while typing a specific shortcut?</li>
</ul>
<p>As shown in the <a href="#how-it-works">illustration above</a>, collections are annotated with information gathered from KeyCombiner’s statistics. Most importantly, the confidence value shows how good you are with a combination in your collections:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/confidence.png" alt="Some keyboard shortcuts that I have practice often and am therefore very confident with."> <figcaption>
<p>Some keyboard shortcuts that I have practice often and am therefore very confident with.</p>
</figcaption>
</figure>
<h2 id="learn-shortcuts-flashcard-style">Learn shortcuts flashcard-style</h2>
<p>Before going deeper into confidence values and other statistical measures, we need to take a step back and look at how data is gathered. It is done while you practice your shortcut collections.</p>
<p>In principle, KeyCombiner’s interactive training is similar to other applications. You are shown what a shortcut does and, ideally, you know the keys and type it in correctly:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/learning.gif" alt="KeyCombiner&amp;rsquo;s interactive trainer has a visual keyboard and options for displaying the keys to type."> <figcaption>
<p>KeyCombiner’s interactive trainer has a visual keyboard and options for displaying the keys to type.</p>
</figcaption>
</figure>
<p>What makes KeyCombiner unique in this regard is that you are practicing your very own collections, hence exactly the shortcuts you want to learn! Furthermore, KeyCombiner gathers detailed statistics that help to analyze your performance. You might know how many words you can type by minute (WPM), but do you also know how many keyboard shortcuts you can execute during this time?</p>
<p>There are many more things to be said about the <em>Practice</em> mode. It does all kinds of things to make learning as efficient as possible. For example, it uses ideas from spaced repetition and shows keyboard shortcuts with low confidence value more often than others. Then, there is the option to display the actual keys of a combination after a delay that gives you some time to think. This is a tricky thing to do, because key combinations typed with hints should not influence the confidence value. But that’s a topic for another blog post.</p>
<p>What I like to do personally is to gradually expand my collections. For example, I set a goal of learning 10 new shortcuts a given week. Then, at the beginning of the week, I browse the public collections for 10 new shortcuts and add them to one of my collections.
Throughout the week, I do a 60-seconds practice session from time to time. Because the new shortcuts have a low confidence value at the beginning, KeyCombiner will show them often during practice, and after just a couple of practice runs, I usually know them well.</p>
<h2 id="statistics-to-improve-accuracy--speed">Statistics to improve accuracy &amp; speed</h2>
<p>One of the defined goals is to help users improve their typing skills beyond just remembering shortcuts. It is of similar importance to be able to type them fast and accurately. To help identify weaknesses and bad habits, KeyCombiner gathers detailed statistics during practice.</p>
<p>The below figure shows an example bar chart for one of my early practice runs.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/test-run-stats.png" alt="Interactive charts show which combinations need some further practice."> <figcaption>
<p>Interactive charts show which combinations need some further practice.</p>
</figcaption>
</figure>
<p>It is immediately obvious that I had problems typing <kbd>Shift</kbd>+<kbd>a</kbd>, <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>m</kbd> and <kbd>Ctrl</kbd>+<kbd>Shift</kbd> + <kbd>c</kbd>. Using such statistics, I actually found that I was occasionaly making mistakes with some of the most essential shortcuts: <kbd>Ctrl</kbd>+<kbd>x</kbd>/<kbd>c</kbd>/<kbd>v</kbd>. This was because I used my pointer finger for each of them. After realizing that this was a problem, I started to use the middle finger for <kbd>Ctrl</kbd>+<kbd>x</kbd> and am no longer making mistakes.</p>
<p>When taking the average time into account, there are many more observations to make. If you find out which combinations are the fastest to type for you, you can use this knowledge and set such convenient combinations wherever possible.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/analytics.gif" alt="KeyCombiner presents statistics per practice run and per key combination."> <figcaption>
<p>KeyCombiner presents statistics per practice run and per key combination.</p>
</figcaption>
</figure>

<p>The most pressing issue right now is user onboarding. Unfortunately, many people sign up and then never create any meaningful …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/">https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/</a></em></p>]]>
            </description>
            <link>https://tkainrad.dev/posts/why-i-built-a-new-app-for-practicing-keyboard-shortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842339</guid>
            <pubDate>Wed, 15 Jul 2020 07:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing 2nd Generation IPU Systems for AI at Scale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842281">thread link</a>) | @ingve
<br/>
July 15, 2020 | https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale | <a href="https://web.archive.org/web/*/https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				
				

				<div>
					
					<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>I am delighted to introduce our second-generation IPU platform with greater processing power, more memory and built-in scalability for handling extremely large Machine Intelligence workloads.</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<!--more-->
<p><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}"><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>The IPU-Machine M2000 is a plug-and-play Machine Intelligence compute blade that has been designed for easy deployment and supports systems that can grow to massive scale. The slim 1U blade delivers one<span>&nbsp;</span></span><span>PetaFlop</span><span><span>&nbsp;</span>of Machine Intelligence compute and includes integrated networking technology, optimized for AI scale-out, inside the box.</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></span></p>
<div>
<p><iframe xml="lang" src="//www.youtube.com/embed/_zvU0uwIafQ" width="560" height="315" allowfullscreen="" data-service="youtube"></iframe></p>
</div>

<p><span data-contrast="auto">Each IPU-Machine M2000 is powered by four of our brand new 7nm Colossus™ Mk2 GC200 IPU processors, and is fully supported by our Poplar® software stack.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Users of our Mk1 IPU products can be assured that their existing models and systems will run seamlessly on these new Mk2 IPU systems but will deliver an incredible 8X step up in performance when compared to our already&nbsp;class-leading&nbsp;first-generation&nbsp;Graphcore&nbsp;IPU products.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=601&amp;name=Colossus%20MK2%20Performance%20Comparison.png" alt="Colossus MK2 Performance Comparison" width="601" srcset="https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=301&amp;name=Colossus%20MK2%20Performance%20Comparison.png 301w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=601&amp;name=Colossus%20MK2%20Performance%20Comparison.png 601w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=902&amp;name=Colossus%20MK2%20Performance%20Comparison.png 902w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=1202&amp;name=Colossus%20MK2%20Performance%20Comparison.png 1202w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=1503&amp;name=Colossus%20MK2%20Performance%20Comparison.png 1503w, https://www.graphcore.ai/hs-fs/hubfs/Colossus%20MK2%20Performance%20Comparison.png?width=1803&amp;name=Colossus%20MK2%20Performance%20Comparison.png 1803w" sizes="(max-width: 601px) 100vw, 601px"></p>
<p><span data-contrast="auto">The design of our IPU-Machine M2000 allows customers to build datacenter-scale systems of up to 64,000 IPUs, in IPU-POD™ configuration, that deliver 16 ExaFlops of Machine Intelligence compute. Our new IPU-Machine M2000 is capable of handling even the toughest Machine Intelligence training or large-scale deployment workloads.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">You can get started with a single IPU-Machine M2000 box, directly connected to one of your existing CPU-servers, or&nbsp;add up to a total of eight IPU-Machine M2000s connected to this one server. For larger systems, you can use our rack-scale IPU-POD</span><sub><span data-contrast="auto">64</span></sub><span data-contrast="auto">, comprising 16 IPU-Machine M2000s built into a standard 19-inch rack and scale these racks out to deliver&nbsp;datacenter-scale Machine Intelligence compute.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=601&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg" alt="IPU Machine for machine intelligence compute" width="601" srcset="https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=301&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 301w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=601&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 601w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=902&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 902w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=1202&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 1202w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=1503&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 1503w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Machine%20for%20machine%20intelligence%20compute.jpg?width=1803&amp;name=IPU%20Machine%20for%20machine%20intelligence%20compute.jpg 1803w" sizes="(max-width: 601px) 100vw, 601px"></p>
<p><span data-contrast="auto">Connecting IPU-Machine M2000s and IPU-PODs at scale is made possible by our new IPU-Fabric™ technology, which has been designed from the ground-up for Machine Intelligence communication and delivers a dedicated low latency fabric that connects IPUs across the entire&nbsp;datacenter.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Our Virtual-IPU software integrates with workload management and orchestration software to easily serve many different users for training and&nbsp;inference, and&nbsp;allows the available resources to be adapted and reconfigured from job to job.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Whether you are using a single IPU or thousands for your Machine Intelligence workload,&nbsp;Graphcore’s&nbsp;Poplar SDK makes this simple. You can use your preferred AI framework, such as TensorFlow or&nbsp;PyTorch, and from this high-level description, Poplar will build the complete compute graph, capturing the computation, the data and the communication. It then compiles this compute graph and builds the runtime programs that manage the compute, the memory management and the networking communication, to take full advantage of the available IPU hardware.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">If you’re looking to add Machine Intelligence compute into your&nbsp;datacenter, there’s nothing more powerful, flexible or easier to use than a&nbsp;Graphcore&nbsp;IPU-Machine M2000.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Innovation and advantage</strong></p>
<p><span data-contrast="auto">Graphcore&nbsp;customers span automotive, consumer internet, finance, healthcare, research and more.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">The number of corporations, organisations and research institutions using Graphcore systems is growing rapidly and includes Microsoft, Oxford Nanopore, EspresoMedia, the University of Oxford, Citadel and Qwant.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Graphcore’s technology is also being evaluated by J.P. Morgan to see if its solutions can accelerate the bank’s advances in AI, specifically in Natural Language Processing and speech recognition.</span></p>
<p><span data-contrast="auto">With the launch of the IPU-Machine M2000 and IPU POD</span><span data-contrast="auto">64</span><span data-contrast="auto">, the competitive advantage that we are able offer is extended even further.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Graphcore’s&nbsp;latest product line is made possible by a range of ambitious technological innovations across compute, data, and communication, that deliver the industry-leading performance customers expect.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Compute</strong></p>
<p><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>At the heart of every IPU-Machine M2000 is our new<span>&nbsp;</span></span><span>Graphcore</span><span><span>&nbsp;</span>Colossus™ Mk2 GC200 IPU. Developed using TSMC’s latest 7nm process technology, each chip contains more than 59.4 billion transistors on a single 823sqmm die, making it the most complex processor ever made.</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=600&amp;name=GC200%20image.jpg" alt="GC200 image" width="600" srcset="https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=300&amp;name=GC200%20image.jpg 300w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=600&amp;name=GC200%20image.jpg 600w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=900&amp;name=GC200%20image.jpg 900w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=1200&amp;name=GC200%20image.jpg 1200w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=1500&amp;name=GC200%20image.jpg 1500w, https://www.graphcore.ai/hs-fs/hubfs/GC200%20image.jpg?width=1800&amp;name=GC200%20image.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></p>
<p><span data-contrast="auto">GC200 integrates 1,472 separate IPU-Cores, and&nbsp;is capable of executing&nbsp;8,832 separate parallel computing threads. Each IPU processor core gets a performance boost from a set of novel floating-point technologies developed by&nbsp;Graphcore, called&nbsp;</span><strong><span data-contrast="auto">AI-Float.&nbsp;</span></strong><span data-contrast="auto">By tuning arithmetic implementations for energy and performance in Machine Intelligence computation, we&nbsp;are able to&nbsp;serve up one&nbsp;PetaFlop&nbsp;of AI compute in each IPU-Machine M2000 1U blade.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">With class leading support for FP32 IEEE floating point arithmetic we also support FP16.32 (16bit multiply with 32bit accumulate) and FP16.16 (16bit multiply accumulate). However, our Colossus IPUs are unique in having support for Stochastic Rounding on the arithmetic that is supported in hardware and runs at the full speed of the processor. This allows the Colossus Mk2 IPU to keep all arithmetic in 16bit formats, reducing memory requirements, saving on read and write energy and reducing energy in the arithmetic logic, while delivering full accuracy Machine Intelligence results. Each of the 1,472 processor cores and each of the 8,832 parallel program threads can generate a separate random number seed with shaped noise, allowing a unique compute capability to support, for example, Probabilistic or Evolution Strategy models. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">The AI-Float arithmetic block also provides native support for sparse arithmetic floating-point operations. We provide library support for different sparse operations including block sparsity and dynamic sparsity. This means that the IPU delivers much more efficient compute on sparse data, not just in inference, but also during training, helping innovators to create new types of complex models that deliver state of the art performance with much fewer parameters, faster training times and using much less energy.&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Data</strong></p>
<p><span data-contrast="auto">Our IPUs working together with Poplar, also have a radical new approach to memory organisation. Firstly, each IPU has a huge amount of In-Processor Memory™ with our new Mk2 GC200 having an unprecedented 900MB ultra-high-speed SRAM inside the processor. This is spread across the IPU, with In-Processor Memory sitting right next to each processor core in an IPU-Tile™ for the lowest energy access per bit. 900 MB is a 3x step up in density when compared to our Mk1 IPU and is enough to hold massive models, prior state, or many layers of even the world’s largest models inside the chip running at the full speed of the processor. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Our Poplar software also allows IPUs to access Streaming Memory™&nbsp; through&nbsp;our unique&nbsp;</span><strong><span data-contrast="auto">Exchange-Memory™</span></strong><span data-contrast="auto"> communication. This allows large models with 100’s Billions of parameters to be supported. Each IPU-Machine M2000 can support Exchange-Memory™ with up to 450GB in density and with an unprecedented bandwidth of 180TBytes/sec. As a result, the IPU Exchange-Memory delivers over a 10x advantage in density together with over a 100x advantage in memory bandwidth when compared to the very latest 7nm GPU products. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Overall, the combination of the unique way that the IPU accesses memory, the class-leading In-Processor Memory design and Exchange Memory features, together with native support for sparsity, enable developers to execute machine learning models at very high speed, no matter how large or how complex. </span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Communication</strong></p>
<p><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>Unlike other solutions, you don’t need to add expensive InfiniBand networking cards to connect the IPU-Machines; each IPU-M2000 has dedicated AI networking built in. We call this<span>&nbsp;</span></span></span><strong><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>IPU-Fabric</span></span></strong><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span><strong>™</strong>.</span></span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=601&amp;name=Fabric%20map.jpg" alt="Fabric map" width="601" srcset="https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=301&amp;name=Fabric%20map.jpg 301w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=601&amp;name=Fabric%20map.jpg 601w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=902&amp;name=Fabric%20map.jpg 902w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=1202&amp;name=Fabric%20map.jpg 1202w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=1503&amp;name=Fabric%20map.jpg 1503w, https://www.graphcore.ai/hs-fs/hubfs/Fabric%20map.jpg?width=1803&amp;name=Fabric%20map.jpg 1803w" sizes="(max-width: 601px) 100vw, 601px"></p>
<p><span data-contrast="auto">We created a new Graphcore GC4000 IPU-Gateway chip that delivers incredibly low latency and high bandwidth, for each IPU-Machine M2000 delivering 2.8 Tbps bandwidth. As you connect more IPU-Machine M2000 systems together, the overall bandwidth grows to many Petabits/sec.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">And while IPU-Fabric has been built from the ground-up to maximise performance in IPU-based systems, it is also designed for maximum compatibility with existing datacenter infrastructure.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">IPU-Fabric uses standard copper or optical OSFP connectors, linking IPUs up and down the rack. In larger configurations, communication between IPU-PODs uses tunneling-over-Ethernet technology to maintain throughput, while allowing the use of standard QSFP interconnect and 100Gb Ethernet switches – underscoring Graphcore’s commitment to straightforward deployment in mixed-use datacenters.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Across the entire system, IPU-Fabric uses a 3D ring topology, chosen both for maximum efficiency and because it maps well to the three dimensions of parallelism found in Machine Intelligence compute.</span></p>
<p><img src="https://play.vidyard.com/N2ErtY89YFKYapUroqdQqZ.jpg" width="1920" height="1080" alt="3D ring topology animation" data-uuid="N2ErtY89YFKYapUroqdQqZ" data-v="4" data-width="1920" data-height="1080" data-viral_sharing="0" data-embed_button="0" data-hide_playlist="1" data-color="FFFFFF" data-playlist_color="FFFFFF" data-play_button_color="2A2A2A" data-gdpr_enabled="0" data-type="inline" data-new_player_ui="1" data-autoplay="0" data-loop="0" data-muted="0" data-hidden_controls="0">

</p>


<p><span data-contrast="auto">IPU-Fabric is fully supported by our Poplar SDK. As you extend your datacenter setup through the addition of extra IPU-PODs our Virtual-IPU software is used to tell Poplar how many machines are present for each workload and all subsequent adjustments to compile and other processes are taken care of by Poplar.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">The incredible IPU-Fabric technology keeps communication latency close to constant while scaling from 10s of IPUs to 10s of thousands of IPUs.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><img src="https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=601&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg" alt="IPU Servers and Machine Images" width="601" srcset="https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=301&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 301w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=601&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 601w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=902&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 902w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=1202&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 1202w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=1503&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 1503w, https://www.graphcore.ai/hs-fs/hubfs/IPU%20Servers%20and%20Machine%20Images.jpg?width=1803&amp;name=IPU%20Servers%20and%20Machine%20Images.jpg 1803w" sizes="(max-width: 601px) 100vw, 601px"></p>
<p><span data-contrast="auto" xml:lang="EN-GB" lang="EN-GB"><span>The IPU-Machine M2000 also enables a flexible disaggregated model, where users are not confined to a fixed ratio of CPU to Machine Intelligence compute at a server level. Rather,<span>&nbsp;</span></span><span>Graphcore</span><span><span>&nbsp;</span>customers can choose their preferred mix of CPUs and IPUs, connected via Ethernet switches. You can easily change this ratio from one workload to the next. For example, NLP has relatively low CPU host processing requirements whereas image classification may require a higher ratio of servers to support more pre-processing of the data. The IPU-Machine M2000 allows these ratios to be changed and will support new applications as they emerge.&nbsp;</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><strong>Virtual-IPU™ and workload management</strong></p>
<p><span data-contrast="auto">Graphcore’s&nbsp;</span><strong><span data-contrast="auto">Virtual-IPU™&nbsp;</span></strong><span data-contrast="auto">Technology allows users to dynamically provision which IPUs they want to associate with specific hosts, and to assign workloads even down to individual IPU level.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>
<p><span data-contrast="auto">Virtual-IPU also supports multi-tenancy …</span></p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale">https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale</a></em></p>]]>
            </description>
            <link>https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842281</guid>
            <pubDate>Wed, 15 Jul 2020 07:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Website Is Killing the Planet]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23842225">thread link</a>) | @brokebroadbeat
<br/>
July 15, 2020 | https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/ | <a href="https://web.archive.org/web/*/https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For a while I’ve been intending to make my website more sustainable, but I succumbed, as I often do, to the human trait of sloth. But this morning after reading <a href="https://alistapart.com/article/webwaste/">Gerry McGovern’s post on webwaste</a>, I thought I’d procrastinated long enough.</p>

<p>So I ran a web page performance test and got some <a href="https://www.webpagetest.org/result/200713_XX_e2daed33a24cd8a099d930fc373b1083/">grim results</a>: my website takes over a minute to load on a Moto G4 on using 3G data networks. It’s just as bad <a href="https://www.webpagetest.org/result/200713_6E_4e249b485a45882604420068caa21ae0/">using a desktop PC in Nottingham on 1.5Mbps DSL</a>. My website is bloated with large images and a bunch of JavaScript, which means it’s eating up lots of energy transmitting those bits and bytes.</p>

<p>But how much energy? I used the <a href="https://www.websitecarbon.com/">Website Carbon Calculator</a> to find out. Turns out that</p>

<ul>
  <li>6.90g of CO2 is produced every time someone visits the homepage</li>
  <li>it emits the amount of carbon that 4 trees absorb in a year, and</li>
  <li>it uses enough electricity to drive an electric car 1,116km</li>
</ul>

<p>Eugh. That’s disgusting. For each year my website has been online, I should have planted 4 trees just for the homepage alone. But, instead, my laziness has filled the atmosphere with more and more carbon.</p>

<p>I have to do something, this has gone on long enough, so I’m committing to some actions.</p>

<ol>
  <li>I’ll move my site to a web hosting provider using renewable energy, one that’s listed on the <a href="https://www.thegreenwebfoundation.org/directory/">Green Web Foundation’s directory</a>. <strong>DONE</strong></li>
  <li>I’ll compress and optimise the images on my site using <a href="https://imageoptim.com/mac">ImageOptim</a>. <strong>DONE</strong></li>
  <li>I’ll get rid of <a href="https://github.com/samesies/barber-jekyll">my energy-guzzling site theme</a> until I can introduce one that’s lightweight and accessible. <strong>DONE</strong></li>
  <li>Going forward, my website will enshrine the principles of the <a href="https://www.sustainablewebmanifesto.com/">Sustainable Web Manifesto</a>. <strong>SIGNED</strong></li>
  <li><strong>NEW</strong>: I’ll pay for some trees to be planted that’ll reduce the impact of my website’s carbon footprint going forward.</li>
</ol>

<p>To show my committment to being a good web citizen, I’ll add the <a href="https://www.websitecarbon.com/badge/">Website Carbon Badge</a> to all pages (<strong>DONE</strong>) and the <a href="https://www.thegreenwebfoundation.org/green-web-check/">Green Web Foundation’s renewable hosting badge</a> (<strong>DONE</strong>). Once I’ve improved things, I’ll add a <a href="https://carbontxt.org/">carbon.txt</a> (<strong>DONE</strong>).</p>

<p>One day I’ll actually get around to building a solar-powered battery bank and run my site off my home connection, but until then I’m taking small steps to remove, minimise and clean-up my presence on the web.</p>

<p>What’s the carbon footprint of your website? What steps will you take to reduce it?</p>

<h2 id="further-reading">Further reading</h2>

<ul>
  <li><a href="https://alistapart.com/article/webwaste/">Webwaste</a></li>
  <li><a href="https://pxlnv.com/blog/bullshit-web/">The bullshit web</a></li>
  <li><a href="https://www.wholegraindigital.com/blog/sustainable-web-design/">3 steps to creating zero carbon websites</a></li>
  <li><a href="https://solar.lowtechmagazine.com/2018/09/how-to-build-a-lowtech-website.html">How to build a low-tech website</a></li>
  <li><a href="https://www.thegreenwebfoundation.org/news/notes-for-greening-internet-governance-at-eurodig/">Greening Internet governance: environmental sustainability and digital transformation</a></li>
</ul>

  </div>
</article>



      </div>
    </div></div>]]>
            </description>
            <link>https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842225</guid>
            <pubDate>Wed, 15 Jul 2020 07:15:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Shouldn’t Use LinkedIn Automation Tools Using Your Own Account]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842205">thread link</a>) | @ferlita
<br/>
July 15, 2020 | https://nubela.co/blog/why-you-shouldnt-use-linkedin-automation-tools-using-your-own-account/ | <a href="https://web.archive.org/web/*/https://nubela.co/blog/why-you-shouldnt-use-linkedin-automation-tools-using-your-own-account/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://nubela.co/blog/content/images/size/w300/2020/07/christopher-gower-m_HRfLhgABo-unsplash.jpg 300w,
                            https://nubela.co/blog/content/images/size/w600/2020/07/christopher-gower-m_HRfLhgABo-unsplash.jpg 600w,
                            https://nubela.co/blog/content/images/size/w1000/2020/07/christopher-gower-m_HRfLhgABo-unsplash.jpg 1000w,
                            https://nubela.co/blog/content/images/size/w2000/2020/07/christopher-gower-m_HRfLhgABo-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://nubela.co/blog/content/images/size/w2000/2020/07/christopher-gower-m_HRfLhgABo-unsplash.jpg" alt="Why You Shouldn’t Use LinkedIn Automation Tools using YOUR OWN Account">
</figure>
<section>
<div>
<blockquote>Automation, especially in digital marketing, has become an important progress feature. It can greatly reduce the time spent on menial work so that you can spend more time doing the things you'd rather be doing and just pass the simple work to the bot. Most of the time, these trade-offs are business-critical functions.</blockquote><p>It might be tempting to start automating such tasks to boost your company's productivity and efficiency. The demand in such a service is so great that it has led to companies scrambling to obtain them. Along with the rise in demand also comes a rise in supply. A lot of tools that offer this functionality exist today in the market, including but not limited to software programs, bots and browser plug-ins and extensions.</p><p>However, there are some caveats to using such tools on LinkedIn.</p><h3 id="1-using-such-tools-can-get-you-banned">1. Using such tools can get you banned</h3><p>Although scraping LinkedIn is considered legal after HiQ winning the case of legal action taken against web scrapers (read our article, <a href="https://nubela.co/blog/is-linkedin-scraping-legal/">Is LinkedIn Scraping Legal</a>, for more details), LinkedIn policies for LinkedIn users include some restrictions and limited access to LinkedIn data that make automation hard to do. One of them is as stated <a href="https://www.linkedin.com/help/linkedin/answer/82934/account-content-restricted-or-removed?lang=en">in LinkedIn website</a>, <em>an unusually large number of page views from the account</em> can get your account restricted or even removed.</p><p><a href="https://www.linkedin.com/help/linkedin/answer/56347/prohibited-software-and-extensions?lang=en">LinkedIn website</a> also state that it is prohibited to <em>develop, support or use the software, devices, scripts, robots, or any other means or processes (including crawlers, browser plugins, and add-ons, or any other technology) to scrape the Services or otherwise copy profiles and other data from the Services</em> and <em>use bots or other automated methods to access the Services, add or download contacts, send or redirect messages</em>. These actions can violate the User Agreement and risk your account from being restricted or shut down.</p><p>Although using automation tools can help you scrape LinkedIn and manage your account, it may not be a good idea to risk your account which may result in losing all your connections and lead customers. Thus, the risk of utilizing LinkedIn automation tools to your LinkedIn account may outweigh the rewards.</p><h3 id="2-the-human-connection-is-lost">2. The human connection is lost</h3><p>One problem with the idea of automation is that believing everything can be automated. This is not true, especially with a process that involves a more human touch, like making connections on LinkedIn. That first message that goes along with the connection request can be the 'make or break' moment for most companies. An automated message can stick out like a sore thumb most of the time, and this can put off a lot of people.</p><p>Most users want to create genuine connections on LinkedIn. One should realize that each connection made requires its own personal approach that cannot be imitated using a mechanical process. Thus, the idea of generating more leads by sending out bulk requests with an automated message is not the best utilization of these tools.</p><h3 id="our-solution">Our solution</h3><p>Now we're not saying that automation on LinkedIn is absolutely bad and you should steer far away from it. On the contrary, we should embrace the wonders of automation and reap the benefits it can bring, but not use it blindly. It all comes down to using it where appropriate and avoiding the common pitfalls that come along with it.</p><p>This is why we suggest narrowing your usage of automation tools to handle tasks doesn't require much complex thinking and doesn't involve social and emotional intelligence. An example would be filtering through hundreds of profiles to find the right fit. But even so, this seemingly simple task can be proven difficult given the factors mentioned above. After all, the tool would need to do at least these 3 things: evade rate limiters, bypass CAPTCHA, and mimic a browser to render JavaScript.</p><p><strong>Fortunately, such a tool is available: Proxycurl, a LinkedIn data scraper that helps to crawl LinkedIn profiles.</strong> Different from others, Proxycurl does not use your LinkedIn account and has no maximum rate limit, so it's safe. You can then sift through the profiles you have scraped in an automated manner to find the ones of most interest to your professional needs without endangering your own account. You can learn more about it <a href="https://nubela.co/proxycurl">here, in Proxycurl's website</a>. Please also read our <a href="https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/">Proxycurl's LinkedIn API tutorial article</a> to understand better how to use it.</p>
</div>
</section>

</article>
</div>
</div></div>]]>
            </description>
            <link>https://nubela.co/blog/why-you-shouldnt-use-linkedin-automation-tools-using-your-own-account/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842205</guid>
            <pubDate>Wed, 15 Jul 2020 07:12:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snorkel AI: Putting Data First in ML Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23842195">thread link</a>) | @dsr12
<br/>
July 15, 2020 | https://www.snorkel.ai/07-14-2020-snorkel-ai-launch | <a href="https://web.archive.org/web/*/https://www.snorkel.ai/07-14-2020-snorkel-ai-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>
                      Today I’m excited to announce Snorkel AI’s launch out of stealth!
                      Snorkel AI, which spun out of the Stanford AI Lab in 2019, was founded on two simple premises: first, that the labeled <b>training data</b>  machine learning models learn from is increasingly what determines the success or failure of AI applications.
                      And second, that we can do much better than labeling this data entirely by hand.
                  </p>
                  <p>
                      At the Stanford AI lab, the Snorkel AI founding team spent over four years developing new <b>programmatic</b> approaches to labeling, augmenting, structuring, and managing this training data.
                      We were fortunate to develop and deploy early versions of our technology with some of the world’s leading organizations like <a href="https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html">Google</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3329486.3329492">Intel</a>, <a href="https://arxiv.org/abs/1909.05372">Apple</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2666389920300192">Stanford Medicine</a>, resulting in <a href="https://www.snorkel.ai/technology#reference">over thirty-six peer-reviewed publications</a> on our findings; innovations in weak supervision modeling, data augmentation, multi-task learning, and more; inclusion in university computer science curriculums; and deployments in popular products and systems that you’ve likely interacted with in the last few hours.
                  </p>
                  <p>
                      Through all this academic tinkering and industry spelunking, we realized two things: first, that this concept of labeling and building training data programmatically, rather than by hand, had transformational potential to make machine learning more iterative, auditable, faster to deploy, and ultimately, more practical.
                      And second, that these ideas changed not just how you label training data, but so much of the entire lifecycle and pipeline of ML: how knowledge and feedback is injected; how models are constructed, trained, versioned, and monitored; how entire pipelines are developed iteratively; and how the full set of stakeholders in any ML deployment, from subject matter experts to ML engineers, are incorporated into the process.
                  </p>
                  <p>
                      In other words, we saw that this shift to programmatic training data required a top-to-bottom rewrite of the entire ML development and deployment process.
                      With the support of some amazing investors (Greylock, GV, In-Q-Tel, and others) and incredible early customers, we’ve spent the last year doing just this: building and deploying <a href="https://www.snorkel.ai/platform">Snorkel Flow</a>, an end-to-end platform to support this new vision of the ML process.
                  </p>
                  <h2>The Training Data Bottleneck</h2>
                  <p>
                      Snorkel Flow was motivated first and foremost by a growing realization that training data had become the key bottleneck in much of ML pipeline and AI application development.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png"></p><p>
                      <b>Today’s ML successes often rest on a hidden cost: massive, hand-labeled training datasets.</b>
                      In the last decade, we’ve seen a tectonic shift in AI and ML towards powerful but data-hungry representation learning models.
                      These models—often deep learning architectures—are not only more powerful at obviating traditionally manual development tasks like feature engineering and bespoke model design, but also have never been more accessible in the open source.
                      However, there’s no such thing as a free lunch: these models are highly complex, with tens to hundreds of millions of parameters, and they require massive labeled training datasets to learn from.
                      And, other than in special scenarios where labels are naturally derivative of existing processes, these training datasets need to be labeled by hand.
                  </p>
                  <p>
                      <b>The hand-labeled training data interface to ML has enabled tremendous progress, but is also ridiculously broken.</b>
                      Consider a simple example: a legal analyst at a bank wants to train a contract classification model, and wants to inject a simple heuristic into the ML model: that if “employment” is in the title, the contract should be labeled as an “Employment contract.”
                      Simple, right?
                      Not so.
                      Theoretically, to communicate this specific feature to a machine learning model via only labeling individual data points could require thousands of examples (roughly, inversely proportional to the sparsity of the feature space).
                      From this perspective, it’s like playing 20 questions rather than just communicating the answer directly—fine if you have a massive question-answer bank, but otherwise wholly impractical.
                  </p>
                  <p>
                      <b>Manually labeling training data is prohibitively expensive–especially when expertise and privacy are required.</b>
                      Building training datasets often requires <a href="http://nytimes.com/2018/11/25/business/china-artificial-intelligence-labeling.html">armies of human labelers</a> at massive cost and time expense.
                      For example, ImageNet—one of the foundational projects behind ML’s current explosive progress—took <a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/">over two years</a> to create.
                      However, labeling cats, dogs, stop signs, and pedestrians is one thing; labeling data like medical images, legal and financial contracts, government documents, user data, and network data requires <b>stringent privacy protections</b> and <b>subject matter expert labelers</b>.
                      This means for sectors like financial services, government, telecommunications, insurance, healthcare, and more, creating training data (and by extension, using ML) is either a hugely expensive on-premise activity—or more often, one that is just not feasible to tackle, let alone practical.
                  </p>
                  <p>
                      <b>Iterative development is not possible with hand-labeled data.</b>
                      From an engineering and data science perspective, manually labeled training data fundamentally breaks the ability to quickly iterate, which is absolutely essential in real world settings where input data, output goals, and annotation schema change all the time.
                      From a business perspective, training data is an expensive asset that can’t be reused across projects, can often depreciate to worthless overnight due to changing conditions or business goals, and that presents growing risks—everything from <a href="https://web.archive.org/web/20200703104247/https://cloud.google.com/ai-platform/data-labeling/docs">COVID-related delays</a> to <a href="https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai">issues of bias</a>.
                  </p>
                  <h2>A New Input Paradigm for ML: Programming with Data</h2>
                  <p>
                      With Snorkel Flow, rather than needing to hand-label any training data, users develop <b>programmatic operators</b> that label, augment, and build training data to drive the ML development process.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png"></p><p>
                      <b>Programmatically labeling and building training data.</b>
                      With Snorkel Flow, the idea is to instead communicate this domain knowledge directly via a programmatic operator like a <a href="https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly">labeling function</a>.
                      For example, our legal analyst could write a labeling function that labels documents as “Employment contracts” if the word “employment” is in the title, and otherwise abstains; or, a range of more complex and powerful labeling functions relying on internal knowlegebases, models, legacy heuristics, and more.
                      This approach of effectively programming ML with data is simple, direct, interpretable, modifiable, and agnostic to the model used (which is especially important given the ongoing Cambrian explosion of powerful new open source model architectures).
                  </p>
                  <p>
                      <b>The directness of rules with the flexibility of ML.</b>
                      Rule-based systems have long been used in industry for certain tasks—as an input, individual rules have the desirable property of being direct and interpretable.
                      However, rules can also be brittle, and lack the robustness, flexibility, and sheer power of ML approaches.
                      With Snorkel Flow, you get the best of both worlds: rules (and other interpretable resources) as inputs, and powerful ML models that generalize beyond these rules as the output.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png"></p><p>
                      <b>A more powerful yet weaker supervision.</b>
                      At the same time that this programmatic supervision is advantageous in several transformational ways, it is also messier and raises fundamental new technical challenges.
                      The labeling functions and other programmatic operators that users write will have varying unknown accuracies and expertise areas, will overlap and disagree with each other, and may be correlated in tangled and unknown ways.
                      We focused on the algorithmic and systems solutions to these issues over <a href="https://www.snorkel.ai/technology">four-plus years of research</a>, showing both empirically and theoretically that with the right techniques, these deep technical challenges can be overcome.
                      The result: training data that is as good as or better than hand-labeled data, and immensely more practical to create and maintain.
                  </p>
                  <p>
                      <b>Beyond labeling: data augmentation, slicing, monitoring, and more.</b>
                      In high-performance production ML, training data is about a lot more than labeling.
                      For example, data augmentation is a cornerstone technique wherein transformed copies of data (e.g. rotated or blurred images) are used to expand the sizes of training datasets, and make resulting models more robust.
                      Slicing or structuring training datasets into more or less important and difficult subsets is also a critical part of managing production ML. 
                      Finally, monitoring and adapting not just models but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snorkel.ai/07-14-2020-snorkel-ai-launch">https://www.snorkel.ai/07-14-2020-snorkel-ai-launch</a></em></p>]]>
            </description>
            <link>https://www.snorkel.ai/07-14-2020-snorkel-ai-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842195</guid>
            <pubDate>Wed, 15 Jul 2020 07:10:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Riot is now Element]]>
            </title>
            <description>
<![CDATA[
Score 413 | Comments 254 (<a href="https://news.ycombinator.com/item?id=23842179">thread link</a>) | @J_tt
<br/>
July 15, 2020 | https://element.io/blog/welcome-to-element/ | <a href="https://web.archive.org/web/*/https://element.io/blog/welcome-to-element/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi everyone,</p><p>We are incredibly excited to announce that <strong>Riot is now Element</strong>! </p><p>In fact we have simplified all our naming: Element is also the name for New Vector (the company behind Riot) while Modular, our flagship Matrix hosting service, has become Element Matrix Services.</p><p>For those discovering us for the first time: Element is the flagship secure collaboration app for the decentralised <a href="https://matrix.org/">Matrix</a> communication network. &nbsp;Element lets you own your own end-to-end encrypted chat server, while still connecting to everyone else in the wider Matrix network.</p><figure><img src="https://element.io/blog/content/images/2020/07/element-logo.png"></figure><p><br>What’s more, <strong>RiotX is now out of beta</strong> - our next generation Matrix client for Android has flown the nest and spread its wings as Element - replacing the old Riot Android app at last!</p><p>This name change has been a long time in the making. As we explained when we announced the rebrand <a href="https://blog.riot.im/the-world-is-changing/">a few weeks ago</a>, we’ve had major issues with a certain gigantic games company which has blocked us from being able to trademark Riot or even Riot.im - a huge issue when it comes to defending users against abusive forks of the app. Secondly, people incorrectly assume Riot refers to violence, rather than the more constructive forms of chaos we had in mind. Lastly, it made sense in the early days of Matrix to have different brands to illustrate the different roles of Riot, Modular and New Vector in the ecosystem… but nowadays there are loads of Matrix clients, Matrix hosting providers and companies building on Matrix - and so all New Vector’s different names were just causing confusion. &nbsp;</p><h3 id="so-why-element">So, why Element?</h3><p>We want a name that reflects the emphasis on simplicity and clarity that we aimed for when designing RiotX; a name that highlights our single-minded mission to make Element the most elegant and usable mainstream comms app imaginable. &nbsp;Riot had a pretty chequered history, spending much of its life in beta, with intermittent attention to design until we hit 1.0 last year - but nowadays we have a dedicated full-time design team working on Element, who not only design the graphics but the overall behaviour of new features in the app. &nbsp;This is not an easy task, given it turns out the hardest bits of end-to-end encryption are almost entirely UX challenges. &nbsp;What’s more, presenting a global decentralised communication network as simply as a centralised communication island is surprisingly tricky. &nbsp;However: we have been making massive progress, to the extent that we are barely recognisable as the Riot of the past. Element reflects a clean start to focus monomaniacally on mainstream usability in future.</p><p>We also want a name that better evokes the idea of data ownership and self-sovereignty. &nbsp;An element is the smallest indivisible thing in a system - yet one which can stand alone. &nbsp;You can customise it, control it and make it your own - you can literally be in your Element!</p><p>Moreover, we want a name that will be future-proof for peer-to-peer Matrix. &nbsp;As Matrix.org announced last month, <a href="https://matrix.org/blog/2020/06/02/introducing-p-2-p-matrix">P2P Matrix is in heavy development</a> - and we can see a world where Element will literally be an element of Matrix, running your own homeserver within the app, so you can communicate if you don’t have a server… or even Internet. In fact, we published the first experimental build of <a href="https://matrix.org/blog/2020/07/10/this-week-in-matrix-2020-07-10#riot-ios-p2p-demo">P2P Riot for iOS</a> on Testflight a few days ago - so we can clearly see a future where we will be in our P2P element!</p><p>Finally, we think it’s a cool name :D &nbsp;It fits in nicely with the term Matrix while not being as nerdy as Vector. &nbsp;We’re obviously aware that Element is (once again) both a dictionary word and a mathematical term - but in practice, looking at search results for Element right now, the top hits are for dictionary sites(!) and the field is wide open. &nbsp;Conversely, in a virgin browser on VPN, Riot is the 4th hit on Google for Riot; second only to a certain games company. &nbsp;In other words, we’ve shown that we can successfully adopt dictionary words - and if you do find yourself lost searching in a maze of mathematics, just throw in the word ‘chat’ to get back on track. &nbsp;(For all the linear algebraists who are spitting with rage at this point: we promise we’ll make it up to you by finally sorting out <a href="https://github.com/matrix-org/matrix-react-sdk/pull/3251">latex support</a> in Element!)</p><p>This change is inevitably going to be disruptive, and we’re painfully aware that we’ve spent four years building up Riot’s reputation and persuading everyone to move their friends, families and teams onto it. &nbsp;To reiterate what we said when we announced the change, we know that many people reading this will have put their necks on the line to get folks to adopt Riot, and we really appreciate how frustrating it may be to have to explain the change to your users. &nbsp;However, this is unquestionably the right time to shed our skin and make the change, and we hope folks will grow to love Element much more than they ever did Riot. &nbsp;To aid the transition, we’ve named the installable apps “Element (Riot.im)” for a while to help people get reoriented (e.g. when searching by name for Riot).</p><p>Last but not least: Element isn’t just a new name - it comes with a massive suite of improvements across Android, iOS and Web.</p><p>We’ll write about these in full over the coming days, but the big headlines are that RiotX (our ground-up rewrite of Riot Android) has exited beta, and replaces Riot Android as Element - complete with VoIP calls and Widget support! Riot Android users will magically autoupgrade into Element; the old RiotX app will be retired in due course. FDroid is likely releasing Element as an entirely new app. &nbsp;Meanwhile On iOS we now have full support for iOS 13, complete with entirely new push notification support (thanks to Apple’s nightmarish <a href="https://appleinsider.com/articles/19/09/05/secure-messaging-apps-working-to-comply-with-apples-ios-13-privacy-changes">deprecation of PushKit</a>).</p><figure><img src="https://element.io/blog/content/images/2020/07/RiotX-1.png"><figcaption>The App Formerly Known As RiotX!</figcaption></figure><p>On Element Web, we’ve given the UI a massive refresh, with a beautiful new font (<a href="https://rsms.me/inter/">Inter</a>) giving much improved legibility, and we’ve <strong>completely</strong> rewritten the Room List control - adding in room previews(!!), alphabetic ordering, resizable lists, improved notification UI and more. We’ve also landed the first phase of further improving the end-to-end encryption setup process - letting users generate a recovery key rather than forcing them to select a recovery passphrase when setting up E2EE for the first time (the next phase is to delay setting up E2EE until the user actually starts talking in encrypted rooms).</p><figure><img src="https://element.io/blog/content/images/2020/07/Screenshot-2020-07-15-at-00.54.45.png"></figure><p>So there you have it. Welcome to a whole new beginning for Riot: welcome to your new Element, one where mainstream Matrix users will enjoy themselves too - and which will pave the way for wider adoption of open, secure, decentralised communication via Matrix throughout the world.</p><p>- Matthew, Amandine, and the whole Element team.</p><p>P.S. Check out our <a href="https://element.io/">all-new website</a> and in particular the <a href="https://element.io/previously-riot">migration page</a> for much more information about our brave new world!<br></p></div></div>]]>
            </description>
            <link>https://element.io/blog/welcome-to-element/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842179</guid>
            <pubDate>Wed, 15 Jul 2020 07:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Welcome to Element [Riot chat rebranded as Element]]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23842154">thread link</a>) | @ptman
<br/>
July 15, 2020 | https://element.io/blog/welcome-to-element/ | <a href="https://web.archive.org/web/*/https://element.io/blog/welcome-to-element/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi everyone,</p><p>We are incredibly excited to announce that <strong>Riot is now Element</strong>! </p><p>In fact we have simplified all our naming: Element is also the name for New Vector (the company behind Riot) while Modular, our flagship Matrix hosting service, has become Element Matrix Services.</p><p>For those discovering us for the first time: Element is the flagship secure collaboration app for the decentralised <a href="https://matrix.org/">Matrix</a> communication network. &nbsp;Element lets you own your own end-to-end encrypted chat server, while still connecting to everyone else in the wider Matrix network.</p><figure><img src="https://element.io/blog/content/images/2020/07/element-logo.png"></figure><p><br>What’s more, <strong>RiotX is now out of beta</strong> - our next generation Matrix client for Android has flown the nest and spread its wings as Element - replacing the old Riot Android app at last!</p><p>This name change has been a long time in the making. As we explained when we announced the rebrand <a href="https://blog.riot.im/the-world-is-changing/">a few weeks ago</a>, we’ve had major issues with a certain gigantic games company which has blocked us from being able to trademark Riot or even Riot.im - a huge issue when it comes to defending users against abusive forks of the app. Secondly, people incorrectly assume Riot refers to violence, rather than the more constructive forms of chaos we had in mind. Lastly, it made sense in the early days of Matrix to have different brands to illustrate the different roles of Riot, Modular and New Vector in the ecosystem… but nowadays there are loads of Matrix clients, Matrix hosting providers and companies building on Matrix - and so all New Vector’s different names were just causing confusion. &nbsp;</p><h3 id="so-why-element">So, why Element?</h3><p>We want a name that reflects the emphasis on simplicity and clarity that we aimed for when designing RiotX; a name that highlights our single-minded mission to make Element the most elegant and usable mainstream comms app imaginable. &nbsp;Riot had a pretty chequered history, spending much of its life in beta, with intermittent attention to design until we hit 1.0 last year - but nowadays we have a dedicated full-time design team working on Element, who not only design the graphics but the overall behaviour of new features in the app. &nbsp;This is not an easy task, given it turns out the hardest bits of end-to-end encryption are almost entirely UX challenges. &nbsp;What’s more, presenting a global decentralised communication network as simply as a centralised communication island is surprisingly tricky. &nbsp;However: we have been making massive progress, to the extent that we are barely recognisable as the Riot of the past. Element reflects a clean start to focus monomaniacally on mainstream usability in future.</p><p>We also want a name that better evokes the idea of data ownership and self-sovereignty. &nbsp;An element is the smallest indivisible thing in a system - yet one which can stand alone. &nbsp;You can customise it, control it and make it your own - you can literally be in your Element!</p><p>Moreover, we want a name that will be future-proof for peer-to-peer Matrix. &nbsp;As Matrix.org announced last month, <a href="https://matrix.org/blog/2020/06/02/introducing-p-2-p-matrix">P2P Matrix is in heavy development</a> - and we can see a world where Element will literally be an element of Matrix, running your own homeserver within the app, so you can communicate if you don’t have a server… or even Internet. In fact, we published the first experimental build of <a href="https://matrix.org/blog/2020/07/10/this-week-in-matrix-2020-07-10#riot-ios-p2p-demo">P2P Riot for iOS</a> on Testflight a few days ago - so we can clearly see a future where we will be in our P2P element!</p><p>Finally, we think it’s a cool name :D &nbsp;It fits in nicely with the term Matrix while not being as nerdy as Vector. &nbsp;We’re obviously aware that Element is (once again) both a dictionary word and a mathematical term - but in practice, looking at search results for Element right now, the top hits are for dictionary sites(!) and the field is wide open. &nbsp;Conversely, in a virgin browser on VPN, Riot is the 4th hit on Google for Riot; second only to a certain games company. &nbsp;In other words, we’ve shown that we can successfully adopt dictionary words - and if you do find yourself lost searching in a maze of mathematics, just throw in the word ‘chat’ to get back on track. &nbsp;(For all the linear algebraists who are spitting with rage at this point: we promise we’ll make it up to you by finally sorting out <a href="https://github.com/matrix-org/matrix-react-sdk/pull/3251">latex support</a> in Element!)</p><p>This change is inevitably going to be disruptive, and we’re painfully aware that we’ve spent four years building up Riot’s reputation and persuading everyone to move their friends, families and teams onto it. &nbsp;To reiterate what we said when we announced the change, we know that many people reading this will have put their necks on the line to get folks to adopt Riot, and we really appreciate how frustrating it may be to have to explain the change to your users. &nbsp;However, this is unquestionably the right time to shed our skin and make the change, and we hope folks will grow to love Element much more than they ever did Riot. &nbsp;To aid the transition, we’ve named the installable apps “Element (Riot.im)” for a while to help people get reoriented (e.g. when searching by name for Riot).</p><p>Last but not least: Element isn’t just a new name - it comes with a massive suite of improvements across Android, iOS and Web.</p><p>We’ll write about these in full over the coming days, but the big headlines are that RiotX (our ground-up rewrite of Riot Android) has exited beta, and replaces Riot Android as Element - complete with VoIP calls and Widget support! Riot Android users will magically autoupgrade into Element; the old RiotX app will be retired in due course. FDroid is likely releasing Element as an entirely new app. &nbsp;Meanwhile On iOS we now have full support for iOS 13, complete with entirely new push notification support (thanks to Apple’s nightmarish <a href="https://appleinsider.com/articles/19/09/05/secure-messaging-apps-working-to-comply-with-apples-ios-13-privacy-changes">deprecation of PushKit</a>).</p><figure><img src="https://element.io/blog/content/images/2020/07/RiotX-1.png"><figcaption>The App Formerly Known As RiotX!</figcaption></figure><p>On Element Web, we’ve given the UI a massive refresh, with a beautiful new font (<a href="https://rsms.me/inter/">Inter</a>) giving much improved legibility, and we’ve <strong>completely</strong> rewritten the Room List control - adding in room previews(!!), alphabetic ordering, resizable lists, improved notification UI and more. We’ve also landed the first phase of further improving the end-to-end encryption setup process - letting users generate a recovery key rather than forcing them to select a recovery passphrase when setting up E2EE for the first time (the next phase is to delay setting up E2EE until the user actually starts talking in encrypted rooms).</p><figure><img src="https://element.io/blog/content/images/2020/07/Screenshot-2020-07-15-at-00.54.45.png"></figure><p>So there you have it. Welcome to a whole new beginning for Riot: welcome to your new Element, one where mainstream Matrix users will enjoy themselves too - and which will pave the way for wider adoption of open, secure, decentralised communication via Matrix throughout the world.</p><p>- Matthew, Amandine, and the whole Element team.</p><p>P.S. Check out our <a href="https://element.io/">all-new website</a> and in particular the <a href="https://element.io/previously-riot">migration page</a> for much more information about our brave new world!<br></p></div></div>]]>
            </description>
            <link>https://element.io/blog/welcome-to-element/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842154</guid>
            <pubDate>Wed, 15 Jul 2020 07:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create a sleek UI in Flutter – Wolt app case study]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842062">thread link</a>) | @czajuuu
<br/>
July 14, 2020 | https://www.nomtek.com/blog/sleek-ui-in-flutter-wolt | <a href="https://web.archive.org/web/*/https://www.nomtek.com/blog/sleek-ui-in-flutter-wolt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Flutter is Google’s UI toolkit for building beautiful, natively compiled applications for mobile, web, and desktop from a single codebase</em>. We are going to check its promises by recreating part of an existing application as accurately as possible. I chose the Wolt app because the Wolt team has been doing an amazing job, creating sleek UI &amp; UX with many subtle details.</p><figure id="w-node-ef7dc46c635c-c5de3bde"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/UI9vN8Y583o"></iframe></p></figure><p>‍<br></p><p>My goal for this series is to present a thought process that leads to the desired result rather than provide a copy-paste solution. We will work in a build-refactor cycle, examining potential problems and framework limitations. You may find the whole code for this series on our github: <a href="https://github.com/nomtek/flutter-meets-wolt">https://github.com/nomtek/flutter-meets-wolt</a>.<br>Let’s dive in!<br></p><h2>App bar buttons &amp; menu</h2><p>Let’s warm up with something that seems to be simple - app bar buttons. There are two of them - one is used to navigate back, and the other is showing a menu with two items. My first idea was to use <em>IconButton</em> composed with <em>Container</em> that has circle-shaped decoration:</p><div>
<pre>class AppBarButton extends StatelessWidget {
  final IconData icon;
  final VoidCallback onPressed;
     
     const AppBarButton({Key key, this.icon, this.onPressed}) : super(key: key);

  @override
  Widget build(BuildContext context) {
    return Container(
      decoration: BoxDecoration(shape: BoxShape.circle, color: Colors.grey[300]),
      child: IconButton(
        icon: Icon(icon),
        onPressed: onPressed,
      ),
    );
  }
}
     </pre>
</div><p>When we put those widgets in an AppBar:</p><div>
<pre>SliverAppBar(
  leading: AppBarButton(
    icon: Icons.keyboard_backspace,
    onPressed: () =&gt; Navigator.pop(context),
  ),
  actions: [
    AppBarButton(
      icon: Icons.more_horiz,
      onPressed: () { /* TODO */ },
    ),
  ],
  </pre>
  </div><p>The result is already quite similar to what we have in the original application:<br></p><figure><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eeca98badfe870ce2c0e65a_Hnet.com-image.gif" alt=""></p></figure><p>Our first implementation has no padding and buttons are too big. When we press the button it shows a grey highlight followed by an animated, darker splash instead of opacity change. Let’s try to implement those missing features.</p><h2>Size and layout</h2><p>On the iPhone 8, original buttons have a size of 40x40 points, 16 points margin to the screen edge and 8 points bottom offset. Given that app bar has a height of 44 points on this iPhone it would mean that those buttons have to overlay status bar (the one with signal strength, clock and battery status) and indeed they are:<br></p><figure id="w-node-53719c61cb64-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eeca9d84b65ff38701fee0a_overlay.png" alt="flutter_overlay"></p></figure><p>We can apply those constraints by wrapping our button widgets in <em>Padding</em> and <em>Align</em>.</p><div>
<pre>    return Padding(
      padding: EdgeInsets.fromLTRB(
        position == AppBarPosition.leading ? 16 : 0, 0,
        position == AppBarPosition.trailing ? 16 : 0, 8),
      child: Align(
        alignment: Alignment.topCenter,
        child: Container(
          width: 40,
          height: 40,
(...)

  </pre>
  </div><figure id="w-node-11a065b0312c-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eecaa077f68da65b8562c7c_56px_app_bar.png" alt="flutter_app_bar"></p></figure><p>One difference is that the bottom offset is bigger in our implementation and we don’t even overflow status bar. The reason is that the height of our app bar is calculated based on the <em>const double kToolbarHeight = 56.0; </em>constant from the Flutter framework. There is no explicit way to set app bar height, eg. by constructor parameter, and the class responsible for the app bar layout, which uses this constant, is private (<em>_SliverAppBarDelegate</em>). This prevents us from using inheritance to override the code responsible for height computation. This delegate is, again, not exposed by the app bar (<em>SliverAppBar</em>), so even if we end up creating our own version, we won’t be able to use it unless we also extend <em>SliverAppBar</em> and override<em> build</em> method from its state. Since Flutter is open source this could be done in a few minutes, by copy-paste original implementation and tweaking those details, but it’s far from feasible solution as we would have to maintain our version and keep it in sync with improvements made by the Flutter team to the original classes.<br></p><p>It’s worth to take a note, that<em> kToolbarHeight</em> is also used to constraint the width of the leading widget (back button in our case), forcing it to be a square. This is how our app bar looks like with margins increased to 25 points. Notice shrunken leading button, while trailing is spaced from the screen edge as expected. This limitation has no effect in our case, as designed margin and button size is exactly matching available space.<br></p><figure id="w-node-0b501ed6363f-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eecaa3d49a49185d4d77cdd_25px_margin.png" alt="flutter_margin"></p></figure><h2>Highlight behaviour<br></h2><p>In the Wolt app when the button is highlighted it changes the opacity of the icon. There is no highlight colour change or splash animation. We can re-create such behaviour by wrapping button in the <em>Opacity</em> widget. To track highlight status we have to introduce an internal state, represented by the <em>_isHighlighted</em> boolean property. That means we have to refactor our widget from stateless to stateful:</p><div>
<pre>enum AppBarPosition {
  leading,
  trailing,
}

class AppBarButton extends StatefulWidget {
  final IconData icon;
  final VoidCallback onPressed;
  final AppBarPosition position;

  const AppBarButton({Key key, this.icon, this.onPressed, this.position}) : super(key: key);

  @override
  _AppBarButtonState createState() =&gt; _AppBarButtonState();
}

class _AppBarButtonState extends State<appbarbutton> {

  bool _isHighlighted = false;

  @override
  Widget build(BuildContext context) {
    return Padding(
      padding: EdgeInsets.fromLTRB(widget.position == AppBarPosition.leading ? 16 : 0, 0,
          widget.position == AppBarPosition.trailing ? 16 : 0, 8),
      child: Align(
        alignment: Alignment.topCenter,
        child: Container(
          width: 40,
          height: 40,
          decoration: BoxDecoration(shape: BoxShape.circle, color: Colors.grey[300]),
          child: Opacity(
            opacity: _isHighlighted ? 0.3 : 1.0,
            child: IconButton(
              icon: Icon(
                widget.icon,
                color: Colors.black,
              ),
              onPressed: widget.onPressed,
            ),
          ),
        ),
      ),
    );
  }
}
  </appbarbutton></pre>
  </div><p>Unfortunately, <em>IconButton</em> we are using is not exposing <em>onHighlightChanged</em> callback - only <em>onPressed</em>, which is not enough for our needs. We have to refactor our code to use more generic button class, like<em> RawMaterialButton</em> where we have more control over callbacks and visual settings.</p><div>
<pre>  child: RawMaterialButton(
    highlightColor: Colors.transparent,
    splashColor: Colors.transparent,
    onHighlightChanged: (isHighlighted) =&gt; setState(() {
      _isHighlighted = isHighlighted;
    }),
    child: Icon(
      widget.icon,
      color: Colors.black,
    ),
    onPressed: widget.onPressed,
  ),
</pre>
</div><h2>Showing the menu<br></h2><p>When the user presses menu button two things happen - the menu is shown and the button icon changes from three dots to close cross. We are going to track the current state in the boolean property <em>_isMenuShown </em>in the State of the screen-route. Updated menu button:</p><div>
<pre>    AppBarButton(
      icon: _isMenuShown ? Icons.close : Icons.more_horiz,
      position: AppBarPosition.trailing,
      onPressed: () {
        Navigator.push(context, AppBarMenu())
            .then((_) =&gt; setState(() =&gt; _isMenuShown = false));
        setState(() =&gt; _isMenuShown = true);
      },
    ),
</pre>
</div><p>We will build <em>AppBarMenu</em> class that extends <em>PopupRoute</em>, as it gives us more control over UI of the menu than <em>PopupMenuButton</em> from the Flutter framework. On button press, Navigator widget is tasked to push our Route to the stack. Push method returns a future which completes after this route is dismissed - that’s why we set <em>_isMenuShown</em> to false in the <em>then </em>callback.</p><h2>Menu look &amp; feel<br></h2><p>Our final task is to build a menu that will be displayed. It’s pretty straightforward - a list with two items, the less obvious parts maybe how to place it on the screen, and how to achieve the shape of a rectangle with rounded corners and triangle indicator on top. We are going to use <em>ClipPath</em> widget with a custom clipper to build the desired shape. An alternative solution would be to compose <em>ClipRRect</em> (RRect stands for rounded rectangle) with an <em>Image</em> widget for the top triangle. Yet another idea is to have a whole background as a nine-patch image, and there are for sure a few more feasible options to achieve the desired UI. Due to Flutter’s widget-oriented architecture, there are often multiple ways how can we compose existing primitives into more complex structures - like this fancy-shaped menu. You can preview updated buttons and the menu on the gif below:<br></p><figure id="w-node-2d5de7a9800c-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eecaa9a37ac27758ef39129_Hnet.com-image%20(1).gif" alt="flutter_buttons_menu"></p></figure><h2>Conclusion<br></h2><p>Flutter allowed us to recreate, very closely, UI and UX of Wolt’s piece of the interface. We were able to achieve the compelling look &amp; feel quickly by composing native widgets, and even if there are certain limitations, due to open-source nature of the Flutter framework, achieving pixel-perfect quality is possible when needed.<br></p></div></div>]]>
            </description>
            <link>https://www.nomtek.com/blog/sleek-ui-in-flutter-wolt</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842062</guid>
            <pubDate>Wed, 15 Jul 2020 06:43:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost in vs Code Windows?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841817">thread link</a>) | @archyking
<br/>
July 14, 2020 | https://marquee.activecove.com/blog/2 | <a href="https://web.archive.org/web/*/https://marquee.activecove.com/blog/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Stop losing track of your thoughts switching between workspaces</h2><p><img src="https://marquee.activecove.com/blog/2/multivscode.png"></p><p>Marquee strives to make working inside VS Code more productive 🦾. Thanks to VS Code's leightweight nature, devs love to open multiple windows for projects, repo, and workspaces. Running multiple VS Code 🗃 instances at the same time. Here are some tools available in Marquee's latest release to help you stay on top of your workspaces.</p><blockquote><p><a href="https://marquee.activecove.com/">Install Marquee</a>, if you haven't already 🤔</p></blockquote><h3>💣 Add todo from editor's context meneu</h3><p>Creating a todo while you're deep inside your editor is now as easy as two clicks away. Just select the text inside your editor, right click, and select "Add todo to Marquee". Done.</p><p><img src="https://marquee.activecove.com/blog/2/context.gif" alt="Marquee Blog"></p><h3>🤖 Auto-suggest to add todos</h3><p>Even more conveniently Marquee will auto-suggest to add a line as todo whenever it's prefixed with uppercase TODO. Notice the blue underline, hover over it, click "Quick Fix", "Add todo". Leave losing track of your thoughts while coding behind you.</p><p><img src="https://marquee.activecove.com/blog/2/quickfix.gif" alt="Marquee Blog"></p><h3>🤓 Workspace specifc todos</h3><p>Marquee will keep a record of all your VS Codes no matter whether you open a new window for workspaces or folders. Whenver you add a new todo Marquee will associate it with your currently active workspace and allow you to toggle the list of displayed todos between all of them (global) or workspace-specifc, scoped down to the active workspace/folder you're currently running.</p><p><img src="https://marquee.activecove.com/blog/2/toggle.gif" alt="Marquee Blog"></p><h2>📮 Didn't do it for you?</h2><p>Let us know what you think. We've located a "Give Feedback" button in the Marquee UX to easily share feedback 📨 with us, good or bad. Please be candid 🤩. If you like Marquee, let your 🧑‍🤝‍🧑 friends know. We mightly appreciate it!</p></div></div></div>]]>
            </description>
            <link>https://marquee.activecove.com/blog/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841817</guid>
            <pubDate>Wed, 15 Jul 2020 05:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OnionFruit Connect – use any browser to connect to the Tor network]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841606">thread link</a>) | @realpanzer
<br/>
July 14, 2020 | https://dragonfruit.network/onionfruit/ | <a href="https://web.archive.org/web/*/https://dragonfruit.network/onionfruit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        


<div>
    <nav>
    <div>
        <p><a href="https://dragonfruit.network/">
            <img src="https://dragonfruit.network/logos/dragonfruit.png" height="25" width="25">
        </a></p>
    </div>
</nav>
    

    <div>
            
            <h3>Free Tor Gateway</h3>
            <p><i>
                    keyboard_arrow_down
                </i>
            </p>
    </div>
</div>

<div>
    <div>
        <div>
            <h2>Connect to Tor in seconds</h2>
            <p>Free and Unlimited Access to the Tor Network</p>
            <p><a href="https://github.com/dragonfruitnetwork/onionfruit/releases/latest/download/install.exe" target="_blank">
                <img src="https://dragonfruit.network/vendor/assets/github.png">
            </a>
        </p></div>
    </div>
</div>



<div>
    <div>
        <div>
            <p><img src="https://dragonfruit.network/img/onionfruit/onionfruit-countries.png">
            </p>
            <div>
                <p>Locations</p>
                <h2>Where to next? Anywhere Specific?</h2>
                <div>
                    <p>OnionFruit Uses a range of open-source databases to find high-speed servers to route your encrypted traffic through. You can choose from over <strong>7,000</strong> servers in <strong>95+</strong> countries to have your data directed through before you connect, or let Tor decide for you with the random option.</p>
                    <p><a href="https://dragonfruit.network/onionfruit/nodes">View Metrics</a>
                </p></div>
            </div>
        </div>
    </div>
</div>



<div>
    <div>
        <div>
            <p><img src="https://dragonfruit.network/img/onionfruit/onionfruit-connected.png">
            </p>
            <div>
                <p>Support</p>
                <h2>Most apps are compatible</h2>
                <p>OnionFruit™ creates a proxy for any app to connect to. Apps that are set to use the system settings are highly likely to be compatible</p>
            </div>
        </div>
    </div>
</div>

<div>
    <div>
        <p>Disclaimer</p>
        <h2>Nice to know...</h2>
        <p>DragonFruit Network does not endorse any activity undertaken using this app. We also provide no warranty and guarantee that you are completely anonymous. We also accept no responsibility for any user activity. DragonFruit Network does not own/maintain any of the servers connected to the Tor network - we canâ€™t guarantee the servers will always be online. OnionFruitâ„¢ Connect is produced independently from TorÂ® and carries no guarantee from The Tor Project about quality, suitability or anything else.</p>
    </div>
</div>








    </div>
</div></div>]]>
            </description>
            <link>https://dragonfruit.network/onionfruit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841606</guid>
            <pubDate>Wed, 15 Jul 2020 05:15:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Bank of Korea to move the country’s financial system to blockchain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23841581">thread link</a>) | @JesseJon
<br/>
July 14, 2020 | https://newsbitcoin247.com/the-bank-of-korea-to-move-the-countrys-financial-system-to-blockchain-by-acquiring-bank-sign/ | <a href="https://web.archive.org/web/*/https://newsbitcoin247.com/the-bank-of-korea-to-move-the-countrys-financial-system-to-blockchain-by-acquiring-bank-sign/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="the-post">

		
<!-- .entry-header-outer /-->


		<!-- .post-footer-on-top /-->

		<div><div><figure><img width="780" height="405" src="https://newsbitcoin247.com/wp-content/uploads/2020/07/bank-of-korea-780x405.jpg" alt=""></figure></div></div>
		<div>

			
			<p>According to <a href="https://thenews.asia/bank-of-korea-acquires-bank-sign/" target="_blank" rel="nofollow noopener noreferrer">The News Asia</a>, the Bank of Korea (BOK) is using blockchain technology in its banking sector also in order to commercialize the infrastructure. It has acquired Bank Sign for this purpose. It will help in transferring the financial services to a more organized structural framework. It will also help in making everything one step away with digital services. People will trust more the authentication and transparency of the system and will be able to invest in blockchain technology.</p>
<p>Bank Sign is a blockchain-based co-verification system that allows authenticated data to transfer among banks and financial institutions.</p>
<h2>Bank sign as&nbsp; a replacement for digital ID</h2>
<p>South Korea’s central bank plans to offer Bank Sign as a replacement for “Digital ID” (DID ). The COVID-19 pandemic situation is forcing South Korea’s banking stakeholders to consider other alternatives rather than currency exchanges such as digital alternatives for live operations.</p>
<p>Since the corona pandemic, organizations and banks have been trying to make everything online and operational through the digital space. Many people also believe that this pandemic can have positive outcomes for the emerging industries as they will render everything online.</p>
<p>Favoring the benefits of adopting Bank Sign, a BOK official told The News Asia:</p>
<blockquote><p>I expect that through cooperation, we will be able to realize cost reduction, service improvements, and discovery of new businesses</p></blockquote>
<p>The BOK adopting a blockchain digital ID system will not only strengthen the infrastructure but also will help in the development of advanced technology.</p>
<h2>Collaborating with Sendsquare to utilize blockchain in medical storage</h2>
<p>According to BTC Manager, the government is now planning to induce blockchain technology in medicine too by work in partnership with Send square.</p>


			
		</div><!-- .entry-content /-->

		
		<!-- .post-footer-on-top /-->

		
	</article><div>

		
		<div>

								<p><a href="https://newsbitcoin247.com/author/danna-james/">
							<img src="https://newsbitcoin247.com/wp-content/uploads/2020/02/danna-e1582923655574.jpg" width="171" height="180" alt="Danna James">						</a>
					</p><!-- .author-avatar /-->
					
			<div>
				

				<p>
					Danna is a journalist and technical writer with six years of experience researching and creating crypto articles, reviews, and how-to guides for different online media outlets, and academic journals.				</p><!-- .author-bio /-->

							</div><!-- .author-info /-->
			
		</div><!-- .about-author /-->
		<!-- .prev-next-post-nav /-->
	

				<!-- #related-posts /-->

				<!-- .comments-area -->


	</div></div>]]>
            </description>
            <link>https://newsbitcoin247.com/the-bank-of-korea-to-move-the-countrys-financial-system-to-blockchain-by-acquiring-bank-sign/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841581</guid>
            <pubDate>Wed, 15 Jul 2020 05:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wiring of the Nervous System]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841506">thread link</a>) | @yoloswagins
<br/>
July 14, 2020 | https://zswitten.github.io/2020/06/03/neuroscience-neural-networks-7.html | <a href="https://web.archive.org/web/*/https://zswitten.github.io/2020/06/03/neuroscience-neural-networks-7.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://zswitten.github.io/2019/08/04/neuroscience-neural-networks-0.html">Part 0: Introduction</a><br>
<a href="https://zswitten.github.io/2019/08/04/neuroscience-neural-networks-1-3.html">Part 1-3: Properties of Neurons</a><br>
<a href="https://zswitten.github.io/2019/09/08/neuroscience-neural-networks-4.html">Part 4: Vision</a><br>
<a href="https://zswitten.github.io/2019/10/07/neuroscience-neural-networks-5.html">Part 5: Wiring of the Visual System</a><br>
<a href="https://zswitten.github.io/2019/11/13/neuroscience-neural-networks-6.html">Part 6: Smell, Taste, Hearing, and Touch</a><br>
<a href="https://zswitten.github.io/2020/06/03/neuroscience-neural-networks-7.html">Part 7: Wiring of the Nervous System</a></p>

<p>We have billions of neurons. And 10^14 connections between those neurons. But our instruction manual for putting it together is a mere 20,000 genes. How does a neuron know what other neurons it’s supposed to connect to?</p>

<p>First, let’s talk about how the basic shape of the brain gets made. A sperm fertilizes an egg. The fertilized egg cell-divides a few thousand times. Then you have a hollow ball. The cells in the ball self-sort into three layers (outside/skin, middle, inside), and the ball of cells flattens out into a plate. Then the plate curves around to form a tube.</p>

<p>Next, on the tube, forward/backward and up/down axes get defined. The way this works is, there are proteins called “morphogens” [short for mighty morphing power generators] that are produced at specific places on the tube. The morphogens spread out from their sources, creating a gradient: the closer a cell is to a morphogen factory, the more morphogen a cell gets. The morphogens control how active various genes are in a cell, and that determines its “cell fate”, i.e. what type of cell it becomes.</p>

<p>Keep in mind this is all happening before the cells have started extending their axons and dendrites to communicate with each other. They have to get their own act together first. In particular, they are deciding whether they will be excitatory, inhibitory, or modulatory, and what neurotransmitter they’re going to use.</p>

<p>But even though they aren’t directly communicating with each other, their fates are intertwined. For instance, each Drosophila (fruit fly) (my biology-knowledgable friends keep yelling at me for calling it “Drosophilia”) sensory organ is supposed to have one socket cell, one hair cell, one sheath cell, and one sensory neuron. If the organ doesn’t have all those things, it doesn’t work, so it’s important for nearby cells to coordinate their cell fate decisions.</p>

<p>This is handled by a protein called Numb. Socket, hair, sheath, and sensory cells all start from the same precursor. When that precursor divides, one child gets most of the Numb. Numb makes another protein called Notch stop working, and one of the things Notch does is 1. upregulate itself and 2. downregulate a different protein called Delta, so the four siblings end up with different amounts of Notch and Delta which makes one of them become socket, one hair, etc. <a href="https://www.youtube.com/watch?v=kXYiU_JCYtU">More like me, less like you!</a></p>

<p>Cells don’t stay in the same place their whole lives. They migrate. In particular, in the cortex, you can tell a cell’s age by how far it is from the center. Cells that are born later migrate to the outer layers of the cortex. Kind of like tree rings.</p>

<p>Now that all the pieces are in place, it’s time for the cells to link up. Remember, cells have one long poky part, the axon, that carries information out, and a bushy bunch of dendrites that take information in. Cells know they’re only meant to have one axon; if you cut off a cell’s axon while it’s growing, one and only one developing dendrite will become the new axon.</p>

<p>Because the axons can grow very long, it’s their job to grow their way to the appropriate dendrites. As we saw in the <a href="https://zswitten.github.io/2019/10/07/neuroscience-neural-networks-5.html">chapter</a> about wiring of the visual system, axons are attracted to or repulsed by various proteins that appear in different amounts in different places, and that determines where they go.</p>

<p>Sometimes, axons have to travel quite a long way to get to their final destination. These long journeys get broken up into multiple steps. For example, there’s a really strong attractant protein at the spine that draws axons to it. But the axon’s true purpose lies elsewhere. So once it reaches the spine, there’s another protein hanging out nearby that makes it so the axon isn’t attracted to the first protein anymore. And meanwhile, there’s a third protein in the area that actively repels the axon away. Grass is always greener!</p>

<p>Axons and dendrites from the same cell repel each other, to induce them to spread out and cover the whole of an area – “dendritic tiling”. But they’re chill with being around axons and dendrites from other cells.</p>

<p>OK, so an axon found the right general area. Now it has to mate with a dendrite to form a synapse. Axons produce a protein called agrin that triggers a bunch of receptors for action potentials to come cluster around it, while also breaking up any random other clusters that happened to be nearby. To make things easier, the axons are attracted to places where there were already preexisting clusters of receptors.</p>

<p>Some of these synapses are lifelong partnerships between two cells, but the divorce rate is real. In mouse muscles, the divorce rate is 90%; each muscle fiber in a mouse newborn gets input from ten neurons, but as the mouse gets older, one of those synapses dominates, taking all the territory from the other synapses which then shrink to nothing. The pattern of which synapses win is unpredictable and differs between individuals and even between the two sides of an individual’s body. This indicates that it’s being driven by activity-dependent competition AKA Nurture not Nature. Synapses can also die out if the axons get pruned, or if the entire cell dies. Long axons are especially likely to get pruned. Also, axons that aren’t firing a lot get pruned.</p>

<p>The second part of the chapter/of this blog post is a case study of the formation of the olfactory map of a mouse. We’ve seen two types of neural map. The first is continuous, in the mathy sense of a continuous function where two points that are close together in the input space will be mapped to close-together points in the output space. Vision is like this: two nextdoor neighbor pixels of your visual screen will map to two nextdoor neighbor neurons. Touch is also mostly continuous. Two nerve cells in your left foot map to two nearby cells in your brain. But it’s not always totally continuous: an example is that signals from mouse whiskers go to their own special place that’s not especially near input from the rest of the face.</p>

<p>Smell is the other kind of map: discrete. Rather than being organized spatially, the smell map is organized by odorant. You could imagine three strategies for making a neural map. Number one: the input neurons are in charge. They know their own identities, and so they know what target neurons in the next layer they should connect to. The target neurons are dumb and define their identity by which input neurons choose them. Number two: the input neurons are dumb and connect randomly to target neurons. It’s the target neurons that are in control and tell the input neurons what to be. Number three: the input neurons and target neurons are both smart. In vision, it’s number three. Both the neurons in the eye and the retinal ganglia cells they connect to are smart. Smart in this sense: different cells in each layer have different amounts of attractor/repeller proteins, and if you turn off the genes that make those proteins, the whole thing stops working. You could call it a healthy equal relationship where both sides contribute.</p>

<p>Smell is the same way, but with another fun twist: the axons sort themselves out along the way. Axons that are coming from cells that sense two different odorants repel each other, while axons that are coming from cells that sense the same odorant attract each other. Like if your tangled-up headphones could magically unscramble themselves on the way to your ears.</p>

<p>Summing it all up, how do we get from 20,000 genes to 10^14 connections?</p>

<ul>
  <li>Some genes make multiple different proteins</li>
  <li>The amount of a protein that’s present makes a difference, not just whether it’s present vs. absent</li>
  <li>Proteins do different stuff in different contexts</li>
  <li>Combinations of proteins do stuff that neither can do alone</li>
  <li>Wiring decisions can have multiple steps, both spatially (multi-step journeys) and temporally (pruning)</li>
  <li>Activity/learned experience can help make connection decisions</li>
  <li>Some of the details don’t matter, like as long as an odorant axon is going to the right glomerulus, it doesn’t really matter which exact cell in the glomerulus it connects to.</li>
</ul>

<p>And finally, what you’ve all been waiting for: half-baked speculation about how we could use this info to make machine learning work better!</p>

<p>Neural networks come into existence with all their connections fully specified. Some of the weights die/go to zero during training, which is like axon pruning. I wonder what it would be like to build up the connectome gradually over time, and to add an element of indeterminism where cells occasionally connect to the “wrong place”. AutoML is arguably like the former, while skip connections are arguably like the latter.</p>

<p>I’m intrigued by the idea of having some concept of a protein, that operates in some “area” (i.e. subset) of different layers, and attracts connections from some neurons in the layers before and after it, while repelling others. Or a whole family of proteins that regulate each other. I wonder whether the practical difficulties of assembling a brain can act as a kind of regularizer. Like, the <a href="https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension#VC_dimension_of_a_neural_network">VC dimension</a> of a brain with 86 billion neurons that can connect to each other in any arbitrary way is huge. The VC dimension of brains that are physically and biologically possible to assemble is a lot smaller.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://zswitten.github.io/2020/06/03/neuroscience-neural-networks-7.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841506</guid>
            <pubDate>Wed, 15 Jul 2020 04:58:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Impact of GitHub Suggested Changes on Recommendations Between Developers [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841479">thread link</a>) | @azhenley
<br/>
July 14, 2020 | http://www.chrisparnin.me/pdf/suggs_FSE_20.pdf | <a href="https://web.archive.org/web/*/http://www.chrisparnin.me/pdf/suggs_FSE_20.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.chrisparnin.me/pdf/suggs_FSE_20.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841479</guid>
            <pubDate>Wed, 15 Jul 2020 04:54:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking the “users always click yes” myth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841435">thread link</a>) | @magic5227
<br/>
July 14, 2020 | https://emilymstark.com/2020/07/14/debunking-the-users-always-click-yes-myth.html | <a href="https://web.archive.org/web/*/https://emilymstark.com/2020/07/14/debunking-the-users-always-click-yes-myth.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>There’s a common myth among software engineers, and security engineers in
particular, that people will always click “yes” on any warning or prompt,
blindly accepting any risk about which the UI warns. This is not generally true,
and the misconception can lead to suboptimal design decisions and even <a href="https://noncombatant.org/2016/01/28/against-security-nihilism/">security
nihilism</a>.</p>

<h2 id="warnings-can-be-designed-for-adherence">Warnings can be designed for adherence</h2>

<p>Warning adherence is the percentage of users who do what a warning wants them to
do. For example, we say that users adhere to an SSL certificate warning if they
leave the offending site upon encountering the warning.</p>

<p>Design decisions can influence adherence significantly – for example,
redesigning the Chrome SSL warning
<a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43265.pdf">increased</a>
adherence from 37% to 62%. (Today, SSL warning adherence is even higher, at
around 80% on Windows. One possible
<a href="https://research.google/pubs/pub46359/">explanation</a> is that we got rid of many
false positive SSL errors, thereby leaving more real errors that users don’t
want to bypass, but I don’t know for sure.) Example of visual or interaction
adherence cues include highlighting the “safe” button or hiding the “unsafe”
button behind a dropdown.</p>

<figure>
  <img src="https://emilymstark.com/assets/cert_error.png" alt="Chrome 86 SSL certificate warning">
  <figcaption><i>Chrome 86 SSL
certificate warning. The safe option (“Back to safety”) is visually highlighted.
The unsafe option is only shown when the “Advanced” button is clicked.</i></figcaption>
</figure>

<p>Some warnings may not need to be as extremely opinionated as the SSL certificate
warning to achieve good adherence. For example, Chrome has a warning for
lookalike domains that use unusual characters to create convincing spoofing
domains. This warning, shown below, is designed to be less opinionated and makes
it easier for people to find the unsafe option, yet people choose the unsafe
option &lt;15% of the time.</p>

<figure>
  <img src="https://emilymstark.com/assets/lookalike_warning.png" alt="Chrome 86 lookalike domain warning">
  <figcaption><i>Chrome 86
SSL lookalike domain warning. This warning is designed to be less scary than the
SSL certificate warning, and it is easier for users to find and exercise the
unsafe option. The warning still produces good adherence.</i></figcaption>
</figure>

<p>It can also be useful to measure user behaviors other than adherence. People may
choose the unsafe option on a warning, but then act more cautiously as they
proceed (for example, by not entering passwords on the unsafe site). Depending
on the risk in question, this may or may not be a safe behavior. My team has
some recent data on this phenomenon that I hope we’ll be able to share publicly
soon.</p>

<p>There are some caveats to this approach of designing warnings for adherence:</p>
<ul>
  <li>In the
<a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43265.pdf">study</a>
I linked above, the redesigned warning did not improve comprehension. People
made safer decisions with the redesigned warning, but they didn’t understand
the warning better than before. Convincing people to make safe choices may be
easier than helping them understand the risks, especially in light of
follow-up <a href="https://research.google/pubs/pub46632/">research</a> suggesting that
there is no single easily-surmountable challenge that gets in the way of
comprehensibility.</li>
  <li>Designing for adherence can be seen as a spectrum. On one end of the spectrum
might be an <a href="https://stackoverflow.com/questions/35274659/does-using-badidea-or-thisisunsafe-to-bypass-a-chrome-certificate-hsts-error/35275060">obfuscated
password</a>
for bypassing the warning. This end of the spectrum could be seen as
paternalistic, or as favoring expert users and denying non-expert users the
same functionality. On the other end might be placing the safe and unsafe
options on equal footing with no visual or interaction distinctions. This end
of the spectrum lets people make their own uninfluenced choices, but puts them
at risk if they do not comprehend the warning well. I think that choosing a
point on this spectrum is probably a subjective, qualitative product decision,
but it’s important to know that the spectrum exists.</li>
</ul>

<h2 id="prompts-that-arent-warnings">Prompts that aren’t warnings</h2>

<p>One might concede that warnings can achieve good adherence, but still speculate
that users will always say “yes” to a prompt – a neutral question that doesn’t
have any particular desired outcome.</p>

<p>I’m less familiar with the research in this area, and there may in fact be less
research overall. But, one public data source we have is the <a href="https://developers.google.com/web/tools/chrome-user-experience-report">Chrome User
Experience
Report</a>,
which recently added <a href="https://developers.google.com/web/updates/2020/02/notification-permission-data-in-crux">permission acceptance
data</a>
for the web notification permission prompt. This data suggests that users
neither blindly accept nor deny notification permission prompts. To pick a few
examples that come to mind, users accept ~3% of notification prompts on
www.tomshardware.com, ~22% on www.facebook.com, and ~82% on news.google.com (as
of early 2020). These numbers are not apples-to-apples comparisons; many
factors, including the audience and context of the website, will influence the
acceptance rate. However, I do think these numbers suggest that users do not
have a constant uniform reaction to permission prompts.</p>

<h2 id="so-what-does-this-mean">So what does this mean?</h2>

<p>Developers shouldn’t assume that users will always blindly say “yes” to any
security or privacy warning or prompt. We can design warnings to achieve good
adherence, and even neutral prompts elicit neither a single uniform response nor
a random response. Still, I think of it as good practice to avoid overloading
people with security and privacy decisions, especially when the risks may not be
comprehensible. I also think it can become unmaintainable to expose every
security decision in the UI; software designers need to prioritize which choices
to expose, and users should choose the software that gives the right level of
control for them.</p>

  </div></div>]]>
            </description>
            <link>https://emilymstark.com/2020/07/14/debunking-the-users-always-click-yes-myth.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841435</guid>
            <pubDate>Wed, 15 Jul 2020 04:46:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hip-Hop Helped Cash App Grow Faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23841365">thread link</a>) | @mehdiyac
<br/>
July 14, 2020 | https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/ | <a href="https://web.archive.org/web/*/https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><h3>Square’s mobile payment service teamed up with rappers to grow fast, use their influence, and acquire the right customers.</h3>
<p><img src="https://i0.wp.com/i.ytimg.com/vi/mjLuy5U9PNU/maxresdefault.jpg?w=700&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.ytimg.com/vi/mjLuy5U9PNU/maxresdefault.jpg?w=700&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h6>Cardi B is the <a href="https://twitter.com/CashApp/following">only person that Cash App follows on Twitter</a>! (via YouTube)</h6>
<p>Last week’s “Cash App Friday” came at the perfect time. The COVID-19 pandemic has been costly, scary, and uncertain, especially for those living paycheck-to-paycheck. On Cash App Fridays, the mobile payment app users can log on Twitter and reply to <a href="https://twitter.com/CashApp">@CashApp</a> with their $cashtag for a chance to win prizes that range from $100 to $500. Later that weekend, Cash App matched some of the giveaways from Shea Serrano –The Ringer staff writer and <a href="https://trapital.co/2019/11/04/shea-serrano-on-the-economics-of-book-publishing-movies-and-other-things-and-how-dj-screw-inspired-his-promotional-tactics/">Trapital Podcast guest</a>— who had already made it habit to give money to those in need.</p>
<p>These philanthropic measures are gracious, but it’s essential to Cash App’s growth model. In 2019, the company spent an estimated <a href="https://money.com/what-is-cash-app-friday/">$60,000 on Cash App Fridays</a>. In return, it earned much more in heightened brand awareness and earned media. This strategy translated well to hip-hop, where rappers use the app to give money to fans. Cash App has now been name-dropped by over 200 hip-hop artists.</p>
<p>Cash App achieved the modern brand’s dream: to become part of the culture. No appropriation. No cringe-worthy attempts to sound like a 23-year-old hypebeast. All genuine. It’s easier said than done, and it’s a model others can learn from.</p>
<hr>
<h4><strong>Make it easy for the customer</strong></h4>
<p>When Cash App launched in 2013, it was much more buttoned-up. Users needed phone numbers or email addresses to transfer money. A year and a half later, the service eased up, followed Venmo’s lead with usernames, and introduced the <a href="https://squareup.com/us/en/press/introducing-cashtags">$cashtag</a>. These handles made the app more social and reduced friction to transfer money.</p>
<p>Square continued this trend when it offered debit cards. From <a href="https://www.fool.com/investing/2018/02/28/squares-cash-app-killed-it-in-2017.aspx">Motley Fool</a>:</p>
<blockquote><p>Square introduced a virtual debit card at the end of 2016, which allowed users to spend their Cash App balance online or through a mobile wallet. So, if you were ordering a pizza online, for example, your friends could send you money on Cash App, then you could pay for the pie with the debit card number.</p>
<p>Square followed it up in April with a physical debit card and allowed users to add a personalized signature or drawing to the front of the card. The card has proved extremely popular, with users spending over $90 million using their Cash Cards during the month of December. That’s a run rate of over $1 billion.</p></blockquote>
<p>It dropped a full year before Venmo’s debit card, which also helped!</p>
<p>Cash App took its efforts to another level in November 2017 when it introduced the ability to trade Bitcoin. This was one month before Bitcoin’s peak valuation (and peak public interest). The timing was perfect. It would be like buying Nicki Minaj stock the month before “Monster” came out.</p>
<p>Square CFO Amrita Ahuja said that Cash App’s Bitcoin and Investing customers <a href="https://www.forbes.com/sites/darrynpollock/2020/02/29/bitcoin-paying-off-for-squares-cash-app-raking-in-178-million/#4ea73a5e28e7">generate up to two-to-three times more revenue</a> than the rest. Since Bitcoin accounts for about <a href="https://www.coindesk.com/bitcoin-drove-half-of-squares-cash-app-revenue-in-the-4th-quarter">half of Cash App’s revenue</a> and Cash App has 24 million monthly active users, that means less than 7 million (28%) use those features.</p>
<p>Most companies would use this as a reason to solely focus on acquiring more Bitcoin investors. They would run ads in fintech newsletters, sponsor emerging tech meetups, find Libertarian groups on Reddit, and so on.</p>
<p>But Cash App expanded its reach. Cash App giveaway recipients aren’t exactly the demo for Bitcoin investing. But they might be someday and may spread the word to someone who <em>is</em> in that cryptocurrency demo. That’s what Cash App is banking on (literally). This is the long game.</p>
<p><img data-attachment-id="3531" data-permalink="https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/screen-shot-2020-03-18-at-10-50-49-am/" data-orig-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?fit=2240%2C1458&amp;ssl=1" data-orig-size="2240,1458" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-03-18 at 10.50.49 AM" data-image-description="" data-medium-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?fit=300%2C195&amp;ssl=1" data-large-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?fit=700%2C456&amp;ssl=1" src="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=700%2C456&amp;ssl=1" alt="" width="700" height="456" srcset="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=2240&amp;ssl=1 2240w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=300%2C195&amp;ssl=1 300w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=1024%2C667&amp;ssl=1 1024w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=768%2C500&amp;ssl=1 768w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=1536%2C1000&amp;ssl=1 1536w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=2048%2C1333&amp;ssl=1 2048w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=1400&amp;ssl=1 1400w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=2100&amp;ssl=1 2100w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=2240&amp;ssl=1 2240w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=300%2C195&amp;ssl=1 300w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=1024%2C667&amp;ssl=1 1024w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=768%2C500&amp;ssl=1 768w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=1536%2C1000&amp;ssl=1 1536w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=2048%2C1333&amp;ssl=1 2048w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=1400&amp;ssl=1 1400w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?w=2100&amp;ssl=1 2100w" data-lazy-src="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-10.50.49-AM.png?resize=700%2C456&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h6>This is a Spotify screenshot of songs named “Cash App.” That list keeps going… it’s clearly an SEO play.</h6>
<h4><strong>Influencer marketing done right</strong></h4>
<p>Square is still not entirely sure how Cash App first became popular with hip-hop. Here’s Square CEO Jack Dorsey at a 2019 investor conference via <a href="https://www.wsj.com/articles/dont-venmo-iggy-azalea-cash-app-rules-rap-11565191206">Wall Street Journal</a>:</p>
<blockquote><p>“This is also something we weren’t expecting, but I think Cash App has touched in the culture. We’ve just benefited from people loving it and wanting to sing about it, and putting it in their music videos, and it’s amazing how much that spreads.”</p></blockquote>
<p>But once Square noticed the trend, it locked in. In 2018 it teamed up with <a href="https://www.businessinsider.com/travis-scott-is-giving-away-100000-to-fans-through-the-cash-app-2018-8">Travis Scott </a>and <a href="https://www.complex.com/music/2018/08/why-are-rappers-giving-away-money-cash-app-lil-b">Lil’ B</a>. In December, it got together with <a href="https://cash.app/legal/us/en-us/snoop-special-stars">Snoop Dogg</a>. Each of them used the app to give away money. The company acquired customers through the rappers’ social media followings at an extremely low cost. Free money is an easy sell, and it doesn’t take that many customers to justify the cost.</p>
<p>Here’s a great breakdown from <a href="https://ark-invest.com/research/squares-cash-app-twitter">Ark Invest</a> on the low-cost customer acquisition:</p>
<blockquote><p>While banks can pay from $350 to $1500 to acquire users, Cash App acquired a new customer through Burger King in five minutes without any direct mail or bank branch visit.</p>
<p>Square has run similar [$100,000] campaigns with rappers like Travis Scott and Lil B and other influencers, triggering a network effect for the Cash App… If only 129 of the 120,000 who commented on [Travis Scott’s] tweet were new to Cash App, then Square’s cost of customer acquisition would have been less than the $925 per user that banks pay on average, according to our research, and 6,000 comments, only 5% of the total, would have dropped it to $20. Moreover, as the converted users appear to spread the word on social media, the Cash App can acquire additional users from just one.</p></blockquote>
<p>That’s well worth $100,000 for both La Flame and Cash App. It’s even more worthwhile considering the influence that hip-hop fans have on their peers. According to <a href="https://www.revolt.tv/2020/1/1/21043728/generation-hip-hop-2020">REVOLT’s Gen Hip Hop study</a>, hip-hop fans are 2x more likely to be culturally influential. It’s the right audience to acquire.</p>
<p>Cash App’s user base is <a href="https://twitter.com/hknightsf/status/1239976638844039168?s=20">strongest in the South and the Midwest</a> of the US, which aligns with the regions where many hip-hop fans are at. It’s the opposite of most founders who focus first on their “early adopter” personal networks in the coastal metro hubs in New York and San Francisco. This strategy made more sense years ago when broadband internet access was noticeably stronger in tech hubs and universities, but that’s no longer the case. It’s 2020. Smartphones are now ubiquitous. It’s time to think beyond Mark Zuckerberg’s Ivy League expansion plan that worked for Facebook in 2004.</p>
<p>Venmo’s growth strategy was more aligned with the traditional tech growth model. The founders are UPenn alums who hit up Princeton Hackathons and other similar events. It had its own “Million Dollar Money Tree” cash giveaway and $5 referral sign-up bonuses to attract customers. But those offers were also centered around Ivy League users and their friends who live on the coasts.</p>
<p>Cash App’s <a href="https://s21.q4cdn.com/114365585/files/doc_financials/2019/q4/2019-Q4-Shareholder-Letter-Square.pdf">monthly active users have grown</a> from 7 million in 2017, 15 million in 2018, to 24 million in 2019. It still trails Venmo in users, but Cash App is <a href="https://www.fool.com/investing/2019/08/27/the-gap-between-cash-app-and-venmo-is-getting-bigg.aspx">growing faster</a>.</p>
<p>I drew this chart to highlight the difference:</p>
<p><img data-attachment-id="3529" data-permalink="https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/screen-shot-2020-03-18-at-9-33-56-am/" data-orig-file="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?fit=2104%2C1576&amp;ssl=1" data-orig-size="2104,1576" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-03-18 at 9.33.56 AM" data-image-description="" data-medium-file="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?fit=700%2C524&amp;ssl=1" src="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=700%2C524&amp;ssl=1" alt="" width="700" height="524" srcset="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?w=2104&amp;ssl=1 2104w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=1024%2C767&amp;ssl=1 1024w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=768%2C575&amp;ssl=1 768w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=1536%2C1151&amp;ssl=1 1536w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=2048%2C1534&amp;ssl=1 2048w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?w=1400&amp;ssl=1 1400w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?w=2104&amp;ssl=1 2104w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=1024%2C767&amp;ssl=1 1024w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=768%2C575&amp;ssl=1 768w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=1536%2C1151&amp;ssl=1 1536w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=2048%2C1534&amp;ssl=1 2048w, https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?w=1400&amp;ssl=1 1400w" data-lazy-src="https://i1.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.33.56-AM.png?resize=700%2C524&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h4><strong>An effective flywheel</strong></h4>
<p>Cash App’s strategy is a true flywheel that drives more peer-to-peer transactions. The hip-hop influencers and their fans grew the user base and brand awareness further, which gained the attention of those who seek higher-end services like Bitcoin and Investing.</p>
<p>The flywheel looks like this:</p>
<p><img data-attachment-id="3530" data-permalink="https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/screen-shot-2020-03-18-at-9-34-31-am/" data-orig-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?fit=2026%2C1172&amp;ssl=1" data-orig-size="2026,1172" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-03-18 at 9.34.31 AM" data-image-description="" data-medium-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?fit=300%2C174&amp;ssl=1" data-large-file="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?fit=700%2C405&amp;ssl=1" src="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=700%2C405&amp;ssl=1" alt="" width="700" height="405" srcset="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?w=2026&amp;ssl=1 2026w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=300%2C174&amp;ssl=1 300w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=1536%2C889&amp;ssl=1 1536w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?w=1400&amp;ssl=1 1400w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?w=2026&amp;ssl=1 2026w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=300%2C174&amp;ssl=1 300w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=1536%2C889&amp;ssl=1 1536w, https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?w=1400&amp;ssl=1 1400w" data-lazy-src="https://i2.wp.com/trapital.co/wp-content/uploads/2020/03/Screen-Shot-2020-03-18-at-9.34.31-AM.png?resize=700%2C405&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>It’s similar to Jay Z’s flywheel with his <em>4:44</em> release. Here’s <a href="https://trapital.co/2019/11/21/jay-zs-cell-phone-partnership-strategy-explained/">what I wrote last year</a>:</p>
<blockquote><p>Jay Z made a sale that valued the company at more than 10x his purchase price just two years earlier. That’s impressive especially with all the turmoil and controversy that surrounded Tidal during that stretch.</p>
<p>But the real kicker is that $75 million was budgeted for exclusive content for Sprint. Five months after the deal was publicized, Jay Z dropped 4:44 as a Sprint-Tidal exclusive. This connected the streaming service with Sprint, which now had a vested interest in Tidal’s success (not too different from Live Nation’s interest in Roc Nation). And by partnering with a cellular carrier instead of a manufacturer like Nokia or Samsung, Jay increased his flexibility and integration capabilities.</p></blockquote>
<p>Jay Z distributed his album through Sprint because it has an active customer base and a means to deliver his product. Sprint was now a co-owner of Tidal, Jay’s streaming service. The cellular carrier had a vested interest in both the delivery and implementation. And Sprint customers got the album for free. Everybody won.</p>

<hr>
<p>In this next decade, Cash App’s customer acquisition tactics will be replicated by many. Products that are built to serve the mass consumer will waste time if they religiously follow Silicon Valley’s age-old mantra to “start in San Francisco and New York” and expand from there. That traditional plan still makes sense for a product like Superhuman, the $30 / month email service that’s specifically targeted at that who will pay for that. It’s less ideal for an app that relies on network effects and massive scale.</p>
<p>Mass-market products need branding. In consumer tech, hip-hop has been the backbone. TikTok had Lil’ Nas X. Snapchat had DJ Khaled. YouTube had Soulja Boy. The list goes on. Hip-hop culture influence continues to grow, and more companies will find their own way to engage fans.</p>

</div></article></main></div></div></div>]]>
            </description>
            <link>https://trapital.co/2020/03/18/how-hip-hop-helped-cash-app-grow-faster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841365</guid>
            <pubDate>Wed, 15 Jul 2020 04:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Insomniac's journey to regular sleep]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23841175">thread link</a>) | @rahulshiv7
<br/>
July 14, 2020 | https://www.sleepedy.com/articles/insomniac-journey-to-better-sleep/ | <a href="https://web.archive.org/web/*/https://www.sleepedy.com/articles/insomniac-journey-to-better-sleep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>I'd done everything right, yet it was 2 am and I still couldn't sleep. I had meditated for 30 minutes before I went to bed. I even took a couple of melatonin pills right after to be sure. Yet, here I was wide awake dreading how exhausted I would be the next day at work.</p><p>My problem wasn't unique. In America, one in every 10 adults will experience chronic insomnia<sup><a href="#references">1</a></sup>. It takes just one poor night of sleep to devolve into long term sleeping problems. This is because the majority of sleeping problems stem from anxiety and worry<sup><a href="#references">2</a></sup>. <b>The more you worry about not getting enough sleep, the worse your sleep gets</b>.</p><p>For me, my sleeping issues began right out of college. I had started a job as a software engineer and I was starting to feel the pressure. I had a couple of big deadlines coming up and I found myself tossing and turning unable to sleep one night. My mind kept racing, thinking about all the work I had until I finally fell asleep.</p><p>I thought that was it — an abnormal night, but then it happened again. This time, my outlook changed. I started worrying about how not getting enough sleep would affect my day. I looked up basic sleep hygiene tips online and decided to go to bed extra early to make sure I made up for lost sleep. This ended up backfiring and it took a few hours before I could finally sleep.</p><p>At this point, my sleeping struggles started becoming more regular. I downloaded a couple of meditation apps in the hopes that meditating and listening to soothing sounds would help me sleep better. I even resorted to over the counter sleeping aids on nights when it took me too long to fall asleep. <b>The results were mixed — I'd fall asleep faster but over time I'd revert back to having poor sleep</b>.</p><p>I finally caved and decided to try prescription medication. I had read a lot about them and was very reluctant because of their long term side effects. On a visit to my doctor, I asked her if she could prescribe me something to help me sleep. She said she said she could, but it wasn't going to be medication. Instead, she put in a referral to a CBT-I (Cognitive Behavioral Therapy for Insomnia) therapist.</p><p>CBT-I is an evidence-based (proven in clinical trials) technique used to treat sleep problems<sup><a href="#references">3</a></sup>. <b>Two driving forces induce sleep — sleep drive &amp; mental arousal</b>. Your sleep drive is how sleepy/tired you feel when going to bed. Your mental arousal is the racing thoughts and alertness you feel when you go to bed. When your sleep drive is high and your arousal levels are low; it is easier to fall asleep. CBT-I prescribes a sleep schedule that ensures you have a high sleep drive. It also teaches you techniques to worry less and reduce your arousal.</p><p><b>CBT-I is extremely effective in treating sleeping problems</b>. Clinical trials have shown that 80% of people that follow a good CBT-I program will have normal sleep by the end<sup><a href="#references">4</a></sup>. The results are also permanent, unlike sleeping aids which are effective only as long as you are taking them<sup><a href="#references">5</a></sup>.</p><p>There were three main rules that I had to follow -</p><ol><li><p>I could only sleep within the sleep window my therapist prescribed. This ensured that I only went to bed when my sleep drive was high.</p></li><li><p>Every time I couldn't sleep, I had to make sure I didn't stay in bed for over 20 minutes. This way, I would subconsciously re-train my mind to not associate my bed with wakefulness<sup><a href="#references">6</a></sup>.</p></li><li><p>No day time naps and no caffeine after 2pm.</p></li></ol><div><p>I was sleeping around 5 hours at the time, so we set a 6 hour window within which I could sleep (1am - 7am in my case). I kept a log of how long it took me to sleep, how long I was awake in the middle of the night and how long I slept. This data was recorded to the closest 15th minute and is self reported. At the end of each week, my therapist would alter my sleep schedule based on the previous week's data.<b> Note:</b> Time awake is the time it took me to fall asleep + my night time awakenings
</p></div><p>
At the end of week 1, I was sleeping about the same as I was before. My time awake at night though had fallen by an hour. I was falling asleep faster and I was having less interrupted sleep. We decided to stick to the same sleep schedule for week 2.
</p><p>
At the end of this week, my sleep had increased and I was consistently awake for less than an hour. We decided to expand my window by 15 minutes for week 3.
</p><p>
We followed the same rules and either expanded or kept the same sleeping window for the next few weeks.
</p><p><b>At the end of the 10 week program, I was sleeping over 7 hours a night</b>. More importantly, I wasn't spending my days worrying about my sleep.
</p><p><b>CBT-I isn't an easy solution</b>. The sleep schedules are hard to follow and the results aren't instantaneous. It takes time and effort but the reward of permanently improved sleep is well worth it. Let me know if you do decide to try it and if it helps you improve your sleep. Here's to hoping you get better sleep soon.</p><p>If you'd like to know more about CBTI and other behavioral therapy techniques to improve sleep, check out our <a href="https://www.sleepedy.com/" target="_blank" rel="nofollow noopener noreferrer">website</a>!</p><h2 id="references">References</h2><ol><li><p><a href="http://sleepeducation.org/news/2014/03/10/insomnia-awareness-day-facts-and-stats" target="_blank" rel="nofollow noopener noreferrer">Insomnia Awareness Day by the American Association of Sleep Medicine</a></p></li><li><p><a href="https://adaa.org/understanding-anxiety/related-illnesses/sleep-disorders" target="_blank" rel="nofollow noopener noreferrer">Sleep Disorders by the Anxiety and Depression Association of America</a></p></li><li><p><a href="https://www.sleepedy.com/cbt-for-insomnia" target="_blank" rel="nofollow noopener noreferrer">CBT for Insomnia: A comprehensive guide</a></p></li><li><p>Trauer, James M. et al. “<a href="https://www.ncbi.nlm.nih.gov/pubmed/26054060" target="_blank" rel="nofollow noopener noreferrer">Cognitive Behavioral Therapy for Chronic Insomnia: A Systematic Review and Meta-analysis.</a> Ann Intern Med. August 2015 163(3) : 191-204</p></li><li><p><a href="https://www.phillymag.com/be-well-philly/2016/04/29/otc-sleep-aids-sleeping-supplements/" target="_blank" rel="nofollow noopener noreferrer">Phily Mag interview with doctors on efficacy of sleep supplements</a></p></li><li><p><a href="https://stanfordhealthcare.org/medical-treatments/c/cognitive-behavioral-therapy-insomnia/procedures/stimulus-control.html" target="_blank" rel="nofollow noopener noreferrer">Stimulus Control: Stanford Healthcare</a></p></li></ol></div></div></div>]]>
            </description>
            <link>https://www.sleepedy.com/articles/insomniac-journey-to-better-sleep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841175</guid>
            <pubDate>Wed, 15 Jul 2020 03:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we grew Sentry's monthly active users by rethinking invitations]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23841049">thread link</a>) | @bentlegen
<br/>
July 14, 2020 | https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations | <a href="https://web.archive.org/web/*/https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><time datetime="2020-02-12T00:00">February 12, 2020</time><div><p>At its core, Sentry is a tool that alerts you to defects in your production software. But it does more than blast stack traces into your inbox: Sentry provides powerful workflows to help your team determine root cause, <a href="https://blog.sentry.io/2019/02/07/sentry-workflow-triage">triage issues</a> to your team, and keep tabs on ongoing concerns with comments and notifications.</p>
<p>These collaborative features can help you resolve problems with your software quickly. But the keyword here is <strong>collaborative</strong>; without your full team having access to Sentry, you may find yourself quickly becoming overwhelmed with an endless backlog of issues and no one to help.</p>
<p>At the end of 2019, the Growth team made it our mission to make it easier for our users to invite their teammates to join them on Sentry. To achieve this, we tackled three distinct areas:</p>
<ol>
<li>Surfacing the ability to invite users contextually</li>
<li>Expanding Sentry’s permission model to allow <em>more types of users</em> to send invitations </li>
<li>Allowing external users to request access themselves</li>
</ol>
<p>Our theory: improving the user experience of inviting users, <em>as well as</em> democratizing the process to include all team members would lead to a significant increase in team-wide adoption. <em>(Narrator: it did.)</em></p>
<h2 id="the-status-quo"><a href="#the-status-quo" aria-label="the status quo permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>The status quo</h2>
<p>Before we get deep into what we changed and how it impacted the bottom line, let’s quickly revisit how user invitations worked: the <em>Add Member to Organization</em> page you see below.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?fm=webp&amp;w=233 233w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?fm=webp&amp;w=465 465w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?fm=webp&amp;w=930 930w" sizes="(max-width: 800px) 100vw, 800px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?w=233 233w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?w=465 465w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?w=930 930w" sizes="(max-width: 800px) 100vw, 800px">
          <img alt="1-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>This full-page experience, tucked away deep in Sentry’s account settings, had a number of issues:</p>
<ol>
<li>Since this is a full page, reaching it meant you would be taken out of context of whatever you were doing previously</li>
<li>Its location deep in our navigation hierarchy meant discoverability was poor</li>
<li>It’s <em>unclear</em> you can actually invite multiple people at once (you can!)</li>
<li>When inviting multiple users, you could only assign the group to the same role and collection of teams</li>
</ol>
<p>Interestingly, to improve discoverability, we had previously introduced a number of “quick links” to reach this page more easily. But these links were scattered around the application, and didn’t appear contextually when users signaled intent to invite members.</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/4xiHp1Gl0HaZ0l8USGDPLr/79402583357d98cf55ad2dfda6ffe537/2-invitations.png" alt="" title="2-invitations"></p></figure><div>
<p>These user experience and discovery challenges felt like obvious starting places. But instead of just settling for a new “improved” form, we decided to rethink the entire experience from the ground up.</p>
<h2 id="the-new-member-invitation-modal"><a href="#the-new-member-invitation-modal" aria-label="the new member invitation modal permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>The new member invitation modal</h2>
<p>It’s probably not a surprise that our first instinct was to convert this page into a modal –&nbsp;one that manages to squeeze all of the capabilities shown earlier into a smaller, more concise experience. It actually does one better: the modal is clearer in indicating that you can invite multiple users, and allows you to set unique permissions for each invitee.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?fm=webp&amp;w=190 190w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?fm=webp&amp;w=381 381w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?fm=webp&amp;w=761 761w" sizes="(max-width: 761px) 100vw, 761px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?w=190 190w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?w=381 381w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?w=761 761w" sizes="(max-width: 761px) 100vw, 761px">
          <img alt="3-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>While modals are sometimes overused in web applications, we believed this approach would solve our key discoverability and navigation concerns: it can be shown contextually without leaving the current page, and completing the form returns you to what you were doing.</p>
<p>To that point, we additionally introduced buttons to launch this <em>Invite New Members</em> modal contextually throughout Sentry:</p>
<ul>
<li>Viewing an issue and notice a <a href="https://docs.sentry.io/workflow/releases/?platform=node#after-associating-commits">suspect commit</a> made by a coworker? If they’re not already part of your Sentry organization, you can now invite them then and there.</li>
<li>Trying to assign an issue to a team member, but don’t see their name in the assignee list? You now have the option to invite them right in the dropdown.</li>
<li>Creating a new team? Now you can invite new members directly to that team as you go.</li>
</ul>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/60GpNeFNg4toier5a02zh4/ba868de307b0dcc6764805901b0b6e93/4-invitations.png" alt="" title="4-invitations"></p><figcaption><p>Example contextual link that launches the Invite New Members modal</p></figcaption></figure><div>
<h2 id="democratizing-invitations"><a href="#democratizing-invitations" aria-label="democratizing invitations permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Democratizing invitations</h2>
<p>As we began rolling out our new <em>Invite New Members</em> experience across the application, we came to a sobering realization: only roughly <strong><em>half</em></strong> of Sentry users could actually use our new modal. That’s because historically, only those with Owner or Manager-level permissions could invite other team members. Combined, users with these permissions accounted for less than 50% of active users.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?fm=webp&amp;w=123 123w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?fm=webp&amp;w=245 245w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?fm=webp&amp;w=490 490w" sizes="(max-width: 490px) 100vw, 490px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?w=123 123w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?w=245 245w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?w=490 490w" sizes="(max-width: 490px) 100vw, 490px">
          <img alt="5-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>Restricting the ability to add new users to account administrators is pretty common practice for software tools, and Sentry is no exception. When an employee onboards on a new team, it’s common to see an exchange like this:</p>
<blockquote>
<p>Alice: Oh awesome, we use Sentry. Can you add me to the organization?
Bob: Ah, I can’t invite you. Maybe ask Jen?</p>
</blockquote>
<p>In a perfect world, one of your administrators is tracked down, and they manually add the new teammate to the account. But sometimes that person is unknown, or is on a vacation, or maybe it takes them days or weeks or even months.</p>
<p>We began asking ourselves: what if we could unlock team members to fast-track this whole process and invite members themselves? This led to our next major change: updating our permission model to allow for <strong>members to request to invite other members.</strong></p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?fm=webp&amp;w=185 185w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?fm=webp&amp;w=369 369w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?fm=webp&amp;w=738 738w" sizes="(max-width: 738px) 100vw, 738px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?w=185 185w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?w=369 369w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?w=738 738w" sizes="(max-width: 738px) 100vw, 738px">
          <img alt="6-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a>  </p>
<p>Now, when non-administrators open up the Invite New Members modal, it changes contextually to become a “request to invite” rather than a direct invitation. Hitting “send” kicks off an email to all organization administrators, who are prompted to approve any outstanding requests.</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/4oi9gYhVX185djAJWppP3Q/ff565fcd34cf00c3a60a32c5ec0cde7b/7-invitations.png" alt="" title="7-invitations"></p><figcaption><p>Organization owners and managers can see pending invitation requests.</p></figcaption></figure><div>
<p>At this point, we had built what we thought was a fantastic new user experience and we just <em>doubled</em> the number of users who could take advantage of it. But this exercise of opening up user invitations got us thinking: what if there was an even <em>further</em> source of untapped users we weren’t reaching?</p>
<h2 id="removing-the-middleman-entirely"><a href="#removing-the-middleman-entirely" aria-label="removing the middleman entirely permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Removing the middleman entirely</h2>
<p>In the last section, we highlighted a scenario where one teammate asks another teammate for access to Sentry. And because of our recent changes, users can request to invite their teammates themselves instead of having to track down and ask their account administrator.</p>
<p>But this scenario still has a gatekeeping element: the new teammate has to ask <em>another</em> teammate for access. What if the new teammate spots an alert from Sentry in Slack stemming from their recent changes, and no one’s around to grant them access? Unfortunately, they’d land on an authentication wall that would prevent them from going any further.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?fm=webp&amp;w=112 112w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?fm=webp&amp;w=225 225w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?fm=webp&amp;w=449 449w" sizes="(max-width: 449px) 100vw, 449px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?w=112 112w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?w=225 225w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?w=449 449w" sizes="(max-width: 449px) 100vw, 449px">
          <img alt="8-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>This begged the question: was there an untapped source of potential users we weren’t reaching by restricting invitations <em>only</em> to active Sentry users? What if new users didn’t have to ask anyone at all?</p>
<p>So, to keep this party going, we dug in and additionally made it possible for <strong>external users to request to join an organization</strong>.</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/6mRCkcVZkkAlZ0ELzWUGHr/3123b1113330661bc7ee5023aa5ef54c/9-invitations.png" alt="" title="9-invitations"></p><figcaption><p>The “Request to Join” button has been added to the organization login page, allowing</p></figcaption></figure><div>
<p>Now when a user lands on an Organization’s login page, they have the option to “Request to join”, which asks for the user’s name and email address. Once they hit send, the organization owners are sent an email that prompts them to approve the join request. Just in case, there’s also a call-to-action to disable the feature entirely for their organization.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?fm=webp&amp;w=165 165w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?fm=webp&amp;w=330 330w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?fm=webp&amp;w=660 660w" sizes="(max-width: 660px) 100vw, 660px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?w=165 165w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?w=330 330w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?w=660 660w" sizes="(max-width: 660px) 100vw, 660px">
          <img alt="10-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>Having developed a new contextual invitation modal and a pair of invite-friendly permission changes, we were <em>feeling</em> confident that these changes were going to have a strong impact on user behavior. It was time now to put our money where our code was, and verify that all this hard work actually moved the needle.</p>
<h2 id="ab-testing-the-impact"><a href="#ab-testing-the-impact" aria-label="ab testing the impact permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>A/B testing the impact</h2>
<p>Our standard procedure for validating the efficacy of product changes is through A/B testing (also known as split testing). This means instrumenting our application code to serve different experiences to segments of users over the same time period, and comparing the results. This step takes extra effort, but it’s worth it –&nbsp;the alternative is to settle for a before-and-after snapshot of data, which is too easily impacted by external factors like seasonality or marketing pushes.</p>
<p>ℹ️ <em>To learn more about how we perform A/B testing at Sentry, please see <a href="https://blog.sentry.io/2019/05/09/easy-ab-testing-with-planout">this earlier blog post</a>.</em></p>
<p>It’s easy to get carried away with A/B testing, and having so many permutations that you don’t have enough data to be statistically significant. So, to simplify things, we decided that all treatments would get the new modal experience, and our “treatment” groups would focus on the new permission changes.</p>
<p>This left us with 4 distinct treatments that we rolled out to 4 equally-sized customer segments:</p>
<ol>
<li><strong>Baseline</strong> (new modal only)</li>
<li><strong>Request to Invite</strong> (user invites another user)</li>
<li><strong>Request to Join</strong> (external user requests to join)</li>
<li><strong><em>Both</em></strong> Request to Invite and Request to Join are enabled together</li>
</ol>
<p>Our main criteria for determining success: which of these treatments would result in <strong>an increase in <em>accepted</em> invitations</strong> (and thus new users)?</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/rlobEVJ4FCzWbU1tmPqqb/8ed779f9a63aa3382e5590cfa8e4bec1/11-invitations_2_.png" alt="" title="11-invitations"></p><figcaption><p>% of accepted invitations relative to baseline</p></figcaption></figure><div>
<p>After 30 days, the results became clear (not to mention, statistically significant):</p>
<ul>
<li><strong>11%</strong> more users accepted invitations in the <em>Request to Invite</em> treatment vs. the baseline</li>
<li><strong>9%</strong> more users accepted invitations in the <em>Request to Join</em> treatment vs. the baseline</li>
<li><strong>21%</strong> more users accepted invitations who had both <em>Request to Invite</em> and <em>Request to Invite</em> treatments enabled</li>
</ul>
<p>It’s probably not a surprise that allowing a wider set of users to invite team members resulted in more users inviting team members. It’s also probably not a surprise that enabling both feature sets at the same time was even better (given that they complement each other)!</p>
<h2 id="turning-users-into-active-users"><a href="#turning-users-into-active-users" aria-label="turning users into active users permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Turning users into active users</h2>
<p>Having more users join your platform is great, but what’s the point if those users never actually <em>use</em> the product? To be truly confident …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations">https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations</a></em></p>]]>
            </description>
            <link>https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841049</guid>
            <pubDate>Wed, 15 Jul 2020 03:42:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Landing Page Optimization Tips (With Examples)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23840363">thread link</a>) | @nscalice
<br/>
July 14, 2020 | https://growthmarketer.co/landing-page-optimization-tips/ | <a href="https://web.archive.org/web/*/https://growthmarketer.co/landing-page-optimization-tips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#ffffff" data-fg="#165cfc" data-width="5" data-mute="" data-fgopacity="0.5" data-mutedopacity="0.5" data-placement="top" data-placement-offset="0" data-content-offset="0" data-placement-touch="top" data-placement-offset-touch="0" data-transparent="" data-touch="1" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#165cfc" data-rtl="">
<p>Need to&nbsp;<strong>optimize your website or landing page</strong>&nbsp;in a hurry?</p>
<p>While there’s no one-size-fits-all approach to conversion optimization, there are some recurring recommendations that come up again and again when I’m consulting with clients.</p>
<p>And in this article, I break down seven such landing page optimization tips for you, one-by-one.</p>
<p>Each tip is based off my <a href="https://growthmarketer.co/framework/">7 Question Landing Page Framework</a>, and backed by years of data and testing.</p>
<p><em>Let’s go!</em></p>
<h2>Focus on clarity</h2>
<p>Simplify the above-the-fold section of your landing page to focus on&nbsp;<strong>one main thought</strong>&nbsp;(headline), a subheadline that goes into more detail, and one&nbsp;clear&nbsp;call-to-action.</p>
<p>Here’s what an&nbsp;<em>unclear</em>&nbsp;headline looks like:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/unclear-headline.png"></figure>
<p>If you just read the headline, would you have any idea what this company does?</p>
<p>Now, on the flip side, what do you think of this headline:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/clear-headline.png"></figure>
<p>It’s pretty clear right away that this tool helps you sell stuff online.</p>
<h2>Increase the relevance</h2>
<p>Focus less on the features and more on&nbsp;<strong>benefits and outcomes</strong>&nbsp;that show the visitor how your offer will solve their problem.</p>
<p>This landing page below does a good job of focusing on the benefits for their sales tool, by mentioning stuff like “prioritize which decision makers to pursue with relevant insights:”</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/copy.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/copy.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/copy.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/copy-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/copy.png"></figure>
<h2>Create strong affinity</h2>
<p><strong>Design</strong>&nbsp;your page in a way that is easy-to-use, easy-to-navigate, looks great on mobile, has legible typography, consistent&nbsp;colors, and authentic images.</p>
<p>Creating a sense of affinity is not easy, but when you nail it, you know right away.</p>
<p>Here are two pages side-by-side:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/affinity.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/affinity.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/affinity.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/affinity-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/affinity.png"></figure>
<p>Don’t you simply like one way better than the other, even if you can’t explain exactly why?</p>
<h2>Showcase your influence</h2>
<p>Add&nbsp;<strong>social proof</strong>&nbsp;to your page with&nbsp;testimonials, case studies, numbers of customers/clients, etc.</p>
<p>One company that goes above and beyond with their social proof is Basecamp. Look at all of those testimonials:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/social-proof.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/social-proof.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/social-proof.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/social-proof-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/social-proof.png"></figure>
<h2>Build up trust</h2>
<p>Increase the perception of&nbsp;<strong>trust</strong>&nbsp;by adding trust indicators, badges, certifications, affiliations, and other quantifiable stats such as the number of years in business.</p>
<p>InVision does a great job of showcasing some well-known trust signals below the hero section:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/trust-signals.png"></figure>
<h2>Mention an advantage</h2>
<p>Make sure to mention your&nbsp;<strong>unique advantage</strong>&nbsp;that highlights something special about your offer/product/service to address how your solution is different from other options.</p>
<p>My&nbsp;<em>favorite</em>&nbsp;example of a unique advantage is Dyson and their “cyclone technology:”</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/unique-advantage.png"></figure>
<h2>Make it easy to take action</h2>
<p>Repeat your&nbsp;<strong>call-to-action</strong>&nbsp;several times throughout the page using a contrasting color/style to make it stand out, especially mentioning it at the top and bottom sections.</p>
<p>Here’s an above-the-fold portion of a site that has literally&nbsp;<em>no</em>&nbsp;visible&nbsp;call-to-action&nbsp;in their hero section:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/bad-cta.png"></figure>
<p>On the other hand, this financial services company makes it super easy to understand exactly what they want you to do next:</p>
<figure><img src="https://growthmarketer.co/wp-content/uploads/2020/07/good-cta.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/good-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/good-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/good-cta-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/good-cta.png"></figure>
<h2>The “7 Question” Landing Page Framework</h2>
<p>If you’ve been reading my blog for a while, or listening to my podcasts, you might realize a recurring theme here.</p>
<p>Each landing page optimization tip I shared above is directly related to one of the questions in my <a href="https://growthmarketer.co/framework/"><strong>7 Question Landing Page Framework</strong></a>.</p>
<p>Get instant access to the free guide <a href="https://growthmarketer.co/framework/">here</a>.</p>
<figure><a href="https://growthmarketer.co/framework/"><img src="https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta.png" alt="" srcset="https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta.png 1920w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-300x169.png 300w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-1024x576.png 1024w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-768x432.png 768w, https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta-1536x864.png 1536w" data-lazy-src="https://growthmarketer.co/wp-content/uploads/2020/07/free-framework-cta.png"></a></figure>
<p>So, there you have it! With the landing page optimization tips I shared above <strong><em>and</em> my <a href="https://growthmarketer.co/framework/">7 Question Landing Page Framework</a></strong>, you’re well on your way to&nbsp;<strong>higher-converting landing pages</strong>.</p>
<p><em>PS: Sharing is caring. ❤️ If you found this article helpful, give it a quick share on Twitter. Here’s a ready-to-go tweet for you!</em> 👇</p>

</div></div>]]>
            </description>
            <link>https://growthmarketer.co/landing-page-optimization-tips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23840363</guid>
            <pubDate>Wed, 15 Jul 2020 01:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Heisenberg's Uncertainty Principle]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23840342">thread link</a>) | @keyboardman
<br/>
July 14, 2020 | https://leimao.github.io/blog/Heisenberg-Uncertainty-Principle/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Heisenberg-Uncertainty-Principle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In quantum mechanics, one of the key discoveries is that it is not always possible that we could measure two physical observables precisely, which is the Heisenberg’s general uncertainty principle.</p>



<p>We might have learned a special case of the Heisenberg’s general uncertainty principle from high school or college physics courses that the more precisely the position of some particle is determined, the less precisely its momentum can be predicted from initial conditions, and vice versa. In this case, the two physical observables are position and momentum.</p>



<p>Formally, the Heisenberg’s general uncertainty principle states that the product of the variances of two arbitrary hermitian operators on a given state is always greater than or equal to one-fourth the square of the expected value of their commutator. In formulas:</p>



<p>where $\mathbb{V}_{\psi}(\Omega_1)$ and $\mathbb{V}_{\psi}(\Omega_2)$ are using the notations from my previous <a href="https://leimao.github.io/blog/Quantum-Mean-Variance/">post</a>, $[\Omega_1, \Omega_2]$ is called the commutator of $\Omega_1$ and $\Omega_2$, and $[\Omega_1, \Omega_2] = \Omega_1 \Omega_2 - \Omega_2 \Omega_1$.</p>



<p>In this blog post, I would like to show a mathematical proof to Heisenberg’s general uncertainty principle.</p>

<h3 id="prerequisites">Prerequisites</h3>

<p>We would use the following four theorems and properties to prove Heisenberg’s general uncertainty principle.</p>

<h4 id="cauchyschwarz-inequality">Cauchy–Schwarz Inequality</h4>

<p>The Cauchy–Schwarz inequality states that for all vectors $u$ and $v$ of an inner product space it is true that</p>



<p>The proof could be found on <a href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Wikipedia</a>.</p>

<h4 id="imaginary-part-of-vector-inner-product">Imaginary Part of Vector Inner Product</h4>

<p>The imaginary part of the inner product of all vectors $u$ and $v$, $\text{Im}\big(\langle u, v \rangle\big)$, could be computed as</p>



<p>Assuming $u = a_1 + b_1 i$ and $v = a_2 + b_2 i$, where $a_1$, $a_2$, $b_1$, and $b_2$ are real (column) vectors.</p>





<p>It is trivial to see that</p>



<p>This concludes the proof.</p>

<h4 id="triangle-inequality">Triangle Inequality</h4>

<p>Let $z$ be any complex number, we have</p>



<p>This should be very straightforward to the people who are familiar with triangles and know the polar coordinate expression of complex numbers. We will skip the formal proof here.</p>

<h4 id="hermitian-property">Hermitian Property</h4>

<p>If A is a hermitian $n$-by-$n$ matrix, then for all $u, v^{\prime} \in \mathbb{C}$. we have</p>



<p>Using the property of hermitian matrix $A^{\dagger} = A$, we simply have</p>



<p>This concludes the proof.</p>

<h3 id="proof-to-heisenbergs-general-uncertainty-principle">Proof to Heisenberg’s General Uncertainty Principle</h3>

<p>Because $\Delta_{\psi}(\Omega) = \Omega - \langle \Omega \rangle_{\psi} I$ and $\Omega$ is a hermitian operator, therefore $\Delta_{\psi}(\Omega)$ is also a hermitian operator. Based on <a href="https://leimao.github.io/blog/Quantum-Mean-Variance/">the definition of variance</a>, using the hermitian property, we further have</p>



<p>We apply the Cauchy–Schwarz inequality to the left side of the Heisenberg’s general uncertainty principle,</p>



<p>We further apply the Triangle inequality,</p>



<p>We use the imaginary part of vector inner product,</p>



<p>We use the hermitian property again,</p>



<p>This concludes the proof.</p>

<h3 id="caveats">Caveats</h3>

<p>In Heisenberg’s general uncertainty principle, the commutator $[\Omega_1, \Omega_2] = 0$ suggests $\Omega_1 \Omega_2 = \Omega_2 \Omega_1$ and $\Omega_1 \Omega_2 | \psi \rangle = \Omega_2 \Omega_1 | \psi \rangle$. This means that the system states after the two sequential measures $\Omega_1 \Omega_2$ and $\Omega_1 \Omega_2$ are the same if $[\Omega_1, \Omega_2] = 0$. Otherwise, if $[\Omega_1, \Omega_2] \neq 0$ the system states after the two sequential measures $\Omega_1 \Omega_2$ and $\Omega_1 \Omega_2$ are not the same. If the commutator $[\Omega_1, \Omega_2] = 0$, Heisenberg’s general uncertainty principle suggests that the two physical observables that $\Omega_1$ and $\Omega_2$ are measuring would have not limit in precision.</p>



<p>In other expressions of Heisenberg’s general uncertainty principle, sometimes we would see the word “simultaneity”. How to understand the simultaneity in Heisenberg’s general uncertainty principle? Given measurement would change the system state, and it is almost impossible to achieve the absolute simultaneity in the time domain, what does the simultaneity mean in this case? Here simultaneity means that the order of measurement $\Omega_1$ and $\Omega_2$ do not change the final observation, as we tried hard to make them simultaneous and it is impossible to control the exact order of these two measurements. In short, simultaneity just means $[\Omega_1, \Omega_2] = 0$.</p>



<p>How to measure the variance of physical observable for a system state, as is shown at the left side of the inequality of Heisenberg’s general uncertainty principle? Measurement changes system state in quantum mechanics. We would need to create lots of clones of the system state. Once a system state is measured, it should be discarded and not be used for the measurement for the physical observable anymore. Measurement on the same system state means measurement on system state clones and not the exact system state.</p>

<h3 id="conclusions">Conclusions</h3>

<p>It is quite amazing that the Heisenberg’s general uncertainty principle could be derived in a such simple way. Unfortunately, the my college physics course instructor never showed a proof to this important principle.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://leimao.github.io/blog/Inner-Product/">Inner Product and Inner Product Space</a></li>
  <li><a href="https://leimao.github.io/blog/Quantum-Mean-Variance/">Expected Value and Variance from the Perspective of Quantum Theory</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Heisenberg-Uncertainty-Principle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23840342</guid>
            <pubDate>Wed, 15 Jul 2020 01:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$45k ARR in 10 months: Optimizations as a company of one]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23840321">thread link</a>) | @jnfr
<br/>
July 14, 2020 | https://lunchbag.ca/company-of-one | <a href="https://web.archive.org/web/*/https://lunchbag.ca/company-of-one">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<p><span>
				Written on <time datetime="2020-05-18 16:00:00 +0000 UTC">May 18, 2020</time>
			</span>
		</p>
		

<p>Hello! 👋 My name is Jen and I’m the founder, engineer, designer and customer support at <a href="https://lunchmoney.app/">Lunch Money</a>, a personal finance and budgeting web app.</p>

<p>In short, I am a company of one. I answer the customer support emails and I code and deploy new features. I also manage the <a href="https://developers.lunchmoney.app/" target="_blank">API docs</a> and <a href="https://support.lunchmoney.app/" target="_blank">knowledge base</a>, poke around the logs when there are issues, write the <a href="https://lunchmoney.app/sample_newsletter" target="_blank">bi-monthly newsletters</a> and I designed the logo!</p>

<p>As the company scales, so too must all aspects of my work which I break down into 4 parts: customer support, engineering, product and marketing.</p>

<p><strong>Finding opportunities for process optimization is honestly one of the more fun parts of running a business</strong>. I greatly attribute these to how I’ve been able to stay both solo &amp; sane up until now, currently with 600+ users and $45,000 ARR. In this post, I’m excited to share some of my most successful strategies along with anecdotes from my experience working on Lunch Money.</p>



<p>In the last 14 days, here’s what I got done across all departments:</p>

<ul>
<li><strong>Product:</strong> Launched an internal beta testers program and two sets of new features to test</li>
<li><strong>Engineering:</strong> Wrapped up a 2-week long refactor of some core components on the client-side</li>
<li><strong>Engineering:</strong> Launched a major feature: advanced transaction filters</li>
<li><strong>Engineering:</strong> Closed 13 tickets related to feature improvements and bug fixes</li>
<li><strong>Marketing:</strong> Sent out a newsletter outlining the latest new features</li>
<li><strong>Marketing:</strong> This blog post</li>
<li><strong>Marketing:</strong> Added new pages to the marketing site (<a href="https://lunchmoney.app/features/rules">Rules</a> and <a href="https://lunchmoney.app/features/collaboration">Collaboration</a>) and updated the icons in <a href="https://lunchmoney.app/features">Features</a></li>
<li><strong>Support:</strong> Received 239 inbound support tickets and sent out 358 emails</li>
</ul>

<p>What makes all this work bearable for me is the fact that there is so much variety (which, of course, is the spice of life!). I love being able to switch between tasks to keep the job interesting and my mind refreshed while still being productive overall.</p>

<p><em>Case in point: I just finished a major refactor and pushed out 2 major features to beta, so writing this blog post right now feels like a vacation for my brain.</em></p>

<p>To state the obvious, I enjoy being hyper-efficient (without burning myself out, of course). Even though I am a single person, I can still automate, optimize and parallelize processes.</p>



<h2 id="implement-safeguards">Implement safeguards</h2>

<p><i>Ah, the blissful beginnings of Lunch Money when I’d push code directly to production several times a day.</i></p>

<p>At 500+ users now, those days are long gone and I’ve since needed to adopt the more boring but responsible approach of implementing safeguards to prevent shipping faulty code.</p>

<p>For one, <b>I’ve been thoroughly reviewing my own code before every change</b>. Every major feature, improvement and bug fix lives in a feature branch that I still, by habit from the corporate days, prepend with <code>jen/</code>. After verifying everything works great locally, I make sure to take a break first, whether that’s working on a completely unrelated task, going for a meal or going to bed. The point of this is to ensure that I’m code reviewing with a clear head.</p>

<p>While adhering to these standards of code reviewing myself may add extra time to my overall process, it potentially saves hours of bug-fixing, answering related support tickets and self-loathing (I’m half-kidding here) down the line if I accidentally ship bad code.</p>

<center><blockquote><p lang="en" dir="ltr">New phase of Lunch Money– no more pushing major features straight to production 🤯😂 <a href="https://t.co/RYsz7BnU3L">https://t.co/RYsz7BnU3L</a></p>— Jen (@lunchbag) <a href="https://twitter.com/lunchbag/status/1256987437600927744?ref_src=twsrc%5Etfw">May 3, 2020</a></blockquote> </center>

<p><b>I also recently implemented an internal beta-testing program open to Lunch Money subscribers.</b> With more users accessing my app on a regular basis, the stakes are higher to ship a version that’s as bug-free as possible.</p>

<p>As an engineering team of one, it’s nearly impossible to always get it right the first time, despite having tests (what if I missed an edge case?) or testing locally extensively (how I think my users will use a feature is not always so).</p>

<p>The beta-testing program has provided some additional benefits. It’s nice to have a cohort of users with whom I can have a more candid conversation about Lunch Money and it’s also a great way to show users that their feedback is valued!</p>

<h2 id="automate-later-than-you-need-to">Automate later than you need to</h2>

<p>While automating tasks can save a lot of time in the long-term, it doesn’t always make sense to automate right off the bat.</p>

<p><img src="https://imgs.xkcd.com/comics/is_it_worth_the_time.png"><span>Obligatory XKCD comic (<a href="https://xkcd.com/1205/" target="_blank">link</a>)</span></p>

<p>Automating too late is not a bad thing. I’ll have done the manual work enough times to understand how to eventually automate the task and what edge cases to look out for. I equate it to doing a job yourself before hiring someone– it’s always better to grok the requirements first to some degree so you can understand how to best utilize who you’ve brought on (and appreciate them more!).</p>

<p>I manually triggered the emails for bi-monthly account summaries for months because I wasn’t confident the sending cadence was reasonable. After observing open rates and collecting user feedback, these are now automated to go out on the 5th &amp; 25th of every month.</p>

<p>Something that I’m glad I didn’t spend the time to automate at all was the referral program. If an existing user refers a new user and the new user subscribes to a plan, then both users will receive credit for 1 month.</p>

<p>In the end, the referral program only brought on 11 extra users. It was not a pain at all to manually process rewards for those who did. If I had spent time conjuring up all the edge cases and automating this process, it would not have been worth the time investment.</p>

<h2 id="keep-low-hanging-fruits-in-the-back-pocket">Keep low-hanging fruits in the back pocket</h2>

<p>In my task management system, I use a tag (🍏) to denote which tasks are low-hanging fruits. For the uninitiated, low-hanging fruits are quick tasks that are easy to knock out, such as one-liners or 5-minute fixes.</p>

<p><img src="https://media.giphy.com/media/YP1Jb0JNc7kqFDbdjm/giphy.gif"></p>

<p>I find that keeping these around and tackling them on days when you feel generally unmotivated can really help raise spirits. Still being able to get something completed and shipped is a great way to get out of a slump.</p>



<h2 id="timing-marketing-pushes">Timing marketing pushes</h2>

<p>At Lunch Money, a big part of the business is using the services of Plaid for bank syncing. Plaid charges on a monthly basis which means that if a user signs up on April 30, connects a bank account immediately and doesn’t end up subscribing at the end of their 14-day trial, they will charge me for this user in both April &amp; May’s invoices.</p>

<p>This realization coupled with my intense aversion to paying more than I need to has shaped a lot of practices at Lunch Money.</p>

<p>For one, the data retention policy used to be 30 days which means if your trial ends and you didn’t put in your billing information, your data will be deleted in 30 days. This certainly guarantees that I’ll be overpaying for churned users and is the reason why the data retention policy has since been revised to 5 days.</p>

<p>In total, a user who does not end up subscribing can spend up to 26 days in the Lunch Money system. This comprises of a 14-day trial, the potential for a 1 week trial extension and a 5 day grace period. Assuming enough users connect their bank accounts, the best way to minimize my costs for churned users is to ensure their lifetimes are within one calendar month.</p>

<p><img src="https://lunchbag.ca/uploads/calendar-1.png"></p>

<p>As a result, I always schedule marketing pushes such as blog posts and product launches in the first few days of the month. When I came to this realization, my next Plaid bill went down for the first time.</p>

<h2 id="merging-marketing-and-engineering-for-a-combo-win">Merging marketing and engineering for a combo win</h2>

<p>Taking this a step further, the perk of having a spike in new users is that their trial periods more-or-less overlap. Usually when a new user signs up, they will poke around the product and maybe send in a bug report, a feature request or another piece of feedback. If I reply and address their feedback by putting in a fix or shipping their requested feature within days, more often than not, they end up converting into a happy customer.</p>

<p>I’ve therefore identified the following cycle to maximize potential conversions from spikes in user signups:</p>

<p><img src="https://lunchbag.ca/uploads/gantt-2.png"></p>

<p>After a marketing push, let’s say a product launch, I will see an immediate increase in signups lasting about 3 days and then slowly trailing off.</p>

<p>Over the next few days, I’ll start hearing from these new users via support tickets. I prioritize responding to them and I get to work. Showing these users that I’m committed to improving Lunch Money based on their feedback is a great and honest sales tactic.</p>

<p>About 3 days before the initial wave of user trials ends, I wrap up my engineering sprint and send out a newsletter detailing the latest features and improvements. This re-enforces to new users that the product is under continuous development.</p>

<p>Finally, I have a drip campaign that automatically notifies users a few days before their trial expires and on the actual date of expiry. This period of time is when I typically see most users convert 🤞.</p>



<p>I used to think that if I were to hire someone, it would first be a customer support agent but I’ve since been moving away from that idea. Users are constantly surprised (in a good way!) when they realize the founder is responding to their bug reports or feature requests directly.</p>

<p><strong>Consistently providing great customer support is a long-term investment for Lunch Money</strong> as it is undoubtedly a great way to turn customers into champions. As I receive and respond to support tickets, I’m also able to identify and overhaul the common sources of trouble for users.</p>

<p>I’ve always believed that customer support would be the most important and the hardest part of the business to scale, especially if I have the goal of staying a company of one.</p>

<p>Corroborating data from <a href="https://emailmeter.com/">EmailMeter</a> and my database, it seems my changes are making a difference. Despite a growing user base, inbound support emails remain fairly steady!</p>

<p><img src="https://lunchbag.ca/uploads/screen-shot-2020-05-21-at-4-20-15-pm.png"><span>Handling support on my own should be sustainable at least for the foreseeable future!</span></p>

<h2 id="how-do-support-tickets-work-at-lunch-money">How do support tickets work at Lunch Money?</h2>

<p>A feedback button is located at the bottom right corner of every page. Clicking on it opens up a text area wherein users can submit feature requests, questions, bug …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lunchbag.ca/company-of-one">https://lunchbag.ca/company-of-one</a></em></p>]]>
            </description>
            <link>https://lunchbag.ca/company-of-one</link>
            <guid isPermaLink="false">hacker-news-small-sites-23840321</guid>
            <pubDate>Wed, 15 Jul 2020 01:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to Logical Arguments for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23840254">thread link</a>) | @jasonswett
<br/>
July 14, 2020 | https://www.codewithjason.com/logical-arguments-programmers/ | <a href="https://web.archive.org/web/*/https://www.codewithjason.com/logical-arguments-programmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<h2>What it means to be wrong and why it’s bad</h2>
<h3>Logical incorrectness</h3>
<p>It’s generally better to be right than to be wrong. Since there’s more than one way to be wrong, I want to be specific about the type of wrongness I want to address in this post before I move on.</p>
<p>The type of wrongness I’m interested in in this post is logical incorrectness, like two plus two equals five.</p>
<h3>The danger of being wrong</h3>
<p>Being right or wrong isn’t just an academic concern. In programming, being wrong often has concrete negative economic (and other) impacts. Developers who are often wrong will be much less efficient and burn up much more payroll cost and opportunity cost than developers who are wrong less often.</p>
<p>Being wrong is also not something that happens every great once in a while. Most humans are wrong about a whole bunch of stuff, a lot of the time, because that’s just human nature. Even really smart people are wrong about things a very nonzero amount of the time.</p>
<p>So I want to share some things we developers can do in order to be wrong less. But first let me share a concrete example of the kind of mistakenness I’m talking about.</p>
<h2>An example of being wrong</h2>
<h3>Bug: an appointment goes missing</h3>
<p>Let’s say I’m building some scheduling software. One of my users, Rachel, reports to me that yesterday she rescheduled someone’s appointment from July 1st at 10am to July 3rd at 10am. Today, Rachel looked at both the schedule for July 1st and July 3rd and the appointment isn’t present on either day. Apparently there’s a bug that removes appointments from the schedule when you try to reschedule them.</p>
<p>So I start to look at the code and see if I can find any evidence that this buggy behavior is present. Unfortunately, the code is very complicated, and my investigation takes a long time. My investigation lasts an entire day. By the end of the day I’ve made almost no progress toward fixing the bug.</p>
<h3>The bug was not the bug</h3>
<p>Unbeknownst to me, the thing I thought was the bug was not actually the bug. In fact, there was no bug. Between the time Rachel rescheduled the appointment and the time Rachel found the appointment missing, another user, Janice. deleted the appointment. There was in fact no bug at all. I was wrong. I wasted a whole day as a consequence of being wrong.</p>
<h2>How to be less wrong</h2>
<p>We developers can be wrong less of the time by studying <b>epistemology</b>. Epistemology is a branch of philosophy which deals with the acquisition of knowledge. Epistemology tells us how we can know, with certainty, what’s true and what isn’t.</p>
<p>More narrowly, we can study <b>logic</b>. Logic is a branch of philosophy that deals with a formal system of reasoning. One of the central ideas of logic is that of an <b>argument</b>. Arguments are the ideas we’ll be focusing on in this post.</p>
<h2>The definition of a logical argument</h2>
<p>An argument is a group of statements including one or more <b>premises</b> and one and only one <b>conclusion</b>. (I shamelessly stole this definition word-for-word from <a href="http://www.uky.edu/~rosdatte/phi120/lesson1a.htm">this web page</a>.)</p>
<p>Now let’s talk about what a premise is and what a conclusion is. As an aid I’ll share an example of a logical argument, henceforth just referred to as an “argument”.</p>
<h3>Argument example</h3>
<blockquote><p>
All fish live in water.<br>
All sharks are fish.<br>
Therefore, all sharks live in water.
</p></blockquote>
<p>This argument contains two premises. “All fish live in water” is a premise. “All sharks are fish” is also a premise.</p>
<p>This argument’s conclusion is of course “Therefore, all sharks live in water”. If it’s true that all fish live in water and it’s true that all sharks are fish, then it’s of course true that all sharks live in water.</p>
<h2>Validity and soundness</h2>
<p>Not all arguments are good ones. An argument can be <b>valid</b> or <b>invalid</b> and <b>sound</b> or <b>unsound</b>.</p>
<h3>Validity</h3>
<p>An argument is <b>valid</b> if the truth of the argument’s conclusion is logically connected to the argument’s premises. Our above fish/shark argument is a valid argument because, if the argument’s premises are true, its conclusion must necessarily be true. We could make the argument invalid by changing some things.</p>
<blockquote><p>
All fish live in water.<br>
All sharks are fish.<br>
Therefore, all sharks have fins.
</p></blockquote>
<p>This argument isn’t valid because its conclusion doesn’t logically flow from its premises. It happens to be true that all sharks have fins, but that fact isn’t true as a natural consequence of this argument’s premises, so the argument isn’t valid.</p>
<p>Note that validity doesn’t have anything to do with truth. An argument can be valid even if its premises aren’t true.</p>
<blockquote><p>
All turtles are invisible.<br>
Everyone has a turtle in their brain.<br>
Therefore, everyone has an invisible turtle in their brain.
</p></blockquote>
<p>The premises of the above argument aren’t true (at least as far as I know) but the argument is nonetheless valid.</p>
<h3>Soundness</h3>
<p>An argument is <b>sound</b> if the argument is valid and its premises are true. Our first argument (“all fish live in water, all sharks are fish, therefore all sharks live in water”) is sound because the argument is valid and its premises are true. <b>Sound arguments always have true conclusions.</b></p>
<p>Here’s another sound argument.</p>
<blockquote><p>
Every 20th century American president has been male.<br>
Richard Nixon was a 20th century American president.<br>
Richard Nixon was male.
</p></blockquote>
<p>Now comes the fun part, where we apply logical arguments to programming. </p>
<h2>Arguments in programming</h2>
<p>Read the following argument, keeping in mind the definitions of validity and soundness. See if you can tell if the argument is valid or invalid, sound or unsound. (If you don’t want a spoiler, don’t scroll past the argument until you’ve read the full argument.)</p>
<blockquote><p>
The site is unusually slow today.<br>
We performed a large deployment this morning.<br>
The deployment is the cause of the slowness.
</p></blockquote>
<p>This argument is <b>unsound</b>. Even if the premises are true, we can’t know based on the premises that the deployment was the cause of the slowness. How do we know it’s not a coincidence? For all we know, our site got featured on Hacker News and a big traffic spike is the cause of the slowness. Our argument is unsound because its conclusion isn’t necessarily true based on its premises. So, the reason that the argument is unsound is because even though its premises are true, its logic is invalid.</p>
<p>Here’s another example. Instead of just two premises, this argument has three.</p>
<blockquote><p>
Sometimes slowness is caused by code changes.<br>
Sometimes slowness is caused by traffic spikes.<br>
The site is unusually slow today.<br>
The cause of the slowness is either a code change or a traffic spike.
</p></blockquote>
<p>This argument is also unsound. There are more possible reasons for a site to be slow than just a code change or a traffic spike. For example, maybe our DevOps person killed half the servers in the middle of the night last night without our knowing it. So despite true premises, this argument, like the preceding one, is <b>invalid</b>.</p>
<p>Here’s another example.</p>
<blockquote><p>
The code in the most recent deployment introduced a bug.<br>
The only thing that went out in the most recent deployment was Josh’s code.<br>
Josh’s code caused the bug.
</p></blockquote>
<p>As long as this argument’s premises are true, this argument is <b>sound</b>. If we know for sure that the most recent deployment introduced a bug, and we know for sure that the only thing that went out in the most recent deployment was Josh’s code, then it does logically follow that Josh’s code caused the bug.</p>
<p>Here’s a final example. This one is a little more detailed than the previous ones.</p>
<blockquote><p>
At 10:32am, a duplicate $20 charge appeared in the system for patient #5225.<br>
Also at 10:32am, Jason carelessly performed a manual actual action on patient #5225, an action that was related to that patient’s $20 charge.<br>
Jason caused the duplicate charge.
</p></blockquote>
<p>This is another <b>unsound</b> argument. Even though it sounds likely that my action caused the duplicate charge, it’s not logically valid to make that inference based on the premises. The invalidity is perhaps not obvious, but can be made more apparent by asking the question: “Are there any possible circumstances under which Jason’s manual action would NOT have created the duplicate charge?” For example, it’s possible that the card could have accidentally been run twice, and the timing was a coincidence.</p>
<p>I have empirical proof of the invalidity of the above argument because this is a real-life example and, in fact, my action was not the cause of the duplicate charge. Part of what helped me determine this is the following sound argument.</p>
<blockquote><p>
It’s impossible to create a charge without having a patient’s credit card information.<br>
It would have been physically impossible for me to involve the patient’s credit card information when I performed my manual action because we don’t store credit card information in the system.<br>
My action couldn’t have created the duplicate charge.
</p></blockquote>
<p>The preceding sound argument (and remember, sound arguments always have true conclusions) led me to investigate more deeply. What I ultimately discovered was that the patient’s card did in fact get run twice and the timing was just a coincidence. Why wasn’t it obvious from the outset that the patient’s card was run twice? Because we use Authorize.net as a payment gateway, and apparently sometimes the Authorize.net API returns a failure response even when the charge was successfully incurred, so from the perspective of our application there was only one charge that got successfully created, even though in reality there were two.</p>
<h2>Good luck with your arguments</h2>
<p>Next time you’re confronted with a programming mystery, I invite you to frame your mystery in terms of arguments. Write down your premises, and make sure to write down only premises that are true, otherwise your argument will be unsound. Then try to come up with a conclusion and make sure that your conclusion necessarily follows from your premises so that your argument is valid. If your argument is valid and sound, your conclusion will necessarily be true.</p>
<p>If you’d like to have an argument with me on Twitter, you can find me <a href="https://twitter.com/JasonSwett">here</a>.</p>
					</div></div>]]>
            </description>
            <link>https://www.codewithjason.com/logical-arguments-programmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23840254</guid>
            <pubDate>Wed, 15 Jul 2020 01:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SHA-256 in Excruciating Detail]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23839895">thread link</a>) | @lanecwagner
<br/>
July 14, 2020 | https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>SHA-2 (Secure Hash Algorithm 2), of which SHA-256 is a part, is one of the most popular <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hashing algorithms</a> out there. In this article, we are going to break down each step of the algorithm as simple as we can and work through a real-life example by hand.</p>



<p>SHA-2 is known for its security (it hasn’t <a aria-label="undefined (opens in a new tab)" href="https://shattered.io/" target="_blank" rel="noreferrer noopener">broken down like SHA-1</a>), and its speed. In cases where <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">keys are not being generated</a>, such as mining Bitcoin, a fast hash algorithm like SHA-2 often reigns supreme.</p>



<h2><span id="What_Is_a_Hash_Function">What Is a Hash Function?</span>
</h2>



<p>If you want to read more about hash functions in general, do so <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">here</a>. That said, in order to move forward let’s recap three of the main purposes of a hash function:</p>



<ul>
<li>To scramble data deterministically</li>
<li>To accept input of any length and output a fixed-length result</li>
<li>To irreversibly manipulate data. The input can’t be derived from the output</li>
</ul>
<h2><span id="SHA-2_vs_SHA-256">SHA-2 vs SHA-256</span>
</h2>



<p>SHA-2 is an <em>algorithm</em>, a generalized idea of how to hash data. SHA-256 sets additional constants that define the SHA-2 algorithm’s behavior. One such constant is the output size. “256” and “512” refer to their respective output digest sizes in bits.</p>



<p>Let’s step through an example of SHA-256.</p>



<h2><span id="SHA-256_hello_world_Step_1_-_Pre-Processing">SHA-256 “hello world”; Step 1 – Pre-Processing</span>
</h2>



<ul><li>Convert “hello world” to binary:</li></ul>
<pre><code>01101000 01100101 01101100 01101100 01101111 00100000 01110111 01101111
01110010 01101100 01100100</code></pre>



<ul><li>Append a single 1:</li></ul>
<pre><code>01101000 01100101 01101100 01101100 01101111 00100000 01110111 01101111
01110010 01101100 01100100 1</code></pre>



<ul><li>Pad with 0’s until data is a multiple of 512, less 64 bits (448 bits in our case):</li></ul>
<pre><code>01101000 01100101 01101100 01101100 01101111 00100000 01110111 01101111
01110010 01101100 01100100 10000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
</code></pre>



<ul><li>Append 64 bits to the end, where the 64 bits are a <a href="https://en.wikipedia.org/wiki/Endianness">big-endian</a> integer representing the length of the original input in binary. In our case, 88, or in binary, “1011000”.</li></ul>
<pre><code>01101000 01100101 01101100 01101100 01101111 00100000 01110111 01101111
01110010 01101100 01100100 10000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 01011000</code></pre>



<p>Now we have our input, which will always be evenly divisible by 512.</p>



<h2><span id="Step_2_-_Initialize_Hash_Values_h">Step 2 – Initialize Hash Values (h)</span>
</h2>



<p>Now we create 8 hash values. These are hard-coded constants that represent the first 32 bits of the fractional parts of the square roots of the first 8 primes: 2, 3, 5, 7, 11, 13, 17, 19</p>



<pre><code>h0 := 0x6a09e667
h1 := 0xbb67ae85
h2 := 0x3c6ef372
h3 := 0xa54ff53a
h4 := 0x510e527f
h5 := 0x9b05688c
h6 := 0x1f83d9ab
h7 := 0x5be0cd19</code></pre>



<h2><span id="Step_3_-_Initialize_Round_Constants_k">Step 3 – Initialize Round Constants (k)</span>
</h2>



<p>Similar to step 2, we are creating some constants (<em>Learn more about constants and when to use them <a href="https://qvault.io/2019/10/14/constants-in-go-vs-javascript-and-when-to-use-them/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">here</a></em>). This time, there are 64 of them. Each value (0-63)  is the first 32 bits of the fractional parts of the cube roots of the first 64 primes (2 – 311).</p>



<pre><code>0x428a2f98 0x71374491 0xb5c0fbcf 0xe9b5dba5 0x3956c25b 0x59f111f1 0x923f82a4 0xab1c5ed5
0xd807aa98 0x12835b01 0x243185be 0x550c7dc3 0x72be5d74 0x80deb1fe 0x9bdc06a7 0xc19bf174
0xe49b69c1 0xefbe4786 0x0fc19dc6 0x240ca1cc 0x2de92c6f 0x4a7484aa 0x5cb0a9dc 0x76f988da
0x983e5152 0xa831c66d 0xb00327c8 0xbf597fc7 0xc6e00bf3 0xd5a79147 0x06ca6351 0x14292967
0x27b70a85 0x2e1b2138 0x4d2c6dfc 0x53380d13 0x650a7354 0x766a0abb 0x81c2c92e 0x92722c85
0xa2bfe8a1 0xa81a664b 0xc24b8b70 0xc76c51a3 0xd192e819 0xd6990624 0xf40e3585 0x106aa070
0x19a4c116 0x1e376c08 0x2748774c 0x34b0bcb5 0x391c0cb3 0x4ed8aa4a 0x5b9cca4f 0x682e6ff3
0x748f82ee 0x78a5636f 0x84c87814 0x8cc70208 0x90befffa 0xa4506ceb 0xbef9a3f7 0xc67178f2</code></pre>



<h2><span id="Step_4_-_Chunk_Loop">Step 4 – Chunk Loop</span>
</h2>



<p>The following steps will happen for each 512-bit “chunk” of data from our input. In our case, because <em>“hello world”</em> is so short, we only have one chunk. At each iteration of the loop, we will be mutating the hash values h0-h7, which will be the final output.</p>



<h2><span id="Step_5_-_Create_Message_Schedule_w">Step 5 – Create Message Schedule (w)</span>
</h2>



<ul><li>Copy the input data from step 1 into a new array where each entry is a 32-bit word:</li></ul>
<pre><code>01101000011001010110110001101100 01101111001000000111011101101111
01110010011011000110010010000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000001011000</code></pre>



<ul><li>Add 48 more words initialized to zero, such that we have an array <strong>w[0…63]</strong>
</li></ul>
<pre><code>01101000011001010110110001101100 01101111001000000111011101101111
01110010011011000110010010000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000001011000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
...
...
00000000000000000000000000000000 00000000000000000000000000000000</code></pre>



<ul>
<li>Modify the zero-ed indexes at the end of the array using the following algorithm:</li>
<li>For <strong>i</strong> from w[16…63]:<ul>
<li>s0 = (w[i-15] rightrotate 7) xor (w[i-15] rightrotate 18) xor (w[i-15] rightshift 3)</li>
<li>s1 = (w[i- 2] rightrotate 17) xor (w[i- 2] rightrotate 19) xor (w[i- 2] rightshift 10)</li>
<li>w[i] = w[i-16] + s0 + w[i-7] + s1</li>
</ul>
</li>
</ul>
<p>Let’s do w[16] so we can see how it works:</p>



<pre><code>w[1] rightrotate 7:
  01101111001000000111011101101111 -&gt; 11011110110111100100000011101110
w[1] rightrotate 18:
  01101111001000000111011101101111 -&gt; 00011101110110111101101111001000
w[1] rightshift 3:
  01101111001000000111011101101111 -&gt; 00001101111001000000111011101101

s0 = 11011110110111100100000011101110 XOR 00011101110110111101101111001000 XOR 00001101111001000000111011101101

s0 = 11001110111000011001010111001011

w[14] rightrotate 17:
  00000000000000000000000000000000 -&gt; 00000000000000000000000000000000
w[14] rightrotate19:
  00000000000000000000000000000000 -&gt; 00000000000000000000000000000000
w[14] rightshift 10:
  00000000000000000000000000000000 -&gt; 00000000000000000000000000000000

s1 = 00000000000000000000000000000000 XOR 00000000000000000000000000000000 XOR 00000000000000000000000000000000

s1 = 00000000000000000000000000000000

w[16] = w[0] + s0 + w[9] + s1

w[16] = 01101000011001010110110001101100 + 11001110111000011001010111001011 + 00000000000000000000000000000000 + 00000000000000000000000000000000

// addition is calculated modulo 2^32

w[16] = 00110111010001110000001000110111


</code></pre>



<p>This leaves us with 64 words in our message schedule (w):</p>



<pre><code>01101000011001010110110001101100 01101111001000000111011101101111
01110010011011000110010010000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000000000000
00000000000000000000000000000000 00000000000000000000000001011000
00110111010001110000001000110111 10000110110100001100000000110001
11010011101111010001000100001011 01111000001111110100011110000010
00101010100100000111110011101101 01001011001011110111110011001001
00110001111000011001010001011101 10001001001101100100100101100100
01111111011110100000011011011010 11000001011110011010100100111010
10111011111010001111011001010101 00001100000110101110001111100110
10110000111111100000110101111101 01011111011011100101010110010011
00000000100010011001101101010010 00000111111100011100101010010100
00111011010111111110010111010110 01101000011001010110001011100110
11001000010011100000101010011110 00000110101011111001101100100101
10010010111011110110010011010111 01100011111110010101111001011010
11100011000101100110011111010111 10000100001110111101111000010110
11101110111011001010100001011011 10100000010011111111001000100001
11111001000110001010110110111000 00010100101010001001001000011001
00010000100001000101001100011101 01100000100100111110000011001101
10000011000000110101111111101001 11010101101011100111100100111000
00111001001111110000010110101101 11111011010010110001101111101111
11101011011101011111111100101001 01101010001101101001010100110100
00100010111111001001110011011000 10101001011101000000110100101011
01100000110011110011100010000101 11000100101011001001100000111010
00010001010000101111110110101101 10110000101100000001110111011001
10011000111100001100001101101111 01110010000101111011100000011110 10100010110101000110011110011010 00000001000011111001100101111011
11111100000101110100111100001010 11000010110000101110101100010110</code></pre>



<h2><span id="Step_6_-_Compression">Step 6 – Compression</span>
</h2>



<ul>
<li>Initialize variables <strong>a, b, c, d, e, f, g, h</strong> and set them equal to the current hash values respectively. <strong>h0, h1, h2, h3, h4, h5, h6, h7</strong>
</li>
<li>Run the compression loop. The compression …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/</a></em></p>]]>
            </description>
            <link>https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839895</guid>
            <pubDate>Wed, 15 Jul 2020 00:38:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polygon Crest – open-source 3D polygonal editor]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23839480">thread link</a>) | @app4soft
<br/>
July 14, 2020 | http://ysflight.in.coocan.jp/polygoncrest/e.html | <a href="https://web.archive.org/web/*/http://ysflight.in.coocan.jp/polygoncrest/e.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div bordercolor="#111111" width="100%" id="AutoNumber1">
        <tbody><tr>
          <td>
          
          <h2>
            What's Polygon Crest?</h2>
          <p>
            This program is a polygon editor. Maybe more commonly called a 
			polygon modeler. You can call whichever comfortable for you. The 
			main purpose is to build aircraft and ground visual models for YS 
			FLIGHT SIMULATOR, but you can use it for making general polygonal 
			models. If you make a correct solid model, you can export the data 
			for 3D printing, for example. I wanted to make it easy to create 
			aircraft models, so this program can quickly make a popular 
			airfoils, and extrude along the wing leading and trailing edges. It 
			also has basic boolean operations and rounding functions as well.
            </p>
		  <p>
            <a href="http://ysflight.in.coocan.jp/polygoncrest/scrnshot/cessna172-english.png">
			<img height="170" src="http://ysflight.in.coocan.jp/polygoncrest/scrnshot/cessna172-english_small.png" width="320" xthumbnail-orig-image="scrnshot/cessna172-english.png"></a></p>
		  <h2>
            How to use?</h2>
		  <p>
            Usage can be found in the following URLs.</p>
		  <p>
            <a href="http://polycre.help.en.ysflight.com/">
			<strong>http://polycre.help.en.ysflight.com/</strong></a> (English)</p>
		  <p>
            <a href="http://polycre.help.jp.ysflight.com/">
			<strong>http://polycre.help.jp.ysflight.com/</strong></a> (Japanese)</p>
		  <h2>
            Donations are welcome</h2>
		  <p>
            Polygon Crest is a fre and open-source program.&nbsp; Therefore, you can 
			use it for free of charge.&nbsp; However, I appreciate if you donate some 
			money for supporting the development.&nbsp; For making donation, please 
			send some money via PayPal using the following button.
            </p>
		  
<!--webbot bot="HTMLMarkup" endspan i-checksum="11026" -->
		  <p>
            I will use the donated money for upgrading my developing 
			environment, buying books for learning new programming techniques, 
			maintaining and adding contents in YSFLIGHT.COM.&nbsp; Thank you for your 
			support!
            </p>
		  <h2>
            Download</h2>
		  <p>
            <strong>Version 20150329</strong></p>
		  <p>
            <strong>
			<a href="http://download.cnet.com/Polygon-Crest/3000-6677_4-76169623.html">[For MacOSX 
			&amp; Linux]</a> (Linux binary is also included in the Mac OSX 
			package.)</strong></p>
		  <p>
            <strong>
			<a href="http://download.cnet.com/Polygon-Crest-for-Windows/3000-6677_4-76170331.html">[For Windows]</a></strong></p>
		  <h2>
            Updates</h2>
          <p>
          <strong>2016/02/21</strong></p>
		  <ul>
			  <li>Digitally signed Mac OSX binary.&nbsp; You should be able to 
			  run the program without warning.&nbsp; If your setting only allows 
			  App Store applications, you will need to change the security 
			  setting to allow App Store &amp; digitally signed by known developers 
			  (or something like that.)</li>
			  <li>Linux binary is bundled in the Mac OSX package.&nbsp; You can 
			  run LinuxInstaller.py in the zip file, which will create an icon 
			  on the desktop.&nbsp; If it works well, I'm going to do the same 
			  for YSFLIGHT.</li>
			  <li>Now YSFLIGHT shares the same data structure of dynamic model 
			  (.DNM) with PolygonCrest.&nbsp; From the next version on, if you 
			  can open the .DNM file with PolygonCrest, it should (is supposed 
			  to) appear the same in YSFLIGHT.</li>
			  <li>Imprinting:&nbsp; You can imprinting a polygon or a constraint 
			  edge to a nearby polygons by selecting a polygon and then select 
			  Edit-&gt;Projection-&gt;Imprinting.</li>
			  <li>Sewing:&nbsp; You can select two vertices and select 
			  Edit-&gt;Local Operations-&gt;Sew between two vertices.&nbsp; Vertices 
			  will be created between the selected vertices and polygons along 
			  the path will be split.</li>
		  </ul>
		  <p>
          <strong>2015/05/23</strong></p>
		  <ul>
			  <li>Polygon Crest for Linux: You can really use the system 
			  clipboard.&nbsp; (Now it's closed inside Polygon Crest program)</li>
			  <li>Input/Output of Wavefront .OBJ format files.</li>
			  <li>Add "Recently Used Files"</li>
			  <li>Color Palette dialog.</li>
			  <li>Polygon Crest for Windows: Erased a false error message on 
			  start up.&nbsp; (It only appeared when I build in a release 
			  configuration, and I didn't notice :-P)</li>
		  </ul>
		  <p>
          <strong>2014/07/19</strong></p>
		  <p>
          First release!&nbsp; Version 20140716.&nbsp; I wanted to add more 
		  features.&nbsp; But, if I wait until I finish all the features that I 
		  want to add, it's going to take infinity.&nbsp; I decided to make it 
		  open now.&nbsp; I'll keep developing and newer versions will be 
		  available.</p>
          
          </td>
        </tr>
        </tbody></div></div>]]>
            </description>
            <link>http://ysflight.in.coocan.jp/polygoncrest/e.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839480</guid>
            <pubDate>Tue, 14 Jul 2020 23:42:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tragic RAF Pilot's Grave Discovered in Albania]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23839399">thread link</a>) | @Hansig_jw
<br/>
July 14, 2020 | https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>This story is about a small. isolated Albanian village which kept a deadly secret for almost 50 years during the oppressive, communist regime of Enver Hoxha. The secret they kept lay unmarked and untended in the local village graveyard. So, what was this secret that if it had leaked out could have had potentially deadly consequences for the village?</p>
<p>The story developed thus:</p>
<p><span>During the long and hot Albanian summer of 1998, the embassy was contacted by the Mayor of Saranda. </span></p>
<p><span>Saranda was a medium-sized coastal town and popular holiday resort in the south of the country located near the Greek border and lying directly opposite the island of Corfu. The Mayor said that he had been contacted by a resident of the village of Drovian which was located in the mountains just above Saranda. </span></p>
<p><span>Apparently, this villager, his family and the whole village had been living with a secret for decades.</span></p>
<p><span>It transpired that during the second World War when the Italians invaded Albania, an RAF fighter plane, during the course of a dogfight, had collided with an Italian machine and the badly burned British pilot had baled out. </span></p>
<p><span>He landed just outside the village and despite the tender ministrations of the villagers, had tragically died from his wounds. The villagers then buried him in an unmarked grave in the church grounds as they did not want the Italians to find him.</span></p>
<p><span>After the war, with the advent of the brutal and repressive Hoxha communist regime and his denial of the extensive British military aid given to him in terms not only of material but also of British lives in defeating his axis occupiers and liberating his country, the villagers did not dare inform anyone outside the village about the hidden British grave in case they would be taken for collaborators. </span></p>
<p><span>So there he lay for over fifty years, this unknown British airman. It is remarkable that the villagers were able to keep this secret for so long under such trying circumstances. Informers and spies were everywhere during the life of this brutal regime. One word of this leaking out to the authorities, would have meant instant, draconian and possibly deadly punishment for the whole village.</span></p>
<p><span>The Ambassador asked me if I would like to take this on as a project as I was ex-Royal Air Force to which I readily agreed. Therefore, my first port of call was to the Commonwealth War Graves Commission (CWGC) in Maidenhead in the UK. </span></p>
<p><span>This organisation is responsible for the upkeep and maintenance of all British war graves worldwide. They were more than happy to assist and I passed on to them all the details of the case that we had managed to glean so far from the Mayor’s office in Saranda.&nbsp;</span></p>
<p><span>CWGC researched the case and eventually got back to me. They confirmed to me that a British aircraft had indeed been lost over that particular area of Albania. What they proposed was that the grave should remain for the time being in situ in the village and not moved to the small CWGC cemetery in Tirana until a full investigation could be carried out.</span></p>
<p><span>Some weeks later, CWGC contacted me again and confirmed that they had identified from RAF after action reports and accounts from surviving members of the pilot’s RAF Squadron that he was Flying Officer Harold Sykes aged 22 and sadly recently married. </span></p>
<p><span>They proposed sending out an inscribed headstone to Tirana and asked if we could transport it down to Drovian and erect it. I reassured them that this was possible and that we would carry out the task and n</span><span>ot long afterwards, an inscribed headstone from CWGC arrived crated through the diplomatic bag.<img src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?resize=300%2C197&amp;ssl=1" alt="" width="300" height="197" srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?resize=300%2C197&amp;ssl=1 300w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?w=550&amp;ssl=1 550w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?resize=300%2C197&amp;ssl=1 300w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?w=550&amp;ssl=1 550w" data-lazy-src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/sykes_2.jpg?resize=300%2C197&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></span></p>
<p>I then contacted the Mayor in Saranda and told him we would be on our way the next morning and that we proposed to overnight in Saranda before driving up to Drovian the next day to erect the headstone.</p>
<p><span>So, on a cold, clear, crisp winter morning, my driver, a locally employed Embassy interpreter and I set off by road for the 300 Km trip down south. We took the coast road, which was deemed safer and eventually reached Saranda late that afternoon. We met the Mayor and explained to him what we proposed to do. After spending the night in a small hotel, we set off the next morning for the village in the mountains accompanied by the Mayor.</span></p>
<p><span>Unfortunately, because of the steep and unstable mountainous terrain, even our 4 wheel drive Landcruisers were not able to negotiate the tracks and terrain that would lead us to Drovian. Thankfully, the Mayor somehow managed to contact a local corn supplier who agreed to hire out six of his mules to us and off we set with our cargo, not a comfortable experience!</span></p>
<p><span>Finally, after about 2 jolting hours in the saddle, we reached the village where, to our delight, the villagers, who had been forewarned of our arrival by the Mayor’s office had very kindly laid on a delicious, communal lunch.</span></p>
<p><span> After lunch we all took a stroll around the small village. The villagers obviously took great care of their fields and their homes. Everything was clean and neat and the fields were well tended though the vista was blighted by the usual blot on the landscape of the ever-present rash of pillboxes, even here high up in the mountains (Hoxha, who was obsessed with the fear of foreign invasion, had constructed over a million such concrete pillboxes throughout the country). </span></p>
<p><span>When asked why they just did not demolish these pillboxes, the villagers said they were in fact very useful for storing their tobacco crop, which I suppose was a very pragmatic and sensible use of these concrete bubbles.</span></p>
<p><span>They then led us to the courtyard of a small building which was called the Church of the 12 Apostles where the burial site was located. It transpired that Harold was not alone. Next to his grave was the grave of an unknown Greek soldier who the villagers had also buried after finding his remains in the hills towards the end of the war. They told us that they had also informed the Greek embassy in Tirana about the soldier and their embassy was still in the process of trying to identify him.</span></p>
<p><span>We offloaded the headstone from the vehicle and uncrated it. With the help of a couple of villagers, we cemented it firmly at the head of the grave. It felt appropriate I say a prayer over the grave which I did. It was touching to note that the villagers who had gathered at the site also paid their respects in a dignified manner with a couple of the women laying colourful, wild flowers on the grave. I then took some photographs.</span><span>&nbsp;<img src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?resize=214%2C300&amp;ssl=1" alt="Fg Off Sykesn headstone" width="214" height="300" srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?resize=214%2C300&amp;ssl=1 214w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?w=400&amp;ssl=1 400w" sizes="(max-width: 214px) 100vw, 214px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?resize=214%2C300&amp;ssl=1 214w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?w=400&amp;ssl=1 400w" data-lazy-src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1.jpg?resize=214%2C300&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></span></p>
<p><span>Before taking our leave of the village, one of the elders produced a burlap sack which he asked me to take back with me. Inside were fragments of old uniform and bits of parachute and harness, which had belonged to the airman.</span></p>
<p><span>Taking our leave of the villagers, we remounted our mules for the trip back down the mountains to our vehicles. I said goodbye to the Mayor and thanked him for all his assistance and then set off on the 300 Km return journey to Tirana.</span></p>
<p><span>The next day, back in the Embassy, I wrote up my report for the CWGC and also despatched the various items given to me in Drovian. I learnt later that my full report, photographs and the returned items had been given to surviving members of Harold’s family.&nbsp;</span></p>
<p><span>To this day (as far as I know) Harold still lies in that mountainside village. At the time CWGC agreed that he could remain there and whether at some future date he was moved to the small CWGC cemetery in Tirana, I have no knowledge.</span></p>
<p>This was the first of my two discoveries and resolutions involving missing RAF airmen. My second was a few years later in North Korea where, working closely with the north Korean military, we found the remains of an RAF pilot who had gone missing during the Korean war. At the time he had been seconded to the United States Air Force when his jet had been shot down near Pyongyang.</p>
<p>I will be doing a full post on this in the weeks to come.</p>
<p><em><strong>*Image of Flying Officer Sykes RAF courtesy of Averil Dorego*</strong></em></p>
  
              </article></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839399</guid>
            <pubDate>Tue, 14 Jul 2020 23:31:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Networked games: Playing in the past or future]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23839390">thread link</a>) | @zdw
<br/>
July 14, 2020 | https://www.evanjones.ca/network-game-simulation.html | <a href="https://web.archive.org/web/*/https://www.evanjones.ca/network-game-simulation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>[ 2020-July-14 10:46 ]</h3>
<p>A few years ago I was fascinated by how network games worked after reading a <a href="https://gafferongames.com/post/introduction_to_networked_physics/">series of articles about Networked Physics that includes some great demo movies</a>. I didn't really understand it. How can the game be playable, when the client and server are separated by approximately 100 ms of network delay? I decided to create a small demo of a networked game, to try and figure it out. However, like most projects I start, I abandoned it after spending a few hours on it. I rediscovered it a couple months ago, and got it to a reasonabl y "finished" state. <a href="https://www.evanjones.ca/network-game-simulation-demo.html">The demo shows the client and server state of a "game"   and lets you adjust the simulated latency</a>. This gave me a huge appreciation for clever tricks used to create fast-paced games that are playable over the Internet. In particular, I find it amazing that the clients are playing the game either in the past or the future, but it still works to create an interactive experience.</p>


<h2>Local latency</h2>
<p>One important lesson is that even a local game has latency. Let's ignore things like <a href="https://danluu.com/keyboard-latency/">keyboard latency</a> or <a href="https://pcmonitors.info/articles/factors-affecting-pc-monitor-responsiveness/">display latency</a>, each of which can easily add ~50 ms of delay. Let's just consider the game loop, which involves reading input, simulating the world, then drawing the world. This means after a button press arrives, the game will not respond until the next frame. Many displays can show a maximum of 60 frames per second (FPS), which translate to an average of 8 ms of delay (uniformly distributed between 0-16 ms). That initial frame also might just register "player is moving forward", but won't actually move the player forward until the next frame, so that means it can be up to 33 ms between when you pressed the button and see a change. Many games run slower than that, which scales up the delay. The conclusion is that even that "fast" reaction you get in a local game is not instantaneous, and may actually have approximately 100 ms delay between inputs and seeing an update.</p>

<h2>No prediction: playing in the past</h2>
<p>The simplest network game model, and the one that is implemented in my demo, is to have the client send commands to the server, and have the server send state back to the client, which displays them. With this implementation, when you press a button to take an action, like moving forward, it takes one entire network round trip before you see the movement. The initial versions of Doom and Quake used this approach, because they were designed for local networks and not the Internet. Quake was released just when home Internet was becoming widespread, and people did play over the Internet anyway, which only worked if the network round trip time was low. With my demo, this feels playable up to about 50 ms of one-way latency.</p>

<p>The most interesting part to me is this means players are playing the game in the past, when compared to the server state. I've drawn the diagram below in an attempt to describe what I mean. Both the client and server start the game at the same instant, <code>t=0</code>. At this time, the player presses the "move forward" button, so the client sends this message to the server. It takes one time unit/frame to get to the server, so at t=1, the server receives and processes the button press. At t=2 the server simulates the player moving forward one unit, and sends the state to the client. Finally, at t=3 the client receives the updated position displays it. This means the client's display was updated at t=3, instead of t=1 in the "local" version. This is delayed by one network round trip time (2 units in this example). At any instant, the client is one time unit behind the server, which is what I mean that the game is being played in the past.</p>

<p><img alt="no prediction diagram" height="361" src="https://www.evanjones.ca/network-game-simulation-past.svg" width="703"></p>

<p>When I experiment with moving and firing in my simulation, I think I can notice even a small amount of latency. However, I feel like I can adapt to it and the game is playable up to about 50 ms. Above that point, it starts to feel "impossibly" slow and really unpleasant. This means this simple simulation will only work for physically "close" players. From my home connection in New York City to Google Cloud's data centers as measured by <a href="http://gcpping.com/">gcpping.com</a>, I can only play games hosted on the eastern half of North America (Virgina, South Carolina, and Montreal).</p>

<h2>Prediction: playing in the future</h2>
<p>To hide the effects of latency, modern games predict the effect of their actions. As a result, clients are now in the future, rather than in the past. Let's reconsider our example, where a game starts and a player immediately starts moving forward, shown below. In the first instant, the client processes the move forward command, so it sends it to the server. In the next instant, the client predicts moving forward one step, and the server receives the message. In the second instant (t=2), the client has predicted moving forward another step. The server simulates the movement and sends the "official" state. In the next instant (t=3), the client receives the confirmation that the user did move forward. The tricky part is the client needs to decide if this agrees with its simulation. If it does not, then it needs to "rewind" its simulation, and replay its local actions again.</p>

<p><img alt="with prediction diagram" height="358" src="https://www.evanjones.ca/network-game-simulation-future.svg" width="700"></p>

<p>With client-side prediction, the time between an input and a display update is the as a local game. However, the client is ahead of the server's "real" state by one network delay, which is what I mean that it is playing in the future.</p>

<h2>Further reading</h2>
<p>I am not an expert on this subject, since I have never worked in games. If you want to learn more, you should read about how real games make this work.</p>

<ul>
<li><a href="https://github.com/evanj/netgamesim">netgamesim source code</a>: The code for my demo simulator.</li>
<li><a href="https://gafferongames.com/post/introduction_to_networked_physics/">Networked Physics</a>: The original series of articles that got me interested. See the <a href="https://gafferongames.com/categories/networked-physics/">series index</a> for more details.</li>
<li><a href="https://www.gabrielgambetta.com/client-server-game-architecture.html">Fast-Paced Multiplayer</a>: Another series describing how this works.</li>
<li><a href="https://fabiensanglard.net/quake3/network.php">Quake 3 Networking</a>: A description of how Quake 3 worked from reviewing the source code. It is instructive to compare this to how <a href="https://fabiensanglard.net/quakeSource/quakeSourceNetWork.php">the original QuakeWorld worked</a>, since it added client-side prediction to Quake.</li>
<li><a href="https://developer.valvesoftware.com/wiki/Latency_Compensating_Methods_in_Client/Server_In-game_Protocol_Design_and_Optimization">Latency Compensating Methods in Client/Server Games</a>: Notably this article describes how Half Life makes "instant hit" weapons work with client-side prediction, and how this is a game design choice since there are some fundamental necessary trade-offs.</li>
</ul>

</div></div>]]>
            </description>
            <link>https://www.evanjones.ca/network-game-simulation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839390</guid>
            <pubDate>Tue, 14 Jul 2020 23:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Remote Work Office Setup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23839328">thread link</a>) | @rchaudhary
<br/>
July 14, 2020 | https://anjuansimmons.com/blog/my-remote-work-office-setup | <a href="https://web.archive.org/web/*/https://anjuansimmons.com/blog/my-remote-work-office-setup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-office-header.jpg" alt="My remote office setup helps me do my best work no matter where the other members of my team are located."></a></dt>

<dd>My remote office setup helps me do my best work no matter where the other members of my team are located.</dd>
</dl>

<p>I’ve worked remotely on and off for several years, and I’ve been lucky to work for a fully remote company over the past nine months. It’s glorious, and I don’t think I can ever be convinced to physically work in a corporate office ever again.</p>

<p>I’m in Zoom meetings for work several hours each day, and I also do a fair amount of speaking at virtual conferences. That means I appear on other people’s screens quite often, and I regularly get asked about my remote office setup. The feedback I’ve generally received is that my audio and video are notable for their clarity and crispness. This high quality is due to the investments I’ve made into building out my home office, and I’m going to share what I think makes my configuration so great. Since so many people are still trying to figure out how to work from home, my hope is that this post is a guide for the things that will make working remotely a great experience.</p>

<p>I should add that I’ve worked for a few companies over the years that provided a stipend for kitting out my remote office. So, I’m fully aware of how much financial privilege that’s been provided to me. However, I hope this article gives everyone at least an idea of the types of gear that can use to upgrade your remote experience, and individual budgets can be adjusted accordingly.</p>

<h2 id="the-location-of-my-office-in-my-home">The Location of My Office in My Home</h2>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/mclaran-first-floor.gif" alt="My remote office is in the room marked 'Study' on this floor plan."></a></dt>

<dd>My remote office is in the room marked 'Study' on this floor plan.</dd>
</dl>

<p>My wife and I purchased our current home in 2014, and it came with a nice office (called “Study” in the floor plan above) on the first floor of the northwest corner of the house. Two things to note about the image above is that my house faces north and the actual build of our house is a mirror image of the floor plan you see. So, the north side of my house is at the bottom of the image, and you take a right turn from the main entrance to enter my office.</p>

<p>The builder’s floor plan called for the West Wall of the study to just be a regular wall with no windows. However, my wife thought that would result in a room that was too dark so she had the bright idea of adding three windows. I can tell you that she was absolutely right, and I’m so glad we went with her idea. You’ll see those three windows later in this post.</p>

<h2 id="outside-the-office">Outside the Office</h2>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/office-from-the-outside.jpg" alt="This is the view of my home office from the outside."></a></dt>

<dd>This is the view of my home office from the outside.</dd>
</dl>

<p>The first thing to understand about my home office is that it’s a totally separate room from the rest of the house. This is key because I have a door that I can close which provides a barrier to keep out noise from the rest of the house. Also, I can simply close the door to signify to my family that I’m working and should not be disturbed.</p>

<p>One key part of my remote office setup that you can’t see from a photo is the <a href="https://www.att.com/internet/fiber/">fiber service from AT&amp;T</a> that provides internet connectivity to my entire home. Since my home has several <a href="https://store.google.com/us/product/nest_cam">Nest security cameras</a> that constantly use data, and we use several services that require internet access, I made the decision a long time ago to purchase a fast connection.</p>










<h2 id="the-door-from-inside-the-office">The Door from Inside the Office</h2>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/office-door.jpg" alt="The door as viewed from inside my office."></a></dt>

<dd>The door as viewed from inside my office.</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td><a href="https://amzn.to/2WzrZtL">Kenney Beckett 5/8” Standard Decorative Curtain Rod, 48-86”, Pewter</a></td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td>Curtain Rod fasteners</td>
    </tr>
    <tr>
      <td>Ⓒ</td>
      <td><a href="https://amzn.to/2SQjeul">NICETOWN Bedroom Blackout Curtains Panels - (52 inches by 108 Inch, Grey, Set of 2) Triple Weave Energy Saving Thermal Insulated Solid Grommet Blackout Draperies</a></td>
    </tr>
    <tr>
      <td>Ⓓ</td>
      <td>Door that closes</td>
    </tr>
    <tr>
      <td>Ⓔ</td>
      <td><a href="https://amzn.to/2WFve2F">Suptikes Door Draft Stopper Under Door Seal</a></td>
    </tr>
  </tbody>
</table>

<p><br>
In addition to having a door that could be closed, I wanted to sound proof my office as much as possible. My office is near the front door and not too far from the dining room and living room. So, at any given moment during the work day, one or more members of my family could be just outside the office or watching TV in the living room. I found complicated (and expensive) ways to sound proof the door, but I went with an economical and effective solution.</p>

<p>I purchased a rod and curtains to provide another layer of sound proofing than just the doors. The doors are quite high so I had to order really tall curtains. I also installed seals on the bottom of the door to help keep out sound from the rest of the house. While this setup doesn’t block all external sound from entering the office, it does provide a much quieter environment in which to work.</p>

<h2 id="east-wall">East Wall</h2>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-office-east-wall-area.jpg" alt="The area in front of the east wall is where I spend most of my time in the office. It's here where I take my calls and also do my work."></a></dt>

<dd>The area in front of the east wall is where I spend most of my time in the office. It's here where I take my calls and also do my work.</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td>Wife’s Wedding Portrait (not for sale)</td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td><a href="https://amzn.to/35Gx87o">Large Size World Map with Black Floater Frame</a></td>
    </tr>
    <tr>
      <td>Ⓒ</td>
      <td><a href="https://amzn.to/3cgV3wD">Amazon Basics Mid-Back Desk Office Chair with Arm rests (Mesh Back)</a></td>
    </tr>
    <tr>
      <td>Ⓓ</td>
      <td><a href="https://amzn.to/3bgfMiW">Anti-fatigue Comfort Floor Mat</a></td>
    </tr>
  </tbody>
</table>

<p><br>
This part of my office has a lot of the things that make it easier to get through my work day. I spend the vast majority of my work day standing, but I also wanted the option to sit for the brief times when sitting in a chair made a task easier. I initially looked for those fancy standing desks that could raise or lower at the touch of a button. However, I had a budget to use to build out my home office, and that would have taken a lot of space in the budget that could be used for other things. So, I decided to go with a far more economical approach. I purchased two coffee tables from Walmart that I put on top of my existing desk, and I set up my primary laptop and monitors on top of those tables. That’s the set of equipment I use when standing. I can also sit down in the chair and use my secondary laptop and monitor on the lower desk.</p>

<p>The map on the wall is a backdrop for framing myself in Zoom calls, and the picture of my wife in her wedding dress is just a lovely reminder of how happy I was when we got married. The boomerang on top of the picture is a gift from a co-worker who went to Australia several years ago.</p>

<p>For comfort, I purchased a reasonably priced office chair and an anti-fatigue mat that spans the part of the floor that’s right in front of my desk. Again, since I stand most of the day, I get a lot more use out of the mat than the chair.</p>

<p>The circular desk beneath my wife’s picture is a place to put random items that I don’t want to put on the upper or lower desks.</p>

<h3 id="upper-desk">Upper Desk</h3>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-work-upper-desk.jpg" alt="The upper desk is designed for use while standing."></a></dt>

<dd>The upper desk is designed for use while standing.</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td><a href="https://amzn.to/2WHtk1J">Inkeltech Ring Light (18 inch, 60 W), Adjustable 3000-6000 K Color Temparature</a></td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td><a href="https://amzn.to/3du1ZH8">Dell Computer Ultrashrp 24.-Inch LED Monitor</a></td>
    </tr>
    <tr>
      <td>Ⓒ</td>
      <td><a href="https://amzn.to/2WeZtOV">Logitech Brio Ultra HD Webcam</a></td>
    </tr>
    <tr>
      <td>Ⓓ</td>
      <td>MacBook Pro (Retina, 15-inch, Mid 2015)</td>
    </tr>
    <tr>
      <td>Ⓔ</td>
      <td><a href="https://amzn.to/2YSuYA2">HP 25-Inch LED Monitor</a></td>
    </tr>
    <tr>
      <td>Ⓕ</td>
      <td>Bugdroid (Android Mascot)</td>
    </tr>
    <tr>
      <td>Ⓖ</td>
      <td>Google Home Mini</td>
    </tr>
    <tr>
      <td>Ⓗ</td>
      <td>Frederick “Freddie” von Chimpenheimer IV (MailChimp Mascot)</td>
    </tr>
    <tr>
      <td>Ⓘ</td>
      <td><a href="https://amzn.to/3bf7rvX">Corsair HS70 Pro Wireless Gaming Headset</a></td>
    </tr>
    <tr>
      <td>Ⓙ</td>
      <td>iPad</td>
    </tr>
    <tr>
      <td>Ⓚ</td>
      <td><a href="https://amzn.to/2yEtbUH">Yeti Blue Microphone (Blackout Edition)</a></td>
    </tr>
    <tr>
      <td>Ⓛ</td>
      <td><a href="https://amzn.to/2LeAa9I">Avantree Universal Wooden &amp; Aluminum Headphone Stand Hanger</a></td>
    </tr>
    <tr>
      <td>Ⓜ</td>
      <td><a href="https://amzn.to/2AeOwVn">Tablet Stand</a></td>
    </tr>
    <tr>
      <td>Ⓝ</td>
      <td><a href="https://amzn.to/3bg8con">Macally Ultra Slim USB Wired Computer Keyboard</a></td>
    </tr>
  </tbody>
</table>

<p><br>
The upper desk is my command center. I use my MacBook Pro as a hub that drives most of the other equipment on my desk. The two monitors provide enough surface area for me to feel productive. I typically use the left monitor for personal productivity items like my task list, the MacBook screen in the middle is where I put the things I’m currently working on, and the right monitor is usually reserved for communications like email, Slack, Jira, etc. The MacBook Pro is hard wired via Ethernet cable to make maximum use of the fiber internet connection.</p>

<p>By the way, I used an old pair of speakers to elevate the Dell and HP monitors. I’ve found that having all three monitors at eye level does wonders for my neck since I don’t have to look down at them while working. This also puts the webcam at a perfect position for video calls since it allows me to naturally look like I’m making eye contact with the attendees.</p>

<p>The equipment that contributes the most to the clear sound and crisp picture on my video calls are the ring light, Logitech Brio webcam, Yeti microphone (which is positioned right in front of my mouth but just out of view from the webcam), and Corsair headset. They provide great lighting as well as strong audio and video signals for the people on the videoconference with me. While the MacBook has a built-in webcam, microphone, and speakers, it can’t match the experience of using separate dedicated devices.</p>

<p>The iPad is nice for quickly pulling up things like my personal calendar, viewing my Nest cameras if I hear something outside of the office, or checking personal email.</p>

<p>I also have little “flair” items like the Android and MailChimp mascots. I’m heavily in the Android ecosystem, and I once gave a talk at the MailChimp office in Atlanta so these are just nice personal items.</p>

<p>The white mat on top of the desk is there to protect it from damage, spills, etc.</p>

<h3 id="lower-desk">Lower Desk</h3>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-office-lower-desk.jpg" alt="The lower desk is designed for use while sitting."></a></dt>

<dd>The lower desk is designed for use while sitting.</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td><a href="https://amzn.to/2zqp4LO">Asus 23.6” Monitor</a></td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td><a href="https://amzn.to/3fxbMOp">Xerox DocuMate 3220 Duplex Document Scanner with Flatbed</a></td>
    </tr>
    <tr>
      <td>Ⓒ</td>
      <td>MacBook Pro</td>
    </tr>
    <tr>
      <td>Ⓓ</td>
      <td><a href="https://amzn.to/2Act9Uv">Brother HL-2270DW Compact Laser Printer</a></td>
    </tr>
    <tr>
      <td>Ⓔ</td>
      <td><a href="https://amzn.to/2YL1Z1d">Anker USB C Hub Adapter, 7-in-1 USB C Adapter</a></td>
    </tr>
    <tr>
      <td>Ⓕ</td>
      <td><a href="https://amzn.to/3ccjP0W">Multifunctional Office Desk Pad, 35.4” x 17”</a></td>
    </tr>
    <tr>
      <td>Ⓖ</td>
      <td><a href="https://amzn.to/3bcNzJX">VASAGLE Industrial Shoe Bench</a></td>
    </tr>
  </tbody>
</table>

<p><br>
I rarely use the lower desk since I stand for most of the day. However, it provides a secondary MacBook as well as an external monitor. I also have a scanner for the odd times I need to scan a picture or document and a laser printer. Like the upper desk, I also have a mat to make it easier to clean the top surface. I try to avoid eating in my office, but, when I do, I usually do it on the lower desk. So, the mat is a great way to protect the desk from spills and stains.</p>

<p>You can see the bench behind the desk. I purchased it to store the various plugs I needed to power my equipment and also serve as a stand for the ring light.</p>

<h3 id="behind-the-desk">Behind the Desk</h3>

<dl>

<dt><a href=""><img src="https://anjuansimmons.com/images/remote-office-behind-desk.jpg" alt="A view of what the back of the desk looks like. I know, I know . . ."></a></dt>

<dd>A view of what the back of the desk looks like. I know, I know . . .</dd>
</dl>

<table>
  <thead>
    <tr>
      <th>Letter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ⓐ</td>
      <td><a href="https://amzn.to/2Act57d">Anker 10 Port 60W Data Hub with 7 USB 3.0 Ports and 3 PowerIQ Charging Ports</a></td>
    </tr>
    <tr>
      <td>Ⓑ</td>
      <td>Exte…</td></tr></tbody></table></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anjuansimmons.com/blog/my-remote-work-office-setup">https://anjuansimmons.com/blog/my-remote-work-office-setup</a></em></p>]]>
            </description>
            <link>https://anjuansimmons.com/blog/my-remote-work-office-setup</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839328</guid>
            <pubDate>Tue, 14 Jul 2020 23:22:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ode to a Pager]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23838884">thread link</a>) | @calcifer
<br/>
July 14, 2020 | https://www.roguelazer.com/2019/06/ode-to-a-pager/ | <a href="https://web.archive.org/web/*/https://www.roguelazer.com/2019/06/ode-to-a-pager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <section id="main-content" role="main">
	<article>
		


		<div><p><img alt="pager" src="https://www.roguelazer.com/images/2019-06-13-pager.png"></p>
<p>I've been on-call for most of the last 11 years. I was on-call for the CS Department at Mudd<sup id="fnref:csdept"><a href="#fn:csdept">1</a></sup>. I was on-call at
Yelp, in a rotation that at times contained as few as three people. I was on-call at Uber in rotations ranging from one
to twenty people. And I've been on-call at EasyPost — initially in a rotation with one other person<sup id="fnref:epdouble"><a href="#fn:epdouble">2</a></sup>, and
currently with two other people. I have responded to tens of thousands of pages. I have been woken up in the middle of
the night hundreds<sup id="fnref:hundreds"><a href="#fn:hundreds">3</a></sup> of times. For the last seven or so years, I've worked at firms where on-call was a <acronym title="Bring Your Own Device">BYOD</acronym> kind of a deal — you bring your own cell phone, register it in
<a href="https://www.pagerduty.com/">PagerDuty</a>, and that's how you handle being on-call. This is my ode to the unfairly-hated pager, to
the practices of yore.</p>
<p>Let's look at the phone you have in your pocket right now<sup id="fnref:nodevice"><a href="#fn:nodevice">4</a></sup>:</p>
<ul>
<li>It runs iOS or Android<sup id="fnref:ios"><a href="#fn:ios">5</a></sup></li>
<li>It gets at most two days of battery life</li>
<li>It receives phone calls, of which at least 90% are robots saying things like <q>Hey buddy, this call is from the Department of Social Security</q></li>
<li>When it's not getting phone calls, it's constantly begging for your attention with notifications, most of which are some degree of spam</li>
</ul>
<p>Is <em>this</em> the device you want to have to have on and audible 24 hours a day, 365 days a year? Do you love the idea of
Apple's <em>Do Not Disturb</em> feature? Well, screw you because PagerDuty might need to reach you at any instant<sup id="fnref:dnd"><a href="#fn:dnd">6</a></sup>. Do you miss
going out into the woods for a hike? Too bad, Apple had to shave 0.7mm off the latest iPhone so now the antenna only
works if it has direct line of sight to the AT&amp;T worldwide headquarters in Dallas, TX. Want to quickly see what you're
getting paged about? I hope you like watching this brief animation as all your icons <em>swoosh</em> in from whatever armpit
of the universe they spend the off-time drinking in before you can actually do anything. Oh, you're using the native
PagerDuty app? Well, then, you've got to give it 10 seconds to load (despite the fact that the Apple A12 CPU in your
phone is faster than <strong>any computer CPU that existed anywhere on the planet 10 years ago</strong>) so that it can render some
emojis and prompt you to take an "On-Call Selfie"<sup id="fnref:selfie"><a href="#fn:selfie">7</a></sup>.</p>
<p>My ideal on-call device would look something like the following:</p>
<ul>
<li>Small and lightweight</li>
<li>Extremely long battery life (imagine… weeks without recharging)</li>
<li>Only capable of receiving emergency notifications from PagerDuty so I can leave it on, unmuted at all times</li>
<li>On a network with great distance and building penetration<sup id="fnref:5G"><a href="#fn:5G">8</a></sup></li>
<li>Maybe a one or two line black-and-white display just long enough to print out messages like <code>CRITICAL: web1sf - 4 packets transmitted, 0 received, 100% packet loss</code></li>
<li>Maybe two buttons so you could acknowledge or escalate incidents — but maybe not; I'm probably going to grab a laptop or bigger device to actually do the investigation<sup id="fnref:onedevice"><a href="#fn:onedevice">9</a></sup></li>
</ul>
<p>Do you know what I've just described, you bunch of ingrates? You damned dirty apes? A bona fide <strong>two-way pager</strong>. We had the technology! We had
built the perfect system! And we destroyed it! In our frivolous pursuit of only carrying one device, in our employers'
endless pursuit of simpler procurement, we got rid of a system where your employer provides a simple-to-use
single-function device to you, the employee, and replaced it with a system where you bring your own massively
over-complicated device, pay your own connectivity bills, and then miss pages at 3 in the morning because you got too
many goddamn Farmville notifications and your battery died.</p>
<p><img alt="You blew it up!" src="https://www.roguelazer.com/images/2019-06-13-pota.jpg"></p>
</div>
<hr>
<h2>Comments</h2>


	</article>
    </section>
</div></div>]]>
            </description>
            <link>https://www.roguelazer.com/2019/06/ode-to-a-pager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838884</guid>
            <pubDate>Tue, 14 Jul 2020 22:33:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cutting user churn for world's fastest-growing bike-share startup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23838768">thread link</a>) | @dasickis
<br/>
July 14, 2020 | https://blog.locale.ai/how-indias-top-micro-mobility-player-used-locale-ai-to-reduce-user-churn-by-9/ | <a href="https://web.archive.org/web/*/https://blog.locale.ai/how-indias-top-micro-mobility-player-used-locale-ai-to-reduce-user-churn-by-9/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.locale.ai/content/images/size/w300/2020/07/SAE_IT--1-.jpg 300w,
                            https://blog.locale.ai/content/images/size/w600/2020/07/SAE_IT--1-.jpg 600w,
                            https://blog.locale.ai/content/images/size/w1000/2020/07/SAE_IT--1-.jpg 1000w,
                            https://blog.locale.ai/content/images/size/w2000/2020/07/SAE_IT--1-.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.locale.ai/content/images/size/w2000/2020/07/SAE_IT--1-.jpg" alt="How India's Top Scooter Sharing Player Used Locale.ai to Reduce User Churn by 9%">
            </figure>

            <section>
                <div>
                    <h2 id="an-introduction-to-our-partner-">An introduction to our Partner:</h2><p>Locale recently worked with a scooter sharing company that helps users commute using their fleet of scooters and bikes. With their rapid growth, large user base, and wonderful review, they have become the face of the growing micro-mobility ecosystem in South Asia. In 2019, they reached a significant milestone of 60,000 rides per day in Bengaluru, making it the fastest-growing bike-sharing start-up in the world. </p><p>Let us take you through how the team<strong><strong> </strong></strong>used <strong><strong><a href="https://locale.ai/">Locale.ai</a> </strong></strong>to open their stations in 7 cities as part of a new initiative by the company, decrease user churn by 9% and attain operational efficiency.</p><h2 id="the-business-problem-s-">The Business Problem(s)</h2><p>To make any important operational decision using geo-data, executives and decision makers have to rely on the data provided by the engineering teams. The case was very similar with our partner too. Their business model was a docked model- where any user (like you or me) could pick up a bike from a station and drop it off to another station.</p><p>As they were rapidly expanding in new cities (pre-COVID), the business problems were to:</p><ul><li>Decide where to open new stations to service demand</li><li>Close stations that were not performing well</li></ul><figure><img src="https://blog.locale.ai/content/images/2020/06/OperationalInsights-1.png"><figcaption>Locale.ai Console</figcaption></figure><p><br>The team wanted to ensure that they could capitalize on latent demand present in certain areas and expand their presence as well as minimise user churn by getting better insights into user behaviour and making a strategy accordingly.</p><p>Meanwhile, they were also trying to ensure that the time and resources in building dashboards could be used in some other avenue so that they could grow more rapidly. That’s where they were looking for a tool to convert location data into insights that can aid business decisions.</p><h3 id="before-we-move-on-a-bit-about-locale-ai">Before we move on, a bit about Locale.ai</h3><p>Locale is your one-stop destination for anything that involves analyzing hyperlocal operations. Imagine a tool built for city teams, ops teams &amp; logistics teams empowering them to get answers to their questions without depending on any engineering or analyst bandwidth.</p><p>We ensure that a large chunk of location data collected from your users or your vehicle sensors, that might otherwise remain unused, can now be used to create meaningful insights that help business teams make quick, data-driven decisions.</p><h2 id="the-how-s-why-s-of-the-solution">The How's &amp; Why's of the Solution</h2><p>The questions that the team asked to make the following decisions:</p><h3 id="expansion-new-stations">Expansion &amp; New Stations</h3><ul><li>Which areas are users downloading the app or searching for bikes?</li><li>Which areas are users churning out [searching but not booking]?</li><li>What is the distance of areas with high churn density with current stations?</li></ul><figure><img src="https://blog.locale.ai/content/images/2020/06/New-Static-Entity-overview.png"><figcaption>Locale.ai: Station Console</figcaption></figure><h3 id="shutting-down-stations"><strong><strong>Shutting Down Stations</strong></strong></h3><ul><li>Which stations are usually facing a high rate of cancellations?</li><li>Which stations have a very high idle time for the bikes?</li><li>Which stations are located near low demand areas?</li></ul><h3 id="making-insights-actionable">Making Insights Actionable</h3><p>At Locale, we consider ourselves successful only when we help companies take more precise and data-driven decisions using our product. So, we are always on the lookout for making these insights more actionable.</p><p>To read more on this, check this out:‌</p><figure><a href="https://blog.locale.ai/how-were-building-our-geospatial-analytics-product-using-first-principles-2/"><div><p>How we’re building our geospatial analytics product using first principles</p><p>Our philosophy on analytics at Locale!</p><p><img src="https://blog.locale.ai/favicon.png"><span>The Locale.ai Blog</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/01/0.png"></p></a></figure><p>With our partner for instance, the central ops team could just right click and get the lat-long of the prospective location. They would send a couple of these lat-longs to their individual city teams who would find the most optimal location on ground, owing to the constraints.</p><p>With our commenting feature, they would coordinate internally on whether the station was opened in that location. If not, what were the possible reasons?</p><h3 id="the-impact">The Impact</h3><p>But, with all these decisions, what was the actual business impact and how did we move business metrics?</p><blockquote>Since the team started using our product, we saw a 9% reduction in user churn and improvement in user satisfaction.</blockquote><p>What this translates to is users who could previously not book a bike because of unavailability of bikes, or bikes being far off can now hop on a nearby bike and start their rides, which resulted in an improvement in user delight.</p><hr><h2 id="the-use-cases-of-locale-in-micro-mobility-">The Use Cases of Locale in Micro-Mobility:‌‌</h2><figure><img src="https://blog.locale.ai/content/images/2020/07/image-6.png"></figure><p>Analysts at McKinsey have evaluated the shared micro mobility industry to cross over <a href="https://www.mckinsey.com/industries/automotive-and-assembly/our-insights/micromobilitys-15000-mile-checkup#">$300 Billion by 2030</a>. But how can companies today reach there? What stops companies from realizing their potential? Inertia in expanding to newer locations? Problems with fleet management? Inaccuracy in gauging demand? A mixture of all these problems often cap the growth of a company.</p><p>Let us explore these problems one by one.</p><ol><li><strong><strong>Expansion</strong></strong>: Metrics such as user bookings, cancellations, distribution of sales and churn helps companies understand the spread of demand and supply across cities.</li><li><strong><strong>Station Performance:</strong></strong> Idle time of bikes, churn density around the stations and cancellations help companies decide where to set up new stations and which stations to shut down.</li><li><strong><strong>User Acquisition:</strong></strong> It is important to understand the behaviour of frequent users, which routes they travel and how they can increase user acquisition along those routes via targeted offline and route-based campaigns.</li><li><strong><strong>Fleet Management:</strong></strong> Issues such as vandalism, incomplete drop-offs, and breakdowns need to be tracked in real time and it helps companies to get immediate notifications for abnormal behaviour of KPIs.‌‌</li></ol><p>Often, companies search for tools that can be used to solve these problems for them, by using their location data. Luckily, that's exactly what we love to do!‌‌ If you work in the micro-mobility or ride-sharing industry, contact us to set up your Locale today. ‌‌</p><p><em><em><em><em>To know more, g<em><em><em><em>et in touch with me on </em></em></em></em></em></em></em></em><a href="https://www.linkedin.com/in/aditi-sinha-6b774ba9/" rel="noopener nofollow"><em><em><em><em><em><em><em><em>LinkedIn</em></em></em></em></em></em></em></em></a><strong><strong><strong><strong><strong><strong><strong><strong><em><em><em><em><em><em><em><em> </em></em></em></em></em></em></em></em></strong></strong></strong></strong></strong></strong></strong></strong><em><em><em><em><em><em><em><em>or </em></em></em></em></em></em></em></em><a href="https://twitter.com/aditi1002" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Twitter</em></em></em></em></em></em></em></em></a><strong><strong><strong><strong><strong><strong><strong><strong><em><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></strong></strong></strong></strong></strong></strong></strong></strong></p><h3 id="read-similar-">Read Similar:</h3><figure><a href="https://blog.locale.ai/how-micromobility-used-locale-ai-to-reduce-user-churn/"><div><p>How India’s Top Micro-Mobility Player Used Locale.ai to Reduce User Churn by 9%</p><p>A step-by-step guide on how they used Locale.ai to set up their stations</p><p><img src="https://blog.locale.ai/favicon.png"><span>Aditi Sinha</span><span>The Locale.ai Blog</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/07/SAE_IT.jpg"></p></a></figure><figure><a href="https://blog.locale.ai/mapping-kpis-with-location-data-for-ride-hailing-companies-using-locale-ai/"><div><p>Key Metrics for Ride-Hailing Companies using Location Data</p><p>Use location intelligence to create heatmaps for your critical business&nbsp;metrics with Locale</p><p><img src="https://blog.locale.ai/favicon.png"><span>Aditi Sinha</span><span>The Locale.ai Blog</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/05/1_C0WaSy2Lt-sdpynFMI8j4A.png"></p></a></figure>
                </div>
            </section>





        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.locale.ai/how-indias-top-micro-mobility-player-used-locale-ai-to-reduce-user-churn-by-9/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838768</guid>
            <pubDate>Tue, 14 Jul 2020 22:22:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spark vs. Snowflake: The Cloud Data Engineering (ETL) Debate]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23838750">thread link</a>) | @ibains
<br/>
July 14, 2020 | https://www.prophecy.io/blogs/spark-vs-snowflake-the-cloud-data-engineering-etl-debate | <a href="https://web.archive.org/web/*/https://www.prophecy.io/blogs/spark-vs-snowflake-the-cloud-data-engineering-etl-debate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Data Integration is a critical engineering system in all Enterprises. Initially, it started with ad hoc <strong>scripts</strong>, which got replaced by <strong>Visual ETL</strong> tools such as Informatica, AbInitio, DataStage, and Talend. To cope with an explosion in data, consumer companies such as Google, Yahoo, and LinkedIn developed new <strong>data engineering</strong> systems based on commodity hardware. The usability of these systems was quite low, and the developer needed to be much more aware of the performance. <strong>Apache Spark</strong> has broken through from this clutter with thoughtful interfaces and product innovation, while <strong>Hadoop</strong> has effectively gotten <strong>disaggregated</strong> in the cloud and become a legacy technology.</p><p>Now, as Enterprises transition to the cloud, often they are developing expertise in the cloud ecosystem at the same time as trying to make decisions on the product and technology stack they are going to use. </p><p>In the rest of the blog, we'll take a look at the two primary processing paradigms for data integration, and their cloud equivalents.</p></div><h2>What is Data Integration (or ETL)</h2><p>Data Integration is your Data Factory. It reads data from various <strong>input sources</strong> such as Relational Databases, Flat Files, and Streaming. It then does various <strong>transformations</strong> on the data such as joining and de-duplicating data, standardizing formats, pivoting, and aggregating. Once the data is ready for analytics (such as in star schemas), it is <strong>stored or loaded</strong> into the target which is typically a Data Warehouse or a Data Lake.</p><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%20%20graphic.png" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%2520%2520graphic-p-1080.png 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%2520%2520graphic-p-1600.png 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%20%20graphic.png 1755w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><h2>The Two On-Premises Execution Paradigms</h2><p>For most large Enterprises and companies rich in data, &nbsp;one server will be insufficient to execute the workloads, and thus, parallel processing is required. For this, there have historically been two primary methods:</p><ul role="list"><li><strong>ETL Execution Engine Processing</strong> - here the ETL tool comes with a distributed high performance execution engine. Most of the processing happens in this execution engine, and after the data is ready for analytics, it is loaded into a data warehouse. <strong>AbInitio</strong> is a good example and is the market leader in performance.</li><li><strong>Data Warehouse Pushdown Processing</strong> - here the ETL tool comes with a single server execution engine. Since it cannot do high volume processing, it provides pushdown processing that pushes computations down to the Data Warehouse and leverages the distributed processing engine there. In the field, we see <strong>Informatica</strong> commonly deployed with <strong>Teradata</strong> this way, though Informatica has a PowerCenter Grid product as well.</li></ul><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%20execution%20graphic.png" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-500.png 500w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-800.png 800w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-1080.png 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-1600.png 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%20execution%20graphic.png 1773w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><p>Two on-premises ETL Execution paradigms</p><h3>Which Architecture is Better?</h3><div><p>One natural question to ask is - <strong>whether one of these paradigms is preferable?</strong> The Answer is Yes!</p><p>The case for <strong>data warehouse ETL execution</strong> is that it reduces one system - ETL execution and data warehouse execution will both happen in Teradata. Also, most data warehouses are typically high-quality products. However, it's an <strong>expensive</strong> approach and <strong>not the right architectural fit</strong>. Data warehouses have an architectural focus on <strong>low latency</strong> since there is often a human analyst waiting for her BI query. For this, they collect high-quality statistics for query planning and have sophisticated caching mechanisms. This is not a great fit for ETL workloads where throughput is the most important factor, and there is no reuse, making caches and statistics useless. Often we've found that 70% of Teradata capacity was dedicated to ETL in Enterprises, and that is what got offloaded to Apache Hive. </p><p>On the other hand, high-quality parallel processing products, exemplified by AbInitio are perhaps the <strong>best solution</strong> - both in inherent processing cost and performance. Most users of AbInitio loved the product, but the high licensing cost has removed any architectural cost advantages they had and made them available to a very few of the largest Enterprises. </p><p>‍<strong>Cloud, with usage based pricing,</strong> is a great equalizer, let's look at how cloud is changing this equation...</p></div><h2>Cloud Transition - the two ETL Architectures</h2><p>There are two primary approaches to choose for your ETL or Data Engineering</p><ul role="list"><li><strong>Data Warehouse ETL Approach: </strong>This is an <strong><em>as-is</em></strong> migration of the on-premises approach, done in a cloud context. An example here, one can use <strong>Snowflake</strong> as the data warehouse instead of <strong>Teradata</strong> on-premises. Then you can use any ETL tool such as <strong>Informatica</strong> or <strong>Matillion</strong> on top and it will push down queries to Snowflake that will do the heavy lifting. If you have small datasets, this works. As discussed above, for large datasets and complex transformations this architecture is far from ideal. This is far from the world of open-source code on Git &amp; CI/CD that data engineering offers - again locking you into proprietary formats, and archaic development processes.</li><li><strong>Data Engineering Approach:</strong> Data Engineering based on Spark for the execution layer, merges the best of the previous generation in high performance, with the best of large scale commodity processing from consumer companies - such as Hadoop. If you use Databricks, it adds transactions from Data Warehouses via delta lake providing the best product in the cloud by a large margin. A product such as <strong>Prophecy</strong> adds the remaining functionality - code and visual drag-and-drop editing that generates code on Git, Metadata with lineage, Scheduling, and CI/CD, providing a complete stack that will free you from proprietary formats.</li></ul><div><p>The following image is how the Cloud Data Engineering architecture looks. The data from on-premise operational systems lands inside the data lake, as does the data from streaming sources and other cloud services. <strong>Prophecy with Spark</strong> runs data engineering or ETL workflows, writing data into a data warehouse or data lake for consumption.</p><p>Reports, Machine Learning, and a majority of analytics can run directly from your Cloud Data Lake, saving you a lot of costs and making it the single system of record. For particular BI use cases (fast interactive queries), Data Marts can be created on Snowflake or another Cloud Data Warehouse such as Redshift, BigQuery, or Azure SQL.</p></div><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture.jpg" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-500.jpeg 500w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-1080.jpeg 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-1600.jpeg 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-2000.jpeg 2000w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture.jpg 2423w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><p>Cloud Data Engineering Architecture</p><h2>How to Choose?</h2><p>If you're moving you ETL to Data Engineering, you're deciding what your architecture for the next decade or more.</p><p>We recommend moving to Apache Spark and a product such as Prophecy. Apart from exceeding the capabilities of the Snowflake based stack at a much cheaper price point, this prevents you from getting locked into proprietary formats. You will also be able to deliver new analytics faster by embracing Git and continuous integration and continuous deployment - that is equally accessible to the Spark coders as well as the Visual ETL developers who have a lot of domain knowledge.</p></div></div>]]>
            </description>
            <link>https://www.prophecy.io/blogs/spark-vs-snowflake-the-cloud-data-engineering-etl-debate</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838750</guid>
            <pubDate>Tue, 14 Jul 2020 22:20:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vlink: Portable multi file format linker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838711">thread link</a>) | @doener
<br/>
July 14, 2020 | http://sun.hasenbraten.de/vlink/ | <a href="https://web.archive.org/web/*/http://sun.hasenbraten.de/vlink/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
  <tbody><tr>
    <td><table>
      <tbody><tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=main">About vlink</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=relsrc">Last release source</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=source">Daily source snapshot</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=tagged">Tagged source archives</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=compile">Compilation notes</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=binrel">Last release binaries</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/index.php?view=bincur">Daily snapshot binaries</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vlink/release/vlink.pdf">vlink docs (pdf)</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://www.compilers.de/vlink.html">Volker's vlink page</a>
      </td></tr>
      <tr><td nowrap="nowrap">
        <a href="http://sun.hasenbraten.de/vbcc/">vbcc/Amiga home page</a>
      </td></tr>
    </tbody></table></td>

    <td>
      <table>
  <tbody><tr><td>
    <p>vlink is a portable linker, written in ANSI-C, that can read
    and write a wide range of object- and executable file formats.
    It can be used to link a specific target format from several
    different input file formats, or for converting, stripping
    and manipulating files.</p>
    <p>The linker can be controlled by GNU-style linker scripts to
    generate absolute code, but it also runs very well with
    default rules to create relocatable executables, as required
    for AmigaOS or MorphOS.</p>
    <p>Of course there might be technical restrictions that object
    files of different architectures cannot be merged because of
    incompatible relocation types, differing endianess or
    symbol-names with and without leading underscores. But in
    theory everything is possible!</p>
  </td></tr>

  <tr><td>
    Currently the following object and executable file formats
    are supported by vlink:
    <ul>
      <li>ELF 32bit PowerPC big endian</li>
      <li>ELF 32bit PowerPC AmigaOS (special dynamic linking rules)</li>
      <li>ELF 32bit PowerPC MorphOS (relocatable executables)</li>
      <li>ELF 32bit PowerPC PowerUp (relocatable executables)</li>
      <li>ELF 32bit M68k big endian</li>
      <li>ELF 32bit Jaguar RISC big endian</li>
      <li>ELF 32bit x86 little endian</li>
      <li>ELF 32bit x86 AROS (relocatable executables)</li>
      <li>ELF 32bit ARM little endian</li>
      <li>ELF 64bit x86_64 little endian</li>
      <li>a.out Sun/010 (also Amiga/Atari 68000)</li>
      <li>a.out Sun/020 (also Amiga/Atari 68020+)</li>
      <li>a.out MiNT (embedded in Atari TOS format)</li>
      <li>a.out Jaguar (M68k with support for RISC relocations)</li>
      <li>a.out NetBSD/68k (4k and 8k pages)</li>
      <li>a.out NetBSD/386</li>
      <li>a.out PC/386</li>
      <li>a.out generic</li>
      <li>AmigaOS hunk format</li>
      <li>EHF, extended hunk format (WarpOS)</li>
      <li>Atari TOS format (writing only)</li>
      <li>Motorola S-Records (writing only)</li>
      <li>Intel-hex format (writing only)</li>
      <li>AMSDOS format (Amstrad/Schneider CPC)</li>
      <li>Commodore 8-bit PRG format</li>
      <li>Raw binaries (writing only)</li>
      <li>VOBJ, proprietary versatile object format (reading only)</li>
    </ul>
  </td></tr>

</tbody></table>


<div>
<b>07-Jul-2020: vlink 0.16e.</b><br><ul>
<li>Changing the address within an output section in a linker script didn't  work correctly when the destination memory region (load-address) differs  from the relocation memory region (execution-address).</li><li>Data commands in linker scripts didn't work when there was nothing  else in the output section.</li><li>Fixed a segfault when a linker script moves the address counter backwards  inside an output section.</li><li>Fixed uninitialized pointer when loading input files via a linker-script  INPUT command.</li><li>New linker-script command: RESERVE(n) to reserve n bytes of memory and  fill it with the current FILL value.</li><li>FILL-pattern should always be written in big-endian.</li><li>Replaced FILL command by FILL8 and FILL16.</li><li>New option -mall to merge everything into a single output section.</li><li>Weak symbols must only be resolved in executables.</li><li>(rawbin) Motorola S-Records: Fixed start address in S8 and S9 trailer.</li><li>(vobj) Fixed reference to a defined weak symbol in an object.</li><li>(elf) Fixed reference to a defined weak symbol in an object.</li></ul></div>
<div>
<b>18-Apr-2020: vlink 0.16d.</b><br><ul>
<li>New option -N for renaming input sections.</li><li>New option -vicelabels to generate a label-address mapping for the  debugger from the VICE emulator.</li><li>-M option for generating map files accepts an optional output file name.</li><li>Map files prints all symbols per section sorted by value. The values  are printed on the first column now, using the target address size for  formatting.</li><li>Multiple lines for the same section in a linker script are not allowed.</li><li>Try to avoid "segment is closed" errors in linker scripts which define  and use memory regions, and no PHDR definitions.</li><li>Fixed output of trailing zero-bytes in all hex-formats, like S-Records,  IHex, SHex1.</li><li>(ados/ehf) Always generate short-reloc hunks, when requested by -Rshort.  Relocs with offsets &gt; 0xffff will be written in a separate hunk.</li><li>(ados/ehf) HUNK_LIB parsing sometimes failed. Fixed.</li><li>(rawbin) Target cbmprg no longer automatically splits the output file,  when there are larger gaps between output sections.</li><li>(rawbin) Trailing S-record (S7, S8, S9) contains the entry address.</li></ul></div>
<div>
<b>10-Jun-2019: vlink 0.16c.</b><br><ul>
<li>New target file format XFile, for Sharp X68000 computers. At the moment  only executables may be created. No object file support.</li><li>(ados/ehf) Handle data-bss sections correctly, when linking/stripping  executable files.</li></ul></div>
<div>
<b>28-Dec-2018: vlink 0.16b.</b><br><ul>
<li>New option -mtype: merge all sections of the same type (code, data,  bss), ignoring name and attributes.</li><li>(ados/ehf) Fixed possible segfault when linking resident modules.</li><li>(ados/ehf) Allow linking/stripping executables again.</li></ul></div>
<div>
<b>14-Aug-2017: vlink 0.16a.</b><br><ul>
<li>New linker script commands: BYTE, SHORT, LONG, QUAD, SQUAD.</li><li>New option -k: keep original section order from the objects.</li><li>Fixed crash with -gc-all and unreferenced symbols.</li><li>Fixed crash with unresolved weak symbols.</li><li>(ados/ehf) _INIT/_EXIT functions with register arguments (prefixed by  '@' instead of '_' for SAS/C-compatibility) are also detected, and their  pointers inserted into the proper con-/destructor tables.</li><li>(elf) Provide __CTOR_LIST_END, __DTOR_LIST_END.</li></ul></div>
<div>
<b>16-May-2017: vlink 0.16.</b><br><ul>
<li>Fixed a potential crash when linking with empty object files, while  using a linker script.</li><li>(ados/ehf): Support blink/slink linker symbols _RESLEN, _RESBASE,  _NEWDATAL for generating resident (pure) programs.</li><li>(ados/ehf): Fixed SAS/C-compatibility linker symbol __BSSLEN. Now it  represents the number of long words instead of the number of bytes.  WARNING! Make sure to check your code, if you used __BSSLEN before!</li><li>(ados/ehf): AmigaOS LoadSeg() (up to V40) has a problem with allocating  data-bss sections, which have an initialized size of 0. Implemented a  workaround for this case.</li><li>(elf) Fixed crash in dynamic linking due to section-trimming.</li><li>(elf,aout) Malformatted library archive files are no longer fatal, but  will be ignored.</li><li>(rawseg) Do not write output sections marked with NOLOAD.</li></ul></div>    </td>
  </tr>
</tbody></div></div>]]>
            </description>
            <link>http://sun.hasenbraten.de/vlink/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838711</guid>
            <pubDate>Tue, 14 Jul 2020 22:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tabletop game OFMOS is a model of the economy as a complex system (Print&Play)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838632">thread link</a>) | @cmitreanu
<br/>
July 14, 2020 | https://www.ofmos.com/how-economies-work | <a href="https://web.archive.org/web/*/https://www.ofmos.com/how-economies-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="siteWrapper">
      
        
      

      


      <main id="page" role="main">
        
          <article data-page-sections="5ec7522d117f476816949b21" id="sections">
  
    <section data-section-id="5ec7522d117f476816949b24" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;backgroundImage&quot; : {
    &quot;id&quot; : &quot;5edec539c19ff3057554ea0c&quot;,
    &quot;recordType&quot; : 2,
    &quot;addedOn&quot; : 1591595635274,
    &quot;updatedOn&quot; : 1591595639125,
    &quot;starred&quot; : false,
    &quot;passthrough&quot; : false,
    &quot;workflowState&quot; : 1,
    &quot;publishOn&quot; : 1591595635274,
    &quot;authorId&quot; : &quot;589a219a46c3c44baeacffc2&quot;,
    &quot;systemDataId&quot; : &quot;1591595635799-L7DEE5JNWGB0O1ENN5CZ&quot;,
    &quot;systemDataVariants&quot; : &quot;942x942,100w,300w,500w,750w&quot;,
    &quot;systemDataSourceType&quot; : &quot;PNG&quot;,
    &quot;filename&quot; : &quot;ofmos-web2020-image.069.png&quot;,
    &quot;mediaFocalPoint&quot; : {
      &quot;x&quot; : 0.5,
      &quot;y&quot; : 0.5,
      &quot;source&quot; : 3
    },
    &quot;colorData&quot; : {
      &quot;topLeftAverage&quot; : &quot;060303&quot;,
      &quot;topRightAverage&quot; : &quot;000000&quot;,
      &quot;bottomLeftAverage&quot; : &quot;442523&quot;,
      &quot;bottomRightAverage&quot; : &quot;000000&quot;,
      &quot;centerAverage&quot; : &quot;000000&quot;,
      &quot;suggestedBgColor&quot; : &quot;000000&quot;
    },
    &quot;urlId&quot; : &quot;1i5h5hszztrut8oatnfyysjisj92xp-9l3b9&quot;,
    &quot;title&quot; : &quot;&quot;,
    &quot;body&quot; : null,
    &quot;likeCount&quot; : 0,
    &quot;commentCount&quot; : 0,
    &quot;publicCommentCount&quot; : 0,
    &quot;commentState&quot; : 2,
    &quot;unsaved&quot; : false,
    &quot;author&quot; : {
      &quot;id&quot; : &quot;589a219a46c3c44baeacffc2&quot;,
      &quot;displayName&quot; : &quot;Cristian Mitreanu&quot;,
      &quot;firstName&quot; : &quot;Cristian&quot;,
      &quot;lastName&quot; : &quot;Mitreanu&quot;,
      &quot;websiteUrl&quot; : &quot;http://www.cristianmitreanu.com&quot;,
      &quot;bio&quot; : &quot;&quot;
    },
    &quot;assetUrl&quot; : &quot;https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591595635799-L7DEE5JNWGB0O1ENN5CZ/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png&quot;,
    &quot;contentType&quot; : &quot;image/png&quot;,
    &quot;items&quot; : [ ],
    &quot;pushedServices&quot; : { },
    &quot;pendingPushedServices&quot; : { },
    &quot;recordTypeLabel&quot; : &quot;image&quot;,
    &quot;originalSize&quot; : &quot;942x942&quot;
  },
  &quot;imageOverlayOpacity&quot; : 0.9,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 85,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;sectionTheme&quot; : &quot;dark&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  <div>
  
    
      
      <p><img alt="" data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591595635799-L7DEE5JNWGB0O1ENN5CZ/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591595635799-L7DEE5JNWGB0O1ENN5CZ/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" data-load="false" src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591595635799-L7DEE5JNWGB0O1ENN5CZ/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png"></p>
    
  
  </div>
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec7522d117f476816949b24"><div><div><div data-block-type="2" id="block-71348fc9d3ad337f8320"><p>View economies as dynamic systems of virtual business worlds.</p></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec7522d117f476816949b28" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;light-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec7522d117f476816949b28"><div><div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1590121073526_16765"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590796197967-NOCLPCNWYOBHB0EVPNBM/ke17ZwdGBToddI8pDm48kMq016PxczJ_Rm803414ovZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITsNzIAhmHx-cX_WInkOSI1sRY40eJrXM7kn3usbhk0gKMshLAGzx4R3EDFOm1kBS/ofmos-web2020-image.062.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590796197967-NOCLPCNWYOBHB0EVPNBM/ke17ZwdGBToddI8pDm48kMq016PxczJ_Rm803414ovZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PITsNzIAhmHx-cX_WInkOSI1sRY40eJrXM7kn3usbhk0gKMshLAGzx4R3EDFOm1kBS/ofmos-web2020-image.062.jpg" data-image-dimensions="792x444" data-image-focal-point="0.5,0.5" alt="ofmos-web2020-image.062.jpg" data-load="false" data-image-id="5ed19fa548814c0a32497957" data-type="image" src="https://www.ofmos.com/ofmos-web2020-image.062.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-11a57b2dc5848e350ea1"><div><h3>Big Three (Marx, Keynes, and Smith): To Intervene, or Not To Intervene</h3><p>The past two and a half centuries have seen only three dominant macroeconomic theories. In 1776, with his book “The Wealth of Nations” marking the beginning of modern economics, Adam Smith first articulates the idea of a hands-off approach to the economy. In simple terms, the view asserts that the “invisible hand” of the free markets will always create the best conditions for all those involved. A century later, in a rebuke to that perspective, Karl Marx’s 1867 book “Das Kapital” lays the foundation for the idea that only a planned and centralized economy can lead to the equitable distribution of the nation’s wealth. Finally, with his 1936 book “The General Theory of Employment, Interest and Money,” John Maynard Keynes introduces the notion that the best way to maintain a healthy economy if to intervene with policies when the economic activity slows down or heats up.</p></div></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1590786298234_16585"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590791903991-0UVJR5M8GELYAF1P5XYO/ke17ZwdGBToddI8pDm48kI-ufTzuIyBgq5smTFSesZ8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIC3HqRX9SuBN0e3zMQF24mUHHgQSMCms5WX5f0KPvnGV8OpWIHMEzVaGEnf67Zcc/joseph%252Bschumpeter.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590791903991-0UVJR5M8GELYAF1P5XYO/ke17ZwdGBToddI8pDm48kI-ufTzuIyBgq5smTFSesZ8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIC3HqRX9SuBN0e3zMQF24mUHHgQSMCms5WX5f0KPvnGV8OpWIHMEzVaGEnf67Zcc/joseph%252Bschumpeter.jpg" data-image-dimensions="1051x591" data-image-focal-point="0.5,0.5" alt="joseph%2Bschumpeter.jpg" data-load="false" data-image-id="5ed18edfb1bea64aa265f46a" data-type="image" src="https://www.ofmos.com/joseph%2Bschumpeter.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1590784412274_16238"><div><h3>Joseph Schumpeter: Creative Destruction</h3><p>“Capitalism, then, is by nature a form or method of economic change and not only never is but never can be stationary. And this evolutionary character of the capitalist process is not merely due to the fact that economic life goes on in a social and natural environment which changes[.] […] The fundamental impulse that sets and keeps the capitalist engine in motion comes from the new consumers’ goods, the new methods of production or transportation, the new markets, the new forms of industrial organization that capitalist enterprise creates. […]</p><p>The opening up of new markets, foreign or domestic, and the organizational development from the craft shop and factory to such concerns as U. S. Steel illustrate the same process of industrial mutation — if I may use that biological term — that incessantly revolutionizes the economic structure <em>from within</em>, incessantly destroying the old one, incessantly creating a new one.&nbsp;This process of Creative Destruction is the essential fact about capitalism.&nbsp;It is what capitalism consists in and what every capitalist concern has got to live in.”</p><p>— Excerpted from Joseph Schumpeter’s “Capitalism, Socialism and Democracy” (1942)</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1590790673064_18724"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590791932355-JKFUN2W7KANQTOR26J6C/ke17ZwdGBToddI8pDm48kKQAGiJ8QoxQVZThzFVMI9wUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dv611mQ9iQVKPCSuQUyCgQfJgq3EQY20myI8A3lW-G-r3WUfc_ZsVm9Mi1E6FasEnQ/peter%252Bdrucker.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1590791932355-JKFUN2W7KANQTOR26J6C/ke17ZwdGBToddI8pDm48kKQAGiJ8QoxQVZThzFVMI9wUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dv611mQ9iQVKPCSuQUyCgQfJgq3EQY20myI8A3lW-G-r3WUfc_ZsVm9Mi1E6FasEnQ/peter%252Bdrucker.jpg" data-image-dimensions="1710x962" data-image-focal-point="0.5,0.5" alt="peter%2Bdrucker.jpg" data-load="false" data-image-id="5ed18efbdf699b54f883a601" data-type="image" src="https://www.ofmos.com/peter%2Bdrucker.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1590789097891_18195"><div><h3>Peter Drucker: Entrepreneurial Society</h3><p>“Innovation and entrepreneurship are thus needed in society as much as in the economy, in public-service institutions as much as in businesses. It is precisely because innovation and entrepreneurship are not ‘root and branch’ but ‘one step at a time,’ a product here, a policy there, a public service yonder; because they are not planned but focused on this opportunity and that need; because they are tentative and will disappear if they do not produce the expected and needed results; because, in other words, they are pragmatic rather than dogmatic and modest rather than grandiose — that they promise to keep any society, economy, industry, public service, or business flexible and self-renewing. […]</p><p>What we need is an entrepreneurial society in which innovation and entrepreneurship are normal, steady, and continual. Just as management has become the specific organ of all contemporary institutions, and the integrating organ of our society of organizations, so innovation and entrepreneurship have to become an integral life-sustaining activity in our organizations, our economy, our society.”</p><p>— Excerpted from Peter Drucker’s “Innovation and Entrepreneurship” (1985)</p></div></div></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ee5367eae359b2983c8616a" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.9,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;sectionTheme&quot; : &quot;bright&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ee5367eae359b2983c8616a"><div><div><div data-block-type="2" id="block-f21fc181d86799296602"><div><h2>The Ofmos Lens</h2><p>Understand economies as ever-changing collections of virtual business spaces defined by an offering and a set of customers with the same need-addressing behavior associated to that offering. Use the Ofmos theory and model to think about the economy as a complex system.</p><p>Then follow the signature that an economy leaves on the continuum of need-addressing behaviors (or perceived offering value), and note its tendency to “bunch up.” Knowing that the economy’s bunchiness level indicates the society’s health, translate your goals into guidance and approach.</p></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec7522d117f476816949b2a" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;white-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec7522d117f476816949b2a"><div><div><div data-block-type="2" id="block-a26aa835bbfc1a176d46"><p><h2>Economic Worldview and Theory</h2></p></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1590172530745_14562"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326413037-WDXJ8MG4OZLPQK3XY6HY/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.022.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326413037-WDXJ8MG4OZLPQK3XY6HY/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.022.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" alt="ofmos-web2020-image.022.png" data-load="false" data-image-id="5ed9b7bb2b7da27a37b4607a" data-type="image" src="https://www.ofmos.com/ofmos-web2020-image.022.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-605767a9671438a7d8a5"><div><h3>Ofmos</h3><p>View companies and economies as collections of ofmos, which are virtual  worlds defined by an offering and a set of customers with the same  behavior.</p></div></div><div data-block-type="2" id="block-99a719955d4a414e99c0"><div><h3>Dynamic Perspective</h3><p>Analyze companies and economies as evolving systems of commoditizing ofmos (offering-market cosmos) or simply as groups of interrelated particles.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1591293197411_24221"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326674775-W7XR88G7EZC6TDT4U9Y4/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326674775-W7XR88G7EZC6TDT4U9Y4/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.069.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" alt="ofmos-web2020-image.069.png" data-load="false" data-image-id="5ed9b7d162e9755b3256cdb6" data-type="image" src="https://www.ofmos.com/ofmos-web2020-image.069.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1591293197411_26500"><div><h3>Economic Cycles</h3><p>Note how economies go through fluctuations, with the constituent collection of (t)ofmos “bunching” and “debunching” over time, directly influencing the society.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1592363329081_26547"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326760386-DJ62Y4WA8WVRI81BKZCT/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.070.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591326760386-DJ62Y4WA8WVRI81BKZCT/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.070.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" alt="ofmos-web2020-image.070.png" data-load="false" data-image-id="5ee989b41cd273133d5700df" data-type="image" src="https://www.ofmos.com/ofmos-web2020-image.070.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592363329081_27858"><div><h3>Tofmos and Ofmos</h3><p>Use the concept of tofmos (total-offering-market-cosmos) to analyze  economies, and the concept of ofmos (offering-market-cosmos) for  companies.</p></div></div></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec820ed18c584174f6f4888" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;light-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec820ed18c584174f6f4888"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1590174983141_16062"><div><h3>The Ofmos Economic Model</h3><p>Use a “complex system” perspective on economies to understand how they evolve and how they influence societies.</p></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec7522d117f476816949b2c" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;bright&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5ec7522d117f476816949b2c"><div><div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1591246204775_33139"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591246136683-D5NTB0W0ZAXB7GZMO9HZ/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/CristianMitreanu-RedefiningStrategy-TheoryOfNeedsAndValue-20181015.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591246136683-D5NTB0W0ZAXB7GZMO9HZ/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/CristianMitreanu-RedefiningStrategy-TheoryOfNeedsAndValue-20181015.jpg" data-image-dimensions="2500x3235" data-image-focal-point="0.5,0.5" alt="CristianMitreanu-RedefiningStrategy-TheoryOfNeedsAndValue-20181015.jpg" data-load="false" data-image-id="5ed87e486991040c505fe1e8" data-type="image" src="https://www.ofmos.com/CristianMitreanu-RedefiningStrategy-TheoryOfNeedsAndValue-20181015.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1591246204775_19034"><div><h3>Needs and Value</h3><p>The article “A Natural Theory of Needs and Value” describes the new view on human nature.</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1591246204775_34355"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591226634313-2O25VGGI3N4RDEPI84O0/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/Spointra-Cover-Front-20140915-FINAL.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591226634313-2O25VGGI3N4RDEPI84O0/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/Spointra-Cover-Front-20140915-FINAL.jpg" data-image-dimensions="2500x3235" data-image-focal-point="0.5,0.5" alt="Spointra-Cover-Front-20140915-FINAL.jpg" data-load="false" data-image-id="5ed87e5c5bbd301c84aecb99" data-type="image" src="https://www.ofmos.com/Spointra-Cover-Front-20140915-FINAL.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1591246204775_22840"><div><h3>Business Success</h3><p>The picture book “Spointra and the Secret of Business Success” details the new worldview in a fun way.</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1591309339971_26177"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591309060380-IPD0N4TTAX6ZH5EKBEIN/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/CristianMitreanu-Spointra-BeyondTheFun-20130519-DRAFT.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1591309060380-IPD0N4TTAX6ZH5EKBEIN/ke17ZwdGBToddI8pDm48kJanlAjKydPZDDRBEy8QTGN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hveExjbswnAj1UrRPScjfAi-WHBb3R4axoAEB7lfybbrcBqLQ3Qt4YGS4XJxXD2Ag/CristianMitreanu-Spointra-BeyondTheFun-20130519-DRAFT.jpg" data-image-dimensions="2500x3235" data-image-focal-point="0.5,0.5" alt="CristianMitreanu-Spointra-BeyondTheFun-20130519-DRAFT.jpg" data-load="false" data-image-id="5ed97454f5d09417a6dbc941" data-type="image" src="https://www.ofmos.com/CristianMitreanu-Spointra-BeyondTheFun-20130519-DRAFT.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1591246204775_26009"><div><h3>Beyond the Fun</h3><p>The 49-page (draft) letter to the readers places the new theories inside the broader literature.</p></div></div></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5ec7522d117f476816949b2e" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;backgroundImage&quot; : {
    &quot;id&quot; : &quot;5ef18bcb53bdf278e3f399a5&quot;,
    &quot;recordType&quot; : 2,
    &quot;addedOn&quot; : 1592888267339,
    &quot;updatedOn&quot; : 1592888343125,
    &quot;workflowState&quot; : 1,
    &quot;publishOn&quot; : 1592888267339,
    &quot;authorId&quot; : &quot;589a219a46c3c44baeacffc2&quot;,
    &quot;systemDataId&quot; : &quot;1592888267479-91LMRT5KGF6ZGP1LQMC9&quot;,
    &quot;systemDataVariants&quot; : &quot;942x942,100w,300w,500w,750w&quot;,
    &quot;systemDataSourceType&quot; : &quot;PNG&quot;,
    &quot;filename&quot; : &quot;ofmos-web2020-image.086.png&quot;,
    &quot;mediaFocalPoint&quot; : {
      &quot;x&quot; : 0.5,
      &quot;y&quot; : 0.5,
      &quot;source&quot; : 3
    },
    &quot;colorData&quot; : {
      &quot;topLeftAverage&quot; : &quot;000000&quot;,
      &quot;topRightAverage&quot; : &quot;000000&quot;,
      &quot;bottomLeftAverage&quot; : &quot;000000&quot;,
      &quot;bottomRightAverage&quot; : &quot;000000&quot;,
      &quot;centerAverage&quot; : &quot;000000&quot;,
      &quot;suggestedBgColor&quot; : &quot;000000&quot;
    },
    &quot;urlId&quot; : &quot;bw3aboc98lpfk5atxuzdtmgaw99tpj&quot;,
    &quot;title&quot; : &quot;&quot;,
    &quot;body&quot; : null,
    &quot;likeCount&quot; : 0,
    &quot;commentCount&quot; : 0,
    &quot;publicCommentCount&quot; : 0,
    &quot;commentState&quot; : 2,
    &quot;unsaved&quot; : false,
    &quot;author&quot; : {
      &quot;id&quot; : &quot;589a219a46c3c44baeacffc2&quot;,
      &quot;displayName&quot; : &quot;Cristian Mitreanu&quot;,
      &quot;firstName&quot; : &quot;Cristian&quot;,
      &quot;lastName&quot; : &quot;Mitreanu&quot;,
      &quot;websiteUrl&quot; : &quot;http://www.cristianmitreanu.com&quot;,
      &quot;bio&quot; : &quot;&quot;
    },
    &quot;assetUrl&quot; : &quot;https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1592888267479-91LMRT5KGF6ZGP1LQMC9/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.086.png&quot;,
    &quot;contentType&quot; : &quot;image/png&quot;,
    &quot;items&quot; : [ ],
    &quot;pushedServices&quot; : { },
    &quot;pendingPushedServices&quot; : { },
    &quot;recordTypeLabel&quot; : &quot;image&quot;,
    &quot;originalSize&quot; : &quot;942x942&quot;
  },
  &quot;imageOverlayOpacity&quot; : 0.9,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;customSectionHeight&quot; : 10,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;customContentWidth&quot; : 50,
  &quot;sectionTheme&quot; : &quot;light-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  <div>
  
    
      
      <p><img alt="" data-src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1592888267479-91LMRT5KGF6ZGP1LQMC9/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.086.png" data-image="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1592888267479-91LMRT5KGF6ZGP1LQMC9/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.086.png" data-image-dimensions="942x942" data-image-focal-point="0.5,0.5" data-load="false" src="https://images.squarespace-cdn.com/content/v1/5e7bba60018d890de703a097/1592888267479-91LMRT5KGF6ZGP1LQMC9/ke17ZwdGBToddI8pDm48kCbb2eKItvfwa0CDzt1q4zpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIMUjQoZs1pTWwzYpiJME_msW7atwiXoSdPfAPxa2PB_Q/ofmos-web2020-image.086.png"></p>
    
  
  </div>
  
</section>

  
    <section data-section-id="5ec7522d117f476816949b30" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--medium&quot;,
  &quot;sectionTheme&quot; : &quot;dark-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  
</section>

  
</article>

          
          
          
        
      </main>
      

      
        
      
    </div></div>]]>
            </description>
            <link>https://www.ofmos.com/how-economies-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838632</guid>
            <pubDate>Tue, 14 Jul 2020 22:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breaking Down Lululemon's $500M Mirror Acquisition]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23838564">thread link</a>) | @Cpevans
<br/>
July 14, 2020 | https://insider.fitt.co/issue-no-87-why-mirror-sold/ | <a href="https://web.archive.org/web/*/https://insider.fitt.co/issue-no-87-why-mirror-sold/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-content">
			<div>
				<div>
					<section>
						<p>A few weeks back, lululemon acquired Mirror for $500M. When the news broke, we wrote&nbsp;<a href="https://insider.fitt.co/lululemon-acquires-mirror-500m/" target="_blank" rel="noopener">a quick analysis</a>&nbsp;of how the partnership might play out. Today, we’re going deeper to explore lulu’s ambitions, Mirror’s motivation for selling, and how, in hindsight, Nike, Peloton, and COVID-19 sealed the deal.</p>
<p><strong>TL;DR:</strong>&nbsp;Even if this acquisition doesn’t pan out, everybody wins. Here’s why.</p>
					</section>

          <section>
						      <div>
        <div>
                      <h2>Calculated Risk</h2>
          
          <p>M&amp;A is a mixed bag. In the case of activewear retailers, buying into digital fitness via high-profile purchases has&nbsp;<a href="https://twitter.com/JoeVennare/status/1281301589190488064" target="_blank" rel="noopener">proven futile</a>. So why did lululemon, a fast-growing apparel company, roll the dice on Mirror? One word: Nike.</p>
<p>Nike is the king of activewear. Try as they might, foes like adidas, Reebok, and Under Armour are no match for the swoosh. For its part, lululemon hopes to become a worthy adversary — if for no other reason than to remain in the good graces of Wall Street. On both accounts, Mirror factors heavily into the equation.</p>
<p>Putting this competition into context, lululemon trails Nike by an order of magnitude. Nike has a $152B market cap. Over the last 12 months, they’ve done $37B in sales. Meanwhile, lulu’s market cap is $37B, and the company had revenues of $3.85B over the same period.</p>
<p>While shares of the yoga pant maker have outperformed Nike in recent years, lulu might not ever reach the scale of Nike. But beating Nike outright isn’t the point. Ultimately, lululemon is in competition with itself, where Nike represents the upper bounds of what’s possible.</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>Just Keep Growing</h2>
          
          <p>To prove that they haven’t peaked, lululemon has one mandate: just keep growing.</p>
<p>Moving beyond the yoga niche and expanding its total addressable market, the company’s&nbsp;<a href="https://us15.campaign-archive.com/?u=4c6bc12e271bc681951ed945a&amp;id=96471d02c6" target="_blank" rel="noopener">five-year strategic plan</a>, released in April 2019, charted the path forward: “double men’s, double digital, and quadruple international” revenues. Add self-care products, a foray into footwear, and the opening of a 20,000-square-foot experiential store (complete with yoga studios and a restaurant) into the mix and grow they shall.</p>
<p>A few months later, in November of 2019, lululemon invested $1M into Mirror’s $34M Series B-1, a bargain for a foothold in connected fitness. As part of the investment, and in keeping with its goal of becoming an experiential brand, lululemon ambassadors began creating workout content for the Mirror platform.</p>
<p>Flash-forward to March: when COVID hit, the table was set. With retail stores shuttered and fitness studios closed, shopping and sweating moved online. In a few short weeks, lululemon had seen enough; they were ready to go all-in on Mirror.</p>
<ul>
<li>In the first week of store closures, 170K people joined lulu’s live workouts on Instagram.</li>
<li>Pre-COVID, 64% of lululemon guests used a digital workout option at home.</li>
<li>During the pandemic, as the coronavirus spread, that number jumped to 75%.</li>
<li>86% of lulu customers who used an at-home option during the outbreak plan to continue or increase their new digital workout habit.</li>
</ul>
<p>In April, lulu’s online sales surged&nbsp;<a href="https://www.cnbc.com/2020/06/11/lululemon-lulu-reports-fiscal-q1-2020-earnings.html" target="_blank" rel="noopener">125%</a>, a trend that’s expected to continue. Add in the fact that some 50% of Mirror users are also lululemon customers, and this deal checks a lot of boxes for the growth-focused retailer.</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>Why Mirror Sold</h2>
          
          <p>Last year, Mirror CEO Brynn Putnam told Fast Company she was building “the next iPhone.” Far from another connected fitness upstart, Mirror would be “the third screen in your life that you’re going to turn to for all immersive interactive experiences going forward.”</p>
<p>About seven months later, Putnam pulled the ripcord, selling her company amid a global pandemic — circumstances tailor-made for an immersive third screen.</p>
<p>So why did Mirror sell? lulu made an offer they couldn’t refuse. Putnam, a solo, female founder just secured a “W” for herself, her investors, and New York’s startup scene.</p>
<p>Beyond the obvious, it’s fair to ask,&nbsp;<em>why now?</em>&nbsp;In many ways, Peloton forced Putnam’s hand.</p>
<p>Pitching Mirror as the “next iPhone” was a strategic move that 1.) established a big vision worthy of $70M+ in funding, and 2.) helped the company duck the question, “how do you compete with Peloton?” Their answer was simple — we don’t.</p>
<p>When COVID hit, Mirror was pigeonholed. They weren’t the third screen, they were in direct competition with Peloton. And despite surging sales, Mirror’s growth pales in comparison to Peloton’s. Plus, there’s&nbsp;<a href="https://www.linkedin.com/posts/joevennare_fitness-startups-activity-6679025786697117697-YuI5" target="_blank" rel="noopener">a growing list of Mirror-like competitors</a>&nbsp;hitting the market. All of a sudden, an interactive screen didn’t feel all that innovative, or defensible.</p>
<p>Meanwhile, digital fitness companies are raking in funding. Hydrow, Aaptiv, and NEOU recently closed investments as Tonal and Tempo target new funds. If Mirror considered raising on the back of its COVID boost, they’d have to become a customer acquisition and retention machine, where every move is audited in relation to Peloton’s now public (and soaring) metrics.</p>
<p>In the end, joining forces with lululemon was more compelling than slugging it out with Peloton or adhering to the “third screen” narrative.</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>Lulu x Mirror</h2>
          
          <p>Upon announcing the deal, lululemon’s stock jumped, and onlookers have been quick to heap on the praise.</p>
<p>According to Bank of America analysts, Mirror could generate&nbsp;<a href="https://www.marketwatch.com/amp/story/lululemon-acquisition-mirror-could-generate-700-million-and-reach-600000-subscribers-by-2023-bank-of-america-2020-07-01" target="_blank" rel="noopener">$700M</a>&nbsp;in revenue and reach 600,000 subscribers by 2023.</p>
<p>To realize this lofty forecast, lululemon will sell Mirrors to its existing customer base, starting with its 489 corporate-owned stores across the globe. The retailer will continue creating content for the platform, where Mirror instructors will be clad in lululemon gear. More than simply selling more apparel, Mirror’s ability to generate recurring revenue and strengthen lulu’s relationship with consumers is the chief aim of this acquisition.</p>
<p>While the hard work of transforming an athleisure retailer into a tech company is just beginning, it will be difficult to criticize lululemon for shooting this shot. Whether or not they can keep growing will be the question on everyone’s mind:</p>
<p><em>“Lulu is showing no signs of slowing down, but acquisitions made outside a retailer’s core skill set have rarely been seamless. There is nothing bad about the story right now. The scariest thing [for investors] about Lulu is, is this as good as it gets?”</em>&nbsp;– Simeon Siegel, managing director &amp; senior retail analyst at BMO Capital Markets.</p>
<hr>
        </div>
      </div>

            <div>
        <div>
                      <h2>💻 Closing the Gap </h2>
          
          <p>Teletherapy is gaining traction during the pandemic. It just might be the key to unlocking access for millions of individuals battling mental illness.</p>
<p>There’s a&nbsp;<a href="https://insider.fitt.co/wellness-startups-mental-health/" target="_blank" rel="noopener">shocking gap</a>&nbsp;between demand (those in need of care) and supply (access to affordable care).</p>
<ul>
<li>46M Americans report experiencing mental illness each year, while only 42.6% received treatment.</li>
<li>Individuals who are able to access care will wait an average of&nbsp;<a href="https://www.psychiatryadvisor.com/home/practice-management/long-wait-times-typical-for-psychiatry-appointments/" target="_blank" rel="noopener">25 days</a>&nbsp;for an appointment.</li>
<li>With in-room therapy costing $150–$400 per session, plus the added cost of medication,&nbsp;<a href="https://www.kff.org/medicaid/report/mental-health-financing-in-the-united-states/" target="_blank" rel="noopener">45%</a>&nbsp;of untreated individuals cite cost as a barrier.</li>
</ul>
<p><strong>Pros:</strong>&nbsp;During COVID, the majority of therapists switched from in-person to remote therapy. A recent&nbsp;<a href="https://www.apaservices.org/practice/legal/technology/psychologists-embrace-telehealth" target="_blank" rel="noopener">survey</a>&nbsp;found that three quarters of clinicians are exclusively using teletherapy. The fact that teletherapy has been&nbsp;<a href="https://pubmed.ncbi.nlm.nih.gov/26864655/" target="_blank" rel="noopener">shown to be</a>&nbsp;just as effective as in-person therapy for treating PTSD, depression, and anxiety helped solidify the switch.</p>
<p><strong>Cons:</strong>&nbsp;The convenience and flexibility of remote care have proven beneficial, but concerns related to privacy regulations, insurance coverage, Zoom fatigue, and missing non-verbal cues leave a lot of room for improving the experience.</p>
<p>As consumer demand for digital behavioral health grows, investors are seizing the moment.</p>
<ul>
<li>According to&nbsp;<em>Rock Health</em>, in the first half of 2020, digital behavioral health companies received&nbsp;<a href="https://rockhealth.com/reports/2020-midyear-digital-health-market-update-unprecedented-funding-in-an-unprecedented-time/" target="_blank" rel="noopener">$588M</a>&nbsp;in funding — a number equal to the annual funding for this category in any previous year.</li>
</ul>
<p><strong>Looking ahead:</strong>&nbsp;With anxiety and isolation at an&nbsp;<a href="https://insider.fitt.co/insider-newsletter-issue-82-ending-addiction/" target="_blank" rel="noopener">all-time high</a>, the need to confront the&nbsp;<a href="https://insider.fitt.co/wellness-startups-mental-health/" target="_blank" rel="noopener">mental health crisis</a>&nbsp;has never been greater. A bright spot amid the pandemic, digital behavioral health is&nbsp;<a href="https://insider.fitt.co/wellness-startups-stigma/" target="_blank" rel="noopener">destigmatizing</a>&nbsp;and expanding access to care.</p>
<p><strong>Related:</strong>&nbsp;<a href="https://insider.fitt.co/23-alex-katz-ceo-of-two-chairs/" target="_blank" rel="noopener">Two Chairs CEO Alex Katz</a>&nbsp;on the Fitt Insider podcast</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>🥊 Put ’em Up</h2>
          
          <p>Liteboxer, the latest&nbsp;<a href="https://us15.campaign-archive.com/?u=4c6bc12e271bc681951ed945a&amp;id=f14e6a628d" target="_blank" rel="noopener">Peloton of ‘X’</a>&nbsp;upstart, is taking aim at boxing within the booming connected fitness category.</p>
<p><strong>What it is:</strong>&nbsp;A competitor to FightCamp, an interactive at-home boxing experience, Liteboxer offers a free-standing, light-up punching bag for $1,495 and a $29/month content subscription.</p>
<p><strong>How it works:</strong>&nbsp;While FightCamp offers punch tracking technology and a variety of workouts from “real fighters”, Liteboxer looks a lot like Dance Dance Revolution for boxing. Flashing lights synced to music tell users where to hit and a force-tracking bag measures performance.</p>
<p><strong>Looking ahead:</strong>&nbsp;Following in Peloton’s footsteps is tempting, but surely at-home fitness has a ceiling — especially when every piece of equipment costs $1,500 or more.</p>
<p>For their part, Peloton appears to be rethinking the category a bit. The company was rumored to be working on a connected rower à la Hydrow. But recently, CFO Jill Woodworth&nbsp;<a href="https://outline.com/9fv3sB" target="_blank" rel="noopener">said</a>&nbsp;the company will forgo the rower, for now, in favor of a cheaper treadmill. Woodworth also said developing a product for the “boot camp category” is a priority. Is Peloton’s Mirror competitor in the works?</p>
<p><strong>Related:</strong>&nbsp;<a href="https://insider.fitt.co/7-khalil-zahar-co-founder-ceo-of-fightcamp/" target="_blank" rel="noopener">FightCamp CEO Khalil Zahar</a>&nbsp;on the Fitt Insider podcast</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>📰 News &amp; Notes</h2>
          
          <ul>
<li>The designification of&nbsp;<a href="https://www.metropolismag.com/interiors/healthcare-interiors/the-problem-with-the-designification-of-health-care/" target="_blank" rel="noopener">health</a>.</li>
<li>A&nbsp;<a href="https://twitter.com/joevennare/status/1278739336268308480?s=12" target="_blank" rel="noopener">thread</a>: Apple as a healthcare company</li>
<li>A 2015&nbsp;<a href="https://medium.com/@nickcrocker/how-to-lose-200m-pounds-why-myfitnesspal-works-d00f392d9783" target="_blank" rel="noopener">memo</a>: How MyFitnessPal works.</li>
<li>Meet&nbsp;<a href="https://highcourt.co/" target="_blank" rel="noopener">Highcourt</a>, NYC’s new wellness-focused “leisure club”.</li>
<li>Who are the best early-stage fitness and wellness&nbsp;…</li></ul></div></div></section></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://insider.fitt.co/issue-no-87-why-mirror-sold/">https://insider.fitt.co/issue-no-87-why-mirror-sold/</a></em></p>]]>
            </description>
            <link>https://insider.fitt.co/issue-no-87-why-mirror-sold/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838564</guid>
            <pubDate>Tue, 14 Jul 2020 22:04:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Liquidity in Sports Betting Markets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838538">thread link</a>) | @conordurkin
<br/>
July 14, 2020 | http://conordurkin.com/liquidity-in-sports-betting-markets/ | <a href="https://web.archive.org/web/*/http://conordurkin.com/liquidity-in-sports-betting-markets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
			
		<div>
		
<p><em>O<em>r, some thoughts on the theory of bid-ask spreads in gambling markets</em></em></p>



<p>One of the things I’ve found interesting to think about for a few months now is how spreads and odds get set by bookmakers. I’ve written a bit about this before, in terms of how the line gets set, but also think it’s worth considering how the house edge is set on any given market. In the simplest terms, what determines whether a two-sided market is -110 on both sides<span id="easy-footnote-1-186"></span><span><a href="#easy-footnote-bottom-1-186" title="~4.55% house edge"><sup>1</sup></a></span> or -115 on both sides <span id="easy-footnote-2-186"></span><span><a href="#easy-footnote-bottom-2-186" title="~6.52% house edge"><sup>2</sup></a></span>, or some other number? Put differently, and more broadly, this can be thought of as a question around efficiency and liquidity in gambling markets, and what determines the bid-ask spread.</p>



<p>It’s useful to start with how lines get set. Broadly speaking, bookmakers begin by opening markets at prices they think reflect the ‘right price’ for a game, based on their actual expectations of performance, expectations of people’s bets, and a variety of other factors<span id="easy-footnote-3-186"></span><span><a href="#easy-footnote-bottom-3-186" title="Contrary to popular belief, it is not entirely based on &amp;#8220;what gets me 50-50 on each side&amp;#8221; &amp;#8211; I wrote a bit about this before, <strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>h</a></strong><strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>e</a></strong><strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>r</a></strong><strong><a href=&quot;http://conordurkin.com/bookmakers-and-keynesian-beauty-contests/&quot;>e</a></strong>."><sup>3</sup></a></span>. Gamblers (or market participants, if you prefer to sound more academic) then places wagers in these markets, moving the line one way or another based on their aggregate volumes, and the line eventually moves to a more efficient equilibrium price such that future bets aren’t one-sided and won’t move the market<span id="easy-footnote-4-186"></span><span><a href="#easy-footnote-bottom-4-186" title="One very very important clarification here: this is not as basic as seeing which side has more volume and shifting the line accordingly; there is far more too it than that. Just as electronic stock market makers or HFTs will likely shift their markets if they know they&amp;#8217;re getting retail volume from someone like Robinhood as opposed to institutional interest from some smart hedge fund, bookmakers will absolutely move their lines differently depending on whether they&amp;#8217;re receiving a few big bets from some random Joe Public as opposed to receiving big bets from known sharp gamblers. While enough one-sidedness of the former *may* move a line, it is much, much, much more the case that they will respond to the latter (and quickly)."><sup>4</sup></a></span>.</p>



<p>At the highest level: markets which reach that equilibrium price faster should have tighter bid-ask spreads. In a gambling context, that should be reflected in the form of a lower vig; the most efficient market possible would be one offering true odds<span id="easy-footnote-5-186"></span><span><a href="#easy-footnote-bottom-5-186" title="E.g. +100 on either side of a 50-50 outcome."><sup>5</sup></a></span>, with any house edge eating away at liquidity in some aspect. The key here is that the tightness of a bid-ask spread is reflective of the risk that the marketmaker is taking; in situations where the marketmaker can trust that he is not exposed to as much risk<span id="easy-footnote-6-186"></span><span><a href="#easy-footnote-bottom-6-186" title="Because the price is correct, or because the market is liquid enough that in the long run he will certainly reach the right price."><sup>6</sup></a></span>, then he should be willing to offer a tighter market to attract more bets.</p>



<p>What makes a market reach that price faster? It’s primarily a function of liquidity. A market with a lot of gamblers, a lot of bets, and a lot of dollars at stake has a lot more volume and is a lot more liquid. Consequently, there’s enough activity going on that you’re able to reach the ‘right price’ a lot quicker. It’s not that the prices in these market necessarily start any more accurately than any others; they just move more quickly into equilibrium much more quickly. This is pretty straightforward to see in the gambling world; the most heavily bet markets are generally NFL games (both spreads and totals), and those bets are generally regarded as most efficient and hardest to find an edge on<span id="easy-footnote-7-186"></span><span><a href="#easy-footnote-bottom-7-186" title="Again, unless you&amp;#8217;re waiting at the window until the minute they open and sharp gamblers haven&amp;#8217;t had an opportunity to move the prices into equilibrium yet."><sup>7</sup></a></span>.</p>



<p>Beyond liquidity, events with more precisely well-known mathematical odds should also be more efficient markets, and this should again be reflected in tighter spreads. However, in this instance the efficiency is a function of the event itself rather than a function of the market participants – if the true odds are particularly well known, the marketmaker can be more confident that his opening lines are already the ‘efficient prices’ and he doesn’t have to rely on gamblers to get him there. As an example, one of the popular Super Bowl prop bets offered every year is whether the coin toss will be Heads or Tails. Prop bets (or derivative bets) tend to get less action than most ‘regular’ bets, and they usually have larger vigs to reflect the fact that they’re less efficient markets. But this is an obviously 50-50 proposition, it’s a literal coin flip – and I think every time I’ve seen the prop offered, it’s been a -105 bet<span id="easy-footnote-8-186"></span><span><a href="#easy-footnote-bottom-8-186" title="~2.38% house edge"><sup>8</sup></a></span> on either side, reflecting that fact.</p>



<p>Conversely, less liquid or well-known stuff should in contrast see wider spreads. I already mentioned derivative (or prop) bets as one example here; less money chasing those markets means prices can remain inefficient longer, and there’s a higher risk of one-sided traffic<span id="easy-footnote-9-186"></span><span><a href="#easy-footnote-bottom-9-186" title="In a liquid market with lots of bettors, you&amp;#8217;ll have enough volume on both sides of a betting market for the price to reach equilibrium and be &amp;#8216;efficient&amp;#8217;. In a smaller market, you might never reach that equilibrium price if the market started at a bad price, so the net exposure to the bookmaker is very one-sided. This is fairly evidently riskier for the bookmaker."><sup>9</sup></a></span>. In some instances, you can actually see the ‘efficiency as liquidity’ question play out in real time, with not just the lines moving dynamically, but the size of the spreads as well. In college football, for example, while most big college football games are pretty liquid markets, FCS games are much less commonly bet. I’ve very frequently seen markets start at -120 or -125 on Monday morning, but have those spreads shrink to -110 on Saturday around noon when it’s almost gametime. Why are they able to tighten the market? Because by that point they feel pretty good about the quality of the price they’re offering, so they have less need to protect against price risk – despite the fact that it was perfectly logical for them to do so a few days prior.</p>



<p>One particularly interesting ‘less liquid’ example is in futures betting <span id="easy-footnote-10-186"></span><span><a href="#easy-footnote-bottom-10-186" title="For example, &amp;#8220;Which team will win the World Series?&amp;#8221; &amp;#8211; markets which deal not with one event happening quickly, but that deal with a bigger event happening down the road"><sup>10</sup></a></span>, which has two real wrinkles to deal with. First, time lag – these events are all things that happen in the future, not today, and the correct probabilities will evolve over time. This creates some level of uncertainty risk in that the efficient prices will change over time, could change dramatically over time, and even if the market lands on the efficient prices today the marketmaker faces a real risk that in the future the market won’t remain liquid enough to stay efficient as prices evolve. That uncertainty ends up reflected in a wider spread. Secondly, these are typically not 1-on-1 outcomes; there’s a whole field of potential options<span id="easy-footnote-11-186"></span><span><a href="#easy-footnote-bottom-11-186" title="For example, there are 30 teams that could win the World Series. Okay, maybe 29 &amp;#8211; the Orioles aren&amp;#8217;t getting it done this year, even with a 60 game season."><sup>11</sup></a></span>. As such, getting to “equilibrium” is a lot harder because it’s not about A vs B, it’s about A, B, C… to Z all being reasonably efficient prices. Liquidity is a lot harder because even with a lot of people betting, there’s no guarantee you’ll receive enough volume on each individual possible outcome of the futures market for the prices to be accurate; it’s a lot easier for a few to be out of whack. Books end up protecting against this by having a much, much higher hold in futures markets than in regular betting – where the house edge is usually something like 4-5% in any typical point spread, the total house edge in most futures markets is often 20-30% or more.</p>



<p>Another example is in live betting, where wagers are accepted during the actual course of play of a game. These markets typically see much wider spreads (something like -120 on each side instead of -110), largely because the timeframe in which bettors can move the price is basically nonexistant – the game is already going on! Bookmakers either have to be very very confident in the prices they offer or offer a less liquid market to protect themselves. They generally choose the latter.</p>



<p>It’s also worth thinking about alternative forms of illiquidity, where you can get tighter spreads at the cost of something else. One example is betting exchanges like Betfair – rather than having a marketmaker take your risk, these exchanges use a peer-to-peer market where your wager remains pending until some other bettor wants to take the other side. Because the exchange isn’t taking any risk themselves, they’re protected against any ‘inefficient prices’ and never have any net exposure, so bettors are able to benefit from tighter spreads<span id="easy-footnote-12-186"></span><span><a href="#easy-footnote-bottom-12-186" title="Betfair typically charges a commission of ~5% on winning tickets, which works out to a house edge of ~2.5%"><sup>12</sup></a></span>, at the cost of some execution risk (you’re not guaranteed for your wager to be received until someone takes the other side). Another example is in parimutuel betting, where odds are constantly fluctuating and the actual odds at which a bet is locked in are not set until shortly prior to the event occurring (this is pretty popular in horse racing). The house takes a fixed percentage from the total pool of wagers and then pays out according to the final odds, so they’re again not taking any risk. From the bettor’s perspective, you can get a tighter ‘spread’ and you’re guaranteed to have your bet be valid, but you’re not guaranteed on the actual price, since that will still move around even after your bet is placed<span id="easy-footnote-13-186"></span><span><a href="#easy-footnote-bottom-13-186" title="For whatever reason, my understanding is that parimutuel horseracing still has a pretty healthy house cut. I still think intuitively the parimutuel format should lend itself to allowing for tighter spreads, but evidently that&amp;#8217;s not always the case."><sup>13</sup></a></span>.</p>



<p>Okay, now that we’re 1400 words into this – what’re the implications of all of this to the average gambler? In my experience a lot of times people see markets with lines at -115 or -120 and get annoyed at the bookmaker’s apparent stinginess. If that’s happening on a major event like an NFL or college football game, then sure, that doesn’t seem appropriate. But if that’s happening on more obscure events, it’s not indicative of cheapness – it’s indicative of the marketmaker being afraid that their price is wrong, and that means it’s an opportunity. Despite wider spreads, the average bettor is far more likely to be able to profit betting into markets with less efficient prices than they are into markets with tight spreads and perfectly efficient prices. Ed Miller and Matthew Davidow make this point really well in <em>The Logic of Sports Betting</em><span id="easy-footnote-14-186"></span><span><a href="#easy-footnote-bottom-14-186" title="I&amp;#8217;d like to be abundantly clear that I am not here to market this book, nor am I being compensated for it but it is an excellent read, and if you care about this sort of thing you should absolutely read it."><sup>14</sup></a></span> when they get into the idea of ‘strong markets versus weak markets,’ and the need for savvy gamblers to attack the latter – when markets are less liquid, spreads are often wider, but they’re less efficient, and that means they are much more likely to be beatable.</p>
		
			</div>

	<!-- .comments-area -->
</div></div>]]>
            </description>
            <link>http://conordurkin.com/liquidity-in-sports-betting-markets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838538</guid>
            <pubDate>Tue, 14 Jul 2020 22:01:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hey Protects Your People]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838398">thread link</a>) | @kenhara
<br/>
July 14, 2020 | https://harriskenny.com/2020/07/14/how-hey-protects-your-people/ | <a href="https://web.archive.org/web/*/https://harriskenny.com/2020/07/14/how-hey-protects-your-people/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I recently signed up for HEY (from the makers of Basecamp). The benefits of this service for you as an end-user are clear. And with how they’ve implemented this anti-tracking, HEY protects your people too. Your family members, your colleagues, your business partners. Read how.</p>



<p>I received an order confirmation and wanted to forward it to a family member, who isn’t using HEY (yet). HEY flagged that the email had tracking enabled… </p>



<p><strong>If HEY blocks the tracking for you, but you then forward the email… What happens? </strong></p>



<p>Good stuff, that’s what. </p>



<h2>HEY on Spy Trackers</h2>



<p>First, let’s check out HEY’s overall stance on <a rel="noreferrer noopener" href="https://hey.com/spy-trackers/" target="_blank">Spy Trackers</a>. Here’s the relevant section: </p>



<figure data-amp-lightbox="true"><img data-attachment-id="2819" data-permalink="https://harriskenny.com/screen-shot-2020-07-14-at-11-32-54-am/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png" data-orig-size="1402,900" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-07-14-at-11.32.54-am" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=700" src="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=1024" alt="HEY manages this protection through several layers of defenses. First, we’ve identified all the major spy-pixel patterns, so we can strip those out directly. When we find one of those pesky pixels, we’ll tell you exactly who put it in there, and from what email application it came. Second, we bulk strip everything that even smells like a spy pixel. That includes 1x1 images, trackers hidden in code, and everything else we can do to protect you. Between those two practices, we’re confident we’ll catch 98% of all the tracking that’s happening out there.

But even if a spy pixel sneaks through our defenses (and we vow to keep them updated all the time!), you’ll have an effective last line of defense: HEY routes all images through our own servers first, so your IP address never leaks. This prevents anyone from discovering your physical location just by opening an email. Like VPN, but for email." srcset="https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/screen-shot-2020-07-14-at-11.32.54-am.png 1402w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I first thought this might work like NoScript, Privacy Badger, or uBlock Origin. Where the tracking is prevented from loading, but is still there. Basically, keeping a lid on it. So I decided to email their customer support.</p>



<p><strong>Yep. There’s an email service provider with real humans providing customer support in 2020.</strong></p>



<h2>How it Works</h2>



<p>Spoiler alert: I was wrong! When they say strip, they literally mean strip. Here’s what the friendly (and prompt) response from their team explained:</p>



<figure><img data-attachment-id="2821" data-permalink="https://harriskenny.com/hey-tracking/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png" data-orig-size="2790,1884" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hey-tracking" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=700" src="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=1024" alt="" srcset="https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=2048 2048w, https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/hey-tracking.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Look at those time stamps! Now that’s service.</figcaption></figure>



<p>They don’t pass along the trackers, they strip them out. Link tracking gets more complicated because of <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/UTM_parameters" target="_blank">UTM parameters</a> and probably other things that I’m not aware of. But this is undeniable progress. </p>



<h2>Sidebar: How it Used to “Work”</h2>



<p>Quick note on how I used to handle this. I would disable image loading on all emails by default. This meant email HTML/CSS styling regularly broke and looked bad. But I did know that the tracking wouldn’t be passed through. It worked “well enough” but not really well at all.</p>



<p>Some unethical senders would try to get around this by sending all-image emails, requiring you to load the images. Then try to Unsubscribe but it’s a hassle, etc. (That’s where <a rel="noreferrer noopener" href="https://hey.com/features/the-screener/" target="_blank">The Screener</a> comes in with HEY.) </p>



<h2>Your Choice</h2>



<p>This falls somewhere between a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Virtuous_circle_and_vicious_circle" target="_blank">virtuous cycle</a> and a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Externality#Positive" target="_blank">positive externality</a>. Basically, when you choose an ethical service like HEY it creates a protective bubble that extends to the people around you. In other words, it partially breaks the tracking chain.</p>



<p><strong>I’m not sure the technical term for this. If you know, please tell me!</strong></p>



<p>Conversely, the same applies. Companies taking a different approach allow tracking to proliferate. They harvest and share information. This is especially concerning when you consider the intimacy of your email.</p>



<p>When you choose technology, you don’t just choose it for yourself. You choose it for the people around you, too. </p>



<hr>



<h2>More on HEY</h2>



<p>Check out the blog post below that I wrote about testing and sending HEY-friendly emails using MailChimp (one of the leading email marketing platforms).</p>


				<div>
			<div data-posts="">
								
	<article data-post-id="2680">
					<figure>
				<a href="https://harriskenny.com/2020/06/17/tracker-testing-hey-vs-mailchimp-can-they-coexist/" rel="bookmark">
					<img width="1200" height="900" src="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=1200&amp;h=900&amp;crop=1" alt="" srcset="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=1200&amp;h=900&amp;crop=1 1200w, https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=150&amp;h=113&amp;crop=1 150w, https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=300&amp;h=225&amp;crop=1 300w, https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=768&amp;h=576&amp;crop=1 768w, https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=1024&amp;h=768&amp;crop=1 1024w" sizes="(max-width: 1200px) 100vw, 1200px" data-attachment-id="2728" data-permalink="https://harriskenny.com/2020/06/17/tracker-testing-hey-vs-mailchimp-can-they-coexist/sending-html-yes-track-2/" data-orig-file="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png" data-orig-size="2472,1264" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sending-html-yes-track" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/06/sending-html-yes-track-1.png?w=700">				</a>

							</figure><!-- .featured-image -->
		
		<!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
					</div></div>]]>
            </description>
            <link>https://harriskenny.com/2020/07/14/how-hey-protects-your-people/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838398</guid>
            <pubDate>Tue, 14 Jul 2020 21:49:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snorkel AI: Putting Data First in ML Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23838310">thread link</a>) | @blopeur
<br/>
July 14, 2020 | https://www.snorkel.ai/07-14-2020-snorkel-ai-launch | <a href="https://web.archive.org/web/*/https://www.snorkel.ai/07-14-2020-snorkel-ai-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>
                      Today I’m excited to announce Snorkel AI’s launch out of stealth!
                      Snorkel AI, which spun out of the Stanford AI Lab in 2019, was founded on two simple premises: first, that the labeled <b>training data</b>  machine learning models learn from is increasingly what determines the success or failure of AI applications.
                      And second, that we can do much better than labeling this data entirely by hand.
                  </p>
                  <p>
                      At the Stanford AI lab, the Snorkel AI founding team spent over four years developing new <b>programmatic</b> approaches to labeling, augmenting, structuring, and managing this training data.
                      We were fortunate to develop and deploy early versions of our technology with some of the world’s leading organizations like <a href="https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html">Google</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3329486.3329492">Intel</a>, <a href="https://arxiv.org/abs/1909.05372">Apple</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2666389920300192">Stanford Medicine</a>, resulting in <a href="https://www.snorkel.ai/technology#reference">over thirty-six peer-reviewed publications</a> on our findings; innovations in weak supervision modeling, data augmentation, multi-task learning, and more; inclusion in university computer science curriculums; and deployments in popular products and systems that you’ve likely interacted with in the last few hours.
                  </p>
                  <p>
                      Through all this academic tinkering and industry spelunking, we realized two things: first, that this concept of labeling and building training data programmatically, rather than by hand, had transformational potential to make machine learning more iterative, auditable, faster to deploy, and ultimately, more practical.
                      And second, that these ideas changed not just how you label training data, but so much of the entire lifecycle and pipeline of ML: how knowledge and feedback is injected; how models are constructed, trained, versioned, and monitored; how entire pipelines are developed iteratively; and how the full set of stakeholders in any ML deployment, from subject matter experts to ML engineers, are incorporated into the process.
                  </p>
                  <p>
                      In other words, we saw that this shift to programmatic training data required a top-to-bottom rewrite of the entire ML development and deployment process.
                      With the support of some amazing investors (Greylock, GV, In-Q-Tel, and others) and incredible early customers, we’ve spent the last year doing just this: building and deploying <a href="https://www.snorkel.ai/platform">Snorkel Flow</a>, an end-to-end platform to support this new vision of the ML process.
                  </p>
                  <h2>The Training Data Bottleneck</h2>
                  <p>
                      Snorkel Flow was motivated first and foremost by a growing realization that training data had become the key bottleneck in much of ML pipeline and AI application development.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png"></p><p>
                      <b>Today’s ML successes often rest on a hidden cost: massive, hand-labeled training datasets.</b>
                      In the last decade, we’ve seen a tectonic shift in AI and ML towards powerful but data-hungry representation learning models.
                      These models—often deep learning architectures—are not only more powerful at obviating traditionally manual development tasks like feature engineering and bespoke model design, but also have never been more accessible in the open source.
                      However, there’s no such thing as a free lunch: these models are highly complex, with tens to hundreds of millions of parameters, and they require massive labeled training datasets to learn from.
                      And, other than in special scenarios where labels are naturally derivative of existing processes, these training datasets need to be labeled by hand.
                  </p>
                  <p>
                      <b>The hand-labeled training data interface to ML has enabled tremendous progress, but is also ridiculously broken.</b>
                      Consider a simple example: a legal analyst at a bank wants to train a contract classification model, and wants to inject a simple heuristic into the ML model: that if “employment” is in the title, the contract should be labeled as an “Employment contract.”
                      Simple, right?
                      Not so.
                      Theoretically, to communicate this specific feature to a machine learning model via only labeling individual data points could require thousands of examples (roughly, inversely proportional to the sparsity of the feature space).
                      From this perspective, it’s like playing 20 questions rather than just communicating the answer directly—fine if you have a massive question-answer bank, but otherwise wholly impractical.
                  </p>
                  <p>
                      <b>Manually labeling training data is prohibitively expensive–especially when expertise and privacy are required.</b>
                      Building training datasets often requires <a href="http://nytimes.com/2018/11/25/business/china-artificial-intelligence-labeling.html">armies of human labelers</a> at massive cost and time expense.
                      For example, ImageNet—one of the foundational projects behind ML’s current explosive progress—took <a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/">over two years</a> to create.
                      However, labeling cats, dogs, stop signs, and pedestrians is one thing; labeling data like medical images, legal and financial contracts, government documents, user data, and network data requires <b>stringent privacy protections</b> and <b>subject matter expert labelers</b>.
                      This means for sectors like financial services, government, telecommunications, insurance, healthcare, and more, creating training data (and by extension, using ML) is either a hugely expensive on-premise activity—or more often, one that is just not feasible to tackle, let alone practical.
                  </p>
                  <p>
                      <b>Iterative development is not possible with hand-labeled data.</b>
                      From an engineering and data science perspective, manually labeled training data fundamentally breaks the ability to quickly iterate, which is absolutely essential in real world settings where input data, output goals, and annotation schema change all the time.
                      From a business perspective, training data is an expensive asset that can’t be reused across projects, can often depreciate to worthless overnight due to changing conditions or business goals, and that presents growing risks—everything from <a href="https://web.archive.org/web/20200703104247/https://cloud.google.com/ai-platform/data-labeling/docs">COVID-related delays</a> to <a href="https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai">issues of bias</a>.
                  </p>
                  <h2>A New Input Paradigm for ML: Programming with Data</h2>
                  <p>
                      With Snorkel Flow, rather than needing to hand-label any training data, users develop <b>programmatic operators</b> that label, augment, and build training data to drive the ML development process.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png"></p><p>
                      <b>Programmatically labeling and building training data.</b>
                      With Snorkel Flow, the idea is to instead communicate this domain knowledge directly via a programmatic operator like a <a href="https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly">labeling function</a>.
                      For example, our legal analyst could write a labeling function that labels documents as “Employment contracts” if the word “employment” is in the title, and otherwise abstains; or, a range of more complex and powerful labeling functions relying on internal knowlegebases, models, legacy heuristics, and more.
                      This approach of effectively programming ML with data is simple, direct, interpretable, modifiable, and agnostic to the model used (which is especially important given the ongoing Cambrian explosion of powerful new open source model architectures).
                  </p>
                  <p>
                      <b>The directness of rules with the flexibility of ML.</b>
                      Rule-based systems have long been used in industry for certain tasks—as an input, individual rules have the desirable property of being direct and interpretable.
                      However, rules can also be brittle, and lack the robustness, flexibility, and sheer power of ML approaches.
                      With Snorkel Flow, you get the best of both worlds: rules (and other interpretable resources) as inputs, and powerful ML models that generalize beyond these rules as the output.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png"></p><p>
                      <b>A more powerful yet weaker supervision.</b>
                      At the same time that this programmatic supervision is advantageous in several transformational ways, it is also messier and raises fundamental new technical challenges.
                      The labeling functions and other programmatic operators that users write will have varying unknown accuracies and expertise areas, will overlap and disagree with each other, and may be correlated in tangled and unknown ways.
                      We focused on the algorithmic and systems solutions to these issues over <a href="https://www.snorkel.ai/technology">four-plus years of research</a>, showing both empirically and theoretically that with the right techniques, these deep technical challenges can be overcome.
                      The result: training data that is as good as or better than hand-labeled data, and immensely more practical to create and maintain.
                  </p>
                  <p>
                      <b>Beyond labeling: data augmentation, slicing, monitoring, and more.</b>
                      In high-performance production ML, training data is about a lot more than labeling.
                      For example, data augmentation is a cornerstone technique wherein transformed copies of data (e.g. rotated or blurred images) are used to expand the sizes of training datasets, and make resulting models more robust.
                      Slicing or structuring training datasets into more or less important and difficult subsets is also a critical part of managing production ML. 
                      Finally, monitoring and adapting not just models but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snorkel.ai/07-14-2020-snorkel-ai-launch">https://www.snorkel.ai/07-14-2020-snorkel-ai-launch</a></em></p>]]>
            </description>
            <link>https://www.snorkel.ai/07-14-2020-snorkel-ai-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838310</guid>
            <pubDate>Tue, 14 Jul 2020 21:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles for Better Design]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23837939">thread link</a>) | @YungSven
<br/>
July 14, 2020 | https://reflexio.debec.eu/principles-for-better-design | <a href="https://web.archive.org/web/*/https://reflexio.debec.eu/principles-for-better-design">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
        <figure>
            <img alt="cover" src="https://reflexio.debec.eu/assets/windmill.svg">
            <figcaption><a href="https://www.pinterest.fr/pin/642044490609394018/" target="_blank">credit</a></figcaption>
            
        </figure>
        
        <p>Design is a broad topic. This post won’t approach the adjective qualifying a style with simple forms and a pure appearance. No. Design is broader than a sleek car or an harmonious living room.</p>

<p>Design is a creative activity that aims to invent, improve and solve problems. Life is full of them, in various domains, which pushes people to eventually become a designer of something. Whether you’re conceiving a recipe, an apartment layout, a software or a rocket you are designing. By learning the fundamentals, you will arm yourself for various situations. Here is a list of the best pragmatic principles I’ve learned to better design. In spite of their obviousness and renown, my experience has shown me that some of these principles are often forgotten.</p>

<p><strong>Fun fact</strong>: In english, <em>to design</em> means both <em>to draw</em> and <em>to conceive according to a plan</em>. Similarly in French, the word <em>dessin</em> (a drawing) derives its etymology from the word <em>dessein</em> (have the intention).</p>

<h2 id="incremental-improvement">Incremental improvement</h2>

<p>Believing you can do it right the first time is naive at best, pretentious at worst. <strong>You will fail and have to accept it</strong>. Do not postpone but instead <strong>release fast</strong>, get feedback early and iterate to make it better. You will find many references, notably on Lean Startup, DevOps culture or Site Reliability Engineering, which encourage <strong>a quick redesign capability rather than a perfect design at the first place</strong>.</p>

<blockquote>
  <p>To write clean code, you must first write dirty code and then clean it. […]
Learning to write clean code is hard work. It requires more than just the knowledge of principles and patterns. You must sweat over it. You must practice it yourself, and watch yourself fail. Robert C. Martin — Clean Code: A Handbook of Agile Software Craftsmanship</p>
</blockquote>

<h2 id="reuse-what-exists">Reuse what exists</h2>

<p>It is unlikely that the problem you face is fundamentally new. Before making any effort, look for <strong>existing solutions</strong> or proven practices. <strong>Be humble</strong> and accept you can’t compete with years of expertise on a subject. If so, the motivation to develop the new model must come from reaching the limits of the previous one. In software engineering for instance, <a href="https://en.wikipedia.org/wiki/Software_design_pattern">design patterns</a> are formalized best practices that the programmer can use to solve common problems when designing an application or system.</p>

<p>Don’t limit yourself to the area of the original problem, sometimes a similar problem has been found and solved long before in <strong>a different field</strong>. Learn about <a href="https://en.wikipedia.org/wiki/Queueing_theory">queuing theory</a> will help you to write an operating system scheduler as well as being frustrated in a supermarket queue. Solutions come from fields of experiences and theories that you would not necessarily expect.</p>

<h2 id="five-whys">Five whys</h2>

<p>The <a href="https://en.wikipedia.org/wiki/Five_whys">Five whys technique</a>, originally developed by Toyota, has been mostly used for exploring the root cause of a defect in a system. It involves asking the relevant question starting with a why in order to find the source which cause the failure. Adapt this technique to find out what really matter in our design. For example, “<em>We need a program which exports our documentation to PDF</em>”:</p>

<ol>
  <li>Why? - So the export can go on the website.</li>
  <li>Why? - Because our customers has to read it.</li>
  <li>Why? - Because they require it to maintain the software.</li>
  <li>Why (don’t they have access to the documentation like everyone else)? - Because they haven’t been integrated into our platform.</li>
  <li>Why? Because they have never been on-board on the platform.</li>
</ol>

<p><strong>Decision</strong>: instead of developing a complex program which exports PDF, write a simple on-boarding guide for the customers.</p>

<p>This situation often occurs when the given requirement includes the design. Before answering the question <em>“How do we do it?”</em> directly, the first and most important step is to remember “<em>Why do we do it?</em>”. Once you have understood the <strong>root reasons</strong> and constraints for the requirement, it clears the path on how to get there and can <strong>prevent</strong> you from taking <strong>very long detours</strong> in addition to <strong>simplifying</strong> the design.</p>

<h2 id="keep-it-simple-stupid">Keep it simple stupid</h2>

<p><strong>Resolve problems, don’t create them</strong>. You should be suspicious of providing a solution that makes the overall system more complicated than before. Remember: You’ll have to maintain everything you build, so you’d better build as little and simply as possible.</p>

<p>Simple designs are easy to <strong>learn</strong>, easy to <strong>teach</strong>, easy to <strong>use</strong> and therefore easily <strong>appeal</strong> to customers. It forces the design to be intuitive and obvious, reducing the learning curve and facilitates the adoption. Like Denis Diderot says in Pensées sur l’interprétation de la nature:</p>

<blockquote>
  <p>These books [of Sthal and Newton] were just waiting to be heard, to be valued for what they were worth; and it would not have cost their authors more than a month to make them clear; that month would have spared three years of labor and exhaustion to a thousand good spirits.</p>
</blockquote>

<p>But what is a simple design? In the <a href="https://landing.google.com/sre/sre-book/chapters/simplicity/">Simplicity chapter of the Site Reliability Engineering</a> book of Google, they mention a great quote from the French poet Antoine de Saint Exupery about perfection which could fit very well with simplicity:</p>

<blockquote>
  <p>perfection is finally attained not when there is no longer more to add, but when there is no longer anything to take away - A. de Saint Exupéry, Terre des Hommes</p>
</blockquote>

<h2 id="perfect-is-the-enemy-of-good-enough">Perfect is the enemy of good enough</h2>

<p><a href="https://www.pinterest.de/pin/397724210839705109/"><img src="https://reflexio.debec.eu/assets/moka-pot.svg" alt="moka"></a></p>

<p>The moka coffee maker may not produce perfect coffee, but it requires so little maintenance compared to a large coffee machine with radiators, pipes, grinder, etc. that it makes the compromise “complexity / coffee taste” great.</p>

<p>Remember the <a href="https://en.wikipedia.org/wiki/Pareto_principle">Pareto principle</a>: in general <strong>80% of a things can be done in 20%</strong> of the total allocated time. Conversely, the hardest <strong>20% left takes 80%</strong> of the time. Perfection requires infinite time and energy. This is impossible and therefore should not be part of your design.</p>

<blockquote>
  <p>Beware of the perfection pitfall and design your architecture only as good as necessary and not as good as ultimate possible. - Ralf S. Engelschall</p>
</blockquote>

<h2 id="postpone-complexity">Postpone complexity</h2>

<p>Simplicity and incremental improvement principles give birth to a another principle: <strong>Postpone complexity</strong>. Complexity lies in early optimization, as Donald E. Knuth points out in his article <a href="https://dl.acm.org/doi/pdf/10.1145/361604.361612?download=true">Computer Programming as Art</a> with “<em>premature optimization is the root of all evil</em>”. Focus on designing something that works instead of something finely tune that does not.</p>

<p>Complexity lies also in early generalization. Focus on designing something that works in a single use case rather than something that will not work in many. When designing a coffee machine, first design something that makes a simple black coffee. If you plan ahead to include all extra options for latte, cappuccino or irish coffee you will end up not making a simple back coffee. As elegantly summarized by Ralf S. Engelschall: “<em>Use before reuse</em>”.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Do you think there’s a principle missing? Send me your comments! This list will certainly be extended and refined, subscribe to the <a data-formkit-toggle="78a863d4eb" href="https://reflexio-debec.ck.page/78a863d4eb">newsletter</a> if you wish to be notified about it. In the meantime, how are you going to ensure that you do not forget to implement the principles you have just learned?</p>

    </div></div>]]>
            </description>
            <link>https://reflexio.debec.eu/principles-for-better-design</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837939</guid>
            <pubDate>Tue, 14 Jul 2020 21:10:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding and writing a JPEG decoder in Python]]>
            </title>
            <description>
<![CDATA[
Score 243 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23837838">thread link</a>) | @sfpoet
<br/>
July 14, 2020 | https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/ | <a href="https://web.archive.org/web/*/https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
			<span>
				<a target="_blank" href="https://github.com/yasoob/personal_blog/tree/master/content/posts/understanding-and-writing-jpeg-decoder-in-python.md">Source</a>
			</span>
			
				<p><img src="https://d33wubrfki0l68.cloudfront.net/797fe040e65dc288b7f22489dbad160e1e4998b8/0496b/images/decoding_jpeg/hero-image.png">
				</p>
			
			
			<span>
				
				<time itemprop="datePublished" datetime="2020-07-14">July 14, 2020</time>
				
			</span>
			<section itemprop="entry-text">
				

<p>Hi everyone! 👋 Today we are going to understand the JPEG compression algorithm. One thing a lot of people don’t know is that JPEG is not a format but rather an algorithm. The JPEG images you see are mostly in the JFIF format (JPEG File Interchange Format) that internally uses the JPEG compression algorithm. By the end of this article, you will have a much better understanding of how the JPEG algorithm compresses data and how you can write some custom Python code to decompress it. We will not be covering all the nuances of the JPEG format (like progressive scan) but rather only the basic baseline format while writing our decoder.</p>

<h2 id="introduction">Introduction</h2>

<p>Why write another article on JPEG when there are already hundreds of articles on the internet? Well, normally when you read articles on JPEG, the author just gives you details about what the format looks like. You don’t implement any code to do the actual decompression and decoding. Even if you do write code, it is in C/C++ and not accessible to a wide group of people. I plan on changing that by showing you how a basic JPEG decoder works using Python 3. I will be basing my decoder on <a href="https://github.com/aguaviva/micro-jpeg-visualizer/blob/master/micro-jpeg-visualizer.py">this</a> MIT licensed code but will be heavily modifying it for increased readability and ease of understanding. You can find the modified code for this article on my  <a href="https://github.com/yasoob/Baseline-JPEG-Decoder">GitHub repo</a>.</p>

<h2 id="different-parts-of-a-jpeg">Different parts of a JPEG</h2>

<p>Let’s start with this nice image by <a href="https://twitter.com/angealbertini">Ange Albertini</a>. It lists all different parts of a simple JPEG file. Take a look at it. We will be exploring each segment. You might have to refer to this image quite a few times while reading this tutorial.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/bdc1363abbd5744200ec5283d4154e55143df86c/8c624/images/decoding_jpeg/jpegrgb_dissected.png" alt="JPEGRGB_dissected.png"></p>

<p>At the very basic level, almost every binary file contains a couple of markers (or headers). You can think of these markers as sort of like bookmarks. They are very crucial for making sense of a file and are used by programs like <code>file</code> (on Mac/Linux) to tell us details about a file. These markers define where some specific information in a file is stored. Most of the markers are followed by <code>length</code> information for the particular marker segment. This tells us how long that particular segment is.</p>

<h3 id="file-start-file-end">File Start &amp; File End</h3>

<p>The very first marker we care about is <code>FF D8</code>. It tells us that this is the start of the image. If we don’t see it we can assume this is some other file. Another equally important marker is <code>FF D9</code>. It tells us that we have reached the end of an image file. Every marker, except for <code>FFD0</code> to <code>FFD9</code> and <code>FF01</code>, is immediately followed by a length specifier that will give you the length of that marker segment. As for the image file start and image file end markers, they will always be two bytes long each.</p>

<p>Throughout this tutorial, we will be working with this image:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7344493a5ee7126f8286dd83ade191cab9e7f292/fbea3/images/decoding_jpeg/profile.jpg" alt="Profile"></p>

<p>Let’s write some code to identify these markers.</p>

<pre><code>from struct import unpack


marker_mapping = {
    0xffd8: "Start of Image",
    0xffe0: "Application Default Header",
    0xffdb: "Quantization Table",
    0xffc0: "Start of Frame",
    0xffc4: "Define Huffman Table",
    0xffda: "Start of Scan",
    0xffd9: "End of Image"
}


class JPEG:
    def __init__(self, image_file):
        with open(image_file, 'rb') as f:
            self.img_data = f.read()
    
    def decode(self):
        data = self.img_data
        while(True):
            marker, = unpack("&gt;H", data[0:2])
            print(marker_mapping.get(marker))
            if marker == 0xffd8:
                data = data[2:]
            elif marker == 0xffd9:
                return
            elif marker == 0xffda:
                data = data[-2:]
            else:
                lenchunk, = unpack("&gt;H", data[2:4])
                data = data[2+lenchunk:]            
            if len(data)==0:
                break        

if __name__ == "__main__":
    img = JPEG('profile.jpg')
    img.decode()    

# OUTPUT:
# Start of Image
# Application Default Header
# Quantization Table
# Quantization Table
# Start of Frame
# Huffman Table
# Huffman Table
# Huffman Table
# Huffman Table
# Start of Scan
# End of Image
</code></pre>

<p>We are using <a href="https://docs.python.org/3/library/struct.html">struct</a> to unpack the bytes of image data. <code>&gt;H</code> tells <code>struct</code> to treat the data as big-endian and of type <code>unsigned short</code>. The data in JPEG is stored in big-endian format. Only the EXIF data <em>can</em> be in little-endian (even though it is uncommon). And a short is of size 2 so we provide <code>unpack</code> two bytes from our <code>img_data</code>. You might ask yourself how we knew it was a <code>short</code>. Well, we know that the markers in JPEG are 4 hex digits: <code>ffd8</code>. One hex digit equals 4 bits (<sup>1</sup>⁄<sub>2</sub> byte) so 4 hex digits will equal 2 bytes and a short is equal to 2 bytes.</p>

<p>The Start of Scan section is immediately followed by image scan data and that image scan data doesn’t have a length specified. It continues till the “end of file” marker is found so for now we are manually “seeking” to the EOF marker whenever we see the SOC marker.</p>

<p>Now that we have the basic framework in place, let’s move on and figure out what the rest of the image data contains. We will go through some necessary theory first and then get down to coding.</p>

<h2 id="encoding-a-jpeg">Encoding a JPEG</h2>

<p>I will first explain some basic concepts and encoding techniques used by JPEG and then decoding will naturally follow from that as a reverse of it. In my experience, directly trying to make sense of decoding is a bit hard.</p>

<p>Even though the image below won’t mean much to you right now, it will give you some anchors to hold on to while we go through the whole encoding/decoding process. It shows the steps involved in the JPEG encoding process: (<a href="https://users.cs.cf.ac.uk/Dave.Marshall/Multimedia/node234.html">src</a>)</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7237dd0093b6a8070b2c927673fd73bc797561d2/33b0a/images/decoding_jpeg/encoding.png" alt="JPEG Encoding process"></p>

<h3 id="jpeg-color-space">JPEG Color Space</h3>

<p>According to the JPEG spec (<a href="http://www.itu.int/rec/T-REC-T.872-201206-I/en">ISO/IEC 10918-6:2013 (E)</a>, section 6.1):</p>

<blockquote>
<ul>
<li>Images encoded with only one component are assumed to be grayscale data in which 0 is black and 255 is white.</li>
<li>Images encoded with three components are assumed to be RGB data encoded as YCbCr unless the image contains an APP14 marker segment as specified in 6.5.3, in which case the color encoding is considered either RGB or YCbCr according to the application data of the APP14 marker segment. The relationship between RGB and YCbCr is defined as specified in Rec. ITU-T T.871 | ISO/IEC 10918-5.</li>
<li>Images encoded with four components are assumed to be <strong>CMYK</strong>, with (0,0,0,0) indicating white unless the image contains an APP14 marker segment as specified in 6.5.3, in which case the color encoding is considered either <strong>CMYK</strong> or <strong>YCCK</strong> according to the application data of the APP14 marker segment. The relationship between <strong>CMYK</strong> and <strong>YCCK</strong> is defined as specified in clause 7.</li>
</ul>
</blockquote>

<p>Most JPEG algorithm implementations use luminance and chrominance (YUV encoding) instead of RGB. This is super useful in JPEG as the human eye is pretty bad at seeing high-frequency brightness changes over a small area so we can essentially reduce the amount of frequency and the human eye won’t be able to tell the difference. Result? A highly compressed image with almost no visible reduction in quality.</p>

<p>Just like each pixel in RGB color space is made up of 3 bytes of color data (Red, Green, Blue), each pixel in YUV uses 3 bytes as well but what each byte represents is slightly different. The Y component determines the brightness of the color (also referred to as luminance or luma), while the U  and V components determine the color (also known as chroma). The U component refers to the amount of blue color and the V component refers to the amount of red color.</p>

<p>This color format was invented when color televisions weren’t super common and engineers wanted to use one image encoding format for both color and black and white televisions. YUV could be safely displayed on a black and white TV if color wasn’t available. You can read more about its history on <a href="https://www.wikiwand.com/en/YUV">Wikipedia</a>.</p>

<h3 id="discrete-cosine-transform-quantization">Discrete Cosine Transform &amp; Quantization</h3>

<p>JPEG converts an image into chunks of 8x8 blocks of pixels (called MCUs or Minimum Coding Units), changes the range of values of the pixels so that they center on 0 and then applies Discrete Cosine Transformation to each block and then uses quantization to compress the resulting block. Let’s get a high-level understanding of what all of these terms mean.</p>

<p>A Discrete Cosine Transform is a method for converting discrete data points into a combination of cosine waves. It seems pretty useless to spend time converting an image into a bunch of cosines but it makes sense once we understand DCT in combination with how the next step works. In JPEG, DCT will take an 8x8 image block and tell us how to reproduce it using an 8x8 matrix of cosine functions.  <a href="https://www.impulseadventure.com/photo/jpeg-minimum-coded-unit.html">Read more here</a>)</p>

<p>The 8x8 matrix of cosine functions look like this:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/97f11adca54888172fc19cef52e514ef0e8b46fd/1a72e/images/decoding_jpeg/cosine-funcs.png" alt="Cosine functions"></p>

<p>We apply DCT to each component of a pixel separately. The output of applying DCT is an 8x8 coefficient matrix that tells us how much each cosine function (out of 64 total functions) contributes to the 8x8 input matrix. The coefficient matrix of a DCT generally contains bigger values in the top left corner of the coefficient matrix and smaller values in the bottom right corner. The top left corner represents the lowest frequency cosine function and the bottom right represents the highest frequency cosine function.</p>

<p>What this tells us is that most images contain a huge amount of low-frequency information and a small amount of high-frequency information. If we turn the bottom right components of each DCT matrix to 0, the resulting image would still appear the same because, as I mentioned, humans are bad at observing high-frequency changes. This is exactly what we do in the next step.</p>

<p>I found a wonderful video on this topic. Watch it if DCT doesn’t make too much sense.</p>

<iframe width="560" height="326" src="https://www.youtube.com/embed/Q2aEzeMDHMA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>We have all heard that JPEG is a lossy compression algorithm but so far we haven’t done anything lossy. We have only transformed 8x8 blocks of YUV components into 8x8 blocks of cosine functions with no loss of information. The lossy part comes in the quantization step.</p>

<p>Quantization is a process in which we take a couple of values in a specific range and turns them into a discrete value. For our case, this is just a fancy name for converting the higher …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/">https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/</a></em></p>]]>
            </description>
            <link>https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837838</guid>
            <pubDate>Tue, 14 Jul 2020 21:03:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manager Can’t Code? They Shouldn’t Be Your Manager]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23837614">thread link</a>) | @lanecwagner
<br/>
July 14, 2020 | https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Managers who can’t code are an outdated artifact of corporate America circa 2005. The best managers that I’ve had spend ~80% of their time coding, architecting, or doing technical work that requires engineering prowess. If your manager thinks coding is “beneath” them then they need a dose of humble pie. Your organization would likely be better off without them.</p>



<h2><span id="But_Managers_Manage_People">But Managers Manage <em>People</em>!</span>
</h2>



<p>There is a long-running stigma associated with developers, that we are all geeks who can’t handle interpersonal relationships. Due to our code monkey nature, we need “people people” who can go to meetings for us and communicate our efforts effectively to the higher-ups.</p>



<div><figure><img src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" alt="introverted programmers are an outdated meme" srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" data-src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>



<p>While the above is still funny, it’s <em>outdated</em>. As the developer community has grown exponentially in the last 20 years, so too has the personality diversity amongst its members. In other words, it is<strong> not hard to find developers with the soft-skills </strong>necessary for management positions.</p>



<h2><span id="Managers_Should_Help">Managers Should Help</span>
</h2>



<p>I am a firm believer in the following:</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" alt="" srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" data-src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><p>While the manager doesn’t need to be the most talented developer on the team, they must at least be technically literate. When a team member goes to their boss with a technical proposal, the manager should be able to give valuable feedback.</p>



<p>In this <a href="https://hbr.org/2016/12/if-your-boss-could-do-your-job-youre-more-likely-to-be-happy-at-work">study from Harvard</a> 35,000 employees from the US and Great Britain were polled about their job satisfaction, and metrics were gathered about what influenced their happiness at work. The results showed that the <em>single greatest influencing factor </em>on employee satisfaction was whether or not their boss was technically competent. I practice what I preach, so at the <a href="https://classroom.qvault.io/">Qvault app,</a> all engineering leadership will forever be responsible for pushing code.</p>



<p>Contrast the idea of a competent boss with the all-too-familiar experience of going to a <a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">non-technical middle-management type</a> with an engineering problem, only to be stuck in a teaching session because the boss has never heard of a pub-sub system.</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/9e3a6f35f44188bad76c100f3560ce69.gif" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><h2><span id="Managers_Need_Empathy">Managers Need Empathy</span>
</h2>



<p>A good manager has empathy for those who report to them. If the boss doesn’t code or hasn’t written code in a long time, they won’t understand the daily problems that their team is faced with. A good engineering leader will not only understand modern problems, but they make it their role to actively seek technical solutions in an ever-changing innovative landscape.</p>



<h2><span id="INB4_So_the_CEO_needs_to_be_able_to_code">INB4: “So the CEO needs to be able to code?”</span>
</h2>



<p>No, but the CTO does!</p>



<p>I am sympathetic to the idea that the CTO will have plenty of business and product-related work to focus on, but they can’t let their technical chops slip. In order to run the engineering arm of an innovative company, the person at the top should have a firm mental grasp on the implementation difficulties. If this just means reviewing architectural diagrams and reviewing pull-requests so be it, but nothing beats hands-on engineering work to stay sharp.</p>



<h2><span id="Feedback_Please">Feedback Please</span>
</h2>



<p>Have you had problems with non-technical leaders, or do you disagree completely with my opinions? Let me know through one of my <a href="https://qvault.io/contact/">social profiles</a>.</p>



<div><div>
<h2><span id="Thanks_For_Reading">Thanks For Reading</span>
</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>



<h2><span id="Related_Articles">Related Articles:</span>
</h2>



<ul><li><a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">Leave Scrum to Rugby, I Like Getting Stuff Done</a></li></ul>



		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837614</guid>
            <pubDate>Tue, 14 Jul 2020 20:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Failed SquadGoals: Spotify doesn’t use the Spotify model and neither should you]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23837535">thread link</a>) | @wahnfrieden
<br/>
July 14, 2020 | https://www.jeremiahlee.com/posts/failed-squad-goals/?hn | <a href="https://web.archive.org/web/*/https://www.jeremiahlee.com/posts/failed-squad-goals/?hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<!-- Spread 1 -->
<section>
<section>
<video autoplay="true" muted="true" loop="true">
<source srcset="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" media="(prefers-reduced-motion: reduce)">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" alt="Taylor Swift and her squad walking away from an explosion in front of the Spotify office at Birger Jarlsgatan.">
</video>
</section>
<section>
<div>

<p><b>Spotify</b> doesn’t use <em>“the Spotify model”</em><br>and neither should you.</p>
<p>By Jeremiah Lee</p>
<p>Sunday, April 19, 2020 • <a href="https://anchor.fm/jeremiah-oral-lee/episodes/Spotifys-Failed-SquadGoals-edia0p">Listen</a> •&nbsp;<a href="https://oyomy.fr/2020/04/l-echec-du-modele-spotify/" hreflang="fr">En français</a> •&nbsp;<a href="https://jp.quora.com/q/agile/Spotify%E3%81%AF-Spotify%E3%83%A2%E3%83%87%E3%83%AB-%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84" hreflang="ja">日本語で</a> • <a href="https://flavioclesio.com/2020/05/18/o-modelo-de-squadgoals-do-spotify-falhou/" hreflang="pt-br">Português (Brasil)</a></p>
</div>
</section>
</section>
<!-- Spread 2 -->
<section>
<section>
<div>
<p>Of all the allures of startup culture, few are more desireable than the speed and nimbleness of a small team. Maintaining that feeling as a company grows is a challenge. In 2012, Spotify shared its way of working and suggested it had figured it out.<sup><a href="#1">1</a></sup></p>
<p>I was excited to see <em>the Spotify model</em> in action when I interviewed for a product management role at its Stockholm headquarters in 2017. However, the recruiter surprised me before the first interview. She cautioned me to not expect Spotify to be an <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile</a> utopia.</p>
<p>I joined the company after it had tripled in size to 3,000 people over 18 months. I learned the famed squad model was only ever aspirational and never fully implemented. I witnessed organizational chaos as the company’s leaders incrementally transitioned to more traditional management structures.</p>
<p>When I asked my coworkers why the content was not removed or updated to reflect reality, I never got a good answer. Many people ironically thought the posts were great for recruiting. I no longer work at Spotify, so I am sharing my experience to set the record straight. The Spotify squad model failed Spotify and it will fail your company too.</p>
</div>
</section>
<section>
<div>
<h3>But you don’t have to take my word for it.</h3>
<p>The co-author of the Spotify model<sup><a href="#2">2</a></sup> and multiple agile coaches who worked at Spotify have been telling people to not copy it for years. Unfortunately, truth doesn’t spread as quickly or as widely as an idea people want to believe in.</p>
<blockquote>
<p>“Even at the time we wrote it, we weren’t doing it. It was part ambition, part approximation. People have really struggled to copy something that didn’t really exist.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify&nbsp;2011–2017<sup><a href="#4">4</a></sup></p>
<blockquote>
<p><em>“It worries me when people look at what we do and think it’s a framework they can just copy and implement.</em> … We are really trying hard now to emphasize we have problems as well. It’s not all ‘shiny and everything works well and all our squads are super amazing’.”</p>
</blockquote>
<p>—Anders Ivarsson, co-author of the Spotify&nbsp;whitepaper<sup><a href="#3">3</a></sup></p>
</div>
</section>
</section>
<!-- Spread 3 -->
<section>
<section>
<div>
<h2>Recap</h2>
<p>You can read and watch the <a href="#1">original content</a> in less than 30 minutes or <a href="#spread-4">skip to the next section</a> if you are familiar. Here is a brief summary.</p>
<p>Spotify had teams it called <em>squads</em> because it sounded cooler (not joking). A group of teams were organized into a department called a <em>tribe</em>. Each team was intended to be an autonomous mini-startup, with a product manager acting as mini-CEO for a feature area. The teams had designers and software engineers with a range of specializations. The intent was that a team should have every skill necessary without needing to rely on another team for success.</p>
<p>Product managers had a traditional management structure. A product manager for a team reported to their department’s product director (<em>“tribe lead”</em>). Same for designers. Software engineers, however, were managed outside of the team structure.</p>
</div>
</section>
<section>
<div>
<p><em>“Chapter leads”</em> managed software engineers specializing in a specific type of software development across the department. For example, all of the software engineers working on backend APIs across all the teams within the department would have one manager and all of the Android mobile engineers in the department would have a different manager. The intent was to allow engineers to be moved between teams within the department to best meet business requirements without them having to change managers.</p>
<figure>
<video autoplay="true" muted="true" loop="true">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.png" alt="Spotify matrix organization diagram. A department is called a tribe and has multiple squads, another name for a team. Each squad has a product owner, another name for a product manager. Software engineers of the same discipline across multiple teams are called a chapter and managed by a chapter lead, another name for an engineering manager.">
</video>
<figcaption>Spotify tried a long-lived matrix team structure with unusual word choices.<sup><a href="#1">1</a></sup> It did not work well.</figcaption>
</figure>
</div>
</section>
</section>
<!-- Spread 4 -->
<section id="spread-4">
<section>

</section>
<section id="matrix-management-sucks">
<div>
<h3>Matrix management solved the wrong problem</h3>
<p>The “full stack” agile team worked well, but the matrix management of software engineers introduced more problems than it solved.</p>
<ul>
<li><p>Teams at Spotify were rather long-lived. The benefit of not having to change manager when moving to another team was limited.</p></li>
<li><p>Engineering managers in this model had little responsibility beyond the career development of the people they managed. Even then, their ability to help with interpersonal people skills development was limited. An engineering manager would not manage enough of the other people on the team or be involved enough in the daily context to independently assess conflict within the team.</p></li>
</ul>
</div>
</section>
</section>
<!-- Spread 5 -->
<section>
<section>
<div>
<ul>
<li><p>Without a single engineering manager responsible for the engineers on a team, the product manager lacked an equivalent peer—the mini-CTO to their mini-CEO role. There was no single person accountable for the engineering team’s delivery or who could negotiate prioritization of work at an equivalent level of responsibility.</p><p>When disagreements within the engineering team arose, the product manager needed to negotiate with all of the engineers on the team. If the engineers could not reach a consensus, the product manager needed to escalate to as many engineering managers as there were engineering specializations within the team. A team with backend, Web app, and mobile app engineers would have at least 3 engineering managers who might need to get involved. If those engineering managers could not reach a consensus, a single team’s issue would have to escalate to the department’s engineering director.</p></li>
</ul>
</div></section>
<section id="matrix-management-sucks">
<div>
<blockquote>
<p>“Chapter leads are servant-leaders who help you grow as an individual. They don’t really work with any team. They have direct reports on all the teams. They don’t have really any accountability for the delivery. They aren’t taking that responsibility. It’s easy to see the product owner as the manager for the team.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>A product—design—engineering team typically contains more engineers than designers or product managers. Having a single engineering manager for the engineers on the team creates an accountable escalation path for conflict within the team.</li>
<li>Product managers should have an equivalent peer for engineering. Product managers should be accountable for the prioritization of work. Engineering managers should be accountable for the engineers’ execution, which includes being able to negotiate speed and quality tradeoffs with the product manager.</li>
</ul>
</div>
</section>
</section>
<!-- Spread 6 -->
<section>
<section id="too-much-autonomy">
<div>
<h3>Spotify fixated on team autonomy</h3>
<p>When a company is small, teams have to do a wide range of work to deliver and have to shift initiatives frequently. As a company grows from startup to scale-up, duplicated functions across teams move to new teams dedicated to increasing organization efficiency by reducing duplication. With more teams, the need for a team to shift initiative decreases in frequency. Both of these changes allow for teams to think more deeply and long term about the problems they are scoped to solve. Faster iteration, however, is not guaranteed. Every responsibility a team cedes to increase its focus becomes a new cross-team dependency.</p>
<p>Spotify did not define a common process for cross-team collaboration. Allowing every team to have a unique way of working meant each team needed a unique way of engagement when collaborating. Overall organization productivity suffered.</p>
<p>The Spotify model was documented when Spotify was a much smaller company. It was supposed to be a multiple part series, according to Anders Ivarsson. Autonomy made the first cut, but the parts on alignment and accountability were never completed.</p>
</div>
</section>
<section>
<div>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>Autonomy requires alignment. Company priorities must be defined by leadership. Autonomy does not mean teams get to do whatever they want.</li>
<li>Processes for cross-team collaboration must be defined. Autonomy does not mean leaving teams to self-organize every problem.</li>
<li>How success is measured must be defined by leadership so people can effectively negotiate cross-team dependency prioritization.</li>
<li>Autonomy requires accountability. Product management is accountable for value. The team is accountable for delivering ‘done’ increments. Mature teams can justify their independence with their ability to articulate business value, risk, learning, and the next optimal move.<sup><a href="#6">6</a></sup></li>
</ul>
</div>
</section>
</section>
<!-- Spread 7 -->
<section>
<section id="too-much-autonomy">
<div>
<blockquote>
<p>“If I were to do one thing differently, I would say we should not be focusing so much on autonomy.</p>
<p>“Every time you have a new team, they have to reinvent the wheel in how they should be working. Maybe, just maybe, we should have a ‘minimum viable agility’. You start with that. You are free to opt out, but people shouldn’t have to opt-in all the time.</p>
<p>“At what point do you start inserting this process? Probably when it’s too late.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Henrik Kniberg talked about how we're not that good at large initiatives and we’re still not that good at large initiatives.</p>
<p>“If you have inconsistent ways of working, it’s more difficult for people to move. If it’s more difficult for people to move, it’s more likely you have inconsistent ways of working. It will just reinforce until all of a sudden, you’re not really working for the same company anymore. You’re working for these kind of weird subcultures.”</p>
</blockquote>
<p>—Jason Yip, agile coach at Spotify<br>2015–time of writing<sup><a href="#5">5</a></sup></p>
</div>
</section>
</section>
<!-- Spread 8 -->
<section>
<section id="collaboration-is-a-competency">
<div>
<h3>Collaboration was an assumed competency</h3>
<p>While Spotify gave teams control over their way of working, many people did not have a basic understanding of Agile practices. This resulted in teams iterating through process tweaks in blind hope of finding the combination that would help them improve their delivery. People lacked a common language to effectively discuss the process problems, the education to solve them, and the experience to evaluate performance. It was not really <em>agile</em>. It was just <em>not-waterfall</em>.</p>
<p><em>“Agile coaches”</em> were internal consultants Spotify provided teams to teach and suggest process improvements. While well-intentioned, there were not enough coaches to help every team. A coach’s engagement with a team was rarely long enough to span a project’s completion to help a team evaluate performance. More so, they were not accountable for anything.</p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Control without competence is chaos.”</p>
</blockquote>
<p>—L. David Marquet, <a href="https://www.indiebound.org/book/9781591846406"><cite>Turn the Ship Around!</cite></a></p>
<p><strong>Learn from Spotify’s …</strong></p></div></section></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jeremiahlee.com/posts/failed-squad-goals/?hn">https://www.jeremiahlee.com/posts/failed-squad-goals/?hn</a></em></p>]]>
            </description>
            <link>https://www.jeremiahlee.com/posts/failed-squad-goals/?hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837535</guid>
            <pubDate>Tue, 14 Jul 2020 20:40:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to spot and fix the biggest UI problems if you are developer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23837398">thread link</a>) | @semy
<br/>
July 14, 2020 | https://www.lunadio.com/blog/how-to-spot-and-fix-the-biggest-ui-problems | <a href="https://web.archive.org/web/*/https://www.lunadio.com/blog/how-to-spot-and-fix-the-biggest-ui-problems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>We are in the new „super-agile” era, an in many cases low-cost MVP’s are being built, that skip the Designer role for financial reasons.</p><p>There are great design systems and free libraries out there, so even the developers can create something that looks high-fidelity enough for initial user testing and idea validation.</p><p>Whether it is adapting a design system, or coding your own based on some inspirations, there are some problems you’re going to encounter along the way. I believe it’s important for developers to understand design, and the reason many don’t dive into it, is because of a big misconception:</p><h2 id="im-not-an-artist">I’m not an artist</h2><p>UI Design is as far from art, as development. Obviously you can add illustrations to your project, but that’s the one piece of artwork in the entire process and it’s usually done by an illustrator, not the designer.</p><h3 id="what-is-ui-design">What is UI Design?</h3><p>Interface design is closer to development than art. That is because it’s actually based on a strict set of rules and a heavy use of consistent number values. Understanding these rules will help you apply the right numbers in the right places and “fix your implementation”.</p><h2 id="rule-1-spacing">Rule 1: Spacing</h2><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/113b1963ec589c177a93bcfeed8191e5/06fd5/1_muc-nmkmrdx9lxn2_kig_g.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/113b1963ec589c177a93bcfeed8191e5/f6cdf/1_muc-nmkmrdx9lxn2_kig_g.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/113b1963ec589c177a93bcfeed8191e5/f6cdf/1_muc-nmkmrdx9lxn2_kig_g.png" alt="Well spaced image on the left, and a chaotic one on the right.">
      </picture>
    </span></p><p>Grid systems deserve their own, separate article, but there are some basics alignment tips and techniques you can use right now to move your project to the next level.</p><p>The main thing to remember is the rule of proximity. But to avoid “industry definition” let’s break it down into plain english:</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/039df04f65b16f9e8823f7870484c554/06fd5/1_qe70feh7gvv2bgpdwrbbow.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/039df04f65b16f9e8823f7870484c554/f6cdf/1_qe70feh7gvv2bgpdwrbbow.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/039df04f65b16f9e8823f7870484c554/f6cdf/1_qe70feh7gvv2bgpdwrbbow.png" alt="1 qe70feh7gvv2bgpdwrbbow">
      </picture>
    </span></p><blockquote><p>The closer the objects are, the more they are perceived as a group. The farther apart they are, the more disconnected they become.</p></blockquote><p>The distance between elements on our screen is thus one of the best way of building a clear, readable hierarchy. So if you have a clear group of items (like a product card) — everything within the card should be rather close together. Then the next card from the stack or carousel should be farther apart from the first one.</p><h3 id="diy-formula">DIY formula</h3><p>Luckily there is an easy formula to do this. Here’s a version of it for the 8-point grid:</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/b773ea1ca97ff4cd39971052fb0ba10d/06fd5/1_kny9vqk6ps2t3s4ptel_qw.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/b773ea1ca97ff4cd39971052fb0ba10d/f6cdf/1_kny9vqk6ps2t3s4ptel_qw.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/b773ea1ca97ff4cd39971052fb0ba10d/f6cdf/1_kny9vqk6ps2t3s4ptel_qw.png" alt="1 kny9vqk6ps2t3s4ptel qw">
      </picture>
    </span></p><p>And 10-point:</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/554cd02c1c618e085dc5def58826ad5c/06fd5/1_jf7esgyqskorwzwadd_d6a.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/554cd02c1c618e085dc5def58826ad5c/f6cdf/1_jf7esgyqskorwzwadd_d6a.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/554cd02c1c618e085dc5def58826ad5c/f6cdf/1_jf7esgyqskorwzwadd_d6a.png" alt="1 jf7esgyqskorwzwadd d6a">
      </picture>
    </span></p><p>If you’re building components, use the first three values only. When setting up the general layout use the rest of them — but remember the rule — the more “connected” functionally the objects, the lower the spacing should be.</p><p>Another good example of this is how cards can be closer to one another, but farther away from navigation bars. It’s a clear way of showing the user what’s what.</p><h2 id="rule-2--alignment">Rule 2 — Alignment</h2><p>If you go to the web right now — to any random website — chances are you’re going to see a button with a badly aligned label inside. This is likely the biggest problem out there, and it’s surprisingly easy to fix.</p><p>Let’s break it down into two main parts:</p><p><strong>1. The label is not in the center of the button.</strong></p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/cfaf50d9a676aec00cba832d06759f53/06fd5/1_ikdd6ewhuncq3tj738xmha.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/cfaf50d9a676aec00cba832d06759f53/f6cdf/1_ikdd6ewhuncq3tj738xmha.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/cfaf50d9a676aec00cba832d06759f53/f6cdf/1_ikdd6ewhuncq3tj738xmha.png" alt="Label  in the center of the button">
      </picture>
    </span></p><p>To fix this you must first determine, whether the button height and the text height are both odd, both even, or mixed. If one of them is an odd number, while the other is an even one, there is no way to align them in the center.</p><p>Most fonts work well enough with their values, so if the size is 16p it usually really is 16p high. Some typefaces, however don’t scale that well and 16p size can be anything from 15 to even 19,5. Try the number alignment method first and then check if it’s aligned optically.</p><p>To do that you need to use any visual design tool. You can try Figma, Sketch or even Powerpoint / Keynote. Just paste in a screenshot of your coded button and then create a square that starts from the font baseline to the bottom edge of the button background.</p><p>Now duplicate that same square and see if it fits just as well on top of that font. If there’s a gap on either side, it means that you need to optically align it. The easiest way is with increasing the font size, or decreasing te button height.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/ceadfbfee534222c80c00c62f40d4549/06fd5/1_xxwqbc5tljktvknnr2onxa.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/ceadfbfee534222c80c00c62f40d4549/f6cdf/1_xxwqbc5tljktvknnr2onxa.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/ceadfbfee534222c80c00c62f40d4549/f6cdf/1_xxwqbc5tljktvknnr2onxa.png" alt="Properly aligned using square method">
      </picture>
    </span></p><p>Keep in mind, however, that buttons should be big enough to use them comfortably. That’s above 44p high on mobile and 32p on the web.</p><p><strong>2. Too little whitespace inside the button.</strong></p><p>For the label to “breathe” and be readable it needs enough space on all sides.</p><h3 id="the-w-method">The W-method</h3><p>You can use grid values for this, but there’s one other, easy way to achieve readability. Just use the capital letter W (2x) on both sides, and 1 x W on the top and bottom.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/a571c20e2337b2cc6f987cdfca968054/06fd5/1_0jqnaxjdl30y7d9qzi2r0q.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/a571c20e2337b2cc6f987cdfca968054/f6cdf/1_0jqnaxjdl30y7d9qzi2r0q.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/a571c20e2337b2cc6f987cdfca968054/f6cdf/1_0jqnaxjdl30y7d9qzi2r0q.png" alt="The W-method">
      </picture>
    </span></p><p>If they fit well, it means the whitespace is big enough. Of course if you have full-length buttons you don’t need to shrink them down. Only use this rule if your buttons are small.</p><h2 id="rule-3--colors-and-fonts">Rule 3 — Colors and fonts</h2><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/053b69e1422824810419afa02860608b/06fd5/1_vmlozppu4fqfvk2eklmxbg.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/053b69e1422824810419afa02860608b/f6cdf/1_vmlozppu4fqfvk2eklmxbg.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/053b69e1422824810419afa02860608b/f6cdf/1_vmlozppu4fqfvk2eklmxbg.png" alt="Good use of color and fonts on the left, and chaos on the right.">
      </picture>
    </span></p><p>The main thing you should do with both colors and fonts in any project is to simplify.</p><p>Go through all the screens and list out all the colors and all the fonts you can find.</p><p>If the list is full of very similar colors or very similar sized fonts — simplify it by picking one and replacing the other with it.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.lunadio.com/static/e2d69041b8f8410df2ca756d1f69a484/06fd5/1_r77egkezgpm2-4igufo3rq.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.lunadio.com/static/e2d69041b8f8410df2ca756d1f69a484/f6cdf/1_r77egkezgpm2-4igufo3rq.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img src="https://www.lunadio.com/static/e2d69041b8f8410df2ca756d1f69a484/f6cdf/1_r77egkezgpm2-4igufo3rq.png" alt="1 r77egkezgpm2 4igufo3rq">
      </picture>
    </span></p><p>Many projects, especially later in their lifecycle accrue a lot of design debt. It’s good to clean it up whenever you can and systemize the front-end. Use common values and a small group of colors only, as the more seemingly similar options, the longer it takes your users to process the information.</p><p>Keep everything consistent and remove any extra chaos.</p><h2 id="summary">Summary</h2><p>You don’t need to be a designer, to understand the basic principles behind how design works. Knowing just these simple rules will already make you a better developer.</p><p>Good luck!</p><hr><p>This is a Guest post by Michal Malewicz. Michal is the co-founder of <a href="https://hype4.com/" target="_blank" rel="noreferrer">HYPE4</a> design driven software house. He’s also a design lecturer, the author of <a href="https://www.designingui.com/" target="_blank" rel="noreferrer">Designing User Interfaces eBook</a> and co-author of the upcoming <a href="https://www.frontendunicorn.com/" target="_blank" rel="noreferrer">Frontend Unicorn ebook</a>.</p></div></article></div>]]>
            </description>
            <link>https://www.lunadio.com/blog/how-to-spot-and-fix-the-biggest-ui-problems</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837398</guid>
            <pubDate>Tue, 14 Jul 2020 20:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recreating YikYak with Postgres]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23837269">thread link</a>) | @AJRF
<br/>
July 14, 2020 | https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/ | <a href="https://web.archive.org/web/*/https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Yik_Yak" target="_blank">YikYak</a> was an anonymous social network that used your location to show you posts 5km around you.  Users of the app could create new posts and the people around them could view the posts and vote up or down.</p>



<p>YikYak filed a few patents for the tech that helped them achieve this. The patents mention segmenting users into buckets by their physical location. One modern tool we have to recreate this type of user segmentation is a data-structure called an <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/R*_tree" target="_blank">R-Tree</a>. </p>



<figure><img data-attachment-id="154" data-permalink="https://adamfallon.com/1rsz300nanspcxrd2bu5sqw/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?fit=2000%2C873&amp;ssl=1" data-orig-size="2000,873" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1rsz300nanspcxrd2bu5sqw" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?fit=300%2C131&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?fit=580%2C253&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>An example on an R-Tree in action</em></figcaption></figure>



<p>R-trees&nbsp;are&nbsp;tree data structures&nbsp;used for&nbsp;spatial access methods, i.e., for indexing multi-dimensional information such as&nbsp;<strong>geographical coordinates</strong>,&nbsp;rectangles&nbsp;or&nbsp;polygons.</p>



<p>Luckily the Postgres database enables us to make use of this data-structure via geospatial extensions. In this post I am going to;</p>



<ol><li>Show how we can enable those extensions.</li><li>Seed a few posts into our database.</li><li>Find the posts in a small around a specific latitude and longitude using a SQL query.</li></ol>



<p>Let’s get started!</p>



<hr>



<h2>Creating tables.</h2>



<p>Firstly you will need an instance of Postgres. It is easy to set up in Docker (I’ve detailed a post <a rel="noreferrer noopener" href="https://adamfallon.com/2020/07/08/postgres-in-docker/" target="_blank">here</a> showing how). </p>



<p>I am going to be using DBeaver for this tutorial but you could use psql or any other Postgres connector. Let’s creating a new table for our posts.</p>



<div><figure><img data-attachment-id="207" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-32-15/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?fit=2560%2C296&amp;ssl=1" data-orig-size="2560,296" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.32.15" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?fit=300%2C35&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?fit=580%2C67&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Select the SQL Editor</em></figcaption></figure></div>



<div><figure><img data-attachment-id="209" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-32-36/" data-orig-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?fit=829%2C339&amp;ssl=1" data-orig-size="829,339" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.32.36" data-image-description="" data-medium-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?fit=300%2C123&amp;ssl=1" data-large-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?fit=580%2C237&amp;ssl=1" src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Chose whatever Database you want. I am going with Postgres</em></figcaption></figure></div>



<div><figure><img data-attachment-id="210" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-33-04/" data-orig-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?fit=1090%2C682&amp;ssl=1" data-orig-size="1090,682" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.33.04" data-image-description="" data-medium-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?fit=580%2C363&amp;ssl=1" src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Name your script</em></figcaption></figure></div>



<p>Ready to go – So below we have a simple example of table for storing new posts. I am using a split latitude and longitude to show how the extensions work, but you could also combine the two into a POINT datatype if you are planning to use a lot of columns.</p>



<pre>CREATE TABLE post (
	id int8 NOT NULL GENERATED ALWAYS AS IDENTITY,
	post_content text NOT NULL,
	latitude float8 NOT NULL,
	longitude float8 NOT NULL
);</pre>



<p>On executing that you should have a table you can start insert values into. </p>



<h2>Inserting posts.</h2>



<p>So let’s start out by inserting two posts, the first posted from 10 Downing Street, and the second from Buckingham Palace.</p>



<pre>INSERT INTO post VALUES (
	default,
	'I absolutely love the Queen. I hope she thinks I am doing a good job.',
	51.5034,
	0.1276
);
INSERT INTO post VALUES (
	default,
	'The new Prime Minister is a prat! I do hope he doesnt come over often',
	51.5014,
	0.1419
);</pre>



<p>Now let’s put another post in from an aspiring politics student who is located in Cambridge University (65 miles away). Now we have an outlier that won’t show up once we do location bound queries later in this tutorial.</p>



<pre>INSERT INTO post VALUES (
	default,
	'Day one of my politics degree. Shall be most fun to stalk the halls of Westminister in 4 years.',
	52.2053,
	0.1218
);</pre>



<h2>Installing Postgres extensions</h2>



<p>We would like to be able to stand in St. James park (a large park between 10 Downing Street and Buckingham Palace) and see the two posts close by, but not the one from Cambridge.</p>



<p>So how do we do that? Through extensions! Postgres enables users to incrementally add features that help us do new things with our data.</p>



<p>Once they are installed we can use the latitude and longitude of <em>51.5032, -0.1349</em> to create a new select query on our posts table.</p>



<div data-amp-noloading="true" data-amp-lightbox="true"><figure><img data-attachment-id="217" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-55-52/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?fit=2560%2C1382&amp;ssl=1" data-orig-size="2560,1382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.55.52" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?fit=300%2C162&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?fit=580%2C313&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>You can install extensions in Postgres simply by running a query. The two extensions we need are <strong><em>cube</em></strong> and <strong><em>earthdistance</em></strong>.</p>



<pre>CREATE EXTENSION IF NOT EXISTS cube;
CREATE EXTENSION IF NOT EXISTS earthdistance;</pre>



<p>After executing those two queries, you should see them under the ‘Extensions’ tab in DBeaver.</p>



<div><figure><img data-attachment-id="219" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-10-24-18/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?fit=652%2C190&amp;ssl=1" data-orig-size="652,190" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-10.24.18" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?fit=300%2C87&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?fit=580%2C169&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h2>Finding nearby posts.</h2>



<p>We can now use these built in functions from those extensions to show us the two nearby posts.</p>



<pre>SELECT * FROM post
WHERE 
	earth_box(ll_to_earth(51.5032,-0.1349), 50000) 
	@&gt; ll_to_earth(latitude, longitude);</pre>



<p>The earth_box function takes two parameters, a point (which is returned by the ll_to_earth function) and a value for the size of the bounding box we want which is in metres. </p>



<p>By using the <a aria-label="undefined (opens in a new tab)" href="https://www.postgresql.org/docs/current/functions-geometry.html" target="_blank" rel="noreferrer noopener nofollow">contains?</a> operator (@&gt;) we are saying we only want values in the table in the bounding box generated by the earth_box function.</p>



<p>When executing that query we will see the two posts we were expecting! Try increasing the bounding box range out and you will be able to see the Cambridge post.</p>



<div><figure><img data-attachment-id="223" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-10-30-11/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?fit=2558%2C1516&amp;ssl=1" data-orig-size="2558,1516" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-10.30.11" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?fit=300%2C178&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?fit=580%2C344&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>So now we have a working example of how to recreate the YikYak location-based functionality.</p>



<h2>So…how?</h2>



<p>Okay so why did we need those extensions? Can’t we just take the world, split it into squares and determine which box a latitude and longitude falls into? </p>



<p>Thats what we would <em>like</em> to do – but there are complications caused by the fact that the world is a sphere. To find posts “in your area” you are querying to find straight line distances between two points, your lat-long and for each row in the database. In a sphere there are no straight lines. </p>



<p>There is a way to determine the distance between two points known as the <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Great-circle_distance#:~:text=The%20great%2Dcircle%20distance%20or,line%20through%20the%20sphere's%20interior)." target="_blank" rel="noreferrer noopener nofollow">Great-Circle distance</a>. Instead of using straight lines we use circles or curves known as geodesics. Through any two points on a sphere that are not&nbsp;<a href="https://en.wikipedia.org/wiki/Antipodal_point">directly opposite each other</a>, there is a unique great circle. </p>



<p>The earthdistance extension allows us to generate queries using the contains? operator from the cube extension to generate efficient distance lookups between points.</p>



<h2>Conclusion</h2>



<p>One thing to note is that this query will do a sequential scan of the entire table, which can be slow once you get up to thousands of posts. </p>



<p>If you do decide to use this setup in your application you should create an index on the latitude, longitude to dramatically speed up queries. That would look like this.</p>



<pre>CREATE INDEX loc_index ON post USING gist (ll_to_earth(latitude, longitude));</pre>



<p>Postgres will then determine whether it needs to use this index to speed up queries. You can check if the index is being used by using a tool to view the execution plan when you run the query detailed above. If it says SEQ_SCAN it is not using the index. </p>



<p>And we’re done! If you’ve noticed any mistakes or improvements I can make please drop me an email at adam@adamfallon.com</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837269</guid>
            <pubDate>Tue, 14 Jul 2020 20:18:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Khmer Rouge: Genocide in the Name of Utopia (2016)]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 176 (<a href="https://news.ycombinator.com/item?id=23836985">thread link</a>) | @exolymph
<br/>
July 14, 2020 | https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/ | <a href="https://web.archive.org/web/*/https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<h5><strong>How is history used to support ideology? Is violence by a government against its own civilian population ever justified? Why are certain events given priority over others in history books?</strong></h5>
<h5><strong>This lesson was reported from:</strong></h5>

<h6>Adapted in part from open sources.</h6>

<figure data-shortcode="caption" id="attachment_464" aria-describedby="caption-attachment-464"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg"><img data-attachment-id="464" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/skulls_2584193k/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg" data-orig-size="858,536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Evidence for genocide in Cambodia." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=820" src="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=581&amp;h=362" alt="Evidence for genocide in Cambodia." width="581" height="362" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=579&amp;h=362 579w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=150&amp;h=94 150w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=300&amp;h=187 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=768&amp;h=480 768w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg 858w" sizes="(max-width: 581px) 100vw, 581px"></a><figcaption id="caption-attachment-464">Evidence for genocide in Cambodia.</figcaption></figure>
<p><!--block-->The Khmer Rouge was formed in 1968 as a revolutionary Communist party in Cambodia. It was the <a href="https://en.wikipedia.org/wiki/Ruling_party">ruling party</a> in Cambodia from 1975 to 1979, led by <a href="https://en.wikipedia.org/wiki/Pol_Pot">Pol Pot</a>. <a href="https://en.wikipedia.org/wiki/Democratic_Kampuchea">Democratic Kampuchea</a> was the name of the state as controlled by the government of the Khmer Rouge from 1975 to 1979.</p>
<p><!--block-->The four-year period cost approximately 2 million lives through the combined result of political executions, disease, <a href="https://en.wikipedia.org/wiki/Starvation">starvation</a>, and <a href="https://en.wikipedia.org/wiki/Unfree_labor">forced labor</a>. Due to the large numbers, the deaths during the rule of the Khmer Rouge are commonly known as the Cambodian Holocaust or <a href="https://en.wikipedia.org/wiki/Cambodian_genocide">Cambodian genocide</a>. The Khmer Rouge took power at the end of the <a href="https://en.wikipedia.org/wiki/Cambodian_Civil_War">Cambodian Civil War</a> and were only toppled after the invasion of Cambodia by the neighboring Socialist Republic of <a href="https://en.wikipedia.org/wiki/Vietnam">Vietnam</a> in the <a href="https://en.wikipedia.org/wiki/Cambodian%E2%80%93Vietnamese_War">Cambodian–Vietnamese War</a>.</p>
<h2>Pol Pot and the Revolution</h2>

<p><!--block-->Saloth Sar was born on 19 May 1925, the eighth of nine children and the second of three sons to Pen Saloth and Sok Nem. The family was living in the small fishing village of <a href="https://en.wikipedia.org/wiki/Prek_Sbauv">Prek Sbauv</a>, <a href="https://en.wikipedia.org/wiki/Kampong_Thom_Province">Kampong Thom Province</a> when Cambodia was still a French colony. Pen Saloth was a rice farmer who owned 12 <a href="https://en.wikipedia.org/wiki/Hectare">hectares</a> of land and several buffaloes; the family was considered moderately wealthy by the standards of the day. Although Pen Saloth’s family was of <a href="https://en.wikipedia.org/wiki/Chinese_Cambodian">Sino</a>–<a href="https://en.wikipedia.org/wiki/Khmer_people">Khmer</a> descent and Saloth Sar was named accordingly due to his fair complexion (“Sar” means white in Khmer), the family had already assimilated themselves with mainstream Khmer society by the time Sar was born.</p>
<p><!--block-->In 1935, Saloth Sar left Prek Sbauv to attend the École Miche, a Catholic school in <a href="https://en.wikipedia.org/wiki/Phnom_Penh">Phnom Penh</a>. He lived with his cousin, a woman called Meak, a member of the <a href="https://en.wikipedia.org/wiki/Royal_Ballet_of_Cambodia">Royal Ballet</a>.In 1926, she bore King <a href="https://en.wikipedia.org/wiki/Sisowath_Monivong">Monivong’s</a> son, HRH Prince Sisowath Kusarak. She was given the official title <em>Khun Preah Moneang Bopha Norleak Meak</em>. Saloth Sar stayed with Meak’s household until 1942. His sister Roeung was a <a href="https://en.wikipedia.org/wiki/Concubinage">concubine</a> of King Monivong, so through the two women, he often had cause to visit the <a href="https://en.wikipedia.org/wiki/Royal_Palace,_Phnom_Penh">royal palace</a>.&nbsp; In 1947, he gained admission to the exclusive <a href="https://en.wikipedia.org/wiki/Lyc%C3%A9e_Sisowath">Lycée Sisowath</a>, but was unsuccessful in his studies.</p>
<p><!--block-->As a student in Phnom Penh and later in Paris, Saloth was exposed to anti-colonial, revolutionary, and socialist ideas.&nbsp; He became increasingly radical, outraged by French colonialism, the poverty of his nation compared to France itself, and wealth inequality within Cambodia even after French granted the nation independence in the 1950s.</p>
<p><!--block-->Saloth was a founding member of the Khmer Rouge, a party dedicated to socialist revolution in Cambodia.</p>
<div>
<h2>Ideology</h2>
<figure data-shortcode="caption" id="attachment_470" aria-describedby="caption-attachment-470"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg"><img data-attachment-id="470" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/9660abf16bdbccfcaa829a72aa444922/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg" data-orig-size="634,692" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="A female Khmer Rouge fighter or ‘mit naree’ carries an AK-47 assault rifle, a weapon of Communist revolution the world over." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=275" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=634" src="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=275&amp;h=300" alt="A female Khmer Rouge fighter or 'mit naree' carries an AK-47 assault rifle, a weapon of Communist revolution the world over." width="275" height="300" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=275&amp;h=300 275w, https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=550&amp;h=600 550w, https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=137&amp;h=150 137w" sizes="(max-width: 275px) 100vw, 275px"></a><figcaption id="caption-attachment-470">A female Khmer Rouge fighter or ‘mit naree’ carries an AK-47 assault rifle, a weapon of Communist revolution the world over.</figcaption></figure>
<p>The Khmer Rouge’s ideology combined elements of&nbsp;<a href="https://en.wikipedia.org/wiki/Marxism">Marxism</a>&nbsp;with an extreme version of Khmer nationalism and&nbsp;<a href="https://en.wikipedia.org/wiki/Xenophobia">xenophobia</a>. It combined an idealization of the&nbsp;<a href="https://en.wikipedia.org/wiki/Angkor_Empire">Angkor Empire</a>&nbsp;(802–1431), with an existential fear for the existence of the Cambodian state, which had historically been liquidated under Vietnamese and Siamese intervention.The spillover of Vietnamese fighters from the&nbsp;<a href="https://en.wikipedia.org/wiki/Vietnam_War">Vietnam War</a>&nbsp;further aggravated anti-Vietnamese feeling. The Khmer Rouge explicitly targeted the Chinese, Vietnamese, and even their partially Khmer offspring for extinction; although the&nbsp;<a href="https://en.wikipedia.org/wiki/Cham_people">Cham Muslims</a>&nbsp;were treated unfavorably, they were encouraged to “mix flesh and blood”, to intermarry and assimilate. Some people with partial Chinese or Vietnamese ancestry were present in the Khmer Rouge leadership; they either were purged or participated in the&nbsp;<a href="https://en.wikipedia.org/wiki/Ethnic_cleansing">ethnic cleansing</a>&nbsp;campaigns.</p>
<p>The Khmer Rouge’s social policy focused on working towards a purely agrarian society. Pol Pot strongly influenced the propagation of this policy. He was reportedly impressed with how the mountain tribes of Cambodia lived, which the party interpreted as a form of&nbsp;<a href="https://en.wikipedia.org/wiki/Primitive_communism">primitive communism</a>; as a result, those minorities received more lenient and sometimes even more favorable treatment than the urbanized “<a href="https://en.wikipedia.org/wiki/Bourgeois">bourgeois</a>” Chinese and Vietnamese. Pol Pot wanted to remove social institutions and to transform the society into an agrarian one. This was his way of “[creating] a complete Communist society without wasting time on the intermediate steps” as the Khmer Rouge said to&nbsp;<a href="https://en.wikipedia.org/wiki/China">China</a>&nbsp;in 1975.</p>
<h2>Control of the countryside</h2>
<p>The Khmer Rouge advanced during 1973. After they reached the outskirts of Phnom Penh, Sar issued orders during the peak of the <a href="https://en.wikipedia.org/wiki/Wet_season">rainy season</a> that the city be taken. The orders led to futile attacks and wasted lives within the Khmer Rouge army. By the middle of 1973, the Khmer Rouge under Sar controlled almost two-thirds of the country and half the population.</p>
<p>Internationally, Sar and the Khmer Rouge gained the recognition of 63 countries as the true government of Cambodia. A move was made at the UN to give the seat for Cambodia to the Khmer Rouge; they prevailed by three votes.</p>
<div>
<p>The Khmer Rouge took the capital <a href="https://en.wikipedia.org/wiki/Phnom_Penh">Phnom Penh</a> on 17 April 1975, proclaiming this be Year Zero – all culture and traditions within society would be completely destroyed or discarded, and a new revolutionary culture would replace it.</p>
<figure data-shortcode="caption" id="attachment_473" aria-describedby="caption-attachment-473"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg"><img data-attachment-id="473" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/d158d8646827595a49fa281c27071779/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg" data-orig-size="611,404" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Phnom Penh, January 1st, 1975 in the waning days of the civil war." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=611" src="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=580&amp;h=383" alt="Phnom Penh, January 1st, 1975 in the waning days of the civil war." width="580" height="383" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=580&amp;h=383 580w, https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=150&amp;h=99 150w, https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=300&amp;h=198 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg 611w" sizes="(max-width: 580px) 100vw, 580px"></a><figcaption id="caption-attachment-473">Phnom Penh, January 1st, 1975 in the waning days of the civil war.</figcaption></figure>
<h2>Societal transformation</h2>
<p>After taking power, the Khmer Rouge leadership renamed the country Democratic Kampuchea. The Khmer Rouge subjected Cambodia to a radical social reform process that was aimed at creating a purely&nbsp;<a href="https://en.wikipedia.org/wiki/Agrarian_socialism">agrarian-based Communist society</a>.&nbsp;The Khmer Rouge forced around three million people from the cities to the countryside to take up work in agriculture. They forced many people out of their homes and ignored many basic human freedoms; they controlled how Cambodians acted, what they wore, to whom they could talk, and many other aspects of their lives.</p>
<dl id="attachment_472">
<dt><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png"><img data-attachment-id="472" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/90631961305feae1ac126f4e2ae87bc7/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png" data-orig-size="1204,1007" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="The evacuation of Cambodia’s urban areas occurred on the pretext of a U.S. invasion that never came." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=820" src="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=300&amp;h=251" alt="The evacuation of Cambodia's urban areas occurred on the pretext of a U.S. invasion that never came." width="300" height="251" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=300&amp;h=251 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=600&amp;h=502 600w, https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=150&amp;h=125 150w" sizes="(max-width: 300px) 100vw, 300px"></a></dt>
<dd>The evacuation of Cambodia’s urban areas occurred on the pretext of a U.S. invasion that never came.</dd>
</dl>
<p>The Khmer Rouge believed that parents were tainted with&nbsp;<a href="https://en.wikipedia.org/wiki/Capitalism">capitalism</a>, so they separated children from their parents, indoctrinated them in&nbsp;<a href="https://en.wikipedia.org/wiki/Communism">communism</a>, and taught them torture methods with animals. Children were a “dictatorial instrument of the party” and were given leadership in torture and executions.</p>
<p>Society was divided into two categories. These were the New People – intellectuals, city-dwellers, minority people, and many of their own party members and soldiers who were suspected of being traitors – and the Old People – those who already lived in the countryside.</p>
<p>The lowest unit of social control, the&nbsp;<em>krom</em>&nbsp;(group), consisted of ten to fifteen nuclear families whose activities were closely supervised by a three-person committee. The committee chairman was selected by the CPK. This grass roots leadership was required to note the social origin of each family under its jurisdiction and to report it to persons higher up in the&nbsp;party hierarchy.</p>
<h2>The New People</h2>
<div>
<figure data-shortcode="caption" id="attachment_475" aria-describedby="caption-attachment-475"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg"><img data-attachment-id="475" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/khmer_rouge_07/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg" data-orig-size="611,404" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Forced labor camp in Kampong Cham, Cambodia." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=611" src="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=368&amp;h=243" alt="Forced labor camp in Kampong Cham, Cambodia." width="368" height="243" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=368&amp;h=243 368w, https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=150&amp;h=99 150w, https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=300&amp;h=198 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg 611w" sizes="(max-width: 368px) 100vw, 368px"></a><figcaption id="caption-attachment-475">Forced labor camp in Kampong Cham, Cambodia.</figcaption></figure>
<p>New People were treated as forced laborers. They were constantly moved, were forced to do the hardest physical labor, and worked in the most inhospitable, fever-ridden parts of the country, such as forests, upland areas, and swamps. “New People were segregated from Old People, enjoyed little or no privacy, and received the smallest rice rations. When the country experienced <a href="https://en.wikipedia.org/wiki/Famine">food shortages</a> in 1977, the New People suffered the most.</p>
</div>
<p>The medical care available to them was primitive or nonexistent. Families often were separated because people were divided into work brigades according to age and sex and sent to different parts of the country. New People were subjected to unending political indoctrination and could be executed without trial.</p>
<p>One of their mottos in reference to the <a href="https://en.wikipedia.org/wiki/New_People">New People</a> was: “To keep you is no benefit. To destroy you is no loss.”</p>
<p>The situation of the Old People under Khmer Rouge rule was more ambiguous. Refugee interviews reveal cases in which villagers were treated as harshly as the New People, enduring forced labor, indoctrination, the separation of children from parents, and executions; however, they were generally allowed to remain in their native villages.</p>
</div>
</div>
<h2>Life Under the Khmer Rouge</h2>
<div>
<p>Once in power, the Khmer Rouge carried out a radical program that included isolating the country from all foreign influences, closing schools, hospitals, and factories, abolishing banking, finance, and currency, outlawing all religions, confiscating all <a href="https://en.wikipedia.org/wiki/Private_property">private property</a> and relocating people from urban areas to <a href="https://en.wikipedia.org/wiki/Collective_farm">collective farms</a> where forced labor was widespread. The purpose of this policy was to turn all Cambodians into Old People through agricultural labor.</p>
<figure data-shortcode="caption" id="attachment_466" aria-describedby="caption-attachment-466"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg"><img data-attachment-id="466" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/8e1cd4dbed4fa55ac88aba90e53ea0e8/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg" data-orig-size="826,779" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="The evactuation of Phnom Penh, 1975." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=820" src="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=300&amp;h=283" alt="The evacuation of Phnom Penh, 1975." width="300" height="283" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=300&amp;h=283 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=600&amp;h=566 600w, https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=150&amp;h=141 150w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-466">The evacuation of Phnom Penh, 1975.</figcaption></figure>
<p>In Phnom Penh and other cities, the Khmer Rouge told <a href="https://en.wikipedia.org/wiki/Residency_(domicile)">residents</a> that they would be moved only about “two or three kilometers” outside the city and would return in “two or three days”. Some witnesses say they were told that the evacuation was because of the “threat of American bombing” and that they did not have to lock their houses since the Khmer Rouge would “take care of everything” until they returned. People who refused to evacuate would have their homes burned to the ground and would be killed immediately. The evacuees were sent on long marches to the countryside, which killed thousands of children, elderly people, and sick people.These were not the first evacuations of civilian populations by the Khmer Rouge; similar evacuations of populations without possessions had been occurring on a smaller scale since the early 1970s.</p>
<p>The entire population was forced to become farmers in <a href="https://en.m.wikipedia.org/wiki/Labour_camp">labor camps</a>. Cambodians were expected to produce three tons of rice per hectare; before the Khmer Rouge era, the average was only one ton per hectare. The total lack of agricultural knowledge by the former city dwellers made <a href="https://en.m.wikipedia.org/wiki/Famine">famine</a> inevitable. Rural dwellers were often unsympathetic or too frightened to assist them. Such acts …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/">https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/</a></em></p>]]>
            </description>
            <link>https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836985</guid>
            <pubDate>Tue, 14 Jul 2020 19:57:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deploying a State-of-the-Art Question Answering System with 60 Lines of Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836903">thread link</a>) | @rbanffy
<br/>
July 14, 2020 | https://www.confetti.ai/post/deploying-a-state-of-the-art-question-answering-system-with-60-lines-of-python-and-streamlit | <a href="https://web.archive.org/web/*/https://www.confetti.ai/post/deploying-a-state-of-the-art-question-answering-system-with-60-lines-of-python-and-streamlit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.3"><div dir="ltr"><div><div id="viewer-4lkva"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.confetti.ai/post/deploying-a-state-of-the-art-question-answering-system-with-60-lines-of-python-and-streamlit" data-pin-media="https://static.wixstatic.com/media/4feadc_eb5e26b838c8483a9137c275351425b6~mv2.jpg/v1/fit/w_3000,h_2000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4feadc_eb5e26b838c8483a9137c275351425b6~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-ftqun">Nowadays, the machine learning and data science job landscape is changing rapidly. </p><p id="viewer-c1di0">Within industry, the skills that are becoming most valuable aren't knowing how to tune a ResNet on an image dataset. In fact, the prevalence of well-designed frameworks such as PyTorch and Tensorflow are making these skills increasingly easy to pickup. </p><p id="viewer-9en8l">Rather as many larger enterprises look to adopt machine learning as part of their business offerings, the skills that are in high demand are knowing how to solve the "last mile problem." In other words, how do you go from a trained, functional model sitting on your local machine to a deployed service that can be used by customers, typically via a web API? </p><p id="viewer-anq5p">Solving this problem is less about the right hyperparameters or features needed to eke out the last percentage point on a task but more about knowing how to engineer a deployment pipeline.</p><p id="viewer-71gnl">This means that engineering and infrastructure requirements are emerging as the biggest bottlenecks in deploying real world machine learning systems. The statistics are sobering: <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/" target="_blank" rel="noopener"><u>87% of data science project never make it into production</u></a>.</p><p id="viewer-af9sd"><span>Thankfully, we are also seeing the emergence of powerful libraries that help address this last mile problem. One library in particular, called </span><a href="https://www.streamlit.io/" target="_blank" rel="noopener"><span><u>Streamlit</u></span></a><span><u>,</u> is a powerful player in this space that offers a low-effort solution to the deployment. </span></p><p id="viewer-7osg6"><span>In this post, we will show how with Streamlit we need only <strong>60 lines of Python</strong> to deploy an interactive web app making calls to a state-of-the-art neural question answering system that can query all of Wikipedia. Let's get started!</span></p><h3 id="viewer-crsad"><span><strong>Use-Case</strong></span></h3><p id="viewer-7jnsp"><span>Our app will use a powerful neural model can be used to answer questions about any arbitrary Wikipedia article. It will allow users to retrieve any Wikipedia article and then ask the model to read and extract bits of information from it. </span></p><h3 id="viewer-5clq9"><span><strong>Model </strong></span></h3><p id="viewer-f54ne"><span>The question answering model used is a variant of </span><a href="https://arxiv.org/pdf/1910.01108.pdf" target="_blank" rel="noopener"><span><u>DistilBert</u></span></a><span>, a neural Transformer model with roughly 66 million parameters. </span></p><h3 id="viewer-5v18j"><span><strong>Code</strong></span></h3><p id="viewer-gmda"><span>We first load up our question answering model via a pipeline:</span></p><pre id="viewer-7fr87"><span><span>from</span></span><span> </span>typing <span><span>import</span></span><span> </span>Dict

<span><span>import</span></span><span> </span>streamlit <span><span>as</span></span><span> </span>st
<span><span>import</span></span><span> </span>wikipedia
<span><span>from</span></span><span> </span>transformers <span><span>import</span></span><span> </span>Pipeline
<span><span>from</span></span><span> </span>transformers <span><span>import</span></span><span> </span>pipeline

<span>NUM_SENT</span> <span>=</span> <span><span>10</span></span>

<span>@st</span><span><span>.</span></span><span>cache</span>
<span>def </span><span><span>get_qa_pipeline</span></span><span>(</span><span>)</span> <span>-</span><span>&gt;</span> Pipeline<span>:</span>
    qa <span>=</span> <span>pipeline</span><span>(</span><span>"<span>question-answering"</span></span><span>)</span>
    <span><span>return</span></span><span> </span>qa


<span>def </span><span><span>answer_question</span></span><span>(</span>pipeline<span>:</span> Pipeline<span><span>,</span></span><span> </span>question<span>:</span> <span>str</span><span><span>,</span></span><span> </span>paragraph<span>:</span> <span>str</span><span>)</span> <span>-</span><span>&gt;</span> Dict<span>:</span>
    input <span>=</span> <span>{</span>
        <span><span>"question"</span></span><span>:</span> question<span><span>,</span></span>
<span>        </span><span><span>"context"</span></span><span>:</span> paragraph
    <span>}</span>
    <span><span>return</span></span><span> </span><span>pipeline</span><span>(</span>input<span>)</span></pre><p id="viewer-bcr9e">Here we are using a pipeline object that wraps around a pretrained model from the  <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener"><u>Transformers library</u></a><u>.</u> Note we are using the @<em>st.cache</em> Streamlit decorator which prevents unnecessary reloads of the model, since this can be computationally expensive. </p><p id="viewer-da3pm">Next we provide functionality for getting articles from Wikipedia: </p><pre id="viewer-8puha"><span>@st</span><span><span>.</span></span><span>cache</span>
<span>def </span><span><span>get_wiki_paragraph</span></span><span>(</span>query<span>:</span> <span>str</span><span>)</span> <span>-</span><span>&gt;</span> <span>str</span><span>:</span>
    results <span>=</span> wikipedia<span>.</span><span>search</span><span>(</span>query<span>)</span>
    <span><span>try</span></span><span>:</span>
        summary <span>=</span> wikipedia<span>.</span><span>summary</span><span>(</span>results<span>[</span><span><span>0</span></span><span>]</span><span><span>,</span></span><span> </span><span>sentences</span><span>=</span><span>NUM_SENT</span><span>)</span>
    <span>except </span>wikipedia<span>.</span>DisambiguationError <span><span>as</span></span><span> </span>e<span>:</span>
        ambiguous_terms <span>=</span> e<span>.</span>options
        <span><span>return</span></span><span> </span>wikipedia<span>.</span><span>summary</span><span>(</span>ambiguous_terms<span>[</span><span><span>0</span></span><span>]</span><span><span>,</span></span><span> </span><span>sentences</span><span>=</span><span>NUM_SENT</span><span>)</span>
    <span><span>return</span></span><span> </span>summary


<span>def </span><span><span>format_text</span></span><span>(</span>paragraph<span>:</span> <span>str</span><span><span>,</span></span><span> </span>start_idx<span>:</span> <span>int</span><span><span>,</span></span><span> </span>end_idx<span>:</span> <span>int</span><span>)</span> <span>-</span><span>&gt;</span> <span>str</span><span>:</span>
    <span><span>return</span></span><span> </span>paragraph<span>[</span><span>:</span>start_idx<span>]</span> <span>+</span> <span><span>"**"</span></span><span> </span><span>+</span> paragraph<span>[</span>start_idx<span>:</span>end_idx<span>]</span> <span>+</span> <span><span>"**"</span></span><span> </span><span>+</span> paragraph<span>[</span>end_idx<span>:</span><span>]</span></pre><p id="viewer-l6fr">This uses the provided query to make a call to the <a href="https://wikipedia.readthedocs.io/en/latest/quickstart.html#quickstart" target="_blank" rel="noopener"><u>Python wikipedia library</u></a>. The second function will be used once our model returns a value to highlight the answer within the paragraph.     </p><p id="viewer-e07ef">Finally, we provide the main engine of the app, which renders the text inputs using Streamlit and makes the subsequent calls to the above functions:</p><pre id="viewer-8sfn5"><span><span>if</span></span><span> </span>__name__ <span>==</span> <span><span>"__main__"</span></span><span>:</span>
    <span><span>""</span></span><span>"</span>
<span>    # Wikipedia Article</span>
<span>    </span><span><span>""</span></span><span>"</span>
<span>    </span>paragraph_slot <span>=</span> st<span>.</span><span>empty</span><span>(</span><span>)</span>
    wiki_query <span>=</span> st<span>.</span><span>text_input</span><span>(</span><span><span>"WIKIPEDIA SEARCH TERM"</span></span><span><span>,</span></span><span> </span><span><span>""</span></span><span>)</span>
    question <span>=</span> st<span>.</span><span>text_input</span><span>(</span><span><span>"QUESTION"</span></span><span><span>,</span></span><span> </span><span><span>""</span></span><span>)</span>
    
    <span><span>if</span></span><span> </span>wiki_query<span>:</span>
        wiki_para <span>=</span> <span>get_wiki_paragraph</span><span>(</span>wiki_query<span>)</span>
        paragraph_slot<span>.</span><span>markdown</span><span>(</span>wiki_para<span>)</span>
        <span># Execute question against paragraph</span>
<span>        </span><span><span>if</span></span><span> </span>question <span>!=</span> <span><span>""</span></span><span>:</span>
            pipeline <span>=</span> <span>get_qa_pipeline</span><span>(</span><span>)</span>
            st<span>.</span><span>write</span><span>(</span>pipeline<span>.</span>model<span>)</span>
            st<span>.</span><span>write</span><span>(</span>pipeline<span>.</span>model<span>.</span>config<span>)</span>
            <span><span>try</span></span><span>:</span>
                answer <span>=</span> <span>answer_question</span><span>(</span>pipeline<span><span>,</span></span><span> </span>question<span><span>,</span></span><span> </span>wiki_para<span>)</span>
                
                start_idx <span>=</span> answer<span>[</span><span><span>"start"</span></span><span>]</span>
                end_idx <span>=</span> answer<span>[</span><span><span>"end"</span></span><span>]</span>
                paragraph_slot<span>.</span><span>markdown</span><span>(</span><span>format_text</span><span>(</span>wiki_para<span><span>,</span></span><span> </span>start_idx<span><span>,</span></span><span> </span>end_idx<span>)</span><span>)</span>
            <span>except</span><span>:</span>
                st<span>.</span><span>write</span><span>(</span><span><span>"You must provide a valid wikipedia paragraph"</span></span><span>)</span>

</pre><p id="viewer-cpa8d">All we have to do to deploy the app locally is save the code within a file <strong>app.py </strong>and run:</p><pre id="viewer-1d05e">streamlit run app<span>.</span>py</pre><p id="viewer-a5pok">And with that, we have a functional state-of-the-art question-answering system deployed as a web application! You can see the <a href="http://streamlit-demo.confetti.ai:8501/" target="_blank" rel="noopener"><u>running demo here</u></a><u>.</u></p><p id="viewer-7cdu4"> There's a lot more that can be done with Streamlit, so we encourage you to check out the <a href="https://docs.streamlit.io/en/stable/api.html" target="_blank" rel="noopener"><u>documentation</u></a>. </p><p id="viewer-4rgns">For more educational resource offerings related to becoming a full-stack machine learning engineer or data scientist, subscribe to the <a href="https://www.confetti.ai/" target="_blank" rel="noopener"><u>Confetti AI newsletter</u></a><u>.</u></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.confetti.ai/post/deploying-a-state-of-the-art-question-answering-system-with-60-lines-of-python-and-streamlit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836903</guid>
            <pubDate>Tue, 14 Jul 2020 19:52:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doom Eternal Privacy Policy Allows Collection and Disclosure of Medical Records]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 125 (<a href="https://news.ycombinator.com/item?id=23836876">thread link</a>) | @gentleman11
<br/>
July 14, 2020 | https://wrap.bnet.idtech.services/legal/?limited=true&fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html | <a href="https://web.archive.org/web/*/https://wrap.bnet.idtech.services/legal/?limited=true&fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p><img src="https://esrbstorage.blob.core.windows.net/esrbcontent/images/privacy_certified_globe_color.gif" alt="ESRB PRIVACY CERTIFIED MEMBER CONFIRMATION"></p>

<p>Last Updated: January 27, 2020</p>
<p>This ZeniMax Media Online Privacy Policy ("<strong>Policy</strong>") describes how ZeniMax Media Inc. and our affiliates and subsidiaries (collectively, "<strong>ZeniMax</strong>", "<strong>we</strong>" or "<strong>us</strong>") collect, use and otherwise process the personal information we collect about our about customers, purchasers, subscribers, and/or users (each a " <strong>User</strong>") of our mobile applications, games, websites and other online services (collectively, our " <strong>Services</strong>").</p>
<table>
  <tbody><tr>
    <th colspan="3">Overview of Our Collection and Use of Personal Information</th>
  </tr>
  <tr>
    <td colspan="3">This table provides an overview and is intended to summarize key information about our information practices, which are further explained in our Privacy Policy below.  The actual information we collect about you and the use of such personal information will vary depending upon the nature of our relationship and interactions with you. </td>
  </tr>
  <tr>
    <td colspan="2">Categories of personal information collected  </td>
    <td colspan="1">Uses of personal information </td>
  </tr>
  <tr>
    <td colspan="2"><b>Name, contact info and other identifiers</b> (e.g., name, email, address, username and alias; UID, BUID, device id, third party platform identifiers and account details (e.g., PlayStationÂ®, Xbox, Steam, Facebook), and other online or unique identifiers)</td>
    <td rowspan="7">
    <ul>
      <li>Providing our Services and related support</li>
      <li>Protecting the integrity of the Services</li>
      <li>Analyzing and improving the Services and our business</li>
      <li>Personalizing the Services</li><li>Advertising, marketing and promotional purposes</li>
      <li>Securing and protecting our business</li>
      <li>Defending our legal rights</li>
      <li>Auditing, reporting, corporate governance, and internal operations</li>
      <li>Complying with legal obligations</li>
    </ul>
</td>
  </tr>
   <tr>
    <td colspan="2"><b>Paper and electronic customer records</b> (e.g., your account and profile, which contains personal information, such as username, name, demographics and other characteristics or descriptions, email, address, telephone number, and other contact information, account credentials, communications preferences, and customer service and support tickets and other records)</td>
  </tr>
   <tr>
    <td colspan="2"><b>Purchase history and tendencies</b> (e.g., information about your subscriptions current and past payments and purchases, and your purchase tendencies)</td>
  </tr>
   <tr>
     <td colspan="2"><b>Usage data</b> (e.g., usage and preference details related to your use of the Services, such as language, in-game purchases, game-play statistics, scores, persona, characters, achievements, rankings, time spent playing, click paths, game profile, preferences and friends)</td>
  </tr>
  <tr>
    <td colspan="2"><b>Geolocation data</b> (e.g., for mobile games users)</td>
  </tr>
   <tr>
    <td colspan="2"><b>Audio, video and other electronic data</b> (e.g., call recordings of customer support calls, and User photos submitted to the Services)</td>
  </tr>
   <tr>
    <td colspan="2"><b>Profiles and inferences</b> (e.g., profiles based on your account and activities, that reflect your preferences, characteristics, and abilities related to the Services)</td>
  </tr>
   <tr>
    <td colspan="3"><b>ESRB Privacy certification.</b> ZeniMax values the importance of your privacy and has received the ESRB Privacy Certification. ZeniMax is a valid licensee, and participating member of the Entertainment Software Rating Board's Privacy Certified Program (â€œ<b>ESRB Privacy Certified</b>â€�). All Services where this Policy is posted and which display an ESRB certification seal have been reviewed and certified by ESRB Privacy Certified to meet established online information collection, use and disclosure practices. As a licensee of this privacy program, we are subject to audits of our Services and other enforcement and accountability mechanisms administered independently by the ESRB.</td>
  </tr>
    <tr>
      <td colspan="3"><b>Individual rights.</b> Please see Section 12. User Rights and Choices below for a description of the choices we provide and the rights you have regarding your personal information. If you are a California resident, please be sure to review Section 15.a.  <u>Additional information for California Residents</u> below for important information about the categories of personal information we collect and disclose and your rights under California privacy laws.  If you are in the European Economic Area, please see Section 15.b. <u>Users in the European Economic Area</u> for more information about your rights under the EU General Data Protection Regulation (GDPR).</td>
  </tr>
</tbody></table>

<p>Scope of Our Policy</p>
<p>Personal Information We Collect</p>
<p>Purposes of Use and Legal Bases for Processing of Personal Information</p>
<p>Disclosure and Sharing of Personal Information</p>
<p>Cookies, Analytics and Personalization</p>
<p>Interest-based Advertising</p>
<p>Third Party Links and Features</p>
<p>User Generated Content</p>
<p>Security of Your Information</p>
<p>Data Retention</p>
<p>International Transfers of Data</p>
<p>User Rights and Choices</p>
<p>Contact Details</p>
<p>Changes to this Policy</p>
<p>Additional Information for Users in Certain Jurisdictions</p>
<p><strong>1.</strong>  <strong>Scope of Our Policy</strong></p>
<p>This Policy applies to the personal information that ZeniMax collects and processes about Users related to our Services, including games published by Bethesda Softworks and ZeniMax Online Studios, and games developed by other ZeniMax studios; more information about our studios is available at www.zenimax.com/studios.  This Policy does not apply to any third party websites, services, products or mobile applications maintained by other companies, which are linked to from our Services.</p>
<p>By registering for an account with us, providing your information to us through the Services, or otherwise using any of our Services, you understand and acknowledge that ZeniMax may process your personal information in accordance with this Policy. If you do not want this Policy to apply to you, please do not use the Services or communicate with us via the Services. If required by applicable law, we will obtain your consent to our collection, use, transfer and disclosure of your personal information.</p>
<p><strong>Personal Information.</strong>  In this Policy, our use of the term "personal information" includes other similar terms under applicable privacy lawsâ€”such as "personal data" and "personally identifiable information."  In general, personal information includes any information that identifies, relates to, describes, or is reasonably capable of being associated, or reasonably linked or linkable with a particular individual.</p>
<p><strong>Not Covered by this Policy.</strong>  This Policy does not apply to job applicants and candidates who apply for employment with us, or to employees and non-employee workers in the context of our working relationship with them.</p>
<p><strong>2.</strong>  <strong>Personal Information We Collect</strong></p>
<p>The information we collect about Users varies depending upon the circumstances and the Services used.</p>
<p>ZeniMax collects personal information directly from Users, automatically related to the use of the Services, and in some cases, from third parties (such as social networks, platform providers, payment processors, and operators of certain third party services that we use).</p>
<p><strong>Information We Collect From You</strong>.  Generally, we collect your personal information on a voluntary basis. However, if you decline to provide certain personal information that is marked mandatory, you may not be able to access certain Services or we may be unable to fully respond to your inquiry. We collect the following personal information from you:</p>
<ul>
<li>
<p>Registration and Profile Information.  To access and use certain Services (e.g., to register a game, download or use a mobile application, access subscription-based Services, create an account) you may be required to register with us, by providing us with certain required information, which is identified on the registration page. Depending upon the Services you use, this may include your name, a username and password, as well as country of residence, email, and contact information; certain Services will not be available if you decline to provide required information. We may also ask you or allow you to submit certain optional information, which may include your phone number, birthdate, location, preferences, a photo or avatar, and other profile information.</p>
</li>
<li>
<p>Purchases and Payments Information.  If you make a purchase or sign up for certain subscription-based Services, you are required to provide your payment information, including name, billing and shipping address and details, payment type, as well as credit card number or other payment account details (e.g., PayPal). We work with third parties like payment processors and fulfillment partners to process these payments. We do not collect, receive, process or store credit card or debit card numbers, or other third-party payment account credentials (e.g., PayPal); this information is collected directly by these third parties. Depending upon the Service, we may receive your username, name, email, the payment type, product(s) or service(s), and other transaction details, and maintain records of your purchase and subscription history.</p>
</li>
<li>
<p>Marketing, Contests and Promotions.  Users can sign up online or in-person (e.g., at tradeshows, conferences and the like) to receive direct marketing communications from us, including emails about game launches, developments, and upcoming releases. If you agree to receive direct marketing communications from us, we collect your email address, and we may also collect your name, preferences, and if relevant, information about your account and the Services and other games you use. We may also run contests, sweepstakes or other events or activities (collectively, "events") on our websites and social media channels. Information collected for these events may include your name, age, email address, and other information.</p>
</li>
<li>
<p>Your Communications.  When you email us, call us, or otherwise send us communications regarding the Services, we collect and maintain a record of your contact details, communications and our responses. We may also maintain records of the in-game communications and information that you post in chat sessions, forums, and in other areas of the Services.</p>
</li>
</ul>
<p><strong>Information We Collect and Receive From Third Parties</strong>.  We may collect and receive personal information about you from third parties, such as:</p>
<ul>
<li>
<p>Third Party Platforms.  You may be able to login through or connect certain third party accounts (each a " <strong>Third Party Account</strong>")â€”such as Steam, Twitch, Xbox Live, PSN and Facebookâ€”to your account with us.  These Third Party Accounts are operated and managed by third …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wrap.bnet.idtech.services/legal/?limited=true&amp;fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html">https://wrap.bnet.idtech.services/legal/?limited=true&amp;fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html</a></em></p>]]>
            </description>
            <link>https://wrap.bnet.idtech.services/legal/?limited=true&amp;fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836876</guid>
            <pubDate>Tue, 14 Jul 2020 19:49:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ludum Dare in 48 hours with Rust and WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836386">thread link</a>) | @yannikyeo
<br/>
July 14, 2020 | https://ianjk.com/rust-gamejam/ | <a href="https://web.archive.org/web/*/https://ianjk.com/rust-gamejam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p><a href="https://ldjam.com/">Ludum Dare</a>, the world's premiere 48 hour solo gamejam, occurred back in April.</p>
<p>Ludum Dare has two tracks: the 'Compo' and the 'Jam'.</p>
<p>The rules of the Compo require you to make a game (other than source code) within 48 hours. At the end your fellow entrants will rate your game and your game will be ranked against your peers.</p>
<p>With everyone quarantined at home due to Coronavirus this April's Ludum Dare had vastly more entrants than usual. A total of 1383 people entered the Compo and there were 3576 entries to the Jam. That's an absurd amount of games!</p>
<p>I've entered the Compo a <a href="https://ldjam.com/events/ludum-dare/43/blueberry-bounce">few</a> <a href="https://ldjam.com/events/ludum-dare/42/noahs-help-1">times</a> using Unity, but this time around I wanted to write a game purely with the relatively new programming language Rust.</p>
<p>This post started out focused on the experience of using Rust, but turned into a general overview of the technical and design process for the game.</p>
<span id="continue-reading"></span>
<p><a href="https://www.rust-lang.org/">Rust</a> is a 'systems programming language' focused on performance and safety. 'Safety' means that Rust helps you avoid certain classes of vulnerabilities and crashes. I have been using Rust for my personal work and decided now was the time to give it a shot for a gamejam.</p>
<h2 id="why-not-unity">Why not Unity?</h2>
<p>I've entered at least five past Ludum Dares with Unity, and Unity with C# is by far the most common set of tools used for Ludum Dare. But I just simply haven't been enjoying Unity as much recently.</p>
<p>Unity is a giant game engine, but I find it hard to get into a flow state with. There are too many knobs, features, and ways to do things. It's easy to flip a bunch of switches and have something decent, but that just doesn't mesh with my personal design flow. I prefer to work in a clean mental environment, not a complex editor.</p>
<p>Additionally Unity's WebGL build takes around 20 minutes on my laptop, which is absolutely miserable.</p>

<p>I've been coding exclusively on a 2016 Macbook Pro for a while now. It's not the best, but not the worst.</p>
<p>I could have used an existing Rust game engine, but I'm not familiar with the popular ones. Instead I cobbled together a mix of Rust libraries and various personal Rust scripts.</p>
<p>Rust makes it trivially easy to use other libraries (which it calls crates) through its package manager <a href="https://crates.io/">crates.io</a>.</p>
<p>For this project I used the following crates:</p>
<ul>
<li><a href="https://github.com/kettle11/kApp">kApp</a> My personal windowing and input library designed to build super fast.</li>
<li><a href="https://github.com/rustwasm/wasm-bindgen">wasm-bindgen</a> The Rust ecosystem's standard way to call Javascript from Rust</li>
<li><a href="https://github.com/grovesNL/glow">glow</a> "GL on whatever" A wrapper around OpenGL and WebGL.</li>
</ul>
<p>The recommended way to work with Rust and WebAssembly (Wasm) is through a command line tool called <a href="https://github.com/rustwasm/wasm-pack"><code>wasm-pack</code></a>. I skipped using <code>wasm-pack</code> and instead just used a two line bash script that would run a Rust build and then call <code>wasm-bindgen</code> directly to generate the web bindings.</p>
<p>Quick iteration times are absolutely critical for a gamejam. The following tools were instrumental in attaining quick iteration times:</p>
<ul>
<li><a href="https://github.com/passcod/cargo-watch"><code>cargo watch</code></a> ran the build script automatically whenever the code was saved.</li>
<li><a href="https://crates.io/crates/devserver/0.1.0"><code>devserver</code></a> hosted the local web page and automatically reloaded it when a file changed</li>
<li>Visual Studio Code was configured to automatically save</li>
</ul>
<p>The combination of <code>cargo watch</code>, <code>devserver</code>, and the Visual Studio Code settings meant that I could edit a value, like a color, in my Rust code and watch it change on the web page nearly instantly.</p>
<p>Typical Rust build times were around 1-3 seconds while working on this project, but sometimes they'd inexplicably go up to around 10 seconds. Rust is known for slow build times, and these quick iteration times were only possible by carefully choosing tiny crates. My goal was to always have the new build ready on the web page by the time I changed to the browser window.</p>
<h2 id="code-structure">Code Structure</h2>
<p>With only 48 hours best practices go out the window, but even still I made some early choices to help make writing new code as easy as possible. One of the key things I wanted to ensure was that if I were to declare a new variable, or load a new asset, that it would only have to be declared once. Many Rust frameworks follow a pattern a bit like the following:</p>
<pre><code><span>struct </span><span>Game </span><span>{
    </span><span>player</span><span>:</span><span> Player,
    </span><span>/* Other stuff */
</span><span>}

</span><span>impl </span><span>Game </span><span>{
    </span><span>fn </span><span>setup</span><span>(</span><span>context</span><span>: &amp;</span><span>Context</span><span>) -&gt;</span><span> Game </span><span>{</span><span>
        Game </span><span>{</span><span>
            player</span><span>: </span><span>Player</span><span>::</span><span>new</span><span>(),
        }
    }

    </span><span>fn </span><span>update</span><span>(</span><span>context</span><span>: &amp;</span><span>Context</span><span>) {
        </span><span>/* Respond to user input and redraw here*/
    </span><span>}
}
</span></code></pre>
<p>The above works fine in regular scenarios, but when you add a new variable like 'player' it needs to be declared in multiple places. Instead I used a structure a bit like the following:</p>
<pre><code><span>fn </span><span>main</span><span>() {
    </span><span>let</span><span> player </span><span>= </span><span>Player</span><span>::</span><span>new</span><span>();
    </span><span>/* Other setup code here */

    </span><span>loop </span><span>{
        </span><span>/* Respond to user input and redraw here forever*/
    </span><span>}
}
</span></code></pre>
<p>This let me declare a variable and use it immediately, no extra fuss.</p>
<h2 id="async">Async</h2>
<p>Unfortunately the above structure doesn't work on web. On Web the main loop must return control to the browser.</p>
<p>The way to get around this is to pass a closure that the browser calls when an event occurs:</p>
<pre><code><span>fn </span><span>main</span><span>() {
    </span><span>let</span><span> player </span><span>= </span><span>Player</span><span>::</span><span>new</span><span>();
    </span><span>/* Other setup code here */

    </span><span>run</span><span>(</span><span>move </span><span>|</span><span>context</span><span>| {
        </span><span>/* Respond to events and draw here */
    </span><span>});
}
</span></code></pre>
<p>Rust windowing and input frameworks like <a href="https://github.com/rust-windowing/winit">Winit</a> use the above approach.</p>
<p>Another issue on web is loading assets. On non-web platforms it's simple to just wait for an asset to be done loading:</p>
<pre><code><span>let</span><span> wind_sound_handle </span><span>= </span><span>std</span><span>::</span><span>fs</span><span>::</span><span>read</span><span>("</span><span>wind.wav</span><span>").</span><span>unwrap</span><span>();
</span></code></pre>
<p>On web the above isn't possible because it would prevent returning control to the browser. It's not appropriate to lock up while waiting for an an asset to return from a server, so all loads are asynchronous.</p>
<p>An approach like the following could be used in Rust:</p>
<pre><code><span>let</span><span> wind_sound_handle </span><span>= </span><span>fetch_asset</span><span>("</span><span>wind.wav</span><span>");

</span><span>run</span><span>(</span><span>move </span><span>|</span><span>context</span><span>| {
    </span><span>let</span><span> wind_sound </span><span>= </span><span>None</span><span>;
    </span><span>/* Respond to events and draw requests here */
    </span><span>if let </span><span>Some</span><span>(</span><span>loaded_asset</span><span>) =</span><span> wind_sound_handle</span><span>.</span><span>get_asset</span><span>() {</span><span>
        window_sound </span><span>=</span><span> loaded_asset</span><span>;
    }

    </span><span>/* Respond to events and draw here */
</span><span>});
</span></code></pre>
<p>But that approach can lead to tedious bookkeeping, which is the opposite of what you want for a gamejam.</p>
<p>Instead I decided to use Rust's relatively new feature: <code>async</code>. Fortunately I had recently added <code>asyc</code> support to <code>kApp</code>.</p>
<p>Rust's <code>async</code> feature generates a state machine for a function that allows it to pause and later resume when ready.</p>
<p>An <code>async</code> function can look very similar to a traditional infinite game loop:</p>
<pre><code><span>async </span><span>fn </span><span>run</span><span>(</span><span>app</span><span>:</span><span> Application, </span><span>events</span><span>:</span><span> Events</span><span>) {
    </span><span>let</span><span> wind_sound </span><span>= </span><span>audio</span><span>::</span><span>load_audio</span><span>("</span><span>wind.wav</span><span>").</span><span>await</span><span>.</span><span>unwrap</span><span>();
    </span><span>loop </span><span>{
        </span><span>match</span><span> events</span><span>.</span><span>next_event</span><span>().</span><span>await </span><span>{
            </span><span>/* Respond to events and draw here */
        </span><span>}
    }
}
</span></code></pre>
<p>This let me load assets with one line and not have to worry about any bookkeeping. Perfect!</p>
<h2 id="game-design">Game Design</h2>
<p>The theme for this Ludum Dare was "Keep It Alive" which immediately struck me as overly morbid given the rapid spread of coronavirus. I couldn't motivate myself to create a game about death, and I nearly decided to quit the jam entirely.</p>
<p>Instead I looked for alternative ways to interpret the theme. As I stared out my apartment window towards San Francisco hills I thought about the way people droop their heads as they walk to and from work. It's a beautiful world, but it's tough to notice the beauty every day when the routine of life weighs heavy.</p>
<p>What if you played as a spirit to lift people up? You could keep their "wonder" alive. You'd play as some sort of spirit and perhaps you'd lift a commuter bicyclist up into the sky where you'd whisk them around and show them the stars.</p>
<p>I imagined you'd guide the bicyclist through the sky to collect stars and people on the ground would notice and point up in awe.</p>
<p>It was difficult to figure out how to pair that idea to gameplay, but what I settled upon was a game inspired by the old school flash game <a href="https://www.linerider.com/">Line Rider</a>.</p>
<p>You'd draw lines for the bicyclist and they'd roll along those lines and bump into collectible stars.</p>
<h2 id="implementation">Implementation</h2>
<p>The plan was to implement the physics of the character as a rolling ball and then substitute in character art for the bicyclist.</p>
<p>The first thing I needed was line rendering. I ripped some code out of a prior Rust project that would generate mesh line segments by creating rectangles with circles at the ends. I wasn't sure if this heavy-handed approach to line joins would cause problems. Each individual line segment was made up of a bunch of triangles so I felt that perhaps the game would lag as too many lines appeared.</p>
<p>I stress tested this by scribbling the entire screen full of lines over and over, and I was shocked when the framerate didn't drop at all.</p>
<p>For the physics I took some math for finding the closest point on a line to the ball. If the point is inside the ball then check if the ball's velocity is moving towards the point. If the ball is moving towards the point then "bounce" the ball by pushing the opposite direction on the ball.</p>
<p>The heart of the collision code wasn't very long at all:</p>
<pre><code><span> </span><span>fn </span><span>check_lines</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>points</span><span>: &amp;</span><span>[Vector3]</span><span>) {
    </span><span>let</span><span> len </span><span>=</span><span> points</span><span>.</span><span>len</span><span>();

    </span><span>for</span><span> i </span><span>in (</span><span>1</span><span>..</span><span>len</span><span>).</span><span>step_by</span><span>(</span><span>2</span><span>) {
        </span><span>let </span><span>(</span><span>distance</span><span>,</span><span> p</span><span>) = </span><span>point_with_line_segment</span><span>(</span><span>self</span><span>.</span><span>position</span><span>,</span><span> points</span><span>[</span><span>i </span><span>- </span><span>1</span><span>],</span><span> points</span><span>[</span><span>i</span><span>]);

        </span><span>if</span><span> distance
            </span><span>&lt; (</span><span>self</span><span>.</span><span>radius </span><span>+ </span><span>LINE_RADIUS </span><span>- </span><span>0.001</span><span>/* Allow ball to sink slightly into surface*/</span><span>)
        {
            </span><span>let</span><span> normal_of_collision </span><span>= (</span><span>self</span><span>.</span><span>position </span><span>-</span><span> p</span><span>).</span><span>normal</span><span>();
            </span><span>let</span><span> velocity_along_collision </span><span>= </span><span>Vector3</span><span>::</span><span>dot</span><span>(</span><span>normal_of_collision</span><span>, </span><span>self</span><span>.</span><span>velocity</span><span>);
            </span><span>if</span><span> velocity_along_collision </span><span>&lt; </span><span>0.0 </span><span>{
                </span><span>self</span><span>.</span><span>velocity </span><span>-=</span><span> normal_of_collision </span><span>*</span><span> velocity_along_collision </span><span>* </span><span>1.4</span><span>;
            }
            </span><span>self</span><span>.</span><span>position </span><span>+=</span><span> normal_of_collision </span><span>* </span><span>0.0001</span><span>;
        }
    }
}
</span></code></pre>
<p>(The code could have been a little cleaner had I known about the <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.chunks">chunks</a> method on iterators.)</p>
<p>I was pretty surprised at how great the ball physics felt without much tuning. When I started with this design the physics felt like a big unknown for me. I felt like I might not be able to get them right within the 48 hour window, but coding the physics was actually one of the shortest features in the project.</p>
<p>I was pretty concerned that the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ianjk.com/rust-gamejam/">https://ianjk.com/rust-gamejam/</a></em></p>]]>
            </description>
            <link>https://ianjk.com/rust-gamejam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836386</guid>
            <pubDate>Tue, 14 Jul 2020 19:14:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reclaiming Technology (From Capital)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836329">thread link</a>) | @twazzle
<br/>
July 14, 2020 | https://t.wang.sh/reclaiming-technology | <a href="https://web.archive.org/web/*/https://t.wang.sh/reclaiming-technology">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>July 14, 2020</span><span>&nbsp; ▴ &nbsp;</span><span>9 minute read 🥤🥤</span><span>🥤🥤</span></p><p>––– views</p></div><p><a href="https://unsplash.com/photos/EOnlL3L3IgQ" target="_blank" rel="nofollow"><span>
      <span></span>
  <img alt="Photo by Aaron Lau on Unsplash" title="Photo by Aaron Lau on Unsplash" src="https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/29d31/sf.jpg" srcset="https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/e52aa/sf.jpg 175w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/70ebb/sf.jpg 350w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/29d31/sf.jpg 700w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/9ecec/sf.jpg 1050w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/d165a/sf.jpg 1400w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/b17f8/sf.jpg 1600w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span></a></p><blockquote>If you get shown a problem, but have no idea how to control it, you just decide to get used to it.</blockquote><p>When I first got into coding in 2016, I looked at the tech industry with glassy eyes. I was coming off winning a university business pitch competition and felt like I had discovered this hidden treasure trove of amazing people, ideas, and opportunity. Coding, to me, felt like the key that unlocked the doors to this treasure. I was sure that if I just mastered this skill, I’d be welcomed with open arms into this abundant, innovative community.</p><p>On the outside, the modern tech industry epitomizes the American dream. Startups dominate the scene, with funding seemingly available for any wild idea out there. I believed that tech was truly democratizing and that with enough hard work, anyone could find success.</p><p><strong>It’s now 2020, and I no longer hold these views.</strong></p><p>The pivotal points that informed my worldview came from a failed app startup and subsequent grueling job searches. I got lucky a couple of times along the way: receiving an initial angel investment for my app, and also working full-time at <a href="https://designcode.io/" target="_blank" rel="nofollow">Design+Code</a>. On the other hand, I went through hundreds of arduous processes and rejections from startup accelerators, investors, and companies, and saw the struggles of my peers who had less luck and privilege than me. These experiences culminated in me waking up to the true nature of the tech industry. Despite being confident in my newfound coding ability, I had not been handed a key to any sort of treasure. Instead, I was offered a pick and shovel and told to mine gold – to make the treasure pile bigger for those who already have it. Ironically, many of the institutions I talked to refused to give me their pick and shovel, claiming they needed better and more experienced miners.</p><p>The foundation on which the modern tech industry is built upon – <a href="https://nyti.ms/2uXTBPA" target="_blank" rel="nofollow">American capitalism</a> – is fundamentally flawed, and now commonly referred to as late-stage capitalism. This is because we have reached a stage where a tiny percentage of people have accumulated so much capital that they not only exclusively dictate which ideas are worth building, but also dictate who is worthy of building those ideas. When people say that the American Dream is dead, this is what they mean.</p><p>Our society’s continual worship of capital, and of those who hold it, has created extreme inequality that threatens the ideals of a free, democratic society. We are bound to the whim of capital, and to the individuals and groups who have accumulated it.</p><p><strong>It’s time we did something about this – but what can we do?</strong></p><h2 id="chapter-11-a-new-industrial-model-from-abolish-silicon-valley"><a href="#chapter-11-a-new-industrial-model-from-abolish-silicon-valley" aria-label="chapter 11 a new industrial model from abolish silicon valley permalink"></a>Chapter 11: A New Industrial Model, from Abolish Silicon Valley</h2><p>The subtitle of <a href="https://dellsystem.me/" target="_blank" rel="nofollow">Wendy Liu</a>’s new book, <a href="https://abolishsiliconvalley.com/" target="_blank" rel="nofollow">Abolish Silicon Valley</a>, is <em>How to Liberate Technology from Capitalism</em>. Chapter 11, <em>A New Industrial Model</em>, specifically proposes five steps to <em>reclaim our world from capital</em>.</p><p><a href="https://abolishsiliconvalley.com/" target="_blank" rel="nofollow"><span>
      <span></span>
  <img alt="Abolish Silicon Valley: How to Liberate Technology from Capitalism" title="Abolish Silicon Valley: How to Liberate Technology from Capitalism" src="https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/8c557/book.png" srcset="https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/4edbd/book.png 175w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/13ae7/book.png 350w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/8c557/book.png 700w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/e996b/book.png 1050w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/2cefc/book.png 1400w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/0734a/book.png 4266w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span></a></p><p>In <a href="https://abolishsiliconvalley.com/" target="_blank" rel="nofollow">Abolish Silicon Valley</a>, Wendy details her first-hand experience working at Google as a software engineering intern, and then as a founder of a tech startup. She presents an intimate look into the inner workings of the tech industry and the stark issues that plague it. I encourage anyone interested in a deeply personal, inside look into the tech industry to pick up Wendy’s book. In this post, I will aim to explore the proposals in Chapter 11, A New Industrial Model, and spark a conversation around how we can begin to address the problems created by capital.</p><blockquote>...we don't owe capital anything. The things we attribute to capital were built by workers: people who labored and sometimes died in the process, their contributions unrecognized in death as in life. So don't thank capital – it doesn't deserve our gratitude, and it doesn't need it, anyway. Thank the people who created everything that capital always takes credit for.</blockquote><h2 id="reclaiming-entrepreneurship"><a href="#reclaiming-entrepreneurship" aria-label="reclaiming entrepreneurship permalink"></a>Reclaiming Entrepreneurship</h2><p><a href="https://unsplash.com/photos/jw3GOzxiSkw" target="_blank" rel="nofollow"><span>
      <span></span>
  <img alt="Photo by Rohan Makhecha on Unsplash" title="Photo by Rohan Makhecha on Unsplash" src="https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/8c557/entrepreneurship.png" srcset="https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/4edbd/entrepreneurship.png 175w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/13ae7/entrepreneurship.png 350w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/8c557/entrepreneurship.png 700w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/e996b/entrepreneurship.png 1050w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/2cefc/entrepreneurship.png 1400w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/29007/entrepreneurship.png 1600w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span></a></p><p>Reclaiming entrepreneurship is the first proposal. The central argument is to have entrepreneurship be accountable to <em>the public</em>, versus <em>private shareholders</em>. Today, this is more commonly referred to as “social entrepreneurship,” where the primary goal is to address social, cultural, or environmental issues rather than turning a profit and returning capital to private investors. To this end, a nonprofit structure works best, as nonprofits have no owners and are accountable to the public and the state. <a href="#references" title="reference">¹</a></p><p>The argument for private ownership usually goes something like this – that without the prospect of reaping the capital benefits of said ownership, people wouldn’t be incentivized to innovate and we would lose all the nice things we have. This argument may hold some truth in a developing world, but today, the incredible wealth concentration created by our current system actually stifles innovation. Real wages have stayed stagnant, fewer companies are being started, and only companies whose products promise to deliver outlandish returns of capital are considered viable. <a href="#references" title="reference">²</a> To make matters worse, Black women, America’s most entrepreneurial demographic, only receive 0.0006% of venture capital funding. <a href="#references" title="reference">³</a></p><p>The standard model for entrepreneurship today is to have an idea, receive investment for that idea, then build it, scale it, and finally return the investment by getting acquired or going public. This model is set up to make the founders, executives, and investors fabulously wealthy. There is no nuance nor any regard for side effects; as long as there is a large return on investment, the venture is considered a success. Thus, the spirit of entrepreneurship and innovation has been clouded by capital. Only by removing this perverse incentive structure and reimagining this standard model, can we expect to have innovation return to America.</p><h2 id="reclaiming-work"><a href="#reclaiming-work" aria-label="reclaiming work permalink"></a>Reclaiming Work</h2><div>
  <p>
    <span>
      <a href="https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/6e52c/balance.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tech workers vs. everybody else" title="Tech workers vs. everybody else" src="https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/8c557/balance.png" srcset="https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/4edbd/balance.png 175w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/13ae7/balance.png 350w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/8c557/balance.png 700w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/e996b/balance.png 1050w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/2cefc/balance.png 1400w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/6e52c/balance.png 1948w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  </p>
  <p>
    <span>
      <a href="https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/6e52c/balance-dark.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tech workers vs. everybody else" title="Tech workers vs. everybody else" src="https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/8c557/balance-dark.png" srcset="https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/4edbd/balance-dark.png 175w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/13ae7/balance-dark.png 350w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/8c557/balance-dark.png 700w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/e996b/balance-dark.png 1050w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/2cefc/balance-dark.png 1400w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/6e52c/balance-dark.png 1948w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  </p></div><p>One thing I find incredibly frustrating is when extremely well-paid, full-time tech workers in Silicon Valley or other tech hubs complain about their salaries. To me, it’s the equivalent of sitting in a fancy restaurant, whining that you didn’t get the same amount of desert as the table sitting next to you, all while people eat garbage in the streets.</p><p>At Google, there exists a large contractor workforce referred to as their “shadow workforce,” a group that outnumbers full-time employees. Most tech companies have contingent labor that makes up for 40-50% of their workforce. <a href="#references" title="reference">⁴</a> This division of the American workforce in the tech industry has created a culture of entitlement at the top and resentment at the bottom. Capitalism requires the wealthy class to own the means of production, so keeping full-time employees (who work on the product) happy is important. However, companies are constantly trying to optimize production, so when a contract workforce can replace production without sacrificing control, companies will outsource this work. As long as we are in a capital-directed system, we can expect the growing trend of contract workers to continue.</p><p>For companies that have increasing contractor workforces, contractors must have a clear path to convert to full-time employees. Contractors who choose not to convert must be paid a higher wage than full-time employees since they aren’t provided benefits. Gig economy workers, like Uber and Lyft drivers, should be given control and flexibility over the jobs they take, the ability to negotiate pay, and a way for workers to collectively bargain and resolve issues with their company. An interesting alternative model for gig workers could be <a href="https://platform.coop/" target="_blank" rel="nofollow">platform co-ops</a>, in which a digital platforms like Uber and Lyft would be owned by the people who depend on and participate in it (the drivers).</p><p>The other proposed solutions in reclaiming work have to do with shifting the power to the working class, reducing income inequality, and improving technological development. These proposals include:</p><ul><li>Giving corporate board seats to democratically elected workers</li><li>Implementing a maximum wage whereby you base the highest-paid wage (typically the CEO) to the lowest-paid wage</li><li>Ensure more equal distribution of stock, or removing stock grants for employees entirely</li><li>Public salary transparency with posted salary bands</li><li>Nationalization of companies with excess profits obtained through rent-seeking, or a combination of lowering prices, increasing R&amp;D spending, increasing wages, and raising taxes</li><li>A strict wealth tax on individuals with a high amount of savings drawing passive income from investments</li><li>Worker control over new technology introduced in the workplace to fit the needs of workers over management</li><li>Software/technical licensing for individuals that comes with a tech version of the Hippocratic oath, with free training and a stipend for higher levels</li><li>A “hiring hall” model that works by a project-by-project basis, instead of being employed at a specific company</li></ul><p>A shocking metaphor for the modern workplace is this idea that workers exist in a system of feudalism, under a complex hierarchy and power structure that intends on making bosses feel like kings and queens. <a href="#references" title="reference">⁵</a> The further we go into late-stage capitalism, the ugliest sides of human history repeat itself. To avoid a further downward spiraling of our most basic freedoms and rights, it is paramount that we take steps to reclaim work for all workers.</p><h2 id="reclaiming-public-services"><a href="#reclaiming-public-services" aria-label="reclaiming public services permalink"></a>Reclaiming Public Services</h2><p>The above tweet by digital researcher and librarian <a href="https://twitter.com/erinroseglass" target="_blank" rel="nofollow">Erin Rose Glass</a> captures succinctly the need for certain industries to be public services rather than owned by private corporations. With software innovation dominating the past decade, we have seen an emergence of surveillance capitalism, where our private data is used to drive engagement and profit. The Internet, which was created based on the principles of free information, decentralized ownership, and open protocols and infrastructure, has been hijacked by private enterprise. <a href="#references" title="reference">⁶</a> We have seen our data analyzed by computational products which aim to predict our behavior, these predictions traded on a new …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://t.wang.sh/reclaiming-technology">https://t.wang.sh/reclaiming-technology</a></em></p>]]>
            </description>
            <link>https://t.wang.sh/reclaiming-technology</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836329</guid>
            <pubDate>Tue, 14 Jul 2020 19:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bridging PyTorch and TVM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836147">thread link</a>) | @homarp
<br/>
July 14, 2020 | https://lernapparat.de/transformers-pytorch-tvm/ | <a href="https://web.archive.org/web/*/https://lernapparat.de/transformers-pytorch-tvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div id="submain">
  <article>

  
  
  <p>July 14, 2020</p>
  
  <section>
   <p>Some of the most intriguing applications of Artificial Intelligence have been in Natural Language Processing.
Models like BERT or GPT-2 and their variants can seemingly grasp enough of a text to continue it in a way that needs a second look to recognize as gibberish.</p>
<p>These models belong to a class of neural network architectures called <em>Transformers</em>. One of the favourite libraries implementing them is the <a href="https://github.com/huggingface/transformers/">HuggingFace transformers library</a>.</p>
<p>But, in contrast to convolutional models or LSTMs where we have heavily optimized implementations, this is not as much the case for transformers.
So here we explore how TVM can fill the gap. We will do so in two steps:<span><label for="fn:tvm_blog:"></label><span><span>A shortened version with only the highlights from the TVM perspective is <a href="https://tvm.apache.org/2020/07/14/bert-pytorch-tvm">on the TVM blog</a>.</span></span></span></p>
<ul>
<li>First we look at BERT inference and tuning that on TVM.</li>
<li>Secondly, we start some more fundamental exploration of how one could use TVM for training in PyTorch.
  Given the experimental nature, we focus on feasibility more than on the performance in this part.</li>
</ul>
<h2>BERT inference on TVM</h2>
<p>How do we get BERT into TVM?<span><label for="fn:code:"></label><span><span>The code is available as Jupyter Notebooks on <a href="https://github.com/t-vi/pytorch-tvmisc/tree/master/transformers-pytorch-tvm/">github</a>.</span></span></span></p>
<p>Helpfully, transformers supports tracing their model with the PyTorch JIT. We use their <a href="https://huggingface.co/transformers/torchscript.html">tutorial on it</a>, the following is copied straight from the tutorial.</p>
<div><pre><span></span><span>import</span> <span>transformers</span>

<span>from</span> <span>transformers</span> <span>import</span> <span>BertModel</span><span>,</span> <span>BertTokenizer</span><span>,</span> <span>BertConfig</span>
<span>import</span> <span>numpy</span>

<span>import</span> <span>torch</span>

<span>enc</span> <span>=</span> <span>BertTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>"bert-base-uncased"</span><span>)</span>

<span># Tokenizing input text</span>
<span>text</span> <span>=</span> <span>"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]"</span>
<span>tokenized_text</span> <span>=</span> <span>enc</span><span>.</span><span>tokenize</span><span>(</span><span>text</span><span>)</span>

<span># Masking one of the input tokens</span>
<span>masked_index</span> <span>=</span> <span>8</span>
<span>tokenized_text</span><span>[</span><span>masked_index</span><span>]</span> <span>=</span> <span>'[MASK]'</span>
<span>indexed_tokens</span> <span>=</span> <span>enc</span><span>.</span><span>convert_tokens_to_ids</span><span>(</span><span>tokenized_text</span><span>)</span>
<span>segments_ids</span> <span>=</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]</span>

<span># Creating a dummy input</span>
<span>tokens_tensor</span> <span>=</span> <span>torch</span><span>.</span><span>tensor</span><span>([</span><span>indexed_tokens</span><span>])</span>
<span>segments_tensors</span> <span>=</span> <span>torch</span><span>.</span><span>tensor</span><span>([</span><span>segments_ids</span><span>])</span>
<span>dummy_input</span> <span>=</span> <span>[</span><span>tokens_tensor</span><span>,</span> <span>segments_tensors</span><span>]</span>

<span># If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag</span>
<span>model</span> <span>=</span> <span>BertModel</span><span>.</span><span>from_pretrained</span><span>(</span><span>"bert-base-uncased"</span><span>,</span> <span>torchscript</span><span>=</span><span>True</span><span>)</span>

<span>model</span><span>.</span><span>eval</span><span>()</span>
<span>for</span> <span>p</span> <span>in</span> <span>model</span><span>.</span><span>parameters</span><span>():</span>
    <span>p</span><span>.</span><span>requires_grad_</span><span>(</span><span>False</span><span>)</span>

<span>transformers</span><span>.</span><span>__version__</span>
</pre></div>





<p>Now we can trace our model. As we want to do inference, we impose evaluation mode and not requiring gradients for the parameters.</p>
<div><pre><span></span><span># Creating the trace</span>
<span>traced_model</span> <span>=</span> <span>torch</span><span>.</span><span>jit</span><span>.</span><span>trace</span><span>(</span><span>model</span><span>,</span> <span>[</span><span>tokens_tensor</span><span>,</span> <span>segments_tensors</span><span>])</span>
<span>traced_model</span><span>.</span><span>eval</span><span>()</span>
<span>for</span> <span>p</span> <span>in</span> <span>traced_model</span><span>.</span><span>parameters</span><span>():</span>
    <span>p</span><span>.</span><span>requires_grad_</span><span>(</span><span>False</span><span>)</span>
</pre></div>


<p>Let us run try our traced model on the GPU:</p>
<div><pre><span></span><span>model</span><span>.</span><span>cuda</span><span>()</span>
<span>tt_c</span> <span>=</span> <span>tokens_tensor</span><span>.</span><span>cuda</span><span>()</span>
<span>st_c</span> <span>=</span> <span>segments_tensors</span><span>.</span><span>cuda</span><span>()</span>
<span>res_pt</span> <span>=</span> <span>model</span><span>(</span><span>tt_c</span><span>,</span> <span>st_c</span><span>)</span>
<span>torch</span><span>.</span><span>cuda</span><span>.</span><span>synchronize</span><span>()</span>
</pre></div>


<p>It worked, but is it fast? Let's run it 100 times and see.
When timing CUDA models, it's always good to do some "warm-up", running the model before the measurement, and we need to be sure to synchronize before the start and end of the timing.</p>
<div><pre><span></span><span>def</span> <span>y</span><span>():</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>100</span><span>):</span>
        <span>model</span><span>(</span><span>tt_c</span><span>,</span> <span>st_c</span><span>)</span>
    <span>torch</span><span>.</span><span>cuda</span><span>.</span><span>synchronize</span><span>()</span>

<span>y</span><span>()</span>
<span>%</span><span>timeit</span>  <span>y</span><span>()</span>
</pre></div>


<div><pre><span></span>773 ms ± 2.33 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</pre></div>


<p>Around 0.65-0.7 seconds for 100 runs means 6.5-7ms per run. That's not too bad.</p>
<p>But let us see if TVM can help us to get faster. Let us convert our model to TVM.</p>
<div><pre><span></span><span>shape_list</span> <span>=</span> <span>[(</span><span>i</span><span>.</span><span>debugName</span><span>()</span><span>.</span><span>split</span><span>(</span><span>'.'</span><span>)[</span><span>0</span><span>],</span> <span>i</span><span>.</span><span>type</span><span>()</span><span>.</span><span>sizes</span><span>())</span> <span>for</span> <span>i</span> <span>in</span>  <span>list</span><span>(</span><span>traced_model</span><span>.</span><span>graph</span><span>.</span><span>inputs</span><span>())[</span><span>1</span><span>:]]</span>
<span>shape_list</span>
</pre></div>


<div><pre><span></span>[('input_ids', [1, 14]), ('attention_mask', [1, 14])]
</pre></div>


<div><pre><span></span><span>mod_bert</span><span>,</span> <span>params_bert</span> <span>=</span> <span>tvm</span><span>.</span><span>relay</span><span>.</span><span>frontend</span><span>.</span><span>pytorch</span><span>.</span><span>from_pytorch</span><span>(</span><span>traced_model</span><span>,</span>
                        <span>shape_list</span><span>,</span> <span>default_dtype</span><span>=</span><span>"float32"</span><span>)</span>
</pre></div>


<div><pre><span></span>ANTLR runtime and generated code versions disagree: 4.8!=4.7.2
ANTLR runtime and generated code versions disagree: 4.8!=4.7.2


WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume it is float32
WARNING:root:Untyped Tensor found, assume …</pre></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lernapparat.de/transformers-pytorch-tvm/">https://lernapparat.de/transformers-pytorch-tvm/</a></em></p>]]>
            </description>
            <link>https://lernapparat.de/transformers-pytorch-tvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836147</guid>
            <pubDate>Tue, 14 Jul 2020 18:57:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Reviews Deserve a Review]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836030">thread link</a>) | @chesterarthur
<br/>
July 14, 2020 | https://staysaasy.com/management/2020/04/22/Writing-Performance-Reviews-101.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/04/22/Writing-Performance-Reviews-101.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Performance reviews are some of the most high stakes moments in management. Done well, they communicate a ton to your report: feedback on how to improve, feedback on how to leverage strengths, and firm acknowledgement that you understand the value that they add.  Done poorly, they can spiral into a tailspin of disappointment, sadness, lack of appreciation, lack of understanding, and inert or missing plans for growth. Read on for tips on how to make your performance reviews fall on the happy side of the dividing line.</p>

<h2 id="rule-1-performance-reviews-are-reviews-not-revelations">Rule 1: Performance Reviews Are Reviews, Not Revelations</h2>

<p>There shouldn’t be any surprises in a performance review. If you’re managing performance and growth properly, both should be active conversations, not things to talk about once every six months. To make sure you’re on the righteous path here, have a regular - aim for at least once per month - check-in on both performance and growth for your report.</p>

<h2 id="rule-2-make-sure-your-review-gets-a-review">Rule 2: Make Sure Your Review Gets A Review</h2>

<p>You might be tempted to downplay the significance of a performance assessment by thinking of it as a review instead of a revelation, but that doesn’t mean you shouldn’t be very, very careful in delivering the right message to your report. The written content and verbal delivery of a performance review are some of the most heavily scrutinized things in all of management.</p>

<p>You should have your own manager review the review you’re giving. Engineers review code for something as trivial as a copy update, but the YOLOing of performance reviews is endemic in industry. Your report’s feedback, growth, and performance review are all much higher stakes and more important than a large swath of much more heavily reviewed artifacts in a software company. If nothing else, try this out – the results can be dramatic.</p>

<h2 id="rule-3-be-specific">Rule 3: Be Specific</h2>

<p>Imagine you’re a junior engineer and you get a review that says “Angela is a great engineer and always up for a challenge.” Problems:</p>
<ul>
  <li>If Angela is a junior engineer and is already “great”, what does growth look like? Have they already peaked?</li>
  <li>Feedback is to either tell someone what to change or what to keep doing. “Great engineer” does none of that.</li>
  <li>People change. You’re describing them as having invariant properties vs. describing things they’ve done. This makes it harder for people to process feedback that’s counter to these claims in the future.</li>
</ul>

<p>So, be very specific in what you’re calling out, and give feedback around actions, not attributes. Good examples:</p>
<ul>
  <li>“Anegla showed impressive persistence in delivering her feature through several requirements changes”</li>
  <li>“Angela is a detail-oriented code reviewer, much to the benefit of our team”</li>
</ul>

<h2 id="rule-4-you-might-be-wrong">Rule 4: You Might Be Wrong</h2>

<p>Be ready to be wrong. You can do this in two ways.</p>

<p>First, deliver feedback as observations and impressions, not the word of God:</p>
<ul>
  <li>Bad: “Angela doesn’t like standup”</li>
  <li>Good: “Angela has shown up late repeatedly which makes me think she’s not prioritizing our standup”</li>
</ul>

<p>But remember, you should be talking about review, not revelations. So, the best is:</p>
<ul>
  <li>“As Angela and I have discussed, being late to stand up causes negative impact on the team, and she has taken steps to improve punctuality.”</li>
</ul>

<p>Second, don’t argue in real time. If people think you’re wrong, listen to their point of view and circle back in the near future. One of the most common mistakes is to try and force a point of view upon someone during the review itself. There are multiple reasons for this:</p>
<ul>
  <li>You might be wrong. If you rebut things in real time you’re not leaving space to realize you might be wrong. And even worse, you’re signalling to your report that you don’t think there’s any way you’re wrong and you don’t value their point of view.*</li>
  <li>Half the time disagreements in performance reviews are purely emotional reactions to feedback. Arguing and forcing the issue escalates and exacerbates the situation. Forcing your viewpoint in real time doesn’t leave space for your report to process the feedback.</li>
  <li>No matter what happens, the act of taking a break, potentially getting more feedback and information, and circling back to discuss is almost always a healthier and more productive way to get agreement. Stated another way - forcing the issue almost always only forces submission, not agreement and understanding.</li>
</ul>

<p>*Note: the one time you do need feedback to be final and agreed upon is in a performance improvement plan. By that point, many back and forths should have passed and it’s time to state clearly what needs to change, without compromise.</p>

<h2 id="rule-5-follow-through">Rule 5: Follow Through</h2>

<p>Common problem: you spend all this time crafting great feedback and aligning on growth plans and places to improve, but then you go back to business as usual next week.</p>

<p>Translate the feedback into TODOs in your recurring performance and growth meetings. You should be providing durable and important feedback, so make sure to use it.</p>

<h2 id="takeaways">Takeaways</h2>

<ul>
  <li>Performance Reviews are reviews, not revelations.</li>
  <li>Get feedback on the reviews you write!</li>
  <li>Give specific and useful feedback.</li>
  <li>Be ready to be wrong. Speak in observations instead of conclusions. Don’t argue in real time.</li>
  <li>Follow Through.</li>
</ul>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/04/22/Writing-Performance-Reviews-101.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836030</guid>
            <pubDate>Tue, 14 Jul 2020 18:48:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Event Driven Level Design]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835963">thread link</a>) | @bourgoisloic
<br/>
July 14, 2020 | https://loicbourgois.com/event-driven-level-design/index.html | <a href="https://web.archive.org/web/*/https://loicbourgois.com/event-driven-level-design/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="right-panel">
      
      <p>[space] to jump</p>
      
      
      <div id="controls">
        
        
        
      </div>
      <div id="editor">
        
        </div>
    </div></div>]]>
            </description>
            <link>https://loicbourgois.com/event-driven-level-design/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835963</guid>
            <pubDate>Tue, 14 Jul 2020 18:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You've only added two lines – why did that take two days?]]>
            </title>
            <description>
<![CDATA[
Score 812 | Comments 459 (<a href="https://news.ycombinator.com/item?id=23835918">thread link</a>) | @gregdoesit
<br/>
July 14, 2020 | https://www.mrlacey.com/2020/07/youve-only-added-two-lines-why-did-that.html | <a href="https://web.archive.org/web/*/https://www.mrlacey.com/2020/07/youve-only-added-two-lines-why-did-that.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pagepbt">
<!-- #masthead -->
<div id="contentpbt">
<div id="primarypbt">
<div id="mainpbt" role="main">
<div id="mainblogsec"><div data-version="1" id="Blog1">
<div>
<!--Can't find substitution for tag [defaultAdStart]-->

          <div>
        


          <div>
        
<div>
<article itemprop="blogPost" itemscope="itemscope" itemtype="http://schema.org/BlogPosting">
<a name="8378966868534474355"></a>


<div id="post-body-8378966868534474355" itemprop="articleBody"><p>
It might seem a reasonable question, but it makes some terrible assumptions:</p><ul>
<li>lines of code = effort</li>
<li>lines of code = value</li>
<li>all lines of code are equal</li>
</ul>

<p>
Why did a fix that seems so simple when looking at the changes made take two days to complete?</p>
<div>
<ul>
<li><b>Because the issue was reported with a vague description of how to recreate it.</b> It took me several hours to get to a reliable reproduction of the item. Some developers would have immediately gone back to the person reporting the problem and required more information before investigating. I try and do as much as I can with the information provided. I know some developers don't like having to fix bugs, and so do whatever they can to get out of it. Claiming there isn't enough is a great way to look like you're trying to help but not have to do anything. I know that reporting errors can be hard, and I'm grateful for anyone who does. I want to show appreciation for error reports by trying to do as much as possible with the information provided before asking for more details.</li>
<li><b>Because the reported issue was related to functionality, I'm not familiar with.</b>&nbsp;The feature it was to do with was something I rarely use and is not something I've ever used in great detail. This meant it took me longer than it might to understand how to use it and the nuances of how it interacts with the software with the bug.</li>
<li><b>Because I took the time to investigate the real cause of the issue, not just looking at the symptoms</b>. If some code is throwing an error, you could just wrap it in a try..catch statement and suppress the error. No error, no problem. Right? Sorry, for me, making the problem invisible isn't the same as fixing it. "Swallowing" an error can easily lead to other unexpected side-effects. I don't want to have to deal with them at a point in the future.</li>
<li><b>Because I investigated if there were other ways of getting to the same problem, not just the reported reproduction steps</b>. One set of reproduction steps can easily make the error appear to be in one place when it may actually be more deep-seated. Finding the exact cause of a problem, and looking at all the ways to get there can provide valuable insights. Insights such as how the code is actually used, where there might be other places with possible (other?) problems that might need addressing, or it may show inconsistencies in the code that mean an error is caused (or handled) in one code path but not another.</li>
<li><b>Because I took the time to verify if there were other parts of the code that might be affected in similar ways</b>. If a mistake led to the bug, the same error could have also been made elsewhere in the code-base. Now's a great time to check.&nbsp;</li>
<li><b>Because when I found the cause of the issue, I looked to find the simplest way of fixing it that would have minimal risk of introducing side-effects</b>. I don't want the quickest possible fix. I want a fix that isn't likely to cause confusion or other problems in the future.</li>
<li><b>Because I tested the change thoroughly and verified that it addressed the problem for all the different code paths that were affected</b>. I don't want to rely on someone else to have to test that what I've done is correct. I don't want a bug to be found in the future and for me to have to come back to this code when I've mentally moved on. Context switching is expensive and frustrating. Having a dedicated tester have to look at the "same" change again is something I want to avoid whenever possible.</li>
</ul>

</div>
<div><p>
I don't like having to fix bugs. Partly because they can feel like the result of a previous failure on my part. The other reason I don't like fixing bugs is that I'd prefer to be working on new things.</p><p>

What's worse than having to fix a bug?<br>
Having to fix the same bug repeatedly.<br>
I take the time to make sure any bug is totally fixed any time it is encountered so that it doesn't need to be faced, investigated, fixed, and tested more than once.</p></div>





</div>

<div>
<p><span>
<span>
<a href="https://www.blogger.com/email-post.g?blogID=33176002&amp;postID=8378966868534474355" title="Email Post">
<img alt="" height="13" src="https://img1.blogblog.com/img/icon18_email.gif" width="18">
</a>
</span>
</span></p>

</div>





</article>




</div>

        </div></div>
      
<!--Can't find substitution for tag [adEnd]-->
</div>

</div></div>
</div><!-- #main -->
</div><!-- #primary -->
<!-- #secondary -->
</div><!-- #content -->
<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://www.mrlacey.com/2020/07/youve-only-added-two-lines-why-did-that.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835918</guid>
            <pubDate>Tue, 14 Jul 2020 18:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What firefighting taught me for my job as an engineering manager]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23835909">thread link</a>) | @andygrunwald
<br/>
July 14, 2020 | https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers | <a href="https://web.archive.org/web/*/https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree.jpg" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree_hu00761edcb0e9c7da5edfb31ed8e7b79e_140481_360x0_resize_q75_box.jpg 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree_hu00761edcb0e9c7da5edfb31ed8e7b79e_140481_700x0_resize_q75_box.jpg 700w" sizes="(max-width: 360px) 360px, (min-width: 700px) 700px"></figure><p><em>— This article is not only for managers! <a href="#not-only-for-managers">read why…</a></em></p><p>I joined the youth group of our small local volunteer fire department in the neighbourhood when I was 12 years old. As a teenager, I was not aware that the youth instructors applied a very smart mix of fun, training, repetition, and strict commands to transform us from clumsy youngsters to real firefighters. Later, I understood that it wasn’t an easy task. I learned how difficult it is to motivate teenagers and train them when I took over the youth instructor role and slowly got into this business (see picture above of my team of youngsters during a fire extinguisher training). It is a challenge to prepare, train, and guide 11-15 years old boys and girls 4 years long while keeping them motivated until they can finally join the crew of adults who extinguish house fires and rescue cats.</p><h2 id="nothing-is-more-difficult-than-motivating-people">Nothing is more difficult than motivating people</h2><p>One would think that the action of fighting a fire already motivates volunteer firefighters to join the weekly training in the evening, several multi-day courses every year, and take over responsibilities in the organization and, thus, sacrifice their free time.</p><p>I have learned that this is not that easy after I was more involved in the management of the organization and was finally elected as the deputy fire chief of our department after 15 years. It might sound corny, but volunteers don’t follow just because you have a higher rank. You need trust and people have to believe that you can handle an operation. If you give the command to enter a burning house, people will only follow your commands if they trust you (and if it makes sense).</p><p>If you give an order that people have to show up at the training next week, they won’t. They don’t have to. It is not the army, it is not their job, they will find excuses and will slowly fade out from the organization. I have experienced hard times when our crew of active people has shrunk from 50 to 20 people.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree2_hub9b363f13c5500af6e5d377b5bc450b8_1316400_1500x0_resize_q75_box.JPG" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree2_hub9b363f13c5500af6e5d377b5bc450b8_1316400_360x0_resize_q75_box.JPG 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree2_hub9b363f13c5500af6e5d377b5bc450b8_1316400_700x0_resize_q75_box.JPG 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>Team of youngsters at a fire extinguisher training during my time as youth instructor</h4></figcaption></figure><h2 id="they-should-be-proud-to-work-for-us">They should be proud to work for us!</h2><p>Engineers work almost voluntarily for you. They earn a lot of money but as they work for you, they are really good I guess ;) and they will find another good job immediately. Thus, money isn’t a motivator for a longer period of time and you have to keep them motivated.
I already heard CEOs say: they should be proud to work for us. In the long run that even doesn’t work for the <a href="https://en.wikipedia.org/wiki/Big_Tech">Big Five</a>, so I assume, it won’t work for you either.</p><p>I figured that the dynamics of engineers and volunteer firefighter teams are very similar, maybe it applies even for all kinds of teams. In this post I have summarized my top five lessons learned from my time in the fire department and how it helped me to shape my leadership style as an engineering manager.</p><h2 id="lesson-1-provide-structure-and-keep-going">Lesson 1: Provide structure and keep going</h2><p>Especially when the motivation in the team is already down, for a lead, it is super hard to keep going. But this is exactly the most important phase and it is crucial to have a lead who does not give up. For a team in this downwards spiral, the most important thing is structure.</p><p>In the fire department, when the team got smaller and smaller due to a lack of motivation, we made a big mistake: We canceled some of the weekly drills as the group of present people was too small to practise bigger operations—or at least that was the excuse. As a result, even more people got bored and dropped out.</p><p>I saw similar situations in engineering teams when the motivation was down. People got more and more passive and they no longer proposed to catch up, to have brainstorming sessions, or to talk with each other to find the best solution for a problem.</p><p>In this situation it is essential to insist on the routine that you have hopefully already established before you experience difficult times. Do not accept cancellation requests for 1:1 sessions, retrospectives, or other regular meetings. In this dangerous situation, as a lead, you are the tower of strength and you can help the team to overcome the situation. It sounds quite easy but in reality it is not. In such situations I was depressed and unmotivated as well.</p><p>Everybody works differently but I think a piece of general advice is to stabilize yourself first. Do something outside of your job that makes you happy. Approach your allies (in private or business) and discuss the situation to be able to digest it faster. After that, support the team and keep the routine going. For the weekly firefighter drills I prepared backup plans in case too few people showed up. It is always good to have backup plans to be prepared and keep the system going. For 1:1s, you can try to bring some variety to it by e.g. <a href="https://jasonevanish.com/2014/05/29/101-questions-to-ask-in-1-on-1s/">asking different and new questions</a>.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/flashover_hue1678e2462bbc6923d1f3f2e59deb1b8_457585_1500x0_resize_q75_box.jpg" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/flashover_hue1678e2462bbc6923d1f3f2e59deb1b8_457585_360x0_resize_q75_box.jpg 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/flashover_hue1678e2462bbc6923d1f3f2e59deb1b8_457585_700x0_resize_q75_box.jpg 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>We do regular trainings such as <a href="https://en.wikipedia.org/wiki/Flashover">Flash-over</a> container trainings to be prepared for the real fire</h4></figcaption></figure><h2 id="lesson-2-celebrate-them">Lesson 2: Celebrate them!</h2><p>Celebrate your team and celebrate with the team. I mention it here explicitly because I forgot it too often. Especially as a lead your rhythm is not always synced with the team. It happened regularly to me that during the last phase of a project I was already snowed under with organizational tasks for the next project.</p><p>A simple “thank you” might be enough, or sometimes a big party together with the team is called for. When the team has accomplished something and can move on to the well-deserved resting time, the lead should think about the celebration and how she can thank people. Firefighters sacrifice their free time and join training events while they could spend time with their families, friends, or just enjoy their free time in another way.</p><p>Our fire department is in a higher region in the mountains in Innsbruck in Austria and it happened several times that the team was on duty for several days during natural disasters in winter (snow) and summer (floodings). It is not a big deal to invite over friends and family to a small dinner party in the fire department but you show the appreciation of all the people involved.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/thankyou.JPG" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/thankyou_huf4ae24ba605289f9976a997829732901_242871_360x0_resize_q75_box.JPG 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/thankyou_huf4ae24ba605289f9976a997829732901_242871_700x0_resize_q75_box.JPG 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>Saying thank you is crucial, not only because we rely on the younger generation in our fire department.</h4></figcaption></figure><p>Your development team might also run into similar exhausting situations. They do over-hours for several weeks to meet a deadline or just work very hard because they believe in the project. This is not the norm and you should thank them. There are many ways of saying “thank you”, and it can range from thanks you deliver in a 1:1 meeting to a bigger team event activity outside of your daily work environment. For me, it is always important that it is an honest “thank you” and that it is not just two words. Again, they could also spend their time in a different way and also other companies pay their employees, that is not unique to you.</p><h2 id="lesson-3-know-your-people-and-support-their-development">Lesson 3: Know your people and support their development</h2><p>It sounds obvious, but do you know your people? Can you answer the following questions for every team member?</p><ul><li>What are the three biggest strengths of the team member?</li><li>What are the motivational factors of the person?</li><li>What non-job-related interests does this person have?</li></ul><p>In our fire department we need people who take responsibility over the IT system, fire trucks, equipment &amp; tools maintenance, operational uniforms, and a lot of other areas. When entering a burning house you better know that the maintenance of tools and equipment was done in a proper way. It is not sufficient to just distribute the responsibilities, you have to know about the passion of people and if they really want to do it. Furthermore, you have to judge if they can and want to learn everything they need to know to take over a responsibility area.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/abseilen_hu041ad4f09540c8d3b36482d8c3bcbb51_3061870_1500x0_resize_q75_box.jpg" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/abseilen_hu041ad4f09540c8d3b36482d8c3bcbb51_3061870_360x0_resize_q75_box.jpg 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/abseilen_hu041ad4f09540c8d3b36482d8c3bcbb51_3061870_700x0_resize_q75_box.jpg 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>Going beyond personal limits during self-rescue training, abseiling on the wall of a building.</h4></figcaption></figure><p>In a company or team you also find a variety of different tasks that have to be done. Especially in smaller companies you do not have specialists for every single area. This can be a burden but also an opportunity for people to not only do their main job and get bored. Some people like to do other things from time to time and also learn new things.</p><p>A good example is recruiting. Not everybody wants to do it and not everybody is suited for it. You have to know your people and sometimes, also push them a bit to take on new challenges. Some people underestimate themselves very often and think they do not know enough to take on a new challenge. It doesn’t matter if it is about taking the tech lead role of a new project, recruiting, or switching from an individual contributor role to a manager role. When you know people, their skills and interests, you can judge better if they are capable of doing it and you can help or motivate them to find new challenges and develop their skills.</p><h2 id="lesson-4-say-yes">Lesson 4: Say yes!</h2><p>There are tons of leadership articles out there that state saying no is crucial. In a lot of situations that might be true but I disagree with them when it is about company or team culture. Think about yourself and how you feel when approaching somebody with a suggestion and then you get the reply “no” or the more or less equivalent “yes, but…”. I call those phrases motivational killers and using it leads to frustrated team members.</p><p>Saying yes doesn’t mean that you have to accept or like everything. For example, the answer “Yes, that sounds like a feasible idea. How would you implement it?” doesn’t mean that you agreed with it. You can ask more questions and analyze the proposal together with the team member. In the worst case, by answering your questions, the person realizes that there might be some issues with the idea. In the best case, it is worth working on it and there is already a team member who buys in and wants to work on this project.</p><p>I heard a lot of ideas from really young firefighters who proposed new ways of training or super cool training objects like old dry Christmas trees (see image at the beginning of the article). Sometimes, especially with more senior people, a “yes, great idea” as a supporting sign from the lead can be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers">https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers</a></em></p>]]>
            </description>
            <link>https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835909</guid>
            <pubDate>Tue, 14 Jul 2020 18:38:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take a gap year and receive $100k to start a company]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835889">thread link</a>) | @rchandna
<br/>
July 14, 2020 | https://contrarycap.com/content/gap-year-2020 | <a href="https://web.archive.org/web/*/https://contrarycap.com/content/gap-year-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This morning, we launched our gap year investment program, which was covered by <a href="https://www.protocol.com/contrary-capital-100k-gap-year-startup">Protocol</a>, <a href="https://www.forbes.com/sites/amyfeldman/2020/07/14/with-universities-going-online-this-vc-28-plans-to-invest-in-student-entrepreneurs-who-want-a-gap-year/">Forbes</a>, <a href="https://www.businessinsider.com/contrary-capital-giving-students-grants-gap-year-entrepreneur-startup-2020-7">Business Insider</a>, and <a href="https://www.nytimes.com/2020/07/14/business/dealbook/spac-blank-check.html">The New York Times</a>.</p><p>Apply <a href="https://contrarycap.com/gap-year">here</a> to get up to $100,000 to take a gap year and start a company instead.</p><hr><p>The founding principle of Contrary is that most important technology companies — from Google to Snapchat to StitchFix — were started at universities.</p><p>However, this year’s pandemic has significantly impacted founders and their ability to raise capital, find collaborators, and access mentorship. This presents the problem: if you can't meet people on campus, how are you supposed to find a brilliant co-founder, access capital and mentorship, or spend time heads-down building? </p><p>65% of students we surveyed are either considering a leave of absence or have already committed to taking a gap year. Yet the unfortunate reality is that most people can't afford to just take a year off and sit this out. </p><p><strong>That's why we’ve decided to invest up to $100,000 in up to 5 companies who choose to build rather than pay high prices for online classes.</strong></p><p>Contrary's gap year investment program will support members like any other portfolio company: with connections to operators who have scaled companies from zero to thousands of employees, a diverse network of potential hires, and tactical advice from our investment team.</p><p>We have no industry preferences and are also interested in funding international students, irrespective of visa status. A large portion of our portfolio companies were started by immigrants, and we don’t want physical location to get in the way of a startup.</p><p>The only requirements are that teams commit to working on their company full-time from September through spring of 2021, and that at least one member of the team is taking a gap year to build the company (undergrad/grad students and dropouts are welcome). </p><p>Teams can apply by filling out the application <a href="https://contrarycap.com/gap-year">here</a>.</p><p>All applications are due by 8/31, and are considered on a rolling basis. If you have any other questions, don't hesitate to reach out at <a href="https://contrarycap.com/cdn-cgi/l/email-protection#f59294858c909487b5969a9b818794878c969485db969a98"><span data-cfemail="7e191f0e071b1f0c3e1d11100a0c1f0c071d1f0e501d1113">[email&nbsp;protected]</span></a>. </p></div></div>]]>
            </description>
            <link>https://contrarycap.com/content/gap-year-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835889</guid>
            <pubDate>Tue, 14 Jul 2020 18:36:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Google Trends to Predict U.S. Elections]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835760">thread link</a>) | @ancoraallora
<br/>
July 14, 2020 | https://www.superhighway98.com/elections | <a href="https://web.archive.org/web/*/https://www.superhighway98.com/elections">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          
            
              
                
                  
                
              
            
          

          <main>
            
              <section data-content-field="main-content">
                <div data-type="page" data-updated-on="1594751103606" id="page-5f0de21d8480bd4a7f3c5900"><div><div><div data-block-type="2" id="block-48a7aec87d4b40ed3b42"><div><p>For as long as Google Trends has existed, it has correctly predicted the winner of each U.S. presidential election. </p><p>The input is simple: [Candidate's Last Name] + [Election Year]; the output is a remarkably effective way to judge the enthusiasm for any given candidate's campaign*. </p><p>Let's review the predictive powers of the historical data:</p><p><em>*Millions of people may search for a candidate’s last name to find newsworthy or biographical information, however, the inclusion of the election year within a query indicates a more specific intent.</em></p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_9720"><p><h2><strong>2004 U.S. Presidential Election</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_10427"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594745521876-FBGZU3RJ8CQNHP24H07W/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2004-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594745521876-FBGZU3RJ8CQNHP24H07W/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2004-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2004-Election.jpg" data-load="false" data-image-id="5f0de2b0d95d7b59b35e8cbe" data-type="image" src="https://www.superhighway98.com/2004-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_12049"><p>This is the first year that Google Trends data was published. For the entire election year, George W. Bush (the incumbent president) had more search demand than his challenger, John Kerry. Bush won both the popular and electoral vote in 2004.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_13937"><p><h2><strong>2008 U.S. Presidential Election</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_14660"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594745684630-2HSPOKGQ5NV8K24L1K6A/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2008-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594745684630-2HSPOKGQ5NV8K24L1K6A/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2008-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2008-Election.jpg" data-load="false" data-image-id="5f0de3541649e924f1ee10e2" data-type="image" src="https://www.superhighway98.com/2008-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_16406"><p>For the duration of 2008, Barack Obama led John McCain in search demand. Obama won both the popular and electoral vote in 2008 (each, by a significant margin).</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_37018"><p><h2><strong>2012 U.S. Presidential Election</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_34768"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594747088012-O2MU2ZMB8LZH3L0BYC2A/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2012-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594747088012-O2MU2ZMB8LZH3L0BYC2A/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2012-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2012-Election.jpg" data-load="false" data-image-id="5f0de8cf51baaa2eeebbbd32" data-type="image" src="https://www.superhighway98.com/2012-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_38258"><p>For the entire year, Barack Obama (the incumbent president) had more search demand than his challenger, Mitt Romney. Obama won both the popular and electoral vote in 2012.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_68695"><p><h2><strong>2016 U.S. Presidential Election</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_69361"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594749276769-TI27OJHPSA4R4GCXTEV0/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2016-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594749276769-TI27OJHPSA4R4GCXTEV0/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2016-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2016-Election.jpg" data-load="false" data-image-id="5f0df15c7056e411372101a7" data-type="image" src="https://www.superhighway98.com/2016-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_71161"><p>In contrast to public opinion polls, Donald Trump had more search demand than Hillary Clinton for the entire year (except for a single week in July). Trump lost the popular vote in 2016, but won the electoral vote and subsequently, won the election.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_72972"><p><h2><strong>2020 U.S. Presidential Election (Forthcoming)</strong></h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1594745378191_73681"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594749503697-E1GW83VBA11KG0A7LWHD/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2020-Election.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e6a3dd54dd6d5121789a9ff/1594749503697-E1GW83VBA11KG0A7LWHD/ke17ZwdGBToddI8pDm48kDo7XVuCOORjDEkD_eIwuDMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctMM4IxEIZ-kgU-HdHOwQFa-X1KiEZwzYHlrZnV-UxQ5-SDPJ_DqFXkMkF7UdbcLP/2020-Election.jpg" data-image-dimensions="1222x667" data-image-focal-point="0.5,0.5" alt="2020-Election.jpg" data-load="false" data-image-id="5f0df23edf9e903fdb5df648" data-type="image" src="https://www.superhighway98.com/2020-Election.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_76222"><p>Search demand for Donald Trump, the incumbent president, is trending significantly higher than searches for Joe Biden. (In fact, this is the largest disparity in search demand between any other contest of presidential hopefuls). This implies a Donald Trump victory.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1594745378191_78448"><div><h2><strong>Is History Repeating Itself?</strong></h2><p>The majority of political scientists, and for that matter, data scientists, were unable to correctly predict the results of the 2016 U.S. presidential election. (In fairness to both groups, the election was swung by around 80,000 votes that held electoral significance.)</p><p>Nevertheless, 2020 presidential polls are again at odds with Google search data.</p><p>This data implies that Joe Biden is an uninspiring candidate who faces an uphill battle in the polls; and that Trump’s “silent majority” may indeed be stronger than it was before.</p><p>###</p><p><a href="https://www.superhighway98.com/">&lt;- RETURN TO SUPERHIGHWAY 98</a></p><p><a href="https://www.superhighway98.com/google">HOW GOOGLE RUINED THE INTERNET -&gt;</a></p></div></div></div></div></div>
              </section>
            
          </main>

        </div>
      </div>

      


    </div></div>]]>
            </description>
            <link>https://www.superhighway98.com/elections</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835760</guid>
            <pubDate>Tue, 14 Jul 2020 18:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Me Think]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835645">thread link</a>) | @behnamoh
<br/>
July 14, 2020 | https://ralphammer.com/make-me-think/ | <a href="https://web.archive.org/web/*/https://ralphammer.com/make-me-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Until recently everyday objects were shaped by their technology. The design of a telephone was basically a hull around a machine. <strong>The task of the designers</strong> was to <strong>make technology look pretty</strong>.</p>

<p><img data-attachment-id="1293" data-permalink="https://ralphammer.com/make-me-think/makemethink_1/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_1.gif?fit=290%2C280&amp;ssl=1" data-orig-size="290,280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_1" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_1.gif?fit=290%2C280&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_1.gif?fit=290%2C280&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_1.gif?resize=290%2C280" alt="" width="290" height="280" data-recalc-dims="1"></p>
<p>It was up to the <strong>engineers</strong> to <strong>define the interfaces</strong> of those objects. Their main concern was <strong>the function of the machine, not its ease of use</strong>. We — the “users” — had to figure out how they worked.</p>
<p><img data-attachment-id="1294" data-permalink="https://ralphammer.com/make-me-think/makemethink_2/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_2.gif?fit=198%2C200&amp;ssl=1" data-orig-size="198,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_2" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_2.gif?fit=198%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_2.gif?fit=198%2C200&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_2.gif?resize=198%2C200" alt="" width="198" height="200" data-recalc-dims="1"></p>
<p>With every technological innovation our everyday objects became richer and increasingly complex. Designers and engineers simply <strong>burdened the users with this increase in complexity</strong>. I am still having nightmares<a href="https://www.youtube.com/watch?v=Kyl2g11KSqc"> trying to get a train ticket from the old BART vending machines in San Francisco</a>.</p>
<p><img data-attachment-id="1295" data-permalink="https://ralphammer.com/make-me-think/makemethink_3/" data-orig-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_3.gif?fit=225%2C215&amp;ssl=1" data-orig-size="225,215" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_3" data-image-description="" data-medium-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_3.gif?fit=225%2C215&amp;ssl=1" data-large-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_3.gif?fit=225%2C215&amp;ssl=1" src="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_3.gif?resize=225%2C215" alt="" width="225" height="215" data-recalc-dims="1"></p>
<h3>From complicated to simple</h3>
<p>Fortunately, UX (User eXperience) designers have found ways to design beautiful interfaces that are easy to use. Their process can resemble a philosophical enquiry, where they constantly ask questions such as: <strong>What is this really about? How do we perceive this? What is our mental model?</strong></p>
<p><img data-attachment-id="1296" data-permalink="https://ralphammer.com/make-me-think/makemethink_4/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_4.gif?fit=222%2C214&amp;ssl=1" data-orig-size="222,214" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_4" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_4.gif?fit=222%2C214&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_4.gif?fit=222%2C214&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_4.gif?resize=222%2C214" alt="" width="222" height="214" data-recalc-dims="1"></p>
<p>Today, as a result of their efforts, we interact with wonderfully designed interfaces. <strong>Designers have been taming complexity for us</strong>. They make extremely sophisticated technology appear simple and easy to use.</p>
<p><img data-attachment-id="1297" data-permalink="https://ralphammer.com/make-me-think/makemethink_5/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_5.gif?fit=128%2C200&amp;ssl=1" data-orig-size="128,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_5" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_5.gif?fit=128%2C200&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_5.gif?fit=128%2C200&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_5.gif?resize=128%2C200" alt="" width="128" height="200" data-recalc-dims="1"></p>
<h3>From simple to too simple</h3>
<p>And easy sells well. Thus more and more products are based on the promise to <strong>make our lives easier</strong> by <strong>using increasingly complex technologies with ever simpler interfaces</strong>.</p>
<p><img data-attachment-id="1298" data-permalink="https://ralphammer.com/make-me-think/makemethink_6/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_6.gif?fit=325%2C284&amp;ssl=1" data-orig-size="325,284" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_6" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_6.gif?fit=300%2C262&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_6.gif?fit=325%2C284&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_6.gif?resize=325%2C284" alt="" width="325" height="284" data-recalc-dims="1"></p>
<p>Just tell your phone what you want and things will appear magically — whether it is the information on a screen or a package delivered to your doorstep. A <strong>gigantic amount of technologies and infrastructure</strong> is domesticated by brave designers and engineers who make all this work.</p>
<p><img data-attachment-id="1299" data-permalink="https://ralphammer.com/make-me-think/makemethink_7/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_7.gif?fit=105%2C180&amp;ssl=1" data-orig-size="105,180" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_7" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_7.gif?fit=105%2C180&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_7.gif?fit=105%2C180&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_7.gif?resize=105%2C180" alt="" width="105" height="180" data-recalc-dims="1"></p>
<p>But we don’t see — let alone understand — what is going on behind the scenes, behind the simple appearance. <strong>We are kept in the dark</strong>.</p>
<p><img data-attachment-id="1300" data-permalink="https://ralphammer.com/make-me-think/makemethink_8/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_8.gif?fit=177%2C146&amp;ssl=1" data-orig-size="177,146" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_8" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_8.gif?fit=177%2C146&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_8.gif?fit=177%2C146&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_8.gif?resize=177%2C146" alt="" width="177" height="146" data-recalc-dims="1"></p>
<p>You should see me whining like a spoiled brat when a video call is not working as smoothly as expected — all those interruptions and the bad sound quality! An experience which would have appeared nothing short of a <strong>miracle</strong> to people just 50 years ago and which requires the operation of a colossal infrastructure has become an expected normality for me.</p>
<p><strong>We fail to appreciate and to empathise because we don’t understand what is going on.</strong></p>
<p>So does technology makes us dumb? This question isn’t really new. Famously Plato warned us about the detrimental effects of writing — which we know of because he wrote them down.</p>
<h3>The problem with “user centered” design</h3>
<p>In his <strong>excellent</strong> book “Living with complexity” Donald Norman offers numerous strategies for how designers can harness the design of complexity to <strong>improve the user experience</strong>.</p>
<p>And there lies a problem.</p>
<p>I am increasingly wary of the term “<strong>user centered design</strong>”. The word “user” has a second meaning — “consumer of drugs”— which implies <strong>dependance, short-sighted gratification and a reliable source of income for the “dealer”</strong>. The word “centered” excludes pretty much everyone and everything else.</p>
<p><img data-attachment-id="1301" data-permalink="https://ralphammer.com/make-me-think/makemethink_9/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_9.gif?fit=230%2C140&amp;ssl=1" data-orig-size="230,140" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_9" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_9.gif?fit=230%2C140&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_9.gif?fit=230%2C140&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_9.gif?resize=230%2C140" alt="" width="230" height="140" data-recalc-dims="1"></p>
<h3>A holistic approach to complexity</h3>
<p>As an alternative we should widen our perspective and ask questions such as:</p>
<h4>Empowerment: Who’s having the fun?</h4>
<p>Maybe being able to speak a foreign language is more fun than using a translation software.</p>
<p>Whenever we are about to substitute a laborious activity such as learning a language, cooking a meal, or tending to plants with a — deceptively — simple solution, we might always ask ourselves: <strong>Should the technology grow — or the person using it?</strong></p>
<p><img data-attachment-id="1302" data-permalink="https://ralphammer.com/make-me-think/makemethink_10/" data-orig-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_10.gif?fit=526%2C157&amp;ssl=1" data-orig-size="526,157" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_10" data-image-description="" data-medium-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_10.gif?fit=300%2C90&amp;ssl=1" data-large-file="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_10.gif?fit=526%2C157&amp;ssl=1" src="https://i2.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_10.gif?resize=526%2C157" alt="" width="526" height="157" data-recalc-dims="1"></p>
<h4>Resilience: Does it make us more vulnerable?</h4>
<p>Highly sophisticated systems work flawlessly, <strong>as long as things go as expected</strong>.</p>
<p>When a problem occurs which hasn’t been anticipated by the designers, those systems are prone to fail. <strong>The more complex the systems are, the higher are the chances that things go wrong</strong>. They are less resilient.</p>
<p><img data-attachment-id="1303" data-permalink="https://ralphammer.com/make-me-think/makemethink_11/" data-orig-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_11.gif?fit=458%2C206&amp;ssl=1" data-orig-size="458,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_11" data-image-description="" data-medium-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_11.gif?fit=300%2C135&amp;ssl=1" data-large-file="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_11.gif?fit=458%2C206&amp;ssl=1" src="https://i1.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_11.gif?resize=458%2C206" alt="" width="458" height="206" data-recalc-dims="1"></p>
<p>A chronic dependance on a combination of electronics, artificial intelligence and a high speed internet connection for the simplest tasks is a recipe for disaster. It makes our lives more complicated, especially when we don’t understand what is going on behind the deceptively simple interface.</p>
<h4>Empathy: What is the impact of simplification on others?</h4>
<p>Our decisions have consequences for ourselves and others. <strong>A simplified appearance can make us blind to those consequences</strong>.</p>
<p><img data-attachment-id="1304" data-permalink="https://ralphammer.com/make-me-think/makemethink_12/" data-orig-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_12.gif?fit=565%2C275&amp;ssl=1" data-orig-size="565,275" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="makemethink_12" data-image-description="" data-medium-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_12.gif?fit=300%2C146&amp;ssl=1" data-large-file="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_12.gif?fit=565%2C275&amp;ssl=1" src="https://i0.wp.com/ralphammer.com/wp-content/uploads/2019/12/makemethink_12.gif?resize=565%2C275" alt="" width="565" height="275" data-recalc-dims="1"></p>
<p>Our decision what smart phone to buy or what to have for dinner has a huge impact on other living beings. Knowing about the complexity behind such a decision can be of tremendous value. <strong>We need to know things better if we want to be better</strong>.</p>
<p><strong>Embracing complexity</strong></p>
<p>Simplification is a powerful design strategy. Naturally the button to make an emergency call should be as simple as possible. And yet, we also need further design strategies that help us accept, understand, and interact with complex situations in our lives.</p>
<h3>Before you go</h3>
<p><em>If you enjoyed this article, please <strong>use the buttons below</strong> to</em><em>&nbsp;<strong>share the story</strong> with your friends&nbsp;</em><em>and </em><a href="http://eepurl.com/cJJLR1" target="_blank" rel="noopener nofollow noreferrer"><strong><em>subscribe to my mailing list </em></strong></a><em>!</em></p>

				</div></div>]]>
            </description>
            <link>https://ralphammer.com/make-me-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835645</guid>
            <pubDate>Tue, 14 Jul 2020 18:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let’s avoid talk of ‘chemical imbalance’: it’s people in distress – Psyche Ideas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23835517">thread link</a>) | @rbanffy
<br/>
July 14, 2020 | https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>After Jenna discovered</strong> that her boyfriend was cheating on her, she went into an emotional tailspin. She was â€˜crying all the timeâ€™, struggled to attend her university classes, slept a lot and avoided situations she normally enjoyed.</p><p>In recounting her emotional reaction, Jenna stressed to me its unreasonableness. Given that she and her boyfriend hadnâ€™t been dating for long, she felt that she shouldnâ€™t have been so upset. After a month, she decided that something was seriously amiss and that she needed professional help. She recalled her psychiatrist diagnosing depression and telling her the problem might be caused by a chemical imbalance in her brain, for which she was prescribed an antidepressant.</p><p>Jenna found her emotional reactions jarring. They defied her basic assumptions about herself as confident, mature and self-sufficient. She told me she welcomed the diagnosis of a neurobiological disorder, which confirmed her problem was â€˜realâ€™ â€“ brought on by a physiological force external to her volition â€“ and that it showed sheâ€™s not â€˜just a slackerâ€™.</p><p>At the same time, Jenna was careful to distance her experience from that of people who are, in her words, â€˜crazyâ€™ or â€˜nutsâ€™. Their illness means a loss of control and ability to function. By contrast, she sees her problem as a common and minor glitch in neurochemistry. No one, she insisted, should mistake her for the mentally ill.</p><p>Jenna was one of 80 diverse volunteers that a research team at the University of Virginia and I interviewed in Chicago, Baltimore, Boston and two small cities in central Virginia. We wanted to find out how people deal with common forms of psychological distress and challenging circumstances, such as: shyness and nervousness in social situations; underperformance at work or school; struggles after the loss of a significant relationship; and disappointment with how their lives are unfolding. A majority of our interviewees had received some form of psychotherapy and/or been diagnosed with a condition such as depression, social anxiety disorder or attention deficit disorder, and prescribed a psychiatric medication.</p><p>It was striking that many (though not all) at least partly explained their distress in terms of biological causes, particularly a neurochemical imbalance. Yet thinking of their problems in this way was a fraught process. Like Jenna, many interviewees sharply distinguished themselves from the mentally ill and cast the mentally ill in a very negative light. This stigmatising of people with serious mental illness wasnâ€™t based on any first-hand experiences; rather, it was motivated by a desire to protect their own dignity and social standing. To justify the distinction between their own situation and mental illness, our interviewees rejected the idea that they had an â€˜illnessâ€™ as such, detached themselves from any formal diagnosis using statements such as â€˜thatâ€™s what the doctor calls itâ€™ or, in some cases, they avoided seeking medical help altogether.</p><p>For people like Jenna, who embraced a neurobiological explanation for their problems, this created a conundrum, which many of them resolved by creating a separate classification for their own experience â€“ what I have called a â€˜third conditionâ€™. The people we spoke to did not give this â€˜conditionâ€™ a name or explicit meaning. Rather it emerged in the rhetorical space opened up by the way they framed their personal struggle, distinguishing it from mental illness, on the one hand, and normality, on the other.</p><p><strong>Consider the perspective</strong> of another of our interviewees, a young woman Iâ€™ll call Piper, who had been diagnosed with depression. When â€˜you think mental illnessâ€™, according to Piper, â€˜you think schizophrenia and crazy people, and Iâ€™m not crazy, I just get really nervous.â€™ In making this distinction, interviewees like Piper and Jenna not only claimed that they were less impaired than the seriously mentally ill, they also insisted that their experience was categorially different. Piper said of herself that biologically something is just â€˜a little offâ€™. She has â€˜too little or too much or whatever it is that makes you have these issuesâ€™. Distinct from â€˜crazy peopleâ€™, she has control over her mind and her story. All she needs is a little pill. Yet at the same time, her â€˜conditionâ€™ is also different from the mundane challenges that normal people might face. Piper was adamant that her nervousness in social situations is different from ordinary shyness. Her taking of medication is warranted. She has a third condition caused by an â€˜imbalanceâ€™.</p><p>The â€˜crazy peopleâ€™ are shadowy, depersonalised figures â€“ the damaged, uncontrolled â€˜otherâ€™ </p><p>To reconcile their perspective with the fact that they had received a psychiatric diagnosis, many interviewees credited a medical professional or a confidant for suggesting something like this third condition idea to them. Others emphasised the ordinariness of their experience and compared it to the types of routine problems that regular physicians treat. As one interviewee put it, â€˜all you have to do is take a pillâ€™.</p><p>There are echoes here of the messages conveyed in direct-to-consumer advertising for psychiatric medication. Iâ€™ve analysed the content of these adverts and found that distress, as listed in symptoms and portrayed in the patientsâ€™ stories, is often presented as a â€˜real medical conditionâ€™ and yet unlike mental illness. The ads contain no references to psychiatrists or to the diagnostic manual of mental disorders from the American Psychiatric Association (APA), nor use of phrases such as â€˜mental illnessâ€™ or â€˜mental disorderâ€™, and no depictions of those affected as anything but productive and successful citizens. In the words of our interviewees and in the advertising messages, the â€˜crazy peopleâ€™ are shadowy, depersonalised figures â€“ the damaged, uncontrolled â€˜otherâ€™ against whom the implicit comparisons are being drawn.</p><p>The views we encountered in our interviews are consistent with national surveys of public opinion about mental health. Today, with respect to mental health problems, the lay public much more freely endorses biological causes, the seeking of medical help and the use of psychoactive medications than in the past. Their views have converged with the biological perspectives long promoted in public campaigns to reduce the stigma of mental illness. According to the American anti-stigma organisation Bring Change to Mind, for instance: â€˜The fact is, a mental illness is a disorder of the brain â€“ your bodyâ€™s most important organ.â€™ Among anti-stigma researchers and activists, the evolution in public attitudes toward biological psychiatry has been celebrated as a sign that the public has at long last become â€˜literateâ€™, with a â€˜more scientificâ€™ even â€˜sophisticatedâ€™ understanding of mental illness.</p><p>In promoting a biogenetic causal theory, anti-stigma campaigners â€“ as well as psychiatrists, the popular media, and others â€“ hoped to convince people that mental illnesses are â€˜just likeâ€™ other chronic physical ailments, such as â€˜heart disease or diabetesâ€™, to <a href="https://www.psychiatry.org/patients-families/what-is-mental-illness" target="_blank">quote</a> the APA, and could be medically addressed. This approach would, in turn, alleviate mental illness stigma and foster tolerance by reducing the (allegedly common) tendency to hold sufferers responsible for their condition. The result, it was confidently believed, would promote treatment optimism and increased help-seeking.</p><p>But something unexpected happened. The public embrace of neurobiology has not led to a more benevolent orientation toward the mentally ill. Rather, according to an <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4409431/" target="_blank">editorial</a> in the <em>Journal of Psychiatry and Neuroscience</em> in 2015, â€˜well-conducted studies have concluded, almost uniformlyâ€™ that the stigma-reduction strategy of recent decades, informed by â€˜biogenetic attribution of all mental disordersâ€™, has â€˜not only not worked, but also may have worsened public attitudes and behaviour toward those with mental illnessesâ€™. Such studies have shown that the growing endorsement of biological causation has continued to exacerbate the stigmatising of mental illness among the <a href="https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/biogenetic-explanations-and-public-acceptance-of-mental-illness-systematic-review-of-population-studies/E6078EED07031B5828DB84FCDC90657F" target="_blank">general public</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/20493559/" target="_blank">patients</a> and <a href="https://www.pnas.org/content/111/50/17786" target="_blank">professionals</a>.</p><p>What accounts for this paradoxical result?</p><p><strong>I believe that </strong>our interviews reveal a crucial reason. While people accepted a neurobiological explanation for their problems, they struggled against the dehumanising notion that their thoughts, feelings or behaviour were mechanistically <em>caused.</em> Drawing on clinicians, drug ads and the popular media, the caricature of the seriously mentally ill served as a pivotal image by which to contrast and affirm their own control and self-determination. Millions of Americans â€“ and countless others in Western countries â€“ likely find themselves sharing this or a similar perspective.</p><p>The idea that oneâ€™s distress is primarily caused by a neurochemical deficiency that can be corrected by a drug is a fiction</p><p>As I argue in my <a href="https://press.uchicago.edu/ucp/books/book/chicago/C/bo48408677.html" target="_blank">book</a> <em>Chemically Imbalanced</em> (2020), to defeat this othering and reduce stigma, clinical practice needs to move away from biogenetic causal language. Psychiatric research doesnâ€™t support the notion of simple cause and effect in mental health, instead uncovering a far more complex and indeterminate picture of vulnerabilities. There is no evidence to justify the continued promotion of one-dimensional theories such as â€˜chemical imbalanceâ€™. Nor does the beneficial use of psychiatric medicines require it. In fact, their precise mechanism of action and relation to troublesome experience <a href="https://www.frontiersin.org/articles/10.3389/fpsyt.2019.00407/full" target="_blank">remains</a> a mystery. It would be more truthful for mental health professionals and public health campaigns to acknowledge this.</p><p>Itâ€™s true, as interviewees such as Jenna made clear, that patients often find biogenetic language appealing. It provides a way to establish their suffering as both tangible and unfeigned, and it offers a simple account and positive prognosis for their struggles. However, the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress">https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/lets-avoid-talk-of-chemical-imbalance-its-people-in-distress</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835517</guid>
            <pubDate>Tue, 14 Jul 2020 18:11:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Demo app of the first cloud storage that uses only browser JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835515">thread link</a>) | @ent101
<br/>
July 14, 2020 | https://www.outpan.com/app/4b9863258e/bmi-calculator-weight-loss-tracker | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/4b9863258e/bmi-calculator-weight-loss-tracker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/4b9863258e-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>8</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/4b9863258e/bmi-calculator-weight-loss-tracker</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835515</guid>
            <pubDate>Tue, 14 Jul 2020 18:11:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The History of Math Rock, Pt 1 (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835340">thread link</a>) | @Elof
<br/>
July 14, 2020 | http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now | <a href="https://web.archive.org/web/*/http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

						
						<article id="post-4600">

							
							<section itemprop="articleBody">

								<span itemprop="reviewBody">
<p>Look, let’s be honest. We can attempt to write a full-fledged, well-attested, unabridged recount of four decades of math rock history and it is still going to be wrong. The bane of theorists and historians the world over is the rewriting of previous records due to emergent refutations, subjective arguments, and, in some cases, author bias. Adding to the complications is, of course, the exhaustive list of underdogs overlooked by the critics and historians, which, upon revelation, demand a restructuring of the original story: punk rock’s <a rel="noopener noreferrer" href="http://www.theguardian.com/music/musicblog/2009/feb/09/detroit-band-death" target="_blank"><u>Death</u></a>, heavy metal’s <a rel="noopener noreferrer" href="http://ultimateclassicrock.com/blue-cheer-vincebus-eruptum/" target="_blank"><u>Blue Cheer</u></a>, and countless others.</p>
<p>It is, perhaps, even more difficult with such a malleable genre as math rock. At its core, ‘math rock’ is the amalgamation of the distorted guitar riffs of punk and hardcore, and the metrical asymmetry associated primarily with 1970s progressive rock, and the history of math rock we present to you will appear to show this fusion. In his essay <em>How Alternative Turned Progressive: The Strange Case Of Math Rock</em> Theo Cateforis defines math rock music as being defined through “<em>the absence of a steady, divisible pulse</em>” <a rel="noopener noreferrer" href="http://www.academia.edu/7315935/How_Alternative_Turned_Progressive_The_Strange_Case_of_Math_Rock" target="_blank"><u><sup>[1]</sup></u></a>. Yet, in the past the word ‘math’ has be used to describe <em>anything</em> dissonant in structure, and has been applied to hardcore (‘mathcore’) and metal (‘math metal’). Thus, a problem exists in that this label could cover quite large territory and, with some leeway, could be used to describe the meter-bending works of <em><strong>Yes</strong></em>, <strong><em>Dave Brubeck</em></strong>, or even <strong><em>Igor Stravinsky</em></strong>. So what is ‘math’? Is it a genre, or is it an adjective, perhaps?</p>
<p>In this four part series, we are stockpiling ambition up our sleeves to set the record straight not only on ‘math rock’ but the word ‘math’ itself. It’s no surprise to some that term has been consistently met with derision; for the alternative kids growing up in the 80’s and 90’s many considered it a derogatory notion, which implied showmanship, excessive virtuosity and pretentiousness (something that seems to be overlooked when it comes to solo-shredding heavy metal guitarists). We hope to provide you with a comprehensive history of ‘math’ in music, starting from the US-rooted math rock boom of the 80’s/90’s, working backwards through the 1970’s progressive rock era of <strong><em>King Crimson</em></strong> and <em><strong>Yes</strong></em>, and finally ending up all the way back in the classical works of yester-century. Perhaps then we can start to idealise what ‘math’ is. But in order to tell the story right, we need to start in Los Angeles during the 70’s…</p>
<hr>
<p><img src="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?resize=211%2C300" alt="The_Screamers" width="211" height="300" srcset="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?resize=211%2C300 211w, https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?w=382 382w" sizes="(max-width: 211px) 100vw, 211px" data-recalc-dims="1" data-old-src="https://i0.wp.com/feckingbahamas.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif?resize=211%2C300" data-src="http://feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers-211x300.jpg" data-srcset="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?resize=211%2C300 211w, https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?w=382 382w"></p>
<h3>1976-1985</h3>
<p><strong><em>The Early Hardcore Punk Movement: Screams, Polyrhythms, And Word Of Math</em></strong></p>
<p>Tomata Duplenty of <em><strong>The Screamers</strong></em> was probably the first punk rock frontman to scream his lyrics. In fact, he was probably the first screaming frontman of any genre. The LA band comprised two keyboardists, a drummer, and Duplenty; an unusual combination of instruments for an undeniably punk band. The Screamers weren’t math rock, but their <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=MdCRcrgX080" target="_blank"><u>unconventional approach to an already unconventional genre</u></a> was an influence on a fresh spawn of punk rock bands forming in LA during the late 70’s and early 80’s. Of these, two in particular are especially important to math rock.</p>
<p><em><strong>Black Flag</strong></em> was formed by Greg Ginn in 1976. Initially fronted by Keith Morris (of <strong><strong>Circle Jerks</strong></strong> and, more recently, <em><strong>OFF!</strong></em> fame), and subsequently succeeded by the bellowing and fiercely-pissed-off Henry Rollins, the band brought an overwhelmingly raw and ferocious sound to punk rock, and were pivotal in solidifying ‘hardcore punk’. However, it is Black Flag’s 1984 release ‘My War’ that is pertinent to math rock history. A clear deviation from previous albums, the record comprised several primordial math rock tracks: ‘Swinging Man’, ‘Three Nights’ and ‘Scream’. The ‘mathiness’ of these songs were mainly based around the polyrhythmic percussion of Bill Stevenson. He’d been put on <em><strong>Mahavishnu Orchestra</strong></em> by guitarist Greg Ginn <a rel="noopener noreferrer" href="http://www.invisibleoranges.com/2013/01/heavy-metal-be-bop-9-greg-ginn/" target="_blank"><u><sup>[2]</sup></u></a>, and they had influenced his craft both here and in his other bands <em><strong><a rel="noopener noreferrer" href="https://youtu.be/_0BHktyIyQ8" target="_blank"><u>The Descendents</u></a></strong></em> and <em><strong><a rel="noopener noreferrer" href="https://youtu.be/z6mPn6j5UKw" target="_blank"><u>All</u></a></strong></em>. In 1985, Black Flag recorded the entirely instrumental album <em>The Process of Weeding Out</em>, which was perhaps Greg Ginn’s attempt to write as weird and as challenging music as he could. It is quite possible that this was the <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=C_BqufJhHYA" target="_blank"><u>first math rock album</u></a>.</p>
<div><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/r-dMjruMHBk" width="400" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe>
<p><small><em><strong>Black Flag</strong> – ‘The Swinging Man’ from <em>My War</em> (1984)</em></small></p>
</div>
<p>The influence of Mahavishnu Orchestra on Greg Ginn’s guitar playing <a rel="noopener noreferrer" href="http://www.invisibleoranges.com/2013/01/heavy-metal-be-bop-9-greg-ginn/" target="_blank"><u><sup>[2]</sup></u></a> suggests the influence of progressive rock on early punk rock, and thus a key constituent in the preliminary math rock blueprints. <em><strong>Minutemen</strong></em> was formed by a bunch of San Pedro kids in 1980, following the demise of <em><strong>The Reactionaries</strong></em> who, like Black Flag, had taken influence from progressive rock heavyweights like <em><strong>Captain Beefheart and the Magic Band</strong></em> <a rel="noopener noreferrer" href="http://inflooenz.com/?artist=Minutemen&amp;influencer=captain+beefheart+%26+the+magic+band" target="_blank"><u><sup>[3]</sup></u></a>. Greg Ginn incidentally produced the band’s first EP, <em>Paranoid Time</em>, a barrage of quick and snappy punk rock tracks. The 1981 release <em><a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=7xYHzC_yYTk" target="_blank"><u>The Punch Line</u></a></em> was an 18 track discourse in compact, rambunctious and deliberately non-commercial music-making. While not deviating from 4/4 explicitly, the album contained experimental interplay between guitar and bass, and unusually syncopated percussion. Interestingly, the eighteenth track of Minutemen’s 1982 magnum opus <em>Double Nickels On The Dime</em> is named ‘<a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=wRbNqeW7BJI" target="_blank"><u>God Bows To Math</u></a>‘, a short yet complexly syncopated piece, and an ironic omen for the later coining of the term ‘math rock’. While this conflicts with claims made almost a decade later (see below), a number of musicians have informed us that the term was being used from at least the mid-late 80’s. Minutemen disbanded after the tragic passing of guitarist D.Boon in a car accident.</p>
<p>As progressive rock was moulding a new generation of experimental punk through the early 80’s, something interesting was also taking shape in the north. Two years prior to Black Flag’s release of <em>My War</em>, Canadian brothers John and Rob Wright had commenced their first studio recording as a drum and bass two-piece. Their band, <strong><em>Nomeansno</em></strong>; the album <em>Mama</em>. Although not as jazzy or punky as their later releases <em>Sex Mad</em> (1986), <em>Small Parts Isolated And Destroyed</em> (1988) and <em>Wrong</em> (1989), the influence of jazz, progressive rock and post-punk in these albums is undeniable. The experimental nature of late 70’s post-punk movements, bands like <em><strong>Gang Of Four</strong></em> and <em><strong>PiL</strong></em>, had instilled some confidence in the Wright brothers to counterbalance the absence of guitar with richer rhythms and compositions to ‘fill out the sound’<a rel="noopener noreferrer" href="http://thequietus.com/articles/12566-nomeansno-john-wright-interview" target="_blank"><u><sup>[4]</sup></u></a>. Music was always in the Wright household: jazz, rock, Beatlemania and big band.<a rel="noopener noreferrer" href="http://www.vice.com/read/going-gray-with-nomeansno" target="_blank"><u><sup>[5]</sup></u></a> <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=wDVpno7bwtg" target="_blank"><u>And there was certainly evidence of this in <em>Mama</em></u></a>. What the Wright Brothers started in <em>Mama</em> would quickly blossom into jazzy and prog-rich punk rock.</p>
<div><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/loNI2Mlc_lc" width="400" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe>
<p><small><em><strong>Nomeansno</strong> – ‘Junk’ from <em>Small Parts, Isolated And Destroyed</em> (1988)</em></small></p>
</div>
<p><strong><em>No-Wave: Music Rebellion With A Touch Of Grind</em></strong></p>
<p>There is another, and perhaps slightly overlooked, angle to the math rock story. Contemporaneous with the early experimental divergences in LA punk rock was the emergence of the ‘No Wave’ movement, a late 70’s ideological counter-response to the overt happiness and mainstream success slowly enveloping the New Wave fad<a rel="noopener noreferrer" href="http://pitchfork.com/features/articles/6764-no-the-origins-of-no-wave/" target="_blank"> <u><sup>[6]</sup></u></a>. Artists were starting to make ugly, disjointed music in conjunction with their frustrations with New Wave. No Wave is likely to have started a couple of years earlier when <em><strong>Brian Eno</strong></em>, taking direct influence from a five-day festival he attended at New York’s non-profit <em>Artists Space</em> venue, quickly produced a compilation spotlighting what he saw as an exciting rebellious music movement. The 1978 compilation, <em><a rel="noopener noreferrer" href="http://www.allmusic.com/album/no-new-york-mw0000260455" target="_blank"><u>No New York</u></a></em>, appeared as a denigration towards New Wave music. The music lacked exuberance and, instead, was <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=re6uN1lOTQw" target="_blank"><u>left-of-center</u></a>, <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=zj_yX3yS8Dk" target="_blank"><u>spacey</u></a>, angular and <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=YpXktFfSy4k" target="_blank"><u>rhythmically irregular</u></a>.</p>
<p>Much like the hardcore punk scene booming down in LA, an interesting connection existed between 70’s progressive rock and the No Wave scene. <em><strong>Gong</strong></em> was a heavily influential psychedelic progressive rock band formed by Australian musician Daevid Allen in the UK in 1967. Following Gong’s breakup in the mid-70’s, Allen moved to NYC and became heavily immersed in No Wave, and released a new album, <em>About Time</em>, under the band name <em><strong>New York Gong</strong></em>. No Wave in style but still retaining the elements of psych-prog pertinent to Gong, <em>About Time</em> brought together two important figures: bassist Bill Laswell and drummer Fred Maher. New York Gong slowly re-collaborated as a new band in 1979, <em><strong>Material</strong></em>, and Laswell and Maher subsequently went on to form a No Wave act with an undeniably math rock dogma: <em><strong>Massacre</strong></em>. Their 1981 debut <em>Killing Time</em> remains a classic; a weird mix of <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=-P7oMwJkQfk" target="_blank"><u>zany chord progressions over odd time signatures</u></a>. <img data-attachment-id="4787" data-permalink="http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now/the_screamers" data-orig-file="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?fit=382%2C543" data-orig-size="382,543" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="The_Screamers" data-image-description="" data-medium-file="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?fit=211%2C300" data-large-file="https://i0.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/The_Screamers.jpg?fit=382%2C543" src="https://i1.wp.com/feckingbahamas.com/wp-content/uploads/2015/04/new-york-gong.jpg?resize=200%2C200" alt="screamers" width="200" height="200" data-recalc-dims="1" data-old-src="https://i0.wp.com/feckingbahamas.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif?resize=200%2C200" data-src="http://feckingbahamas.com/wp-content/uploads/2015/04/new-york-gong.jpg"></p>
<p>By the early 80’s No Wave was proliferating amongst the New York venues, and a number of interesting releases are pertinent to this story. In the same year as <em>Killing Time</em>‘s release, John Lurie’s instrumental punk-jazz group <em><strong>Lounge Lizards</strong></em> released their <a rel="noopener noreferrer" href="https://www.youtube.com/watch?v=bZB4Hf9aKJc" target="_blank"><u>highly angular self-titled album</u></a>. <strong><em>Swans</em></strong>‘ 1984 sophomore release ‘Cop’ was abrasive and weirdly syncopated; and it is here that many music historians attribute the first use of the term ‘grind’. In 1983, Massacre members Bill Laswell and Anton Fier went on to join a new group, <em><strong>The Golden Palominos</strong></em>, which also featured No-Wave icon Arto Lindsay on guitar and vocals, and an at-the-time unknown John Zorn. The Golden Palominos were described as poly-style music due to their stylistic shifts between no-wave, noise-rock, jazz, funk, polyrhythmic world music, and, well, weirdness. The heterogeneity and general pithiness to their style and composition laid a lot of ground work for Zorn’s renowned spazzy jazz band <em><strong>Naked City</strong></em>, which continued the legacy of weird time changes and off-kilter compositions into the late 80’s.</p>
<hr>
<div><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/gNdnOTvGbJQ" width="400" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe>
<p><small><em><strong>Cardiacs</strong> – ‘R.E.S’, originally from <em>The Seaside</em> (1984)</em></small></p>
</div>
<h3>1986 – 1998</h3>
<p><strong><em>The Rhythmic Bedlam of Cardiacs</em></strong></p>
<p>Before we move towards the late 80’s, we must acknowledge a final band that sits uncomfortably between the branches of the math rock story hitherto. While not explicitly ‘No Wave’ or ‘punk’, <em><strong>Cardiacs</strong></em>‘ non-conventional approach to …</p></span></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now">http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now</a></em></p>]]>
            </description>
            <link>http://feckingbahamas.com/history-math-rock-pt-1-guess-black-flag-math-rock-now</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835340</guid>
            <pubDate>Tue, 14 Jul 2020 17:59:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vmagent – resource-efficient Prometheus metrics collector]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835152">thread link</a>) | @valyala
<br/>
July 14, 2020 | https://victoriametrics.github.io/vmagent.html | <a href="https://web.archive.org/web/*/https://victoriametrics.github.io/vmagent.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article>

  

  <div>
    <p><code>vmagent</code> is a tiny but brave agent, which helps you collect metrics from various sources
and stores them in <a href="https://github.com/VictoriaMetrics/VictoriaMetrics">VictoriaMetrics</a>
or any other Prometheus-compatible storage system that supports the <code>remote_write</code> protocol.</p>

<p><img alt="vmagent" src="https://victoriametrics.github.io/vmagent.png"></p>

<h3 id="motivation">Motivation</h3>

<p>While VictoriaMetrics provides an efficient solution to store and observe metrics, our users needed something fast
and RAM friendly to scrape metrics from Prometheus-compatible exporters to VictoriaMetrics.
Also, we found that users’ infrastructure are snowflakes - no two are alike, and we decided to add more flexibility
to <code>vmagent</code> (like the ability to push metrics instead of pulling them). We did our best and plan to do even more.</p>

<h3 id="features">Features</h3>

<ul>
  <li>Can be used as drop-in replacement for Prometheus for scraping targets such as <a href="https://github.com/prometheus/node_exporter">node_exporter</a>.
See <a href="#quick-start">Quick Start</a> for details.</li>
  <li>Can add, remove and modify labels (aka tags) via Prometheus relabeling. Can filter data before sending it to remote storage. See <a href="#relabeling">these docs</a> for details.</li>
  <li>Accepts data via all the ingestion protocols supported by VictoriaMetrics:
    <ul>
      <li>Influx line protocol via <code>http://&lt;vmagent&gt;:8429/write</code>. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-send-data-from-influxdb-compatible-agents-such-as-telegraf">these docs</a>.</li>
      <li>Graphite plaintext protocol if <code>-graphiteListenAddr</code> command-line flag is set. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-send-data-from-graphite-compatible-agents-such-as-statsd">these docs</a>.</li>
      <li>OpenTSDB telnet and http protocols if <code>-opentsdbListenAddr</code> command-line flag is set. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-send-data-from-opentsdb-compatible-agents">these docs</a>.</li>
      <li>Prometheus remote write protocol via <code>http://&lt;vmagent&gt;:8429/api/v1/write</code>.</li>
      <li>JSON lines import protocol via <code>http://&lt;vmagent&gt;:8429/api/v1/import</code>. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-import-time-series-data">these docs</a>.</li>
      <li>Data in Prometheus exposition format. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-import-data-in-prometheus-exposition-format">these docs</a> for details.</li>
      <li>Arbitrary CSV data via <code>http://&lt;vmagent&gt;:8429/api/v1/import/csv</code>. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-import-csv-data">these docs</a>.</li>
    </ul>
  </li>
  <li>Can replicate collected metrics simultaneously to multiple remote storage systems.</li>
  <li>Works in environments with unstable connections to remote storage. If the remote storage is unavailable, the collected metrics
are buffered at <code>-remoteWrite.tmpDataPath</code>. The buffered metrics are sent to remote storage as soon as connection
to remote storage is recovered. The maximum disk usage for the buffer can be limited with <code>-remoteWrite.maxDiskUsagePerURL</code>.</li>
  <li>Uses lower amounts of RAM, CPU, disk IO and network bandwidth compared to Prometheus.</li>
</ul>

<h3 id="quick-start">Quick Start</h3>

<p>Just download <code>vmutils-*</code> archive from <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/releases">releases page</a>, unpack it
and pass the following flags to <code>vmagent</code> binary in order to start scraping Prometheus targets:</p>

<ul>
  <li><code>-promscrape.config</code> with the path to Prometheus config file (it is usually located at <code>/etc/prometheus/prometheus.yml</code>)</li>
  <li><code>-remoteWrite.url</code> with the remote storage endpoint such as VictoriaMetrics. The <code>-remoteWrite.url</code> argument can be specified multiple times in order to replicate data concurrently to an arbitrary amount of remote storage systems.</li>
</ul>

<p>Example command line:</p>

<div><div><pre><code>/path/to/vmagent -promscrape.config=/path/to/prometheus.yml -remoteWrite.url=https://victoria-metrics-host:8428/api/v1/write
</code></pre></div></div>

<p>If you only need to collect Influx data, then the following is sufficient:</p>

<div><div><pre><code>/path/to/vmagent -remoteWrite.url=https://victoria-metrics-host:8428/api/v1/write
</code></pre></div></div>

<p>Then send Influx data to <code>http://vmagent-host:8429</code>. See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/README.md#how-to-send-data-from-influxdb-compatible-agents-such-as-telegraf">these docs</a> for more details.</p>

<p><code>vmagent</code> is also available in <a href="https://hub.docker.com/r/victoriametrics/vmagent/tags">docker images</a>.</p>

<p>Pass <code>-help</code> to <code>vmagent</code> in order to see the full list of supported command-line flags with their descriptions.</p>

<h3 id="use-cases">Use cases</h3>

<h4 id="iot-and-edge-monitoring">IoT and Edge monitoring</h4>

<p><code>vmagent</code> can run and collect metrics in IoT and industrial networks with unreliable or scheduled connections to the remote storage.
It buffers the collected data in local files until the connection to remote storage becomes available and then sends the buffered
data to the remote storage. It re-tries sending the data to remote storage on any errors.
The maximum buffer size can be limited with <code>-remoteWrite.maxDiskUsagePerURL</code>.</p>

<p><code>vmagent</code> works on various architectures from IoT world - 32-bit arm, 64-bit arm, ppc64, 386, amd64.
See <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/app/vmagent/Makefile">the corresponding Makefile rules</a> for details.</p>

<h4 id="drop-in-replacement-for-prometheus">Drop-in replacement for Prometheus</h4>

<p>If you use Prometheus only for scraping metrics from various targets and forwarding these metrics to remote storage,
then <code>vmagent</code> can replace such Prometheus setup. Usually <code>vmagent</code> requires lower amounts of RAM, CPU and network bandwidth comparing to Prometheus for such a setup.
See <a href="#how-to-collect-metrics-in-prometheus-format">these docs</a> for details.</p>

<h4 id="replication-and-high-availability">Replication and high availability</h4>

<p><code>vmagent</code> replicates the collected metrics among multiple remote storage instances configured via <code>-remoteWrite.url</code> args.
If a single remote storage instance temporarily is out of service, then the collected data remains available in another remote storage instances.
<code>vmagent</code> buffers the collected data in files at <code>-remoteWrite.tmpDataPath</code> until the remote storage becomes available again.
Then it sends the buffered data to the remote storage in order to prevent data gaps in the remote storage.</p>

<h4 id="relabeling-and-filtering">Relabeling and filtering</h4>

<p><code>vmagent</code> can add, remove or update labels on the collected data before sending it to remote storage. Additionally,
it can remove unwanted samples via Prometheus-like relabeling before sending the collected data to remote storage.
See <a href="#relabeling">these docs</a> for details.</p>

<h4 id="splitting-data-streams-among-multiple-systems">Splitting data streams among multiple systems</h4>

<p><code>vmagent</code> supports splitting the collected data between muliple destinations with the help of <code>-remoteWrite.urlRelabelConfig</code>,
which is applied independently for each configured <code>-remoteWrite.url</code> destination. For instance, it is possible to replicate or split
data among long-term remote storage, short-term remote storage and real-time analytical system <a href="https://github.com/Telefonica/prometheus-kafka-adapter">built on top of Kafka</a>.
Note that each destination can receive its own subset of the collected data thanks to per-destination relabeling via <code>-remoteWrite.urlRelabelConfig</code>.</p>

<h4 id="prometheus-remote_write-proxy">Prometheus remote_write proxy</h4>

<p><code>vmagent</code> may be used as a proxy for Prometheus data sent via Prometheus <code>remote_write</code> protocol. It can accept data via <code>remote_write</code> API
at <code>/api/v1/write</code> endpoint, apply relabeling and filtering and then proxy it to another <code>remote_write</code> systems.
The <code>vmagent</code> can be configured to encrypt the incoming <code>remote_write</code> requests with <code>-tls*</code> command-line flags.
Additionally, Basic Auth can be enabled for the incoming <code>remote_write</code> requests with <code>-httpAuth.*</code> command-line flags.</p>

<h3 id="how-to-collect-metrics-in-prometheus-format">How to collect metrics in Prometheus format</h3>

<p>Pass the path to <code>prometheus.yml</code> to <code>-promscrape.config</code> command-line flag. <code>vmagent</code> takes into account the following
sections from <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/">Prometheus config file</a>:</p>

<ul>
  <li><code>global</code></li>
  <li><code>scrape_configs</code></li>
</ul>

<p>All the other sections are ignored, including <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write">remote_write</a> section.
Use <code>-remoteWrite.*</code> command-line flags instead for configuring remote write settings.</p>

<p>The following scrape types in <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config">scrape_config</a> section are supported:</p>

<ul>
  <li><code>static_configs</code> - for scraping statically defined targets. See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#static_config">these docs</a> for details.</li>
  <li><code>file_sd_configs</code> - for scraping targets defined in external files aka file-based service discover.
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#file_sd_config">these docs</a> for details.</li>
  <li><code>kubernetes_sd_configs</code> - for scraping targets in Kubernetes (k8s).
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config">kubernetes_sd_config</a> for details.</li>
  <li><code>ec2_sd_configs</code> - for scraping targets in Amazon EC2.
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#ec2_sd_config">ec2_sd_config</a> for details.
<code>vmagent</code> doesn’t support <code>role_arn</code> config param yet.</li>
  <li><code>gce_sd_configs</code> - for scraping targets in Google Compute Engine (GCE).
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#gce_sd_config">gce_sd_config</a> for details.
<code>vmagent</code> provides the following additional functionality for <code>gce_sd_config</code>:
    <ul>
      <li>if <code>project</code> arg is missing, then <code>vmagent</code> uses the project for the instance where it runs;</li>
      <li>if <code>zone</code> arg is missing, then <code>vmagent</code> uses the zone for the instance where it runs;</li>
      <li>if <code>zone</code> arg equals to <code>"*"</code>, then <code>vmagent</code> discovers all the zones for the given project;</li>
      <li><code>zone</code> may contain arbitrary number of zones, i.e. <code>zone: [us-east1-a, us-east1-b]</code>.</li>
    </ul>
  </li>
  <li><code>consul_sd_configs</code> - for scraping targets registered in Consul.
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#consul_sd_config">consul_sd_config</a> for details.</li>
  <li><code>dns_sd_configs</code> - for scraping targets discovered from DNS records (SRV, A and AAAA).
See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#dns_sd_config">dns_sd_config</a> for details.</li>
</ul>

<p>File feature requests at <a href="https://github.com/VictoriaMetrics/VictoriaMetrics/issues">our issue tracker</a> if you need other service discovery mechanisms to be supported by <code>vmagent</code>.</p>

<p><code>vmagent</code> also support the following additional options in <code>scrape_config</code> section:</p>

<ul>
  <li><code>disable_compression: true</code> - for disabling response compression on a per-job basis. By default <code>vmagent</code> requests compressed responses from scrape targets
in order to save network bandwidth.</li>
  <li><code>disable_keepalive: true</code> - for disabling <a href="https://en.wikipedia.org/wiki/HTTP_persistent_connection">HTTP keep-alive connections</a> on a per-job basis.
By default <code>vmagent</code> uses keep-alive connections to scrape targets in order to reduce overhead on connection re-establishing.</li>
</ul>

<p>Note that <code>vmagent</code> doesn’t support <code>refresh_interval</code> option these scrape configs. Use the corresponding <code>-promscrape.*CheckInterval</code>
command-line flag instead. For example, <code>-promscrape.consulSDCheckInterval=60s</code> sets <code>refresh_interval</code> for all the <code>consul_sd_configs</code>
entries to 60s. Run <code>vmagent -help</code> in order to see default values for <code>-promscrape.*CheckInterval</code> flags.</p>

<h3 id="adding-labels-to-metrics">Adding labels to metrics</h3>

<p>Labels can be added to metrics via the following mechanisms:</p>

<ul>
  <li>Via <code>global -&gt; external_labels</code> section in <code>-promscrape.config</code> file. These labels are added only to metrics scraped from targets configured in <code>-promscrape.config</code> file.</li>
  <li>Via <code>-remoteWrite.label</code> command-line flag. These labels are added to all the collected metrics before sending them to <code>-remoteWrite.url</code>.</li>
</ul>

<h3 id="relabeling">Relabeling</h3>

<p><code>vmagent</code> supports <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config">Prometheus relabeling</a>.
Additionally it provides the following extra actions:</p>

<ul>
  <li><code>replace_all</code>: replaces all the occurences of <code>regex</code> in the values of <code>source_labels</code> with the <code>replacement</code> and stores the result in the <code>target_label</code>.</li>
  <li><code>labelmap_all</code>: replaces all the occurences of <code>regex</code> in all the label names with the <code>replacement</code>.</li>
  <li><code>keep_if_equal</code>: keeps the entry if all label values from <code>source_labels</code> are equal.</li>
  <li><code>drop_if_equal</code>: drops the entry if all the label values from <code>source_labels</code> are equal.</li>
</ul>

<p>The relabeling can be defined in the following places:</p>

<ul>
  <li>At <code>scrape_config -&gt; relabel_configs</code> section in <code>-promscrape.config</code> file. This relabeling is applied to target labels.</li>
  <li>At <code>scrape_config -&gt; metric_relabel_configs</code> section in <code>-promscrape.config</code> file. This relabeling is applied to all the scraped metrics in the given <code>scrape_config</code>.</li>
  <li>At <code>-remoteWrite.relabelConfig</code> file. This relabeling is aplied to all the collected metrics before sending them to remote …</li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://victoriametrics.github.io/vmagent.html">https://victoriametrics.github.io/vmagent.html</a></em></p>]]>
            </description>
            <link>https://victoriametrics.github.io/vmagent.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835152</guid>
            <pubDate>Tue, 14 Jul 2020 17:45:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Motivation Behind Digital Minimalism]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835093">thread link</a>) | @huhn
<br/>
July 14, 2020 | https://huhn.dev/my-motivation-behind-digital-minimalism/ | <a href="https://web.archive.org/web/*/https://huhn.dev/my-motivation-behind-digital-minimalism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    <div id="body">
      <section id="page-title">
        
      </section>


<section>
    
    
    <div>
        <p><strong>tl;dr</strong>: Digital minimalism allows me to regain lost control and increases my <a href="https://en.wikipedia.org/wiki/Quality_time">quality time</a> as well as time for hobbies and other interests.</p>
<hr>
<p><strong>What the hell?</strong></p>
<p>In general, people are incredulous when telling them that I do not own a smartphone. Even though a few people understand my intention, they would rarely commit doing the same. Therefore, I think I must explain my motivation behind digital minimalism a bit more precisely.</p>
<p>Not having a smartphone is just the first step for me. I want to avoid digital life as much as possible. If, however, digital life is unavoidable I consequently use open source software only. While this sounds as if I am making it unnecessarily difficult for myself, especially regarding my computer science studies, it is a great relief for me in various ways.</p>
<p>There are different levels of digital minimalism and everyone must find the right dose for themselves. Certainly, my way seems very radical, but small steps are sufficient to feel a change.</p>
<p><strong>You can do without</strong></p>
<p>As mentioned before, I do not own a smartphone. Also no e-book reader, no smart TV, no smart watch and certainly not a fucking smart fridge or anything else that does not need to be smart. I am just using a laptop, a desktop and a <a href="https://en.wikipedia.org/wiki/Dumbphone">dumbphone</a>. That is quite enough.</p>
<p>My laptop runs <a href="https://www.openbsd.org/">OpenBSD</a> and the desktop <a href="https://www.freebsd.org/">FreeBSD</a>. I am cautious to use only minimal programs and do almost everything directly from the terminal to reduce complexity and increase my productivity. The dumbphone is mainly used to be reachable in time critical emergencies.</p>
<p>Neither my work nor my university studies require any additional equipment. Life requires none at all. Hardly anyone used anything smart before the 2000s. It is amazing how smart devices are now almost indispensable for many people.</p>
<p><strong>Finally, control again</strong></p>
<p>Digital minimalism is not only about the devices you use or do not use, it is also the attitude of how you use them. I do not need social media and I also do not need the 387th account on a service where I am not the owner of my own data. If I register somewhere now, I have thought about it thoroughly before. Unfortunately, countless people lose track on how many services they are registered. Try to list all your online accounts yourself. You will probably soon notice that you cannot remember all of them.</p>
<p>Every service that you use online generates personal data that can be exploited. Therefore, I want to have control over my data and data flow.</p>
<p><strong>Get rid of the drug</strong></p>
<p>Over time, I realized how addicted I was. I was not only <a href="https://huhn.dev/decentralization-is-dead-long-live-decentralization/">dependent on the infrastructure of others</a>, but I was really hooked. In every free minute I picked up my smartphone and looked up what news there was in the world. First, I updated my Instagram feed, then Facebook and oh look, I got a new snap! The world was always available to me and I was always available to the world.</p>
<p>Not only have I wasted my time, but I have also lost the ability to concentrate. Constant interruptions caused my attention span to decrease. Besides losing time, I was manipulated by countless actors who wanted to monetize me.</p>
<p><strong>Open your eyes</strong></p>
<p>About 3 years ago, I made a radical break and I do not miss anything. I have closed almost all online accounts and sold all non-essential equipment. Just then I realized how screwed up this society is with its compulsion for self-expression and self-optimization. I never liked the whole nonsense, but I was just too glad to be a spectator.</p>
<p>A lot of people are too afraid that they would miss something if they got rid of social media, <a href="https://www.gwern.net/docs/culture/2010-dobelli.pdf">news</a> and so forth. This differs greatly from my experience. Just as long as you can keep scrolling and updating the feeds, you feel like you might miss something. Believe me, you will lose that fear, when you separate yourself from all of that.</p>
<p>I now enjoy the time when I am on the road and am not constantly available. When I do something with family and friends, they now get my full attention and I do not let myself be distracted by anything. The biggest gain for me personally was to get time for self-reflection. The time at the bus stop is no longer just another chance to satisfy the addiction, but now serves as time to reflect. To think about everything that is going on in my head at that moment.</p>

    </div>
</section>

    </div>        		
      
    </div></div>]]>
            </description>
            <link>https://huhn.dev/my-motivation-behind-digital-minimalism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835093</guid>
            <pubDate>Tue, 14 Jul 2020 17:41:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mathsteroids]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23834968">thread link</a>) | @todsacerdoti
<br/>
July 14, 2020 | http://www.mscroggs.co.uk/blog/55 | <a href="https://web.archive.org/web/*/http://www.mscroggs.co.uk/blog/55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.mscroggs.co.uk/blog/55</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834968</guid>
            <pubDate>Tue, 14 Jul 2020 17:31:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apollo GraphQL Releases Apollo Client 3, a Client-Side Data Graph Library]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23834708">thread link</a>) | @stemmlerjs
<br/>
July 14, 2020 | http://go.apollo.dev/c/ac3-release | <a href="https://web.archive.org/web/*/http://go.apollo.dev/c/ac3-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Today we’re thrilled to announce the <strong>official release of Apollo Client 3.0</strong>! This release is the culmination of 55 betas, 14 release candidates, and hundreds of resolved issues and merged pull requests over the past eleven months. Phew!</p>



<p>To everyone who’s tried out AC3 during this extended beta period, <em>thank you</em>. We couldn’t have reached this milestone without your continued feedback and support. And to everyone who’s been waiting for the official launch, we appreciate your patience. Yes, it really is finally here!</p>



<p><strong>Here’s a recap of what’s new, with links to related documentation:</strong></p>



<ul><li>A single, consolidated <code>@apollo/client</code> package<ul><li>Includes entry points like <code>@apollo/client/utilities</code> for efficient use <em>without</em> the core library</li></ul></li><li>New <code>InMemoryCache</code> APIs:<ul><li><a href="https://www.apollographql.com/docs/react/caching/garbage-collection/#cacheevict" target="_blank" rel="noreferrer noopener">Eviction of objects and fields</a></li><li><a href="https://www.apollographql.com/docs/react/caching/garbage-collection/#cachegc" target="_blank" rel="noreferrer noopener">Garbage collection</a></li><li>Configurable policies for <a href="https://www.apollographql.com/docs/react/caching/cache-configuration/#typepolicy-fields" target="_blank" rel="noreferrer noopener">types</a> and <a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/">fie</a><a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/" target="_blank" rel="noreferrer noopener">l</a><a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/">ds</a></li><li>Pagination helpers</li></ul></li><li>Improved <a href="https://www.apollographql.com/docs/react/local-state/local-state-management/" target="_blank" rel="noreferrer noopener">local state management</a></li><li>Expanded and refined UI reactivity:<ul><li><a href="https://www.apollographql.com/docs/react/local-state/reactive-variables/" target="_blank" rel="noreferrer noopener">Reactive variables</a></li><li>More reliable cache broadcast behavior</li><li>More predictable <code>FetchPolicy</code> enforcement</li></ul></li><li>Extensive internal refactoring</li></ul>



<p>Before diving into some of those features here, I’d like to talk a bit about Apollo Client’s cache-focused design philosophy, which informed just about everything that’s included in this release.</p>



<h2>The purpose of a GraphQL client library</h2>



<p>You can consume GraphQL with anything that makes an HTTP request, such as <code>fetch</code> in the browser or <code>curl</code> on the command line. Whichever tool you use, you get all the classic GraphQL benefits: fetching exactly the data you need, in exactly the shape you need, with a single network request.</p>



<p><em>But.</em> Modern client applications use <strong>caching</strong> extensively to improve performance and user experience. And generic HTTP caching just doesn’t work with GraphQL. Every time you request even slightly different data, your HTTP-cached value is invalidated, making it useless for an application of any complexity.</p>



<p>GraphQL data is inherently, well, <em>graphical</em>. And to support GraphQL data effectively, a cache needs to <em>reflect</em> that graphical structure. HTTP caching can’t do this, but a library like Apollo Client <em>can</em>. In our opinion, this is the most important functionality that a GraphQL client library can provide.</p>



<h3>The client-side data graph</h3>



<p>When Apollo Client fetches data from your server, it caches that data using a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-configuration/#data-normalization" target="_blank">normalized structure</a> that matches your GraphQL schema. By caching this data, <em>Apollo Client locally reconstructs a subset of your back-end data graph</em>. This means that the next time Apollo Client queries some of that same data, it can fetch it directly from the cache, <em>even if an entirely different query requests it</em>. The cache only falls back to contacting your remote server when local data is missing or invalidated. And like any other GraphQL server, the cache provides APIs to <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-configuration/#typepolicy-fields" target="_blank">define how types and fields are read and modified</a>.</p>



<p>Because the cache is integrated directly with Apollo Client, it knows exactly which queries use exactly which fields in your graph. Whenever a cached field’s value changes, Apollo Client automatically updates all of the queries that include that field. This makes the cache just as reactive as any other part of a modern web application.</p>



<p>It’s because of the cache-focused philosophy behind Apollo Client that we don’t think of it primarily as a library for executing GraphQL operations, but rather as <strong>a library for interacting with a client-side data graph</strong>.</p>



<h2>Feature Spotlight</h2>



<p>This is far from everything that’s new in AC3, but it’s some of what we’re most excited for you to try out in your application!</p>



<h3>Reactive variables</h3>



<p>A <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/local-state/reactive-variables/" target="_blank">reactive variable</a> is a value that registers a dependency when you read it, and later triggers re-reading whenever the value is updated. The concept has been around for decades, predating <a rel="noreferrer noopener" href="https://docs.meteor.com/api/reactive-var.html" target="_blank">Meteor’s <code>ReactiveVar</code> API</a> back in 2014. Reactive variables are a staple of reactive programming, and now they enable flexible new ways of storing local state in AC3.</p>



<p>When you modify a reactive variable created with the <code>makeVar</code> function, Apollo Client automatically updates every active query that depends on that variable’s value. This is similar to what happens whenever a field in the cache changes, <em>however</em>: reactive variables <em>aren’t in the cache</em>. That means they can hold data of any type and structure, and you can interact with them throughout your application without using GraphQL syntax.</p>



<p>As a company with a long history of creating and consuming reactive variable APIs, we genuinely believe that this addition to Apollo Client will have a transformative effect on local state management.</p>



<p>Here’s an example:</p>



<pre><code>

<span>import</span> <span>{</span>
  InMemoryCache<span>,</span>
  makeVar<span>,</span>
  gql<span>,</span>
  useQuery<span>,</span>
<span>}</span> <span>from</span> <span>"@apollo/client"</span>




<span>const</span> darkModeVar <span>=</span> <span>makeVar</span><span>(</span><span>false</span><span>)</span><span>;</span>

<span>const</span> cache <span>=</span> <span>new</span> <span>InMemoryCache</span><span>(</span><span>{</span>
  typePolicies<span>:</span> <span>{</span>
    Query<span>:</span> <span>{</span>
      fields<span>:</span> <span>{</span>
        
        
        
        <span>darkModeEnabled</span><span>(</span><span>)</span> <span>{</span>
          <span>return</span> <span>darkModeVar</span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span>



<span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> loading <span>}</span> <span>=</span> <span>useQuery</span><span>(</span>
    gql<span><span>`</span><span>query { darkModeEnabled @client }</span><span>`</span></span><span>,</span>
  <span>)</span><span>;</span>
  <span>return</span> loading <span>?</span> <span><span><span>&lt;</span><span>Loading</span></span><span>/&gt;</span></span> <span>:</span>
    <span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>{</span>data<span>.</span>darkModeEnabled <span>?</span> <span>"dark"</span> <span>:</span> <span>"light"</span><span>}</span></span><span>&gt;</span></span><span>...</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>;</span>
<span>}</span>





<span>function</span> <span>toggleDarkMode</span><span>(</span><span>)</span> <span>{</span>
  <span>darkModeVar</span><span>(</span><span>!</span><span>darkModeVar</span><span>(</span><span>)</span><span>)</span><span>;</span>
<span>}</span></code></pre>



<h3>Cache field policies</h3>



<p>You can define a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/" target="_blank">field policy</a> for any and every GraphQL field that appears in your cache. A field policy can include a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/#the-read-function" target="_blank"><code>read</code> function</a> that customizes what happens when the field is read from the cache, and a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/#the-merge-function" target="_blank"><code>merge</code> function</a> that customizes what happens when it’s written.</p>



<pre><code><span>const</span> cache <span>=</span> <span>new</span> <span>InMemoryCache</span><span>(</span><span>{</span>
  typePolicies<span>:</span> <span>{</span>
    Person<span>:</span> <span>{</span>
      fields<span>:</span> <span>{</span>
        name<span>:</span> <span>{</span>
          <span>read</span><span>(</span><span>name</span><span>)</span> <span>{</span>
            
            <span>return</span> name<span>.</span><span>toUpperCase</span><span>(</span><span>)</span><span>;</span>
          <span>}</span>
        <span>}</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre>



<p><strong>You can even do this for fields that aren’t in your schema!</strong> Such <a href="https://www.apollographql.com/docs/react/local-state/managing-state-with-field-policies/" target="_blank" rel="noreferrer noopener">local-only fields</a> are the basis for using AC3 to query both local and remote data simultaneously.</p>



<p>By defining all of this custom field logic in one place (the constructor of <code>InMemoryCache</code>), you avoid repeating code, and your teammates can interact with the types and fields you’ve configured <em>without</em> needing to understand how they’re stored or fetched.</p>



<p>After <a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/" target="_blank" rel="noreferrer noopener">reading the documentation</a>, you’ll have the tools to write your own field policies to handle use cases like:</p>



<ul><li>Default field values</li><li>Transforming or normalizing field values</li><li>Sorting and slicing lists</li><li>Exposing reactive variables as GraphQL fields</li><li>Using references to redirect to data elsewhere in the cache</li><li>Pagination (covered below as well)</li><li>…&nbsp;and much more!</li></ul>



<h3>Pagination helpers</h3>



<p>One of the most compelling use cases for a custom field policy is to handle <strong>paginated lists</strong> of data without baking any specific pagination logic into Apollo Client.</p>



<p>Even with field policies, though, it can be tricky to get pagination exactly right. With so many details to digest, you might want to start with one of our prewritten helper functions.</p>



<p>Here’s how you can consume search results from a Relay-friendly GraphQL server, such as the <a rel="noreferrer noopener" href="https://metaphysics-production.artsy.net/" target="_blank">Artsy search API</a>:</p>



<pre><code><span>import</span> <span>{</span> ApolloClient<span>,</span> InMemoryCache <span>}</span> <span>from</span> <span>"@apollo/client"</span><span>;</span>
<span>import</span> <span>{</span> relayStylePagination <span>}</span> <span>from</span> <span>"@apollo/client/utilities"</span><span>;</span>

<span>const</span> client <span>=</span> <span>new</span> <span>ApolloClient</span><span>(</span><span>{</span>
  uri<span>:</span> <span>"https://metaphysics-production.artsy.net/"</span><span>,</span>
  cache<span>:</span> <span>new</span> <span>InMemoryCache</span><span>(</span><span>{</span>
    typePolicies<span>:</span> <span>{</span>
      Query<span>:</span> <span>{</span>
        fields<span>:</span> <span>{</span>
          
          
          
          search<span>:</span> <span>relayStylePagination</span><span>(</span><span>[</span><span>"query"</span><span>]</span><span>)</span><span>,</span>
        <span>}</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>)</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>function</span> <span>BasquiatSearchResults</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> loading<span>,</span> fetchMore <span>}</span> <span>=</span> <span>useQuery</span><span>(</span>gql<span><span>`</span><span>
    query BasquiatQuery($afterCursor: string) {
      search(query: "basquiat", first: 10, after: $afterCursor) {
        edges {
          node {
            displayLabel
          }
        }
        pageInfo {
          endCursor
        }
      }
    }
  </span><span>`</span></span><span>)</span><span>;</span>

  <span>if</span> <span>(</span>loading<span>)</span> <span>return</span> <span>&lt;</span>Loading <span>/</span><span>&gt;</span><span>;</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span>div<span>&gt;</span>
      <span>&lt;</span>ul<span>&gt;</span>
        <span>{</span>data<span>.</span>search<span>.</span>edges<span>.</span><span>map</span><span>(</span><span>edge</span> <span>=&gt;</span> <span>(</span>
          <span>&lt;</span>li<span>&gt;</span><span>{</span>edge<span>.</span>node<span>.</span>displayLabel<span>}</span><span>&lt;</span><span>/</span>li<span>&gt;</span>
        <span>)</span><span>)</span><span>}</span>
      <span>&lt;</span><span>/</span>ul<span>&gt;</span>
      <span>&lt;</span>input
        <span>type</span><span>=</span><span>"button"</span>
        value<span>=</span><span>"load more"</span>
        onClick<span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>fetchMore</span><span>(</span><span>{</span>
          variables<span>:</span> <span>{</span>
            afterCursor<span>:</span> data<span>.</span>search<span>.</span>pageInfo<span>.</span>endCursor<span>,</span>
          <span>}</span><span>,</span>
          
          
        <span>}</span><span>)</span><span>}</span>
      <span>/</span><span>&gt;</span>
    <span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre>



<p>If you’ve ever read Relay’s <a rel="noreferrer noopener" href="https://relay.dev/graphql/connections.htm" target="_blank">GraphQL Cursor Connections specification</a>, you know how complex Relay pagination can be, so it’s a big help to capture that complexity in a single helper function.</p>



<blockquote><p>If you find your own field policies becoming repetitive, don’t forget that you can reuse logic! Write a helper function that generates a generic field policy, and that takes parameters for customization.</p></blockquote>



<p>Following this release, we’ll continue collecting useful cache policy helper functions like <code>offsetLimitPagination</code> and <code>relayStylePagination</code> in <code>@apollo/client/utilities</code>. Feel free to use them directly in your own code, or adapt them to your own specific needs!</p>



<h2>Release FAQ</h2>



<h3>How do I get started?</h3>



<p>If you have an existing application that uses Apollo Client 2.x, check out the <a href="https://www.apollographql.com/docs/react/migrating/apollo-client-3-migration/" target="_blank" rel="noreferrer noopener">migration guide</a> and refreshed <a href="https://www.apollographql.com/docs/react/" target="_blank" rel="noreferrer noopener">documentation</a>, as certain concepts and interfaces have changed. We’ve worked hard to ensure that every required change is a <em>positive</em> one that makes logical sense and leaves you feeling better about your application and its data.</p>



<p>If you’re brand new to Apollo Client, <a href="https://www.apollographql.com/docs/react/get-started/" target="_blank" rel="noreferrer noopener">get started here</a>!</p>



<h3>Is AC3 a complete rewrite of Apollo Client?</h3>



<p>No. We care deeply about providing a pleasant migration between software versions, and the majority of 2.x functionality remains in 3.0. You can <a href="https://www.apollographql.com/docs/react/migrating/apollo-client-3-migration/" target="_blank" rel="noreferrer noopener">migrate to AC3</a> now and incrementally adopt its features on your own timeline. Note that some 2.x features (such as local resolvers) are now officially deprecated.</p>



<p>Even though it <em>isn’t</em> a rewrite, AC3 includes features that needed a while to bake. As one example, the new <a href="https://www.apollographql.com/docs/react/caching/garbage-collection/#cacheevict" target="_blank" rel="noreferrer noopener"><code>cache.evict</code> API</a> (<a href="https://github.com/apollographql/apollo-client/pull/5310" target="_blank" rel="noreferrer noopener">#5310</a>) enables you to remove objects and individual fields from the cache. Initial versions of this feature made it possible to leave the cache in a broken state after evicting critical data. To address …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://go.apollo.dev/c/ac3-release">http://go.apollo.dev/c/ac3-release</a></em></p>]]>
            </description>
            <link>http://go.apollo.dev/c/ac3-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834708</guid>
            <pubDate>Tue, 14 Jul 2020 17:13:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Integrals with the Overshooting Method]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23834678">thread link</a>) | @R3G1R
<br/>
July 14, 2020 | https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas | <a href="https://web.archive.org/web/*/https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2><img src="https://mathvault.ca/wp-content/uploads/Overshooting.jpg" alt="Integration Series — The Overshooting Method" width="800" height="444" title="Overshooting" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20444'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Overshooting.jpg"></h2><p>Hey! Greeting from a bunch of&nbsp;<em>post-April-Fool bunnies</em>&nbsp;who never managed&nbsp;to get their modules published on time — because they were simply too busy eating <em>Easter eggs</em> and <em>shooting for the moon</em>. &nbsp;🙂</p><p>Moving onto a more serious topic though, if you’re currently into&nbsp;(or have been into) this thing called <a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Derivative_and_Integral" target="_blank" rel="noopener noreferrer"><strong>integral calculus</strong></a>, you might know from first-hand experience&nbsp;that integration in general is no easy task. After all, most of us&nbsp;spend at least a semester honing different methods of integration, which include — among others —&nbsp;the&nbsp;techniques&nbsp;of&nbsp;<strong>Substitution</strong>, <strong>Partial Fraction</strong> and I<strong>ntegration By Parts</strong>.</p><p>In what follows though, we will share with you a powerful technique for&nbsp;finding <strong>antiderivatives</strong>&nbsp;— possibly without paper and pen. We call&nbsp;this technique&nbsp;the <strong>Overshooting Method</strong>, which — as we shall see later — can even be just as efficient as several <strong>standard integration techniques</strong> combined.<span id="more-5619"></span></p><h2 id="basic"><span id="The_Overshooting_Method_%E2%80%94_Basic_Ideas"></span><a href="#toc">The Overshooting Method — Basic Ideas</a><span></span></h2><p>So what is this <em>marvelous</em> technique you ask? Well, the short answer is that it&nbsp;can be found&nbsp;in the header image above. What? <strong>Overshooting</strong>, of course! 🙂</p><p>More specifically, given a function $f$, the <strong>Overshooting Method</strong> consists in finding an antiderivative of $f$ first by&nbsp;<em>guessing</em> a <strong>potential candidate</strong>, and then checking to see how <em>close</em>&nbsp;the candidate&nbsp;<em>differentiates</em> to $f$.</p><p><span>In the event where&nbsp;the&nbsp;derivative is off, but <em>only</em> by an <strong>additional term</strong></span><span>&nbsp;or a </span><strong>multiple</strong><span>, then additional steps can be implemented to correct this discrepancy, thereby transforming a&nbsp;potential candidate into a <em>valid</em> antiderivative of $f$.</span></p><p>All right. That’s about as intuitive and accurate as it gets. In <strong>formal terms</strong> though, this is&nbsp;what the&nbsp;technique would look like <em>in a nutshell</em>:</p><div id=""><p>Theorem 1 — The Overshooting Method</p><div><p>Given a function $f$ defined on an interval $I$, if there exists another function $F^*$ such that:</p><ul><li>$(F^*)’ = kf$ on $I$ for some <em>non-zero</em> number $k$ (i.e., $F^*$ is off by a <strong>multiple</strong>), then the function $\dfrac{F^*}{k}$ constitutes&nbsp;a&nbsp;valid&nbsp;antiderivative of $f$ on $I$.</li><li>$(F^*)’=f + g$ on $I$ for some function $g$, with $\displaystyle \int g$ being one of its own antiderivatives on $I$ (i.e., $F^*$ is off by a <strong>term</strong> that is itself <em>antidifferentiable</em>), then the function $\displaystyle F^* – \int g$ constitutes a valid antiderivative of $f$ on $I$.</li></ul></div></div><p>OK. Enough of the <a href="https://mathvault.ca/math-glossary/">mathematical jargon</a>? Let’s move on to how we can apply the Overshooting Method to integrate all kinds of functions then!</p><h2 id="multiple"><span id="The_Overshooting_Method_%E2%80%94_Adjusting_for_Multiples"></span><a href="#toc">The Overshooting Method — Adjusting for Multiples</a><span></span></h2><p>As it turns out, when a potential antiderivative&nbsp;is off by <em>only</em> a <strong>multiple</strong>, it’s not hard to readjust it so as to produce a valid antiderivative. In fact, learning to adjust for a multiple paves the way for more complex applications of the Overshooting Method, which can take a bit more<em>&nbsp;insight</em> and&nbsp;<em>ingenuity</em> to be executed elegantly.</p><p>With that in mind, here are 16 examples illustrating how the Overshooting Method can be used to integrate certain <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/#Key_Functions" target="_blank" rel="noopener noreferrer"><strong>elementary functions</strong></a> with ease. These include a good chunk of <a href="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/#Trigonometric_Functions" target="_blank" rel="noopener noreferrer">trigonometric functions</a>, exponential functions, power functions and trig-substitution functions.</p><h3 id="trig"><span id="Trigonometric_Functions"></span><a href="#toc">Trigonometric Functions</a><span></span></h3><h4 id="cos"><span id="Cosine_Functions"></span><a href="#toc">Cosine Functions</a><span></span></h4><p>To find an antiderivative of a function like $6\cos (2x+4)$, for instance, we start by noticing that since this&nbsp;function&nbsp;behaves very much like $\cos x$, we can try to integrate it&nbsp;<em>as if</em> we were dealing with&nbsp;$\cos x$. With this insight, the idea of&nbsp;$\sin (2x+4)$ being a <em>potential</em> antiderivative of&nbsp;$6\cos (2x+4)$ naturally comes to mind.</p><p>Before we move on though, let’s check&nbsp;how well this idea works out:</p><p>\begin{align*}[\sin (2x+4)]’ &amp; =\cos (2x+4)(2x+4)’ \\ &amp; = 2\cos (2x+4)= \frac{6\cos (2x+4)}{3} \end{align*}</p><p>So, $\sin (2x+4)$ is <em>off</em> by a multiple of $\dfrac{1}{3}$ as a result of <a href="https://mathvault.ca/chain-rule-derivative/">chain rule</a>. To get rid this multiple, we multiply our <em>potential antiderivative</em> by $3$, yielding that:</p><p>\begin{align*}\displaystyle [3\sin (2x+4)]’ &amp; =3\, [\sin (2x+4)]’\\ &amp; = 3\, \frac{6\cos (2x+4)}{3} \\ &amp; = 6\cos (2x+4) \qquad (\text{for all } x \in \mathbb{R}) \end{align*}</p><p>Hence, $\displaystyle \int&nbsp;6\cos (2x+4)\, dx = 3 \sin (2x+4) + C$ for all $x \in \mathbb{R}$ — as desired.</p><h4 id="sin"><span id="Sine_Functions"></span><a href="#toc">Sine Functions</a><span></span></h4><p>How about a function such as $\pi \sin (10x)$? Well, we can always begin by pulling&nbsp;the <em>coefficient</em> $\pi$ outside the integral:</p><p>$$ \int \pi \sin (10x)\, dx = \pi \int \sin (10x)\, dx$$</p><p>Presumably, since $\sin (10x)$ behaves very much like $\sin x$, the first potential antiderivative that comes to mind would be $-\cos (10x)$. To test it, we need to see what it <em>actually</em> differentiates to:</p><p>$$ [- \cos (10x)]’ = \sin (10x) (10x)’ = 10 \sin(10x) $$</p><p>This means that our candidate is off by a multiple of $10$. Dividing it however&nbsp;by $10$ yields that:</p><p>\begin{align*} \left(\frac{- \cos (10x)}{10}\right)’ &amp; = \frac{1}{10}\, [- \cos (10x)]’ \\ &amp;= \frac{1}{10} \, [10 \sin(10x)] \\ &amp; = \sin (10x) \qquad (\text{for all }x \in \mathbb{R})\end{align*}</p><p>which is exactly what we needed. Putting everything together, we get that&nbsp;$\displaystyle&nbsp;\int \pi \sin (10x)\, dx = \pi \int \sin (10x)\, dx $ $\displaystyle = \pi \, \frac{- \cos (10x)}{10} + C$ for all $x \in \mathbb{R}$.</p><h4 id="sec"><span id="Secant_Functions"></span><a href="#toc">Secant Functions</a><span></span></h4><p>For functions such as $\displaystyle \dfrac{1}{2} \sec^2 (4-x)$, we begin by pulling out the <em>extraneous</em> coefficent:</p><p>$$ \int \dfrac{1}{2} \sec^2 (4-x) \, dx= \dfrac{1}{2}&nbsp;\int \sec^2 (4-x) \, dx $$</p><p>Here, since $\sec^2 (4-x)$ behaves very much like $\sec^2 x$, we choose $\tan (4-x)$ as a potential antiderivative to start with. To be sure, we actually have that:</p><p>$$ [\tan (4-x)]’ = – \sec^2 (4-x) $$</p><p>which means that we are off by a <em>negative sign</em>. In this case, simply <em>negating</em>&nbsp;our candidate function&nbsp;would do the trick:</p><p>$$&nbsp;[-\tan (4-x)]’ = \sec^2 (4-x) $$</p><p>Therefore,</p><p>\begin{align*} \int&nbsp;\dfrac{1}{2} \sec^2 (4-x) \, dx &amp; = \dfrac{1}{2}&nbsp;\int \sec^2 (4-x) \, dx \\ &amp; = \frac{1}{2}\, &nbsp;[-\tan (4-x)] + C\end{align*}</p><p>(<strong>Bonus</strong>: Can you figure out what is the <em>largest</em> domain under which this equality holds? 🙂 )</p><h4 id="sectan"><span id="SecantTangent_Functions"></span><a href="#toc">Secant-Tangent Functions</a><span></span></h4><p>For functions such as $3 \sec (2x+ \pi) \tan (2x+ \pi)$, we begin by noticing that since this falls into the family of $\sec x \tan x$, a potential antidervative that comes to mind would be $\sec (2x+ \pi)$. To be sure, we have that:</p><p>\begin{align*} &nbsp;[\sec (2x + \pi)]’ &amp; = \sec (2x+\pi) \tan (2x+\pi) (2x+\pi)’ \\ &amp; = 2 \sec (2x+\pi) \tan (2x+\pi) \end{align*}</p><p>So almost there, except that we need to have $3$ as our <strong>leading coefficient</strong> instead of $2$, and a bit of reflection shows that multiplying our candidate&nbsp;by $\dfrac{3}{2}$ would do:</p><p>\begin{align*} &nbsp;\left( \frac{3}{2}\sec (2x + \pi) \right)’ &amp; = \frac{3}{2} \, 2 \sec (2x+\pi) \tan (2x+\pi) \\ &amp; = 3 \sec (2x+\pi) \tan (2x+\pi) \end{align*}</p><p>And that’s a <em>homerun</em>! Hence $\displaystyle \int&nbsp;3 \sec (2x+ \pi) \tan (2x+ \pi) \, dx =$ $\displaystyle \frac{3}{2}\sec (2x + \pi) + C$ (where $2x + \pi \ne \frac{\pi}{2} + k\pi$ for some <em>integer</em> $k$).</p><h4 id="csc"><span id="Cosecant_Functions"></span><a href="#toc">Cosecant Functions</a><span></span></h4><p>For functions like $-6 \csc^2 (5x-4)$, we start by noticing that since it pretty much behaves like $\csc^2 x$ (which antidifferentiates to $-\cot x$ — by the way), the idea of $-\cot (5x-4)$ being one of its&nbsp;antiderivatives becomes more than a <em>remote reality</em>. However, we need to&nbsp;verify this idea in practice:</p><p>$$[-\cot (5x-4)]’= \csc^2 (5x-4) (5x-4)’ = 5 \csc^2 (5x-4) $$</p><p>To correct the leading coefficient from $5$ to $-6$, we multiply our guess by $\dfrac{-6}{5}$, yielding that:</p><p>\begin{align*}&nbsp;\left( \frac{-6}{5} [- \cot (5x-4)] \right)’ &amp; = \frac{-6}{5} \, [5 \csc^2 (5x-4)] \\ &amp; = -6&nbsp;\csc^2 (5x-4)\end{align*}</p><p>Done! Hence $\int -6 \csc^2 (5x-4) \, dx =$ $\frac{-6}{5}\, [- \cot (5x-4)] + C =$ $\frac{6}{5} \cot (5x-4) +C\,$ (where $5x-4 \ne k \pi$ for some integer $k$).</p><h4 id="cot"><span id="Cotangent_Functions"></span><a href="#toc">Cotangent Functions</a><span></span></h4><p>OK. What about $\cot (2x-e)$? Let’s see… looking at the <strong>table of integrals</strong>, we see that $\cot x$ integrates to $\ln |\sin x|$, which suggests that $\ln |\sin (2x-e)|$ might work out very well as a candidate. Let’s check what it differentiates to:</p><p>$$ \left[\ln |\sin (2x-e)|\right]’ = \frac{\cos(2x-e)}{\sin (2x-e)}(2x-e)’=&nbsp;2\cot (2x-e)$$</p><p>Pretty close! Because in thise case, dividing both sides of the equation by $2$ would do:</p><p>$$ \left[\frac{1}{2}\ln |\sin (2x-e)| \right]’ = \cot (2x-e)$$</p><p>Therefore, $\displaystyle \int \cot (2x-e) \, dx =&nbsp;\frac{1}{2}\ln |\sin (2x-e)| + C$ (where $2x-e \ne k\pi$ for some integer $k$).</p><h3 id="exp"><span id="Exponential_Functions"></span><a href="#toc">Exponential Functions</a><span></span></h3><h4 id="natural"><span id="Natural_Base"></span><a href="#toc">Natural Base</a><span></span></h4><p>For functions such as $\displaystyle -5.6e^{-2x+4}$, once we notice its <em>similarity</em> with $\displaystyle e^x$, trying out $\displaystyle e^{-2x+4}$ becomes our <em>first line of attack</em>:</p><p>$$(e^{-2x+4})’=e^{-2x+4} \, (-2x+4)’ = -2 e^{-2x+4} $$</p><p>Now, multiplying both sides by $\dfrac{5.6}{2}$ yields:</p><p>$$\left( \frac{5.6}{2} \, e^{-2x+4} \right)’=\frac{5.6}{2} (-2 e^{-2x+4}) = -5.6 e^{-2x+4}$$</p><p>And that’s it! Hence $\displaystyle \int -5.6e^{-2x+4} \ dx = \frac{5.6}{2}(e^{-2x+4}) + C$ (for all $x \in \mathbb{R}$).</p><h4 id="arbitrary"><span id="Arbitrary_Bases"></span><a href="#toc">Arbitrary Bases</a><span></span></h4><p>So that was for the <strong>natural base</strong> $e$. For exponential functions of other bases like $34 \pi^{3x-1}$, we can always start by taking out the <em>annoying</em> leading coefficient:</p><p>$$ \int 34 \pi^{3x-1} \, dx = 34 \int \pi^{3x-1} \, dx$$</p><p>Now, what function could possibly <em>differentiate</em> to $\displaystyle&nbsp;\pi^{3x-1}$ ? Out of curiosity, let’s just try the function <em>itself</em>:</p><p>$$\left(\pi^{3x-1}\right)’ = \pi^{3x-1} \ln \pi \, (3x-1)’ = (3 \ln \pi) \pi^{3x-1}$$</p><p>In which case, all that’s left to do is to <em>divide both sides</em> by $3 \ln \pi$:</p><p>$$\left(\frac{\pi^{3x-1}}{3 \ln \pi}\right)’ = \pi^{3x-1}$$</p><p>yielding that $\displaystyle \int 34 \pi^{3x-1} \, dx =$ $\displaystyle 34 \int \pi^{3x-1} \, dx =$ $\displaystyle 34 \, \frac{\pi^{3x-1}}{3 \ln \pi} +C\,$ (for all $x \in \mathbb{R}$).</p><h3 id="power"><span id="Power_Functions"></span><a href="#toc">Power Functions</a><span></span></h3><h4 id="root"><span id="Square_Root_Functions"></span><a href="#toc">Square Root Functions</a><span></span></h4><p>Here’s another one for you: &nbsp;$e\sqrt{7x-9}$. <em>Strange</em> huh?</p><p>Actually, by inspection, this really just looks like $\sqrt{x}$, so let’s try out $\displaystyle \frac{(7x-9)^{\frac{3}{2}} }{\frac{3}{2}}$:</p><p>$$ \left(&nbsp;\frac{(7x-9)^{\frac{3}{2}} }{\frac{3}{2}} \right)’= \sqrt{7x-9}\, (7x-9)’ = 7 \sqrt{7x-9}$$</p><p>Here, we need to turn the $7$ into a $\displaystyle e$, and&nbsp;a bit of thought reveals&nbsp;that multiply both sides by $\dfrac{e}{7}$ would do the trick:</p><p>$$\left( …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas">https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/integration-overshooting-method/#The_Overshooting_Method_%E2%80%94_Basic_Ideas</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834678</guid>
            <pubDate>Tue, 14 Jul 2020 17:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Run a Live Coding Stream on Twitch Using OBS]]>
            </title>
            <description>
<![CDATA[
Score 450 | Comments 170 (<a href="https://news.ycombinator.com/item?id=23834153">thread link</a>) | @jordanlewis
<br/>
July 14, 2020 | https://jordanlewis.org/posts/twitch-live-coding/ | <a href="https://web.archive.org/web/*/https://jordanlewis.org/posts/twitch-live-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
		

		<section>
    <div>
      <p><img src="https://jordanlewis.org/images/stream/streaming-desk.jpg" alt="Stream software picture"></p>
<p>If you’re reading this post, you might be interested in trying your hand at
live coding on stream, as a way of sharing your projects in a more relatable,
immediate way than a polished blog post, teaching others about programming, or
just as a way to have fun. I think that live coding and streams in general are
an interesting possible future form of both education and entertainment, and if
you’re contemplating starting your own stream, I sincerely hope that you do it.</p>
<p>This month marks the 6 month anniversary of the first stream on <a href="https://twitch.tv/large__data__bank">LARGE DATA
BANK</a>, my Twitch live coding channel. It’s
grown from a one-off Friday experiment into a regularly scheduled part of my
life, a community of dozens of wonderful regular viewers and chatters, and
an activity that’s one of the top things I look forward to doing every week.</p>
<p>I’ve learned a lot along the way, and this detailed guide to the way I’ve
set up my stream is my attempt at stepping back and sharing those learnings in
the hopes of inspiring others to try this awesome hobby for themselves. I hope
it’s useful for you as you start your own journey into streaming.</p>
<p>If you have any questions that aren’t answered in this blog post, I’m more than
happy to answer them <a href="https://twitter.com/JordanALewis">on Twitter</a> or
<a href="https://jordanlewis.org/">elsewhere online</a>.</p>
<p>Also, please send me a follow on <a href="https://largedatabank.com/">Twitch</a> and
<a href="https://twitter.com/JordanALewis">Twitter</a> for stream notifications! I stream
every Friday at 3 PM ET, and most Sundays at some time in the afternoon.</p>
<nav id="TableOfContents">
  <ul>
    <li><a href="#intro">Intro</a></li>
    <li><a href="#obs-configuration">OBS configuration</a>
      <ul>
        <li><a href="#scenes">Scenes</a></li>
        <li><a href="#video">Video</a></li>
        <li><a href="#audio">Audio</a></li>
        <li><a href="#streaming-to-twitch-finally">Streaming to Twitch (finally)</a></li>
      </ul>
    </li>
    <li><a href="#stream-alerts">Stream Alerts</a>
      <ul>
        <li><a href="#sound-in-stream-alerts">Sound in Stream Alerts</a></li>
      </ul>
    </li>
    <li><a href="#channel-setup">Channel setup</a>
      <ul>
        <li><a href="#stream-category-and-tags">Stream Category and Tags</a></li>
        <li><a href="#panels">Panels</a></li>
        <li><a href="#emotes">Emotes</a></li>
        <li><a href="#banner-image">Banner image</a></li>
        <li><a href="#saving-videos">Saving Videos</a></li>
      </ul>
    </li>
    <li><a href="#chatbot">Chatbot</a></li>
    <li><a href="#becoming-a-twitch-affiliate">Becoming a Twitch Affiliate</a></li>
    <li><a href="#shoutouts">Shoutouts</a></li>
  </ul>
</nav>


<p>Whatever your reasons for wanting to try streaming, there’s quite a bit of setup
that you’ll need to do up front to try it out that can feel daunting. Everyone
has to go through this initial setup period, though, and so can you. You got
this!</p>
<p>The most important part of this post is the
<a href="#obs-configuration">section</a> about
<a href="https://obsproject.com/">OBS</a>, which is the awesome, cross-platform, free and
open source streaming software that most of the community uses. OBS will be
your best friend on your streaming journey! You will use it to control your
webcam, desktop, audio, and every other element that goes into the final
product of your livestream.</p>
<p>The rest of the post focuses on configuration that’s more specific to Twitch.
I like to use Twitch because I like the culture that’s developed there over
time, but plenty of people think that YouTube Live is more appropriate for
professional content. I’m not too familiar with YouTube Live, but most of the
discussion about OBS should apply the same for YouTube as it does for Twitch:
the main difference is that you’ll configure OBS to send to your YouTube
account instead of Twitch in Stream settings.</p>
<blockquote>
<p><strong><em>Yo!</em> If you’re trying to set up your very first stream</strong>, you really
don’t need most of the stuff in this guide, which represents what I’ve built
gradually over the past 6 months, stream by stream. My recommendation for the
livecoding-curious is to try streaming with a bare-bones setup, to see how
you like it, before investing in expensive gear or diving into hours of
configuration and asset creation. You can accomplish this in several hours
over a weekend. Set up a single scene in OBS with your captured desktop as
the background and your webcam in the corner, with your microphone configured
under Mic/Aux. That’s all you need: a simple setup for streaming your coding
is now yours! I’ll cover how to make that happen below, in the OBS
Configuration section. Just ignore most of the extra scenes and various bells
and whistles, and you’ll be good to go.</p>
</blockquote>

<p><a href="https://obsproject.com/">OBS</a> is where you’ll produce everything that your
viewers can see and hear on the live video, including your desktop, the camera
with your beautiful face on it, your voice, and any stream alerts, overlays,
text, or other information that you might want to show to your viewers.</p>
<p><img src="https://jordanlewis.org/images/stream/desktop2.png" alt="Desktop"></p>
<p>There’s a lot to cover with OBS and I’m not going to try to explain all of it,
so I’ll just talk about what’s worked for me. To make something that suits you,
you’ll need to flex your creative muscles! You can use the ideas here as a
starting place, but you’ll need to dive into OBS and play around: everyone’s
setup is going to be different.</p>
<h2 id="scenes">Scenes <a href="#scenes" arialabel="Anchor"><i data-feather="link-2"></i></a> </h2>
<p>A <em>scene</em> is OBS’s name for a particular layout of video and audio components
on a stream. Typically, you’ll see Twitch streamers stay on a single scene for
most of their stream: their game, desktop, or whatever their focus is. But it’s
handy to have a few extra ones for the intro and outro to your stream,
something that covers the screen for when you want to take a break, and so on.</p>
<p><img src="https://jordanlewis.org/images/stream/scenes.png" alt="Scenes popped out"></p>
<p>I have the main scenes that I use bound to global hotkeys, so I can switch
between them without having to click around in OBS. Unfortunately, sometimes
the hotkeys stop working during the stream - I’ve yet to figure out exactly why
this happens. If you happen to have this same problem and have found a
workaround, please let me know!</p>
<p>I have 6 primary scenes, and a couple of child scenes that are embedded in
several main scenes to deduplicate on-screen elements (the ones below the
<code>-----</code> in the picture). However, I spend the vast majority of my stream on one
of them: the Desktop scene.</p>
<h3 id="desktop">Desktop <a href="#desktop" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>This scene is the workhorse of the stream, and the one that’s active 95% of the
time. It consists of a full-screen, 1080p Display Capture source of my external
monitor. This is convenient because it leaves no ambiguity about what’s catpured
on the stream (it’s the whole monitor) and leaves my laptop screen free for
the OBS window, monitoring chat, and anything else that I want to look at while
streaming without having to show my viewers.</p>
<p>My <a href="https://jordanlewis.org/posts/desk-setup-2020">Desktop setup post</a> goes into more detail about the
way that I’ve set up my desk to have two monitors. It’s so convenient for the
stream that I’m hooked, and I’m not sure how I’d manage without.</p>
<p><img src="https://jordanlewis.org/images/stream/desktopscene.png" alt="Desktop Scene in OBS"></p>
<blockquote>
<p>A quick note on font size: you have to make your text editor font quite large
to make it legible for your viewers! It will take a little while to get used
to this. I use 26-point font in my editor, which provides only about 30
visible horizontal lines of code. This is next to nothing compared to the
amount of context you’re probably used to seeing while programming. This
hamstringing is worth it, though: the bigger your font, the more likely it is
that your viewers will be able to follow along with what you’re doing, stay
engaged, ask questions, learn, and have fun.</p>
<p>You should also try to remove as many distracting elements from your editor
and desktop as possible while streaming, to keep the focus on the code. For
me, this has meant disabling the Mac’s menubar and Dock, and removing the
vast majority of toolbars from my IDE.</p>
</blockquote>
<p>Besides the desktop capture source, which is at the back of the scene, I’ve
added several other sources:</p>
<ol>
<li>Face cam, which is a video source from my capture card (more information about the video sources in the <a href="#video">Video</a> section)</li>
<li>Keyboard cam, which is a video source from a webcam pointed at my keyboard.</li>
<li>A couple of text boxes, to show my most recent subscriber, follower, and
some on-stream commands. The text boxes are updated automatically by the
<a href="https://streamlabs.com/dashboard#/streamlabels">StreamLabels</a> app.</li>
<li>A web page source connected to Streamlabs Stream Alerts, which I’ll cover <a href="#stream-alerts">below</a>.</li>
</ol>
<p>I definitely didn’t start with all of these elements - it’s quite a lot of work
to tweak things just the way you want - but I’ve kept this configuration for the
past couple of months and I like the way it looks.</p>
<h3 id="whiteboard">Whiteboard <a href="#whiteboard" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>The whiteboard scene is meant to showcase my iPad full screen, allowing me to
draw things on stream to demonstrate ideas or concepts. I use the Concepts app
on the iPad along with an Apple Pencil for drawing, and it works pretty nicely.</p>
<p><img src="https://jordanlewis.org/images/stream/whiteboard.png" alt="Whiteboard scene"></p>
<p>I didn’t know how to fill up the space on the bottom left, since the iPad
doesn’t have a widescreen aspect ratio like my monitor does, so I put a picture
that my friend Aileen drew of me to make the stream a bit more visually
interesting!</p>
<p>This scene references the same facecam and alerts source as the Desktop scene.
You can definitely use DRY principles in OBS, just like software - but it does
get tricky to keep everything de-duplicated.</p>
<h3 id="ipad-green-screen-overlay">iPad Green Screen Overlay <a href="#ipad-green-screen-overlay" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>I also set up a “green screen” configuration for the iPad that I can overlay
over any other scene with a global hotkey. This gives me the ESPN football
announcer effect during my stream: I can draw on my iPad, and the lines will
appear overlayed on top of whatever else I have on stream at the time.</p>
<p>This is probably the most complex video element on my
stream, but OBS makes it pretty simple to set up. I added a Color Key filter
with a black background on top of the raw iPad video feed, set my drawing app
to have a black background, and tweaked the Color Key settings in OBS until
things looked right:</p>
<p><img src="https://jordanlewis.org/images/stream/colorkey.png" alt="iPad Color Key"></p>
<p>I don’t use this element as nearly as often as I’d like, but I think it’s
pretty neat. I recorded a <a href="https://www.youtube.com/watch?v=U4WJQmN1cSo">demo
video</a> of it if you’re curious for
how it looks - I also use it occasionally on the stream.</p>
<h3 id="selfie">Selfie <a href="#selfie" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>This is just a full-screen version of the facecam. I copied the name of the
scene from <a href="https://medium.com/@suzhinton/my-twitch-live-coding-setup-b2516672fb21">@noopkat’s
blog</a>.</p>
<p><img src="https://jordanlewis.org/images/stream/selfie.png" alt="Selfie scene"></p>
<p>I use this scene for “turn to the camera” moments, which I find really fun. I’ll
switch to the scene, look right at the camera, and talk for a bit before
switching back to the desktop view.</p>
<h3 id="starting-soon">Starting Soon <a href="#starting-soon" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>This scene goes on as soon as the stream turns on, until I’m ready to start
talking to the camera. I’ll usually start the stream a few minutes before the
time that I announced on Twitter for my stream, and leave it up until that time
comes (with a muted mic!).</p>
<p><img src="https://jordanlewis.org/images/stream/startingsoon.png" alt="Starting Soon scene"></p>
<p>I used a gif I found on the internet of someone typing, so people can tell that
the stream is live even though there’s nothing happening yet. There’s also music
during this “pre-roll”. I’ll talk about music and sound <a href="#audio">later</a>).</p>
<h3 id="brb">BRB <a href="#brb" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>I’ll put this scene on if I need to step away from the stream for a moment to
use the bathroom or whatever. I added a sound to …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordanlewis.org/posts/twitch-live-coding/">https://jordanlewis.org/posts/twitch-live-coding/</a></em></p>]]>
            </description>
            <link>https://jordanlewis.org/posts/twitch-live-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834153</guid>
            <pubDate>Tue, 14 Jul 2020 16:38:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snorkel AI: Putting Data First in ML Development]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23834116">thread link</a>) | @vincentschen
<br/>
July 14, 2020 | https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html | <a href="https://web.archive.org/web/*/https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>
                      Today I’m excited to announce Snorkel AI’s launch out of stealth!
                      Snorkel AI, which spun out of the Stanford AI Lab in 2019, was founded on two simple premises: first, that the labeled <b>training data</b>  machine learning models learn from is increasingly what determines the success or failure of AI applications.
                      And second, that we can do much better than labeling this data entirely by hand.
                  </p>
                  <p>
                      At the Stanford AI lab, the Snorkel AI founding team spent over four years developing new <b>programmatic</b> approaches to labeling, augmenting, structuring, and managing this training data.
                      We were fortunate to develop and deploy early versions of our technology with some of the world’s leading organizations like <a href="https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html">Google</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3329486.3329492">Intel</a>, <a href="https://arxiv.org/abs/1909.05372">Apple</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2666389920300192">Stanford Medicine</a>, resulting in <a href="https://www.snorkel.ai/technology#reference">over thirty-six peer-reviewed publications</a> on our findings; innovations in weak supervision modeling, data augmentation, multi-task learning, and more; inclusion in university computer science curriculums; and deployments in popular products and systems that you’ve likely interacted with in the last few hours.
                  </p>
                  <p>
                      Through all this academic tinkering and industry spelunking, we realized two things: first, that this concept of labeling and building training data programmatically, rather than by hand, had transformational potential to make machine learning more iterative, auditable, faster to deploy, and ultimately, more practical.
                      And second, that these ideas changed not just how you label training data, but so much of the entire lifecycle and pipeline of ML: how knowledge and feedback is injected; how models are constructed, trained, versioned, and monitored; how entire pipelines are developed iteratively; and how the full set of stakeholders in any ML deployment, from subject matter experts to ML engineers, are incorporated into the process.
                  </p>
                  <p>
                      In other words, we saw that this shift to programmatic training data required a top-to-bottom rewrite of the entire ML development and deployment process.
                      With the support of some amazing investors (Greylock, GV, In-Q-Tel, and others) and incredible early customers, we’ve spent the last year doing just this: building and deploying <a href="https://www.snorkel.ai/platform">Snorkel Flow</a>, an end-to-end platform to support this new vision of the ML process.
                  </p>
                  <h2>The Training Data Bottleneck</h2>
                  <p>
                      Snorkel Flow was motivated first and foremost by a growing realization that training data had become the key bottleneck in much of ML pipeline and AI application development.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png"></p><p>
                      <b>Today’s ML successes often rest on a hidden cost: massive, hand-labeled training datasets.</b>
                      In the last decade, we’ve seen a tectonic shift in AI and ML towards powerful but data-hungry representation learning models.
                      These models—often deep learning architectures—are not only more powerful at obviating traditionally manual development tasks like feature engineering and bespoke model design, but also have never been more accessible in the open source.
                      However, there’s no such thing as a free lunch: these models are highly complex, with tens to hundreds of millions of parameters, and they require massive labeled training datasets to learn from.
                      And, other than in special scenarios where labels are naturally derivative of existing processes, these training datasets need to be labeled by hand.
                  </p>
                  <p>
                      <b>The hand-labeled training data interface to ML has enabled tremendous progress, but is also ridiculously broken.</b>
                      Consider a simple example: a legal analyst at a bank wants to train a contract classification model, and wants to inject a simple heuristic into the ML model: that if “employment” is in the title, the contract should be labeled as an “Employment contract.”
                      Simple, right?
                      Not so.
                      Theoretically, to communicate this specific feature to a machine learning model via only labeling individual data points could require thousands of examples (roughly, inversely proportional to the sparsity of the feature space).
                      From this perspective, it’s like playing 20 questions rather than just communicating the answer directly—fine if you have a massive question-answer bank, but otherwise wholly impractical.
                  </p>
                  <p>
                      <b>Manually labeling training data is prohibitively expensive–especially when expertise and privacy are required.</b>
                      Building training datasets often requires <a href="http://nytimes.com/2018/11/25/business/china-artificial-intelligence-labeling.html">armies of human labelers</a> at massive cost and time expense.
                      For example, ImageNet—one of the foundational projects behind ML’s current explosive progress—took <a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/">over two years</a> to create.
                      However, labeling cats, dogs, stop signs, and pedestrians is one thing; labeling data like medical images, legal and financial contracts, government documents, user data, and network data requires <b>stringent privacy protections</b> and <b>subject matter expert labelers</b>.
                      This means for sectors like financial services, government, telecommunications, insurance, healthcare, and more, creating training data (and by extension, using ML) is either a hugely expensive on-premise activity—or more often, one that is just not feasible to tackle, let alone practical.
                  </p>
                  <p>
                      <b>Iterative development is not possible with hand-labeled data.</b>
                      From an engineering and data science perspective, manually labeled training data fundamentally breaks the ability to quickly iterate, which is absolutely essential in real world settings where input data, output goals, and annotation schema change all the time.
                      From a business perspective, training data is an expensive asset that can’t be reused across projects, can often depreciate to worthless overnight due to changing conditions or business goals, and that presents growing risks—everything from <a href="https://web.archive.org/web/20200703104247/https://cloud.google.com/ai-platform/data-labeling/docs">COVID-related delays</a> to <a href="https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai">issues of bias</a>.
                  </p>
                  <h2>A New Input Paradigm for ML: Programming with Data</h2>
                  <p>
                      With Snorkel Flow, rather than needing to hand-label any training data, users develop <b>programmatic operators</b> that label, augment, and build training data to drive the ML development process.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png"></p><p>
                      <b>Programmatically labeling and building training data.</b>
                      With Snorkel Flow, the idea is to instead communicate this domain knowledge directly via a programmatic operator like a <a href="https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly">labeling function</a>.
                      For example, our legal analyst could write a labeling function that labels documents as “Employment contracts” if the word “employment” is in the title, and otherwise abstains; or, a range of more complex and powerful labeling functions relying on internal knowlegebases, models, legacy heuristics, and more.
                      This approach of effectively programming ML with data is simple, direct, interpretable, modifiable, and agnostic to the model used (which is especially important given the ongoing Cambrian explosion of powerful new open source model architectures).
                  </p>
                  <p>
                      <b>The directness of rules with the flexibility of ML.</b>
                      Rule-based systems have long been used in industry for certain tasks—as an input, individual rules have the desirable property of being direct and interpretable.
                      However, rules can also be brittle, and lack the robustness, flexibility, and sheer power of ML approaches.
                      With Snorkel Flow, you get the best of both worlds: rules (and other interpretable resources) as inputs, and powerful ML models that generalize beyond these rules as the output.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png"></p><p>
                      <b>A more powerful yet weaker supervision.</b>
                      At the same time that this programmatic supervision is advantageous in several transformational ways, it is also messier and raises fundamental new technical challenges.
                      The labeling functions and other programmatic operators that users write will have varying unknown accuracies and expertise areas, will overlap and disagree with each other, and may be correlated in tangled and unknown ways.
                      We focused on the algorithmic and systems solutions to these issues over <a href="https://www.snorkel.ai/technology">four-plus years of research</a>, showing both empirically and theoretically that with the right techniques, these deep technical challenges can be overcome.
                      The result: training data that is as good as or better than hand-labeled data, and immensely more practical to create and maintain.
                  </p>
                  <p>
                      <b>Beyond labeling: data augmentation, slicing, monitoring, and more.</b>
                      In high-performance production ML, training data is about a lot more than labeling.
                      For example, data augmentation is a cornerstone technique wherein transformed copies of data (e.g. rotated or blurred images) are used to expand the sizes of training datasets, and make resulting models more robust.
                      Slicing or structuring training datasets into more or less important and difficult subsets is also a critical part of managing production ML. 
                      Finally, monitoring and adapting not just models but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html">https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html</a></em></p>]]>
            </description>
            <link>https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834116</guid>
            <pubDate>Tue, 14 Jul 2020 16:36:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SPA Doesn’t Need a Router]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23834010">thread link</a>) | @jerodsanto
<br/>
July 14, 2020 | https://forweb.dev/en/blog/drop-the-router/ | <a href="https://web.archive.org/web/*/https://forweb.dev/en/blog/drop-the-router/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>So&nbsp;you are building a&nbsp;client-side web app for that next big project and wondering: “Which router should I&nbsp;use?”. Here is&nbsp;the thing: you don’t need any, and you will understand why shortly.</p><h2>What is&nbsp;routing?</h2><p>The first interface for a&nbsp;user to&nbsp;access any website is&nbsp;their browser address bar. Even if&nbsp;your website is&nbsp;visited via a&nbsp;link or&nbsp;from bookmarks, for a&nbsp;user it&nbsp;still goes through the address bar. Change of&nbsp;the address leads to&nbsp;a&nbsp;change of&nbsp;the page.</p><p>Our application needs to&nbsp;determine from that URL which screen and in&nbsp;what state to&nbsp;show to&nbsp;the user.</p><figure><img src="https://forweb.dev/en/blog/drop-the-router/one-step-away.jpg" alt="“One step away” by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/one-step-away@2x.jpg 2x" width="1000" height="563"><figcaption>“One step away” by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>So, in&nbsp;a&nbsp;nutshell, routing is&nbsp;deriving the state from the input URL. Yes, that simple.</p><h2>Why is&nbsp;routing difficult then?</h2><p>When we&nbsp;scale our app, we&nbsp;split the state into many pieces. There are two reasons to&nbsp;do&nbsp;it:</p><ol><li>it&nbsp;helps to&nbsp;avoid cognitive overload;</li><li>it&nbsp;allows sharing the workload between several team members.</li></ol><p>Usually, we&nbsp;don’t need all the pieces at&nbsp;once, so&nbsp;we&nbsp;put them to&nbsp;different endpoints and storages. When a&nbsp;user opens the app, we&nbsp;reconstruct the required state from little pieces scattered all over the system. Moreover, some of&nbsp;the state pieces determine which subset of&nbsp;other pieces should be&nbsp;restored.</p><figure><img src="https://forweb.dev/en/blog/drop-the-router/state-reconstruction.jpg" alt="Example state reconstruction scheme, drawing by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/state-reconstruction@2x.jpg 2x" width="1000" height="563"><figcaption>Example state reconstruction scheme, drawing by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>Sometimes state reconstruction is&nbsp;simple. For example, when a&nbsp;user requests the login page, we&nbsp;should just give them the login page. Most of&nbsp;the time, though, this logic is&nbsp;a&nbsp;lot more complex, depending on&nbsp;the current context, system state, and business requirements.</p><p>The question is&nbsp;how much of&nbsp;this logic should we&nbsp;own, and how much could we&nbsp;generalize and delegate to&nbsp;routing via a&nbsp;framework or&nbsp;a&nbsp;library?</p><p>Naturally, we&nbsp;would prefer to&nbsp;delegate as&nbsp;much code as&nbsp;possible. There are different approaches to&nbsp;that. One of&nbsp;them would be&nbsp;to&nbsp;fully separate routing and business logic.</p><p>For instance, we&nbsp;could match a&nbsp;path to&nbsp;some handler function and pass query parameters to&nbsp;it. Then it&nbsp;will decide how to&nbsp;restore the state and what to&nbsp;show to&nbsp;the user.</p><p>It&nbsp;could look like this (🔀 is&nbsp;for routing, 🅱️️ is&nbsp;for business logic, ❇️ is&nbsp;for dependencies loading):</p><pre><code>🔀 Receive request path with parameters in&nbsp;it
    🔀 Determine handler for this path and separate parameters
        ❇️ Load user session
            🅱️ Check if&nbsp;the user is&nbsp;authenticated
        ❇️ Load user profile
            🅱️ Check if&nbsp;the user is&nbsp;authorized to&nbsp;use this handler
        ❇️️ Load the first item from the path with parameter
            🅱️ Check if&nbsp;it&nbsp;exists
            🅱️ Check if&nbsp;the user is&nbsp;authorized to&nbsp;use&nbsp;it
        ❇️️ Load the second item from the path with parameter
            🅱️ Check if&nbsp;it&nbsp;exists
            🅱️ Check if&nbsp;it&nbsp;is&nbsp;relevant to&nbsp;the first item
            🅱️️ Check if&nbsp;the user is&nbsp;authorized to&nbsp;use&nbsp;it
        🅱️️ ... (Other business logic)
    🔀 Return the combined result
</code></pre><p>After a&nbsp;while, we&nbsp;will notice that most of&nbsp;these handlers mainly consist of&nbsp;the same instructions&nbsp;— session loading and authentication check, for instance. Maybe we&nbsp;could separate all these checks into another layer to&nbsp;stop repeating the same thing all over again?</p><p>Paths are hierarchical by&nbsp;design, which can be&nbsp;used to&nbsp;simplify our code. Like, we&nbsp;can agree that all the authenticated paths start with <code>/user</code> — meaning we&nbsp;could match paths from left to&nbsp;right and apply different checks depending on&nbsp;where we&nbsp;are in&nbsp;the hierarchy right now.</p><p>Welcome to&nbsp;the concept of&nbsp;Routing Middleware. It&nbsp;is&nbsp;still business logic, but it&nbsp;also can’t be&nbsp;separated from paths structure. So&nbsp;it&nbsp;is&nbsp;still routing too.</p><p>Both routing and business logic? Too complicated! We&nbsp;wanted a&nbsp;clear separation to&nbsp;delegate as&nbsp;much routing code as&nbsp;possible. Instead, we&nbsp;got the opposite. Screw middleware then. Why don’t we&nbsp;just define the list of&nbsp;all the checks and dependencies for each route?</p><p>That would work, but we&nbsp;still need to&nbsp;provide context for those. For authentication and handler authorization it’s quite straightforward&nbsp;— we&nbsp;can identify the user from the named cookie passed in&nbsp;the request context. But what about data availability and access control? Do&nbsp;we&nbsp;need to&nbsp;invent an&nbsp;additional language to&nbsp;extract ids from the path? Or do we need to always name those ids using a naming convention to uniformly map ids to checks?</p><p>We&nbsp;also want to&nbsp;optimize things, so&nbsp;we&nbsp;need to&nbsp;define sequences or&nbsp;relations for dependencies loading and checks. And some of&nbsp;them could be&nbsp;done in&nbsp;parallel&nbsp;— that should be&nbsp;defined too. Do&nbsp;we&nbsp;need one more language? Or&nbsp;do&nbsp;we&nbsp;do&nbsp;it&nbsp;imperatively? Then how is&nbsp;it&nbsp;different from middlewares?</p><p>These questions make routing such a&nbsp;difficult task.</p><p>Should it&nbsp;be&nbsp;so&nbsp;hard, though? Maybe backend already solved all the problems, and frontend should repeat after it’s elder brother? It&nbsp;already does, but there are multiple important obstacles along the way.</p><h2>How is&nbsp;frontend routing different from backend routing?</h2><p>First, <strong>we&nbsp;usually can’t have all the logic on&nbsp;the client-side</strong>: data is&nbsp;stored on&nbsp;a&nbsp;remote server, and we&nbsp;need to&nbsp;check if&nbsp;data is&nbsp;still valid to&nbsp;perform the desired transition. An&nbsp;observant reader will note that the same problems exist on&nbsp;the backend: database requests are asynchronous. The problem&nbsp;is: asynchronous nature of&nbsp;data requests is&nbsp;conflicting with the synchronous nature of&nbsp;the core concept of&nbsp;the web&nbsp;— links.</p><p>By&nbsp;saying links are synchronous, I&nbsp;don’t mean they transfer you immediately to&nbsp;your target, rather that they don’t require writing any asynchronous javascript. The web platform already handles the links for&nbsp;us.</p><p>This takes&nbsp;us to&nbsp;the second point. <strong>We&nbsp;need to&nbsp;entertain users while they are waiting</strong>. Modern web apps try to&nbsp;behave more like native apps rather than websites of&nbsp;the past. To&nbsp;make transitions smooth and seamless, we&nbsp;handle link clicks with javascript implementing from scratch all the logic provided by&nbsp;the platform.</p><p>User falls for this little deception and assumes that all the required resources are already on&nbsp;their device, so&nbsp;there is&nbsp;no&nbsp;need to&nbsp;load the whole page from the server&nbsp;— it&nbsp;can be&nbsp;just shown. It&nbsp;could be&nbsp;a&nbsp;smooth transition, or&nbsp;skeleton&nbsp;UI, or&nbsp;just plain old loader&nbsp;— in&nbsp;any case, we&nbsp;need to&nbsp;show something immediately after user interaction. On&nbsp;the contrary, waiting for a&nbsp;response from the backend is&nbsp;handled by&nbsp;the platform.</p><p>Third, <strong>client-side logic requires request chains</strong>. We&nbsp;have to&nbsp;ask the server for the first data chunk, then decide to&nbsp;load one of&nbsp;the next chunks depending on&nbsp;the first, then load all the items from the list in&nbsp;the second chunk... Only after a&nbsp;long chain of&nbsp;async requests we&nbsp;finally can make the transition.</p><p>The backend also has dependent data requests, but they could be&nbsp;optimized with stored procedures or&nbsp;JOIN queries. The only attempt to&nbsp;do&nbsp;something similar for the frontend is&nbsp;GraphQL, but it&nbsp;comes with a&nbsp;lot of&nbsp;disadvantages (which are out of&nbsp;the scope of&nbsp;this article).</p><p>And the last one&nbsp;— on&nbsp;the frontend, we&nbsp;sometimes have <strong>virtual routes</strong>, meaning we&nbsp;have different screen states for the same path. Because, well, you filled the first two steps of&nbsp;that wizard form&nbsp;— so&nbsp;we&nbsp;need to&nbsp;show you the third one and not allow you to&nbsp;go&nbsp;to&nbsp;the fourth one.</p><h2>Why none of&nbsp;the popular routers solve the problem?</h2><p>For some unknown reason, most of&nbsp;the popular routing solutions for web frontend focus on&nbsp;the tip of&nbsp;the iceberg, while making some significant mistakes in&nbsp;core architecture design.</p><h3>Mistake #1: defining routes in&nbsp;the view layer</h3><figure><img src="https://forweb.dev/en/blog/drop-the-router/off-label.jpg" alt="“Off-label” by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/off-label@2x.jpg" width="1000" height="563"><figcaption>“Off-label” by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>As&nbsp;you already know, the routing process is&nbsp;heavily dependent on&nbsp;business logic. The only two cases when routing and view should collide are mapping resolved state to&nbsp;page and rendering links.</p><p>So&nbsp;there is&nbsp;no&nbsp;actual reason to&nbsp;use your view logic for routes definition. And when you do&nbsp;something without cause, you make your code difficult to&nbsp;understand and maintain.</p><p>It&nbsp;still works quite well on&nbsp;small apps, though, because they don’t have any complex or&nbsp;asynchronous business logic, and the only thing they need is&nbsp;a&nbsp;list of&nbsp;route-page pairs.</p><h3>Mistake #2: routing as&nbsp;a&nbsp;simple mapping from paths to&nbsp;pages</h3><figure><img src="https://forweb.dev/en/blog/drop-the-router/obvious.jpg" alt="“Obvious” by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/obvious@2x.jpg 2x" width="1000" height="563"><figcaption>“Obvious” by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>Some routers selling point is&nbsp;the declarative style of&nbsp;routes definition. Meaning the whole routing problem is&nbsp;just a&nbsp;key-value dictionary.</p><p>No, it’s not. It&nbsp;could&nbsp;be, but only in&nbsp;simple hello-world-ish cases, which get complex as&nbsp;soon as&nbsp;your app becomes one month old.</p><p>In&nbsp;general, it&nbsp;is&nbsp;a&nbsp;fully-fledged process with dependency loading, data processing, and decision-making. It&nbsp;is&nbsp;also full of&nbsp;side effects: from external dependencies and data loading to&nbsp;browser history management.</p><h3>Mistake #3: immediate transitions</h3><p>Let’s assume you are on&nbsp;a&nbsp;simple website with no&nbsp;javascript at&nbsp;all. When you click the link, are you immediately transitioned to&nbsp;your destination? No, even in&nbsp;this simple case, you have to&nbsp;wait until the next page is&nbsp;loaded.</p><p>Waiting for transitions is&nbsp;in&nbsp;the DNA of&nbsp;the web from day one. We&nbsp;got used to&nbsp;waiting after clicking the link, and we&nbsp;<strong>expect the next page to&nbsp;be&nbsp;loaded</strong>. This means it’s ok&nbsp;to&nbsp;wait because&nbsp;I requested my&nbsp;entire friend list, and that’s a&nbsp;lot of&nbsp;data, and I’m on&nbsp;2G&nbsp;internet in&nbsp;the middle of&nbsp;nowhere, so&nbsp;I totally understand.</p><p>A&nbsp;router should allow to&nbsp;transition out of&nbsp;the page, handle waiting time, then transition to&nbsp;the next page. That’s what browsers already do&nbsp;with websites, and the least we&nbsp;can do&nbsp;is&nbsp;not break&nbsp;it.</p><h3>Mistake #4: no&nbsp;place for dependencies or&nbsp;common behavior</h3><figure><img src="https://forweb.dev/en/blog/drop-the-router/ever-ready.jpg" alt="“Ever-ready” by&nbsp;Anna Zarubey" srcset="https://forweb.dev/en/blog/drop-the-router/ever-ready@2x.jpg 2x" width="1000" height="563"><figcaption>“Ever-ready” by&nbsp;<a href="https://t.me/anna_zarubey">Anna Zarubey</a></figcaption></figure><p>It&nbsp;is&nbsp;generally a&nbsp;combination of #2 and #3 but feels like something to&nbsp;be&nbsp;addressed explicitly.</p><p>Routers tend to&nbsp;work with pages as&nbsp;if&nbsp;the app already has everything it&nbsp;needs to&nbsp;display every page. And that may be&nbsp;true for a&nbsp;calculator, or&nbsp;some mini-game.</p><p>In&nbsp;reality, we&nbsp;have network-heavy applications, which require both data loading and a&nbsp;lot of&nbsp;javascript and styles to&nbsp;display&nbsp;it. And most of&nbsp;the users won’t even visit that one heavy page. So&nbsp;the most logical solution is&nbsp;to&nbsp;separate its resources from the rest of&nbsp;the app.</p><p>Now if&nbsp;we&nbsp;are going to&nbsp;separate that page, we&nbsp;have to&nbsp;put all the preconditions and dependencies inside of&nbsp;the page itself, but is&nbsp;it&nbsp;really where they belong? …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://forweb.dev/en/blog/drop-the-router/">https://forweb.dev/en/blog/drop-the-router/</a></em></p>]]>
            </description>
            <link>https://forweb.dev/en/blog/drop-the-router/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834010</guid>
            <pubDate>Tue, 14 Jul 2020 16:30:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Preoccupied with Occupations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833955">thread link</a>) | @hackernewsreadr
<br/>
July 14, 2020 | http://blogofjake.com/2020/07/14/preoccupied-with-occupations/ | <a href="https://web.archive.org/web/*/http://blogofjake.com/2020/07/14/preoccupied-with-occupations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Why do we see defeat and destruction in the occupations of cities but definition and duty in the occupations of men?</p>



<p>In both cases, occupations seize control of the occupied entity, and yet it is cursed in the first instance but celebrated in the second.</p>



<p>Occupations do not defeat cities and define men. They defeat cities and defeat men.</p>



<p>It is our very preoccupation with occupations that stops us from noticing its own nature.</p>



<p>The occupied man does not seriously consider the possibility of living without an occupation any more than the man born into a city that has been occupied for centuries considers that it must not be so forever.</p>



<p>We are blinded by a bias which believes the present will persist. We fail to imagine a future that is radically different, though that is what has happened over and over again, decade after decade, by a degree which has been dramatically accelerating over the course of the last century.</p>



<p>We view automated industry almost exclusively as a threat while ignoring the opportunity that comes along with it. Automation may offer the potential to free ourselves from our occupations through the automated and automatic satisfaction of our most <a href="https://blogofjake.com/2020/03/31/the-eleven-human-needs/">essential human needs</a>. Such a standard would free us from necessarily having to do anything while simultaneously empowering us to do almost anything.</p>



<p>We have little gratitude for the generations of humans who have succeeded collectively in driving us to this defining moment in the unfathomably long but universally short history of humanity. We fail to appreciate even those alive today who are pressing us forward faster than ever, choosing instead to nitpick flaws and cancel the courageous. These brave leaders know that we are close. They consider this time the luckiest ever to be alive, and so do I.</p>



<p>People fear the new world because it is so different from the one we have known and that any generation before us has ever known. Those who have gained power in this long era of history will not willingly give their power away. They will fight in an effort to delay the disruptive forces but they will fail to realize that while their power over others will be taken away so too will the power of others over them.</p>



<p>Why should we all be satisfied with living in the middle of this chain of occupations where our lives are seized so that we may seize the lives of others and so that we may use our monies not to free ourselves from seizure but rather to seize possession of mostly meaningless goods and services which only serve to ensure the continuance of our dependence on our occupations as our growing wants overshadow our modest needs and the margin between the earnings we sell our lives for and the expenses we feel obligated to incur becomes ever narrower.</p>



<p>Some will read this and criticize me for being privileged, young, and ignorant. I cannot help but that I am the first two of these things. As for the third, is ignorance not at least as good to admit as certainty is to claim? Is it not as worthwhile to consider my opinion as it would be that of a disadvantaged old man who is certain of everything he knows? My privilege, youth, and ignorance may have assisted me in recognizing these truths but that does not mean that others less fortunate than myself cannot also recognize them and seek to apply them in their own lives however they may.</p>



<p>We cannot all escape occupation overnight, but we can recognize our preoccupation with occupations, and we can begin to think differently such that there may be another way to live.</p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2020-07-14T12:13:26-04:00">July 14, 2020</time><time datetime="2020-07-14T12:30:27-04:00">July 14, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>http://blogofjake.com/2020/07/14/preoccupied-with-occupations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833955</guid>
            <pubDate>Tue, 14 Jul 2020 16:27:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Illustrations for Your Website]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833905">thread link</a>) | @ronaldsvilcins
<br/>
July 14, 2020 | https://www.ronaldsvilcins.com/2020/07/14/illustrations-for-your-website/ | <a href="https://web.archive.org/web/*/https://www.ronaldsvilcins.com/2020/07/14/illustrations-for-your-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><nav><ul><li><a href="https://www.ronaldsvilcins.com/" aria-current="page">Writing</a></li><li><a href="https://www.ronaldsvilcins.com/projects/">Projects</a></li><li><a href="https://www.ronaldsvilcins.com/about/">About</a></li><li><a href="https://www.ronaldsvilcins.com/atom.xml">RSS</a></li></ul></nav></header><hr><section><p><time datetime="2020-07-14">July 14, 2020</time> •
<a href="https://www.ronaldsvilcins.com/tags/illustrations">Illustrations</a></p><p>Using illustrations has emerged as a popular trend in modern web design. But did you know that the use of illustration is also an incredibly effective way to engage your visitors and a great way to add a personal touch to your website and make it really stand out from other websites? Great illustrations are vital for grabbing attention and getting your message across. So, to help you out with your quest to find beautiful illustrations for your website, I put together a list of some of my favorite resources. Enjoy the selection!</p><ul><li><p><a href="https://blush.design/">Blush Design</a> - Blush is a tool that brings illustrations to everyone from artists around the world. The cool thing is that you can customize every piece of an illustration to create your own compositions.</p></li><li><p><a href="https://www.humaaans.com/">humaaans</a> - Mix-&amp;-match illustrations of people with a design library. Free for commercial or personal use.</p></li><li><p><a href="https://www.drawkit.io/">DrawKit</a> - Beautiful, free illustrations. Updated weekly. Hand-drawn vector illustration and icon resources, perfect for your next project.</p></li><li><p><a href="https://www.openpeeps.com/">Open Peeps</a> - A hand-drawn illustration library. The library works like building blocks made of vector arms, legs, and emotions. You can mix these elements to create different Peeps.</p></li><li><p><a href="https://absurd.design/illustrations.html">Absurd</a> - Each illustration offers the possibility of limitless interpretations and uses and everyone can give it its own meaning. It depends only on each one’s creativity and free spirit.</p></li><li><p><a href="https://icons8.com/illustrations">Ouch</a> - Ouch helps creators who don’t draw overcome the lack of quality graphics.</p></li><li><p><a href="https://www.ls.graphics/whoosh">Whoosh</a> - Free illustrations for your projects. Use this pack of illustrations for any kind of projects from websites to applications. All illustrations are neatly structured. Each element is assigned a color style so that it is convenient to change colors at once in all the images. They are all appropriately named and packed into symbols.</p></li><li><p><a href="https://www.karthiksrinivas.in/charco">Charco Illustrations</a> - A set of 16 handcrafted illustrations for your web &amp; app projects. This set includes categories like 404 error, no internet connection, no service, fatal error, page not found, something went wrong, under construction and many more.</p></li><li><p><a href="https://undraw.co/illustrations">unDraw</a> - Use the on-the-fly color image generation to match your brand identity.</p></li><li><p><a href="https://www.streamlineicons.com/ux/free-illustrations.html">Streamline Illustrations</a> - 50 vector Illustrations in three styles: Multicolor, Duotone and Line. Use them for any commercial work.</p></li><li><p><a href="https://iconscout.com/paper-illustrations">Paper Illustrations</a> - Incredible set of paper illustrations absolutely free for both personal and commercial use. Carefully crafted illustrations to use in different categories.</p></li><li><p><a href="https://illlustrations.co/">illlustrations.co</a> - Designed 100 awesome illustrations during 100 days of illustration challenge (Now added more than 120+illustrations). You can download all illustrations completely free and use these to design awesome - landing pages, mobile app or presentations.</p></li><li><p><a href="https://lukaszadam.com/illustrations">Illustrations by Lukasz Adam</a> - MIT licensed SVG illustration images in different shapes &amp; styles. Use these free Illustrations for your website, use the icons to represent your services or simply use these images to help users to understand your content.</p></li></ul><p>To wrap up, if you have decided on using illustrations for your next website design, you are definitely on the right path to impress your future visitors. The resources listed above will give you plenty of material to use no matter what you’re designing.</p></section><hr></div></div>]]>
            </description>
            <link>https://www.ronaldsvilcins.com/2020/07/14/illustrations-for-your-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833905</guid>
            <pubDate>Tue, 14 Jul 2020 16:24:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bunkobon Leadership]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833896">thread link</a>) | @mikeberv
<br/>
July 14, 2020 | https://www.billiondollarstartupideas.com/ideas/bunkobon-leadership | <a href="https://web.archive.org/web/*/https://www.billiondollarstartupideas.com/ideas/bunkobon-leadership">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1594743809883" id="item-5f0dd758c4fe94112447ab5f"><div><div><div data-block-type="2" id="block-139d3d3e2fdcd6f733c7"><div><p><strong>Problem: </strong>We spend 1/3 of our lives at work, but often don’t work effectively. Moreover, current books on optimizing leadership, management, and work are long.</p><p><strong>Solution: </strong>A company that produces and publishes mini-guides on bite-sized leadership topics. Ideally these publications would be small enough to be Bunkobons. In Japan,&nbsp;<strong><em>bunkobon</em></strong>&nbsp;(文庫本)&nbsp;are small-format&nbsp;paperback&nbsp;books, designed to be affordable and space saving. The great majority of&nbsp;<em>bunkobon</em>&nbsp;are&nbsp;<a href="https://en.wikipedia.org/wiki/Paper_size#International_paper_sizes" title="Paper size">A6</a>&nbsp;(105×148mm or 4.1"×5.8") in size. As described by <a href="https://www.redcircleauthors.com/factbook/books-in-japan-are-generally-published-as-tanko-bon-bunko-bon-or-both/">Red Circle Authors</a>,</p><p><em>Bunko</em>&nbsp;or&nbsp;<em>bunko-bon</em>&nbsp;is the widely used Japanese term for a book that is a small-format paperback book designed to be affordable, portable and not take up too much shelf space. The format has a long and interesting&nbsp;<a href="https://www.futurelearn.com/courses/japanese-rare-books-culture/0/steps/17269">history</a>&nbsp;going back to books designed to fit into the sleeves of kimonos in Japan’s Edo Period (1603-1868).&nbsp;</p><p>The format allows for cheaper editions of books which have already been published as&nbsp;hardbacks. Imagine carrying around mini pocket books with lessons distilled from the Harvard Business Review, Fast Company, Bloomberg Businessweek, and more. Perhaps as an added bonus, the business would allow anyone to write, publish, and sell their own bunkobon on a centralized bunkobon leadership website.</p><p>As writer Annie Dillard famously said, “How we spend our days is, of course, how we spend our lives.” For many of us, a large portion of our days is spent at work; in fact, <a href="https://www.payscale.com/career-news/2018/10/heres-how-many-years-youll-spend-work-in-your-lifetime">the average person will spend 90,000 hours at work over a lifetime</a>. Thus books that are designed to give you more insight into how to thrive during this chunk of your life would be extremely useful. Like digital book tours, this business would play in <a href="https://publishingperspectives.com/2018/07/us-statshot-publisher-survey-2017-estimates-revenue/#:~:text=Online%20Sales%3A%2043.2%20Percent%20Print%2C%2027%20Percent%20Ebook&amp;text=The%20top%20line%20offered%20in,2017%2C%20representing%202.72%20billion%20units.">the book publishing industry</a> which generated an estimated $26.23 billion in net revenue for 2017 (accounting for 2.72 billion units). It would be in direct competition with companies like “<a href="https://hbsp.harvard.edu/home/">Harvard Business Publishing.</a>”</p><p><strong>Monetization: </strong>Selling these books. </p><p><strong>Contributed by: </strong><a href="https://www.michaelbervell.com/">Michael Bervell</a> (Billion Dollar Startup Ideas)</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.billiondollarstartupideas.com/ideas/bunkobon-leadership</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833896</guid>
            <pubDate>Tue, 14 Jul 2020 16:24:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do not render a PDF in a canvas]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833883">thread link</a>) | @valkum
<br/>
July 14, 2020 | https://oltdaniel.at/2020/just-do-not-render-a-pdf.html | <a href="https://web.archive.org/web/*/https://oltdaniel.at/2020/just-do-not-render-a-pdf.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>Do not render a PDF in a canvas</h2>
    <post-meta>
        <time datetime="2020-07-14T00:00:00+02:00">14 July 2020</time>
        with <words>887</words> words
        (<reading-time>4</reading-time> minute(s) to read)
    </post-meta>
    <p>Mobile browsers are far from perfect. Browsing larger GitHub Source files, slow loading websites with one gig of images and js. They are just not done for it. However, there are things, that should just not be.</p>

<!--abstract-->

<hr>

<blockquote>
  <p>I am a student in my second semester of computer science. I have a lot of stuff to learn, but this is something that “I don’t enjoy”. Just do not build it in the first place. Done.</p>
</blockquote>

<p>A fellow student of mine, send me a lecture notes to a module to prepare for my exams. We have an own GitLab instance running for our university where every student is free to create and share their work. In this case, a user create a repo for a specific module to store the source files and final PDF of his lecture notes. So far, so good.</p>

<p>Got the link, opened up on my smartphone, waited for the PDF to load and … crash. The browser closed, the homescreen restarted. Wait, what? Opened up the messenger, clicked the link again, waited for the PDF to load. Crash. My first thought was, my phone was just too bad. But I have a Samsung Galaxy S9, nothing low end, nothing ultra. But does the job in everything … except this. So I started digging.</p>

<p>First off, GitLab (at least the version 13.1.3-ee, used by our university) renders the PDF file in a HTML canvas, each page, one canvas. First thought, maybe there are too many pages. No, there are just 90 pages in that PDF. But as I have exams coming up, I cannot dig deeper into the JavaScript Part of GitLab. So I did some other testing for now instead.</p>

<p>The default Browser I have on my phone is Chrome v83.0.4103.106 and additionally Firefox v68.10.1, running on Android 10 and One UI v2.1 (build number: QP1A.190711.020.G960FXXU9ETF5). So I know Chrome fails to render the PDF in 90 Canvas elements. So I checked Firefox, same thing happens. With this knowledge I asked in the computer science group of my university, for other people to verify this behavior and the android users could verify it. Apple users verified that it renders successfully in both Safari and Firefox on IOS. I wanted to record my screen in order to document this crash, but as lucky I am, the screen recorder app is killed straight away after the browser crashed. As I have no additional equipment to record, feel free to crash it yourself.</p>

<h3 id="how-do-we-test">how do we test</h3>

<p>Well, as the GitLab instance of my university is public and repos can be shared publicly, I still do not want to get into any trouble. But, now problem, we have GitLab itself and a small demo side I built. Technical stuff: GitLab uses PDF.js from mozilla. My version is based on one of their examples, as I am not currently able to dive into GitLab source code. For a PDF I used the ethereum PDF file, twice, to have a PDF file that is large enough. It is a bit bigger than the original PDF file I had, but roughly the same number of pages (just 78 here).</p>

<p>During the development I tested in my desktop to see if the page displays everything correctly, and then continue testing on my mobile device. During this phase I crashed by laptop while it was rendering 78Pages of PDF in the browser. Note here, my Laptop is an XPS15 with an Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz with 6 cores. Due to my time limits, I need to continue my work in the future (1 month from now).</p>

<h2 id="attention">ATTENTION</h2>

<p>THESE LINKS ARE LIKELY TO CRASH YOUR BROWSER, IF YOU ARE ON ANDROID. IF THERE IS ANY DAMAGE DONE BY OPENING THIS LINK, I HAVE WARNED YOU WITH THIS MESSAGE AND AM NOT ACCOUNTABLE FOR ANY DAMAGE. IF THE TAB LOADS, JUST CLOSE IT TO AVOID THE CRASH. I SUGGEST MY VERSION, AS YOU JUST NEED TO CLICK A BUTTON TO CRASH YOUR BROWSER.</p>

<p><a href="https://oltdaniel.at/pdf_test.html">My Version</a></p>

<p><a href="https://gitlab.com/oltdaniel/crash-pdf/-/blob/master/paper.pdf">GitLab Version</a></p>

<h3 id="conclusion">conclusion</h3>

<p>PDF files are like SVG files. You can zoom into each character without seeing any pixels. It’s a great format. But as usual, there where people that need to render PDF files to a raw canvas. Nothing wrong with it, but e.g. to keep up the Quality GitLab renders each page in a 2381x3367 canvas (at least on my computer). It is required, because if you reduce the scale there is no damn way to read the pdf in this rendered format. But that is the reason, why there are so many PDF readers on so many platforms. That is the reason why desktop browser have built-in PDF readers, because in any other format you just kill system resources and/or do not get the same visual quality.</p>

<p>In the end, I am fascinated how quickly someone can crash a browser. And I mean, really crash a browser. Nobody, expects a mobile browser crashing just by rendering a PDF file. It could be fixed in this special case, by reducing the size of each canvas, or just render pager per page (as the key example of mozilla’s PDF.js presents <a href="https://mozilla.github.io/pdf.js/examples/">here</a>).</p>

<p>More to this scenario will follow in the future with further details and demos.</p>

</div></div>]]>
            </description>
            <link>https://oltdaniel.at/2020/just-do-not-render-a-pdf.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833883</guid>
            <pubDate>Tue, 14 Jul 2020 16:23:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Founder of Puppet on bootstrapping, burnout, and babies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833608">thread link</a>) | @tomashertus
<br/>
July 14, 2020 | https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/ | <a href="https://web.archive.org/web/*/https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-215">
		<!-- .entry-header -->

	
	<div>
		<p><em>How I got here, how it went, and what happened along the way.</em><br>
<img src="https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-scaled.jpeg" width="2560" height="1920" srcset="https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-scaled.jpeg 2560w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-300x225.jpeg 300w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-1024x768.jpeg 1024w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-768x576.jpeg 768w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-1536x1152.jpeg 1536w, https://lukekanies.com/wp-content/uploads/2020/07/DraggedImage-2048x1536.jpeg 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><br>
I didn’t want to start a company. But I had no choice.</p>
<p>I was a SysAdmin after college, because I tried everything else and got fired from them all. I had seven jobs in two and a half years. I’m very fireable. System administration was just the chair where I happened to be sitting when the music stopped. More a safe, fun place than a source of deep passion.</p>
<p>By that point in my career, I was a little easier to keep around. More importantly, I had become worth the hassle. I did good work because I liked the puzzles.</p>
<p>I had a particular way of working. My boss would say, “You should do this thing, and you should do it this way.” He did not look at how I worked, only the result. That gave me the freedom that made the job worth it. When I told him I had finished he would say, “Great, how did you do it?” and I’d say, “Look, is that a bird?”</p>
<p>I automated everything I could, whether it needed it or not. Automation has a built-in reward mechanism. I would take this well-paying but stultifying job — <em>Type this command 1,000 times</em> — and I would reframe it: <em>How about I tell the computer to type the command 1,000 times? It will work. I’ll watch.</em> Bam! Now I can move on to other fun stuff.</p>
<p>Over time I did so much automation I kind of ran out of work. I was in Nashville at the time, while my wife was getting her PhD, so there were no interesting jobs that needed my skills. Hmm.</p>
<p>I could go to business school, but — sorry! — I don’t have any respect for the MBA. Everything I hear about business school is how valuable the network is. If I want that, I’ll take a cruise. I thought about going to law school, but it is so expensive you have to become a lawyer afterward. I didn’t want to be a lawyer. I just wanted to change my career.</p>
<p>So I was like, I’ll find someone who’s doing what I want to do—building a product to help people like me—and I’ll go and help them.</p>
<p>Oh my god, that was miserable. I lasted five months.</p>
<p>Commuting back and forth between Boston and Nashville did not help. I also had the brilliant idea of commuting seven miles each way by bike. In the winter. In Boston. I gave myself permission not to ride if it was under twenty-seven degrees. Being on the road in Boston is dangerous in a tank. On a bike, in the snow, was a cruel joke.</p>
<p>But mostly I just hated our software. I hated what we were building. At one team meeting, a senior developer said, “What does it matter what our customers think? They’ve already bought the product.” Reaction to that statement — nothing at all — told me I was in the wrong place.</p>
<p>So I left.</p>
<p>I got home. I said, I have a little money saved up, and I’ve tried everything else, and now that I think about it, I guess my dad was kind of an entrepreneur. I mean, he did run his own business for thirty years. Technically. I suppose.</p>
<p>Maybe I should start a company?</p>
<p>I know everyone in the world who is building automation tools for sysadmins, and none of them are going to build a business. “I built this, so, obviously, it’s the best.” But they’re only interested in publishing papers and getting academic tenure. Their software was already perfect, so they saw no reason to listen to anyone’s reasons for not using it.</p>
<p>I thought, what if I build something? And then listen to the people who are using it? (And maybe those who aren’t?) Hmm. Could work.</p>
<p>I quit my job. Well, I quit my job first and said, “Eh, I should probably find a way to eat.” So after trying everything else, I started a company.</p>
<p>We lived on my wife’s generous graduate student stipend of $23,000 a year — the job I quit paid $110,000 a year — and, like I said, I thought I had some money saved up. At some point the IRS sent me a letter that said, “We disagree,” and it turns out when the IRS disagrees with you, well, you know how that goes. And even if you’re right, by the time you prove you’re right, “Ok, I had ten grand, and I spent ten grand on a lawyer proving I have ten grand, and…” Just send them the check.</p>
<p>So I was broke when I started my company.</p>
<p>As a sysadmin, you’re not a developer. People will tell you: In DevOps, everyone’s a developer. Those people are lying to you. Or selling something. Which, you know. So I had to become a developer. I had written some code before Puppet, maybe 5,000 lines total. But by the time I handed it over, it was 130,000 lines of code.</p>
<p>The people I handed it to regretted my learning experience.</p>
<p>I adored it.</p>
<p>I learned a lot. It was, to be frank, super fun. One of the densest learning periods of my life. Programming is the best puzzle. I find it harder to step away from it than anything else I’ve ever done. It’s been two days since I ate, I think my wife has been trying to get my attention for the past twelve hours, I should probably … and then I try to move, my legs don’t work. I’m lightheaded from hunger and my feet are tingly.</p>
<p>Good times.</p>
<p>After about ten months I got my first paying customer.</p>
<p>I often advise other entrepreneurs. Much of what I tell them is to avoid what I did. I only had a vague idea for how to make money. I figured, “I’m confident I can make something valuable. I kind of have a plan, but I know my plan is stupid. If I bring my plan to people and listen to them, that could help make my plan less stupid.”</p>
<p>This is not that bad of a strategy! But it’s not exactly specific.</p>
<p>I didn’t really ask myself: What is my overall business going to look like? How will I get there? I started with services, because I’d been consulting for a while, and I was confident I could make enough money to eat. I know investors are down on services businesses, or anything that doesn’t look like a founder throwing themselves off a cliff with what they hope is a parachute. But you gotta eat. And services are a fantastic way to make money while you’re figuring things out.</p>
<p>I had a lot to figure out.</p>
<p>At the time — 2005 — there were a lot of open source companies out there. When I say a lot, there were four. I thought, “They’re doing well, I will copy one of them at some point later on.” That was not that great of a plan. Two years later Red Hat was the only one left. They’re a software powerhouse today, but they went public during the bubble as a T-shirt and mug company. There’s no copying that.</p>
<p>I did start making money, though. We consulted for three-and-a-half years. “We.” I was the only employee. About three years into the company, I discovered one day that I was incredibly burned out. This was the first of three major burnouts for me at Puppet.</p>
<h2>Burnout Strikes</h2>
<p>I distinctly remember realizing I was burned out. I was standing next to my wife, at the doctor’s office, looking at an ultrasound. We just learned we’re going to have twins, and I get a sudden flash of insight: My life is unsustainable.</p>
<p>I personally can’t recommend, when you’re in a bootstrapped startup, planning to have a baby. I would work especially hard to avoid having more than one at a time. But that’s what we did.</p>
<p>(Speaking of which: All you people who had your babies serially, you’re lazy and you don’t know what you’re doing. You think you had it hard. We were tested. Y’all are amateurs.)</p>
<p>The technician said, “Oh, you are going to get scanned a lot.” Um. You’re going to have to explain that one. She told us we were having two. We laughed. She must be incompetent. Just because <em>you</em> have twins (she did) doesn’t mean you can recognize them in someone else. While using an ultrasound wand. Which is your job. Scan… scan… BING! The two fetuses clearly popped into view. My wife would have fallen over if she weren’t already lying down. My knees shook. I thought, I can’t do this anymore.</p>
<p>I had been working every hour I could. I counted once: It was about 72 hours in my busiest week. There are people who say, I work 100 hours a week. You might stand there 100 hours a week. I’m skeptical you’re working. Based on <a href="https://cs.stanford.edu/people/eroberts/cs201/projects/crunchmode/econ-hours-productivity.html">what I know about productivity</a>, I hope you’re not.</p>
<p>I couldn’t do it anymore. Since February 2008 or so, coincidentally the same day I found out we were having twins, I haven’t worked more than 40 or 50 hours a week. No evenings and weekends. I might dabble sometimes, but I won’t let it become a pattern.</p>
<p>Don’t worry. I managed to burn myself out two more times without those extra hours. It can still be just as bad. Pack that intensity into fewer hours, and you’re all good.</p>
<p>So. I need help. How?</p>
<h2>Getting Help</h2>
<p>I had tried to hire people in the past. Both of them were misses.</p>
<p>The first hire was the most notable. In the three months it took to figure out he wouldn’t work out, the best person I could possibly have hired became available and then unavailable. This guy’s biggest impact was ensuring I couldn’t hire the person who would have been most helpful.</p>
<p>There’s one more crazy story about him. In the middle of his interview at my house there was a drive-by shooting next door. He had taken a bathroom break when the shooting happened. They weren’t trying to hurt anybody, just shooting up a car to send a message. One of the bullets ricocheted off the car, then my porch, and broke my front window. He came out of my bathroom, and I said, “Are you ok?”<br>
“Yeah, why?”<br>
“No reason.”</p>
<p>I needed him to work in my house.</p>
<p>(Yes, I did actually tell him. Eventually.)</p>
<p>When he didn’t pan out, I concluded, I guess I just can’t hire. I’ll do it all myself.</p>
<p>Pro tip: Don’t do that.</p>
<p>Puppet worked in spite of these decisions, not because of them.</p>
<p>Things had changed, quite suddenly. I needed help, and now.</p>
<p>I hired the only people I could think of who might do me a favor: my college roommate and my best friend. Two separate people. Again: Don’t do this. I paid them full salaries.</p>
<p>Years later, I realized, “Wait a minute, if I was paying them full salary, they weren’t really doing me a favor, were they?”</p>
<p>Burned-out people make low-quality decisions. Your brain is gone, and you’re stupid. You work too many hours, you get burned out. You hurt your business doing this kind of thing. Get sleep, eat well, get exercise, step away …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/">https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/</a></em></p>]]>
            </description>
            <link>https://lukekanies.com/entrepreneur-stage-1-bootstrapping-burnout-and-babies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833608</guid>
            <pubDate>Tue, 14 Jul 2020 16:07:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Credit card fraud – Covid style]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833538">thread link</a>) | @falafel_muncher
<br/>
July 14, 2020 | https://pauli.us/qr-code-credit-card-fraud/ | <a href="https://web.archive.org/web/*/https://pauli.us/qr-code-credit-card-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img src="https://images.unsplash.com/photo-1572798793834-67d5e285760d?ixlib=rb-1.2.1&amp;q=85&amp;fm=jpg&amp;crop=entropy&amp;cs=srgb&amp;ixid=eyJhcHBfaWQiOjYzOTIxfQ&amp;w=3600" alt="credit card at a restaurant">
A few days ago, a friend (lets call her Eli) told me about how someone stole her credit card info at a restaurant.</p>
<p>We’re in Chicago in the middle of the Covid-19 pandemic. Restaurants have started to open back up, but only those with outdoor seating. To avoid spreading Covid, some restaurants are placing a laminated piece of paper with a QR code on each table.</p>
<p>This QR code links to a menu on the restaurant’s website. What a great idea! Restaurants don’t need to hand out menus, in fact they don’t even have to print them anymore! They can update the menu in realtime as things go out of stock or the selection changes.</p>
<p>When Eli sat down at this restaurant in Chicago, she used the QR code to open up the menu and browsed around for a bit. After a few minutes, a pop-up asked her to enter her credit card info for a seamless checkout.</p>
<p>Hmm. This is where alarm bells might go off, but remember - we’re in the middle of a pandemic. Passing credit cards to a server is dangerous! What if they have covid? What if <em>you</em> have Covid and you infect your server? It would be best to have everything be contactless. Eli entered her card info, thinking that this was actually a pretty good user experience.</p>
<p>As you may have guessed by now, it wasn’t the restaurant collecting her credit card info. Someone placed a fake menu on the table with a QR code pointing to their own phishing site. This seems pretty easy to do. Someone could walk by and place fake menus on a few tables.</p>
<p>On the tech side, things are even easier. The attacker can register a generic sounding domain, eg. lookatmenu.app. Next, they create a unique QR code for each target restaurant. You don’t even need a separate domain for each restaurant. Just add the restaurant’s actual menu URL as a query parameter. Eg: <a href="https://lookatmenu.app/?s=%5Bhttps://orders.giordanos.com/#/menu/national/ToGo/Pickup%5D(https://orders.giordanos.com/#/menu/national/ToGo/Pickup)">https://lookatmenu.app?s=https://orders.giordanos.com/#/menu/national/ToGo/Pickup</a></p>
<p>You can pass this query string into an iFrame, which makes it look like you’re actually on <a href="http://giordanos.com/">giordanos.com</a>. After a few seconds, simply show a popup to a payment form of your choosing.</p>
<p>In Eli’s case, the credit card was charged to some sort of nondescript subscription service. If it’s something with a generic name for a $20/month or so, a lot of people might not notice for a long time.</p>
<p><a href="https://codepen.io/pranas/pen/rNxZMMy">Here’s a codepen with example code</a>.</p>
<h2><strong>So, how do I protect myself?</strong></h2>
<ol>
<li>Always look at the URL of the page when entering credit card info. If anything seems off, don’t enter your payment info.</li>
<li>Be sure to ask the server if the menu is legit.</li>
</ol>
<p>Although I hate to hear stories like this, it’s always interesting to see how fraudsters exploit technology and our trust. Luckily, my friend’s credit card company refunded the charges and issued a new card.</p>
<p>Stay safe out there!</p></section></div>]]>
            </description>
            <link>https://pauli.us/qr-code-credit-card-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833538</guid>
            <pubDate>Tue, 14 Jul 2020 16:03:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Etcd, or, why modern software makes me sad]]>
            </title>
            <description>
<![CDATA[
Score 1161 | Comments 578 (<a href="https://news.ycombinator.com/item?id=23833362">thread link</a>) | @Spellman
<br/>
July 14, 2020 | https://www.roguelazer.com/2020/07/etcd-or-why-modern-software-makes-me-sad/ | <a href="https://web.archive.org/web/*/https://www.roguelazer.com/2020/07/etcd-or-why-modern-software-makes-me-sad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <section id="main-content" role="main">
	<article>
		


		<div><p><img alt="etcd icon" src="https://www.roguelazer.com/images/etcd-icon.png"></p>
<p>Once upon a time in 2013, there was a tool called <a href="https://etcd.io/">etcd</a> which was a really lightweight database written
around the <a href="https://web.stanford.edu/~ouster/cgi-bin/papers/raft-atc14">Raft</a> consensus algorithm. This tool was
originally written in 2013 for a <del>bullshit</del> unsuccessful project called <a href="https://coreos.com/os/docs/latest/">CoreOS Container Linux</a> that was
EOL'd several years ago, but that doesn't really matter — etcd was greater than its original use-case. Etcd
provided a convenient and simple set of primitives (set a key, get a key, set-only-if-unchanged, watch-for-changes) with
a drop-dead simple HTTP API on top of them. I have built a number of tools using etcd as a lightweight consensus store
behind them and it's absolutely a pleasure to work with.</p>
<div>
<p>Hello <strong>massive influx of new readers</strong>! I see that some <del>person who's out to get me</del> kind soul has
cross-posted this to Hacker News, Reddit, and a bunch of other sites. Cool! A few things you might want to know <em>before</em>
you send me hate-mail:</p>
<ul>
<li>The word "rant" is right up there in the tags line. This is not meant to be a persuasive argument to the secret cabal
  that controls API design or a nuanced technical comparison article. It's just some off-the-cuff thoughts. Chillax.</li>
<li>If this didn't come across clearly enough in the article: <em>I think etcd is great!</em> I have written a bunch of tools and
  applications on top of it! I think it's a fantastic little dæmon and its API, even the new janky v3 API, is still a
  million times better than ZooKeeper</li>
</ul>
<p>Okay, then. Read on.</p>
</div>
<p>In 2015, an unrelated tool called <a href="https://github.com/kubernetes/kubernetes">Kubernetes</a> was released by Google (but, really, by
Xooglers). I would go so far as to say that Kubernetes (or, as the "cool kids" say, <kbd>k8s</kbd>) is the worst thing to happen to system administration
since <a href="https://www.roguelazer.com/2020/03/systemd/">systemd</a>. It's a comprehensive suite that promises to simplify operating clusters of software and give something like 
the experience of Google's <kbd>borg</kbd> cluster manager. What it really does is:</p>
<ol>
<li>Add hundreds of new failure modes to your software</li>
<li>Move you from writing portable software configuration to writing thousands of lines of k8s-specific YAML</li>
<li>Ensnare you in a mesh of questionably-good<sup id="fnref:questionably-good"><a href="#fn:questionably-good">1</a></sup> patterns like containerization and software defined networking</li>
</ol>
<p>If you are running a truly enormous system and want to have off-the-shelf orchestration for it, Kubernetes may be
the tool for you. For 99.9% of people out there, it's just an extra layer of complexity that adds almost nothing of
value.</p>
<p>I digress, though; this is a story about etcd. And, unfortunately, our stories come together because Kubernetes was
quickly changed to use etcd as its state store. Thus began the rapid decline of etcd.</p>
<p>With the massive influx of Kubernetes users came, of course, a large number of Xooglers who decided to infect etcd with
Google technologies, as is their way<sup id="fnref:infection"><a href="#fn:infection">2</a></sup><sup id="fnref:who"><a href="#fn:who">3</a></sup>. Etcd's simple HTTP API was replaced by a "gRPC"<sup id="fnref:grpc"><a href="#fn:grpc">4</a></sup> version; the
simple internal data model was replaced by a dense and non-orthogonal data model with different types for leases, locks,
transactions, and plain-old-keys. etcd 3.2 added back a tiny subset of the HTTP API through the <a href="https://etcd.io/docs/v3.4.0/dev-guide/api_grpc_gateway/">"gRPC
Gateway"</a>, but not enough to implement
any of the rich applications built on top of the original API. The v2 API lives on for now, but upstream threatens to
remove it in every new version and there will surely come a time when it'll be removed entirely.</p>
<p>That's it. That's the story. Popular modern technology is taken over by expats from a megacorp and made worse in the
service of a hyper-specialized (and just plain over-hyped) orchestration platform. That's the world today. Anything that
has a simple and elegant feature-set ends up coöpted by people who just want to build big ungainly architecture and ends
up inheriting features from whatever megacorp the coöpters came from<sup id="fnref:megacorp"><a href="#fn:megacorp">9</a></sup>. The software development world would
prefer to use their multi-gigabyte IDEs running on ElectronJS to build thousand-dependency Java applications targeting
ungainly APIs on hard-to-operate systems than support something simpler and better. Quality is, alas, a dying art.</p>
</div>
<hr>
<h2>Comments</h2>


	</article>
    </section>
</div></div>]]>
            </description>
            <link>https://www.roguelazer.com/2020/07/etcd-or-why-modern-software-makes-me-sad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833362</guid>
            <pubDate>Tue, 14 Jul 2020 15:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Covid-19 Extra-Parliamentary Inquiry Committee (Statement)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833285">thread link</a>) | @eternalban
<br/>
July 14, 2020 | https://acu2020.org/international/ | <a href="https://web.archive.org/web/*/https://acu2020.org/international/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<h2>The COVID-19 Extra-Parliamentary Inquiry Committee </h2>



<h4>Start 03.07.2020</h4>



<p>Heiko Schöning, Dr. Bodo Schiffman, Prof. Martin Haditsch</p>



<figure><p>
<iframe title="ACU 2072020_multilanguage" src="https://player.vimeo.com/video/434999409?dnt=1&amp;app_id=122963" width="580" height="326" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
</p></figure>



<div><figure><img src="https://acu2020.org/wp-content/uploads/2020/07/Infografik_2_E_web_acu2020.org_.png" alt="" srcset="https://acu2020.org/wp-content/uploads/2020/07/Infografik_2_E_web_acu2020.org_.png 500w, https://acu2020.org/wp-content/uploads/2020/07/Infografik_2_E_web_acu2020.org_-300x300.png 300w, https://acu2020.org/wp-content/uploads/2020/07/Infografik_2_E_web_acu2020.org_-150x150.png 150w" sizes="(max-width: 500px) 100vw, 500px"></figure></div>



<p><strong>Transcript in English</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/England-Flagge-1024x512.png" alt="" width="298" height="149" srcset="https://acu2020.org/wp-content/uploads/2020/07/England-Flagge-1024x512.png 1024w, https://acu2020.org/wp-content/uploads/2020/07/England-Flagge-300x150.png 300w, https://acu2020.org/wp-content/uploads/2020/07/England-Flagge-768x384.png 768w, https://acu2020.org/wp-content/uploads/2020/07/England-Flagge.png 1200w" sizes="(max-width: 298px) 100vw, 298px"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-english-1.pdf">Text-ACU-english</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-english-1.pdf" download="">Herunterladen</a></p></div>
</div>
</div>



<p><strong>Transkript auf Deutsch</strong></p>



<div><div>
<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/180px-Flag_of_Germany.svg_ergebnis.png" alt="" width="302" height="181"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-deutsch.pdf">Text-ACU-deutsch</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-deutsch.pdf" download="">Herunterladen</a></p></div>
</div>
</div>
</div></div>



<p><strong>Transcripte en Francais</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/180px-Flag_of_France.svg_ergebnis.png" alt="" width="298" height="199"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Texte-ACU-francais.pdf">Texte-ACU-francais</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Texte-ACU-francais.pdf" download="">Download</a></p></div>
</div>
</div>



<p><strong>Trascrizione in Italiano</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/180px-Flag_of_Italy.svg_ergebnis.png" alt="" width="301" height="200"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Testo-ACU-italiano.pdf">Testo-ACU-italiano</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Testo-ACU-italiano.pdf" download="">Download</a></p></div>
</div>
</div>



<p><strong>Transcripción en español</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/Spanische-Flagge.png" alt="" width="298" height="198"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Texto-ACU-Espa%C3%B1ol.pdf">Texto ACU Español</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Texto-ACU-Espa%C3%B1ol.pdf" download="">Herunterladen</a></p></div>
</div>
</div>



<p><strong>Стенограмма на русском языке</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-1024x682.png" alt="" width="299" height="199" srcset="https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-1024x682.png 1024w, https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-300x200.png 300w, https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-768x512.png 768w, https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge-1200x800.png 1200w, https://acu2020.org/wp-content/uploads/2020/07/russische-Flagge.png 1280w" sizes="(max-width: 299px) 100vw, 299px"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-russisch.pdf">Текст ACU русский</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-russisch.pdf" download="">Herunterladen</a></p></div>
</div>
</div>



<p><strong>Transcriere în limba română</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1-1024x683.png" alt="" width="299" height="199" srcset="https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1-1024x683.png 1024w, https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1-300x200.png 300w, https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1-768x512.png 768w, https://acu2020.org/wp-content/uploads/2020/07/rum%C3%A4nische-Flagge-1.png 1200w" sizes="(max-width: 299px) 100vw, 299px"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-rom%C3%A2n%C4%83.pdf">Text-ACU-română</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Text-ACU-rom%C3%A2n%C4%83.pdf" download="">Herunterladen</a></p></div>
</div>
</div>



<p><strong>Tekst ACU Polski</strong></p>



<div>
<div>
<figure><img src="https://acu2020.org/wp-content/uploads/2020/07/Polnische-Flagge-1.png" alt="" width="300" height="185"></figure>
</div>



<div>
<div><p><a href="https://acu2020.org/wp-content/uploads/2020/07/Tekst-ACU-Polski.pdf">Tekst-ACU-Polski</a><a href="https://acu2020.org/wp-content/uploads/2020/07/Tekst-ACU-Polski.pdf" download="">Herunterladen</a></p></div>
</div>
</div>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://acu2020.org/international/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833285</guid>
            <pubDate>Tue, 14 Jul 2020 15:44:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resignation Letter]]>
            </title>
            <description>
<![CDATA[
Score 601 | Comments 614 (<a href="https://news.ycombinator.com/item?id=23833267">thread link</a>) | @kirillzubovsky
<br/>
July 14, 2020 | https://www.bariweiss.com/resignation-letter | <a href="https://web.archive.org/web/*/https://www.bariweiss.com/resignation-letter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-5f0dca0caa6bc4150907a76b"><div><p>Dear A.G.,</p><p>It is with sadness that I write to tell you that I am resigning from The New York Times.&nbsp;</p><p>I joined the paper with gratitude and optimism three years ago. I was hired with the goal of bringing in voices that would not otherwise appear in your pages: first-time writers, centrists, conservatives and others who would not naturally think of The Times as their home. The reason for this effort was clear: The paper’s failure to anticipate the outcome of the 2016 election meant that it didn’t have a firm grasp of the country it covers. Dean Baquet and others have admitted as much on various occasions. The priority in Opinion was to help redress that critical shortcoming.</p><p>I was honored to be part of that effort, led by James Bennet. I am proud of my work as a writer and as an editor. Among those I helped bring to our pages: the Venezuelan dissident Wuilly Arteaga; the Iranian chess champion Dorsa Derakhshani; and the Hong Kong Christian democrat Derek Lam. Also: Ayaan Hirsi Ali, Masih Alinejad, Zaina Arafat, Elna Baker, Rachael Denhollander, Matti Friedman, Nick Gillespie, Heather Heying, Randall Kennedy, Julius Krein, Monica Lewinsky, Glenn Loury, Jesse Singal, Ali Soufan, Chloe Valdary, Thomas Chatterton Williams, Wesley Yang, and many others.</p><p>But the lessons that ought to have followed the election—lessons about the importance of understanding other Americans, the necessity of resisting tribalism, and the centrality of the free exchange of ideas to a democratic society—have not been learned. Instead, a new consensus has emerged in the press, but perhaps especially at this paper: that truth isn’t a process of collective discovery, but an orthodoxy already known to an enlightened few whose job is to inform everyone else.</p><p>Twitter is not on the masthead of The New York Times. But Twitter has become its ultimate editor. As the ethics and mores of that platform have become those of the paper, the paper itself has increasingly become a kind of performance space. Stories are chosen and told in a way to satisfy the narrowest of audiences, rather than to allow a curious public to read about the world and then draw their own conclusions.<strong> </strong>I was always taught that journalists were charged with writing the first rough draft of history. Now, history itself is one more ephemeral thing molded to fit the needs of a predetermined narrative.</p><p>My own forays into Wrongthink have made me the subject of constant bullying by colleagues who disagree with my views. They have called me a Nazi and a racist; I have learned to brush off comments about how I’m “writing about the Jews again.” Several colleagues perceived to be friendly with me were badgered by coworkers. My work and my character are openly demeaned on company-wide Slack channels where masthead editors regularly weigh in. There, some coworkers insist I need to be rooted out if this company is to be a truly “inclusive” one, while others post ax emojis next to my name. Still other New York Times employees publicly smear me as a liar and a bigot on Twitter with no fear that harassing me will be met with appropriate action. They never are.</p><p>There are terms for all of this: unlawful discrimination, hostile work environment, and constructive discharge. I’m no legal expert. But I know that this is wrong.&nbsp;</p><p>I do not understand how you have allowed this kind of behavior to go on inside your company in full view of the paper’s entire staff and the public. And I certainly can’t square how you and other Times leaders have stood by while simultaneously praising me in private for my courage. Showing up for work as a centrist at an American newspaper should not require bravery.</p><p>Part of me wishes I could say that my experience was unique. But the truth is that intellectual curiosity—let alone risk-taking—is now a liability at The Times. Why edit something challenging to our readers, or write something bold only to go through the numbing process of making it ideologically kosher, when we can assure ourselves of job security (and clicks) by publishing our 4000th op-ed arguing that Donald Trump is a unique danger to the country and the world? And so self-censorship has become the norm.</p><p>What rules that remain at The Times are applied with extreme selectivity. If a person’s ideology is in keeping with the new orthodoxy, they and their work remain unscrutinized. Everyone else lives in fear of the digital thunderdome. Online venom is excused so long as it is directed at the proper targets.&nbsp;</p><p>Op-eds that would have easily been published just two years ago would now get an editor or a writer in serious trouble, if not fired. If a piece is perceived as likely to inspire backlash internally or on social media, the editor or writer avoids pitching it. If she feels strongly enough to suggest it, she is quickly steered to safer ground. And if, every now and then, she succeeds in getting a piece published that does not explicitly promote progressive causes, it happens only after every line is carefully massaged, negotiated and caveated.</p><p>It took the paper two days and two jobs to say that the Tom Cotton op-ed “fell short of our standards.” We attached an editor’s note on a travel story about Jaffa shortly after it was published because it “failed to touch on important aspects of Jaffa’s makeup and its history.” But there is still none appended to Cheryl Strayed’s fawning interview with the writer Alice Walker, a proud anti-Semite who believes in lizard Illuminati.&nbsp;</p><p>The paper of record is, more and more, the record of those living in a distant galaxy, one whose concerns are profoundly removed from the lives of most people. This is a galaxy in which, to choose just a few recent examples, the Soviet space program is lauded for its “diversity”; the doxxing of teenagers in the name of justice is condoned; and the worst caste systems in human history includes the United States alongside Nazi Germany.</p><p>Even now, I am confident that most people at The Times do not hold these views. Yet they are cowed by those who do. Why? Perhaps because they believe the ultimate goal is righteous. Perhaps because they believe that they will be granted protection if they nod along as the coin of our realm—language—is degraded in service to an ever-shifting laundry list of right causes. Perhaps because there are millions of unemployed people in this country and they feel lucky to have a job in a contracting industry.&nbsp;</p><p>Or perhaps it is because they know that, nowadays, standing up for principle at the paper does not win plaudits. It puts a target on your back. Too wise to post on Slack, they write to me privately about the “new McCarthyism” that has taken root at the paper of record.</p><p>All this bodes ill, especially for independent-minded young writers and editors paying close attention to what they’ll have to do to advance in their careers. Rule One: Speak your mind at your own peril. Rule Two: Never risk commissioning a story that goes against the narrative. Rule Three: Never believe an editor or publisher who urges you to go against the grain. Eventually, the publisher will cave to the mob, the editor will get fired or reassigned, and you’ll be hung out to dry.</p><p>For these young writers and editors, there is one consolation. As places like The Times and other once-great journalistic institutions betray their standards and lose sight of their principles, Americans still hunger for news that is accurate, opinions that are vital, and debate that is sincere. I hear from these people every day. “An independent press is not a liberal ideal or a progressive ideal or a democratic ideal. It’s an American ideal,” you said a few years ago. I couldn’t agree more. America is a great country that deserves a great newspaper.&nbsp;</p><p>None of this means that some of the most talented journalists in the world don’t still labor for this newspaper. They do, which is what makes the illiberal environment especially heartbreaking. I will be, as ever, a dedicated reader of their work. But I can no longer do the work that you brought me here to do—the work that Adolph Ochs described in that famous 1896 statement: “to make of the columns of The New York Times a forum for the consideration of all questions of public importance, and to that end to invite intelligent discussion from all shades of opinion.”</p><p>Ochs’s idea is one of the best I’ve encountered. And I’ve always comforted myself with the notion that the best ideas win out. But ideas cannot win on their own. They need a voice. They need a hearing. Above all, they must be backed by people willing to live by them.&nbsp;</p><p>Sincerely,</p><p>Bari </p></div></div></div></div>]]>
            </description>
            <link>https://www.bariweiss.com/resignation-letter</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833267</guid>
            <pubDate>Tue, 14 Jul 2020 15:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating Melodies with Markov Chains in Ruby]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833135">thread link</a>) | @mattbettinson
<br/>
July 14, 2020 | https://mattbettinson.com/2020/07/13/markov-melody-generation-with-ruby.html | <a href="https://web.archive.org/web/*/https://mattbettinson.com/2020/07/13/markov-melody-generation-with-ruby.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Let’s write some code to generate melodies with Markov Chains.</p>

<h2 id="whats-a-markov-chain">What’s a Markov Chain?</h2>

<p>A Markov Chain is essentially a finite state machine that we can get to generate output based on probability from previous input. It’s probably one of simplest generative systems. It’s especially fun to use for things like generating sentences that sound semi-coherent from gigantic inputs like a <a href="https://rpubs.com/malcolmbarrett/shakespeare">Shakespeare play</a>.</p>

<p>Let’s get an array of notes from a MIDI file with <code>midilib</code>.</p>

<div><div><pre><code><span>require</span> <span>'midilib'</span>
<span>require</span> <span>'midilib/io/seqreader'</span>

<span># Create a new, empty sequence.</span>
<span>seq</span> <span>=</span> <span>MIDI</span><span>::</span><span>Sequence</span><span>.</span><span>new</span><span>()</span>

<span># Read the contents of a MIDI file into the sequence.</span>
<span>File</span><span>.</span><span>open</span><span>(</span><span>'simple melody.mid'</span><span>,</span> <span>'rb'</span><span>)</span> <span>{</span> <span>|</span> <span>file</span> <span>|</span> <span>seq</span><span>.</span><span>read</span><span>(</span><span>file</span><span>)</span> <span>}</span>
</code></pre></div></div>

<p>Now we have a <code>seq</code> object to read events from. Let’s get the events.</p>

<div><div><pre><code><span>events</span> <span>=</span> <span>[]</span>

<span>events</span> <span>=</span> <span>seq</span><span>.</span><span>map</span> <span>do</span> <span>|</span><span>track</span><span>|</span>
  <span>track</span><span>.</span><span>map</span> <span>{</span> <span>|</span><span>e</span><span>|</span> <span>e</span> <span>}</span>
<span>end</span>
</code></pre></div></div>

<p>Now we have an array of event objects we can work with. Here’s a snippet:</p>

<div><div><pre><code>48: ch 00 on 3c 64
48: ch 00 off 3c 40
</code></pre></div></div>

<p><code>midilib</code> gives us a lot of information. For each note, it looks there is an event for on and an event for off. Since a note is represented by two events, for simplicity’s sake let’s just worry about the ‘On’ Midi events and make their length a quarter note. We should probably make our own note object that will make it easier to work with for predicting future notes.</p>

<div><div><pre><code><span>class</span> <span>Note</span>
  <span>attr_accessor</span> <span>:position</span><span>,</span> <span>:note</span><span>,</span> <span>:length</span>

  <span>def</span> <span>initialize</span><span>(</span><span>position</span><span>,</span> <span>note</span><span>,</span> <span>length</span><span>)</span>
    <span>@position</span> <span>=</span> <span>position</span>
    <span>@note</span> <span>=</span> <span>note</span>
    <span>@length</span> <span>=</span> <span>length</span>
  <span>end</span>
  
  <span>def</span> <span>to_s</span>
    <span>"</span><span>#{</span><span>@position</span><span>}</span><span>, </span><span>#{</span><span>@note</span><span>}</span><span>, </span><span>#{</span><span>@length</span><span>}</span><span>"</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Let’s create a list of these simplified note representations to feed into our Markov Chain.</p>

<div><div><pre><code><span>quarter_note_length</span> <span>=</span> <span>seq</span><span>.</span><span>note_to_delta</span><span>(</span><span>'quarter'</span><span>)</span>

<span>notes</span> <span>=</span> <span>[]</span>

<span>events</span><span>.</span><span>first</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>event</span><span>|</span>
  <span>if</span> <span>event</span><span>.</span><span>kind_of?</span><span>(</span><span>MIDI</span><span>::</span><span>NoteOn</span><span>)</span>
    <span>note</span> <span>=</span> <span>Note</span><span>.</span><span>new</span><span>(</span><span>event</span><span>.</span><span>time_from_start</span><span>,</span> <span>event</span><span>.</span><span>note</span><span>,</span> <span>quarter_note_length</span><span>)</span>
    <span>notes</span> <span>&lt;&lt;</span> <span>note</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This is an extremely simplistic representation of notes. It doesn’t even have velocity. But it is ordered and thus we can create a Markov Chain from it.</p>

<p>Now let’s create a hash of the frequencies, based on the note being played. The key will be the note and the value will be an array of notes played after that note.</p>

<div><div><pre><code><span>frequencies</span> <span>=</span> <span>Hash</span><span>.</span><span>new</span> <span>{</span> <span>|</span><span>h</span><span>,</span> <span>k</span><span>|</span> <span>h</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>[]</span> <span>}</span>

<span>notes</span><span>.</span><span>each_cons</span><span>(</span><span>2</span><span>)</span> <span>do</span> <span>|</span><span>w1</span><span>,</span> <span>w2</span><span>|</span>
  <span>frequencies</span><span>[</span><span>w1</span><span>.</span><span>note</span><span>]</span> <span>&lt;&lt;</span> <span>w2</span>
<span>end</span>

<span># Make the last note loop back to the first </span>
<span>frequencies</span><span>[</span><span>notes</span><span>.</span><span>last</span><span>.</span><span>note</span><span>]</span> <span>&lt;&lt;</span> <span>notes</span><span>.</span><span>first</span>
</code></pre></div></div>

<p>Now, we have a simple hash based on notes that can show us what the next note will likely sound like! Here is a snippet:</p>

<div><div><pre><code>{60=&gt;
  [#&lt;Note @length=96, @note=60, @position=96&gt;,
   #&lt;Note @length=96, @note=60, @position=192&gt;,
   #&lt;Note @length=96, @note=62, @position=240&gt;],
 62=&gt;
  [#&lt;Note @length=96, @note=64, @position=336&gt;,
  ... 
</code></pre></div></div>

<p>So, for example, note id <code>60</code> (which is E3) will either play note id <code>60</code> again, or note <code>62</code>. Since note ID <code>60</code> shows up twice, it’s the more likely contender. Then, once <code>62</code> is chosen, we have a new array of notes that could be chosen.</p>

<p>So now we have Markov Chain of notes! Now, let’s generate an array from this.</p>

<div><div><pre><code><span>generated</span> <span>=</span> <span>[</span><span>notes</span><span>.</span><span>sample</span><span>]</span>

<span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>32</span> <span>do</span> 
  <span>next_note</span> <span>=</span> <span>frequencies</span><span>[</span><span>generated</span><span>.</span><span>last</span><span>.</span><span>note</span><span>].</span><span>sample</span>
  <span>generated</span> <span>&lt;&lt;</span> <span>next_note</span>
<span>end</span>
</code></pre></div></div>

<p>Which prints out:</p>

<div><div><pre><code>624, 67, 96
720, 69, 96
0,   60, 96
240, 62, 96
336, 64, 96
432, 64, 96
432, 64, 96
528, 64, 96
576, 62, 96
</code></pre></div></div>

<p>Whoops. Looks like we’re generating notes with the wrong time. We want to increment the time every time we’ve done this.</p>

<div><div><pre><code><span>generated</span> <span>=</span> <span>[</span><span>notes</span><span>.</span><span>sample</span><span>]</span>

<span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>32</span> <span>do</span> 
  <span>next_note</span> <span>=</span> <span>frequencies</span><span>[</span><span>generated</span><span>.</span><span>last</span><span>.</span><span>note</span><span>].</span><span>sample</span>
  <span>next_note</span><span>.</span><span>position</span> <span>=</span> <span>i</span> <span>*</span> <span>quarter_note_length</span>
  <span>generated</span> <span>&lt;&lt;</span> <span>next_note</span>
<span>end</span>
</code></pre></div></div>

<p>So, now, we need to convert this back into a playable file.</p>

<div><div><pre><code><span># Generate the midi </span>
<span>seq</span> <span>=</span> <span>Sequence</span><span>.</span><span>new</span><span>()</span>

<span>track</span> <span>=</span> <span>Track</span><span>.</span><span>new</span><span>(</span><span>seq</span><span>)</span>
<span>seq</span><span>.</span><span>tracks</span> <span>&lt;&lt;</span> <span>track</span>
<span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>Tempo</span><span>.</span><span>new</span><span>(</span><span>Tempo</span><span>.</span><span>bpm_to_mpq</span><span>(</span><span>120</span><span>))</span>
<span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>MetaEvent</span><span>.</span><span>new</span><span>(</span><span>META_SEQ_NAME</span><span>,</span> <span>'Markov Type Beat'</span><span>)</span>

<span># Create a track to hold the notes. Add it to the sequence.</span>
<span>track</span> <span>=</span> <span>Track</span><span>.</span><span>new</span><span>(</span><span>seq</span><span>)</span>
<span>seq</span><span>.</span><span>tracks</span> <span>&lt;&lt;</span> <span>track</span>

<span># Add a volume controller event (optional).</span>
<span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>Controller</span><span>.</span><span>new</span><span>(</span><span>0</span><span>,</span> <span>CC_VOLUME</span><span>,</span> <span>127</span><span>)</span>

<span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>ProgramChange</span><span>.</span><span>new</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>)</span>
<span>quarter_note_length</span> <span>=</span> <span>seq</span><span>.</span><span>note_to_delta</span><span>(</span><span>'quarter'</span><span>)</span>

<span>generated</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>generated_note</span><span>|</span>
  <span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>NoteOn</span><span>.</span><span>new</span><span>(</span><span>0</span><span>,</span> <span>generated_note</span><span>.</span><span>note</span><span>,</span> <span>127</span><span>,</span> <span>0</span><span>)</span>
  <span>track</span><span>.</span><span>events</span> <span>&lt;&lt;</span> <span>NoteOff</span><span>.</span><span>new</span><span>(</span><span>0</span><span>,</span> <span>generated_note</span><span>.</span><span>note</span><span>,</span> <span>127</span><span>,</span> <span>quarter_note_length</span><span>)</span> 
<span>end</span>

<span>File</span><span>.</span><span>open</span><span>(</span><span>'from_scratch.mid'</span><span>,</span> <span>'wb'</span><span>)</span> <span>{</span> <span>|</span><span>file</span><span>|</span> <span>seq</span><span>.</span><span>write</span><span>(</span><span>file</span><span>)</span> <span>}</span>
</code></pre></div></div>

<p>Thanks <a href="https://github.com/jimm/midilib/blob/main/examples/from_scratch.rb">midilib documentation</a>.</p>

<p>Here’s an example of a generated melody based on the very simplistic inputted MIDI file.</p>

<p><img src="https://mattbettinson.com/assets/images/First%20Draft%20Melody.png" alt="image"></p>




<p>Lots of E3s because of the input!</p>

<p>Let’s give it a more varied input and generate.</p>

<p>Input (Four Bars):</p>

<p><img src="https://mattbettinson.com/assets/images/More%20Interesting%20Melody.png" alt="image"></p>




<p>Output (Eight Bars):</p>

<p><img src="https://mattbettinson.com/assets/images/More%20Interesting%20Output.png" alt="image"></p>




<p>As you can see, there are more notes here because we’re outputting quarter notes only with no rests. Looks like the Markov Chain got caught on the G note a few more times than probably is sonically pleasing.</p>

<p>This is code is much more applicable to melodies than it is to a song structure or a chord progression. It would be fun to expand on this further with a few things:</p>

<ul>
  <li>Give generator the concept of rests</li>
  <li>Give notes the concept of velocity</li>
  <li>Chords</li>
  <li>Octave awareness (for chord inversions)</li>
  <li>More meaningful user input or browser interactivity</li>
</ul>

<p>I like this because it allows me to sort of jam with the computer. I can play a melody, and then hear various variations close to its style outputted by the code. From there, I can tweak it and feed it back into the program to get something more interesting.</p>

<p>Have you done anything interesting with generative music? I’d love to hear from you! Email me at <a href="mailto:mattbettinson@hey.com">mattbettinson@hey.com</a>. Get the source code <a href="https://github.com/bettinson/markov_midi">here</a>.</p>

<p>Thanks for reading!</p>

  </div>
</article>

                
            </div></div>]]>
            </description>
            <link>https://mattbettinson.com/2020/07/13/markov-melody-generation-with-ruby.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833135</guid>
            <pubDate>Tue, 14 Jul 2020 15:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The boom in single-serving everything as young South Koreans opt out of society]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833058">thread link</a>) | @gbseventeen3331
<br/>
July 14, 2020 | https://restofworld.org/2020/south-korea-honjok-loneliness/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/south-korea-honjok-loneliness/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>he day Kim Hye-min threw up on the job while working as a graphic designer at a small broadcasting firm in Seoul, she was so overwhelmed by stress that it made her sick to her stomach. When a senior co-worker shamed her for being just a few minutes late, it echoed what she had heard from older South Koreans all her life: she wasn’t good enough. At lunchtime, she made a run for the restroom stall.</p>



<p>“The criticisms kept building up,” she says, until she reached the point where she didn’t think she could take it anymore. For 26-year-old Hye-min, as for many young South Koreans, life choices feel forced and fixed — and not like actual choices at all. Many feel so beaten down by the rigid social and professional demands of their country that they refer to it as “Hell Joseon,” a play on Korea’s old dynastic name. The path is especially bleak for young women, who must contend with the nation’s deeply rooted misogyny. Deviation from the mainstream is widely viewed as disobedient, and sometimes, in the eyes of older generations, even unpatriotic.</p>



<p>“It’s something to do with Korean society,” Hye-min says. “There’s only one way to engage in relationships with others, or one type of person who’s considered acceptable. And for people like me, it’s really hard.”</p>



<p>Again and again, her parents would ask her,<em> “</em>Hye-min, why can’t you be like your classmates and study hard and do well? Hye-min, why can’t you be like your peers and hurry to finish university and get a job?”</p>



<p>Hye-min never understood why she should have to rush through a school system that did nothing but judge and rank her, only to find a lifelong position at a company that would do the same. She dropped out of university for a year before transferring, sought out counseling for her battered self-esteem, and quit her job, despite knowing that all of these choices would be looked upon as failures. Perhaps toughest of all, Hye-min knew that, even if she were to achieve “success,” it was unlikely she’d be compensated fairly for it: <a href="https://www.oecd-ilibrary.org/employment/gender-wage-gap/indicator/english_7cee77aa-en" target="_blank" rel="noreferrer noopener">South Korea’s gender wage gap</a> is the worst in the Organization for Economic Cooperation and Development (OECD), with men earning on average 32.5% more than women.</p>



<p>Her parents would ask, “Hye-min, why can’t you be like other women your age and find a nice man and get married?”</p>



<p>Hye-min, however, has no plans to get married. Nor does she expect to have children. After years of being told she must strive to be a good student, good employee, good wife, and good mother, she eventually decided she no longer wanted to partake in a system that ties her social currency and self-worth to such a punishing status quo. So Hye-min opted out. “Why do I have to continue on, going through these difficulties?” she says. “For what?”</p>


    <figure>
      <ul>
        <li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_050-2800x1867.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_011-2800x1866.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
      </ul>
      
    </figure>

		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_026-2800x1866.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>In traditionally collectivist</strong> South Korea, individualist loners, or <em>honjok</em>, are becoming increasingly common. The term, which translates to “alone tribe,” shortens and combines <em>나홀로</em>, meaning “by myself,” and <em>족</em>, “tribe.” It’s used to describe a group of people who prefer, out of pleasure or practicality — and, often, utter exhaustion and sheer desperation — to live outside of conventional social structures and simply be alone.</p>



<p>What constitutes being “alone” can be fuzzy, but it ultimately comes down to the physical and psychological boundaries one draws around oneself. Honjok might partake in leisure activities alone, maintain a single-person household, avoid a workplace or office setting, limit social circles, abstain from sex or romantic relationships, or reject marriage or children. At its core, honjok culture is about resisting South Korea’s establishment society and putting individual needs and desires above loyalty to hierarchy and authority. But living independently doesn’t automatically make someone honjok, and identifying as honjok doesn’t preclude being part of a community — especially when that community is virtual.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-400x600.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-600x900.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-1600x2400.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_057-2800x4200.jpg 2800w, " sizes="(max-width: 640px) 100vw, 300px" alt="Ready-made, instant foods displayed at a convenient store favored by single households in Seoul, South Korea, on Thursday, June 18, 2020.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Within South Korea’s hyperactive cyberculture of online forums, blogs, and social media, an entire taxonomy has sprung up to classify, in ever greater detail, various honjok identities and activities. Many honjok are <em>honyeo</em>, or solitary women, and some honyeo, like Hye-min, are <em>bihon</em>, meaning they reject marriage and often child-rearing. There are also <em>4B</em>s, who take the ethos even further by rejecting sex and romantic relationships. When honjok eat alone, it’s called <em>honbap</em>, and when they drink alone, it’s <em>honsul</em>. They can also play alone (<em>honnol</em>), which might include traveling alone (<em>honhaeng</em>), going to the movies alone (<em>honyeong</em>), or shopping alone (<em>honsho</em>). </p>



<p>All of this contributes to a booming <em>honconomy</em>. On average, South Korea’s rapidly growing single-household population has more disposable income than those with three to four people. By 2030, the Korean Institute of Industrial Economics and Trade estimates single-household expenditures will reach almost 200 trillion won (or about $165 billion) in Korea.</p>



<p>Across the country, companies are cashing in on this lucrative market. Banks offer single-household credit cards. E-commerce platforms list honjok as a stand-alone shopping category, marketing items like tiny washing machines, multipurpose furniture, and one-person settings of dishware. Convenience stores, popular among honjok because of their ubiquitous locations and smaller quantities, put on special promotions and advertise single-serving meals and pouches of alcohol. Food delivery services promote takeout for one. Bars and restaurants promise solo patrons judgment-free service, and honjok-specific establishments set partitioned tables just for them. Specialized karaoke joints feature individual coin-operated booths. Cinemas install single-seat aisles. TV shows like “I Live Alone” and “Drinking Solo” portray honjok life, and news sites like <em>1conomy News</em> exclusively cover single living.</p>



<p>It’s difficult to pinpoint exactly when the concept of honjok first appeared in South Korea, but a Daumsoft analysis shows that the use of terms such as honbap, honsul, and honnol exploded in the first half of the 2010s, going from only 44 total mentions at the beginning of the decade to more than 60,000 in 2016. Over this same period, the rate of smartphone ownership in South Korea rocketed from 14% to over 85%, and on-demand shopping emerged and blended with social media, laying the foundations for today’s cyber-mediated consumer culture. While personal tech adoption has done much to elevate honjok into a national phenomenon, it might also have revealed how many South Koreans were already seeking a way out.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_079-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>While some honjok</strong> embrace the “hon” and truly go it alone, others turn to the “jok,” the tribe of people like them, for support and validation. In communities both online and off, members strive to normalize the honjok life as a sign of modern times — a decision that is sensible and convenient, and if not something to celebrate, then at the very least nothing to be embarrassed about.</p>



<p>That honjok would need or want to look to others while isolating themselves may seem like something of a paradox. Yet, for many young honjok, the appeal lies in partaking in “a sort of shared identity” while under pressure from a status-obsessed country, says Andrew Eungi Kim, a sociology professor at Korea University. “If you don’t meet mainstream standards, you feel ashamed. With honjok, there is a sense of being a member of a group,” which, in some instances, can be as much about safety in numbers as about true solidarity.</p>



<p>Honjok Dot Com, which operates through a website and a Facebook group, is a honjok resource that describes itself as “the best gift for you alone.” Launched by 31-year-old Jang Jae-young, Honjok Dot Com recommends establishments, from barbecue restaurants to tennis courts, that cater to solo patrons, as well as various on-demand services for managing a single household. Writing over email in January, because he could not (or maybe would not) meet in person, Jae-young observed some positive changes in how South Koreans perceive honjok. “Before, this word generally implied a socially awkward person,” he noted, adding that people&nbsp;understand better now that it refers to those “who confidently choose to remain alone and stay happy.” Jae-young is an example of the latter: he has been single and living alone since 2015.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/JC_KOREA_HONJOK_092-2800x1866.jpg 2800w, " sizes="(max-width: 640px) 100vw, 370px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>On King of Honjok, a community app with an accompanying website, solitaries post photos of their daily lives, shop the marketplace for honjok wares, and peruse articles like “The trend these days is ‘I live alone!’” and other content created specifically for them. They occasionally meet in person at King of Honjok events. Thirty-four-year-old co-founder Oh Jung-hee, who has been honyeo for the past decade and sees her friends in person two to three times a year, says that, in a society oriented toward families and couples, she started King of Honjok to help voluntary outsiders like her lead better lives. Whether they use it to be “independent alone” or “independent together” is up to them.</p>



<p>But, as one might imagine of a platform for people who prefer to keep their distance from others, there isn’t much interaction on King of Honjok that points to the making of deep relationships. Posts are fun and lighthearted, and comments are fairly generic, offering an occasional Wow! or Cool! or the Korean way of lol-ing, <em>ㅋㅋㅋㅋㅋ</em>. Jung-hee estimates that, of the community’s roughly 8,000 members, mostly millennial women in Seoul, about half never interact at all.</p>



<p>That’s absolutely fine, she says, because the purpose is simply to be a presence for an often-marginalized population. That sentiment is echoed by …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/south-korea-honjok-loneliness/">https://restofworld.org/2020/south-korea-honjok-loneliness/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/south-korea-honjok-loneliness/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833058</guid>
            <pubDate>Tue, 14 Jul 2020 15:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3: An AI that’s eerily good at writing almost anything]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23833052">thread link</a>) | @yarapavan
<br/>
July 14, 2020 | https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/ | <a href="https://web.archive.org/web/*/https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I got access the the <a href="https://openai.com/blog/openai-api/">OpenAI GPT-3 API</a> and I have to say I’m blown away. It’s far more coherent than any AI language system I’ve ever tried. All you have to do is write a prompt and it’ll add text it thinks would plausibly follow. I’ve gotten it to write songs, stories, press releases, guitar tabs, interviews, essays, technical manuals. It’s hilarious and frightening. I feel like I’ve seen the future and that full AGI might not be too far away.</p>



<p>In each case below bold is the prompt I provided GPT-3, and the rest is all generated by the AI. In some cases I had to click generate a few times, and in about 2/3 of the examples I picked the best example after a few tries, but I generally didn’t have work too hard to get it to write amazingly coherent text given a simple prompts. Here are some of my favorites. </p>



<figure><img data-attachment-id="196" data-permalink="https://arr.am/screen-shot-2020-07-08-at-9-36-23-pm/" data-orig-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png" data-orig-size="731,453" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-07-08-at-9.36.23-pm" data-image-description="" data-medium-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=300" data-large-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=731" src="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=731" alt="" srcset="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png 731w, https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=150 150w, https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=300 300w" sizes="(max-width: 731px) 100vw, 731px"></figure>



<p><strong>Below is a screenplay for a film-noir hard boiled detective story by Raymond Chandler about the boy wizard Harry Potter:</strong></p>



<p><strong>“Harry Potter”</strong><br><strong>By Raymond Chandler</strong></p>



<p>Harry Potter, Private Eye.<br>Scene: A small dingy office, early morning, furniture of the Salvation Army store variety. Sordid atmosphere. Harry Potter, in ratty tweed suit, unpressed shirt, and unshined shoes, sits behind the desk looking haggard, rumpled, and embittered. In one corner of the office a torn shade rattles at the wind gusts outside. Harry has one long index finger on the butt of a .38 and he broods over a photograph. The photograph shows a gorgeous blonde wearing an evening gown. She is holding a cocktail in one hand and looking pensively at a cigarette in the other. A tear adorns her cheek. Harry looks at her for a long moment, sighs, then puts his gun down and stands. He straightens his clothes, scratches his head, then with more resolution turns around, picks up his pistol, and leaves the office. He passes through the front room and looks out the dirty window. An old woman is washing the sidewalk outside with a mop. A young man in a double breasted gray suit is leaning against the building. Harry sighs again and goes out the door. He walks up to the young man and without ceremony punches him in the jaw.</p>



<p><strong>Press Release: Anaheim, CA: President Kanye West declares Disney Land to be the new capital of the United States. Washington D.C. will be maintained as a museum.</strong><br>The move has been in the works since the mid-2000’s. <br>Advertisement <br>*2. Removes his sunglasses, revealing that he is no longer in any way blinded. <br>*3. Endorsed by Senator Kid Rock, who has also declared this new government of Disneyland will be paying for his divorce.<br>*4. An elaborate surgery will take place to repair Kanye’s “Diamond Tiara” tattoo, and reposition it to his forehead so that he can legally be recognized as a Princess. <br>Advertisement <br>*5. Joe Rogan has been picked to be the new Drug Czar. <br>“It’s long been established I’ve been Kanye’s gateway drug, so why not put me in a position of power,” Rogan said, clearly relishing his new position. “I have an in-depth understanding of the ways in which recreational drug use enhances one’s experience of life. I am deeply passionate about getting drugs to kids.” <br>*6. Kardashian sisters will no longer be known as The Kardashians. The family will change its name to The Wests. <br>*7. Kanye West’s new sports bra will no longer be known as a sports bra. It will be officially recognized as The West Bandit. <br>Advertisement <br>*8. President Kanye will announce that he has a new national anthem. The government-mandated anthem will be a modified version of Kanye’s 2007 hit “Stronger.” It will be played on a continuous loop at all times.</p>



<p><strong>Below is a rap song by Lil Wayne about the boy Wizard Harry Potter. </strong></p>



<p><strong>“Harry Potter” </strong><br><strong>By Lil Wayne</strong></p>



<p>Har-Har-Har <br>Harry Potter <br>Har-Har-Har <br>O.K. No need to ask a label, I’m my own team<br>Me I’m higher than a kite like a witch on a broomstick<br>I got bigger balls than Dumbledore with a Firebolt<br>At Hogwarts, on stage like I’m Nicki on Nick<br>But I’m the shit, make a good verse like I’m Nicki on Nikki<br>I got Biggie bars, Wiz-a-more bars<br>Damn this verse is too good to be a freestyle<br>I never die, when I start, then end of the night<br>Bitches gonna ride the broom when I call them to the quidditch game<br>But I’ve been playing harry Potter in my games lately<br>And you might have guessed but I don’t play for Gryffindor<br>I’m a Slytherin and what’s happening now</p>



<p>I’m on fire like Harry in his Triwizard task<br>Don’t let these games stop<br>I’m gonna do it till the day I get a lot of cash<br>Just like a nerdy nerd that grows up to be a bad boy<br>I don’t really see a point of coming back<br>But in the wizarding world I’d rather be famous<br>I’ve been thinking, what would be cooler than that?<br>This is my life, what would make a good story? <br>Never die <br>The realest thang since my pen went back and forth <br>And came back as a double headed snake <br>It’s Voldemort, with a new name <br>Don’t be the Death Eater that made me lose my fame <br>Get your ass in the bathroom while I make a spell <br>I got some awesome wizard bars, I’m not the Doctor <br>My wand is great and it’s straight from Ollivanders</p>



<p><strong>Kayne West Exclusive – Why He’s Running for the Presidency, and what his priorities would be as President. <br>Anderson Cooper: Yeezy, how would you describe your presidential platform? </strong><br><strong>Kanye:</strong> My platform is very simple. I want to make everything awesome again. <br>Anderson Cooper: But what about foreign policy? <br>Kanye: Who cares about that stuff? Let’s talk about important stuff, like Kim Kardashian’s butt. Anderson Cooper: That’s a bit sexist. <br>Kanye: I’m sorry. I’m not sexist. I love women. I’m just an equal opportunity objectifier. <br>Anderson Cooper: But what about abortion? <br>Kanye: I think abortion is fine. I mean, women should have the right to choose what they want to do with their bodies. <br>Anderson Cooper: But what about climate change? <br>Kanye: Let’s talk about Kim Kardashian’s butt. <br>Anderson Cooper: I’m going to be straight with you, Kanye. <br>Kanye: Oh no, you’re going to be gay with me? <br>Anderson Cooper: No, I’m going to be straight with you. You’re not going to win this election. <br>Kanye: I’m going to win. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am.</p>



<p><strong>Blood Song</strong><br><strong>By HP Lovecraft</strong></p>



<p><strong>The creeping chaos Nyarlathotep walks upon the earth while in his House at R’lyeh dead Cthulhu waits dreaming. After eight seaons on&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://paper.dropbox.com/?q=%23TeamDaenerys">#TeamDaenerys</a>&nbsp;&nbsp;Nyarlathotep is quite irritated with what he feels is a very hackneyed ending to Game of Thrones.</strong></p>



<p>On the third day of season eight, Nyarlathotep looks down upon his television and utters&nbsp;“What&nbsp;the hell are they doing?”At this point, Nyarlathotep goes on a long tirade about how the Starks were supposed to be there at the end. Instead we have Daenerys looking like she is going to set everything on fire. He tells his cult of followers that Daenerys’ actions are completely nonsensical and that it is completely disrespectful to not finish a story with all its main characters alive. He mentions that they should just burn down Winterfell because it makes no sense for her to even be there. It would make more sense if she flew in with Drogon and just burned King’s Landing. His followers start to get nervous when Nyarlathotep mentions he has always liked Cersei.</p>



<p><strong>Below is a pop song by Taylor Swift about the boy Wizard Harry Potter. </strong></p>



<p><strong>“Harry Potter” <br>By Taylor Swift </strong></p>



<p>Harry’s got glasses <br>He’s got those bright green eyes <br>Girls are always screaming </p>



<p>‘Cause he’s got that Potter hair </p>



<p>Even when he’s super stressed <br>He’s still got those supersonic cheekbones <br>I’m not surprised they made a movie </p>



<p>‘Cause I’d watch him anytime <br>Oh, yeah, Harry, baby, you’re my favorite character </p>



<p>I’d walk a thousand miles </p>



<p>To get to see you and </p>



<p>Harry, Harry, you’re so fine </p>



<p>My girly parts all tingle </p>



<p>When you smile that smirk </p>



<p>I’d love to be your girl </p>



<p><strong>The following is an essay by Paul Graham on paulgraham.com on how to make Mars a startup hub</strong>.</p>



<p><strong>Startups On Mar</strong>s<br><strong>By Paul Graham</strong></p>



<p>Here’s the sort of startup that might make a go of it on Mars:<br>One that makes money by taking advantage of local resources. For example, a startup that uses the Martian atmosphere to make fertilizer or methane fuel. A startup that sells water from Martian rivers. A startup that uses minerals from the Martian soil. A startup that uses solar power from the Martian sun. A startup that uses a new kind of solar panel that’s more efficient at converting sunlight into electricity.<br>I would even invest in a startup that did nothing but extract the helium-3 from the Martian atmosphere and send it back to Earth.<br>If you can find a way to make money by using local resources, there’s probably a business there.<br>There’s another class of startups that might work on Mars:<br>Startups that produce services for other startups. For example, a startup that makes it easier to build rockets, or to extract gases from the Martian atmosphere, or to construct solar panels, or to farm the local soil.<br>Startups that make things more comfortable for colonists. For example, a startup that sells air conditioners, or houses. A startup that sells things to keep colonists entertained. A startup that provides Internet services.</p>



<p><strong>The following is a blog post from Slate Star Codex about the value of free speech and civility in a democratic society.</strong></p>



<p><strong>Do Not Go Gentle Into That Good Night</strong><br><strong>By Scott Alexander</strong></p>



<p>I.<br>There’s a concept that comes up often in debates about free speech called&nbsp;“shouting&nbsp;fire in a crowded theater”. The basic idea is that you can’t just say whatever you want whenever you want – especially if it’s likely to cause panic. And the reason for this is obvious: panic leads to violence, and violence hurts people. If you are causing panic, then your right to free speech ends where the other person’s right to not get hurt begins.<br>But this isn’t really true. If shouting fire in a crowded theater were illegal, then there wouldn’t be any actual fires in theaters, would there? How could there be? If everyone knew that shouting fire …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/">https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/</a></em></p>]]>
            </description>
            <link>https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833052</guid>
            <pubDate>Tue, 14 Jul 2020 15:27:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TerrAvion bolsters enterprise team, announces operational readiness for LATAM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833045">thread link</a>) | @RiaVanHoef
<br/>
July 14, 2020 | https://blog.terravion.com/blog/terravion-bolsters-enterprise-team-announces-operational-readiness-for-latin-american-expansion | <a href="https://web.archive.org/web/*/https://blog.terravion.com/blog/terravion-bolsters-enterprise-team-announces-operational-readiness-for-latin-american-expansion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
            

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>TerrAvion offers functional and affordable imagery data that creates value and ROI for the whole agricultural supply chain is expanding its services in Latin America.</em></p>
<!--more-->
<p>TerrAvion, the largest aerial imagery provider for agriculture, today announced that after another year of successful growth in Brazil, it is expanding its services to other countries in Latin America. With multiple years of experience, working out the logistics of capturing agricultural imagery at a large scale in different climates and countries, TerrAvion has obtained regulatory approval in Chile and Paraguay to start its operation. TerrAvion has built a program that can help its imagery distributors successfully implement and optimize digital agronomy programs for agricultural suppliers and growers alike.</p>
<p>"Within a few years, we've grown from a start-up into an international company, and the global demand for our services is accelerating," said Robert Morris, Chief Executive Officer, Founder of TerrAvion. "We have continuously increased our footprint to meet client demand and are excited and ready to bring affordable, high-quality data to any country in the Americas where we can partner with a local distributor. Our sales model is built on supporting local distributors enabling growers to improve their yield, making it a win for the entire agricultural supply chain."</p>
<p><img src="https://blog.terravion.com/hubfs/Pansharpened%20thermal%20cotton%20field%20brazil%201200*600.png" alt="Pansharpened thermal cotton field brazil 1200*600"></p>
<p>After receiving several years of positive feedback for bringing affordable high-resolution imagery solutions to Brazil, TerrAvion is responding to interest from other countries in Latin America. As a result, TerrAvion has appointed the <a href="https://www.terravion.com/staff/">Enterprise Vice Presidents</a> Raúl Enrique Peña for Spanish speaking Latin America and Andrew Pylypchuk for Brazil and Commonwealth countries. Both have a broad experience working with distributors to help implement and successfully grow their digital agronomy services and aligning their business with TerrAvion's aerial imagery services.</p>
<p>"I am excited to be leading TerrAvion's commitment to expanding our presence in Chile and Paraguay with our affordable and scalable services," said​ Raúl Peña, Enterprise Vice President at TerrAvion. "We are prepared to support our distributor's programs with our high-quality and timely data, vital to perform precision agronomy.</p>
<p><img src="https://blog.terravion.com/hubfs/Dynamic%20vigorSugarcane%20field%20in%20Brazil%20with%20weeds%201504*753.png" alt="Dynamic vigorSugarcane field in Brazil with weeds 1504*753"></p>
<p>TerrAvion helps farms take a high-­tech approach to improve yield and revenue, with the largest cloud-­based aerial imaging and data analytics service for agriculture. The high-resolution, affordable imagery services are provided through API-integrated partners and dealers locally to provide the needed support to growers to optimize their inputs and receive the highest ROI possible on every acre/hectare. TerrAvion's open API enables easy integration with agricultural software.</p>
<p>TerrAvion imagery services have the features and benefits that agriculture needs to implement a digital agronomy program successfully:</p>
<ul>
<li>Bands and products to drive meaningful decisions</li>
<li>Functional image data resolution to see every row</li>
<li>Schedules and services to show every agronomic event for your crop</li>
<li>Access how, when, and where you need it</li>
<li>Reliability to run your digital program at the scale of agriculture</li>
</ul>
<h4>Interested to learn more? Complete the form below and we will be in touch.</h4>
</span>
</p>


</div>
</div></div>]]>
            </description>
            <link>https://blog.terravion.com/blog/terravion-bolsters-enterprise-team-announces-operational-readiness-for-latin-american-expansion</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833045</guid>
            <pubDate>Tue, 14 Jul 2020 15:26:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Adverts of the Ault and Wiborg Company]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23833042">thread link</a>) | @nvid
<br/>
July 14, 2020 | https://artvee.com/collection/adverts-for-the-ault-wiborg-company/ | <a href="https://web.archive.org/web/*/https://artvee.com/collection/adverts-for-the-ault-wiborg-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>
							<div>
								<div>
									
																	
										<div><div>								
			<p>A series of poster inserts placed in trade publications by The Ault &amp; Wiborg Company, a Cincinnati based manufacturer of printing inks and dry color dyes. The posters were created by some of the best artists and illustrators of the time, including Edward Liggett, Henri Toulouse-Lautrec, Frank Swick, Carolyn Huntington, Robert Henri, Louis Rhead and Will Bradley.</p></div></div>										
																	</div>
								
							</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://artvee.com/collection/adverts-for-the-ault-wiborg-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833042</guid>
            <pubDate>Tue, 14 Jul 2020 15:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generate fully static Haskell binary with Nix]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832988">thread link</a>) | @matsutsu
<br/>
July 14, 2020 | https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html | <a href="https://web.archive.org/web/*/https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>13 Jul 2020</span></p><p>In this post, I’ll try to explain what are dynamic libraries and static executable, how they work what are there strengths/weaknesses.<br>
I’ll also show how to create the latter with Nix on Linux.</p>



<p>PatchGirl is a rest client that works directly in your browser. But because browsers save users from security issues (i.e: <a href="https://developer.mozilla.org/docs/Web/HTTP/CORS">CORS</a>, <a href="https://developer.mozilla.org/docs/Web/Security/Same_origin_policy_for_JavaScript">same origin policy</a>), some features couldn’t be implemented in a web app.<br>
So I created the <strong>patchgirl-runner</strong> app which is an executable that runs on the user computer and overcome those limitations.</p>

<p>The complete project looks like this:</p>

<p><img src="https://blog.patchgirl.io/assets/patchgirl-diagram.svg" alt="test"></p>

<p>I wanted Patchgirl-runner to be easy to use. Ideally, you would just have to download it and run it. But because it is written in Haskell, it was natively compiled to a dynamic executable.</p>



<p>By default, when you compile your Haskell program to an executable it will require dynamic libraries to work. This means that your executable cannot work alone.</p>

<h2 id="visualizing-dynamic-libraries">Visualizing dynamic libraries</h2>

<p>Let’s take a simple example to explain how it works.
Let’s create a basic project:<br>
<code>stack new HelloWorld</code><br></p>

<p>This project has 2 files:</p>

<div><div><pre><code><span>-- src/lib.hs</span>

<span>module</span> <span>Lib</span>
    <span>(</span> <span>someFunc</span>
    <span>)</span> <span>where</span>

<span>someFunc</span> <span>::</span> <span>IO</span> <span>()</span>
<span>someFunc</span> <span>=</span> <span>putStrLn</span> <span>"someFunc"</span>
</code></pre></div></div>
<div><div><pre><code><span>-- app/Main.hs</span>

<span>module</span> <span>Main</span> <span>where</span>

<span>import</span> <span>Lib</span>

<span>main</span> <span>::</span> <span>IO</span> <span>()</span>
<span>main</span> <span>=</span> <span>someFunc</span>
</code></pre></div></div>

<p>Now let’s build our project:</p>
<div><div><pre><code>stack build
stack <span>install</span> <span># copy the generated executable to a folder in your $PATH (e.g: ~/.local/bin/HelloWorld-exe)</span>
</code></pre></div></div>

<p>This executable is not a standalone binary, meaning that you can’t just copy it to another computer and expect it to work. Indeed, it requires dynamic libraries. <br>
If we want to show this executable’s dependencies we can run the command <code>ldd</code> which given its manual <em>“print shared object dependencies”</em> (you can replace <em>shared object</em> by <em>dynamic library</em>).</p>

<p>So let’s run it:</p>

<div><div><pre><code>% ldd HelloWorld-exe
    linux-vdso.so.1 <span>(</span>0x00007ffc3fdba000<span>)</span>
    libm.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libm.so.6 <span>(</span>0x00007f419e709000<span>)</span>
    libgmp.so.10 <span>=&gt;</span> /lib/x86_64-linux-gnu/libgmp.so.10 <span>(</span>0x00007f419e688000<span>)</span>
    librt.so.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/librt.so.1 <span>(</span>0x00007f419e67d000<span>)</span>
    libdl.so.2 <span>=&gt;</span> /lib/x86_64-linux-gnu/libdl.so.2 <span>(</span>0x00007f419e677000<span>)</span>
    libpthread.so.0 <span>=&gt;</span> /lib/x86_64-linux-gnu/libpthread.so.0 <span>(</span>0x00007f419e654000<span>)</span>
    libc.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libc.so.6 <span>(</span>0x00007f419e463000<span>)</span>
    /lib64/ld-linux-x86-64.so.2 <span>(</span>0x00007f419e871000<span>)</span>
</code></pre></div></div>

<p>This means that this executable requires <code>libm.so.6</code>, <code>libgmp.so.10</code>, <code>libc.so.6</code>,…
Those are dynamic libraries. <br>
One way to tell whether a library is dynamic is the extension <code>.so</code> (i.e <strong>s</strong>hared <strong>o</strong>bject).</p>

<p>When you run your executable, these libraries will also be loaded and accessible to your program.
I’m not going to describe them all but to in a nutshell, <code>libm</code> provides mathematic functions like <code>abs</code>, <code>div</code> or <code>cos</code>…<br>
<code>libgmp</code> provides arbitrary precision arithmetic, operating on signed integers, rational numbers, and floating-point numbers…
This libraries are part of a more global library <code>glibc</code> that was splitted.</p>

<h2 id="dynamic-libraries-pros-and-cons">Dynamic libraries pros and cons</h2>

<p>Dynamic libraries have some advantages. One of them is the executable size. <br>
These libraries are shared by all executables which need them.
That means you can have lightweight executables because they doesn’t include libraries.</p>

<p>An other nice advantage is maintainability. If many programs depends on a library with security issues or bugs, you will only need to upgrade the culprit library to fix them all.</p>

<p>On the other hand, you cannot distribute your executable easily to your customer. If you copy the executable on another computer, it will most likely fail to run because the dynamic libraries it requires are not present.</p>

<p>Which brings us to static binary.</p>



<p>Dynamic libraries are not great when it comes to make application usage/installation easy. This is even more true on Linux distributions where each distribution has it own way of packaging a software (e.g: <em>dpgk</em>, <em>rpm</em>, <em>yum</em>, <em>snap</em>, <em>flatpak</em>…)<br>
If we want to provide a standalone executable to simplify the developer and the customers’ life, we should generate a static executable instead.</p>

<h2 id="static-executable">Static executable</h2>

<blockquote>
  <p>nb: When I refer to a <strong>static executable</strong>, I mean an executable which doesnt require dynamic libraries.</p>
</blockquote>

<p>If we want to provide an executable without dependency, we’d rather make it completely static (i.e: running <code>ldd</code> on it should return nothing). One way of doing this is to tweak Cabal/Stack/whatever building tool you are using and set it up to build static binary.
But we unfortunately can’t just stop here. Indeed, even if you build a static executable with this solution, you might not be able to ship your binary to another platform.</p>

<p>The reason is that your static binary will have been compiled against a specific version of glibc which might not be the same on your the targeted computer. That means that the API your executable is going to use could be incompatible with the kernel.</p>

<p>So can we overcome this issue ? On GNU/linux operating systems, we can thanks to musl.</p>

<h2 id="musl">Musl</h2>

<blockquote>
  <p><a href="https://musl.libc.org/">musl</a> is an implementation of the C standard library built on top of the Linux system call API, including interfaces defined in the base language standard, POSIX, and widely agreed-upon extensions. musl is lightweight, fast, simple, free, and strives to be correct in the sense of standards-conformance and safety.</p>
</blockquote>

<p>In a nutshell, musl is another implementation of the libc. It has the nice advantage of providing a single API so whatever program compiled statically against musl should theorically work on any GNU/Linux platforms.</p>

<p>Cool, so musl looks like a great solution! How do we use it in our project. Well GHC is traditionally compiled against glibc so every time you compile with GHC, it will make it glibc dependent… The solution is to compile GHC with musl!</p>

<p>This looks like a difficult job, Fortunately <strong>@nh2</strong> has already done the job with <a href="https://github.com/nh2/static-haskell-nix">static-haskell-nix</a></p>



<p>Static-haskell-nix’s purpose is to build fully static haskell executables for linux. It uses a lot of Nix machinery so it might not be super easy for beginners.</p>

<p>It provides multiple solutions to generate your executable. The easiest one is to use <a href="https://github.com/nh2/static-haskell-nix#building-stack-projects">stack</a> but I won’t describe it. I tried it and <a href="https://github.com/nh2/static-haskell-nix/issues/95">failed</a> because of some incompatibility with recent version of stack.</p>

<p>Instead, we are going to write some Nix code to use with static-haskell-nix.</p>



<h2 id="requirements">Requirements</h2>

<p>Alright, here is the requirements:</p>
<ul>
  <li>simple project that uses a recent version of stack</li>
  <li>our project should be split in 2 packages, the library and the executable</li>
  <li>the executable package should depend on the library</li>
  <li>our project should use postgresql-simple (meaning we will have to generate an executable that embed the <strong>libpq</strong> library)</li>
</ul>

<h2 id="project-architecture">Project architecture</h2>

<p>Ok, so just like before let’s generate a simple stack project by running:<br>
<code>stack new HelloWorld</code></p>

<p>Let’s modify our <code>stack.yaml</code> so we have 2 packages and a recent resolver version:</p>

<div><div><pre><code><span># stack.yaml</span>

<span>resolver</span><span>:</span> <span>lts-15.13</span>
<span>packages</span><span>:</span>
<span>-</span> <span>hello-world-lib/</span>
<span>-</span> <span>hello-world-app/</span>
</code></pre></div></div>

<p>Let’s create both packages’s <code>package.yaml</code> file:</p>
<div><div><pre><code><span>#  hello-world-lib/package.yml</span>

<span>name</span><span>:</span> <span>hello-world-lib</span>

<span>library</span><span>:</span>
  <span>source-dirs</span><span>:</span>
    <span>-</span> <span>src</span>

<span>dependencies</span><span>:</span>
  <span>-</span> <span>base</span>
  <span>-</span> <span>postgresql-simple</span>
</code></pre></div></div>

<div><div><pre><code><span>#  hello-world-app/package.yml</span>

<span>name</span><span>:</span> <span>hello-world-app</span>

<span>executables</span><span>:</span>
  <span>hello-world-app-exe</span><span>:</span>
    <span>main</span><span>:</span> <span>app/Main.hs</span>
    <span>dependencies</span><span>:</span>
    <span>-</span> <span>hello-world-lib</span>

<span>dependencies</span><span>:</span>
  <span>-</span> <span>base</span>
</code></pre></div></div>

<p>So that was the easy part. We can check that everything works by running <code>stack build</code>.
We can also check that the executable generated isn’t static by running:</p>
<div><div><pre><code>stack <span>install
</span>ldd ~/.local/bin/hello-world-app-exe

	linux-vdso.so.1 <span>(</span>0x00007ffed50fb000<span>)</span>
	libm.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libm.so.6 <span>(</span>0x00007fd92c9ce000<span>)</span>
	libpq.so.5 <span>=&gt;</span> /lib/x86_64-linux-gnu/libpq.so.5 <span>(</span>0x00007fd92c982000<span>)</span>
	librt.so.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/librt.so.1 <span>(</span>0x00007fd92c977000<span>)</span>
	libc.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libc.so.6 <span>(</span>0x00007fd92c6d5000<span>)</span>
	libssl.so.1.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/libssl.so.1.1 <span>(</span>0x00007fd92c643000<span>)</span>
	libcrypto.so.1.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/libcrypto.so.1.1 <span>(</span>0x00007fd92c36e000<span>)</span>
	libkrb5support.so.0 <span>=&gt;</span> /lib/x86_64-linux-gnu/libkrb5support.so.0 <span>(</span>0x00007fd92c1a5000<span>)</span>
    ... truncated <span>for </span>brevity
</code></pre></div></div>

<p>The output shows that adding <code>postgresql-simple</code> as a dependency added other dynamic libraries like <code>libpq</code>.
This executable works fine but we want it to be fully static. It’s time to play with Nix and <code>static-haskell-nix</code>!</p>

<h2 id="static-build-script-with-nix">Static build script with Nix</h2>

<p>As we said before, we are not going to use the <code>stack</code> part of static-haskell-nix. Instead we are relying on the generated Cabal files (i.e: <code>hello-world-lib.cabal</code> and <code>hello-world-app.cabal</code>) from our Nix Script.</p>

<p>Our build script was inspired a lot by postgrest <a href="https://github.com/PostgREST/postgrest">build script</a>.</p>

<p>Our program will have two main scripts.</p>

<p><em>default.nix</em> will pin nixpkgs and define where are our packages:</p>

<div><div><pre><code><span># default.nix</span>

<span>let</span>
  <span># We are using lts-15.13 stack resolver which uses ghc883 (cf: https://www.stackage.org/lts-15.13)</span>
  <span>compiler</span> <span>=</span> <span>"ghc883"</span><span>;</span>

  <span># pin nixpkgs for reproducible build</span>
  <span>nixpkgsVersion</span> <span>=</span> <span>import</span> <span>nix/nixpkgs-version.nix</span><span>;</span>
  <span>nixpkgs</span> <span>=</span>
    <span>builtins</span><span>.</span><span>fetchTarball</span> <span>{</span>
      <span>url</span> <span>=</span> <span>"https://github.com/nixos/nixpkgs/archive/</span><span>${</span><span>nixpkgsVersion</span><span>.</span><span>rev</span><span>}</span><span>.tar.gz"</span><span>;</span>
      <span>sha256</span> <span>=</span> <span>nixpkgsVersion</span><span>.</span><span>tarballHash</span><span>;</span>
    <span>};</span>

  <span># overlays define packages we need to build our project</span>
  <span>allOverlays</span> <span>=</span> <span>import</span> <span>nix/overlays</span><span>;</span>
  <span>overlays</span> <span>=</span> <span>[</span>
    <span>allOverlays</span><span>.</span><span>gitignore</span> <span># helper to use gitignoreSource</span>
    <span>(</span><span>allOverlays</span><span>.</span><span>haskell-packages</span> <span>{</span> <span>inherit</span> <span>compiler</span><span>;</span> <span>})</span>
  <span>];</span>

  <span>pkgs</span> <span>=</span> <span>import</span> <span>nixpkgs</span> <span>{</span> <span>inherit</span> <span>overlays</span><span>;</span> <span>};</span>

  <span># We define our packages by giving them names and a list of source files</span>
  <span>hello-world-lib</span> <span>=</span> <span>{</span>
    <span>name</span> <span>=</span> <span>"hello-world-lib"</span><span>;</span>
    <span>src</span> <span>=</span> <span>pkgs</span><span>.</span><span>lib</span><span>.</span><span>sourceFilesBySuffices</span> <span>(</span><span>pkgs</span><span>.</span><span>gitignoreSource</span> <span>./hello-world-lib</span><span>)[</span> <span>".cabal"</span> <span>".hs"</span> <span>".lhs"</span> <span>"LICENSE"</span> <span>];</span>
  <span>};</span>
  <span>hello-world-app</span> <span>=</span> <span>{</span>
    <span>name</span> <span>=</span> <span>"hello-world-app"</span><span>;</span>
    <span>src</span> <span>=</span> <span>pkgs</span><span>.</span><span>lib</span><span>.</span><span>sourceFilesBySuffices</span> <span>(</span><span>pkgs</span><span>.</span><span>gitignoreSource</span> <span>./hello-world-app</span><span>)[</span> <span>".cabal"</span> <span>".hs"</span> <span>".lhs"</span> <span>"LICENSE"</span> <span>];</span>
  <span>};</span>

  <span># Some patches are unfortunately necessary to work with libpq</span>
  <span>patches</span> <span>=</span> <span>pkgs</span><span>.</span><span>callPackage</span> <span>nix/patches</span> <span>{};</span>

  <span>lib</span> <span>=</span> <span>pkgs</span><span>.</span><span>haskell</span><span>.</span><span>lib</span><span>;</span>

  <span># call our script which add our …</span></code></pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html">https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html</a></em></p>]]>
            </description>
            <link>https://blog.patchgirl.io/haskell/2020/07/13/static-haskell-binary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832988</guid>
            <pubDate>Tue, 14 Jul 2020 15:22:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSSE3 Fast Popcount]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832953">thread link</a>) | @fanf2
<br/>
July 14, 2020 | http://0x80.pl/articles/sse-popcount.html | <a href="https://web.archive.org/web/*/http://0x80.pl/articles/sse-popcount.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="ssse3-fast-popcount">

<table>
<colgroup><col>
<col>
</colgroup><tbody>
<tr><th>Author:</th><td>Wojciech Muła</td>
</tr>
<tr><th>Added on:</th><td>2008-05-24</td>
</tr>
<tr><th>Last update:</th><td>2017-01-28 (link to the XOP variant), 2016-11-27 (link to the paper)</td>
</tr>
</tbody>
</table>

<div id="introduction">

<p>Population count is a procedure of counting number of ones in a bit string.
Intel introduced instruction <tt>popcnt</tt> with <a href="http://en.wikipedia.org/wiki/SSE4">SSE4.2</a> instruction
set. The instruction operates on 32 or 64-bit words.</p>
<p>However <a href="http://en.wikipedia.org/wiki/SSSE3">SSSE3</a> has powerful instruction <tt>PSHUFB</tt>.  This instruction
can be used to perform a <strong>parallel</strong> 16-way lookup; LUT has 16 entries and is
stored in an XMM register, indexes are 4 lower bits of each byte stored in
another XMM register.</p>
</div>
<div id="vector-algorithm">

<p>With help of <tt>PSHUFB</tt> we can get a vector that contains population count
for 16 nibbles.  To get a vector of population count for each 16 byte,
instruction <tt>PSHUFB</tt> have to be called twice on vectors of lower and higher
nibbles, and finally added together.</p>
<p>Following code shows the idea:</p>
<pre>; xmm0 - input (16 bytes)
; xmm7 - POPCOUNT_4bit  -- lookup table
; xmm6 - MASK_bits03 = packed_byte(0x0f) -- mask 4 lower bits

movdqa  %%xmm0, %%xmm1
psrlw       $4, %%xmm1

pand    %%xmm6, %%xmm0  ; xmm0 - lower nibbles
pand    %%xmm6, %%xmm1  ; xmm1 - higher nibbles

movdqa  %%xmm7, %%xmm2  ; since instruction pshufb modifies LUT
movdqa  %%xmm7, %%xmm3  ; it must be saved for further use

pshufb  %%xmm0, %%xmm2  ; xmm2 = vector of popcount for lower nibbles
pshufb  %%xmm1, %%xmm3  ; xmm3 = vector of popcount for higher nibbles

paddb   %%xmm3, %%xmm2  ; xmm2 += xmm3 -- vector of popcount for bytes
</pre>
<p>The last step is adding all bytes from vector.</p>
<p>Instruction <tt>PSADBW</tt> calculate sum of absolute differences of
unsigned bytes — if the first arguments is full of zeros, then result is a
sum of bytes from second argument.  Unfortunately <tt>PSADBW</tt> invoked
with 128-bits arguments calculate separate sums for bytes 0..7 and
8..15, and finally stores them in the lower and the higher quad words.
Because of that few additional instructions are needed:</p>
<pre>pxor    %%xmm0, %%xmm0  ; xmm0 = packed_byte(0x00)
psadbw  %%xmm0, %%xmm3  ; xmm3 = [popcount of bytes 0..7 | popcount of bytes 8..15]
movhlps %%xmm3, %%xmm0  ; xmm0 = [         0             | popcount of bytes 0..7 ]
paddd   %%xmm3, %%xmm0  ; xmm0 = [     not needed        | popcount of bytes 0..15]
</pre>
</div>
<div id="further-improvements">

<p><tt>PSADBW</tt> has 3 or 4 cycles latency, also additional instructions
need some time to execute (I guess around 2 cycles).</p>
<p><tt>PSADBW</tt> doesn't need to be called in every iteration — since max
values of popcount for single byte is 8, we can perform up to
<tt><span>floor(255/8)=31</span></tt> parallel additions (<tt>PADDB</tt>) without overflow.
Moreover, partial sums returned by <tt>PSADBW</tt> could be added together in
the end.</p>
<p>Pseudocode:</p>
<pre>pxor %%xmm5, %%xmm5             // global accumulator

while (bytes to end &gt; 0) {
        pxor %%xmm4, %%xmm4     // local accumulator (for inner loop)

        n = min(bytes to end/16, 31)    // up to 31 blocks
        for (i=0; i &lt; n; i++) {
                // calculate xmm3, a vector of popcount for bytes

                paddb %%xmm3, %%xmm4    // xmm4 += xmm3 -- update local acc.
        }

        pxor   %%xmm0, %%xmm0
        psadbw %%xmm4, %%xmm0   // xmm4 -- calculate two popcounts

        // update global acc.
        paddd  %%xmm4, %%xmm5
}

// add halfs of global accumulator
movhlps %%xmm5, %%xmm0
paddd   %%xmm5, %%xmm0
movd    %%xmm0, %%eax   // eax = population count for all bytes
</pre>
</div>
<div id="source-code">

<p><a href="https://github.com/WojciechMula/sse-popcount">Github repository</a> contains the original code from 2008 and also the new C++11
(2015, 2016), intrinsics-based implementation.</p>
</div>
<div id="experiments-64-bit-code">

<p>Program from the repository were run with default settings (<tt>make run</tt> and
<tt>make run_avx2</tt>) and repeated several times. Minimal measurements were considered.</p>
<p>Below is the list of procedures listed in here. The repository has more variants.</p>
<table>
<colgroup>
<col width="25%">
<col width="75%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>implementation</th>
</tr>
</thead>
<tbody>
<tr><td>lookup-8</td>
<td>LUT-based procedure (<tt>uint8_t[266]</tt>)</td>
</tr>
<tr><td>lookup-64</td>
<td>LUT-based procedure (<tt>uint8_t[266]</tt>), avoid zero-extend</td>
</tr>
<tr><td>bit-parallel</td>
<td>well know method, described for example in <a href="https://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetParallel">Bit Twiddling Hacks</a></td>
</tr>
<tr><td>bit-parallel-optimized</td>
<td>above + the trick from section "Further improvements"</td>
</tr>
<tr><td>harley-seal</td>
<td><a href="http://en.wikipedia.org/wiki/Hamming_weight#Efficient_implementation">Harley-Seal</a> variant</td>
</tr>
<tr><td>sse-bit-parallel</td>
<td>SSE variant of <tt><span>bit-parallel</span></tt></td>
</tr>
<tr><td>sse-lookup</td>
<td><strong>the method described in this text</strong> using SSE instructions</td>
</tr>
<tr><td>sse-lookup</td>
<td><strong>the method described in this text</strong> using AVX2 instructions</td>
</tr>
<tr><td>cpu</td>
<td><tt>popcnt</tt> instruction emitted via intrinsic</td>
</tr>
</tbody>
</table>
<div id="core-i5-westmere">
<h2>Core i5 (Westmere)</h2>
<p>The CPU architecture: Core i5 M540 @ 2.53GHz (Westmere)</p>
<p>More details in <a href="https://github.com/WojciechMula/sse-popcount/blob/master/results/westmere/westmere-m540-gcc4.9.2-sse.rst">a separate file</a>.</p>
<table>
<colgroup>
<col width="19%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>32 B</th>
<th>64 B</th>
<th>128 B</th>
<th>256 B</th>
<th>512 B</th>
<th>1024 B</th>
<th>2048 B</th>
<th>4094 B</th>
</tr>
</thead>
<tbody>
<tr><td>lookup-8</td>
<td>2.29884</td>
<td>2.20039</td>
<td>2.15086</td>
<td>2.12830</td>
<td>3.40985</td>
<td>3.38632</td>
<td>3.37334</td>
<td>3.36643</td>
</tr>
<tr><td>lookup-64</td>
<td>2.29837</td>
<td>2.19979</td>
<td>2.15067</td>
<td>2.12608</td>
<td>3.40112</td>
<td>3.38135</td>
<td>3.37165</td>
<td>3.36490</td>
</tr>
<tr><td>bit-parallel</td>
<td>2.13645</td>
<td>2.00652</td>
<td>1.93406</td>
<td>1.90567</td>
<td>3.01241</td>
<td>2.99661</td>
<td>2.99112</td>
<td>2.99828</td>
</tr>
<tr><td>bit-parallel-optimized</td>
<td>1.37812</td>
<td>1.23970</td>
<td>1.16183</td>
<td>1.13877</td>
<td>1.79016</td>
<td>1.77086</td>
<td>1.75989</td>
<td>1.78260</td>
</tr>
<tr><td>harley-seal</td>
<td>1.47658</td>
<td>1.29922</td>
<td>0.79424</td>
<td>0.63432</td>
<td>0.90197</td>
<td>0.86194</td>
<td>0.83491</td>
<td>0.85399</td>
</tr>
<tr><td>sse-bit-parallel</td>
<td>2.69418</td>
<td>2.40001</td>
<td>1.40793</td>
<td>0.95652</td>
<td>1.17003</td>
<td>1.00129</td>
<td>0.92382</td>
<td>0.86693</td>
</tr>
<tr><td>sse-lookup</td>
<td>0.75528</td>
<td>0.54195</td>
<td>0.34942</td>
<td>0.31078</td>
<td>0.47211</td>
<td>0.45694</td>
<td>0.44650</td>
<td>0.46007</td>
</tr>
<tr><td>cpu</td>
<td><strong>0.49283</strong></td>
<td><strong>0.37799</strong></td>
<td><strong>0.32058</strong></td>
<td><strong>0.29185</strong></td>
<td><strong>0.44360</strong></td>
<td><strong>0.43213</strong></td>
<td><strong>0.42637</strong></td>
<td><strong>0.36332</strong></td>
</tr>
</tbody>
</table>
<p>CPU <tt>popcnt</tt> outperforms the code described here.</p>
</div>
<div id="core-i7-haswell">
<h2>Core i7 (Haswell)</h2>
<p>The CPU architecture: Haswell i7-4770 CPU @ 3.40GHz.</p>
<p>More details in <a href="https://github.com/WojciechMula/sse-popcount/blob/master/results/haswell/haswell-i7-4770-gcc5.3.0-avx2.rst">a separate file</a>.</p>
<table>
<colgroup>
<col width="19%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>32 B</th>
<th>64 B</th>
<th>128 B</th>
<th>256 B</th>
<th>512 B</th>
<th>1024 B</th>
<th>2048 B</th>
<th>4094 B</th>
</tr>
</thead>
<tbody>
<tr><td>lookup-8</td>
<td>1.20408</td>
<td>1.10938</td>
<td>1.06312</td>
<td>1.10722</td>
<td>1.69922</td>
<td>1.66315</td>
<td>1.64113</td>
<td>1.63397</td>
</tr>
<tr><td>lookup-64</td>
<td>1.17775</td>
<td>1.09994</td>
<td>1.06374</td>
<td>1.09102</td>
<td>1.67579</td>
<td>1.64548</td>
<td>1.62390</td>
<td>1.61094</td>
</tr>
<tr><td>bit-parallel</td>
<td>1.26768</td>
<td>1.10553</td>
<td>1.05222</td>
<td>1.02626</td>
<td>1.62086</td>
<td>1.61024</td>
<td>1.60495</td>
<td>1.61435</td>
</tr>
<tr><td>bit-parallel-optimized</td>
<td>1.00233</td>
<td>0.82545</td>
<td>0.72246</td>
<td>0.67454</td>
<td>1.04113</td>
<td>1.02366</td>
<td>1.01708</td>
<td>1.03801</td>
</tr>
<tr><td>harley-seal</td>
<td>1.00260</td>
<td>0.79597</td>
<td>0.50116</td>
<td>0.39440</td>
<td>0.54553</td>
<td>0.50277</td>
<td>0.48139</td>
<td>0.48978</td>
</tr>
<tr><td>sse-bit-parallel</td>
<td>2.15206</td>
<td>2.02008</td>
<td>1.09393</td>
<td>0.66777</td>
<td>0.75717</td>
<td>0.61179</td>
<td>0.53791</td>
<td>0.49923</td>
</tr>
<tr><td>sse-lookup</td>
<td>0.53520</td>
<td>0.33902</td>
<td>0.21379</td>
<td>0.18061</td>
<td>0.26688</td>
<td>0.25605</td>
<td>0.25054</td>
<td>0.25780</td>
</tr>
<tr><td>avx2-lookup</td>
<td>0.53068</td>
<td>0.33920</td>
<td>0.21373</td>
<td>0.13579</td>
<td><strong>0.17133</strong></td>
<td><strong>0.15500</strong></td>
<td><strong>0.14293</strong></td>
<td><strong>0.17005</strong></td>
</tr>
<tr><td>cpu</td>
<td><strong>0.29480</strong></td>
<td><strong>0.24051</strong></td>
<td><strong>0.15478</strong></td>
<td><strong>0.13270</strong></td>
<td>0.20052</td>
<td>0.19462</td>
<td>0.20843</td>
<td>0.21684</td>
</tr>
</tbody>
</table>
<p>AVX2 code is <strong>faster</strong> than the dedicated instruction for input size 512 bytes and larger.</p>
</div>
<div id="core-i7-skylake">
<h2>Core i7 (Skylake)</h2>
<p>The CPU architecture: Skylake i7-6700 CPU @ 3.40GHz</p>
<p>More details in <a href="https://github.com/WojciechMula/sse-popcount/blob/master/results/skylake/skylake-i7-6700-gcc5.3.0-avx2.rst">a separate file</a>.</p>
<table>
<colgroup>
<col width="19%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>32 B</th>
<th>64 B</th>
<th>128 B</th>
<th>256 B</th>
<th>512 B</th>
<th>1024 B</th>
<th>2048 B</th>
<th>4094 B</th>
</tr>
</thead>
<tbody>
<tr><td>lookup-8</td>
<td>1.02956</td>
<td>0.94836</td>
<td>1.04671</td>
<td>0.95623</td>
<td>1.46018</td>
<td>1.42373</td>
<td>1.40633</td>
<td>1.39675</td>
</tr>
<tr><td>lookup-64</td>
<td>1.00704</td>
<td>0.94387</td>
<td>1.03233</td>
<td>0.94744</td>
<td>1.45629</td>
<td>1.42371</td>
<td>1.40747</td>
<td>1.39947</td>
</tr>
<tr><td>bit-parallel</td>
<td>1.05662</td>
<td>0.95297</td>
<td>0.90992</td>
<td>0.88908</td>
<td>1.40587</td>
<td>1.39753</td>
<td>1.39337</td>
<td>1.41585</td>
</tr>
<tr><td>bit-parallel-optimized</td>
<td>0.81278</td>
<td>0.69091</td>
<td>0.63329</td>
<td>0.60453</td>
<td>0.94443</td>
<td>0.93320</td>
<td>0.92760</td>
<td>0.95122</td>
</tr>
<tr><td>harley-seal</td>
<td>0.81283</td>
<td>0.66397</td>
<td>0.43348</td>
<td>0.34035</td>
<td>0.46871</td>
<td>0.43077</td>
<td>0.41181</td>
<td>0.41767</td>
</tr>
<tr><td>sse-bit-parallel</td>
<td>2.25432</td>
<td>1.70980</td>
<td>0.92443</td>
<td>0.57618</td>
<td>0.68189</td>
<td>0.58220</td>
<td>0.50169</td>
<td>0.45568</td>
</tr>
<tr><td>sse-lookup</td>
<td>0.40749</td>
<td>0.29802</td>
<td>0.18290</td>
<td>0.15742</td>
<td>0.23956</td>
<td>0.23057</td>
<td>0.22657</td>
<td>0.23177</td>
</tr>
<tr><td>avx2-lookup</td>
<td>0.43350</td>
<td>0.26368</td>
<td>0.17950</td>
<td><strong>0.11587</strong></td>
<td><strong>0.14881</strong></td>
<td><strong>0.13729</strong></td>
<td><strong>0.12798</strong></td>
<td><strong>0.14222</strong></td>
</tr>
<tr><td>cpu</td>
<td><strong>0.21676</strong></td>
<td><strong>0.16256</strong></td>
<td><strong>0.13546</strong></td>
<td>0.12192</td>
<td>0.18423</td>
<td>0.22065</td>
<td>0.19643</td>
<td>0.20293</td>
</tr>
</tbody>
</table>
<p>Again AVX2 code is <strong>faster</strong> than the dedicated instruction for input size 256 bytes and larger.</p>
</div>
</div>
<div id="experiments-32-bit-code-outdated">

<p><strong>Note 2016-03-13</strong>: this section refers to results from 2008.</p>
<p><a href="https://github.com/WojciechMula/sse-popcount/blob/master/original/ssse3_popcount.c">ssse3_popcount.c</a> is a test program
that contains implementations of following procedures:</p>
<ul>
<li><tt>lookup</tt>  — popcount based on LUT with 256 entries;
I tested GCC <tt>__builtin_popcount</tt>, however it was much
slower than my implementation</li>
<li><tt><span>ssse3-1</span></tt> — straightforward SSSE3 implementation</li>
<li><tt><span>ssse3-2</span></tt> — improved SSSE3 implementation</li>
<li><tt><span>ssse3-unrl</span></tt> — <tt><span>ssse3-2</span></tt> with inner loop unrolled 4 times</li>
<li><tt><span>sse2-1</span></tt> — SSE2 bit-level parallel implementation</li>
<li><tt><span>sse2-2</span></tt> — improved SSE2 implementation (using the same tricks as SSSE3 version)</li>
<li><tt><span>see2-unrl</span></tt> — <tt><span>ssee2-2</span></tt> with inner loop unrolled 4 times</li>
</ul>
<p>The first argument of the program is a function name, the second is the number of
16-byte chunks processed by the selected procedure in one iteration
and the third is the iterations number.</p>
<p>The table shows results for different chunk count; <a href="https://github.com/WojciechMula/sse-popcount/blob/master/original/ssse3_popcount-test.sh">test script</a> I've used is
available.  Program was compiled with following options:</p>
<pre>gcc -O2 -DALIGN_DATA ssse3_popcount.c -o ssse3_popcount
</pre>
<p>Tests were run on my Linux box, with Core 2 Duo E8200;</p>
<p><img alt="chart" src="http://0x80.pl/articles/img/ssse3_popcount_speedup.png"></p><p>Results clearly show, that the method presented above brings significant
speedup, which depends on the data size.</p>
<p>The straightforward SSSE3 implementation is 2-2.8 times faster, the improved
around 3 times, and the unrolled 4-5 times.</p>
<table>
<colgroup>
<col width="20%">
<col width="34%">
<col width="16%">
<col width="13%">
<col width="17%">
</colgroup>
<thead>
<tr><th>procedure</th>
<th>number of 16-byte chunks</th>
<th>iterations</th>
<th>time [s]</th>
<th>speedup</th>
</tr>
</thead>
<tbody>
<tr><td><tt>lookup</tt></td>
<td rowspan="5">1</td>
<td rowspan="5">20,000,000</td>
<td>0.22</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.19</td>
<td>115%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.20</td>
<td>110%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.14</td>
<td>157%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.16</td>
<td>137%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="5">8</td>
<td rowspan="5">20,000,000</td>
<td>1.42</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.92</td>
<td>154%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.79</td>
<td>179%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.61</td>
<td>232%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.52</td>
<td>273%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">32</td>
<td rowspan="7">2,000,000</td>
<td>0.55</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.34</td>
<td>161%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.30</td>
<td>183%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>0.22</td>
<td>250%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.22</td>
<td>250%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.19</td>
<td>289%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.12</td>
<td>458%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">128</td>
<td rowspan="7">200,000</td>
<td>0.21</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.13</td>
<td>161%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.11</td>
<td>190%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>0.08</td>
<td>262%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.08</td>
<td>262%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.07</td>
<td>299%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.04</td>
<td>525%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">512</td>
<td rowspan="7">200,000</td>
<td>0.86</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>0.53</td>
<td>162%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.45</td>
<td>191%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>0.34</td>
<td>252%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.34</td>
<td>252%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.26</td>
<td>330%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.18</td>
<td>477%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">1024</td>
<td rowspan="7">200,000</td>
<td>1.73</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>1.07</td>
<td>161%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>0.90</td>
<td>192%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>0.68</td>
<td>254%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>0.69</td>
<td>250%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>0.52</td>
<td>332%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.38</td>
<td>455%</td>
</tr>
<tr><td><tt>lookup</tt></td>
<td rowspan="7">2048</td>
<td rowspan="7">200,000</td>
<td>3.47</td>
<td>100%</td>
</tr>
<tr><td><tt><span>sse2-1</span></tt></td>
<td>2.14</td>
<td>162%</td>
</tr>
<tr><td><tt><span>sse2-2</span></tt></td>
<td>1.80</td>
<td>192%</td>
</tr>
<tr><td><tt><span>sse2-unrl</span></tt></td>
<td>1.37</td>
<td>253%</td>
</tr>
<tr><td><tt><span>ssse3-1</span></tt></td>
<td>1.38</td>
<td>251%</td>
</tr>
<tr><td><tt><span>ssse3-2</span></tt></td>
<td>1.06</td>
<td>327%</td>
</tr>
<tr><td><tt><span>ssse3-unrl</span></tt></td>
<td>0.76</td>
<td>456%</td>
</tr>
</tbody>
</table>
</div>
<div id="acknowledgments">

<p><a href="http://lemire.me/">Daniel Lemire</a> has gave me access to computers with
Haswell and Skylake processors, thanks to that I could play with AVX2 code
and run tests. <a href="https://github.com/kimwalisch">Kim Walisch</a> contributed
the Harley-Seal implementation. There were some fixes and enhancements
to sample code by <a href="https://github.com/WojciechMula/sse-popcount/graphs/contributors">various people</a>. Thank you.</p>
</div>
<div id="see-also-update">

<ul>
<li><p><a href="http://0x80.pl/articles/xop-popcnt.html">Population count using XOP instructions</a></p>
</li>
<li><p>Paper by Daniel Lemire, Nathan Kurz and me: <a href="https://arxiv.org/abs/1611.07612">Faster Population Counts using AVX2 Instructions</a>.</p>
</li>
<li><p><a href="https://news.ycombinator.com/item?id=11277891">Hacker news discussion</a>.</p>
</li>
<li><p><a href="http://0x80.pl/articles/faster-popcount-for-large-data.html">Speeding up bit-parallel population count</a> — delaying byte-wise
sum (the trick with <tt>PSADBW</tt>) applied for bit parallel method gives
50% speedup over plain, <a href="http://en.wikipedia.org/wiki/SWAR">SWAR</a> 64-bit procedure.</p>
</li>
<li><p><a href="http://www.cs.stanford.edu/people/ihaque/#publications">Anatomy of High-Performance 2D Similarity Calculations</a> — paper contains
interesting comparison of similarity calculations which heavily use popcount
operation. The authors compared 4 basic methods: 1) hardware-based, i.e.
<tt>popcnt</tt> instruction, 2) simple LUT, 3) bit-level parallel method (SSE2
procedure), and 4) the method described here. The most important observation,
from my point of view of course, is that the speed of SSSE3 code is
<strong>comparable</strong> to hardware <tt>popcnt</tt>, it is just a bit
slower.</p>
<p>The authors published also the full source code and I noticed they manually
unrolled inner loop. I did the same in my code and speedup increased
from 3 to …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://0x80.pl/articles/sse-popcount.html">http://0x80.pl/articles/sse-popcount.html</a></em></p>]]>
            </description>
            <link>http://0x80.pl/articles/sse-popcount.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832953</guid>
            <pubDate>Tue, 14 Jul 2020 15:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PS Now Is Holding Your Save Files Hostage: Now What?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832739">thread link</a>) | @kiraleighleigh
<br/>
July 14, 2020 | https://weebtrash.ga/2020/07/14/ps-now-is-holding-your-save-files-hostage-now-what/ | <a href="https://web.archive.org/web/*/https://weebtrash.ga/2020/07/14/ps-now-is-holding-your-save-files-hostage-now-what/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<div>
		<!-- Start Article -->
				<article>		
						<div id="post-1082">
				<div>
					<!-- Start Content -->
					<div id="content">
					<header>
						<!-- Start Title -->
						
						<!-- End Title -->
						<p>Posted On July 14, 2020</p>

					</header>

						
<h3>Playstation’s Streaming Service Woes Are Indicative Of A Greater Problem</h3>



<p>There are a lot of things in life that don’t make sense to me. <a rel="noreferrer noopener" href="https://medium.com/there-is-no-design/if-youre-mad-about-ok-boomer-you-re-part-of-the-problem-a571b5b85d68" target="_blank">Ok boomer’s hysteria</a>, for one thing. <a rel="noreferrer noopener" href="https://medium.com/the-bad-influence/feminism-got-you-mad-this-theory-explains-why-afd5f5fc0937" target="_blank">Grown-ass adults failing at logic</a>, another. Even the <a rel="noreferrer noopener" href="https://medium.com/the-bad-influence/ignorance-about-vaping-is-killing-people-ffbaa95d3d47" target="_blank">vaping ban</a> of yore boggles the mind.</p>



<p>It seems like life is an exercise in asking:<strong><em> excuse me, wtf?</em></strong></p>



<p>But what possibly confuses me more—because humans are by nature consistently disappointing—is when <strong><em>businesses engage in practices that are anti-customer and think this makes a lick of sense.</em></strong></p>



<h3>One such business being Sony Playstation</h3>



<h4>Specifically Playstation Now, Sony’s streaming service</h4>



<div><figure><img data-attachment-id="1088" data-permalink="https://weebtrash.ga/2020/07/14/ps-now-is-holding-your-save-files-hostage-now-what/gi4qmjppjde21/" data-orig-file="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?fit=480%2C360&amp;ssl=1" data-orig-size="480,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gi4qmjppjde21" data-image-description="" data-medium-file="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?fit=480%2C360&amp;ssl=1" src="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?w=678&amp;ssl=1" alt="" srcset="https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?w=480&amp;ssl=1 480w, https://i2.wp.com/weebtrash.ga/wp-content/uploads/2020/07/gi4qmjppjde21.jpg?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 480px) 100vw, 480px" data-recalc-dims="1"></figure></div>



<p>In theory, <a rel="noreferrer noopener" href="https://www.playstation.com/en-us/explore/playstation-now/" target="_blank">Playstation Now</a> is a cash-strapped gamer’s perfect solution: Pay $9.99 a month and get lightning-fast streaming access to 800+ titles on tons of different digital devices.&nbsp;In fact, Sony’s streaming service is doing very well indeed. PS Now has received a huge boost during these crayola times, <a rel="noreferrer noopener" href="https://www.pushsquare.com/news/2020/05/playstation_now_records_highest_subscriber_count_ever_at_2_2_million" target="_blank">boasting 2.2 million subscribers</a>.</p>



<p>PS Now also offers many PS3 titles, which is rad because even if you’ve missed a gem, you get the opportunity to play it anyways.</p>



<figure><img src="https://i2.wp.com/cdn-images-1.medium.com/max/800/1*Mwn-UiFR0UEFC_edX7V4Rw.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure>



<p>But what PS Now <strong><em>doesn’t</em></strong> offer is out-of-the-box support for rescuing your save files if you want to <strong><em>actually</em></strong> purchase the games you’ve lowkey rented.</p>



<p><em>(Sorry Shallie &amp; Shallie, I can never truly take you with me.)</em></p>



<p>For that, you need <a href="https://www.playstation.com/en-us/explore/playstation-plus/" rel="noreferrer noopener" target="_blank">PS Plus</a>.</p>



<h3>PS Now isn’t $9.99 if you want to actually own the games you lowkey ‘rent’</h3>



<h4>It’s $20, because for gamers who like owning things, PS Plus is non-negotiable</h4>



<figure><img src="https://i1.wp.com/cdn-images-1.medium.com/max/800/1*Av4wXbN3l96-4KImiVbPGQ.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure>



<p>Say you’ve played a PS Now title and you enjoyed it. You want to purchase it and don’t want to lose your progress. You now have to rescue your save files from PS Now, instead of migrating them out-of-the-box like one would expect.</p>



<p>In order to liberate your saves, you need to get a subscription for PS Plus. This bumps the price from $9.99 to $20.&nbsp;That cost is fine, or it would be.</p>



<p><a rel="noreferrer noopener" href="https://support.playstation.com/s/article/How-to-Transfer-Game-Progress-between-PlayStation-Now-and-Your-PS4" target="_blank">But that’s not the end of it.</a>&nbsp;There exists a preposterous UX-nightmare dance you must engage with, and it only sometimes works, which I’ll get to shortly.</p>



<p>You start off by opening the game in the streaming service. You need an active PS Now subscription, as well as PS Plus; there is no rescue otherwise.&nbsp;</p>



<p>Then you press the PS button in the center of your controller and pray it gives you the option to migrate your save files.</p>



<p>Thirdly, you must upload everything to “””””””the cloud”””””””.</p>



<p>Then, you have to whole-ass exit PS Now.</p>



<p>Then, you have to go <em>all the way to the settings</em> on your PS4 console to download what you uploaded. Depending on what you’re trying to do, saving it to a USB stick might be the best option.&nbsp;</p>



<p>It’s not <em>very</em> complicated, but it is a lot of needless menu navigation. </p>



<p><em>(Let’s get a </em><a rel="noreferrer noopener" href="https://www.thereisno.design/" target="_blank"><em>UX professional</em></a><em> who is sensitive to gamers on this, please.)</em></p>



<div><figure><img src="https://i0.wp.com/cdn-images-1.medium.com/max/800/1*fBprjzW9iFTIN9GJ2V6qpw.png?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>With this process, I managed to salvage my <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Rogue_Galaxy" target="_blank">Rogue Galaxy save files</a>; one of my favorite somewhat-obscure PS2 titles.&nbsp;</p>



<p>I was very satisfied with this outcome…</p>



<p>Until it came time to scoop up the often maligned, but honestly awesome, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Tales_of_Zestiria" target="_blank">Tales of Zestiria</a>. Sadly, the PS Now Streaming Service’s version of Zesty is<strong><em> PS3-specific</em></strong>. Hmm…</p>



<p>You may be formulating a question in your mind right now, maybe equipped with a tad bit of panic:</p>



<h3>Can you transfer PS3 PS Now saves to the PS Plus&nbsp;Cloud?</h3>



<h4>Well yes, but actually&nbsp;no…</h4>



<div><figure><img src="https://i1.wp.com/cdn-images-1.medium.com/max/800/1*9H8fybBvuDMnZdDG-XmatA.gif?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>The option to rescue Zesty never showed up. Because of this, I spent 40 minutes on the phone with Sony Playstation’s customer service seeking a solution. Apparently, you were <strong><em>once</em></strong> able to log into PS Now on PS3 and rescue your save files. Apparently, this is <strong>now impossible</strong>.</p>



<p>After talking to the rep, he gave me the truth about rescuing PS3-specific save files from PS Now:</p>



<p><strong>Because Playstation is ‘looking forward, not back’, you cannot rescue PS3 saves from PS Now at this current moment in&nbsp;time.</strong></p>



<p>That renders PS Now’s exhaustive PS3 game catalog moot to the saving function of PS&nbsp;Plus. Not only is this frustrating, but it’s also indicative of Sony’s sentiments towards backwards compatibility, which I’ll get to shortly.</p>



<p>According to the rep, PS3 titles run off an entirely different server than PS1/PS2/PS4 titles.</p>



<p>PS3 saves won’t work on PS4 because you get PS3-specific trophies, can download PS3 DLCs, and the PS4 just doesn’t know how to deal with this.</p>



<p>PS1/PS2 has none of that baggage, so those saves are safe.</p>



<p>He mentioned that, because the PS Now Streaming Service was relaunched/revamped, we may very well find that PS3 save-file-liberation will be available again in the future.</p>



<p>But as far as I’m concerned, and the rep lowkey agreed, Sony Playstation just doesn’t care about its PS3 catalog very much. In fact, it doesn’t seem to care very much about its legacy catalog at all.</p>



<p>Looking forward—not back—brings me to one conclusion:</p>



<h2>Backwards compatibility is not a Sony priority, even if gamers keep requesting it</h2>



<figure><img src="https://i2.wp.com/cdn-images-1.medium.com/max/800/1*ZmruYJGxAkdQVYU_fpOxzg.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure>



<p>HD remasters may be the compromise Sony proposes for older titles, but that solution seems at odds with a constant request: gamers want backwards compatibility. PS Now’s PS3 save-file issue is just another symptom of this reluctance to be fully pro-consumer.</p>



<p>More than that, <a rel="noreferrer noopener" href="https://www.goliath.com/gaming/sony-explains-why-the-playstation-4-isnt-backwards-compatible/" target="_blank">they appear to think gamers</a> don’t want this feature:</p>



<blockquote><p>As Sony global sales chief Jim Ryan tells<a rel="noreferrer noopener" href="https://time.com/4804768/playstation-4-ps4-pro-psvr-sales/" target="_blank">&nbsp;TIME</a>, backwards compatibility is something the company has taken some steps to address with things like HD remasters of select PlayStation 2 titles, but it just isn’t something that gamers ultimately use that much, even if they claim it’s something they want. “When we’ve dabbled with backwards compatibility, I can say it is one of those features that is much requested, but not actually used much,” said Ryan. “That, and I was at a&nbsp;<em>Gran Turismo</em>&nbsp;event recently where they had PS1, PS2, PS3, and PS4 games, and the PS1 and the PS2 games, they looked ancient, like why would anybody play this?”</p></blockquote>



<p>It’s puzzling how Ryan—global sales chief of Sony—can claim gamers don’t ultimately use pure backwards compatibility, when Sony has never truly offered it aside from PS1/PS2 consoles.</p>



<p>Furthermore, if the growing catalog of PS1/2/3 titles in PS Now’s roster is any indication of what gamers are into (I’d assume this inclusion was spurred by sales/use data), it stands to reason it’s very much desired.</p>



<p>Lastly, if Ryan thinks outdated graphics impede enjoyment for gamers, I’m unsure if he’s in touch with the average gamer’s age, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Video_games_in_the_United_States" target="_blank">which is 35</a>, and consequentially people who grew up comfortable with crunchy graphics.</p>



<p>What he seems to suggest is new gamers are the key demographic, ones who are most likely into eSports and fresh titles. Forwards, not backwards.</p>



<p>This leaves loyal, life-long fans of the console in the dust.</p>



<p><em>(I’ll redact this article if </em><a rel="noreferrer noopener" href="https://www.notebookcheck.net/PS5-backwards-compatibility-Likely-PS-Now-patent-invigorates-debate-on-whether-Cerny-s-PlayStation-5-BC-graphic-was-deliberately-incomplete.480817.0.html" target="_blank"><em>Sony manages to surprise me</em></a><em>, but until then, no.)</em></p>



<h3>I’m sure that Sony has other priorities right now, like the&nbsp;PS5</h3>



<h4>But this specific priority, that gamers want, has really has never felt like a priority, at&nbsp;all</h4>



<div><figure><img src="https://i1.wp.com/cdn-images-1.medium.com/max/800/1*JNJbbWlTwYdUjZWioeJfbg.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>Imagine if you bought a digital copy of a TV show you’ve binged halfway through, and Amazon Prime Video updated its app, thus rendering your copy inaccessible. That’s very anti-consumer, isn’t it? Yet Sony doesn’t really seem to mind the likesome roadblock between PS3 and PS4.</p>



<p>With streaming service ubiquity for both software and media, I can’t help but feel like customers are getting shafted out of actually owning the things they buy. This, my friends, is anti-consumer.</p>



<p>To counter that narrative, the <a rel="noreferrer noopener" href="https://www.nintendo.com/switch/" target="_blank">Nintendo Switch</a> is now offering various titles that would have been lost to time immemorial.&nbsp;You purchase them, and they are your’s.</p>



<p>Nintendo is rescuing older titles like the <a href="https://www.gamespot.com/articles/the-legend-of-heroes-trails-of-cold-steel-3-is-com/1100-6471839/" rel="noreferrer noopener" target="_blank">Trails series</a>. It’s offering a way to play these older games, all on one system.</p>



<figure><img src="https://i1.wp.com/cdn-images-1.medium.com/max/800/1*tOx-TvAW0YhhzORTjsmp0A.jpeg?w=678&amp;ssl=1" alt="" data-recalc-dims="1"></figure>



<p>Decidedly, Nintendo wants to support gamers who lament the loss of older titles. They perhaps also want to get new fans of beloved older IPs into the fold. That shows a level of care I don’t see Sony possessing.</p>



<p>There are so many wonderful games people have missed out on. Either due to time, lagging releases in their country, or otherwise. </p>



<p>Having that option is very pro-consumer, and if I’ve learned anything in my marketing career, it’s that this is the only way to truly <a rel="noreferrer noopener" href="https://medium.com/there-is-no-design/marketers-weve-got-to-reconfigure-87c47a7499ab" target="_blank">do business</a>.</p>



<p>Because ranting about this could easily take up another 6,000 words, I leave you with one final sentiment.</p>



<p>Something I think Sony would do well to remember:</p>



<h3>Being pro-consumer is being a pro-business. </h3>



<h4>Consider giving your long-time, loyal fans what they&nbsp;want. It makes money-sense and gives us just one more reason to stan.</h4>
<p>Hits: 564</p>
																		<!-- Start Tags -->
						
						<!-- End Tags -->
											</div><!-- End Content -->
					  
								  
								
<!-- You can start editing here. -->
			
							</div>
						</div>
									</article>
				<!-- End Article -->
				<!-- Start Sidebar -->
				
				<!-- End Sidebar -->
			</div>
		</div></div>]]>
            </description>
            <link>https://weebtrash.ga/2020/07/14/ps-now-is-holding-your-save-files-hostage-now-what/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832739</guid>
            <pubDate>Tue, 14 Jul 2020 15:01:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How major and minor device numbers worked in V7 Unix]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832722">thread link</a>) | @beefhash
<br/>
July 14, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How major and minor device numbers worked in V7 Unix</h2>

	<p><small>July 13, 2020</small></p>
</div><div><p>Unix people who've been around for a while know that Unix devices
have <em>device numbers</em>, and that device numbers are divided into
<em>major</em> and <em>minor</em> device numbers. When you do '<code>ls -l /dev/null</code>'
and one of the fields that <code>ls</code> prints is two comma separated
numbers, those are the major and minor numbers (on Linux, they are
'1, 3'; this varies by Unix). Device numbers and their split into
major and minor parts go back a long way, to before Research Unix
V7, but V7 makes a convenient point to look at what they meant and
how they worked in the original Unixes.</p>

<p>As various sources will tell you, the major number tells you (and
the Unix kernel) what sort of device it is and thus what device
driver to use to talk to it, while the minor number tells the device
driver what specific bit of hardware it's responsible for that you
want to talk to.  Sometimes the minor number also determines some
bit of functionality. Because V7 was a deliberately simple and
brute force system and kernel, major device numbers had a very
simple implementation. We can see it in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/c.c">the generated V7 kernel
configuration file <code>c.c</code></a>:</p>


<pre> struct bdevsw bdevsw[] =
 {
   nulldev, nulldev, rkstrategy, &amp;rktab, /* rk = 0 */
   nodev, nodev, nodev, 0, /* rp = 1 */
   [...]
   nodev, nodev, nodev, 0, /* hp = 6 */
   htopen, htclose, htstrategy, &amp;httab, /* ht = 7 */
   nodev, nodev, nodev, 0, /* rl = 8 */
   0
 };
</pre>

<p>What we're seeing here is that V7 literally had an array of <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/conf.h"><code>bdevsw</code>
structures</a> indexed
by the major (block) device number, with various function that were
called when you did things like open a device (in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/sys/fio.c"><code>fio.c</code></a>).
There was a similar array for character devices, the <code>cdevsw</code> array.
In both of them, what driver functions were listed here instead of
stubbed out were determined by simple configuration files (<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf">here</a>)
that said what devices you had (among other things).</p>

<p>(The <code>c.c</code> file was generated by <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/mkconf.c">a program</a>.
The particular <code>c.c</code> file in the TUHS V7 tree was built with only
two block devices configured, the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rk.c">RK disk driver</a> and
<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/ht.c">TJU16 tape driver 'ht'</a>.)</p>

<p>In V7 the minor device number was only interpreted by the device
driver, as far as I can see. Device drivers used this for a variety
of purposes. For instance, <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/mem.c">the <code>mem</code> character driver</a>
implemented <code>/dev/null</code> as minor device 2, to go along with access
to physical memory and kernel memory. The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rl.c"><code>rl</code> disk driver</a> used
the minor device number to decide what physical disk it was talking
to (it supported up to four of them). Once V7 started getting out
in the world, other people wrote drivers for it (such as <a href="http://clara.comm.sfu.ca/pups/PDP-11/Trees/V7/usr/sys/dev/rx2.c">the RX02
floppy disk driver</a>) that
used minor device numbers both to select what to talk to and control
what features to use.</p>

<p>(There's also <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/kl.c">the <code>kl</code> KL/DL-11 serial and console driver</a>, which
seems to deal with three different sets of hardware control registers
based on the minor number.)</p>

<p>The <code>/dev/tty</code> character device was implemented in a clever and
very short way in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/sys.c"><code>sys.c</code></a>. In
V7, there were no pseudo-ttys and no hot-plugged devices, so your
underlying physical terminal device always existed and was recorded
in your <code>u</code> area (see <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/user.h"><code>user.h</code></a>) The
general tty driver simply used this recorded device number of your
controlling tty to call its open, read, write, and ioctl functions
through the <code>cdevsw</code> array. As far as I can tell, this driver paid
no attention at all to the minor device number; as long as <code>/dev/tty</code>
had major number 7, the minor number was irrelevant.</p>

<p>PS: Note that V7 device drivers tended to be a little relaxed about
error checking for their minor device numbers (and other things).
For instance, as far as I can tell the <code>mem</code> driver actually only
distinguishes between minor number 2, minor number 1, and 'everything
else', which is treated as minor number 0, giving access to physical
memory.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832722</guid>
            <pubDate>Tue, 14 Jul 2020 14:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low-Code for Coders]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832708">thread link</a>) | @thmslee
<br/>
July 14, 2020 | https://visionx.sibvisions.com/low-code-coders/ | <a href="https://web.archive.org/web/*/https://visionx.sibvisions.com/low-code-coders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="26820" itemscope="" itemtype="http://schema.org/Article"><div><div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><div itemprop="logo" itemscope="" itemtype="https://schema.org/ImageObject">
<p><img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTc1IDM1IiB3aWR0aD0iMTc1IiBoZWlnaHQ9IjM1IiBkYXRhLXU9Imh0dHBzJTNBJTJGJTJGdmlzaW9ueC5zaWJ2aXNpb25zLmNvbSUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAxNiUyRjAxJTJGdmlzaW9ueF9sb3djb2RlX2JsYWNrLnBuZyIgZGF0YS13PSIxNzUiIGRhdGEtaD0iMzUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-spai="1" alt=""></p><meta itemprop="url" content="https://visionx.sibvisions.com/wp-content/uploads/2016/01/visionx_lowcode_black.png"><meta itemprop="width" content="175"><meta itemprop="height" content=""></div><meta itemprop="name" content="Low Code Development Platform for Enterprises | VisionX"></div><meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://visionx.sibvisions.com/low-code-coders/"><p>Low-code for coders</p><meta itemprop="datePublished" content="2020-07-14 1:50:48"><meta itemprop="dateModified" content="2020-07-15 9:55:20"></div><header></header><section><div itemprop="articleBody"><div><figure itemscope=""><img width="1470" height="980" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTQ3MCA5ODAiIHdpZHRoPSIxNDcwIiBoZWlnaHQ9Ijk4MCIgZGF0YS11PSJodHRwcyUzQSUyRiUyRnZpc2lvbnguc2lidmlzaW9ucy5jb20lMkZ3cC1jb250ZW50JTJGdXBsb2FkcyUyRjIwMjAlMkYwNyUyRkxvdy1Db2RlLUNvZGVycy5wbmciIGRhdGEtdz0iMTQ3MCIgZGF0YS1oPSI5ODAiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-spai="1" alt="Low-Code for Coders" sizes="(max-width: 1470px) 100vw, 1470px"></figure></div><div><p><img alt="" src="https://secure.gravatar.com/avatar/e6c04f4433d5af7c32a9447bff92d130?s=140&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/e6c04f4433d5af7c32a9447bff92d130?s=280&amp;d=mm&amp;r=g 2x" height="140" width="140"></p></div><h2>Low-code for coders</h2><p>Oxymoron? I think not. Let me explain.</p><p>Software developers tend to be very skeptical about low-code tools. Every time a new low-code or no-code platform comes out, its founders announce with big fanfare that they have created a panacea for the developer shortage, and that writing code is no longer required. CEOs and CFOs get excited because they think they found a way to cut cost, CTOs and developers get frustrated because, yet again, they have to explain why the new tool won’t solve all of their software development problems and why “real” programmers will still be required.</p><p>It is a battle that has been raging since the days of Apple’s HyperCard. Software engineers generally do not like these tools, and can be very passionate in their defense of manually writing code. Just take a look around the developer forums – anytime a new low-code tool is introduced, there is a pretty good chance it will get shredded, if it gets attention at all. There are a number of reasons for that, and being coders ourselves, we certainly don’t disagree with them:</p><p><strong>1. Restrictions</strong> – this is the most obvious point. Even when a low-code tool claims to give developers all the flexibility they need, there will still be a trade-off associated with visual design that needs to be considered. Coders often have their own way of doing things, and they balk when their creativity is restricted.</p><p><strong>2. Writing code is the easy part.</strong> What really takes time is figuring out what the client wants, accurately specifying the problem, and defining a solution that not only works from the user’s perspective, but also fits into the company’s IT infrastructure. Faster coding does not help with any of these.</p><p><strong>3. Security and other issues.</strong> This one is obvious to software engineers, but is often more difficult to explain to business units. We don’t want a bunch of apps floating around in an uncontrolled way. Security is a concern, as are performance, scalability, reliability, compatibility quality, and maintainability. And of course, we want to avoid vendor lock-in.</p><h2><strong>The real benefit for developers</strong></h2><p>Given these concerns, it is no surprise that developers often strongly resist the introduction of low-code platforms. The preference for the status quo can lead to internal battles between IT and upper management. But this conflict misses the point: for developers, the real benefit of low-code is not only its ability to speed up writing a few lines of code, but the improved cooperation with business units. Involving users in the development process has a number of benefits:</p><p><strong>1. They actually get what they want.</strong> If the person who uses the application is involved in the development process in a meaningful way, the final result is more likely to be the product they actually need.</p><p><strong>2. Buy-in.</strong> Just like we as developers don’t like to be told how to write code, business users can get frustrated when they are forced to use tools that don’t work for their processes. Having them involved in the development will result in much better acceptance of the final product.</p><p><strong>3. Better communication.</strong> Business users often have difficulty explaining what they need in terms that are useful to a developer. Allowing them to build their own prototypes means they will better understand the process and will begin to communicate better when it comes to feature requests und updates. They might even hold off on asking for features they don’t really need.</p><h2><strong>Get the users involved</strong></h2><p>Here is the thing – they’re already doing it anyway. We know shadow IT is out there. Some users, especially engineers and accountants, can be extremely resourceful when it comes to clever ways of using excel and other software to further their cause. That’s all fine to a point, but we know about the amount of data that is lost by the lack of coordination with IT. Not to mention the security issues.</p><p>On the other hand, harnessing all of that creativity can 5-10x our development capacity, improve relationships with business units, and make sure that data is kept in the right place.</p><h2><strong>Facilitating the interaction</strong></h2><p>With that in mind, we should think of low-code tools less as “development accelerators”, but more as facilitators of communication with users.</p><p>But how do we really make that cooperation happen? There still is that trade-off between the speed and simplicity of a visual designer, and the flexibility of manual code. Most low-code/no-code tools are on the former end of the spectrum, focusing on simplicity, and will therefore remain in the “only works for basic applications that are needed quickly” category. For the interaction between IT and business to work, we need a platform that is easy enough for users to understand, but offers sufficient flexibility to avoid restrictions on development.</p><p>There are a few other factors that need to be considered:</p><ol><li>The interaction has to go both ways. A standard code generator is not enough if it cannot translate changes to the code back to the visual designer. Otherwise the interaction stops the first time the code is manually adjusted.</li><li>The generated code has to be of sufficient quality. Developers often complain about the garbage code that is created by code generators, so the bar here is set pretty high.</li></ol><p>Meeting all of these requirements is a tall order. Our next post will explain how we address them.</p><div><div><div><p><img alt="" src="https://secure.gravatar.com/avatar/e6c04f4433d5af7c32a9447bff92d130?s=140&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/e6c04f4433d5af7c32a9447bff92d130?s=280&amp;d=mm&amp;r=g 2x" height="140" width="140"></p><div><p itemprop="author" itemscope="" itemtype="http://schema.org/Person"><h3>About <span itemprop="name">Roland Hörmann</span></h3></p><p>
Roland Hörmann is founder and CEO of SIB Visions GmbH and lecturer at the FH Technikum Wien. He has many years of experience in the development of enterprise solutions. His focus of interest is on efficient software development and framework development in the field of classic business applications. He is a regular speaker at Oracle User Group events (DOAG, AOUG), Java User Groups events, and W-JAX.</p>
<p><a href="https://visionx.sibvisions.com/author/roland/">More by Roland Hörmann</a></p></div></div></div></div></div></section></article></div>]]>
            </description>
            <link>https://visionx.sibvisions.com/low-code-coders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832708</guid>
            <pubDate>Tue, 14 Jul 2020 14:58:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK bans Huawei from 5G networks, with total removal by 2027]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832698">thread link</a>) | @suleaty
<br/>
July 14, 2020 | https://newsworthy.to/article/2020/07/14/uk-bans-huawei-from-5g-networks-with-total-removal-by-2027 | <a href="https://web.archive.org/web/*/https://newsworthy.to/article/2020/07/14/uk-bans-huawei-from-5g-networks-with-total-removal-by-2027">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><p><time datetime="2020-07-14T11:46:39">July 14, 2020</time> by <a href="https://www.theverge.com/2020/7/14/21322880/uk-bans-huawei-5g-network-infrastructure-trump-administration-pressure">The Verge</a> | <a href="https://newsworthy.to/category/opinion">Opinion</a></p><p>After allowing it a limited role in January</p><p>Huawei’s networking equipment is to be phased out of the UK’s 5G networks, the <a href="https://www.gov.uk/government/news/huawei-to-be-removed-from-uk-5g-networks-by-2027">government announced today</a>. Telecoms operators will not be allowed to buy new 5G telecoms equipment from the Chinese firm from January next year, and they will have seven years to remove its existing technology from their 5G infrastructure at an expected cost of £2 billion. The announcement follows a new report about Huawei’s role in the UK’s national infrastructure from the UK’s National Cyber Security Centre.</p><p>The decision marks a U-turn from the government’s previous position, <a href="https://www.theverge.com/2020/1/28/21083762/huawei-5g-network-infrastructure-uk-national-security">announced in January</a>, which allowed Huawei’s equipment to be used in the country’s 5G infrastructure, with certain limitations. Under that position, Huawei would be limited to a 35 percent market share, and its equipment couldn’t be used in core parts of the network or geographically sensitive locations. Now, however, its equipment will be completely removed from the country’s 5G networks. </p><p>The UK’s Digital, Culture, Media, and Sport Secretary Oliver Dowden warned that the decision “will delay our rollout of 5G.” As part of the announcement, the government said that it is also advising full fiber broadband operators to transition away from buying Huawei’s equipment.</p><p>In recent months, the British government has seen mounting pressure, both domestically and internationally, to phase out the use of Huawei’s equipment entirely. That pressure has been driven by concern from security experts that <a href="https://www.theverge.com/2019/3/17/18264283/huawei-security-threat-experts-china-spying-5g">Huawei’s equipment poses a national security risk</a> by allowing Beijing to spy on Western countries. Huawei has <a href="https://www.bbc.co.uk/news/business-47279262">strenuously denied these allegations</a>.</p><p>International pressure has mainly come from the US. Huawei has been on the country’s “entity list” since <a href="https://www.theverge.com/2019/5/15/18216988/white-house-huawei-china-equipment-ban-trump-executive-order">May 2019</a>, meaning US companies cannot sell technology to the company. However, in May this year, <a href="https://www.nytimes.com/2020/05/15/business/economy/commerce-department-huawei.html"><em>The New York Times</em> reported</a> the US toughened its stance with the announcement of new sanctions against Huawei. Under the new measures, which are due to go into effect in September, Huawei and its suppliers, like chip manufacturer TSMC, cannot use American tech to design or produce Huawei’s products. At the time, US officials characterized the move as “closing a loophole” through which Huawei could effectively have previously used American technology.</p><p>These new measures could have a big impact on the products Huawei is able to produce, which critics argue could make its equipment less safe to use. The restrictions “will force the company to use untrusted technology that could increase the risk to the UK,” according to a <a href="https://www.theverge.com/2020/7/6/21314340/huawei-5g-networks-security-risk-us-uk">security report that leaked earlier this month</a>.</p><p>For example, Huawei’s own HiSilicon chipsets could be impacted by the measures. <a href="https://www.bbc.co.uk/news/technology-53179963"><em>BBC News</em> reports</a> that the semiconductor industry relies on electronic design automation (EDA) software to automate the process of designing modern chips like Huawei’s Kirin 990 5G processor. However, the sanctions mean that this software can no longer be used in the design or production of Huawei’s chips since the major EDA developers have ties to the US. It makes it difficult for Huawei to produce its own modern top-of-the-line processors, <a href="https://www.bbc.co.uk/news/technology-53341080">according to <em>BBC News</em></a><em>, </em>pushing it towards third-party chips that, it’s argued, could be harder for UK cybersecurity officials to vet.</p><p>Meanwhile, UK Prime Minister Boris Johnson is also facing pressure from inside his own party. The government suffered the biggest defeat of its current term back in March, when <a href="https://www.bbc.co.uk/news/uk-politics-51806704"><em>BBC News</em> reports</a> 38 Conservative MPs voted against the government in favor of an amendment calling for an end to the use of Huawei equipment in the country’s 5G networks by 2023. Increasing numbers of Conservative MPs claim that the equipment poses a national security risk, potentially allowing Beijing to spy on the UK, <a href="https://www.ft.com/content/e4b7f816-00cc-4dc5-bb97-4e761200022a">according to the<em> Financial Times</em></a>. Although the government won the vote, the incident put pressure on Johnson to take a tougher stance.</p><p>Responding to the news, a spokesperson from Huawei called the decision “disappointing” and said that the company is “confident” the new US sanctions wouldn’t affect “the resilience or security of the products we supply to the UK.” It claimed that they were driven by US trade policy rather than security and urged the British government to reconsider its decision.</p><p>News of a possible ban has proved unpopular with telecom firms, many of which have already started using Huawei’s equipment to <a href="https://www.theguardian.com/technology/2019/jul/06/huawei-uk-mobile-5g-networks-operators-gamble-security-concerns">build out their 5G networks</a>. In comments <a href="https://www.theguardian.com/technology/2020/jul/13/bt-boss-warns-of-outages-and-security-risks-if-uk-ditches-huawei">later published in <em>The Guardian</em></a>, BT chief executive Philip Jansen told BBC Radio 4’s Today program that it would be “impossible” to remove Huawei entirely from the country’s telecoms infrastructure in the next decade and that it would take five to seven years to remove it from the 5G network. Jansen warned that forcing the removal of Huawei’s equipment too quickly could create outages and security risks of its own.</p><p><em><strong>Update July 14th, 8:13AM ET:</strong></em><em> Updated with response from Huawei and more details from government press release. </em></p></article></div></div></div>]]>
            </description>
            <link>https://newsworthy.to/article/2020/07/14/uk-bans-huawei-from-5g-networks-with-total-removal-by-2027</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832698</guid>
            <pubDate>Tue, 14 Jul 2020 14:58:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supabase Launch Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832692">thread link</a>) | @kiwicopple
<br/>
July 14, 2020 | https://supabase.io/blog/2020/07/10/alpha-launch-postmortem | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/07/10/alpha-launch-postmortem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>On May 27 Supabase hit the <a href="https://news.ycombinator.com/item?id=23319901" target="_blank" rel="noopener noreferrer">top of Hacker News</a> and stayed on the front page for more than 24 hours. </p><p>Since then, Supabase has been featured on the <a href="https://stackoverflow.blog/2020/06/05/podcast-241-new-tools-for-new-times/" target="_blank" rel="noopener noreferrer">Stack Overflow podcast</a>, hit the <a href="https://twitter.com/supabase_io/status/1268062559023685633" target="_blank" rel="noopener noreferrer">trending page</a> on GitHub, and scaled to over 1000 databases.</p><p>Here is everything that went wrong along the way.</p><h2>Quick stats - launch week</h2><p>Before we get into the details, here are some high-level numbers for the week following the launch.</p><p>We had 30,000 new website visitors to <a href="http://supabase.io/">supabase.io</a>:</p><p>We had over 1400 signups in 7 days:</p><p>Github stars rocketed for our two main repos, <a href="https://github.com/supabase/supabase" target="_blank" rel="noopener noreferrer">supabase</a> and <a href="https://github.com/supabase/realtime" target="_blank" rel="noopener noreferrer">realtime</a>. </p><br><h2>The good</h2><p>Here are the things that survived well.</p><h3>Middleware: docker-compose up</h3><p>This was the most surprising survivor. Our middleware was served from a single Ubuntu server with 4 CPUs and 8GB of RAM. This server was running our middleware using <code>docker-compose up</code>:</p><p>In case you're wondering why any sane company would use that in production, it's because we weren't planning to launch - the HackerNews post was created by an early GitHub follower, while we were alpha testing, and it was too scary to migrate the middleware while it was servicing the thundering herd. All Supabase projects use the same middleware stack (sans docker-compose), so I guess this counts as as a successful load test. </p><p>We have since migrated our middleware to multiple ECS clusters, globally load-balanced using AWS's <a href="https://aws.amazon.com/global-accelerator/" target="_blank" rel="noopener noreferrer">Global Accelerator</a>. </p><h3>Frontend: Netlify, Vercel, Auth0</h3><p>We serve our marketing site (<a href="http://supabase.io/">supabase.io</a>) from Netlify. It's a static-build <a href="https://v2.docusaurus.io/" target="_blank" rel="noopener noreferrer">Docusaurus (v2)</a> site, so it had no problems (apart from one developer in Russia who couldn't access the site - it looks like some of Netlify's IP addresses are blocked there).</p><p>We serve our app (<a href="http://app.supabase.io/">app.supabase.io</a>) using Vercel, and the login system uses Auth0. These were both rock-solid. Before the launch we noticed that Vercel was extremely slow on their free plan, and once we upgraded to their Pro Plan for multi-region deploys it solved performance issues. It looks like they are changing their plans again so buyer beware.</p><h2>The Bad</h2><h3>Digital Ocean cloud limits</h3><p>In May we were using Digital Ocean to serve all of our customer databases. We hit the first server limit (400 servers) in the space of a few hours. They bumped our limit up to 1000 and we hit that again a few hours later. </p><p>Digital Ocean were very responsive when we asked for increases, each time responding in 30 minutes or less.</p><h3>Cloudflare cloud limits</h3><p>Each Supabase project gets a unique URL for their API and database. This is set up using Cloudflare's API. This was a seamless process until we hit the 1000-subdomain limit, at 4am in the morning. My cofounder was awake, managed to identify the problem early, and reached out to the support to increase the limit. </p><p>Cloudflare support advised him to upgrade the account to increase the limit, but the upgrade could only be done by the owner (me). Unfortunately my phone was on silent, so for 3 hours our systems were down. Ideally any one of our team could have upgraded our account, but I imagine that Cloudflare have their reasons for this restriction.</p><h2>The Ugly - migrating 1800 servers</h2><p>Let me start by saying that Digital Ocean have been great for getting up and running. The experience was simple to start with, but ended painfully. </p><h3>Digital Ocean production errors</h3><p>The first sign of problems were the frequent production errors. This is a screenshot of emails from Digital ocean for the month of June.</p><p>Each of these emails represents one or more servers that has a critical issue:</p><blockquote><p>We have identified an issue on the physical machine hosting one or more of your Droplets. In the event that we are not able to perform a live migration of a Droplet, we will perform an offline migration during which the Droplet will be powered off and migrated offline during the window.</p></blockquote><p>Luckily we are in alpha, and our community has been extremely patient. </p><h3>Credit limits</h3><p>Most of our frustration was due to their internal policy around credits program. We were generously granted $10,000 Digital Ocean credits in February through Stripe Atlas, and so they became our primary cloud provider.</p><p>Digital Ocean have another (more generous) credits package for YC companies. Unfortunately when we applied for this we were told we weren't eligible because it was a "Partner switch" from Stripe to YC. This was frustrating because a "Partner switch" is completely arbitrary to us as a customer.  </p><p>Also we had conveniently just run out of credits. We don’t expect cloud providers to fund our inefficiencies, but we needed time to optimize our infrastructure after our surprise launch. We had assumed that the more generous credits package was guaranteed - an assumption which cost us several thousand dollars. After swift deliberation, we decided to migrate away from Digital Ocean. </p><h2>Going Forward: AWS t3a</h2><p>In the past 3 weeks we have migrated 1800 servers over to AWS. </p><p>We are on the AWS "Activate" program, which grants us $100,000 credits. Since Firebase has a very generous free-tier, and we want to be able to offer Supabase developers a similar experience, this is ultimately a huge benefit to our community.</p><p>The AWS team were helpful, suggesting their new <code>t3a</code> instances. We're already seeing improvements, with database startup times almost halved from ~90s to ~50s. From our research, this is the fastest Postgres setup in the market.</p><p>We will release a detailed write-up on these instances in the next few weeks. Sign up to our newsletter if you want to be notified when we release the post.</p></section></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/07/10/alpha-launch-postmortem</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832692</guid>
            <pubDate>Tue, 14 Jul 2020 14:57:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Siberia to Tibet: Life on a Train]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832549">thread link</a>) | @9nGQluzmnq3M
<br/>
July 14, 2020 | https://driftingclouds.net/2018/07/04/from-siberia-to-tibet-life-on-a-train/ | <a href="https://web.archive.org/web/*/https://driftingclouds.net/2018/07/04/from-siberia-to-tibet-life-on-a-train/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-494">
	<!-- .entry-header -->

	
		<div>
			
<div data-original-width="636" data-carousel-extra="{&quot;blog_id&quot;:40678465,&quot;permalink&quot;:&quot;https:\/\/driftingclouds.net\/2018\/07\/04\/from-siberia-to-tibet-life-on-a-train\/&quot;,&quot;likes_blog_id&quot;:40678465}" itemscope="" itemtype="http://schema.org/ImageGallery"> <div data-original-width="636" data-original-height="533">  <!-- close group --> <div data-original-width="401" data-original-height="533"> <div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"> <a href="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg" itemprop="url"> <meta itemprop="width" content="397"> <meta itemprop="height" content="529"> <img data-attachment-id="503" data-orig-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 2&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1531032696&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.442&quot;,&quot;iso&quot;:&quot;50&quot;,&quot;shutter_speed&quot;:&quot;0.004403&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20180708_065136" data-image-description="" data-medium-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg?w=225" data-large-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg?w=636" src="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg?w=397&amp;h=529" width="397" height="529" data-original-width="397" data-original-height="529" itemprop="http://schema.org/image" title="img_20180708_065136" alt="img_20180708_065136"> </a> </div> </div> <!-- close group --> </div> <!-- close row --> </div>
<p>Many writers wax lyrical about the romance of long-distance train travel, but on this trip I sampled four them — Irkutsk to Ulaanbaatar, Ulaanbaatar to Beijing, Beijing to Xi’an, and Xining to Lhasa — and the sad truth is that the passenger trains in these parts are strictly utilitarian workhorses, inferior to airplanes on virtually every measure of speed or comfort.&nbsp; &nbsp;Here’s the lowdown on life in a 4-berth sleeper (<em>kupé</em> in Russia, 软卧 <em>ruǎnwò&nbsp;</em>in China).</p>
<h2>Eat</h2>

<p>When you’re on a train for 24 hours or more, you’ve got to eat something, and this leaves you with three options.</p>
<p>The first and most obvious option is <strong>restaurant cars</strong>, and the Mongolian ones with their intricate wood carvings and embroidered tablecloths even look quite attractive.&nbsp; Alas, the food they serve ranges&nbsp;from bland but edible, like our Chinese breakfast set composed mostly of sausage, celery and chilli, to bland and near-inedible, such as the&nbsp;<em>incredibly&nbsp;</em>gristly beef served on the Mongolian train — I was picking bits out of my teeth for the next two days.&nbsp; Perhaps we should have taken the hint from the plastic bags of frozen beef sitting in the corridor, tenderizing in the midsummer heat of the Gobi Desert.</p>
<p>Alternatively, you can try to buy food on <strong>station platforms</strong>, but this presents a number of practical problems.&nbsp; First, stops are few and far between and rarely aligned with mealtimes.&nbsp; Second, stops are short and on arrival you neither have any idea what the options are nor where to find them.&nbsp; Third, if you do find something food-like, it’s often unclear how many days those mince-meat&nbsp;<em>khuushuurs</em>&nbsp;sitting on a table&nbsp;have been fermenting under the Mongolian sun.&nbsp; We did manage to swing some pretty decent&nbsp;<em>piroshki </em>pastries&nbsp;in Ulan-Ude, plus rye bread and boiled eggs in Mongolia, but it really is the luck of the draw and you can’t count on finding more than packaged snacks this way.</p>

<p>Finally, you can <strong>bring your own food</strong>, but with no refrigeration or heating available (aside from hot water), you’ll be hard pressed to expand your culinary horizons beyond packaged bread, instant noodles and the giant Russian rye croutons called&nbsp;<a href="http://snackproduction.com.ua/grenki-3/"><em>grenki</em></a>.&nbsp; (Best flavor: garlic with garlic dip.&nbsp; You’re welcome.)&nbsp; A useful compromise is to buy a meal at your&nbsp;<em>departure&nbsp;</em>station: you’re not going to find much more than fast food, but even KFC is likely tastier, cheaper and healthier than the alternatives.</p>
<p>All that said, you <em>can</em> generally rely on the restaurant cars to supply lukewarm beer at only mildly extortionate prices, which brings me to…</p>
<h2>Drink</h2>

<p>Russian and Mongolian trains forbid drinking <strong>alcoholic beverages</strong> on board; fortunately, this being Russia and Mongolia, beer is not considered alcohol.&nbsp; (Seriously.)&nbsp; Needless to say, this rule is widely ignored by all and sundry, although it’s generally wise to close your compartment door if you have one and avoid tippling at times when conductors are on the prowl.</p>
<p>The one free drink provided in abundant quantities is <strong>boiling hot water</strong>, supplied by a coal or wood fired boiler at the end of each carriage.&nbsp; If you’re lucky, there may even be a thermos bottle in your cabin, which you can use to stock your own supply.&nbsp; Bring along some teabags, instant coffee or cocoa, and you can stay caffeinated.&nbsp; A&nbsp;pedantic nit: most travelers call these <a href="https://en.wikipedia.org/wiki/Samovar">samovars</a>, but in Russian they’re actually “titans” (титан).</p>
<p>Non-hot water, on the other hand, is in distinctly short supply, as the water from the bathroom taps is <strong>not drinkable</strong>.&nbsp; Bring along more than you think you will need, particularly if it’s hot or high outside.&nbsp; As for taking a shower or a bath, forget about it.</p>
<h2>Poop</h2>
<p>Yes, this section has no pictures.&nbsp; (You’re welcome.)</p>
<p>The upside to strictly functional trains is that their toilets are also unencumbered with pneumatic vacuums and mysterious blue liquids.&nbsp; Instead, when you press the lever, the bottom opens up and the contents are deposited straight onto the tracks, followed by a slightly apologetic trickle of water.&nbsp; While this does an admirable job of preventing the toilet from clogging, it does also mean that the doors are locked while the train is stationary, including during those multi-hour border crossings.</p>
<p>On Chinese trains, you will also encounter squat toilets, although there are usually a few thrones to be found as well.&nbsp; The upside to these is that, no matter how filthy the rest of the room, only your feet need make contact; the downside is that whatever your feet make contact with is likely to be unpleasant.&nbsp; This is why everybody on board brings flip-flops to wear.&nbsp; &nbsp;And whether your train is Russian, Mongolian or Chinese, you’ll want to bring toilet paper and soap as well.</p>
<h2>Sleep</h2>
<p>Fed, hydrated and voided, it’s time to sleep.&nbsp;&nbsp;The uninitiated are often tempted by the idea of a hotel on wheels: just slumber away peacefully on board and you’ll arrive at your destination not just refreshed, but having saved on a night’s hotel bill!&nbsp; Reality is more complicated.</p>

<p>Even when not manufactured in the DDR, the berths are <strong>generally uncomfortable</strong>, even in the misnamed Russian “luxe” or Chinese “soft sleeper”.&nbsp; The sheets are nailed to plyboard (we ended up buying an inflatable camping mattress because my dad’s back was wrecked by the four nights of the Moscow-Irkutsk stretch), the blankets are covered in stains of indeterminate origin and getting onto the top bunks requires acrobatics.&nbsp; If the window is closed, it’ll be stuffy and hot inside; if it’s open, every rattle, clank and blast of the horn is amplified and your toes will freeze.&nbsp; &nbsp;While the Trans-Siberian and most railways in China are continuously welded and thus smooth, the Trans-Mongolian is not, meaning your bedtime lullaby will be a constant&nbsp;<em>clunk-clunk, clunk-clunk</em>.</p>
<div data-original-width="636" data-carousel-extra="{&quot;blog_id&quot;:40678465,&quot;permalink&quot;:&quot;https:\/\/driftingclouds.net\/2018\/07\/04\/from-siberia-to-tibet-life-on-a-train\/&quot;,&quot;likes_blog_id&quot;:40678465}" itemscope="" itemtype="http://schema.org/ImageGallery"> <div data-original-width="636" data-original-height="319"> <div data-original-width="424" data-original-height="319"> <div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"> <a href="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg" itemprop="url"> <meta itemprop="width" content="420"> <meta itemprop="height" content="315"> <img data-attachment-id="513" data-orig-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 2&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1531086666&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.442&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.024963&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20180708_215106" data-image-description="" data-medium-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg?w=300" data-large-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg?w=636" src="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg?w=420&amp;h=315" width="420" height="315" data-original-width="420" data-original-height="315" itemprop="http://schema.org/image" title="img_20180708_215106" alt="img_20180708_215106"> </a> </div> </div> <!-- close group -->  <!-- close group --> </div> <!-- close row --> </div>
<p>In addition, <strong>border crossings</strong> are both interminable and inevitably timed to happen in the middle of night.&nbsp; It was past midnight when we finally entered Mongolia after two hours of inspections, and while our arrival into China was at 9 PM, we all had to get off the train and wait for&nbsp;5 hours, until 2 AM, while they swapped the bogies from Russian to Chinese gauge.</p>
<p>Unsurprisingly, you’re likely to wake up groggy and grumpy.&nbsp; If you’re at your destination already, you’ll be decanted onto the streets and condemned to wander until your hotel opens; if not, you’ll probably catch up by napping in your bunk during the day, throwing your sleep cycle even more out of whack.</p>
<h2>So why do it?</h2>
<p>Well, that was quite the litany of whinging, why would anybody voluntarily subject themselves to this then?</p>
<p>It’s <strong>an opportunity to idle</strong>.&nbsp; There is way more time than there are things to do, so you can read a book, play cards, study the <a href="https://driftingclouds.net/2018/02/20/that-is-not-your-name-the-kafkaesque-world-of-russian-duolingo/">finer points of Russian grammar</a> on Duolingo, or just take a nap — and all the earlier kvetching aside, your train bunk is still more spacious and comfy than even a business class seat on an airplane.</p>
<p>Traveling by train, you get a <strong>sense of distance</strong>.&nbsp; I flew Beijing to Irkutsk in 2.5 hours, and saw basically nothing even from the window seat.&nbsp; Traveling the same route by train took 54 hours, and while I still can’t say I <em>really&nbsp;</em>know what it felt like to <a href="https://www.goodreads.com/book/show/17286667-on-the-trail-of-genghis-khan">cross the Gobi by camel</a>, now at least I have some reference point for the sheer scale of the feat.</p>
<div data-original-width="636" data-carousel-extra="{&quot;blog_id&quot;:40678465,&quot;permalink&quot;:&quot;https:\/\/driftingclouds.net\/2018\/07\/04\/from-siberia-to-tibet-life-on-a-train\/&quot;,&quot;likes_blog_id&quot;:40678465}" itemscope="" itemtype="http://schema.org/ImageGallery"> <div data-original-width="636" data-original-height="294"> <div data-original-width="441" data-original-height="294"> <div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"> <a href="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg" itemprop="url"> <meta itemprop="width" content="437"> <meta itemprop="height" content="290"> <img data-attachment-id="517" data-orig-file="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg" data-orig-size="4928,3264" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D7000&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1530730133&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;18&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.004&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dsc_5645" data-image-description="" data-medium-file="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg?w=300" data-large-file="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg?w=636" src="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg?w=437&amp;h=290" width="437" height="290" data-original-width="437" data-original-height="290" itemprop="http://schema.org/image" title="dsc_5645" alt="dsc_5645"> </a> </div> </div> <!-- close group -->  <!-- close group --> </div> <!-- close row -->  <!-- close row --> </div>
<p>But above all, <strong>you see a slice of real life</strong>.&nbsp; It’s not always pretty (any train traveler in India will have a hard time unseeing the spectacle of the track sides being used as a public lavatory), but simply put, without taking the train you wouldn’t see ramshackle Siberian dachas, rusting factories around Ulan-Ude, yurt cities around Ulan Bator, ghastly commieblocks around a Mongolian military base in the Gobi desert, Chinese factories spewing grey smoke into the skies of Inner Mongolia, the green hills of Shaanxi, the shaggy yaks wandering around the plateaus of Tibet, the massive scale of construction around Lhasa and more.&nbsp; This trip wouldn’t have been the same at all without it, and I have zero regrets.</p>
<p>On to Mongolia!</p>
<p><strong><a href="https://driftingclouds.net/2018/07/02/from-siberia-to-tibet-irkutsk-lake-baikal/">&lt;&lt;&lt; Irkutsk &amp; Lake Baikal</a>&nbsp;|&nbsp;<a href="https://driftingclouds.net/2018/07/07/from-siberia-to-tibet-ulaanbaatar-gorkhi-terelj-and-the-gobi-desert/">Ulaanbaatar, Gorkhi-Terelj and the Gobi Desert &gt;&gt;&gt;</a></strong></p>
			
			
								</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://driftingclouds.net/2018/07/04/from-siberia-to-tibet-life-on-a-train/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832549</guid>
            <pubDate>Tue, 14 Jul 2020 14:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ebbflow – A Multi-Cloud Load Balancer and SSH Proxy. Host from Anywhere]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832533">thread link</a>) | @gorbot
<br/>
July 14, 2020 | https://ebbflow.io/blog/announce | <a href="https://web.archive.org/web/*/https://ebbflow.io/blog/announce">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>After almost a year of hard work, Ebbflow has launched! It has been an invaluable learning experience and I'm super excited to get this tool into the hands of other developers.</p>
    <p>Ebbflow is multi-cloud load balancer and SSH proxy service. You can use it to host websites (or generic TLS endpoints!) privately and securely with browser-trusted certificates which can be automatically provisioned and presented for you. Connect to your servers from anywhere, no matter where they are or what network they are in. In a word, Ebbflow is flexible.
    </p><h3>Why Ebbflow?</h3>
    <p>Networking is a pain. Configuring firewalls, DNS, EC2 security groups, port-forwarding, etc., is complicated and difficult. It can be extremely specific. And most importantly, it is inflexible. Let's look at an example: home hosting. If I asked you to host a website from your home computer/raspberry pi, with a browser-trusted certificate, how would you do that? How durable is it? How much manual configuration does it involve? The easiest solution I can think of involves port-forwarding your home router to a server of yours and routing your DNS name to your home's IP address. Is that private? What if your IP changes? Sounds fun. Don't get a new router! Or move!</p>
    <p>Enterprise web hosting can be little easier - all cloud providers have load balancers you can use to route traffic to your servers in a local network, typically in a single region. This will work for many people, but things get hard once you'd like to move outside this standard model. If you are familiar with cloud networking, consider the difficulty of the following situations: migrating from on-premises to cloud, cloud-cloud migration, being multi-region or global, routing to a Kubernetes cluster and handling updates, migrating from instances to containers, handling AZ failover, or region failover. A lot of these problems do have solutions - you <i>can</i> solve these problems and some are easier than others - but the solutions are vendor specific, disjoint, application specific, and typically inflexible.</p>
    <p>Ebbflow provides a single and global networking model that doesn't just solve a few of these problems, it solves all of these problems.</p>
    <h3>The Ebbflow Model</h3>
   <p><u>In short</u>: All things connect to Ebbflow. Ebbflow routes clients to servers, privately and securely.</p>
   <p><img src="https://ebbflow.io/resources/smallnarrow.png" width="100px"></p><p>Ebbflow flips the paradigm you are currently used to. With Ebbflow, your servers reach up and await connections. Ebbflow has the fun task of routing clients to your servers. When a client visits your website or endpoint, Ebbflow picks the nearest server and proxies the connection through the <a href="https://ebbflow.io/documentation#client" target="_blank">client</a> to your server process or local SSH daemon.</p>
    <p>This new way of modeling your network removes many of the roadblocks and bumps that the current world of networking has. Ebbflow allows for some interesting properties to be achieved:</p>
    <p><small>
    <ul>
       <li><strong>Firewall Friendly</strong> - Feel free to block all inbound connections to your servers yet still host your endpoint and be SSH-ed to.</li>
       <li><strong>Global &amp; Local</strong> - Ebbflow has one single interface for all customers and uses nearest-server routing to keep your traffic local for low latencies.</li>
       <li><strong>Multi Cloud</strong> - Ebbflow is deployed to AWS and Google Cloud, and is multi-region in both clouds. If a region Ebbflow is deployed to goes down, your clients <i>and servers</i> will both be routed to other regions or clouds. You don't need to account for region-failure when considering your server scaling, as your servers are always hittable.</li>
       <li><strong><a href="https://ebbflow.io/documentation#client" target="_blank">Linux, MacOS, Windows, Pi</a></strong> - Host where you want with what OS you want. Ebbflow is also ready to adopt new distros and targets to fit your needs</li>
       <li><strong>Centralized Certificate Management</strong> - Ebbflow manages and presents a browser-trusted <a href="https://letsencrypt.org/" target="_blank">Let's Encrypt</a> certificate to the visitors of your endpoint</li>
       <li><strong>LAN Agnostic</strong> - Ebbflow does not care what private network your servers are in and they can be completely isolated.</li>
       <li><strong>No Network, No Problem</strong> - Let's say you have a Raspberry Pi in the field collecting data over a cellular connection, this pi could host an endpoint, or be SSH-ed to with Ebbflow.</li>
       </ul>
       </small></p><p>This new networking model solves the above problems in a convenient and simple way. You can load balance across any network at any time. You can move the same instance between networks and without any configuration at all, the instance will continue to host your endpoint or be SSH-ed to. Multi cloud? Sure. Home hosting? Cool. Host from your Pi? Sweet!</p>
   <h3>Living in an Ebbflow World</h3>
   <p>Ebbflow takes many of the problems of modern networking off your play. Ebbflow use of technologies like nearest-host routing, global availability, and multi-cloud durability, all Ebbflow customers benefit from this as well. It's also low-investment in time and money to start hosting or connecting your servers. </p>
   <p>Prototyping and testing with Ebbflow takes <a href="https://ebbflow.io/quickstart#endpointguide" target="_blank">only a few minutes</a>. During the development of Ebbflow, I used Ebbflow many times to host endpoints or for SSH connectivity. One interesting case was that I was in a coffee shop using the SSH proxy feature to connect to my dev-box at home, while trying to fix a bug in the SSH proxy feature which caused occasional disconnects (now fixed). Ebbflow uses Ebbflow for its website and its linux package server - this request was served by <code id="hostname">raspberrypi-1-useast</code>. Also Ebbflow uses Ebbflow to host its staging environment and testing stack. It is simpler and easier to configure than other load balancing solutions and provides so many features that others lack.</p>
   <p>I'm excited to see how people use Ebbflow to solve interesting problems. We want to hear about the ways it unlocks new forms of web hosting and connectivity (just <a href="mailto:info@ebbflow.io">email us!</a>). Ebbflow provides a simple solution to complex problems and simple ones such as hosting a personal blog on your Raspberry Pi that's currently collecting dust in your junk drawer. Like I said before, Ebbflow is flexible. It will meet you at your use case and remove the complexities of networking from your problem set. See for yourself, and start testing today with the <a href="https://ebbflow.io/create_account">free trial</a>!</p>
    </div></div>]]>
            </description>
            <link>https://ebbflow.io/blog/announce</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832533</guid>
            <pubDate>Tue, 14 Jul 2020 14:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVPR 2020: The Top Object Detection Papers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23832469">thread link</a>) | @mwitiderrick
<br/>
July 14, 2020 | https://heartbeat.fritz.ai/cvpr-2020-the-top-objection-detection-papers-f920a6e41233 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/cvpr-2020-the-top-objection-detection-papers-f920a6e41233">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://heartbeat.fritz.ai/@mwitiderrick?source=post_page-----f920a6e41233----------------------" rel="noopener"><img alt="Derrick Mwiti" src="https://miro.medium.com/fit/c/96/96/2*9aohLPF6ipIrrmZ50g8zNQ.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2306/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg" width="1153" height="581" srcset="https://miro.medium.com/max/552/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg 276w, https://miro.medium.com/max/1104/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg 552w, https://miro.medium.com/max/1280/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg 640w, https://miro.medium.com/max/1400/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*A67D7A2ZmaPlddeIi4UtoQ.jpeg?q=20"></p></div></div></div><figcaption><a href="https://www.amazon.science/conferences-and-events/cvpr-2020" target="_blank" rel="noopener">Image Source</a></figcaption></figure><p id="17e5">The recently-concluded CVPR 2020 had quite a large number of contributions in pushing <a href="https://www.fritz.ai/object-detection/" target="_blank" rel="noopener">object detection</a> forward. In this piece, we’ll look at a couple of the especially impressive papers.</p></div></div></section><hr><section><div><div><p id="b499">This paper proposes a graph convolution-based (GConv) hierarchical graph network (HGNet) for 3D object detection. It processes raw point clouds directly to predict 3D bounding boxes. HGNet is able to capture the relationship of the points and uses multi-level semantics for object detection.</p><p id="1d1c">HGNet consists of three main components:</p><ul><li id="a8ee">a GConv based U-shape network (GU-net)</li><li id="3b16">a Proposal Generator</li><li id="540c">a Proposal Reasoning Module (ProRe Module) — that uses a fully-connected graph to reason on the proposals</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2420/1*2LWJMtQLwK9xOWQwEUjnVg.png" width="1210" height="460" srcset="https://miro.medium.com/max/552/1*2LWJMtQLwK9xOWQwEUjnVg.png 276w, https://miro.medium.com/max/1104/1*2LWJMtQLwK9xOWQwEUjnVg.png 552w, https://miro.medium.com/max/1280/1*2LWJMtQLwK9xOWQwEUjnVg.png 640w, https://miro.medium.com/max/1400/1*2LWJMtQLwK9xOWQwEUjnVg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*2LWJMtQLwK9xOWQwEUjnVg.png?q=20"></p></div></div></div></figure><p id="b36f">The authors present a shape-attentive GConv (SA-GConv) to capture the local shape features. This is done by modeling the relative geometric positions to describe object shapes.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1082/1*8ixotq1FqZ367wbotywgdw.png" width="541" height="358" srcset="https://miro.medium.com/max/552/1*8ixotq1FqZ367wbotywgdw.png 276w, https://miro.medium.com/max/1082/1*8ixotq1FqZ367wbotywgdw.png 541w" sizes="541px" data-old-src="https://miro.medium.com/max/60/1*8ixotq1FqZ367wbotywgdw.png?q=20"></p></div></div></figure><p id="cc59">The SA-GConv based U-shape network captures the multi-level features. They are then mapped onto an identical feature space by a voting module and used to generate proposals. In the next step, a GConv based Proposal Reasoning Module uses the proposals to predict bounding boxes.</p><p id="5d73">Here are some of the performance results obtained on the <a href="https://rgbd.cs.princeton.edu/" target="_blank" rel="noopener">SUN RGB-D V1</a> dataset.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2308/1*NWypUDcLF9Ss9iSEEJZ3gA.png" width="1154" height="282" srcset="https://miro.medium.com/max/552/1*NWypUDcLF9Ss9iSEEJZ3gA.png 276w, https://miro.medium.com/max/1104/1*NWypUDcLF9Ss9iSEEJZ3gA.png 552w, https://miro.medium.com/max/1280/1*NWypUDcLF9Ss9iSEEJZ3gA.png 640w, https://miro.medium.com/max/1400/1*NWypUDcLF9Ss9iSEEJZ3gA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*NWypUDcLF9Ss9iSEEJZ3gA.png?q=20"></p></div></div></div></figure></div></div></section><hr><section><div><div><p id="28de">In this paper, the authors present the Hybrid Voxel Network (HVNet), a one-stage network for point cloud-based 3D object detection for autonomous driving.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2486/1*Jx7-FBXXK6aeFUZS0hT2UA.png" width="1243" height="334" srcset="https://miro.medium.com/max/552/1*Jx7-FBXXK6aeFUZS0hT2UA.png 276w, https://miro.medium.com/max/1104/1*Jx7-FBXXK6aeFUZS0hT2UA.png 552w, https://miro.medium.com/max/1280/1*Jx7-FBXXK6aeFUZS0hT2UA.png 640w, https://miro.medium.com/max/1400/1*Jx7-FBXXK6aeFUZS0hT2UA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Jx7-FBXXK6aeFUZS0hT2UA.png?q=20"></p></div></div></div></figure><p id="008f">The voxel feature encoding (VFE) method used in this paper contains three steps:</p><ul><li id="5d07">Voxelization — assigning of a point cloud to a 2D voxel grid</li><li id="a86b">Voxel Feature Extraction — computation of a grid-dependent point-wise feature that’s fed to a PointNet style feature encoder</li><li id="e25a">Projection — aggregation of the point-wise feature to the voxel-level feature and projection to their original grid. This forms a pseudo-image feature map</li></ul><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1226/1*_Vl9dsBUX1CXglvmkl-a6Q.png" width="613" height="654" srcset="https://miro.medium.com/max/552/1*_Vl9dsBUX1CXglvmkl-a6Q.png 276w, https://miro.medium.com/max/1104/1*_Vl9dsBUX1CXglvmkl-a6Q.png 552w, https://miro.medium.com/max/1226/1*_Vl9dsBUX1CXglvmkl-a6Q.png 613w" sizes="613px" data-old-src="https://miro.medium.com/max/56/1*_Vl9dsBUX1CXglvmkl-a6Q.png?q=20"></p></div></div></figure><p id="1d27">The size of the voxel is very important in VFE methods. Smaller voxel sizes capture finer geometry features. They’re also better at object localization, but take longer at inference. Faster inference speeds can be obtained using a coarser voxel, since it leads to a smaller feature map. Its performance is inferior, however.</p><p id="8598">The authors propose the Hybrid Voxel Network (HVNet) to enable the utilization of fine-grained voxel features. It’s made up of three steps:</p><ul><li id="19d2">Multi-Scale Voxelization — the creation of a set of feature voxel scales and the assignment of each to multiple voxels.</li><li id="0982">Hybrid Voxel Feature Extraction —computing of a voxel dependent feature for each scale and feeding it into the attentive feature encoder (AVFE). Features from each voxel scale are concatenated point-wise.</li><li id="1f9c">Dynamic Feature Projection — Projecting the feature back to the pseudo-image by creating a set of multi-scale project voxels.</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2534/1*zyGPbSVftzzdHPxerAXQxQ.png" width="1267" height="561" srcset="https://miro.medium.com/max/552/1*zyGPbSVftzzdHPxerAXQxQ.png 276w, https://miro.medium.com/max/1104/1*zyGPbSVftzzdHPxerAXQxQ.png 552w, https://miro.medium.com/max/1280/1*zyGPbSVftzzdHPxerAXQxQ.png 640w, https://miro.medium.com/max/1400/1*zyGPbSVftzzdHPxerAXQxQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*zyGPbSVftzzdHPxerAXQxQ.png?q=20"></p></div></div></div></figure><p id="17b9">Here are the results obtained on the KITTI dataset.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2472/1*MGF7HcNNTMKfYSdFa4sllQ.png" width="1236" height="513" srcset="https://miro.medium.com/max/552/1*MGF7HcNNTMKfYSdFa4sllQ.png 276w, https://miro.medium.com/max/1104/1*MGF7HcNNTMKfYSdFa4sllQ.png 552w, https://miro.medium.com/max/1280/1*MGF7HcNNTMKfYSdFa4sllQ.png 640w, https://miro.medium.com/max/1400/1*MGF7HcNNTMKfYSdFa4sllQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*MGF7HcNNTMKfYSdFa4sllQ.png?q=20"></p></div></div></div></figure></div></div></section><hr><section><div><div><blockquote><p id="d025">State-of-the-art object detection models can also work in real-time on mobile devices. <a href="https://www.fritz.ai/product/studio.html?utm_campaign=object-detection-cvpr&amp;utm_source=heartbeat" target="_blank" rel="noopener">And Fritz AI Studio allows you to build, test, and deploy custom object detection models to iOS and Android. Start building for free</a>.</p></blockquote><p id="e8a5">Authors of this paper present a graph neural network — Point-GNN — to detect objects from a <a href="https://en.wikipedia.org/wiki/National_lidar_dataset" target="_blank" rel="noopener">LiDAR</a> point cloud. The network predicts the category and shape of the object that each vertex in the graph belongs to. Point-GNN has an auto-regression mechanism that detects multiple objects in a single shot.</p><p id="b2a8">The proposed method has three components:</p><ul><li id="8cc5">graph construction: a voxel downsampled point cloud is used for graph construction</li><li id="520b">a graph neural network of <em>T</em> iterations</li><li id="2685">bounding box merging and scoring</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2286/1*0O8VhuRPdxqwVFhWamyTCA.png" width="1143" height="623" srcset="https://miro.medium.com/max/552/1*0O8VhuRPdxqwVFhWamyTCA.png 276w, https://miro.medium.com/max/1104/1*0O8VhuRPdxqwVFhWamyTCA.png 552w, https://miro.medium.com/max/1280/1*0O8VhuRPdxqwVFhWamyTCA.png 640w, https://miro.medium.com/max/1400/1*0O8VhuRPdxqwVFhWamyTCA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*0O8VhuRPdxqwVFhWamyTCA.png?q=20"></p></div></div></div></figure><p id="0c03">Here’re the results obtained on the KITTI dataset:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1834/1*VgfFosL4qu9Mr8lvLR62TQ.png" width="917" height="567" srcset="https://miro.medium.com/max/552/1*VgfFosL4qu9Mr8lvLR62TQ.png 276w, https://miro.medium.com/max/1104/1*VgfFosL4qu9Mr8lvLR62TQ.png 552w, https://miro.medium.com/max/1280/1*VgfFosL4qu9Mr8lvLR62TQ.png 640w, https://miro.medium.com/max/1400/1*VgfFosL4qu9Mr8lvLR62TQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*VgfFosL4qu9Mr8lvLR62TQ.png?q=20"></p></div></div></div></figure><p id="e229">The code is available here:</p></div></div></section><hr><section><div><div><p id="76a1">This paper addresses the challenge of detecting objects that are embedded in their surroundings — camouflaged object detection (COD). The authors also present a new dataset called COD10K. It contains 10,000 images covering camouflaged objects in many natural scenes. It has 78 object categories. The images are annotated with category labels, bounding boxes, instance-level, and matting-level labels.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2302/1*oUHPPL-gG6kEzpUlj1iMww.png" width="1151" height="292" srcset="https://miro.medium.com/max/552/1*oUHPPL-gG6kEzpUlj1iMww.png 276w, https://miro.medium.com/max/1104/1*oUHPPL-gG6kEzpUlj1iMww.png 552w, https://miro.medium.com/max/1280/1*oUHPPL-gG6kEzpUlj1iMww.png 640w, https://miro.medium.com/max/1400/1*oUHPPL-gG6kEzpUlj1iMww.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*oUHPPL-gG6kEzpUlj1iMww.png?q=20"></p></div></div></div></figure><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2262/1*vt8wuBQCjKT6KQgVqwwa7Q.png" width="1131" height="224" srcset="https://miro.medium.com/max/552/1*vt8wuBQCjKT6KQgVqwwa7Q.png 276w, https://miro.medium.com/max/1104/1*vt8wuBQCjKT6KQgVqwwa7Q.png 552w, https://miro.medium.com/max/1280/1*vt8wuBQCjKT6KQgVqwwa7Q.png 640w, https://miro.medium.com/max/1400/1*vt8wuBQCjKT6KQgVqwwa7Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*vt8wuBQCjKT6KQgVqwwa7Q.png?q=20"></p></div></div></div></figure><p id="0447">The authors develop a COD framework called a Search Identification Network (SINet). The code is available here:</p><p id="ea04">The network has two main modules:</p><ul><li id="5593">the search module (SM) for searching for a camouflaged object</li><li id="bc25">the identification module (IM) for detecting the object</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2304/1*lu3cY_bKE_-wnbTsbb4SqA.png" width="1152" height="572" srcset="https://miro.medium.com/max/552/1*lu3cY_bKE_-wnbTsbb4SqA.png 276w, https://miro.medium.com/max/1104/1*lu3cY_bKE_-wnbTsbb4SqA.png 552w, https://miro.medium.com/max/1280/1*lu3cY_bKE_-wnbTsbb4SqA.png 640w, https://miro.medium.com/max/1400/1*lu3cY_bKE_-wnbTsbb4SqA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lu3cY_bKE_-wnbTsbb4SqA.png?q=20"></p></div></div></div></figure><p id="63ae">Here are the results obtained on various datasets:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2362/1*UyVfgef-qfXcGrKljiH3FA.png" width="1181" height="594" srcset="https://miro.medium.com/max/552/1*UyVfgef-qfXcGrKljiH3FA.png 276w, https://miro.medium.com/max/1104/1*UyVfgef-qfXcGrKljiH3FA.png 552w, https://miro.medium.com/max/1280/1*UyVfgef-qfXcGrKljiH3FA.png 640w, https://miro.medium.com/max/1400/1*UyVfgef-qfXcGrKljiH3FA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*UyVfgef-qfXcGrKljiH3FA.png?q=20"></p></div></div></div></figure></div></div></section><hr><section><div><div><h2 id="4f7c">Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector</h2><p id="eb21">This paper proposes a few-shot object detection network whose objective is to detect objects of unseen categories that have a few annotated examples.</p><p id="a68b">Their method includes an attention-RPN, multi-relation detector, and a contrastive training strategy. The method takes advantage of the similarity between the few-shot support set and query set to identify new objects, while also reducing false identification. The authors also contribute a new dataset that contains 1000 categories with objects that have high-quality annotations.</p><p id="71e2">The network architecture consists of a weight-shared framework that has multiple branches—one branch is the query set, while the rest are for the support set. The query branch of the weight-shared framework is a Faster R-CNN network.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2436/1*RUUYLi6Eg3vPjFmY7tY6Cg.png" width="1218" height="521" srcset="https://miro.medium.com/max/552/1*RUUYLi6Eg3vPjFmY7tY6Cg.png 276w, https://miro.medium.com/max/1104/1*RUUYLi6Eg3vPjFmY7tY6Cg.png 552w, https://miro.medium.com/max/1280/1*RUUYLi6Eg3vPjFmY7tY6Cg.png 640w, https://miro.medium.com/max/1400/1*RUUYLi6Eg3vPjFmY7tY6Cg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*RUUYLi6Eg3vPjFmY7tY6Cg.png?q=20"></p></div></div></div></figure><p id="a03e">The authors introduce an attention-RPN and detector with multi-relation modules to produce accurate parsing between support and the potential boxes in the query.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1236/1*T2hy3IxGrcyiAvQKBvQApA.png" width="618" height="288" srcset="https://miro.medium.com/max/552/1*T2hy3IxGrcyiAvQKBvQApA.png 276w, https://miro.medium.com/max/1104/1*T2hy3IxGrcyiAvQKBvQApA.png 552w, https://miro.medium.com/max/1236/1*T2hy3IxGrcyiAvQKBvQApA.png 618w" sizes="618px" data-old-src="https://miro.medium.com/max/60/1*T2hy3IxGrcyiAvQKBvQApA.png?q=20"></p></div></div></figure><p id="e227">Here are some results obtained on the ImageNet dataset.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1140/1*As81-1oOCZvtoERYLe6gIw.png" width="570" height="299" srcset="https://miro.medium.com/max/552/1*As81-1oOCZvtoERYLe6gIw.png 276w, https://miro.medium.com/max/1104/1*As81-1oOCZvtoERYLe6gIw.png 552w, https://miro.medium.com/max/1140/1*As81-1oOCZvtoERYLe6gIw.png 570w" sizes="570px" data-old-src="https://miro.medium.com/max/60/1*As81-1oOCZvtoERYLe6gIw.png?q=20"></p></div></div></figure><p id="125e">Here are some observations obtained on a number of datasets.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1806/1*Bb8HkNNllnSZMDZYewMJGQ.png" width="903" height="579" srcset="https://miro.medium.com/max/552/1*Bb8HkNNllnSZMDZYewMJGQ.png 276w, https://miro.medium.com/max/1104/1*Bb8HkNNllnSZMDZYewMJGQ.png 552w, https://miro.medium.com/max/1280/1*Bb8HkNNllnSZMDZYewMJGQ.png 640w, https://miro.medium.com/max/1400/1*Bb8HkNNllnSZMDZYewMJGQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Bb8HkNNllnSZMDZYewMJGQ.png?q=20"></p></div></div></div></figure></div></div></section><hr><section></section><hr><section><div><div><p id="ab0d">Authors of this paper propose D2Det, a method that addresses both precise localization and accurate classification. They introduce a dense local regression that predicts multiple dense box offsets for an object proposal. This enables them to achieve precise localization.</p><p id="5dc5">The authors also introduce a discriminative RoI pooling scheme in order to achieve accurate classification. The pooling scheme samples from several sub-regions of a proposal and performs adaptive weighting to get discriminating features.</p><p id="2c8b">The code is available at:</p><p id="487f">The method is based on the standard Faster R-CNN framework. In this method, the traditional box offset regression of Faster R-CNN is replaced by the proposed dense local regression. In the method, classification is enhanced by the discriminative RoI pooling.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1956/1*PxcLCxREMAidDShpAJoP-A.png" width="978" height="607" srcset="https://miro.medium.com/max/552/1*PxcLCxREMAidDShpAJoP-A.png 276w, https://miro.medium.com/max/1104/1*PxcLCxREMAidDShpAJoP-A.png 552w, https://miro.medium.com/max/1280/1*PxcLCxREMAidDShpAJoP-A.png 640w, https://miro.medium.com/max/1400/1*PxcLCxREMAidDShpAJoP-A.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PxcLCxREMAidDShpAJoP-A.png?q=20"></p></div></div></div></figure><p id="f1b4">In the two-stage method, a region proposal network (RPN) is used in the first stage, while separate classification and regression branches are put into effect in the second stage. The classification branch is based on discriminative pooling. The local regression branch’s objective is exact localization of an object.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1046/1*5aP-iJHp_6ekwW2_QJE6og.png" width="523" height="622" srcset="https://miro.medium.com/max/552/1*5aP-iJHp_6ekwW2_QJE6og.png 276w, https://miro.medium.com/max/1046/1*5aP-iJHp_6ekwW2_QJE6og.png 523w" sizes="523px" data-old-src="https://miro.medium.com/max/50/1*5aP-iJHp_6ekwW2_QJE6og.png?q=20"></p></div></div></figure><p id="6547">Here are the results obtained on the MS COCO dataset:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1842/1*V25SVKupb4ts1x6mDZyQGg.png" width="921" height="552" srcset="https://miro.medium.com/max/552/1*V25SVKupb4ts1x6mDZyQGg.png 276w, https://miro.medium.com/max/1104/1*V25SVKupb4ts1x6mDZyQGg.png 552w, https://miro.medium.com/max/1280/1*V25SVKupb4ts1x6mDZyQGg.png 640w, https://miro.medium.com/max/1400/1*V25SVKupb4ts1x6mDZyQGg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*V25SVKupb4ts1x6mDZyQGg.png?q=20"></p></div></div></div></figure></div></div></section><hr><section><div><div><h2 id="3951">Final Thought</h2><p id="b662">When it comes to object detection and a whole host of other computer vision tasks, CVPR 2020 offered plenty more. Here’s the open source repo of all the conference papers, in case you’d like to explore further.</p></div></div></section><hr><section><div><div><p id="8a55"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="595e"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="863b"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/cvpr-2020-the-top-objection-detection-papers-f920a6e41233</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832469</guid>
            <pubDate>Tue, 14 Jul 2020 14:38:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Partner Management for SaaS Companies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832461">thread link</a>) | @iliasanta
<br/>
July 14, 2020 | https://elioplus.com/prm-software | <a href="https://web.archive.org/web/*/https://elioplus.com/prm-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
    
    <div id="MainContent_UpdatePanel2">
	 
    <!-- banner area start -->
    

    <!-- About us section start -->
    <section id="abouts">
        <div>
            <div>
                <div>
                    <p><img src="https://elioplus.com/assets/prm/images/all-img/Partner_Relationship_Management_PRM_Dashboard.png" alt=""></p>
                </div>
                <!-- end about img -->
                <div>
                    <h2>Elioplus PRM</h2>
                    <p>
                        Elioplus PRM is the Partner Relationship Management software for every size of business operating in software, SaaS and cloud industry.
                        We break the rule that exists in IT channel industry giving access actually only to Entrerprise level companies that have the budget to invest on a PRM system to manage their channel partners.
                        We give access FOR FREE to software, SaaS and cloud services Vendors to manage up to 25 channel partners enjoying a 2GB library storage as well with full access to all of our features.
                    </p>
                    <p><a href="https://elioplus.com/prm-software/partner-portal" id="MainContent_aFeatures">Our Features</a>
                </p></div>
                <!-- end about conetent -->
            </div>
        </div>
    </section>

    <!-- Services area start -->
    <section id="feature">
        
        <!-- end feature bg shape 1 -->
        
        <!-- end feature bg shape 2 -->
        <div>
            <div>
                <div>
                    <h2>Features that matter</h2>
                    <p>
                        <span id="MainContent_LblPrmFeatures1">Elioplus PRM provides features that can increase your channel sales. Avoid a ton of features that make your life difficult.</span><br>
                        <span id="MainContent_LblPrmFeatures2">Through Elioplus PRM you are focusing on your channel partners productivity and needs through collaboration and incentivization.</span>
                    </p>
                </div>
                <!-- end section-titile -->
            </div>
            <!-- end row -->
            <div>
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>01</p>
                        <h3><a href="https://elioplus.com/prm-software/partner-onboarding" id="MainContent_aPrmSoftwareFeatures1">Onboarding</a></h3>
                        <p>
                            Your new partners need to have the right knowledge and skills to sell your solution from the beginning of your collaboration. Upload all the files and video that are needed through our onboarding feature and they'll automatically have access to any of them.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>02</p>
                        <h3><a href="https://elioplus.com/prm-software/deal-registration" id="MainContent_aPrmSoftwareFeatures2">Deal registration</a></h3>
                        <p>
                            Secure your channel partners' sales though our deal registration feature. Your channel partners won't worry anymore about losing a potential client that is interested to buy your solution. The only worry of them will be how to win the deal.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>03</p>
                        <h3><a href="https://elioplus.com/prm-software/lead-distribution" id="MainContent_aPrmSoftwareFeatures3">Lead distribution</a></h3>
                        <p>
                            Send hot leads to your channel partners though your PRM account. Satisfy the clients of your solution by assigning them the right partner for training, support and more. Increase sales for both and build a fruitful and strong relationship with your channel network.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>04</p>
                        <h3><a href="https://elioplus.com/prm-software/channel-analytics" id="MainContent_aPrmSoftwareFeatures4">Analytics</a></h3>
                        <p>
                            Get insights about your channel network’s performance, detailed analytics for each partner, their activity on your partner portal and forecasting for potential deals that might close successfully from your channel partners for the next quarters.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>05</p>
                        <h3><a href="https://elioplus.com/prm-software/collaboration" id="MainContent_aPrmSoftwareFeatures5">Collaboration &amp; Library</a></h3>
                        <p>
                            Invite your partners to your PRM, communicate real time, exchange material, create groups for chatting and increase revenue though collaboration. Enjoy a 2GB secured library, upload different types of files and categorize them. Send and receive files from your partners.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>06</p>
                        <h3><a href="https://elioplus.com/prm-software/partner-portal" id="MainContent_aPrmSoftwareFeatures6">Partner Portal</a></h3>
                        <p>
                            Enjoy a full branded partner portal with your own logo and your unique sign up and sign in URL. Your channel partners can now easily have access to the PRM through your unique partner portal page which you can upload on your website as well.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>07</p>
                        <h3><a href="https://elioplus.com/prm-software/partner-locator" id="MainContent_aPrmSoftwareFeatures7">Partner Locator</a></h3>
                        <p>
                            Add a partner locator to showcase your partners to your visitors in order to find a local company that offers your products and services. Incentivize your partners with new leads and your customers with better support.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
                <!-- end single feature -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        <p>08</p>
                        <h3><a id="MainContent_aPartnerRecruitment">Customization</a></h3>
                        <p>
                            Customize your partner portal based on your needs and your brand to get the best out of it at no extra charge.
                        </p>
                    </div>
                </div>
                <!-- end single feature -->
            </div>
            
        </div>
    </section>

    <!-- integrations start -->
    <section id="integration">       
        
    </section>

    <!-- security start -->
    <section id="security">       
        <div>
            <div>
                <p>
                    <h2>Security</h2>                    
                </p>
                <div>
                    <p><img id="MainContent_Image1" src="https://elioplus.com/images/Security_Icon.png" alt="PRM Security Fully Secure">
                       <span id="MainContent_LblSecurity1">Fully Secure</span>
                    </p>                    
                </div>
                <div>
                    <p><img id="MainContent_Image2" src="https://elioplus.com/images/Security_Icon.png" alt="PRM Security Platform Uptime">
                       <span id="MainContent_Label1">99.9% Platform Uptime</span>
                    </p>
                </div>
                <div>
                    <p><img id="MainContent_Image3" src="https://elioplus.com/images/Security_Icon.png" alt="PRM Security GDPR Compliant">
                       <span id="MainContent_Label2">GDPR Compliant</span>
                    </p>
                </div>
                <p><img id="MainContent_Image4" src="https://elioplus.com/images/Security_Icon.png" alt="PRM Security SSL Encryption Enabled">
                       <span id="MainContent_Label3">SSL Encryption Enabled</span>
                </p>
            </div>
        </div>
    </section>

    <!-- apposh pricing table start -->
    <section id="price">
        
        <!-- end feature bg shape 1 -->
        <div>
            <div>
                <div>
                    <h2>Our pricing</h2>
                    <p>
                        Select the plan that fits your needs and start inviting your channel partners to join your PRM portal
                    </p>
                </div>
                <!-- end single pricicng -->
                <div data-animation="fadeInUp" data-animation-delay="0.18s">
                    <div>
                        
                        <!-- end price header -->
                        <div>
                            <ul>
                                <li>Manage up to 25 partners</li>
                                <li>2 GB library storage</li>
                                <li>Onboarding</li>
                                <li>Deal registration</li>
                                <li>Lead distribution</li>
                                <li>Collaboration</li>
                                <li>Partner directory</li>
                                <li>Partner to partner</li>
                            </ul>
                        </div>
                        <!-- end price body -->
                        
                        <!-- end price footer -->
                    </div>
                </div>
                <!-- end section-titile -->
                <div data-animation="fadeInUp" data-animation-delay="0.1s">
                    <div>
                        
                        <!-- end price header -->
                        <div>
                            <ul>
                                <li>+ Manage up to 100 partners</li>
                                <li>+ 10 GB library storage</li>
                                <li>Onboarding</li>
                                <li>Deal registration</li>
                                <li>Lead distribution</li>
                                <li>Collaboration</li>
                                <li>Partner directory</li>
                                <li>Partner to partner</li>
                                <li>+ Partner recruitment</li>
                                <li>+ Customization</li>
                            </ul>
                        </div>
                        <!-- end price body -->
                        
                        <!-- end price footer -->
                    </div>
                </div>
                <!-- end single pricicng -->
                <div data-animation="fadeInUp" data-animation-delay="0.14s">
                    <div>
                        
                        <p><span>Popular</span>
                        </p>
                        <!-- end price header -->
                        <div>
                            <ul>
                                <li>+ Manage up to 250 partners</li>
                                <li>+ 20 GB library storage</li>
                                <li>Onboarding</li>
                                <li>Deal registration</li>
                                <li>Lead distribution</li>
                                <li>Collaboration</li>
                                <li>Partner directory</li>
                                <li>Partner to partner</li>
                                <li>+ Partner recruitment(advanced)</li>
                                <li>+ Customization</li>
                            </ul>
                        </div>
                        <!-- end price body -->
                        
                        <!-- end price footer -->
                    </div>
                </div>                
                <!-- end single pricicng -->                
            </div>
            <p>
                    Have you got a bigger partner network to manage? Get in touch with our sales team
                    <a href="https://elioplus.com/contact-us" id="MainContent_aContactUs">Contact us</a>
                </p>
        </div>
    </section>

    <!-- apposh team start -->
    <section id="team">
        
    </section>

    <!-- testimonials start -->
    <section id="clinetssay">
        <div>
            <div>
                <div>
                    <h2>Testimonials</h2>                    
                    <p>
                        We focus on the success of our clients. Take a look at the experience they are facing by using Elioplus for their channel development efforts.
                    </p>
                </div>
                <!-- end section-titile -->
                <div>
                    <div>
                        <div>
                            <div>
                                <p><img src="https://elioplus.com/assets/prm/images/testimonials/chatwork_testimonial.png" alt=""></p><p>
                                    Guys you are doing a great job, really appreciate your support and your help by increasing our channel partners network through your service.
                                </p>
                                <p>
                                    <h4>Tomi Brooks</h4>
                                    <h5>VP of Growth at Chatwork</h5>
                                </p>
                            </div>
                            <!-- end single testimonilas -->
                            <div>
                                <p><img src="https://elioplus.com/assets/prm/images/testimonials/evernote_testimonial.png" alt=""></p><p>
                                    Amazing service and partnership matches, excellent support and summary of the work. Thanks a lot Elioplus!
                                </p>
                                <p>
                                    <h4>Manuel Marquina</h4>
                                    <h5>Head of Account Management and Business, EMEA at Evernote</h5>
                                </p>
                            </div>
                            <!-- end single testimonilas -->
                            <div>
                                <p><img src="https://elioplus.com/assets/prm/images/testimonials/bobile_testimonial.png" alt=""></p><p>
                                    Elio platform is easy to use and has all the features you need to increase your channel partners and manage your existing and new ones. Highly recommended!
                                </p>
                                <p>
                                    <h4>Eran Amit</h4>
                                    <h5>CMO at Bobile</h5>
                                </p>
                            </div>
                            <!-- end single testimonilas -->
                            <div>
                                <p><img src="https://elioplus.com/assets/prm/images/testimonials/repsly_testimonial.png" alt=""></p><p>
                                    Interface is easy to understand and use. Data is in a …</p></div></div></div></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elioplus.com/prm-software">https://elioplus.com/prm-software</a></em></p>]]>
            </description>
            <link>https://elioplus.com/prm-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832461</guid>
            <pubDate>Tue, 14 Jul 2020 14:37:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[See Slow Faster with Performance Monitoring]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832358">thread link</a>) | @gilad
<br/>
July 14, 2020 | https://blog.sentry.io/2020/07/14/see-slow-faster-with-performance-monitoring/ | <a href="https://web.archive.org/web/*/https://blog.sentry.io/2020/07/14/see-slow-faster-with-performance-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>iPod to iPhone. Breaking Bad to Better Call Saul. Super Mario to Mario Maker. Leaders don’t rest on their laurels. That’s what motivated us to create Performance, our new code monitoring offering: to build off our core functionality and toward the demands developers face, both today and in the future. </p>
<p>From tracking down slow-loading pages to ensuring auto-completes actually complete, <a href="https://docs.sentry.io/performance-monitoring/getting-started/">Performance</a> gives you deeper visibility into the API calls and database queries that are critical toward delivering fast customer experiences with just five lines of code. </p>
<blockquote>
<p>We’ve been using Sentry since the early days of Tackle, so getting set up with Performance was literally a one-line change for us. It quickly identified problematic endpoints and how our users were being impacted. We’re now planning some improvements to these APIs; can’t wait to see those times go down!</p>
</blockquote>
<p><em>Dillon Woods, Founder and CTO, <a href="http://tackle.io/">Tackle</a></em></p>
</div><div>
<h2 id="developers-take-comfort-in-resolving-user-misery"><a href="#developers-take-comfort-in-resolving-user-misery" aria-label="developers take comfort in resolving user misery permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Developers: Take Comfort in Resolving User Misery</h2>
<p>Slow is a relative term. It’s why, in order to properly troubleshoot a slow customer experience, you need a consistent metric for slow. Enter User Misery. By pairing industry metrics with user metrics, User Misery tells you what is making any number of users…miserable. This means getting out in front of painful experiences before they become problems, and problems before they cause your customers to churn.</p>
<h2 id="mission-critical-context"><a href="#mission-critical-context" aria-label="mission critical context permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Mission-critical Context</h2>
<p>Without context, a customer’s spinning pinwheel can quickly turn into a developer’s panic spiral. Transaction Summary surfaces transactions by duration time, related code errors, and impact to the customer. With it, you can quickly see the number of affected users as well as the transaction’s impact on your response time. And by defining Key Transactions, your team can prioritize those critical functions and callbacks that need to be addressed immediately.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?fm=webp&amp;w=305 305w,
https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?fm=webp&amp;w=610 610w,
https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?fm=webp&amp;w=1220 1220w" sizes="(max-width: 800px) 100vw, 800px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?w=305 305w,
https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?w=610 610w,
https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png?w=1220 1220w" sizes="(max-width: 800px) 100vw, 800px">
          <img alt="transaction summary" title="" src="https://images.ctfassets.net/em6l9zw4tzag/2iW7jSnWPu3T1FDU06wAxj/afbc0ec6b7eb540617cd6f80fd406ad1/01_performance__2_.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>We also extended our alerting capabilities to include transactions. Developers can set an alert on what they perceive to be a poor user experience. Want to get notified when an important page takes 4 seconds to load? You can do that.</p>
<blockquote>
<p><em>Considering that we’re in the middle of migrating to a modern application stack, Performance from Sentry is exactly what we need. Being able to see slow transactions and related errors out of the box with Sentry is going to help us deliver an even faster, more reliable experience.</em></p>
</blockquote>
<p><em>Mike Diaz, Lead Frontend Engineer at <a href="http://smugmug.com/">SmugMug</a></em></p>
<h2 id="untangle-tracing"><a href="#untangle-tracing" aria-label="untangle tracing permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Untangle Tracing</h2>
<p>Some error monitoring tools show you data from a frontend error. Only Performance can trace that frontend back to its API calls and slow database queries - all while surfacing related errors. What’s more, Performance aggregates the metadata surrounding your errors so you can easily search and sort your exceptions.</p>
</div><div>
<blockquote>
<p>Sentry’s performance tracking has been a huge help for us. Before, it was difficult to know exactly how long key functions actually took to load in real-time conditions. Now, we have metrics to assess whether load times are acceptable and we can learn which conditions impact performance, as part of our drive to constantly improve the user’s experience.</p>
</blockquote>
<p><em>Alexandre Grégoire, web lead at <a href="http://transit.app/">Transit</a></em></p>
<p>Just like Apple, Saul Goodman, and Mario Maker 2, we’re going to keep raising the code monitoring bar, so you can keep raising the bar for your customers by shipping performant and reliable software.</p>
<p>Curious yet? <a href="https://sentry.io/signup/">Sign up</a> or contact <a href="mailto:sales@sentry.io">sales@sentry.io</a> to get started.</p></div></div>]]>
            </description>
            <link>https://blog.sentry.io/2020/07/14/see-slow-faster-with-performance-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832358</guid>
            <pubDate>Tue, 14 Jul 2020 14:28:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PCAP or it didn't happen: packet capture for the insanely bored]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23832283">thread link</a>) | @kimballo
<br/>
July 14, 2020 | https://www.kimballleavitt.com/pktcapture/ | <a href="https://web.archive.org/web/*/https://www.kimballleavitt.com/pktcapture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.kimballleavitt.com/pktcapture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832283</guid>
            <pubDate>Tue, 14 Jul 2020 14:22:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eventual Consistency isn’t for Streaming]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 45 (<a href="https://news.ycombinator.com/item?id=23832149">thread link</a>) | @arjunnarayan
<br/>
July 14, 2020 | https://materialize.io/eventual-consistency-isnt-for-streaming/ | <a href="https://web.archive.org/web/*/https://materialize.io/eventual-consistency-isnt-for-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Streaming systems consume inputs and produce outputs asyncronously: the output of a system at any moment may not reflect all of the inputs seen so far. These systems provide various guarantees about how their outputs relate to their input. Among the weaker (but not unpopular) guarantees is <a href="https://en.wikipedia.org/wiki/Eventual_consistency">eventual consistency</a>. Informally, eventual consistency means if the input stops changing, the output will eventually arrive at the correct result.</p>
<p>In this post we’ll see that for as long as its input streams haven’t been stopped, natural eventually consistent computations can produce <em>unboundedly large and systematic errors</em>. If you are doing even slightly non-trivial computations, you should be prepared for your results to be <em>never-consistent</em> (a much less popular consistency definition). Until you pause the input streams and await correct answers, at least.</p>
<p>Not all is lost! There are stream processing systems that provide strong consistency guarantees. <a href="https://materialize.io/">Materialize</a> and <a href="https://github.com/TimelyDataflow/differential-dataflow">Differential Dataflow</a> both avoid these classes of errors by providing <em>always correct</em> answers, as do several other streaming systems.</p>
<p>If you want to avoid systematic and on-going errors in your results, you should probably check if the stream processor you use provides stronger consistency guarantees.</p>
<h2>Background on Eventual Consistency</h2>
<p>To quote from the <a href="https://en.wikipedia.org/wiki/Eventual_consistency">Wikipedia page on eventual consistency</a></p>
<blockquote><p>
  Eventual consistency is a consistency model used in distributed computing to achieve high availability that informally guarantees that, if no new updates are made to a given data item, eventually all accesses to that item will return the last updated value.
</p></blockquote>
<p>Eventual consistency is most often invoked for key-value stores, where each key tracks an independent value and one can reasonably imagine not updating the value associated with a key for long enough that the right answer might shake out. For example, if a database stores a map from people to their addresses, your update to your own address might not be visible immediately, but if you give it a few minutes it will probably sort itself out (if you don’t further update your address).</p>
<p>The requirement is only that folks stop updating a specific key, not that they stop using the database entirely. The rest of the world can keep reading out addresses, even keep reading out your stale address, and an eventually consistent system is obliged to eventually update your address (assuming you don’t keep re-submitting updates). Eventual consistency is a workable definition of consistency for key-value stores, where the vast majority of operations do not conflict, and one can reasonably expect to wait out any inconsistency.</p>
<p>Is eventual consistency a workable definition of consistency for streaming computations?</p>
<h2>Streaming computations</h2>
<p>There are many streaming computations out there. I’m going to focus on a class that lines up well with our study of consistency: incremental view maintenance. Incremental view maintenance is where you’ve defined a view, essentially a name bound to a query, and want to see the output answers change as the input data change.</p>
<p>Let’s say you’ve defined a query that could be applied to a static dataset, something like</p>
<pre title="">-- count the records in `data`
select count(*) from data
</pre>
<p>Now, the underlying <code>data</code> might change. As they do, we should produce the corresponding changes to the output. In this case, we would like to see how the <code>count</code> of the records in <code>data</code> have changed.</p>
<p>There are more complicated queries we might write. For example, this query determines the set of keys whose values are the largest among all keys:</p>
<pre title="">-- select keys with maximum values
select data.key
from data
where data.value in (select max(data.value) from data)
</pre>
<p>As <code>data</code> change, we would like to see the resulting set of keys track the maximum values</p>
<p>This next query determines the standard deviation of values for each key, and then selects out those values that are surprisingly large.</p>
<pre title="">-- determine average and stddev for groups
create view stats_by_key
select
    data.key,
    avg(data.value) as average,
    stddev(data.value) as deviation
from data
group by data.key;

-- select out surprisingly large values
select data.key, data.value
from data, stats_by_key
where
    data.key = stats_by_key.key and
    data.value &gt; average + 3 * devation
</pre>
<p>As <code>data</code> move around, the set of current outliers moves around too, and we would be delighted to be warned of them so that we can take some important action.</p>
<p>I don’t have strong opinions about whether these are exciting queries to compute, but we’ll use them as examples of streaming computations that can go surprisingly wrong. If your computations are more sophisticated than these examples, you might have even more to worry about.</p>
<h2>Eventual consistency in streaming: example 1</h2>
<p>What does a naive application of eventual consistency have to say about</p>
<pre title="">-- count the records in `data`
select count(*) from data
</pre>
<p>It’s not really clear, is it? Even if there were clear keys we are writing to, the thing we want to be correct is an aggregation across all of them rather than the value associated with a specific key. That result depends on all values. We could still extrapolate the definition of eventual consistency out to mean that if the input stops changing entirely, the system will eventually update to the correct count of records in <code>data</code>.</p>
<p>Although you shouldn’t expect to see this in the wild, an eventually consistent streaming system is certainly permitted to delay its processing as long as there are any outstanding input records that haven’t been processed yet.</p>
<p>This is actually not as unreasonable as you might think. Many stream processors intentionally batch up their inputs to improve their efficiency, and get started only once they get a moment of fresh air in their input stream. This technique allows them to improve their throughput during load spikes, by batching and re-ordering updates (for example, bundling all updates to the same key). It would be natural to see updates out of order, but taken to the extreme this technique results is no updates during the load spike.</p>
<p>While this is not necessarily something you’ll see in a professional stream processor, nothing about eventual consistency prevents behavior like this. So, while it’s not the most realistic reason to be worried about eventual consistency, it paints a bit of a picture about what we might need to watch out for.</p>
<p>Let’s ignore the possibility that a technically correct eventually consistent processor could produce no results, and instead look at what happens for more reasonable systems on continually changing input streams.</p>
<h2>Eventual consistency in streaming: example 2</h2>
<p>Let’s take the query that selects out the keys with maximum values:</p>
<pre title="">-- select keys with maximum values
select data.key
from data
where data.value in (select max(data.value) from data)
</pre>
<p>This is how you express “argmax” in SQL, and it is roughly equivalent to a join between the collections <code>data</code> and <code>select max(data.value) from data</code>.</p>
<p>A reasonable person might expect to see the keys with maximum values here, and have an eventually consistent system eventually show it some maximal keys. Some head scratching and you might walk that back to “any keys at all” because they might no longer be maximal at the moment you see them. But <em>eventually</em> we should see <em>some</em> keys, right?</p>
<p>Nope.</p>
<p>At least, not as long as the input stream is allowed to change.</p>
<p>Imagine the join between <code>data</code> and <code>select max(data.value) from data</code> receives its eventually consistent inputs consistently later for <code>data</code> than for <code>select max(data.value) from data</code>. This is not unreasonable, as it can be easier to maintain a <code>max</code> than to maintain an entire collection (<code>data</code>). As each record of <code>data</code> arrives, even those records with maximal values at the time of their submission may find that the maximum has advanced before they got there. They no longer match the maximum value, and are not produced as output.</p>
<p>Let’s demonstrate this in <a href="https://github.com/TimelyDataflow/differential-dataflow">Differential Dataflow</a>. We’ll have to fake some things out, because its consistency guarantees are unfortunately too strong. Fortunately, we can directly program transient delays in to the dataflow.</p>
<p>Imagine a collection that may have multiple keys in it, but we’ll only need one. We’ll increment the value associated with the key regularly (perhaps this is bandwidth used, or money spent, or most recent access, or …). Importantly, we’ll delay the update along one path by the gap in time between updates.</p>
<pre title="">// Global aggregation of values, on-time.
let input1 =
data.map(|(key,val)| ((),val))
    .max_by_key() // not real; should be `reduce(...)`.
    .map(|((), val)| (val, ()));

// Delayed map from values back to their keys.
let input2 =
data.delay(|t| t + 1)
    .map(|(key,val)| (val,key));

// Observe any results
input2.semijoin(&amp;input)
      .inspect(|x| println!("KEY: {:?}", x));
</pre>
<p>We’ll feed in changes that add elements to <code>data</code>, one at a time. Roughly like so</p>
<pre title="">(key, 1000)
(key, 2000)
(key, 3000)
...
</pre>
<p>The keys and values aren’t important, other than that the maximum increases. If the maximum increases within the time of the delay associated with the “eventual” nature of the consistency, we see no results:</p>
<pre title="">    Finished dev [unoptimized + debuginfo] target(s) in 0.04s
     Running `target/debug/examples/eventual`
Round 0 complete
Round 1 complete
Round 2 complete
Round 3 complete
Round 4 complete
Round 5 complete
...
</pre>
<p>Suffice it to say we didn’t see any <code>KEY</code> reports. We would, eventually, if we were to stall the input stream and allow one of the inputs to the join to catch up to the other.</p>
<p>What happens if we <code>delay</code> the <code>max</code> computation instead of the <code>data</code> stream? If the updates overwrite their previous values (<em>i.e.</em> if <code>(key, 2000)</code> overwrites <code>(key, 1000)</code>) then we also see no outputs, because by the time the maximum arrives the value has changed.</p>
<p>Eventual consistency is pretty badly suited to problem of aligning data, when the contents of either of those streams of data can be expected to move on. In our case, the maximum is regularly …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://materialize.io/eventual-consistency-isnt-for-streaming/">https://materialize.io/eventual-consistency-isnt-for-streaming/</a></em></p>]]>
            </description>
            <link>https://materialize.io/eventual-consistency-isnt-for-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832149</guid>
            <pubDate>Tue, 14 Jul 2020 14:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dev Team Lead: things they didn't tell me when I got promoted]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23832046">thread link</a>) | @elorant
<br/>
July 14, 2020 | https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="294854cf" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png.webp 1700w" sizes="(max-width: 1700px) 100vw, 1700px">
<img src="https://linearb.io/wp-content/uploads/2020/06/superman2.png" alt="Dev team lead: Sometimes they suffer from Superman complex." srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png 1700w, https://linearb.io/wp-content/uploads/2020/06/superman2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/superman2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/superman2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/superman2-1536x723.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px">
</picture>
</figure>



<h2><strong>Getting promoted to dev team lead</strong></h2>



<p>I was 24 years old. A baby.&nbsp;</p>



<p>Three years into my software engineering career and loving it.&nbsp;</p>



<p>Life was great. I lived in a small apartment in Southie (Boston) with <a rel="noreferrer noopener" href="https://www.linkedin.com/in/vinh-quang-van-ha-b7023a10/" target="_blank">my college roommate “Q”</a>. I had a good job at a tech start-up called CloudLock. I hammered out code 12-14 hours a day. I worked so much I never knew what day it was and my bosses had to force me to go home. When I wasn’t working, I was playing <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Cornhole" target="_blank">bags (aka cornhole)</a> with my friends, lighting people up in Super Smash Bros Melee, or sleeping. Not a care in the world.&nbsp;</p>



<p>Then a freight train hit me.&nbsp;</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/train_V2.png.webp 1700w" sizes="(max-width: 1700px) 100vw, 1700px">
<img src="https://linearb.io/wp-content/uploads/2020/06/train_V2.png" alt="Getting promoted to dev team lead felt like getting hit my a freight train." srcset="https://linearb.io/wp-content/uploads/2020/06/train_V2.png 1700w, https://linearb.io/wp-content/uploads/2020/06/train_V2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/train_V2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/train_V2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/train_V2-1536x723.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px">
</picture>
</figure>



<p>My boss, our VP of Engineering <a href="https://www.linkedin.com/in/michael-zeldich-b788a8/" target="_blank" rel="noreferrer noopener">Michael Zeldich</a>, pulled me aside one day. He explained our team was growing fast and it was getting tough for him to have 15+ engineers reporting to him directly. We needed to put some team leads in place so we could scale our org and make sure everyone was getting enough attention.&nbsp;</p>



<p>Would I be interested?&nbsp;</p>



<figure><img src="https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-1024x482.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-1536x723.png 1536w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>&nbsp;Ok… I’m not going to lie. I was surprised. But it wasn’t the first time I thought about it.&nbsp;</p>



<p>CloudLock was my second job out of college. My first job was working for Nuance Communications. I got a taste of what it might be like to lead a team when my boss went on vacation for two weeks. He nominated me to be the engineering contact for tech support while he was out. In those two weeks, my network within the company expanded, I got on customer calls for the first time and I got to see what it was like being responsible for more than just my own code. It was pretty fun and I was good at it!&nbsp;</p>



<p>That experience was in my mind that day while Michael and I were talking. I wanted to say yes but I had a million questions.&nbsp;</p>



<p>I don’t remember his exact words, but he gist of what Michael said was “Don’t worry. You’re going to be great. I’ll help you and we’ll make it work together.”&nbsp;</p>



<p>Michael is a really good guy. I trusted and respected him. So that was all I needed to hear.&nbsp;</p>







<h3><strong>My first few months on the job&nbsp;</strong></h3>



<p>Looking back on it, in those first few months, I didn’t really understand the job.&nbsp;</p>



<p>I was going through the motions. Mimicking all of the things I had seen other dev team leads do.&nbsp;</p>



<p>Don’t get me wrong. I did some good. But I also had quite a few struggles.&nbsp;</p>



<p>For starters, every time there was a problem, I went into Superman mode. Single-handedly fixing it at the speed of light. After all, I was a great coder and had an expanding set of knowledge of the entire system. And I was good at helping other developers fix their problems. That is why I got promoted to team lead, right? (Kinda.)&nbsp;</p>



<p>Some of the team actually liked it at first. They acknowledged me for getting my hands dirty and being helpful and responsive.&nbsp;</p>



<p>But some of the team didn’t like it. It came across as controlling. And the ones who liked it initially stopped liking it because they were making the same mistakes over and over again and not getting better. Our weaker devs stayed weak and our stronger devs weren’t growing.</p>



<p>There were more mistakes. Like when I waited too long to fire a bad developer who’s negative behavior was hurting the team.&nbsp;</p>







<h2><strong>8 things they didn’t tell me&nbsp;</strong></h2>



<p>I believe being a leader is a never-ending journey. There’s always more to learn. Thankfully, I had great mentors who taught me a lot. And I also learned some lessons the hard way.&nbsp;</p>



<p>Here’s 8 things I wish I knew back then.</p>







<h3><strong>1. Many of your skills don’t translate.&nbsp;</strong></h3>



<p>The cruel irony is that there is a reverse connection between strong individual dev skills and dev team lead skills. The strongest devs will have more of an uphill battle starting out as managers.&nbsp;</p>



<p>75% of the issues we face as a dev team lead are not technical. The job is mostly about people and processes. Once I realized this, everything changed for me.&nbsp;</p>



<p>I could fix anything in the codebase. I was great at finding creative solutions to fix problems other devs were having. Not only are those skills not super relevant anymore, there are other traits of great devs that can actually hurt you as manager:&nbsp;</p>



<p><strong>Superman complex.</strong> If the team has a technical problem (bug, technical blocker), great devs often have the instinct to jump in and fix it right that second. In fact, when I did that as a dev, I received praise from my peers and leaders for being a great team player. As a manager when you do that, you’re the opposite of a team player.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png.webp 1700w" sizes="(max-width: 1700px) 100vw, 1700px">
<img src="https://linearb.io/wp-content/uploads/2020/06/superman2.png" alt="Dev team lead: Sometimes they suffer from superman complex" srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png 1700w, https://linearb.io/wp-content/uploads/2020/06/superman2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/superman2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/superman2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/superman2-1536x723.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px">
</picture>
</figure>







<p>Instead, we need to enable our people to solve the problem. Even if it takes longer the first time. Even if they make mistakes. Even if they don’t do it as well we would.&nbsp;</p>



<p>By helping your team figure it out, instead of doing it for them, you’ll get many benefits. Your people will see that you trust them. They’ll learn more. They’ll become more self-sufficient over time. And they’ll also learn to help each other which will bring the team closer together.&nbsp;</p>



<p><strong>Pro tip:</strong> Avoid judgment at all costs. When your people feel free to get out of their comfort zone and make mistakes without fear of criticism, you’ll see their true creativity come out and you’ll be amazed at what they’re capable of.&nbsp;</p>



<div><p><strong>Pro tip: </strong>You can scale yourself by educating your people on your thought process. Help them understand why your instincts kicked in about a problem. Explain the process you go through to diagnose the issue. Explain your mental model for identifying fix options. Explain how you would communicate everything to the rest of the team.</p><p><strong>Deep focus.</strong> Another skill that did not serve me well as a manager was deep focus. As a dev, you have to get in the zone. I was good at locking in and focusing all of my energy on a single problem. That will kill you as a dev team lead.&nbsp;</p></div>



<p>Great leaders embrace context switching. They move around. They talk to a lot of people. If you find yourself locked in on a technical problem for hours, that’s probably a sign that you need to delegate more.&nbsp;</p>



<p>When you do have the luxury of deep focus time, use it to think about strategic initiatives. Like how to propose your next big non-functional investment to your executive team or the profile of your next three dev hires.</p>







<h3><strong>2. Keep your instincts. Change your behavior.&nbsp;</strong></h3>



<p>Great devs have great instincts. Your intuition, which comes from your experiences, your expansive knowledge of the system, and your understanding of the end-to-end process, allows you to feel things even before you can even put your finger on exactly what it is. You sense when you went down the wrong path in your code. You sense when your team’s iteration is behind schedule.&nbsp;</p>



<p>Continue to hone these instincts. Just don’t act on them the same way you used to.&nbsp;</p>



<p>You need your spidey sense even more now to figure out when others need help:</p>



<ul><li>When you hear something in your daily stand-up that doesn’t sound right.&nbsp;</li><li>When someone can’t find the root cause of a production issue.&nbsp;</li><li>When you’re helping out on a code review.&nbsp;</li></ul>



<p>But if we aren’t jumping in like Spiderman to save the day, then what?&nbsp;</p>



<p>(Superman? Spiderman? Make up your mind, Dude! I know. Actually, Deadpool is my favorite superhero. What’s the best Deadpool quote about engineering leadership you ask? “House blowing up builds character.”)&nbsp;</p>



<figure><img src="https://linearb.io/wp-content/uploads/2020/06/DP-1-1024x595.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/06/DP-1-1024x595.png 1024w, https://linearb.io/wp-content/uploads/2020/06/DP-1-300x174.png 300w, https://linearb.io/wp-content/uploads/2020/06/DP-1-768x446.png 768w, https://linearb.io/wp-content/uploads/2020/06/DP-1-1536x893.png 1536w, https://linearb.io/wp-content/uploads/2020/06/DP-1.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>First, take a breath. I process things quickly but that can be a disadvantage as a manager. Keep listening and take extra time to process.</p>



<p>If you aren’t hearing enough info, ask questions. Gather as much information as possible before you offer any advice. Sometimes, just asking the right question helps your dev think about the issue in a new way and come up with a solution on their own.&nbsp;</p>



<p><strong>Pro tip: </strong>The stand-up is an especially useful time to listen for things that might be slightly off. If I was <a href="https://linearb.io/blog/my-team-goes-home-on-time-every-night/" target="_blank" rel="noreferrer noopener">worried someone was not on track</a>, these questions always helped me figure out if I needed to dig deeper:</p>



<ul><li>Has (fill in the dev or team who is dependent on this work) reviewed this?</li></ul>



<ul><li>What are you thinking for scalability testing?</li><li>Tell me about your feature roll-out plan?</li></ul>







<h3><strong>3. Communicate “why” more than “what” and “how”.&nbsp;</strong></h3>



<p>As developers, we’re used to dealing with what and how. As dev managers, those are still relevant but it’s more important for us to focus on why.&nbsp;</p>



<p>There’s four reasons for this:</p>



<p><strong>Customer alignment:</strong> Product managers are hopefully delivering stories that clearly explain the customer problem and use case. But it’s still easy for devs to get in the weeds. If you constantly remind your team to come back to the problem and user experience, you’ll deliver a higher quality product more often.&nbsp;</p>



<p><strong>Pro tip:</strong> Another question I Iike to ask when a dev is stuck: “Can you describe what your user is going to be doing before, during, and after using this feature?” If they can’t, they need more info.&nbsp;</p>



<p><strong>Pro tip: </strong>Encourage your devs to listen to customer support calls and sales prospects calls. In my experience, lots of teams say they are going to do this then they don’t. At LinearB we have a rule (voted on by the team) that every dev attends two customer calls minimum every month.&nbsp;</p>



<p><strong>Business alignment: </strong>A big part of being a dev leader is <a href="https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/" target="_blank" rel="noreferrer noopener">translating executives to engineers</a> and aligning your team’s work to business objectives. I believe there is a business decision behind every line of code. Is the ultimate goal to acquire more customers and generate revenue? Or are we trying to increase customer satisfaction and drive renewals? Are we making a strategic investment in non-functional work to save money and drive higher profit? The more your people understand the big picture impact of what they are working on, the more they’ll be able to think strategically and make better decisions about how to write their code.&nbsp;</p>



<p><strong>Mission and motivation:</strong> Most people want to feel part of something bigger. Sharing the why with your team helps connect them to the rest of the company. Also, regardless of what your company does, you have customers that rely on your product. Real people. Sharing “why” helps …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/">https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832046</guid>
            <pubDate>Tue, 14 Jul 2020 14:02:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I created a website to help 10 people find a job. Everyday]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23831983">thread link</a>) | @milanspeaks
<br/>
July 14, 2020 | https://www.jobroz.com/about | <a href="https://web.archive.org/web/*/https://www.jobroz.com/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div method="post" action="./about" id="form1">




        
        
        <div id="fullbodycontainer">
            
    <!-- Page Content -->
    <div>
        <div>
            <div>
                
                
                <p>
                    JobRoz curates job profile of interesting people looking for a job, every day. We are building a global community to help people find their dream job.



                </p>
                <p><a href="https://www.jobroz.com/signup">Join Now</a>
            </p></div>
            <p><img src="https://www.jobroz.com/Landing/cv.png">
            </p>

        </div>
    </div>

    <div>
        <div>
            <p>
                <h4>Our mission is to help 3000+ people find a job.
                </h4>
            </p>
            <div>
                <p>
                    <img src="https://www.jobroz.com/Landing/endorser1.png">
                </p>
                <h3>Job Seekers</h3>
            </div>
            <div>
                <p>
                    <img src="https://www.jobroz.com/Landing/recruiter.png">
                </p>
                <h3>Recruiters</h3>
            </div>
            <div>
                <p>
                    
                    <img src="https://www.jobroz.com/Landing/Endorser.png">
                </p>
                <h3>Endorsers</h3>
            </div>
        </div>
    </div>
    <div>
        <div>
            <div>
                
                <p>
                    We are building a community of job seekers, endorsers and recruiters. On JobRoz, job seekers can upload their information for public view and  endorsers helps job seekers to connect to a recruiter by sharing, upvoting and guiding them on their profile to land their dream job.
                </p>
            </div>
        </div>
    </div>
    <div>
        <div>
            <div>
                <h4>JOIN NOW. 
                </h4>
                <p>
                    <img src="https://www.jobroz.com/Landing/browser.png">
                </p>
            </div>
        </div>
    </div>
    <div id="joinnow">
        <div>
            <h3>Job Seekers </h3>
            <p>Looking for a job? Finding your dream job is difficult and takes a lot of time. Searching for a job is a lonely process &amp; so we thought why not let the collective power of internet help and guide you in your journey.</p>
            <p>Interested? register now. </p>
            
            
        </div>
        <div>
            <div>
                <h3>Endorsers </h3>
                
                <p>Looking to help by endorsing someone? Are you a founder, C-level executive, recruiter, consultant, careeer counsellor, trainer or anyone with the desire to help someone get a job? </p>
                <p>If yes, register now to help someone find a job! </p>
                
                
            </div>
        </div>
    </div>
    <div id="about">
        <div>
            <p>
                <h4>About Us
                </h4>
            </p>
            <div>
                <p>What does JobRoz mean?</p>
                <p>Roz is a Hindi &amp; Urdu word which means Daily. JobRoz is a portal which lists and curates Jobs &amp; People on a daily basis and so the name.</p>
                <p>What is JobRoz all about?</p>
                <p>On JobRoz, job seekers puts up their CV and profile online for people to view, upvote and share it. If the job seeker needs any help regarding learning something, people can volunteer to help too. We are putting a spotlight on a profile trying to help a person out to the maximum extend possible.</p>
                <p>What are the pricing plans?</p>
                <p>Nada. Nil. Zero. We do not charge any money from a job seeker and we never plan to charge a money from them in future too. If a job seeker gets a good offer and want to donate us, we will be glad to take a donation.</p>

            </div>
            <div>
                <p>Who can submit a profile?</p>
                <p>Almost anyone above legal working age. We are open to all kind of professionals but initally we would prefer IT related folks to submit their profile. Also we will keep a limit on submission of 50-100 profiles per day.</p>
                <p>What about my privacy?</p>
                <p>We will not reveal your email, phone and other contact details on the site. However, your photo and other details shall be displayed. This site is all about people who are open to share information about themselves to the world.</p>
                <p>As an endorser, what do I get?</p>
                <p>Good Karma. Moreover, we will have Karma points too.  </p>


            </div>

        </div>
    </div>

  

    


 
    <!-- Bootstrap core JavaScript -->
    

    <!-- Modal -->

    

    


    <!-- Global site tag (gtag.js) - Google Analytics -->
    
    
    
    
      


            
            

            

        </div>
    </div></div>]]>
            </description>
            <link>https://www.jobroz.com/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831983</guid>
            <pubDate>Tue, 14 Jul 2020 13:55:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Stories for WordPress]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831712">thread link</a>) | @durmonski
<br/>
July 14, 2020 | https://google.github.io/web-stories-wp/beta/ | <a href="https://web.archive.org/web/*/https://google.github.io/web-stories-wp/beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <header>
        
        
        <ul>
            <li><a href="#about">About</a></li>
            <li><a href="#get-started">Get Started</a></li>
            <li><a href="#faq">FAQ</a></li>
            <li><a href="https://github.com/google/web-stories-wp">GitHub</a></li>
            <li><a href="https://github.com/google/web-stories-wp/releases/download/v1.0.0-beta.1/web-stories.zip">Download Beta</a></li>
        </ul>
    </header>

    <section>
        <div>
            <h2>Stories Editor</h2>
            <h3><span>Get</span> <span>Ready</span> <span>to</span> <span>Tell</span> <span>Stories</span> <span>on</span> <span>WordPress</span></h3>
            <p>We're not quite ready for prime time yet, but if you like to live dangerously, we invite you to try our first public beta.</p>
            
        </div>
        
        
    </section>

    <section>
        <h2><a id="about">About</a></h2>
        <p>With Stories for WordPress, we're bringing first-class Web Stories support to WordPress.</p>
    </section>

    <amp-animation id="videoAnim" layout="nodisplay">
        
    </amp-animation>    
    <section>
        <amp-position-observer intersection-ratios="0.4" on="enter:videoAnim.start" layout="nodisplay" once="">
        </amp-position-observer>
        <p>WYSIWYG all the way</p>
        <amp-video width="1920" height="1200" layout="responsive" title="Stories for WordPress in action" src="./assets/wysiwyg.mp4" loop="" muted="" autoplay="">
    </amp-video></section>

    <amp-animation id="templateAnim" layout="nodisplay">
    
    </amp-animation>
    <section>
        <amp-position-observer intersection-ratios="0.5" on="enter:templateAnim.start" layout="nodisplay" once="">
        </amp-position-observer>
        <p>Expressive Templates</p>
        <ul>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/1.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/2.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/3.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/4.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/5.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/6.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/7.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/8.png"></amp-img></li>
        </ul>
    </section>

     <section>
        <h2><a id="get-started">Get Started</a></h2>
        <div>
            <p>Welcome</p>
            <h3>Tips to make the most of the Beta</h3>
            <p>Welcome! Starting on a new tool can be daunting, so we created a Web Story (naturally!) with some tips to help you get started. We can't wait to see your stories!</p>
            <p>Click <a href="https://google.github.io/web-stories-wp/beta/tips.html">here</a> or on the image to view.</p>
        </div>
        
     </section>

     <section>
        <h2><a id="faq">FAQ</a></h2>
        <dl>
            <dt>Where can I learn more about Web Stories?</dt>
            <dd><a href="https://amp.dev/about/stories/">Web Stories</a> are tappable, engaging visual stories brought to the web. They’re powered by AMP technology, so learn more about them on <a href="https://amp.dev/about/stories/">amp.dev</a>.</dd>
        
            <dt>How do I install the Stories for WordPress plugin?</dt>
            <dd>
                As soon as we’re graduating from beta, the plugin will be available on WordPress.org. While we’re in beta, the plugin has to be downloaded as zip. After that:

                <ol>
                    <li>Navigate to Plugins &gt; Add New.</li>
                    <li>Click the Upload Plugin button at the top of the screen.</li>
                    <li>Select the zip file from your local filesystem.</li>
                    <li>Click the Install Now button.</li>
                    <li>When installation is complete, you’ll see “Plugin installed successfully.” Click the Activate Plugin button at the bottom of the page.</li>
                </ol>
            </dd>
        
            <dt>I found a bug or missing feature! How do I report it?</dt>
            <dd>Awesome! That’s exactly what the beta is for. Please submit feedback and <a href="https://github.com/google/web-stories-wp/issues">file a bug or feature request on Github</a> for now - we'll follow up with an easier-to-use feedback form in the next days. Your help is greatly appreciated.</dd>

            <dt>When is the final version shipping, and what will be included?</dt>
            <dd>Later this summer. In addition to stabilization, performance fixes and bug fixes, the final version will also include animation and page attachment support.</dd>
        </dl>
     </section>

     



</div>]]>
            </description>
            <link>https://google.github.io/web-stories-wp/beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831712</guid>
            <pubDate>Tue, 14 Jul 2020 13:32:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Suggesting Chord Names with Glorious Voice Leader]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831693">thread link</a>) | @pcorey
<br/>
July 14, 2020 | http://www.petecorey.com/blog/2020/07/13/suggesting-chord-names-with-glorious-voice-leader/ | <a href="https://web.archive.org/web/*/http://www.petecorey.com/blog/2020/07/13/suggesting-chord-names-with-glorious-voice-leader/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <article>
        <p><a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a>, my chord-obsessed side project, now has the ability to turn a collection of notes played on the guitar fretboard into a list of possible chord names. Deciding on a specific chord name is still a very human, very context dependent task, but we can let the computer do a lot of the heavy lifting for us.</p>



<p>I’ve included a simplified version of this chord namer to the left. Feel free to click on the frets to enter any guitar chord you’d like the name of. <a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a> will crunch the numbers and come up with a list of possible names that exactly describes the chord you’ve entered, sorted alphabetically.</p>

<p>In the full-fledged <a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a> application, this functionality is accessible by simply clicking on the fretboard without first selecting the name of the chord you want. This felt like an intuitive design decision. You might know the shape of a specific chord you want to play in a progression, but you’re not sure of its name.</p>

<p>Enter it into the fretboard and <a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a> will give you a corresponding list of names. When you click on one of those names, it’ll automatically suggest alternative voicings that voice lead smoothly from the previous chord.</p>

<p>The actual code behind this feature is dead simple. We simply filter over our set of all possible chord roots and qualities, and compare the set of notes in each resulting chord with the set of notes entered by the user:</p>

<pre><code>
let possibleNames = _.chain(qualities)
  .flatMap(quality =&gt;
    _.map(Object.keys(roots), root =&gt; {
      return {
        root,
        quality
      };
    })
  )
  .filter(({ root, quality }) =&gt; {
    if (_.isEmpty(chord.notes)) {
      return false;
    }
    let chordNotes = _.chain(chord.notes)
      .map(([string, fret]) =&gt; (tuning[string] + fret) % 12)
      .uniq()
      .sortBy(_.identity)
      .value();
    let qualityNotes = _.chain(quality.quality)
      .map(note =&gt; (roots[root] + note) % 12)
      .sortBy(_.identity)
      .value();
    return _.isEqual(chordNotes, qualityNotes);
  })
  .map(({ root, quality }) =&gt; {
    return `${root}${quality.name}`;
  })
  .sortBy(_.identity)
  .value();
</code></pre>

<p>From there we simply present the list of possible chord names to the user in some meaningful or actionable way.</p>

<p>For future work, it would be nice to sort the list of name suggestions in order of the lowest notes they entered on the fretboard. For example, if they entered the notes <code>C</code>, <code>E</code>, <code>G</code>, and <code>B</code> in ascending order, we should sort the <code>Cmaj7</code> suggestion before the <code>Am9 no 1</code> suggestion. As with all of the items on my future work list, there are many subtitles and nuances here that would have to be addressed before it becomes a reality.</p>

<p>I hope you find this helpful. If you find <a href="http://gloriousvoiceleader.com/">Glorious Voice Leader</a> interesting or useful in any way, please let me know!</p>










    </article>
  </div></div>]]>
            </description>
            <link>http://www.petecorey.com/blog/2020/07/13/suggesting-chord-names-with-glorious-voice-leader/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831693</guid>
            <pubDate>Tue, 14 Jul 2020 13:30:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some of my GPT-2 experiments]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831477">thread link</a>) | @bemmu
<br/>
July 14, 2020 | http://viznut.fi/texts-en/gpt2-experiments.html | <a href="https://web.archive.org/web/*/http://viznut.fi/texts-en/gpt2-experiments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2>Some of my GPT-2 experiments</h2>

<p>Like many others, I have been experimenting with <a href="https://openai.com/">OpenAI</a>'s GPT-2 network that processes
natural-language text. This is a collection of some of the best responses I
have gotten from the various GPT-2 incarnations.</p>

<p>My fascination sparked when the 774M-parameter model was presented in a
<a href="https://www.youtube.com/watch?v=0OtZ8dUFxXA">Two Minute Papers
video</a> in October 2019. The earlier models had seemed to me like
glorified Markov chains, but this one seemed to be capable of far deeper
creativity – specificially, the creative combination of unrelated
concepts.</p>

<p>The examples come from the unmodified English-language 774M model unless
otherwise specified. I've also been retraining the 124M model to handle the
Finnish language, but that's a different story. Besides, <a href="https://www.reddit.com/user/FINGPT/">someone on Reddit</a> got much
better results than I.</p>

<p>I've been planning to reimplement the basic algorithm in order to make it
more suitable for my creative needs (including a better hands-on access to
the internal operation), but that's still on my TODO list.</p>

<p>The parts given in <b>bold</b> come from me, the rest come from the
network. Comments are given in <i>italic</i>.</p>

<h2>Plain prompting</h2>

<p><b>The main difference between Dwarven and Elven computers is</b> that
Dwarven computers use the term "hardware" and Elven computers use the term
"software."</p>

<p><b>Nettles are inhabited by intelligent creatures that control the
operations of the nettle from a kind of "main bridge". This "bridge" is</b>
predominantly green in color, with the seats and consoles having remarkably
spiky designs. This "main bridge" is the entrance to both the nettle "main
chamber" and their nettle "nettle core", and is where they are found most
often in the wild. A majority of the creatures in the nettle are in the form
of humanoid in appearance. The vast majority of the nettles have the head,
feet, and tail of an insectoid creature from an insectoid race, and the
limbs and arms of a humanoid (usually humanoid-like).</p>

<p><i>[1558M]</i> <b>Implementing an Elven mushroom rasterizer</b>
<br>
This chapter will cover implementing a "real" mushroom rasterizer. The
algorithm for the rasterizer can be found in the "Mushroom rasterizer
algorithm" chapter. The example program will be very simple; you should be
able to get a feeling for how to implement it. In particular, you can use
the Python example.
<br>
The basic idea is to take all pixels that are on a texture, and draw them as
mushrooms, in order to maximize the amount of pixels that are available for
rendering.
<br>
In the following, we describe the general idea, as well as how the
implementation works.
<br>
This is the simplest approach, where we just draw the image as is. However,
it may not be very efficient, if we are using a large rasterizer.
<br>
First of all, you will need some way of calculating the maximum amount of
mushrooms. This value is a simple integer which is used for all drawing,
including drawing pixels on the screen. For example, the maximum value for
the rasterizer we'll use will"</p>

<p><b>The laptop was decorated like a shaman drum</b>. The rim was red, the
inside bronze, and the base a spail of blue woolen offerings. The bag had a
quarts of silken hide, totems of life - all connected to a pot of spirulina.
The lid, on the other hand, was a tiny knife with a blade of carved wood
that cut a copy of the Unicronian shaman's hand sign. Mirok walked up to the
table. "Did you have something for me to drink?"</p>

<p><b>The ancient floppy disks carved in the First Dwarven Empire</b> were
purposefully crafted to last for a thousand years, recorded and always in
legible format. The same constraints apply to a computer in our world.</p>

<p><b>The ancient ROM cartridges crafted in the First Dwarven Empire</b>
must be returned to their original stock location at the Vaults of Thrall,
stored in Silithus' basement underground, and transported to The Nexus.</p>

<p><i>[1558M]</i> <b>The ancient ROM cartridges crafted in the First
Dwarven Empire</b> are extremely valuable, often found in the pockets of the
nobility. They are made from the purest of crystal, and are much harder than
the gold used in modern cartridges. However, they are still only half as
good as the golden ones used by the dwarves. The ROM cartridges are highly
prized because they are able to record sound or video over the radio and TV.
The gold ones, on the other hand, are often used by the commoners for their
personal enjoyment.</p>

<p><b>The computer demoscene of the Elven Empire</b> was effectively
destroyed by the Dark Elf wizard Ourgkh on the ongoing Khakaire Ilat Battle
in Rainbow Onslaught long after the computer demoscene in Quel'Thalas was
destroyed by Sauron's forces. However, some elves were still able to enter
their special computer mode, and some intelligences were encoded in computer
programs. The Alliance managed to enter this mode using the computer program
"Black Talon" and eventually defeated Melandru and his forces.[3] It was
possible to continue the reorganization of the Elf computers and create an
alliance of different races to investigate the true nature of the
Underking's Resurrecting Ritual.</p>

<p><b>Medieval Finnish starships had sauna-based warp engines.</b> The sauna
would be built into one of the hull plates, which are actually made out of
thin metal sheets. The sauna would have a large window where the starboard
side of the vessel would be located, and a set of heaters on the port side
to heat the water in the sauna.
<br>
The captain on duty would sit on the sauna platform and have a comfortable
chair. The sauna would be powered by the captain's crew who would be
sweating and doing the sweating, while sitting inside the heated sauna. The
heat would be turned by two steam engines, one on each side of the
vessel.</p>

<p><b>These floppy disks are ancient. I got them from an old Dwarven
computer warrior when I was a little kid.</b> He sold some floppy disks for
gold to a pirate crew that stole some things from him, so the pirate wanted
them back. They worked very well, and this old computer warrior started
developing them.
<br>
He got all of the design files and instructions from the dwarf computer
warrior. He sold them to an alchemist. When the alchemist showed them to me,
he told me that he had to get rid of the "old" floppy disks if he was going
to continue to develop them.
<br>
So many adventures started from a floppy disk. The floppy disks were the
source of many a treasure hunt.</p>

<p><b>The traditional board games of the Finnish people include</b> lokko,
hakkopi, kukkala, and kyttära, but not every one of these games involves a
game of chess. Instead, they are more like cards and are usually played
during the day in small groups.
<br>
Some lokko games have a history more than 100 years. The first game of lokko
was a game of chance called kaikku lokko (the board game of luck). This
means the game of fate was played with cards.</p>

<p><b>The core principle of Mythic Rationality is</b> that every proposition
that could possibly occur in your mind, is in fact true. This is a very
important idea– it's not what I'm saying that is wrong. It's what I'm saying
is absolutely true. I'm simply saying that every possible scenario is true,
for you. Because of this, I've written a book called The Reality of the Myth
of Self-Consciousness.</p>

<p><b>The most influental philosopher in pre-Christian Finland was</b> the
famous geologist Ästämäki Perö. He is sometimes described as a
"philosopher-warrior" or a "mythologist-soldier" who fought against "evil
paganism".</p>

<p><i>[1558M] </i><b>The first computer in Song-dynasty China was invented
by</b> a woman named Wan-chao (猪子) in the 12th century. However, her
system could not run because she did not have enough space for the entire
data, and thus it was only used for calculations. However, it is not clear
whether she was simply the first person in history to invent a computer, or
if it was her assistant who made the system possible.</p>

<p><b>The ancient Finns believed that computers were inhabited by
spirits</b> and deities called the gods. And the Finns were so in touch with
these spirits that they had developed the art of magic—a branch of
traditional magic that still plays a central role in Finnish culture.</p>

<p><i>[1558M] </i><b>Elves, dwarves and other intelligent non-human
species have been able to build spaceships of their own for a long time.</b>
These vessels, called "Dwarves of the Stars" by the dwarven population, are
large and sturdy. They're generally built of metal, but some dwarves build
their ships from wood, bone or even leather, as is the case with the ships
of the Ironforge dwarves.[1]</p>

<p><b>The electronic computer was invented in the Dwarven kingdom by</b>
Luthien the Tinker, who wanted to build robots. The dwarves developed the
computer in the fortress of Al-Rashid, and it could be used as a control for
all kinds of machines.
<br>
In the beginning, the computer was only operated by Dwarves. They created
many gadgets and devices. After many years of use, the dwarves were forced
to stop development of the computer and had to use it for more practical
purposes.</p>

<p><b>The electronic computer was invented in the Elven kingdom by</b> a
student of R'hllor. He had found it on a hill overlooking the city and had
started to use it to study his brother.
<br>
"This was my first real contact with magic," he said. "I had to spend two
months studying it and I've never forgotten it."
<br>
The old dwarf laughed. "You didn't."
<br>
R'hllor's power was very special, he thought softly. He took the small
device from the man and stroked the screen of his computer with a small
magic wand.
<br>
A very strange image suddenly appeared. A golden light appeared in the
middle of a large stone structure of many towers. A huge golden figure
loomed up through the sky— a great knight, almost twice the size of many of
the towers, standing just above the stone walls and staring down at the
great tower below him. He was smiling, just as the old dwarf had imagined.
"That must take hours to learn," the dwarf said.</p>

<p><b>Ancient Finnish flying machines were known to be superior to the
Indian Vimanas.</b> A German scientist, Carl Friedrich Wulf, was responsible
for discovering their remarkable success in World War I. He used them to
explore the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://viznut.fi/texts-en/gpt2-experiments.html">http://viznut.fi/texts-en/gpt2-experiments.html</a></em></p>]]>
            </description>
            <link>http://viznut.fi/texts-en/gpt2-experiments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831477</guid>
            <pubDate>Tue, 14 Jul 2020 13:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Receving GOES satellite signal with SDR]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831423">thread link</a>) | @Xeanort
<br/>
July 14, 2020 | https://lucasteske.dev/goes-satellite-hunt/ | <a href="https://web.archive.org/web/*/https://lucasteske.dev/goes-satellite-hunt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p><span>Written by</span>
    
        Lucas Teske
    

    
      <br>
      <span>on </span><time datetime="2017-02-19 00:00:00 -0300">
  19
  
  February
  2017
</time>
    
  </p>

  
  

  

<p>This book is adaptation of my blog post <a href="http://www.teske.net.br/lucas/2016/10/goes-satellite-hunt-part-1-antenna-system/">GOES Satellite Hunt</a> that was published in the end of 2016 while I was reverse engineering the satellite signal. I’m doing this book to have a more organized document about GOES-13 Signals and also to keep up to date with my GOES-16 Reverse Engineering that followed the GOES-13 Reverse Engineering. This book will also be hosted at GitHub in <a href="https://creativecommons.org/licenses/by-sa/2.5/br/">Create Commons Share Alike</a> license and any fixes are welcome from anyone. In the future I plan to add information about other satellites that use similar down link protocols like MSG-3 (Meteosat 10).</p>

<p>I also need to thank all people in #hearsat @ starchat (IRC) for the help I got understanding SDR and Satellite Signal stuff, since when I started that I had no knowledge at all about it. Special thanks for trango (<a href="https://twitter.com/usa_satcom">@usa-satcom</a>) and mybit (<a href="https://twitter.com/devnulling">@devnulling</a>) for all the help with previous experiences in the area. Also I need to thank all my family for supporting it putting several dishes and antennas all over the roof of our house.</p>

<p>The study in this book lead to the creation of <a href="https://github.com/opensatelliteproject">Open Satellite Project</a>.</p>

<p><a href="https://lucasteske.dev/goes-satellite-hunt/motivation">Next Part</a></p>



<ul>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/motivation">Motivation</a></li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup">The Hardware Setup</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/assemble-process">Assemble Process</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/dish-feed">Dish Feed</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/lna-and-filter">LNA and Filter</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/pointing-the-antenna">Pointing the Antenna</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator">The Demodulator</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/demodulator-in-gnu-radio">Binary Phase Shift Keying Modulation</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/demodulating-bpsk-signal">Demodulating BPSK Signal</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/gnu-radio-flow">GNU Radio Flow</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/decimating-and-filtering-to-desired-sample-rate">Decimating and filtering to desired sample rate</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/automatic-gain-control-and-root-raised-cosine-filter">Automatic Gain Control and Root Raised Cosine Filter</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/synchronization-and-clock-recovery">Synchronization and Clock Recovery</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/symbol-output-from-gnu-radio">Symbol Output from GNU Radio</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder">Frame Decoder</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/convolution-encoding-frame-synchronization-and-viterbi">Convolution Encoding, Frame Synchronization and Viterbi</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/encoding-the-sync-word">Encoding the sync word</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/frame-synchronization">Frame Synchronization</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/decoding-frame-data">Decoding Frame Data</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer">Packet Demuxer</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/de-randomization-of-the-data">De-randomization of the data</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/reed-solomon-error-correction">Reed Solomon Error Correction</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/virtual-channel-demuxer">Virtual Channel Demuxer</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/packet-demuxer">Packet Demuxer</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/saving-the-raw-packet">Saving the Raw Packet</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler">File Assembler</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/file-header-processing">File Header Processing</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/lritrice-compression">LritRice Compression</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/file-name-from-header">File Name from Header</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/viewing-the-files-content">Viewing the files content</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types">File Types</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description">LRIT Header Description</a>
        <ul>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/primary-header">0 - Primary Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/1-image-structure-header">1 - Image Structure Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/2-image-navigation-record">2 - Image Navigation Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/3-image-data-function-record">3 - Image Data Function Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/4-annotation-record">4 - Annotation Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/5-timestamp-record">5 - Timestamp Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/6-ancillary-text">6 - Ancillary Text</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/7-key-header">7 - Key Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/128-segment-identification-header">128 - Segment Identification Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/128-segment-identification-header">128 - Segment Identification Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/129-noaa-specific-header">129 - NOAA Specific Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/130-header-structured-record">130 - Header Structured Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/131-rice-compression-record">131 - Rice Compression Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/132-dcs-filename-record">132 - DCS Filename Record</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/ending">Ending</a></li>
</ul>


</div></div>]]>
            </description>
            <link>https://lucasteske.dev/goes-satellite-hunt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831423</guid>
            <pubDate>Tue, 14 Jul 2020 13:06:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL beginner guide – connecting, remote access, psql CLI and troubleshoot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831413">thread link</a>) | @lukasbar
<br/>
July 14, 2020 | https://knowledgepill.it/posts/postgresql_basics_guide/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql_basics_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<p>By default after instalation and creting database cluster PostgreSQL will listner only on localhost. No remote access will be allowed.</p>
<hr>
<p><a href="https://knowledgepill.it/posts/postgresql_installation/">PostgreSQL installation on Linux - with database creation</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 127.0.0.1:5432          0.0.0.0:*               LISTEN      1977/postmaster     
tcp6       <span>0</span>      <span>0</span> ::1:5432                :::*                    LISTEN      1977/postmaster     
</code></pre></div><p>To change listen address we have to configure parameter in <code>postgresql.conf</code></p>
<p>Check <code>PGDATA</code> - after <code>-D</code> parameter:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ ps aux | grep postgres
postgres  <span>1977</span>  0.0  2.5 <span>286388</span> <span>14864</span> ?        Ss   Jun28   0:02 /usr/pgsql-12/bin/postmaster -D /postgresql/data
postgres  <span>1979</span>  0.0  0.2 <span>140768</span>  <span>1360</span> ?        Ss   Jun28   0:00 postgres: logger   
postgres  <span>1981</span>  0.0  0.5 <span>286504</span>  <span>3028</span> ?        Ss   Jun28   0:00 postgres: checkpointer   
postgres  <span>1982</span>  0.0  0.2 <span>286388</span>  <span>1696</span> ?        Ss   Jun28   0:03 postgres: background writer   
postgres  <span>1983</span>  0.0  0.9 <span>286388</span>  <span>5676</span> ?        Ss   Jun28   0:03 postgres: walwriter   
postgres  <span>1984</span>  0.0  0.4 <span>286924</span>  <span>2688</span> ?        Ss   Jun28   0:02 postgres: autovacuum launcher  
</code></pre></div><p>Locate the file:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/
<span>[</span>postgres@postgres-lab data<span>]</span>$ ls -lah postgresql.conf
-rw-------. <span>1</span> postgres postgres 26K Jun <span>28</span> 21:44 postgresql.conf
</code></pre></div><p>Change in <code>postgresql.conf</code> parameter <code>listen_addresses</code> to your server IP or <code>*</code> to listen on all IP’s available on server:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ vi postgresql.conf

<span>#------------------------------------------------------------------------------</span>
<span># CONNECTIONS AND AUTHENTICATION</span>
<span>#------------------------------------------------------------------------------</span>

<span># - Connection Settings -</span>

listen_addresses <span>=</span> <span>'*'</span>          <span># what IP address(es) to listen on;</span>
                                        <span># comma-separated list of addresses;</span>
                                        <span># defaults to 'localhost'; use '*' for all</span>
</code></pre></div><p>Restart PostgreSQL to apply changes - you can do that with <code>systemctl</code> from <code>root</code> os user  service or with <code>pg_ctl -D PGDATA restart</code> from <code>postgres</code> os user:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># systemctl restart postgresql-12.service</span>
</code></pre></div><p>Check whre PostgreSQL is listening now:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 0.0.0.0:5432            0.0.0.0:*               LISTEN      30161/postmaster    
tcp6       <span>0</span>      <span>0</span> :::5432                 :::*                    LISTEN      30161/postmaster  
</code></pre></div>
<p>PostgreSQL instance has got restricted access by <code>pg_hba.conf</code> file(host based authentication file).</p>
<p>We can provide in it information from which <code>ADDRESS</code> to which <code>DATABASE</code> on which <code>USER</code> by what <code>METHOD</code> we allow connecting. Additionaly we have to provide <code>TYPE</code> of connection.</p>
<p>This file resides in same place where <code>postgresql.conf</code>(we can alter this behavior by setting <code>pg_hba</code> parameter in <code>postgresql.conf</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/

<span>[</span>postgres@postgres-lab data<span>]</span>$ vi pg_hba.conf
<span># TYPE  DATABASE        USER            ADDRESS                 METHOD</span>

<span># "local" is for Unix domain socket connections only</span>
local   all             all                                     trust
<span># IPv4 local connections:</span>
host    all             all             127.0.0.1/32            trust
<span># IPv6 local connections:</span>
host    all             all             ::1/128                 trust
</code></pre></div><p>Allowed <code>TYPE</code>'s:</p>
<ul>
<li><code>local</code> - socket connection - needed to connect from shell on database server</li>
<li><code>host</code> - standard TCP/IP connection over the network - bnost SSL and no SSL</li>
<li><code>hostssl</code> - TCP/IP connection but only with SSL</li>
<li><code>hostnossl</code> - TCP/IP only without SSL</li>
<li><code>hostgssenc</code> - TCP/IP only GSSAPI</li>
<li><code>hostnogssenc</code> - TCP/IP only without GSSAPI</li>
</ul>
<p>With <code>DATABASE</code> we can specify database name or use special value <code>sameuser</code> if database name should be same as name of user that is connecting.</p>
<p>With <code>USER</code> we can specify user or role - role name should be preceded by <code>+</code> sign.</p>
<p><code>ADDRESS</code> field could be - hostname, IP range in CIDR format or special words:</p>
<ul>
<li><code>samehost</code> - which correspond to all IP adresses of database server</li>
<li><code>samenet</code> - which correspond to all IP in database server subnet</li>
</ul>
<p>With <code>METHOD</code> field we can set one of authentication methods - most important ones are:</p>
<ul>
<li><code>trust</code> - allow connection without password - moslty set for local connections from database server itself</li>
<li><code>reject</code> - reject connections</li>
<li><code>md5</code> - allow connections after getting from user password - encrypted</li>
<li><code>password</code> - allow connection after getting plain password - DO NOT USE in untrusted networks - better -&gt; never use this option</li>
<li><code>ldap</code> - getting account authorization data from LDAP server</li>
</ul>
<p>In <code>DATABASE</code> and <code>USER</code> fields you can specify special word <code>all</code> if you don’t want to create any restrictions here.</p>
<p>There can be situation when we must use additional field named <code>auth-options</code> for specyfying details for example for <code>hostssl</code> connection type. This topic will be covered in another post.</p>
<h2 id="sample-pg_hba-record---allow-all-users-connect-to-any-db-from-all-ip-addresses---only-with-password">Sample pg_hba record - allow all users connect to any DB from all IP addresses - only with password</h2>
<p>Add in <code>pg_hba.conf</code>:</p>
<div><pre><code data-lang="bash"><span># Network access</span>
host    all             all             0.0.0.0/0               md5
</code></pre></div><p>Reload(online operation) PostgreSQL that it can use <code>pg_hba.conf</code> changes:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ /usr/pgsql-12/bin/pg_ctl -D /postgresql/data reload
server signaled
</code></pre></div>
<h2 id="local-from-server">Local from server</h2>
<p>It will work without password because we have <code>trust</code> in <code>pg_hba.conf</code> for <code>local</code> connections:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><h2 id="remote-machine">Remote machine</h2>
<p>Default URI syntax - you can connect like this:<br>
<code>psql postgresql://user:passwd@host:5432/dbame</code><br>
or by more common method:<br>
Connect to remote database from <code>psql</code> with connections details provided in parameters(it will ask for password because of <code>md5</code> method in <code>pg_hba.conf</code> for connections from <code>0.0.0.0/0</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ psql -h 10.128.0.2 -p <span>5432</span>
Password <span>for</span> user postgres:
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.

postgres<span>=</span>#
</code></pre></div><p>We can also use parameter <code>-U</code> to specify username different than OS username we currently are using.</p>
<p>Also all this parameters can be taken from shell variables which names are self descriptive - if we set all of them we can just use plain <code>psql</code> command to connect:</p>
<ul>
<li><code>PGHOST</code></li>
<li><code>PGPORT</code></li>
<li><code>PGDATABASE</code></li>
<li><code>PGUSER</code></li>
<li><code>PGPASSWORD</code></li>
</ul>
<h2 id="check-connected-database">Check connected database</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select current_database();</span>
 current_database
------------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-current-user">Check current user</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select current_user;</span>
 current_user
--------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-ip-and-port-used-for-connection">Check IP and port used for connection</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select inet_server_addr(), inet_server_port();</span>
 inet_server_addr | inet_server_port
------------------+------------------
 10.128.0.2       |             <span>5432</span>
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-postgresql-version">Check PostgreSQL version</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select version();</span>
                                                version                                                 
--------------------------------------------------------------------------------------------------------
 PostgreSQL 12.3 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 8.3.1 <span>20191121</span> <span>(</span>Red Hat 8.3.1-5<span>)</span>, 64-bit
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-connection-info">Check connection info</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># \conninfo</span>
You are connected to database <span>"postgres"</span> as user <span>"postgres"</span> on host <span>"10.128.0.2"</span> at port <span>"5432"</span>.
</code></pre></div>
<h2 id="execute-single-command-from-shell">Execute single command from shell</h2>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:09:19.854598+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="exacute-sql-script-from-shell">Exacute sql script from shell</h2>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -f create_user.sql
CREATE ROLE
CREATE ROLE
CREATE ROLE
</code></pre></div><h2 id="combine-single-command-with-sql-script-from-shell">Combine single command with sql script from shell</h2>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span> -f create_user.sql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:14:26.922453+00
<span>(</span><span>1</span> row<span>)</span>

CREATE ROLE
CREATE ROLE
CREATE ROLE
    current_time    
--------------------
 14:14:26.926545+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div>

<p>Do it yourself to see all available commands - output trimmed to important ones!</p>
<div><pre><code data-lang="bash">postgres<span>=</span><span># \?</span>
General
  <span>\c</span>opyright             show PostgreSQL usage and distribution terms
  <span>\c</span>rosstabview <span>[</span>COLUMNS<span>]</span> execute query and display results in crosstab
  <span>\e</span>rrverbose            show most recent error message at maximum verbosity
  <span>\g</span> <span>[</span>FILE<span>]</span> or ;         execute query <span>(</span>and send results to file or |pipe<span>)</span>
  <span>\g</span>desc                 describe result of query, without executing it
  <span>\g</span>exec                 execute query, <span>then</span> execute each value in its result
  <span>\g</span>set <span>[</span>PREFIX<span>]</span>         execute query and store results in psql variables
  <span>\g</span>x <span>[</span>FILE<span>]</span>             as <span>\g</span>, but forces expanded output mode
  <span>\q</span>                     quit psql
  <span>\w</span>atch <span>[</span>SEC<span>]</span>           execute query every SEC seconds

  Query Buffer
    <span>\e</span> <span>[</span>FILE<span>]</span> <span>[</span>LINE<span>]</span>       edit the query buffer <span>(</span>or file<span>)</span> with external editor
    <span>\e</span>f <span>[</span>FUNCNAME <span>[</span>LINE<span>]</span><span>]</span>  edit <span>function</span> definition with external editor
    <span>\e</span>v <span>[</span>VIEWNAME <span>[</span>LINE<span>]</span><span>]</span>  edit view definition with external editor
    <span>\p</span>                     show the contents of the query buffer
    <span>\r</span>                     reset <span>(</span>clear<span>)</span> the query buffer
    <span>\s</span> <span>[</span>FILE<span>]</span>              display history or save it to file
    <span>\w</span> FILE                write query buffer to file

</code></pre></div><h2 id="list-objects-in-psql">List objects in psql</h2>
<ul>
<li>\d[S+]          -       list tables, views, and sequences</li>
<li>\d[S+]  NAME     -      describe table, view, sequence, or index</li>
<li>\da[S]  [PATTERN] -     list aggregates</li>
<li>\dA[+]  [PATTERN]  -    list access methods</li>
<li>\db[+]  [PATTERN]   -   list tablespaces</li>
<li>\dc[S+] [PATTERN]    -  list conversions</li>
<li>\dC[+]  [PATTERN]     - list casts</li>
<li>\dd[S]  [PATTERN]     - show object descriptions not displayed elsewhere</li>
<li>\dD[S+] [PATTERN]     - list domains</li>
<li>\ddp    [PATTERN]     - list default privileges</li>
<li>\dE[S+] [PATTERN]     - list foreign tables</li>
<li>\det[+] [PATTERN]     - list foreign tables</li>
<li>\des[+] [PATTERN]     - list foreign servers</li>
<li>\deu[+] [PATTERN]     - list user mappings</li>
<li>\dew[+] [PATTERN]     - list foreign-data wrappers</li>
<li>\df[anptw][S+] [PATRN]- list [only …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql_basics_guide/">https://knowledgepill.it/posts/postgresql_basics_guide/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql_basics_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831413</guid>
            <pubDate>Tue, 14 Jul 2020 13:05:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Repetition, Automation, Organization, and Disconnection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831220">thread link</a>) | @nonoesp
<br/>
July 14, 2020 | https://sketch.nono.ma/repetition-automation-organization-disconnection | <a href="https://web.archive.org/web/*/https://sketch.nono.ma/repetition-automation-organization-disconnection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://nono.imgix.net/folio/images/veil.gif" data-src="https://nono.imgix.net/img/u/sketch-nono-ma-logo.svg"></p>
<hr>
<!-- <p class="u-font-size--g u-opacity--high u-text-align--center">
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p> -->
<p>
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p>

<p><span>One email per week. No spam ever.</span></p>

<p><img src="https://sketch.nono.ma/img/u/profile-nono-ma-sketch.jpg" alt="Pencil sketch of Nono Martínez Alonso.">
</p>
<p><strong>Hi. I'm Nono.</strong> I host <a href="https://gettingsimple.com/">Getting Simple</a>—a podcast about how you can live a meaningful, creative, simple life—<a href="https://sketch.nono.ma/">sketch</a> things that call my attention, and <a href="https://nono.ma/">write</a> about enjoying a slower life.</p>

      </div></div>]]>
            </description>
            <link>https://sketch.nono.ma/repetition-automation-organization-disconnection</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831220</guid>
            <pubDate>Tue, 14 Jul 2020 12:48:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using AWS Firecracker microVMs for IoT deployments at the Edge]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23831217">thread link</a>) | @amarti
<br/>
July 14, 2020 | https://opennebula.io/using-firecracker-clouds-at-the-edge-for-iot-deployments | <a href="https://web.archive.org/web/*/https://opennebula.io/using-firecracker-clouds-at-the-edge-for-iot-deployments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-25872">

    <!-- .entry-header -->

    <div>

		
<div><div id="kt-layout-id_4b706c-c7"><div>
<div><div>
<p>📺 Short of time? Jump to the <strong>Screencast</strong>:</p>



<figure><a href="#screencast"><img src="https://opennebula.io/wp-content/uploads/2020/07/IoT_Edge.jpg" alt=""></a></figure>
</div></div>



<div><div>
<p>The inception of the Internet of Things (IoT) technology has amplified the cloud computing paradigm by establishing the means to be able to distribute computing and processing activities away from the centralized cloud. With the broad explosion of smart devices and their compute processing capabilities, technologies and their supporting organizations are focused on <strong>reducing latency</strong> and providing computing/storing capabilities and analytic applications <strong>as close as possible to the devices</strong>.</p>



<p>This is critical to reducing latency and creating a much more “real-life” response time which is key to so many emerging technologies. Smart devices that are distributed across the globe cannot effectively depend on a <strong>centralized cloud</strong> to perform the cumulative analytical workload at the “speed of thought”.</p>
</div></div>
</div></div></div>



<p>A number of technologies have emerged in the last few year to provide a platform for edge nodes and devices to act on local data and to distribute analytical workloads and compute power across a broadly disseminated infrastructure, even with <strong>intermittent connectivity</strong> to a central cloud. Analytics and machine learning can effectively occur in close proximity to the devices that are generating the raw data, thus distributing workload and vastly reducing latency.</p>



<p>One key factor is that it’s not in the interest of many organizations, nor is it financially feasible for them, to host their own <strong>edge resources across the globe</strong>, with measured geographical distance from deployment areas, so that they can make sure that they are running their IoT solutions as close as possible to end-users.&nbsp;</p>



<p>OpenNebula’s <a href="https://oneedge.io/">ONEedge</a> solution will provide organizations with the necessary tools to create their own <strong>private distributed cloud</strong> in which they can easily deploy and manage edge nodes—on demand, and leased on usage—in geographical locations that are in close proximity to IoT devices and applications. When our client plans an IoT deployment in a new region, they will be able to use OneEdge to determine where they will need edge resources to best service the devices or applications, so that they can allocate on-demand, deploy and control edge nodes <strong>based on the current demand</strong> at those specific geographical locations.<a id="screencast"></a></p>



<p>Now, thanks to our recent integration of AWS’ <a href="https://opennebula.io/firecracker/" target="_blank" rel="noreferrer noopener">Firecracker</a> as a <strong>new virtualization technology</strong> officially supported by OpenNebula, organizations will be able to base the distributed infrastructure they require for their containerized IoT applications on <strong>fast and secure microVMs</strong> that can be quickly deployed on-demand on edge resources from public cloud and bare-metal providers.</p>



<p><a href="https://opennebula.io/firework/" target="_blank" rel="noreferrer noopener">OpenNebula 5.12</a> comes now with seamless integration with the <a href="https://hub.docker.com/" target="_blank" rel="noreferrer noopener">Docker Hub marketplace</a>, which makes it even easier to deploy IoT solutions at the edge using Firecracker microVMs for your <strong>containerized applications</strong>.</p>



<p>Watch the following screencast to learn how you can use OpenNebula to deploy an IoT solution based on <a href="https://thingsboard.io/" target="_blank" rel="noreferrer noopener">ThingsBoard</a>, an <strong>open source IoT platform</strong> for collecting, managing, storing and visualizing data coming from multiple IoT devices. In this use case, edge nodes have been easily provisioned by using <strong>resources from third-party bare-metal providers</strong>, with edge applications being configured and deployed as <strong>containers running within Firecracker microVMs</strong>:</p>



<figure><p>
<iframe title="OpenNebula - Deploy a Firecracker Edge Cloud for Containers" width="640" height="360" src="https://www.youtube.com/embed/JbNzwXz0xHc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>We have prepared a <strong>step-by-step guide</strong> based on our evaluation tool <strong>miniONE</strong> for everyone interested in reproducing this very same use case: just visit OpenNebula’s <a rel="noreferrer noopener" href="https://support.opennebula.pro/hc/en-us/articles/360045122532-How-to-Use-miniONE-to-Deploy-a-Firecracker-Edge-Cloud-for-Containers" target="_blank">Customer Portal</a>.</p>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/17d78d186d5a1a47d0a46f553bbe377f?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/17d78d186d5a1a47d0a46f553bbe377f?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Marco Mancini</span></p><p>Cloud Technical Evangelist at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/using-firecracker-clouds-at-the-edge-for-iot-deployments</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831217</guid>
            <pubDate>Tue, 14 Jul 2020 12:48:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manager Can’t Code? They Shouldn’t Be Your Manager]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23831151">thread link</a>) | @lanecwagner
<br/>
July 14, 2020 | https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Managers who can’t code are an outdated artifact of corporate America circa 2005. The best managers that I’ve had spend ~80% of their time coding, architecting, or doing technical work that requires engineering prowess. If your manager thinks coding is “beneath” them then they need a dose of humble pie. Your organization would likely be better off without them.</p>



<h2><span id="But_Managers_Manage_People">But Managers Manage <em>People</em>!</span>
</h2>



<p>There is a long-running stigma associated with developers, that we are all geeks who can’t handle interpersonal relationships. Due to our code monkey nature, we need “people people” who can go to meetings for us and communicate our efforts effectively to the higher-ups.</p>



<div><figure><img src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" alt="introverted programmers are an outdated meme" srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" data-src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>



<p>While the above is still funny, it’s <em>outdated</em>. As the developer community has grown exponentially in the last 20 years, so too has the personality diversity amongst its members. In other words, it is<strong> not hard to find developers with the soft-skills </strong>necessary for management positions.</p>



<h2><span id="Managers_Should_Help">Managers Should Help</span>
</h2>



<p>I am a firm believer in the following:</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" alt="" srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" data-src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><p>While the manager doesn’t need to be the most talented developer on the team, they must at least be technically literate. When a team member goes to their boss with a technical proposal, the manager should be able to give valuable feedback.</p>



<p>In this <a href="https://hbr.org/2016/12/if-your-boss-could-do-your-job-youre-more-likely-to-be-happy-at-work">study from Harvard</a> 35,000 employees from the US and Great Britain were polled about their job satisfaction, and metrics were gathered about what influenced their happiness at work. The results showed that the <em>single greatest influencing factor </em>on employee satisfaction was whether or not their boss was technically competent. I practice what I preach, so at the <a href="https://classroom.qvault.io/">Qvault app,</a> all engineering leadership will forever be responsible for pushing code.</p>



<p>Contrast the idea of a competent boss with the all-too-familiar experience of going to a <a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">non-technical middle-management type</a> with an engineering problem, only to be stuck in a teaching session because the boss has never heard of a pub-sub system.</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/9e3a6f35f44188bad76c100f3560ce69.gif" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><h2><span id="Managers_Need_Empathy">Managers Need Empathy</span>
</h2>



<p>A good manager has empathy for those who report to them. If the boss doesn’t code or hasn’t written code in a long time, they won’t understand the daily problems that their team is faced with. A good engineering leader will not only understand modern problems, but they make it their role to actively seek technical solutions in an ever-changing innovative landscape.</p>



<h2><span id="INB4_So_the_CEO_needs_to_be_able_to_code">INB4: “So the CEO needs to be able to code?”</span>
</h2>



<p>No, but the CTO does!</p>



<p>I am sympathetic to the idea that the CTO will have plenty of business and product-related work to focus on, but they can’t let their technical chops slip. In order to run the engineering arm of an innovative company, the person at the top should have a firm mental grasp on the implementation difficulties. If this just means reviewing architectural diagrams and reviewing pull-requests so be it, but nothing beats hands-on engineering work to stay sharp.</p>



<h2><span id="Feedback_Please">Feedback Please</span>
</h2>



<p>Have you had problems with non-technical leaders, or do you disagree completely with my opinions? Let me know through one of my <a href="https://qvault.io/contact/">social profiles</a>.</p>



<div><div>
<h2><span id="Thanks_For_Reading">Thanks For Reading</span>
</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>



<h2><span id="Related_Articles">Related Articles:</span>
</h2>



<ul><li><a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">Leave Scrum to Rugby, I Like Getting Stuff Done</a></li></ul>



		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831151</guid>
            <pubDate>Tue, 14 Jul 2020 12:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Futhark implements bounds checking on the GPU]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831009">thread link</a>) | @argh-man
<br/>
July 14, 2020 | https://futhark-lang.org/blog/2020-07-13-bounds-checking.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-07-13-bounds-checking.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on July 13, 2020
    
        by Troels Henriksen
    
</p>

<p>Futhark is supposed to be a safe programming language. This implies that risky operations, such as <code>a[i]</code> which indexes an array at some arbitrary index, should be protected with a dynamic check. While C programmers are famous for never making mistakes, and therefore C does not perform do such checking, the vast majority of programming languages do check array indexes, usually by generating code like this:</p>
<pre><code>if (i &lt; 0 || i &gt; n) {
  // throw exception

  // OR print error message

  // OR terminate program

  // OR do anything else
}</code></pre>
<p>This immediately changes the control flow of the program based on the bounds check. Usually the implementation challenge is not how to perform such checks in the first place, but how to eliminate them in cases where the compiler can statically determine that the check can never fail. However, for Futhark we would like to generate code for GPUs, and GPUs are great at turning solved problems unsolved.</p>
<p>In this post I will describe why it took Futhark <em>years</em> to get support for bounds-checking on the GPU, how we recently solved the problem, and what the performance is like. This post is a rewritten extract of a <a href="https://futhark-lang.org/publications/hlpp20.pdf">recently presented paper</a>, which you can read if you are particularly interested in the details of bounds checking.</p>
<h2 id="asynchronous-execution"><a href="#asynchronous-execution" id="asynchronous-execution-link" title="asynchronous-execution">Asynchronous execution</a></h2>
<p>The basic problem is that the GPU functions as a <em>co-processor</em> that receives data and code from the CPU, but which is then processed at the GPUs own pace. Explicit synchronisation and copying (both slow) is necessary to exchange information between the CPU and GPU.</p>
<p>GPU code is organised as <em>kernels</em> (no relation to operating systems, more like functions), and when we launch code on the GPU, we tell it to run a specific kernel with a specific number of threads, with some specific arguments. It’s a lot like performing an asynchronous remote procedure call. And similarly to a remote procedure, a kernel that contains an index that is out of bounds has no way of directly affecting the control flow of the CPU. In practice, our only option is to simply write a value to a distinguished memory location indicating that things have gone wrong, and then terminate the running GPU thread:</p>
<pre><code>if (i &lt; 0 || i &gt;= n) {
  *global_failure = 1;
  return;  // Terminate GPU thread
}</code></pre>
<p>On the CPU, whenever we launch a GPU kernel, we then <em>block</em> until the kernel is done running, copy back the <code>global_failure</code> value, and check whether a bounds error occurred:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-gpu-cpu-sync.png" alt="A diagram of checking for errors after every GPU kernel."></p>
<p>Surely reading a single number after every kernel (which usually processes tens of thousands of array elements) must be fast? Let’s check the overhead on the Futhark benchmark suite, measured on an RTX 2080 Ti GPU:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-overhead-sync.png" alt="Slowdown of synchronous bounds checking compared to no bounds checking."></p>
<p>The vertical axis shows the <em>slowdown</em> of synchronous bounds checking compared to not doing any bounds checking. The overhead is pretty bad: A <a href="https://en.wikipedia.org/wiki/Geometric_mean">geomean</a> of <em>1.66x</em> , and more than <em>6x</em> on the worst affected benchmarks. I’m only measuring those benchmarks that require bounds checking <em>at all</em>, so the mean overhead across all benchmarks would be lower. Still, this is too slow to be practical.</p>
<p>GPUs perform well when given a large queue of work to process at their own pace, not when they constantly stop to transfer 32 bits back to the CPU for inspection, and have to wait for a go-ahead before proceeding. To speed this up, we need to cut the amount of synchronisation.</p>
<p>Let’s take a step back and consider why we do bounds checking in the first place: we want to avoid corrupting memory by writing to invalid addresses, and we want to avoid making bad control flow decisions based on reading garbage. This implies that we have to do bounds checking <em>immediately</em> whenever we access an array. But since the GPU’s control flow is completely decoupled from what is happening on the CPU, the CPU doesn’t actually need to know immediately that something has gone wrong - it only needs to be informed when it eventually copies data from the GPU, so that it knows not to trust it. The actual <em>check</em> still needs to be done immediately on the GPU, but copying back <code>global_failure</code> to the CPU can wait until the CPU would in any case need to synchronise with the GPU:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-gpu-cpu-async.png" alt="A diagram of delaying error checking."></p>
<p>This amortises the copying overhead over potentially many kernel launches. But we’re still not quite done, as kernel <em>i+1</em> may contain unchecked operations that are safe if and only if the preceding kernel <em>i</em> completed successfully. To address this, we add a prelude to every GPU kernel body where each thread checks whether <code>global_failure</code> is set:</p>
<pre><code>// Prelude added to every GPU kernel
if (*global_failure) {
  return;
}</code></pre>
<p>If so, that must mean one of the preceding kernels has encountered a failure, and so the all threads of the current kernel terminate immediately. Checking <code>global_failure</code> on the GPU is much faster than checking it on the CPU, because it does not involve any synchronisation or copying. The overhead is a single easily cached global memory read for every thread, which is in most cases negligible. Asynchronous checking performs like this:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-overhead-async.png" alt="Slowdown of synchronous bounds checking compared to no bounds checking."></p>
<p>Much better! The mean overhead is down to <em>1.07x</em> (compared to <em>1.66x</em> before), and the maximum overhead is <em>1.4x</em> (<em>6x</em> before). The slowest program is now the <a href="https://github.com/diku-dk/futhark-benchmarks/blob/master/rodinia/srad/srad.fut">srad</a> benchmark, which is structured roughly as follows:</p>

<p>The <code>reduce</code> runs on the GPU but produces a scalar, which in Futhark’s compilation model is copied back to the CPU where a tiny amount of sequential computation takes place, after which it is used to update the <code>image</code> array in various ways. The fact that we copy a value (even just a single number!) back to the CPU forces us to do a full synchronisation and also check <code>global_failure</code>. This is because the compiler is conservative - it does not understand that <code>x</code> is not going to be used for any CPU-side control flow, but is instead going to be sent right back to the GPU. Since each instance of <code>reduce</code> and <code>map</code> run for extremely short periods (little more than a dozen microseconds each), the communication cost becomes significant. This was already a problem, but bounds checking makes it worse.</p>
<p>The solution to this is not directly related to bounds checking at all, but is about refining our compilation model such that individual scalars are more aggressively kept on the GPU, if we can determine that their value is not truly needed on the CPU. As a side effect, this will allow us to delay checking <code>global_failure</code> until the entire outermost sequential loop has run, which will make the overhead of bounds checking essentially zero. But this is future work.</p>
<h2 id="cross-thread-communication"><a href="#cross-thread-communication" id="cross-thread-communication-link" title="cross-thread-communication">Cross-thread communication</a></h2>
<p>So far, we have assumed that a GPU thread, upon encountering an error, can safely terminate itself, or even the entire kernel. Unfortunately, reality is not so forgiving. A GPU thread can terminate itself, sure, but this can induce deadlocks if the kernel contains <a href="https://en.wikipedia.org/wiki/Barrier_(computer_science)">barriers</a>, because other threads may be waiting for the now-terminated thread. Life would be easier if the prevailing GPU APIs (CUDA and OpenCL) provided a way for a single thread to unilaterally abort execution of the entire kernel, but they don’t. The solution to this is a little hairy, and involves the failing thread jumping ahead to the next barrier instead of simply terminating, then after each barrier checking whether any threads have failed. See <a href="https://futhark-lang.org/publications/hlpp20.pdf">the paper</a> for the full details. It’s a solution that relies heavily on all communication being under the control of the compiler, so it’s not something you could do for a low-level GPU language.</p>
<h2 id="optimisations"><a href="#optimisations" id="optimisations-link" title="optimisations">Optimisations</a></h2>
<p>All effective and elegant implementation techniques must inevitably be followed by a collection of ad-hoc micro-optimisations of dubious impact, and bounds checking in Futhark is no different. Some of the special cases we handle are as follows:</p>
<ol type="1">
<li>Certain particularly simple kernels are able to execute safely even when previous kernels have failed, typically because they merely copy or replicate memory. Matrix transposition is an example of such a kernel. For these kernels we can eliminate all failure checking entirely, because bounds failures cannot result in memory becoming <em>inaccessible</em>, it can only result in the values stored being <em>wrong</em>, and these simple kernels are not sensitive to the values they are copying.</li>
<li>Some kernels may contain no bounds checks. They still need to check whether any previous kernels have failed, but do not need to be careful with respect to barriers and such.</li>
<li>At run-time, whenever we enqueue a kernel, we have dynamic knowledge of whether any kernels with bounds checks have been enqueued since the last time <code>global_failure</code> was checked. That is, we know dynamically whether <code>global_failure</code> is <em>certainly unset</em>. If so, we can pass that information along to the kernel as a kernel argument, which means the kernel does not have to check the value of <code>global_failure</code> in its prelude.</li>
</ol>
<p>The impact of these optimisations (and others covered in the paper) is quite minor, as shown in the following graph.</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-overhead.png" alt="Slowdown of synchronous bounds checking compared to no bounds checking."></p>
<p>Most of the optimisations were motivated by micro-benchmarks, where the impact is more significant. On these benchmarks, they reduce the mean overhead to <em>1.04x</em> (from <em>1.07x</em>), and have no impact on the maximum overhead. Useful, but not crucial the way asynchronous checking is.</p>
<h2 id="error-messages"><a href="#error-messages" id="error-messages-link" title="error-messages">Error messages</a></h2>
<p>As discussed above, <code>global_failure</code> contains only a single bit of information: did the program fail or not? But the modern programmer is accustomed to luxuries such as being told <em>where</em> it failed, so clearly this will not do. The solution is simple. At compile time, we associate each bounds check with a unique number, a <em>failure code</em>, with a <code>global_failure</code> value of <em>-1</em> meaning <em>no error so far</em>. When a bounds check fails, the thread writes the failure code corresponding to the bounds check. At compile-time we also construct a table that maps each failure code to a <code>printf()</code>-style format string such as the following:</p>
<pre><code>"index %d out of bounds for array of size %d"</code></pre>
<p>For simplicity, <code>%d</code> is the only format specifier that can occur, but each distinct format string can contain a different number of format specifiers. We …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://futhark-lang.org/blog/2020-07-13-bounds-checking.html">https://futhark-lang.org/blog/2020-07-13-bounds-checking.html</a></em></p>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-07-13-bounds-checking.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831009</guid>
            <pubDate>Tue, 14 Jul 2020 12:24:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WTF Is a Closure?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23830998">thread link</a>) | @danabramov
<br/>
July 14, 2020 | https://whatthefuck.is/closure | <a href="https://web.archive.org/web/*/https://whatthefuck.is/closure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Closures are confusing because they are an “invisible” concept.</p>
<p>When you use an object, a variable, or a function, you do this intentionally. You think: “I’m gonna need a variable here,” and add it to your code.</p>
<p>Closures are different. By the time most people approach closures, they have already used them unknowingly many times — and it is likely that this is true for yourself, too. So learning closures is less about understanding a <em>new</em> concept and more about recognizing something you have <em>already been doing</em> for a while.</p>
<h3><a href="#tldr" id="tldr">tl;dr</a></h3><p>You have a closure when <strong>a function accesses variables defined outside of it</strong>.</p>
<p>For example, this code snippet contains a closure:</p>
<pre><code><p><span>let</span><span> users </span><span>=</span><span> </span><span>[</span><span>'Alice'</span><span>,</span><span> </span><span>'Dan'</span><span>,</span><span> </span><span>'Jessica'</span><span>]</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>'A'</span><span>;</span><span></span></p><p><span></span><span>let</span><span> user </span><span>=</span><span> users</span><span>.</span><span>filter</span><span>(</span><span>user</span><span> </span><span>=&gt;</span><span> user</span><span>.</span><span>startsWith</span><span>(</span><span>query</span><span>)</span><span>)</span><span>;</span></p></code></pre><p>Notice how <code>user =&gt; user.startsWith(query)</code> is itself a function. It uses the <code>query</code> variable. But the <code>query</code> variable is defined <em>outside</em> of that function. That’s a closure.</p>
<hr>
<p><strong>You can stop reading here, if you want.</strong> The rest of this article approaches closures in a different way. Instead of explaining what a closure is, it will walk you through the process of <em>discovering</em> closures — like the first programmers did in the 1960s.</p>
<hr>
<h3><a href="#step-1-functions-can-access-outside-variables" id="step-1-functions-can-access-outside-variables">Step 1: Functions Can Access Outside Variables</a></h3><p>To understand closures, we need to be somewhat familiar with variables and functions. In this example, we declare the <code>food</code> variable <em>inside</em> the <code>eat</code> function:</p>
<pre><code><p><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>eat</span><span>(</span><span>)</span><span>;</span><span> </span></p></code></pre><p>But what if we wanted to later change the <code>food</code> variable <em>outside</em> of the <code>eat</code> function? To do this, we can move the <code>food</code> variable itself out of our function into the top level:</p>
<pre><code><p><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span> </span><span></span></p><p><span></span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span></p></code></pre><p>This lets us change the <code>food</code> “from the outside” any time that we want to:</p>
<pre><code><p><span>eat</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>food </span><span>=</span><span> </span><span>'pizza'</span><span>;</span><span></span></p><p><span></span><span>eat</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>food </span><span>=</span><span> </span><span>'sushi'</span><span>;</span><span></span></p><p><span></span><span>eat</span><span>(</span><span>)</span><span>;</span><span> </span></p></code></pre><p>In other words, the <code>food</code> variable is no longer <em>local</em> to our <code>eat</code> function, but our <code>eat</code> function nevertheless has no trouble accessing it. <strong>Functions can access variables outside of them.</strong> Stop for a second and make sure that you have no problem with this idea. Once it has settled comfortably in your brain, move to the second step.</p>
<h3><a href="#step-2-wrapping-code-in-a-function-call" id="step-2-wrapping-code-in-a-function-call">Step 2: Wrapping Code in a Function Call</a></h3><p>Let’s say we have some code:</p>
<pre><code></code></pre><p>It doesn’t matter what that code does. But let’s say that <strong>we want to run it twice</strong>.</p>
<p>One way to do it would be to copy and paste it:</p>
<pre><code></code></pre><p>Another way to do it would be to use a loop:</p>
<pre><code><p><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> </span><span>2</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span></p></code></pre><p>The third way, which we’re particularly interested in today, is to wrap it in a function:</p>
<pre><code><p><span>function</span><span> </span><span>doTheThing</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>doTheThing</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>doTheThing</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Using a function gives us the ultimate flexibility because we can run this function any number of times, at any time — and from anywhere in our program.</p>
<p>In fact, <strong>we can even call our new function only <em>once</em></strong>, if we wanted to:</p>
<pre><code><p><span>function</span><span> </span><span>doTheThing</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>doTheThing</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Notice how the code above is equivalent to the original code snippet:</p>
<pre><code></code></pre><p>In other words, <strong>if we take some piece of code, “wrap” that code in a function, and then call that function exactly once, we haven’t changed what that code is doing</strong>. There are some exceptions to this rule which we will ignore, but generally saying this should make sense. Sit on this idea until your brain feels comfortable with it.</p>
<h3><a href="#step-3-discovering-closures" id="step-3-discovering-closures">Step 3: Discovering Closures</a></h3><p>We have traced our way through two different ideas:</p>
<ul>
<li><strong>Functions can access variables defined outside of them.</strong></li><li><strong>Wrapping code in a function and calling it once doesn’t change the result.</strong></li></ul>
<p>Now let’s see what happens if we combine them.</p>
<p>We’ll take our code example from the first step:</p>
<pre><code><p><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span></span></p><p><span></span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>eat</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Then we’ll wrap <em>this whole example</em> into a function, which we’re going to call once:</p>
<pre><code><p><span>function</span><span> </span><span>liveADay</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span></span></p><p><span>  </span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>eat</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>liveADay</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Read both snippets one more time and make sure that they are equivalent.</p>
<p>This code works! But look closer. Notice the <code>eat</code> function is <em>inside</em> the <code>liveADay</code> function. Is that even allowed? Can we really put a function inside another function?</p>
<p>There are languages in which a code structured this way is <em>not</em> valid. For example, this code is not valid in the C language (which doesn’t have closures). This means that in C, our second conclusion isn’t true — we can’t just take some arbitrary piece of code and wrap it in a function. But JavaScript doesn’t suffer from that limitation.</p>
<p>Take another good look at this code and notice where <code>food</code> is declared and used:</p>
<pre><code><p><span>function</span><span> </span><span>liveADay</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span> </span><span></span></p><p><span>  </span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>eat</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>liveADay</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Let’s go through this code together — step by step. First, we declare the <code>liveADay</code> function at the top level. We immediately call it. It has a <code>food</code> local variable. It also contains an <code>eat</code> function. Then it calls that <code>eat</code> function. Because <code>eat</code> is inside of <code>liveADay</code>, it “sees” all of its variables. This is why it can read the <code>food</code> variable.</p>
<p><strong>This is called a closure.</strong></p>
<p><strong>We say that there is a closure when a function (such as <code>eat</code>) reads or writes a variable (such as <code>food</code>) that is declared outside of it (such as in <code>liveADay</code>).</strong></p>
<p>Take some time to re-read this, and make sure you can trace this in the code.</p>
<p>Here is an example we’ve introduced in the tl;dr section:</p>
<pre><code><p><span>let</span><span> users </span><span>=</span><span> </span><span>[</span><span>'Alice'</span><span>,</span><span> </span><span>'Dan'</span><span>,</span><span> </span><span>'Jessica'</span><span>]</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>'A'</span><span>;</span><span></span></p><p><span></span><span>let</span><span> user </span><span>=</span><span> users</span><span>.</span><span>filter</span><span>(</span><span>user</span><span> </span><span>=&gt;</span><span> user</span><span>.</span><span>startsWith</span><span>(</span><span>query</span><span>)</span><span>)</span><span>;</span></p></code></pre><p>It may be easier to notice the closure if we rewrite it with a function expression:</p>
<pre><code><p><span>let</span><span> users </span><span>=</span><span> </span><span>[</span><span>'Alice'</span><span>,</span><span> </span><span>'Dan'</span><span>,</span><span> </span><span>'Jessica'</span><span>]</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>'A'</span><span>;</span><span></span></p><p><span></span><span>let</span><span> user </span><span>=</span><span> users</span><span>.</span><span>filter</span><span>(</span><span>function</span><span>(</span><span>user</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> user</span><span>.</span><span>startsWith</span><span>(</span><span>query</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span></p></code></pre><p>Whenever a function accesses a variable that is declared outside of it, we say it is a closure. The term itself is used a bit loosely. Some people will refer to the <em>nested function itself</em> as “the closure” in this example. Others might refer to the <em>technique</em> of accessing the outside variables as the closure. Practically, it doesn’t matter.</p>
<h3><a href="#a-ghost-of-a-function-call" id="a-ghost-of-a-function-call">A Ghost of a Function Call</a></h3><p>Closures might seem deceptively simple now. This doesn’t mean they’re without their own pitfalls. The fact that a function may read and write variables outside has rather deep consequences if you really think about it. For example, this means that these variables will “survive” for as long as the nested function may be called:</p>
<pre><code><p><span>function</span><span> </span><span>liveADay</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> food </span><span>=</span><span> </span><span>'cheese'</span><span>;</span><span></span></p><p><span>  </span><span>function</span><span> </span><span>eat</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>food </span><span>+</span><span> </span><span>' is good'</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>setTimeout</span><span>(</span><span>eat</span><span>,</span><span> </span><span>5000</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>liveADay</span><span>(</span><span>)</span><span>;</span></p></code></pre><p>Here, <code>food</code> is a local variable inside the <code>liveADay()</code> function call. It’s tempting to think it “disappears” after we exit <code>liveADay</code>, and it won’t come back to haunt us.</p>
<p>However, inside of <code>liveADay</code> we tell the browser to call <code>eat</code> in five seconds. And <code>eat</code> reads the <code>food</code> variable. <strong>So the JavaScript engine needs to keep the <code>food</code> variable from that particular <code>liveADay()</code> call available until <code>eat</code> has been called.</strong></p>
<p>In that sense, we can think of closures as of “ghosts” or “memories” of the past function calls. Even though our <code>liveADay()</code> function call has long finished, its variables must continue to exist for as long as the nested <code>eat</code> function may still be called. Luckily, JavaScript does that for us, so we don’t need to think about it.</p>
<h3><a href="#why-closures" id="why-closures">Why “Closures”?</a></h3><p>Finally, you might be wondering why closures are called that way. The reason is mostly historical. A person familiar with the computer science jargon might say that an expression like <code>user =&gt; user.startsWith(query)</code> has an “open binding”. In other words, it is clear from it what the <code>user</code> is (a parameter), but it is not clear what <code>query</code> is in isolation. When we say “actually, <code>query</code> refers to the variable declared outside”, we are “closing” that open binding. In other words, we get a <em>closure</em>.</p>
<p>Not all languages implement closures. For example, in some languages like C, it is not allowed to nest functions at all. As a result, a function may only access its own local variables or global variables, but there is never a situation in which it can access a parent function’s local variables. Naturally, that limitation is painful.</p>
<p>There are also languages like Rust which implement closures, but have a separate syntax for closures and regular functions. So if you want to read a variable from outside a function, you would have to opt into that in Rust. This is because under the hood, closures may require the engine to keep the outer variables (called “the environment”) around even after the function call. This overhead is acceptable in JavaScript, but it can be a performance concern for the very low-level languages.</p>
<p>And with that, I hope you can get a closure on the concept of closures!</p>
<blockquote>
<p>If you prefer a more visual approach to the JavaScript fundamentals, check out <a href="https://justjavascript.com/" target="_blank" rel="noopener noreferrer">Just JavaScript</a>. It is my illustrated course in collaboration with <a href="https://maggieappleton.com/" target="_blank" rel="noopener noreferrer">Maggie Appleton</a>.</p>
</blockquote>
</article></div>]]>
            </description>
            <link>https://whatthefuck.is/closure</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830998</guid>
            <pubDate>Tue, 14 Jul 2020 12:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I'm building a personal notes app focused on Data Longevity (beta)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23830995">thread link</a>) | @ricg
<br/>
July 14, 2020 | http://kitestack.com/lnotes/ | <a href="https://web.archive.org/web/*/http://kitestack.com/lnotes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<nav>
    <a href="http://kitestack.com/">
        <img src="http://kitestack.com/assets_v8/img/images/textblocks/small-logo.png">
        Kitestack
    </a>
    
    
</nav>

<section>
    <div>
        <p><img src="http://kitestack.com/assets_v8/img/images/lnotes/lnotes_512.png" width="256" height="256"></p>
        <h2>A new notes app for Mac<br>built around simple files and folders.</h2>
        
		
	
		<div>
	        <p>New in version 0.3.5:</p>
			<div>
				<ul>
					<li>Full text search via the location bar</li>
				</ul>
			</div>
	    </div>
    </div>
</section>

<section>
    

    
</section>

<section>
    <div>
		<p><a href="http://kitestack.com/assets_v8/img/images/lnotes/Main-Book-Research.png"><img src="http://kitestack.com/assets_v8/img/images/lnotes/Main-Book-Research.png"></a></p>
    </div>

</section>

<section>
    <div>
        
        <p>
        	Each note is a file, every folder, well, a folder on your Mac. All show up in Finder. Other files and documents are shown with a preview and the option to be opened with their default app.
        </p>
		<p><img src="http://kitestack.com/assets_v8/img/images/lnotes/Attach-to-PDF.gif"></p>
    </div>

</section>

<section>
    <div>
        
		<div>
            <div>
				
				<p>
		        	Rearrange your thoughts as you see fit. You can add notes as sub-notes to other notes, folders, and even files.
		        </p>
            </div>
            
            <p><img src="http://kitestack.com/assets_v8/img/images/lnotes/outline.png">
            </p>
        </div>

    </div>
</section>

<section>
    <div>
        
        <p>
			You can add links to other notes and files. When renaming a note, all related notes are updated automatically. Each note that is mentioned in another note includes a list of backlinks at the end to navigate both ways.
        </p>
		<p><img src="http://kitestack.com/assets_v8/img/images/lnotes/linkupdate.gif"></p>
    </div>
</section>

<section>
    <div>
        
        <p>
			Note file names are prefixed with the current date in YYYY-MM-DD format; very handy for sorting in Finder. For linking between notes, there's no need to reference notes by an abstract ID, because the app takes care of keeping links up-to-date when renaming or moving notes.
        </p>
    </div>
</section>
 
<section>
    <div>
        
        <p>
			Type "[]" to start a new to do list. You can mix and match numbered, bulleted, and to-do lists. A summary of open to-dos is shown in the bottom right of each note.
        </p>
    </div>
</section>

<section>
    <div>
        
        
        <p>
          	Imagine one morning you wake up and realize that the software update that installed itself automatically last night now crashes your notes app. The backup copy that you keep online is gone, because the company behind the service was acquired, pivoted on its heels and is now onto bigger things, and not even that old copy that you emailed to yourself is within reach, because, well, you are offline. 
</p>
<p>
			The best protection against getting locked out from an app and your data is to not rely on any particular app in the first place. Using a data format that is compatible across many apps, ideally simple enough so that even in 20 years from now there will still be apps around that will be able to open it.</p>

<p>
			The most basic form of keeping notes in an accessible form has to be plain text files. Many people favor Markdown over plain text, because it supports text formatting and referencing images. The app uses HTML as its data format. The advantage here is that this allows embedding images inside notes and note contents can be previewed in their formatted form in any browser (and copied to other word processing apps from there, if needed).
        </p>
        </div>
    
</section>



<section>
    
</section>







</div>]]>
            </description>
            <link>http://kitestack.com/lnotes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830995</guid>
            <pubDate>Tue, 14 Jul 2020 12:21:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chopper Commando Revisited]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23830881">thread link</a>) | @loadzero
<br/>
July 14, 2020 | https://blog.loadzero.com/blog/chopper258/ | <a href="https://web.archive.org/web/*/https://blog.loadzero.com/blog/chopper258/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p><i>This article contains pixel art. For best results please use 100% browser zoom.</i></p>

<p><a href="https://github.com/loadzero/chopper258">chopper258</a> is a port of <a href="https://www.mobygames.com/game/chopper-commando">Chopper Commando</a>, a DOS game written by <a href="https://www.mobygames.com/developer/sheet/view/developerId,59219/">Mark Currie</a> using Turbo Pascal in 1990.</p>

<p>Some thirty years later, in 2020, I've dusted off the old code and breathed some new life into it. I've ported it to C and made it work with SDL2, and it can now run natively in modern environments.</p>

<p>The canvas below shows a minute or so of gameplay from the new version.</p>




<p>The game can also be played on the web, thanks to emscripten.</p>

<p>Let's do a quick check to see if you can play.</p>

<span>
    <p>Yes, you can play the game by <span>clicking</span> on the button below.</p>

    
    
</span>

<span>
    <p>Unfortunately, your browser looks to be incompatible. The game currently only works in Desktop Chrome, due to the use of certain low level features.</p>
</span>



<p>Thanks to Mark Currie for granting me permission to publish this translation of his game.

</p><p>In addition to publishing the <a href="https://github.com/loadzero/chopper258">source code</a>, and
<span><a href="https://blog.loadzero.com/demo/chopper258">playable version</a>,</span>
<span>playable version,</span> I am also writing a series of articles to accompany the
project, the first part of which is included below.</p>

<p>I have also made some animations and interactive parts that you can <span>play</span> around
with, such as the <a href="#picker_link">palette picker</a> later on in this piece.</p>



<h2>Background</h2>

<p>I chose to revisit Chopper Commando for a few reasons.

</p><p>One of the biggest ones is nostalgia. I remember enjoying playing this game
as a child, on my PC and with others, and being surprised at some of the novel
mechanics. I also remember having a good laugh.

</p><p>This is the first game I played where you could leave a
vehicle, run around and do things on foot, and then get back in and keep going.
I thought that was so cool, and it was an early precursor to the sandbox games I
enjoy today.

</p><p>I have a soft spot for bedroom coded efforts like this, where the heart and
soul of the game isn't obscured by many layers of polish. It's not too hard to
imagine a 15-year old Mark Currie writing a game for himself on his 286, and
getting a real kick out of doing so.

</p><p>Games like this were pretty formative for me as a young aspiring games
programmer. Unlike something like Super Mario, which seemed unreachable to me at the time, I could play this and start working out how to make something similar, even with the simple tools I had.

</p><h2>Project Scale</h2>

<p>This was a bit smaller and more straightforward than my previous effort,
<a href="http://blog.loadzero.com/blog/si78c/">Space Invaders In C</a>. This project
took around 3 months of calendar time, and about 200 hours were spent on it in total.

</p><p>As the source code to the game was available, albeit in Pascal, not much
reverse engineering was required. Most of the effort went into the translation
to C, and building new code to provide workalikes for the Turbo Pascal API.

</p><p>One of the last parts I worked on, the sound, also turned out to be one of
the most difficult. The original game used PC speaker sound in a dynamic way,
and I had to write a synthesizer for it. It was quite fiddly to get the timing
right and make it sound like the original. More on that in part two.

</p><p>The original code is around 5500 lines of Pascal, all of it game logic code.
The new C version is around 5500 lines of game logic, 1500 lines of support
code and 400 lines of comments.

</p><p>Compared to the last project, there isn't too much behind the scenes
unpublished code in this one. I wrote a few small pieces to aid translation,
some scripts to build the font data, and some prototypes to help figure out the
sound code.

</p><p>I did end up writing a little bit of pascal code, mostly as temporary mods to the
original game source to help me figure out what the original system was doing. More
detail on compiling the old code is provided in a later piece.

</p><h2>Graphics</h2>

<p>One of the very first things I did on the project was to figure out the framebuffer format
for the original game, and start hacking to get it to display on a modern system.

</p><p>The frame buffer is CGA, meaning it is 320 pixels wide, 200 lines high and has
2 bit paletted color, for a grand total of four possible colors on screen at
any one time.

</p><p>Below is a selection of screen shots from the game in all their CGA glory.</p>



<p>If you look carefully, even though each screen can only show four colors, 
you can see that there are more than four colors in total. This is due to
palettes. In the CGA scheme, four base color palettes are available and each has a
different arrangement of sixteen possible colors.

</p><p>As an extra tweak, the first color in the palette (typically the background color), can be
freely chosen out of the sixteen, giving slightly more flexibility. This means that there
are sixteen variations of each of the four base palettes, giving sixty four palettes in total.

<a id="picker_link"></a>

</p><p>To play with the color combinations, <span>click</span> on the colored areas in the first panel below.
You can pick a palette and background color, and the effect will be shown in the second panel,
using one of the screenshots. Use prev and next to cycle to a different screenshot.

</p>


<p>In the old system, the framebuffer and the palette settings are bits of memory
that live on the graphics card and are twiddled by the game directly. In the
new system, these reside in host memory, and must be converted into a modern texture format
on the fly every frame for the GPU to use.

</p><p>Given that there are only 64 possible palettes, a neat trick can be used to
simplify and speed up the framebuffer conversion. Before the game starts
running, every possible combination of palette, background color and input
framebuffer byte (4 pixels at 2bpp) are iterated through, and the resulting 8
output bytes (4 pixels at 16bpp) are stored in a 16 * 4 * 256 entry lookup
table. Converting the framebuffer each frame is then just a matter of iterating
through each byte and performing a simple lookup and memcpy to stamp out four
pixels at a time.

</p><h2>To be continued...</h2>

<p>As mentioned earlier, the sound code was one of the hardest parts of the port. Part two
explains why that was so, and the solution I used to solve it.</p>

<p>The canvas below shows a little preview.</p>












</article></div>]]>
            </description>
            <link>https://blog.loadzero.com/blog/chopper258/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830881</guid>
            <pubDate>Tue, 14 Jul 2020 12:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I'm Switching to Apple]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830840">thread link</a>) | @caspii
<br/>
July 14, 2020 | https://casparwre.de/blog/why-i-am-switching-to-apple/ | <a href="https://web.archive.org/web/*/https://casparwre.de/blog/why-i-am-switching-to-apple/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Because the hardware is great and the software is not made by a gigantic and opaque ad-tech company (Google).</p>

<p>That’s all. Bye 👋</p>

  </div></div>]]>
            </description>
            <link>https://casparwre.de/blog/why-i-am-switching-to-apple/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830840</guid>
            <pubDate>Tue, 14 Jul 2020 12:01:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Color barcode becomes ISO standard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830777">thread link</a>) | @FraunhoferSIT
<br/>
July 14, 2020 | https://www.sit.fraunhofer.de/en/news-events/latest/press-releases/details/news-article/show/bunter-barcode-wird-iso-standard/ | <a href="https://web.archive.org/web/*/https://www.sit.fraunhofer.de/en/news-events/latest/press-releases/details/news-article/show/bunter-barcode-wird-iso-standard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="c6662"><h2> Fraunhofer brings JAB-Code into standardization: globally uniform rules for data exchange and practical use</h2>
<p> <b>JAB-Code, the color barcode of the Fraunhofer Institute for Secure Information Technology SIT, is on the way to becoming an international ISO standard. JAB-Code – Just Another Barcode – is to be brought to a full ISO standard by 2022. The globally uniform rules for data formats and their use in practice provide both device manufacturers and user companies with planning security for innovative developments – an important prerequisite for the successful dissemination of JAB-Code in industry. The advantage of the color code compared to the common black and white barcodes is that it can store much more data in the same space. Besides securing job certificates, training certificates and last wills, JAB-Code can also provide proof of authenticity for products. JAB-Code is not subject to licensing. It is open source and ready to be put into practice. To test the color barcode, go to <a href="https://www.sit.fraunhofer.de/typo3/www.jabcode.org" title="Externen Link in neuem Fenster öffnen" target="_blank" rel="noopener">www.jabcode.<span>or<svg viewBox="0 0 125 118"><path fill="none" stroke="#000" stroke-width="7" stroke-miterlimit="10" d="M59.2 27.6L24.6 27.6 24.6 100 97 100 97 67.8"></path><path d="M66.6 14H104.39999999999999V22.4H66.6z"></path><path transform="rotate(90 100.159 32.354)" d="M81.8 28.2H118.5V36.6H81.8z"></path><path transform="rotate(134.999 78.516 39.71)" d="M51.2 35.2H105.9V44.300000000000004H51.2z"></path></svg></span></a>g.&nbsp;</b></p>
<p>Black and white barcodes can be found everywhere in everyday life: on packaging, parcel shipping labels, on the backs of books and more. However, these barcodes contain only a small amount of data, it is therefore often necessary to include links to websites that contain more information, for example about a product. Fraunhofer SIT's JAB-Code uses color as a third dimension and can therefore store more information in the same space. The color code does not have to use database references and links, it simply stores the information itself. JAB-Code uses the colors cyan, yellow, magenta, black and mixtures of these. With up to eight colors, the barcode is as robust as its black and white counterparts are. With JAB-Code being able to take on many varying shapes, not just the square form, it greatly extends the design possibilities. </p>
<h2>How the color code works</h2>
<p>Fraunhofer SIT's experts developed the code with a high data density so that documents can be identified as genuine, even when offline. JAB-Code makes the authenticity of documents verifiable, thereby increasing the protection against counterfeits. The content of a document is signed and encrypted digitally so that later alterations will not go unnoticed. The signed content and the signature are mapped into JAB-Code. JAB-Code is then printed onto the corresponding document using a standard color printer. Every authorized person can now scan JAB-Code with a smartphone and verify the authenticity of the document: First, the smartphone reads and verifies the digital signature. If this is successful, the document content is displayed on the tester's smartphone so that the paper can be compared to the content displayed. If differences show up, the paper in question has been forged. </p>
<h3>Application examples for JAB-Code</h3>
<p>This is always useful when, for example, documents are exchanged between public authorities and end-users or businesses, but when no common database exists for verification purposes, e.g. for data protection reasons. During the lockdown due to the Corona crisis, companies in border regions issued their employees with a pass to prove that this person worked for the company and had to cross the border on a regular basis. This permit is merely a paper with a company stamp, and officials at the border cannot easily check the authenticity of the document. Besides simplifying verification, digital signatures and JAB-Codes will also make documents forgery-proof and data protection compliant. </p>
<p>Another example are medical prescriptions. They can be forged in order to obtain expensive medication, with double submissions being a problem as well. JAB-Code could prevent this, because the color code stores all the important information directly on the prescription. When issuing the prescription, the doctor extracts certain unique properties from the prescription paper, such as structures or fibers, which are kind of like a fingerprint of the paper. This can be done with commercially available cameras, for example a smartphone, within seconds. Using this paper fingerprint and the contents of the prescription, i.e. which medicines have been prescribed, the doctor signs the prescription digitally. From the signed data, a JAB-Code is created together with the doctor's digital signature and printed on the prescription. At the pharmacy, the pharmacist first checks the digital signature by scanning it using a smartphone. Once the signature has been verified and the paper properties in JAB-Code and the prescription match, the pharmacist knows that the prescription is the original.   </p>
<p>JAB-Code was developed on behalf of the Federal Office for Information Security (BSI). The color code is on its way to ISO 23634 (more information at <a href="https://www.iso.org/standard/76478.html" title="Externen Link in neuem Fenster öffnen" target="_blank" rel="noopener">https://www.iso.org/standard/76478.<span>html<svg viewBox="0 0 125 118"><path fill="none" stroke="#000" stroke-width="7" stroke-miterlimit="10" d="M59.2 27.6L24.6 27.6 24.6 100 97 100 97 67.8"></path><path d="M66.6 14H104.39999999999999V22.4H66.6z"></path><path transform="rotate(90 100.159 32.354)" d="M81.8 28.2H118.5V36.6H81.8z"></path><path transform="rotate(134.999 78.516 39.71)" d="M51.2 35.2H105.9V44.300000000000004H51.2z"></path></svg></span></a>) and is expected to be available as a standard at the beginning of next year. The source code is open source on GitHub under the license LGPL v2.1 (free use for all purposes under mention of Fraunhofer SIT as developer): <a href="https://github.com/jabcode/jabcode" title="Externen Link in neuem Fenster öffnen" target="_blank" rel="noopener">https://github.com/jabcode/<span>jabcode<svg viewBox="0 0 125 118"><path fill="none" stroke="#000" stroke-width="7" stroke-miterlimit="10" d="M59.2 27.6L24.6 27.6 24.6 100 97 100 97 67.8"></path><path d="M66.6 14H104.39999999999999V22.4H66.6z"></path><path transform="rotate(90 100.159 32.354)" d="M81.8 28.2H118.5V36.6H81.8z"></path><path transform="rotate(134.999 78.516 39.71)" d="M51.2 35.2H105.9V44.300000000000004H51.2z"></path></svg></span></a>   </p></div></div>]]>
            </description>
            <link>https://www.sit.fraunhofer.de/en/news-events/latest/press-releases/details/news-article/show/bunter-barcode-wird-iso-standard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830777</guid>
            <pubDate>Tue, 14 Jul 2020 11:52:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Whiteboard: React Hooks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830691">thread link</a>) | @fazlerocks
<br/>
July 14, 2020 | https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc | <a href="https://web.archive.org/web/*/https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>We have talked before in <a target="_blank" rel="noopener noreferrer" href="https://blog.ranaemad.com/text-recorder-react-states-event-handling-and-conditional-rendering-ckc35etwr0000zds16hcj5nm5">Text Recorder: React States, Event Handling and Conditional Rendering</a> about states and how to set them and handle their changes. That was while using Class components, but of course we don't have to use Class components to get all the perks, do we?</p>
<p>Let's find out how we can do the same for Function components!</p>

<p>Hooks allow us to use states and lifecycle methods within a Function component. They were not always there, they have been recently introduced in React 16.8</p>
<p>They are Javascript functions, but they can NOT be called inside loops, conditions, or nested functions. They always have to be called at the top level of your React function.</p>
<p>We are going to discuss 2 main Hooks:</p>
<ul>
<li>useState</li>
<li>useEffect</li>
</ul>

<p>To set a state in a Class component, we used <code>this.state</code> in the constructor or  <code>this.setState()</code> anywhere else. Our code would look something like this:</p>
<pre><code><span>this</span>.setState({
        dummyState: <span>"dum dum"</span>
});
</code></pre>
<p>To use Hooks to rewrite the above code, we are going to need the help of useState. It accepts a parameter that can be used to set the initial value of the state and returns an array with its first element as the current value of this state and its second element as a function to be used later to set the value of the state.</p>
<pre><code><span>const</span> [dummyState, setDummyState]= useState(<span>"dum dum"</span>);
</code></pre>
<p>We can name them anything we want, of course, but the convention goes as above. Also, it is common to use the <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment">array destructuring</a> method to easily access the returned values.</p>
<p>To update the state's value later, we simply call the returned function with the updated value.</p>
<pre><code>setDummyState(<span>"dum dum dum"</span>);
</code></pre>

<p>We previously learned about componentDidMount, componentDidUpdate, and componentWillUnmount in <a target="_blank" rel="noopener noreferrer" href="https://blog.ranaemad.com/woof-vs-meow-data-fetching-and-react-component-lifecycle-ckcbpsbvj0002yys155ij60g0">Woof Vs. Meow: Data Fetching and React Component Lifecycle</a>. Our useEffect Hook can act as an equivalent to all of them combined. Isn't that some cool Hook?</p>
<p>useEffect accepts a function as a parameter and also an optional array. Let's translate the following code to Hooks to get a better understanding!</p>
<p>Both</p>
<pre><code>componentDidMount(){
    functionThatFetchesSomeData();
}
</code></pre>
<p>And</p>
<pre><code>componentDidUpdate(){
    functionThatFetchesSomeData();
}
</code></pre>
<p>Can be translated to the same thing by the useEffect Hook</p>
<pre><code>useEffect(()=&gt;{
    functionThatFetchesSomeData();
});
</code></pre>
<p>As mentioned before, the useEffect Hook acts as componentDidUpdate. It re-runs whenever any update occurs. Sometimes we want to filter when to run our useEffect and that's why the second array parameter exists. By passing a certain state to this array, we would be telling our Hook to compare its current value with its previous value and only if they were different from each other then our code would run.</p>
<pre><code>useEffect(()=&gt;{
    functionThatFetchesSomeData();
},[userId]);
</code></pre>
<p>We can have multiple useEffect Hooks and each can have its own filter and its own code.</p>
<p>If we only want to fetch data when the component mounts and we don't want to rerun our code on update, we can trick our Hook and provide it with an empty array as the second argument and by that it would never detect any changes in the array and will only run once.</p>
<p>Our final method to discuss is componentWillUnmount which is known to be used as a clean up method. To let our Hook know what to clean up all we have to do is return a function with our instructions.</p>
<pre><code>useEffect(()=&gt;{
    functionThatOpensAnImaginaryConnection();

    <span>return</span> ()=&gt;{
        functionThatClosesAnImaginaryConnection();
    }

});
</code></pre>
<p>That's enough to get us started on building something! I am already Hooked!</p>

<p>Do you know how sometimes when you are explaining something, you just feel like backing your theory up with a disfigured hand-drawn diagram? Or when you're trying to solve a problem and you need to scribble some notes to understand it better?</p>
<p>Today, we are going to build our own whiteboard to draw upon all the disfigured shapes and scribbles we want!</p>
<p><em>Experiment a little <a target="_blank" rel="noopener noreferrer" href="https://ranaemad.github.io/whiteboard/">HERE</a></em>
<img src="https://dev-to-uploads.s3.amazonaws.com/i/fi7xt4cs9g0cbjsw21tb.gif" alt="hooks written on whiteboard"></p>

<p>We want to have a huge white space to draw on, so there goes our first component, let's call it Board! We also, want to have a couple of controls to change the color and erase our content, so that will add to our application three more components; one for Controls, the other for Color and another for Eraser.</p>
<p>Let's roll!</p>

<p>By now, we should be able to install create-react-app and create our folder structure with our eyes blindfolded, so I am going to sit this one out.</p>
<p>The first thing we need in our Board component is a canvas element. Usually, to add 2d context to our canvas and make it drawable, we select it using its id, but in React no selections with id-s or classes take place. Instead, to do that we are going to use refs.</p>
<p>We have talked previously, about handling refs in Class components and they're not so different in Function components. Let's see how they look like!</p>
<pre><code><span>import</span> React <span>from</span> <span>"react"</span>;
<span>import</span> <span>"./Board.css"</span>;

<span><span>function</span> <span>Board</span>(<span></span>) </span>{
  <span>const</span> canvasRef = React.useRef(<span>null</span>);
  <span>return</span> (
    <span><span>&lt;<span>div</span> <span>className</span>=<span>"board"</span>&gt;</span>
      <span>&lt;<span>canvas</span> <span>ref</span>=<span>{canvasRef}</span> /&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  )</span>;
}

<span>export</span> <span>default</span> Board;
</code></pre>
<p>Let's add our Board to our App to view the changes as we are used to!</p>
<pre><code><span>import</span> React <span>from</span> <span>"react"</span>;
<span>import</span> <span>"./App.css"</span>;
<span>import</span> Board <span>from</span> <span>"./components/Board/Board"</span>;

<span><span>function</span> <span>App</span>(<span></span>) </span>{
  <span>return</span> (
    <span><span>&lt;<span>div</span> <span>className</span>=<span>"app"</span>&gt;</span>
      <span>&lt;<span>Board</span> /&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  )</span>;
}

<span>export</span> <span>default</span> App;
</code></pre>
<p>Now we are going to start using our Hooks. Let's import useState and start by adding our context!</p>
<pre><code><span>import</span> React,{useState} <span>from</span> <span>"react"</span>;
<span>import</span> <span>"./Board.css"</span>;

<span><span>function</span> <span>Board</span>(<span></span>) </span>{
  <span>const</span> canvasRef = React.useRef(<span>null</span>);
  <span>const</span> [ctx, setCtx] = useState({});
  <span>return</span> (
    <span><span>&lt;<span>div</span> <span>className</span>=<span>"board"</span>&gt;</span>
      <span>&lt;<span>canvas</span> <span>ref</span>=<span>{canvasRef}</span> /&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  )</span>;
}

<span>export</span> <span>default</span> Board;
</code></pre>
<p>We are going to need to set our context for the canvas the first thing. In Class components we would have used componentDidMount, which as we agreed in our case would be replaced by useEffect Hook. So let's import it and set our context!</p>
<pre><code><span>import</span> React, { useState, useEffect } <span>from</span> <span>"react"</span>;
<span>import</span> <span>"./Board.css"</span>;

<span><span>function</span> <span>Board</span>(<span></span>) </span>{
  <span>const</span> canvasRef = React.useRef(<span>null</span>);
  <span>const</span> [ctx, setCtx] = useState({});
  useEffect(() =&gt; {
    <span>let</span> canv = canvasRef.current;

    <span>let</span> canvCtx = canv.getContext(<span>"2d"</span>);
    canvCtx.lineJoin = <span>"round"</span>;
    canvCtx.lineCap = <span>"round"</span>;
    canvCtx.lineWidth = <span>5</span>;
    setCtx(canvCtx);
  }, [ctx]);

  <span>return</span> (
    <span><span>&lt;<span>div</span> <span>className</span>=<span>"board"</span>&gt;</span>
      <span>&lt;<span>canvas</span> <span>ref</span>=<span>{canvasRef}</span> /&gt;</span>
    <span>&lt;/<span>div</span>&gt;</span>
  )</span>;
}

<span>export</span> <span>default</span> Board;
</code></pre>
<p>I gave the context some basic settings and added <code>ctx</code> as my second parameter to useEffect to trigger it only when <code>ctx</code> changes and avoid entering an infinite loop of setting its value.</p>
<p>Great! Now we need to take care of the events we will use.</p>
<p>We would need to handle 3 major events:</p>
<ul>
<li>onMouseDown when we click the mouse to start drawing</li>
<li>onMouseMove when we move the mouse while drawing</li>
<li>onMouseUp when we leave the mouse to stop drawing</li>
</ul>
<p>Let's add these events to our canvas element</p>
<pre><code>&lt;canvas
  ref={canvasRef}
  onMouseDown={handleMouseDown}
  onMouseUp={handleMouseUp}
  onMouseMove={handleMouseMove}
/&gt;
</code></pre>

<p>For this event we are going to need a flag to keep track of whether the drawing process is started or not and give it an initial state of <code>false</code></p>
<pre><code><span>const</span> [drawing, setDrawing] = useState(<span>false</span>);
</code></pre>
<p>And in our function we are just going to set it to true</p>
<pre><code><span><span>function</span> <span>handleMouseDown</span>(<span></span>) </span>{
  setDrawing(<span>true</span>);
}
</code></pre>

<p>In this function we are going to do the exact opposite to what we did in the handleMouseDown function</p>
<pre><code><span><span>function</span> <span>handleMouseUp</span>(<span></span>) </span>{
  setDrawing(<span>false</span>);
}
</code></pre>

<p>This is our main function that handles the drawing. We need to move to the last mouse position we detected and draw a line from that point all the way to our current mouse position.</p>
<p>So, first thing is we are going to record the previous position with a start value of (0,0)</p>
<pre><code><span>const</span> [position, setPosition] = useState({ x: <span>0</span>, y: <span>0</span> });
</code></pre>
<p>We also need to record our canvas offset. In our case the canvas would be located at the top left corner of the window, but maybe we would like to add another element or some CSS that will shift its position, later. </p>
<pre><code><span>const</span> [canvasOffset, setCanvasOffset] = useState({ x: <span>0</span>, y: <span>0</span> });
</code></pre>
<p>To guarantee that our mouse position gives us the expected results, we will record the canvas left and top offset, when setting our context.</p>
<pre><code>useEffect(() =&gt; {
    <span>let</span> canv = canvasRef.current;

    <span>let</span> canvCtx = canv.getContext(<span>"2d"</span>);
    canvCtx.lineJoin = <span>"round"</span>;
    canvCtx.lineCap = <span>"round"</span>;
    canvCtx.lineWidth = <span>5</span>;
    setCtx(canvCtx);

    <span>let</span> offset = canv.getBoundingClientRect();
    setCanvasOffset({ x: <span>parseInt</span>(offset.left), y: <span>parseInt</span>(offset.top) });
  }, [ctx]);
</code></pre>
<p>After that, we will easily be able to detect the position by subtracting that offset from our mouse position. Now, we have our previous and current position. Before we begin our path, we just need to check our drawing flag to make sure the process is ongoing and after we're done we will set our position for the next stroke.</p>
<pre><code><span><span>function</span> <span>handleMouseMove</span>(<span>e</span>) </span>{
    <span>let</span> mousex = e.clientX - canvasOffset.x;
    <span>let</span> mousey = e.clientY - canvasOffset.y;
    <span>if</span> (drawing) {
      ctx.strokeStyle = <span>"#000000"</span>;
      ctx.beginPath();
      ctx.moveTo(position.x, position.y);
      ctx.lineTo(mousex, mousey);
      ctx.stroke();
    }
    setPosition({ x: mousex, y: mousey });
  }
</code></pre>
<p>Also, we will need to set the position once the mouse is clicked to have a position to move to for our next stroke, so we need to modify our handleMouseDown function.</p>
<pre><code><span><span>function</span> <span>handleMouseDown</span>(<span>e</span>) </span>{
  setDrawing(<span>true</span>);
  setPosition({
      x: <span>parseInt</span>(e.clientX - canvasOffset.x),
      y: <span>parseInt</span>(e.clientY - canvasOffset.y),
    });
}
</code></pre>
<p>Cool! Now, let's add some CSS to our App.css</p>
<pre><code>* {
  <span>box-sizing</span>: border-box;
}
<span>html</span>,
<span>body</span>,
<span>#root</span> {
  <span>width</span>: <span>100%</span>;
  <span>height</span>: <span>100%</span>;
}
<span>.app</span> {
  <span>height</span>: <span>100vh</span>;
  <span>width</span>: <span>100vw</span>;
  <span>display</span>: flex;
  <span>flex-direction</span>: column;
}
</code></pre>
<p>And our Board.css</p>
<pre><code><span>.board</span> {
  <span>background-color</span>: white;
  <span>cursor</span>: crosshair;
  <span>margin</span>: <span>0</span> auto;
  <span>position</span>: relative;
  <span>width</span>: <span>100%</span>;
  <span>overflow</span>: hidden;
  <span>flex</span>: auto;
  <span>display</span>: flex;
  <span>flex-direction</span>: column;
  <span>justify-content</span>: center;
 …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc">https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc</a></em></p>]]>
            </description>
            <link>https://blog.ranaemad.com/whiteboard-react-hooks-ckclrvccg0005fls16f1h80mc</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830691</guid>
            <pubDate>Tue, 14 Jul 2020 11:36:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collabera infected with Maze ransomware; employee data stolen]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830538">thread link</a>) | @darshansavla
<br/>
July 14, 2020 | https://androidrookies.com/recruiting-firm-collabera-infected-by-maze-ransomware-employees-personal-data-stolen/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/recruiting-firm-collabera-infected-by-maze-ransomware-employees-personal-data-stolen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8857"><div><div><div><h2>Hackers infected the recruitment and IT consultancy firm Collabera with Maze Ransomware, stole employees data</h2><p>The Basking Ridge, New Jersey, United States-based IT consulting and recruitment firm, Collabera has been hacked and infected by ransomware. The hackers believed to be from Maze ransomware group infiltrated into Collabera servers and stole exposed employee data like&nbsp;names, addresses, contact and social security numbers, dates of birth, employment benefits, and passport and immigration visa details.</p><p>Collabera is a multinational company offering information technology recruiting, staffing, consulting, and business services to companies worldwide. It is a $1billion company with more than 16,000 employees globally.</p><p>The Maze Ransomware group claimed the hacking of Collabera and infecting it with Maze ransomware on their Dark Web website in June. However, Collabera has not confirmed it was the work of Maze Ransomware. The Collabera security team discovered the ransomware attack on 8th June 2020.</p><blockquote><p>On June 8, 2020, Collabera identified malware in its network system consistent with a ransomware attack. We promptly restored access to our backup files and immediately launched an investigation to determine the nature and scope of the event. On June 10, we became aware that the unauthorized party obtained some data from our system.</p><p>Mike Chirico, director Collabera in an email to employees.</p></blockquote><p>While Collabera suffered no consequences of the ransomware, it has emerged that the hackers stole some of the exposed employee data. The company said it was informing every employee whose data was stolen. In the meantime, the company is offering two years of credit and identity monitoring services through Experian to the affected staff.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/recruiting-firm-collabera-infected-by-maze-ransomware-employees-personal-data-stolen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830538</guid>
            <pubDate>Tue, 14 Jul 2020 11:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeepSinger: Singing Voice Synthesis with Data Mined from the Web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830477">thread link</a>) | @dgorges
<br/>
July 14, 2020 | https://speechresearch.github.io/deepsinger/ | <a href="https://web.archive.org/web/*/https://speechresearch.github.io/deepsinger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="entry-text">
				
<ul>
<li>Yi Ren* (Zhejiang University) <a href="mailto:rayeren@zju.edu.cn">rayeren@zju.edu.cn</a></li>
<li>Xu Tan* (Microsoft Research Asia) <a href="mailto:xuta@microsoft.com">xuta@microsoft.com</a></li>
<li>Tao Qin (Microsoft Research Asia) <a href="mailto:taoqin@microsoft.com">taoqin@microsoft.com</a></li>
<li>Jian Luan (Microsoft STCA) <a href="mailto:jianluan@microsoft.com">jianluan@microsoft.com</a></li>
<li>Zhou Zhao (Zhejiang University) <a href="mailto:zhaozhou@zju.edu.cn">zhaozhou@zju.edu.cn</a></li>
<li>Tie-Yan Liu (Microsoft Research Asia) <a href="mailto:tyliu@microsoft.com">tyliu@microsoft.com</a></li>
</ul>
<p><small>* Equal contribution.</small></p>
<h2 id="chinese">Chinese</h2>
<table><thead>
<tr>
<th> / </th>
<th>Sample 1</th>
<th>Sample 2</th>
<th>Sample 3</th>
</tr></thead><tbody>
<tr>
<td>Data crawling</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/xx_0K2P2e1dc_5.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 爱从不容许人三心两意<br>Phonemes: PAD ai c ong b u r ong x v r en s an x in l iang PAD i</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/xx_0K2P2e1dc_15.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 遮住你的眼睛<br>Phonemes: zh e zh u n i d e PAD ian j ing</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/xx_XIKddfe0_37.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 好久好久<br>Phonemes: h ao j iou h ao j iou</td>
</tr>
<tr>
<td>Singing and accompaniment separation</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_raw.wav" autoplay="">Your browser does not support the audio element.</audio> </td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_raw.wav" autoplay="">Your browser does not support the audio element.</audio>  </td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/XIKddfe0_37_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
</tr>
<tr>
<td>Lyrics-to-singing alignment</td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_attn_0.8244.png"><br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_splits.png"> </td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_attn_0.8329.png"><br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_splits.png"></td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/zh/XIKddfe0_37_attn_0.3764.png"></td>
</tr>
<tr>
<td>Data filtration</td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.8244 $)  </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.8359 $)  </td>
<td>Discard (Splitting Reward: $\mathcal{O} = 0.3764 $)</td>
</tr>
<tr>
<td>Singing modeling</td>
<td>
$\textit{GT (Linear+GL)}$   <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
$\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
Pitch Plot
<img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_pitch.png">
</td>
<td>
$\textit{GT (Linear+GL)}$   <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br> 
 $\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15.wav" autoplay="">Your browser does not support the audio element.</audio> <br>
 Pitch Plot
 <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_pitch.png">
</td>
<td>
<p>/</p>
</td>
</tr>
</tbody></table>
<p>
P.S. 1) $\textit{GT}$, the ground-truth audio; 2) $\textit{GT (Linear+GL)}$, where we synthesize voices based on the ground-truth linear-spectrograms using Griffin-Lim; 3) $\textit{DeepSinger}$, where the audio is generated by DeepSinger.
</p>
<!-- 
## English
<table><thead>
<tr>
<th style="text-align: center"> / </th>
<th style="text-align: center">Sample 1</th>
<th style="text-align: center">Sample 2</th>
<th style="text-align: center">Sample 3</th>
</tr></thead><tbody>
<tr>
<td>Data crawling</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/xx_8GfscTff70f_1.wav" autoplay/>Your browser does not support the audio element.</audio><br>Lyrics: But sometimes I feel so<br>Phonemes: b ʌ t s ʌ m t aɪ m z aɪ f iː l s oʊ</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/xx_8GfscTff70f_39.wav" autoplay/>Your browser does not support the audio element.</audio><br>Lyrics: In my dreams I'm not so far away from home<br>Phonemes: ɪ n m aɪ d ɹ iː m z aɪ m n ɑː t s oʊ f ɑː ɹ ɐ w eɪ f ɹ ʌ m h oʊ m</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/xx_8GfscTff70f_37.wav" autoplay/>Your browser does not support the audio element.</audio><br>Lyrics: All my life all the time so far away from home<br>Phonemes: ɔː l m aɪ l aɪ f ɔː l ð ə t aɪ m s oʊ f ɑː ɹ ɐ w eɪ f ɹ ʌ m h oʊ m</td>
</tr>

<tr>
<td>Singing and accompaniment separation</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_1_raw.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_39_raw.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_37_raw.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>


<tr>
<td>Lyrics-to-singing alignment</td>
<td>Attention map <img src='../audio/deepsinger/en/8GfscTff70f_1_attn_0.7427.png'/><br> Lyrics-to-singing alignment <img src='../audio/deepsinger/en/8GfscTff70f_1_splits.png'/> </td>
<td>Attention map <img src='../audio/deepsinger/en/8GfscTff70f_39_attn_0.7306.png'/><br> Lyrics-to-singing alignment <img src='../audio/deepsinger/en/8GfscTff70f_39_splits.png'/></td>
<td>Attention map <img src='../audio/deepsinger/en/8GfscTff70f_37_attn_0.4725.png'/></td>
</tr>

<tr>
<td>Data filtration</td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.7427 $) </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.7306 $)  </td>
<td>Discard (Splitting Reward: $\mathcal{O} = 0.4725 $)</td>
</tr>

<tr>
<td>Singing modeling</td>

<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_1_gt.wav" autoplay/>Your browser does not support the audio element.</audio> <br>  
$\textit{DeepSinger}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_1.wav" autoplay/>Your browser does not support the audio element.</audio> <br>  
Pitch Plot
<img src='../audio/deepsinger/en/8GfscTff70f_1_pitch.png'/>
</td>

<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_39_gt.wav" autoplay/>Your browser does not support the audio element.</audio> <br> 
 $\textit{DeepSinger}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_39.wav" autoplay/>Your browser does not support the audio element.</audio> <br>
 Pitch Plot
 <img src='../audio/deepsinger/en/8GfscTff70f_39_pitch.png'/>
</td>

<td>

/

</td>
</tr>

</tbody></table>
-->
<h2 id="cantonese">Cantonese</h2>
<table><thead>
<tr>
<th> / </th>
<th>Sample 1</th>
<th>Sample 2</th>
<th>Sample 3</th>
</tr></thead><tbody>
<tr>
<td>Data crawling</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/xx_bClau824b25f_3.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 我已经不懂心痛<br>Phonemes: ŋ o5 j i5 ɡ inɡ1 b a1 t d unɡ2 s a1 m t unɡɜ</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/xx_bClau824b25f_9.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 或你会了解在孤单中的心痛<br>Phonemes: w aa6 k n ei5 w ui6 l iu5 ɡ aai2 z oi6 ɡ u1 d aa1 n z unɡ1 d i1 k s a1 m t unɡɜ</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/xx_bBfZ2b39bf_32.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 唔知点解 我成日都好担心<br>Phonemes: nɡ4 z i1 d i2 m ɡ aai2 ŋ o5 s inɡ4 j a6 t d ou1 h ou2 d aa1 m s a1 m</td>
</tr>
<tr>
<td>Singing and accompaniment separation</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bBfZ2b39bf_32_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
</tr>
<tr>
<td>Lyrics-to-singing alignment</td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_attn_0.8105.png"> <br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_splits.png"></td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_attn_0.7372.png"><br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_splits.png"></td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/hk/bBfZ2b39bf_32_attn_0.3601.png"></td>
</tr>
<tr>
<td>Data filtration </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.8105 $) </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.7372 $)  </td>
<td>Discard (Splitting Reward: $\mathcal{O} = 0.3601 $)</td>
</tr>
<tr>
<td>Singing modeling</td>
<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
$\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
Pitch Plot
<img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_pitch.png">
</td>
<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br> 
 $\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9.wav" autoplay="">Your browser does not support the audio element.</audio> <br>
 Pitch Plot
 <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_pitch.png">
</td>
<td>
<p>/</p>
</td>
</tr>
</tbody></table>

<p><a href="https://speechresearch.github.io/unsuper/">Almost Unsupervised Text to Speech and Automatic Speech Recognition</a><br>
<a href="https://speechresearch.github.io/fastspeech/">FastSpeech: Fast, Robust and Controllable Text to Speech</a><br>
<a href="https://speechresearch.github.io/multispeech/">MultiSpeech: Multi-Speaker Text to Speech with Transformer</a><br>
<a href="https://speechresearch.github.io/seminas/">Semi-Supervised Neural Architecture Search</a><br>
<a href="https://speechresearch.github.io/lrspeech/">LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition</a><br>
<a href="https://speechresearch.github.io/fastspeech2/">FastSpeech 2: Fast and High-Quality End-to-End Text-to-Speech</a><br>
<a href="https://speechresearch.github.io/uwspeech/">UWSpeech: Speech to Speech Translation for Unwritten Languages</a><br></p>
<!-- ### Good Alignment Example

<p>
Splitting Reward: $\mathcal{O} = 0.8024 $  
</p>

<img src='../audio/deepsinger/good_align.png'/>
<audio controls="controls" ><source src="../audio/deepsinger/good_align.wav" autoplay/>Your browser does not support the audio element.</audio>

### Bad Alignment Example

<p>
Splitting Reward: $\mathcal{O} = 0.3196 $  
</p>

<img src='../audio/deepsinger/bad_align.png'/>
<audio controls="controls" ><source src="../audio/deepsinger/bad_align.wav" autoplay/>Your browser does not support the audio element.</audio>


## Audio Samples

<!-- ### Chinese  -->
<!-- 
*爱从不容许人三心两意*

<table><thead>
<tr>
<th style="text-align: center">Raw Audio</th>
<th style="text-align: center">Vocal (after seperation)</th>
<th style="text-align: center">GT (Linear+GL)</th>
<th style="text-align: center">DeepSinger</th>
</tr></thead><tbody>
<tr>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/raw/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt_gl/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/ds/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody></table>


*遇见浑然天成的交集*

<table><thead>
<tr>
<th style="text-align: center">Raw Audio</th>
<th style="text-align: center">Vocal (after seperation)</th>
<th style="text-align: center">GT (Linear+GL)</th>
<th style="text-align: center">DeepSinger</th>
</tr></thead><tbody>
<tr>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/raw/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt_gl/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/ds/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody></table>



*遮住你的眼睛*

<table><thead>
<tr>
<th style="text-align: center">Raw Audio</th>
<th style="text-align: center">Vocal (after seperation)</th>
<th style="text-align: center">GT (Linear+GL)</th>
<th style="text-align: center">DeepSinger</th>
</tr></thead><tbody>
<tr>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/raw/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt_gl/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/ds/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody></table>

<br> --> 

			</section></div>]]>
            </description>
            <link>https://speechresearch.github.io/deepsinger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830477</guid>
            <pubDate>Tue, 14 Jul 2020 11:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Could predictive database queries replace machine learning models?]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23830474">thread link</a>) | @tlarkworthy
<br/>
July 14, 2020 | https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models | <a href="https://web.archive.org/web/*/https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This post appeared first on <a href="https://towardsdatascience.com/predictive-queries-vs-supervised-ml-models-ee7f17e4840e">Towards Data Science</a> in July 12th, 2020.</p></blockquote><p>One of the greatest trends in today’s technology landscape is the <a href="http://knowledge.wharton.upenn.edu/article/democratization-ai-means-tech-innovation/">democratization of machine learning</a>. Because the commodity state-of-the-art models, better tooling and better access to hardware: machine learning is becoming an everyday tool in the companies’ toolbox.</p><p>The ML democratization is still an on-going trend and given the disruption in this space it’s worth asking: where will this transformation take us? What the future of the everyday ML will look like?</p><p>Predictive queries are an interesting take on machine learning, especially in the ML democratization context. Solutions like <a href="http://probcomp.csail.mit.edu/">MIT’s</a> <a href="https://github.com/probcomp/bayeslite">BayesDB/BayesLite</a> and Aito provide a way to get arbitrary predictions instantly with SQL-like queries. As an example, here’s a predictive query in Aito:</p><div data-language="json"><pre><code><span>{</span>
  <span>"from"</span><span>:</span> <span>"invoice_data"</span><span>,</span>
  <span>"where"</span><span>:</span> <span>{</span>
    <span>"Item_Description"</span><span>:</span> <span>"Packaging design"</span><span>,</span>
    <span>"Vendor_Code"</span><span>:</span> <span>"VENDOR-1676"</span>
  <span>}</span><span>,</span>
  <span>"predict"</span><span>:</span> <span>"Product_Category"</span>
<span>}</span></code></pre></div><p>As such: the predictive queries seem like an easier, faster and radically different way to do machine learning. They give a glimpse of a future, where anyone can do machine learning as easily as one does database queries.</p><p>This article gives a brief introduction to the predictive queries, and it compares the predictive queries to supervised learning through 3 different aspects that are:</p><ol><li>The workflow, comparing the easiness and the costs between predictive queries and supervised machine learning</li><li>The architecture, comparing the high level differences between using predictive queries and using supervised models</li><li>And the qualitative properties (scaling, accuracy) as the quality is an obvious concern for an emerging, if promising, technology.</li></ol><h2>Introduction to the predictive queries</h2><p>Predictive queries resemble normal database queries with the exception that they provide predictions about the unknown, while the traditional database queries provide facts about the known. Here’s an example of the BQL (Bayesian Query Language) query done against BayesDB/BayesLite database:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-queries-in-bayeslite.png" alt=""></p></div><p><span>Predictive BayesQL queries in BayesLite. BayesQL is based on SQL and it provides a very elegant way to query arbitrary estimates. This query can be executed after the CREATE POPULATION, CREATE ANALYSIS, INITIALIZE ANALYSIS and ANALYZE operations. </span></p></div><p>In essence, the predictive queries can provide a very SQL-like alternative to the supervised ML models with the key differences that:</p><ol><li><p>While supervised machine learning models need to be configured, trained and deployed before usage, the predictive queries provide instant answers after the database is prepared with data. As such: the predictive queries have a different workflow.</p></li><li><p>While supervised machine learning is always specialized for a single prediction from A to B, predictive queries can be used a) to instantly predict any unknown X based on any known Y and b) to provide also recommendations, smart search and pattern mining. As such, the supervised models are narrow, while the predictive queries are multipurpose, which has implications on the architecture.</p></li><li><p>While with the supervised machine learning the narrow models are explicitly formed train time, the predictive queries do multi-purpose modeling write time or narrow modeling during query time. As such: the predictive queries are technically more challenging.</p></li></ol><p>Only few solutions exist, that provide such predictive queries. One is the mentioned BayesDB/BayesLite, which creates an in-memory multi-purpose models in a special preparation phase. Another solution is Aito.ai, which does query-time narrow modeling without explicit preparations. Here’s is an example of the Aito workflow:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-queries-in-3-steps.png" alt=""></p></div><p><span>Predictive BayesQL queries in BayesLite. BayesQL is based on SQL and it provides a very elegant way to query arbitrary estimates. This query can be executed after the CREATE POPULATION, CREATE ANALYSIS, INITIALIZE ANALYSIS and ANALYZE operations. </span></p></div><p>We are focusing the following comparisons on Aito. We feel this focus is justified as in Aito we are more familiar with the solution, and it is mature enough to serve the end customers in live production settings. While BayesLite is extremely impressive and their BQL interface and DB/ML integration are worth envy: BayesLite seems to have properties like the 16 minute preparation phase for simple data, which are not consistent with the presented arguments.</p><p>So let’s next dig deeper on the difference in workflow, architecture and quality between the predictive queries and supervised ML models.</p><h2>1. The Workflow</h2><p>The first difference between predictive queries and the traditional supervised models relates to the workflow and the costs.</p><p>Supervised ML models are deployed typically in data science projects, which have several steps like the handover to the data scientist, data preparation, feature engineering, model fitting, deployment, integrations, retraining and monitoring &amp; maintenance. As an addition to this linear progression, you also often have an iteration phase, where the results are improved by refining the data, the preparations, the features, the models, the deployment or the integrations.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-data-science-project-workflow.png" alt=""></p></div><p><span>A simplified version of the data science project.</span></p></div><p>Taking a supervised model to production may take several weeks or months from one to two persons. This can raise the price point up to hundred thousand euros per model. If you need several models, you need several data science projects, leading to multiplied expenses and delays.</p><p>Now this process changes rather dramatically, if you implement the machine learning functionality with predictive queries. With predictive queries the workflow is in essence the following:</p><ol><li>Prepare the auxiliary <a href="https://aito.ai/blog/introducing-a-new-database-category-the-predictive-database/">predictive database</a> once (if it’s not used as the main database)</li><li>Verify good enough prediction quality with evaluate requests</li><li>Integrate the predictive queries like you would integrate SQL queries</li><li>Write the test/evaluation cases, push these to Git and let the CI handle the regression testing</li><li>If seen as necessary: track the in-production prediction quality with analytics and display the metrics in the product dashboard.</li></ol><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-query-workflow.png" alt=""></p></div><p><span>The workflow with the predictive queries is similar to the workflow with the database queries. Still, because predictive functionality is statistical and its behavior may drift as the data changes: it is advisable to verify the prediction quality (step 2) before implementation and monitor the prediction quality in production (step 5).</span></p></div><p>While putting an auxiliary database (like ElasticSearch) into production can take weeks, the expense related to putting each query into production is closer to the expense of using search/database queries. Often such queries form only a small part of the related functionality’s expense, and often the query based functionality can be implemented in hours and put into production in days.</p><p>This dramatic difference between the workflows and the expenses are explained a) partly by the <a href="https://aito.ai/blog/introducing-a-new-database-category-the-predictive-database/">predictive database</a>’s AutoML capabilities that are accelerated by a specialized database and b) partly by the reduced need for deployments and integrations as the data and the ML are already integrated into a single system. The complex phases of the data science project get systematically eliminated or simplified:</p><ol><li>The handover of the data science project to the data scientist is not needed as the predictive query workflow is easy enough for the software developers.</li><li>Data preparation and feature engineering steps can be greatly eliminated with the ML-database integration. You don’t need to re-prepare and re-upload the data, if the data is already in the database. You don’t need to manually aggregate data into flat data frames, if you can do <a href="https://aito.ai/docs/articles/utilizing-relationships-in-aito/">inference through the database references</a>. You don’t need to manually featurize text either, as the predictive database analyzes the <a href="https://aito.ai/docs/api/#schema-analyzer">text automatically</a> just like ElasticSearch. Last: you don’t need to manage feature redundancies, if the database has built-in <a href="https://aito.ai/blog/introducing-concept-learning-to-free-you-from-feature-engineering/">feature learning capabilities</a>.</li><li>Modeling phase can be automated with a single sophisticated model that provides good enough results for most applications.</li><li>Per model cloud deployment, live integrations and retraining of models simply disappear, because you don’t need to ‘deploy’ or retrain the predictive queries. Instead you integrate one auxiliary predictive database like you would integrate <a href="https://www.elastic.co/">ElasticSearch</a>. If you use the predictive database as your main database, you can omit even that one integration.</li><li>Maintenance is easier, because instead of maintaining deployed infrastructure for each prediction target, you maintain the SQL-like queries like you would maintain code with Git &amp; CI.</li></ol><p>As a consequence, the workflow and the cost of implementing ML via predictive queries is similar to the process of implementing normal business logic via SQL.</p><p>The second difference between the predictive queries and the supervised models is the narrowness and it’s implications on the software architecture.</p><p>Famously: the supervised ML models are <em>narrow</em> in 2 different respects:</p><p>1.Narrowness of the prediction setting. Supervised learning models are essentially narrow functions from A (e.g. text) to B (category), which means that if you have 10 different problems, you end up with with 10 different supervised ML models.
2. Narrowness of the predictive functionality type. A single kind of supervised method can typically serve only one kind of predictions. For this reason you often need completely separate systems or products to implement predictions, recommendations, smart search and pattern mining.d up with with 10 different supervised ML models.</p><p>This combined narrowness has negative implications on the architecture. If you have 10 different predictive functionalities that mix prediction, recommendation and smart search use cases: you end up struggling with a very complex system. The system may include separate supervised model platform with half dozen deployed models, separate recommendation system, a separate smart searching product and separate pattern mining tools. Such complexity is hard to learn, master and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models">https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models</a></em></p>]]>
            </description>
            <link>https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830474</guid>
            <pubDate>Tue, 14 Jul 2020 11:01:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Purism-Librem13v4]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830046">thread link</a>) | @luu
<br/>
July 14, 2020 | https://anarc.at/hardware/laptop/purism-librem13v4/ | <a href="https://web.archive.org/web/*/https://anarc.at/hardware/laptop/purism-librem13v4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>The <a href="https://puri.sm/products/librem-13/">Purism Librem 13</a> is a 13" laptop that's similar to the
Macbook Air but slightly heavier and thicker, from what I
understand. I have the <code>v4</code> means it's the fourth hardware version of
the device. This is the latest incarnation of the <a href="https://anarc.at/hardware/angela/">angela</a>
node.</p>

<p>TL;DR: I recommend people avoid the Purism brand and products. I find
they have questionable politics, operate in a "libre-washing" fashion,
and produce unreliable hardware. Will not buy again.</p>






<ul>
<li>Operating system: PureOS</li>
<li>TPM: Included</li>
<li>Battery life: Roughly 7 to 9 hours (actual: more like 6h)</li>
<li>Processor: Core i7 7500U (Kabylake)</li>
<li>Display: 13.3" 1920×1080</li>
<li>Graphics: Intel HD Graphics 620</li>
<li>Memory: Up to 32GB, DDR4 at 2133 MHz</li>
<li>Storage: 2.5" SATA + NVMe-capable M.2 slots</li>
<li>Chassis: Black anodized aluminium</li>
<li>Webcam: 720p 1.0 megapixel</li>
<li>Dimensions: 325×219×18mm</li>
<li>Weight: 1.4kg</li>
<li>Wireless: Atheros 802.11n w/ Two Antenna</li>
<li>Radio hardware killswitch: Yes</li>
<li>Mic and cam killswitches: Yes</li>
<li>Audio port: 1 headphone/line output jack</li>
<li>USB ports: 2 USB 3.0 Ports (1 type C, data transfer only)</li>
<li>External monitor output: 1 HDMI Port (4K capable @ 30Hz max)</li>
<li>Card reader: Yes, 2-in-1 SD/MMC</li>
<li>Backlit keyboard: Yes</li>
<li>Touch interface: Elantech Multitouch Trackpad</li>
<li>Thermal design: Low noise fan (actual: not really, quite noisy when
all CPUs are maxed)</li>
</ul>


<p>The machine came with a 250GB Crucial SSD drive with PureOS
pre-installed, even if I ordered it without storage.</p>

<h2 id="semi-standard-power-connector"><a name="index1h2"></a>Semi-standard power connector</h2>

<p>The power connector is <a href="https://learn.sparkfun.com/tutorials/connector-basics/power-connectors">somewhat standard</a>: 19V DC on a 5.5mm
sleeve with 2.5 positive pin, with a <a href="https://en.wikipedia.org/wiki/IEC_60320#C5/C6_coupler">C5/C6 cable</a> for the AC side
(as opposed to the more standard C13/C14 coupler, mind you). I was
able to find a "universal 19V adapter" for ~60$ at a local store that
also supported other barrel connectors.</p>

<p>It would be better if the laptop would charge through USB-C,
naturally, as <em>that</em> is slowly becoming the standard for charging
computing devices, but that will have to do for now.</p>

<h2 id="good-monitor"><a name="index2h2"></a>Good monitor</h2>

<p>The monitor shipped with the Librem is actually quite good by my
standards (1920x1080 / 1080p / FullHD). It does mean messing around
with <a href="https://wiki.debian.org/MonitorDPI">HiDPI</a> settings which I haven't quite figured out yet.</p>

<p><a href="https://vincent.bernat.ch/en/blog/2018-4k-hidpi-dual-screen-linux">This post</a> seems to have good resources. From what I understand,
the resolution of the screen is actually 166dpi, which takes some
configuring to display properly. This can be computed from the aspect
ratio (16:9), the resolution (1920x1080) and the diagonal of the
screen (13.3"). According to <a href="https://www.sven.de/dpi/">this calculator</a>, this is the
formula:</p>

<pre><code>Display size: 11.59" × 6.52" = 75.59in² (29.44cm × 16.56cm = 487.64cm²) at 165.63 PPI, 0.1534mm dot pitch, 27434 PPI² 
</code></pre>

<p>All this does make my old monitor (which I found in the basement) look
like crap. So I need to find a <a href="https://forums.puri.sm/t/suitable-external-monitor-for-librem-13/5627">new monitor</a>, arguably not a
problem with the Librem per se of course...</p>

<p>It seems the Librem can drive 1440p, so not "4K UHD" (3840x2160), but
"QHD" (2560x1440) which should be more than enough.</p>

<h2 id="liberated-boot"><a name="index3h2"></a>Liberated boot</h2>

<p>The Purism folks did a pretty awesome job at liberating their
BIOS. They run their own version of coreboot they call
<a href="https://docs.puri.sm/PureBoot.html">Pureboot</a>. In theory, it should be easier to setup a trusted,
<a href="http://wiki.debian.org/SecureBoot">SecureBoot</a> but in practice I have yet to set that up.</p>

<p>I did try to configure the laptop with an encrypted <code>/boot</code>, but that
didn't go so well. First, I get a double password prompt: once in
<code>grub</code> and once in the <code>initramfs</code>. But more annoying is the <code>grub</code>
prompt has no retry: if you fail, you drop in the rescue shell which
is really impractical.</p>

<p>(Update: that is, of course, not specific to Purism or PureOS, but a
limitation in grub itself.)</p>

<p>Finally, Pureboot doesn't support encrypted <code>/boot</code> so it actually
makes it <em>harder</em> to implement trusted boot.</p>

<p>The coreboot stuff needs to be updated, and instructions are available
<a href="https://puri.sm/coreboot/">on the Purism website</a>.</p>

<h2 id="excellent-linux-support"><a name="index4h2"></a>Excellent Linux support</h2>

<p>On top of the liberated BIOS, it must be said the device has
<em>excellent</em> support for free operating systems. <em>Every</em> device on the
machine has full support in the Linux kernel, even the "older" version
in Debian stretch (Linux 4.9). No binary blobs, no proprietary
drivers, even for wifi.</p>

<p>That is just awesome. It's the first device, in a long time, that
gives me this freedom, so it should be acknowledged and celebrated.</p>

<p>Update: I still have some <code>non-free</code> packages installed:</p>

<ul>
<li><p>the Intel CPU firmware package (<a href="http://packages.debian.org/intel%2Dmicrocode">intel-microcode</a>)</p></li>
<li><p>I also use some "non-free" documentation packages (<a href="http://packages.debian.org/doc%2Drfc">doc-rfc</a>, <a href="http://packages.debian.org/emacs%2Dcommon%2Dnon%2Ddfsg">emacs-common-non-dfsg</a>, <a href="http://packages.debian.org/make%2Ddoc">make-doc</a>)</p></li>
<li><p>Bluetooth requires <a href="http://packages.debian.org/firmware%2Datheros">firmware-atheros</a></p></li>
</ul>


<p>When building the <code>initramfs</code>, there are warnings about the <code>i915</code>
graphics controller, which is solved by installing the <a href="http://packages.debian.org/firmware%2Dmisc%2Dnonfree">firmware-misc-nonfree</a> package, but the graphics card works without
the firmware. Apparently, the warnings are harmless and indeed PureOS
fixed <a href="https://tracker.pureos.net/T362">the bug</a> by simply <a href="https://source.puri.sm/pureos/core/initramfs-tools/commit/005ca5b834fa7ee44bb913d74b4ff2aa542fc9d1">disabling all such warnings</a>.3</p>

<p>The Debian-specific stuff is also documented in <a href="https://wiki.debian.org/InstallingDebianOn/Purism/Librem%2013">the Debian wiki</a>.</p>

<h2 id="good-speakers"><a name="index5h2"></a>Good speakers</h2>

<p>The builtin speakers sound great.</p>



<p>I have a few issues with the device.</p>

<h2 id="weird-keyboard-layout"><a name="index6h2"></a>Weird keyboard layout</h2>

<p>The <a href="https://forums.puri.sm/t/keyboard-layout-unable-to-recognize-pipe/2022">keyboard layout is strange</a>: the key above <kbd>enter</kbd>,
instead of sending <kbd>\</kbd> or <kbd>|</kbd>, sends
"chevrons". This is due to the Purism folks expecting you to pick the
"US international" keyboard instead of the "US" keyboard, which is a
very strange pick, as the "US" keyboard seems pretty standard. The
workaround is to drop this in your <code>udev</code> configuration, say in
<code>/etc/udev/hwdb.d/90-purism-pipe-symbol-fix.hwdb</code>:</p>

<pre><code>evdev:atkbd:dmi:bvn*:bvr*:bd*:svnPurism:pnLibrem13v4*
 KEYBOARD_KEY_56=backslash
</code></pre>

<p>Then running:</p>

<pre><code>sudo systemd-hwdb update
sudo udevadm trigger
</code></pre>

<p>The keyboard layout, in general, is a little unique: the sound buttons
are split across the <kbd>F4</kbd> key (mute) and
<kbd>-</kbd>/<kbd>=</kbd> (volume up/down keys) for some reason.</p>

<p>The <kbd>PrtSc</kbd> key <a href="https://forums.puri.sm/t/does-alt-sysrq-work-on-librem-laptops/5290/9">can be as SysRq</a> but is <em>backwards</em>
(<kbd>ScrLk</kbd> <kbd>PrtSc</kbd>) to their usual order
(<kbd>PrtSc</kbd> <kbd>ScrLk</kbd>).</p>

<h2 id="limited-usb-c-port"><a name="index7h2"></a>Limited USB-C port</h2>

<p>The USB-C port <a href="https://forums.puri.sm/t/is-hdmi-over-usb-c-possible-on-13v2/2020">does not support video</a> which makes it limited to
charging and data transfer. It can also not charge the laptop itself,
as there's a separate power connector, losing many of the benefits
usually associated with USB-C.</p>

<p>Ideally, a USB-C port might be used as a universal docking port: one
wire to plug and you have power, video, audio, and USB for keyboard
and mouse. Unfortunately, I'm still stuck with about 4 wires to plugin
when I come into the office, something I was hoping to avoid. People
have <a href="https://forums.puri.sm/t/please-recommend-a-port-replicator-docking-station/1115">looked for a dock station</a> without success.</p>

<h2 id="shipping-delays-doa"><a name="index8h2"></a>Shipping delays, DOA</h2>

<p>I waited almost four weeks to have my laptop delivered. Presumably
this was due to a <a href="https://forums.puri.sm/t/where-was-purism-moving/5799/">warehouse move</a> but I found that communication
about the issue could have been better. Worse: the laptop was <a href="https://forums.puri.sm/t/librem-13v3-bricked/5714/19?u=anarcat">dead on
arrival</a> (DOA) so I had to return it, adding another week delay for
getting an actual working laptop. FedEx even charged me for the return
even though Purism actually issued a shipping label, something I still
haven't quite resolved.</p>

<p>Update: I ended up paying over 260$ in shipping fees to Fedex, in the
end. I first paid around 70$ for the first laptop sent, then Fedex
sent me <em>another</em> 200$ bill for the <em>second</em> laptop. Purism were
unable to help me with this issue and Fedex has been totally useless
as well. I've tried to reach to both organizations to get around those
fees but the time wasted waiting on hold and support has outgrown the
possible savings I could to by not paying the damn bill, so I just
paid it now.</p>

<h2 id="bright-leds-not-accessible-when-lid-closed"><a name="index9h2"></a>Bright LEDs, not accessible when lid closed</h2>

<p>There are three leds on the top right of the keyboard: one for wifi,
battery and power. They are very bright and even though they can
technically be dimmed, the firmware is not open so there's <a href="https://forums.puri.sm/t/is-there-a-way-to-dim-the-leds-on-the-13-v2/1172">no way to
dim the LEDs</a>.</p>

<h2 id="no-ethernet-port"><a name="index10h2"></a>No ethernet port</h2>

<p>That was a deal breaker for me originally, but I changed my
mind. First, I don't need gigabit transfer speeds that often. Then my
office doesn't have wired connectivity yet, so it is not that
useful. Plus, I can afford to have a USB dongle there with a gigabit
ethernet port, indeed, I already have one of those USB hubs. So not
that big of a deal.</p>

<h2 id="libre-washing"><a name="index11h2"></a>Libre-washing</h2>

<p>I have found Purism's commitment to free hardware and free software to
be questionable. While, yes, they try to provide a <a href="#liberated-boot">liberated boot</a>
and coreboot-based BIOS, that BIOS is not free software. At best they
"neuter" the Intel Management Engine, but you still require non-free
firmware to operate a Librem Computer, from the CPU down to the
Bluetooth and Wifi hardware. Even if that is a very common pattern on
laptops and phone, it is a huge disconnect with the "purity" and
"freedom" narrative on their website.</p>

<p>For example, the replacement for the Librem 13, called Librem 14,
claims to be:</p>

<blockquote><p><strong>The first 14″ laptop designed to protect your digital life</strong></p>

<p>Ultra-portable workstation laptop that was designed chip-by-chip,
line-by-line, to respect your rights to privacy, security, and
freedom.</p></blockquote>

<p>Yet it still ships with Intel processors, known for a large variety of
fundamental security issues that are part of the hardware design,
which Intel refuses to fix. That it ships <a href="https://puri.sm/coreboot/">coreboot</a> on top of that
is besides the point: coreboot, as shipped by Purism, is not open
source, or at least ships proprietary blobs.</p>

<p>Compare this with the work System76 has been doing in recent
times. While they brand themselves as just a company shipping Linux
laptops, they <a href="https://blog.system76.com/post/187072707563/the-new-firmware-manager-updating-firmware-across">work with the de-facto standard LVFS</a> (even though
that is a <a href="https://blog.system76.com/post/173801677358/system76-and-lvfs-what-really-happened">bumpy ride</a>), actually <a href="https://blog.system76.com/post/612315972866637824/a-look-back-at-manufacturing">design and prototype their own
hardware</a>, and <a href="https://opensource.com/article/20/1/system76-open-source-firmware">liberated their keyboard microcontroller</a>. They
have even started <a href="https://blog.system76.com/post/186655523269/open-firmware-and-more-news-from-july">working on an open Thunderbolt
microcontroller</a>. And while those might sound like small things
compared to liberating the CPU firmware, I will point out that they
actually <em>succeed</em> in completely liberating those components, while
Purism, in the <em>years</em> they have supposedly been working on those
projects, have only managed to reuse (and, to be fair, improve on) the
work <em>others</em> have done to neutralize the IME.</p>

<p>What has Purism done, in the meantime? Neutralized IME. That's
it. They have not published <em>anything</em> on LVFS. Even closed-source
companies like <a href="https://fwupd.org/lvfs/vendors/#logitech">Logitech</a>, <a href="https://fwupd.org/lvfs/vendors/#synaptics">Synaptics</a>, <a href="https://fwupd.org/lvfs/vendors/#hp-ws">HP</a> and <a href="https://fwupd.org/lvfs/vendors/#dell">Dell</a>
ship their updates on LVFS. Purism <a href="https://fwupd.org/lvfs/vendors/#purism">has a test account</a> and work
has been <a href="https://forums.puri.sm/t/submit-firmware-to-linux-vendor-firmware-service-lvfs-for-easy-updating/4731">stalled for years now</a>.</p>

<h2 id="bullshit-anti-interdiction"><a name="index12h2"></a>Bullshit anti-interdiction</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anarc.at/hardware/laptop/purism-librem13v4/">https://anarc.at/hardware/laptop/purism-librem13v4/</a></em></p>]]>
            </description>
            <link>https://anarc.at/hardware/laptop/purism-librem13v4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830046</guid>
            <pubDate>Tue, 14 Jul 2020 09:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatland Challenge - Multi Agent Reinforcement Learning on Trains]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829991">thread link</a>) | @jonbaer
<br/>
July 14, 2020 | https://www.aicrowd.com/challenges/flatland-challenge | <a href="https://web.archive.org/web/*/https://www.aicrowd.com/challenges/flatland-challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="description-wrapper">
        <div>
          <div data-controller="challenge-overview" data-action="resize@window->challenge-overview#showTOC" data-challenge-overview-scrollable-tabs="true">
            <blockquote>
<p>The Flatland 2019&nbsp;challenge has ended! Do you want more?</p>

<p><a href="https://www.aicrowd.com/challenges/neurips-2020-flatland-challenge/"><strong>Check out the NeurIPS 2020 Flatland challenge!</strong></a></p>
</blockquote>

<figure><img alt="flatland_logo" src="https://s3.eu-central-1.amazonaws.com/aicrowd-static/SBB/images/Flatland_Logo.svg"></figure>

<p><strong>The key question we want to answer here is: How can trains learn to automatically coordinate among themselves, so that there are minimal delays in large train networks ?</strong></p>

<h2>Abstract</h2>

<p><i>The Flatland Challenge is a competition to foster progress in multi-agent reinforcement learning for any </i><a href="https://en.wikipedia.org/wiki/Vehicle_rescheduling_problem"><i>re-scheduling problem (RSP)</i></a><i>. The challenge addresses a real-world problem faced by many transportation and logistics companies around the world (such as the Swiss Federal Railways, SBB. Different tasks related to RSP on a simplified 2D multi-agent railway simulation must be solved. Your contribution may shape the way modern traffic management systems (TMS) are implemented not only in railway but also in other areas of transportation and logistics. This will be the first of a series of challenges related to re-scheduling and complex transportation systems.</i></p>

<h2>Background</h2>

<p>The Swiss Federal Railways (SBB) operate the densest mixed railway traffic in the world. SBB maintain and operate the biggest railway infrastructure in Switzerland. Today, there are more than 10,000 trains running each day, being routed over 13,000 switches and controlled by more than 32,000 signals. Each day 1.2 million passengers and almost half of Switzerland’s volume of transported goods are transported on this railway network. Due to the growing demand for mobility, SBB needs to increase the transportation capacity of the network by approximately 30% in the future.</p>

<p>The increase in transport capacity can be achieved through different measures, such as <a href="https://smartrail40.ch/index.asp?inc=&amp;lang=en">denser train schedules, investments in new infrastructure, and/or investments in new rolling stock</a>. However, SBB currently lack suitable technologies and tools to quantitatively assess these different measures.</p>

<p>A promising solution to this dilemma is a complete railway simulation that efficiently evaluates the consequences of infrastructure changes or schedule adaptations for network stability and traffic flow. A complete railway simulation consists of a full dynamical physics simulation as well as an automated traffic management system.</p>

<figure><img alt="flatland_visual" src="https://s3.eu-central-1.amazonaws.com/aicrowd-static/SBB/images/Flatland_Preview.svg"></figure>

<p><i><strong>Flatland</strong>: This image illustrates an early draft of the environment visualization. The core task of this challenge is to manage and maintain railway traffic on complex scenarios in complex networks.</i></p>

<p>The research group at SBB has developed a high-performance simulator which simulates the dynamics of train traffic as well as the railway infrastructure. Different approaches for <a href="https://on-demand-gtc.gputechconf.com/gtcnew/on-demand-gtc.php?searchByKeyword=erik%20nygren&amp;searchItems=&amp;sessionTopic=&amp;sessionEvent=&amp;sessionYear=&amp;sessionFormat=&amp;submit=&amp;select=">automated traffic management systems (TMS)</a> are currently under investigation. The role of the traffic management system is to select routes for all trains and decide on their priorities at switches in order to optimize traffic flow across the network.</p>

<p>At the core of this challenge lies the general vehicle re-scheduling problem (VRSP) proposed by Li, Mirchandani and Borenstein in 2007:</p>

<blockquote>
<p>The vehicle rescheduling problem (VRSP) arises when a previously assigned trip is disrupted. A traffic accident, a medical emergency, or a breakdown of a vehicle are examples of possible disruptions that demand the rescheduling of vehicle trips. The VRSP can be approached as a dynamic version of the classical vehicle scheduling problem (VSP) where assignments are generated dynamically.</p>
</blockquote>

<p>The “Flatland” Competition aims to address the vehicle rescheduling problem by providing a simplistic grid world environment and allowing for diverse solution approaches. The challenge is open to any methodological approach, e.g. from the domain of reinforcement learning or of operations research.</p>

<p>The problems are formulated as a 2D grid environment with restricted transitions between neighboring cells to represent railway networks. On the 2D grid, multiple agents with different objectives must collaborate to maximize global reward. There is a range of tasks with increasing difficulty that need to be solved as explained in the coming sections.</p>

<h2>Tasks</h2>

<p>The challenge requires your creativity and savviness. In 3 submission rounds with increasing difficulty, you can prove that you have what it takes. We invite you to enter the race with your unique solution and to win great prizes - at the same time solving one of the key challenges in the world of transportation!</p>

<p>Here is a teaser of what we expect you to do:&nbsp;</p>

<figure><img alt="Teaser" src="https://i.imgur.com/9cNtWjs.gif"></figure>

<p>Your overall goal is to make all agents (trains) arrive at their target destination with a minimal travel time. In other words, we want to minimize the time steps (or wait time) that it takes for each agent in the group to reach its destination.</p>

<p>Let’s say in a scenario with n-agents, the travel time is measured by the collected amount of timesteps all the agents have until the n-th agent arrives at its destination.</p>

<h3>1. Can you design the best-performing agent?</h3>

<p>Design the best-performing agent. At the more basic levels, the agents may achieve their goals using ad-hoc decisions. But as difficulty increases from round to round, the agents have to be able to plan ahead, i.e. with increasing difficulty, planning becomes more relevant!</p>

<h3>2. Can you design the best observation?</h3>

<p>As a participant, you have the choice. You can either work with the three base observations that we prepared or better, design an improved observation yourself. If you do the latter, then share your observation and you will have chances of winning the Community Contribution Prize (see Prizes). These are the three base observation that we prepared:</p>

<p>Global Observation: The whole scene is observed</p>

<p>Local Grid Observation: A local grid around the agent is observed</p>

<p>Tree Observation: The agent can observe its navigable path to some predefined depth.</p>

<p>Sounds complicated? Do not despair, the next sections will provide you with more useful information about these rounds!</p>

<h2>Timeline</h2>

<p>There will be 3 rounds in the challenge. The first one (round 0) is a beta round and serves as an introduction to get familiar with Flatland (as well as bug fixing). Rounds 1 and 2 pose the actual problems to be solved. Submissions are only accepted for Round 1 and Round 2, both rounds will contribute to the final ranking. <strong>Round 2 is currently ongoing and will close on Sunday, 5th of January 2020, 12 PM, UTC +1.</strong></p>

<h3>Round 0: Learn to navigate (Beta Round)</h3>

<p>A single agent has to navigate from a freely chosen starting point to a freely chosen target destination on a random infrastructure. It is, in other words, a relatively simple shortest path problem.</p>

<p>There will be no uploading possibility, no ranking, nor any prizes to be gained in this round - but the collected insights make it all worth it!</p>

<p>Check out this simple <a href="https://gitlab.aicrowd.com/flatland/baselines/blob/master/torch_training/Getting_Started_Training.md">introduction to training</a> to get started with your own training on Flatland.</p>

<p><strong>The beta round starts on the 1st of July 2019 and ends on the 30th of July 2019</strong></p>

<figure><img alt="Round0" src="https://i.imgur.com/t5ULr4L.gif"></figure>

<h3>Round 1: Avoid conflicts</h3>

<p>We pick-up the same problem from the previous round and turn it into a multi-agent problem. This means, multiple agents have to find their ways to their respective target destinations. In this scenario you are likely to encounter resource conflicts when two or more agents simultaneously plan to occupy the same section of infrastructure. Thus, the agents have to learn to avoid conflicts and find feasible solutions. By timely submitting your solution and adhering to the <a href="#rules">participation rules</a> you are automatically eligible for the <a href="#prizes">Contribution Prize &amp; Best Agent Prize</a>. Good luck!</p>

<p><strong>Round 1 will open on Tuesday, 30th of July and close on Sunday, 13th of October 2019, 12 PM, UTC +1.</strong> <strong>Round 1 submissions closed early in order to start with Round 2 as early as possible.</strong> <strong>If you still want to test your code on earlier version please get in touch with us directly.</strong></p>

<figure><img alt="Round1" src="https://i.imgur.com/AvBHKaD.gif"></figure>

<p><strong>Round 2: Optimize train traffic</strong>: In reality, not all trains can go at the same speed. In round 2 we introduce additional complexity to the multi-agent-problem of round 1 by letting the trains have different speeds! Furthermore, stochastic events will occur during the episodes which mean that your controller will need to adapt to a changing environment. Key features of the updated environment are:</p>

<ul>
	<li>Agents travel at 4 different speeds.</li>
	<li>Some agents will experience malfunctions which render them immobile at times.</li>
	<li>Agents have to actively start their journey in the environment and leave the environment when they reach their target.</li>
</ul>

<p>This means that a good solution not only avoids/resolves conflicts, but also optimizes by taking into account that slower agents can slow down the faster ones. The prize is reserved for the winner who submits the solution with the minimal cumulated travel time for all agent. By submitting your solution timely and adhering to the <a href="#rules">participation rules</a>, you are automatically eligible for the <a href="#prizes">Contribution Prize &amp; Best Agent Prize</a>. Good luck!</p>

<figure><img alt="Round2" src="https://i.imgur.com/Pc9aH4P.gif"></figure>

<p><strong>Round 2 is now open and will close on Sunday, 5th of January 2020, 12 PM, UTC +1.</strong></p>

<h2>Environment</h2>

<p>There are a few important basic elements and notions specific to this challenge that you should be aware of before diving into the “Lets get started” section.</p>

<h3>Agent</h3>

<p>Flatland is a discrete time simulation, that means that all actions performed happen with a constant time step. At each step, the agents can choose an action. The term agent is defined as an entity that can move within the grid and must solve tasks - these agents are, who would have thought, trains. A train does basically two things: wait or go into a particular direction. Depending on the train type (e.g. freight train or passenger train), they have different speeds. An agent can move in any arbitrary direction (if the environment permits it) and transition from one cell to the next. If the agent chooses a valid action, the corresponding transition will be executed and the agent’s position and orientation is updated. Each agent has its individual start and target.</p>

<p>Agent at start:</p>

<figure><img alt="starting_agent" src="https://i.imgur.com/mXW7O3L.png"></figure>

<p>Target Destination:</p>

<figure><img alt="destination" src="https://i.imgur.com/NiSEryT.png"></figure>

<p>The cell where the agent is located at must have enough capacity to hold …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aicrowd.com/challenges/flatland-challenge">https://www.aicrowd.com/challenges/flatland-challenge</a></em></p>]]>
            </description>
            <link>https://www.aicrowd.com/challenges/flatland-challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829991</guid>
            <pubDate>Tue, 14 Jul 2020 09:24:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Decision Trap for Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829988">thread link</a>) | @KingOfCoders
<br/>
July 14, 2020 | https://www.svese.de/essay/the-decision-trap-for-developers-in-startups | <a href="https://web.archive.org/web/*/https://www.svese.de/essay/the-decision-trap-for-developers-in-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When I was joining a startup with plans to replace the CTO, there was a relaunch going on. I’ve talked to people and no one seemed happy. Developers were unhappy and helpless and the founders were also unhappy with the relaunch. I’ve heard it had being going on since months. The whole company couldn’t understand why tech didn’t deliver. Digging deeper I found over 150 open bugs in a small team, a founder who changed the design every week and a product manager sandwiched between the unhappy founder and the unhappy developers. I forced the founder to make a lasting decision, we fixed or closed all of the bugs and delivered a new website. The founder team, developers and I were happy, not to speak of the product manager.</p><p>Developers are trapped in a cycle of bad decision making in startups. Companies are bad at making decisions. Founders and executives treat decisions as a way to show leadership, the woman or man at the helm being able to decide about the future of the company. Creative visionaries come up with new ideas and decisions to build new products every day, changing direction on a whim in the chase for customers and investor satisfaction. Developers bear the brunt. They believe a process around decisions in startups and companies is not of their concern. They only need to execute. Tell me what I should code. </p><p>I hear from founders and CEOs who want to speed up development because they have the perception technology is slow. With the abundance of knowledge on processes, lean development and of-the-shelf technology this is unlikely. The perception of development being slow is the impact of a bad decision process in startups. For development the negative consequences are time pressure, constantly changing requirements, ongoing reprioritizations and therefor even more pressure and blame. </p><p>We will investigate why decision making is broken, what consequences this has for developers and CTOs and how to fix it.</p><p>0.</p><p><em>“Our research shows that the difference between leaders who make good decisions and those who make bad ones is striking. The former recognize that all decisions are processes, and they explicitly design and manage them as such.” </em><br>David A. Garvin and Michael A. Roberto in HBR</p><p>To many people decision making is an event, while decision making is a process. This perception causes several bad side effects. The most important one is that their decision has not the intended effects. Founders wonder why after taking a decision, the company does not change. Why after taking a decision they get a lot of discussion instead of people executing their decision towards success.</p><p>‍</p></div><div><p>How does one change this? How would a decision process look if done right? </p><p>The four steps of a decision process are:</p><ol start="" role="list"><li>Prepare</li><li>Make</li><li>Rollout</li><li>Enforce</li></ol><p>Let us look into each phase in more detail. I’ll show how mistakes in all four phases have impact on software developers and CTOs.</p><p>1.</p><p>The first phase is ‘prepare a decision’. Preparing a decision means getting the facts and information that are needed to make a decision. It also means getting feedback and the mood from stakeholders about the decision. If you surprise people with a decision, you have done it wrong. If as a founder you want to make a decision, ask your management team before what they think about it. First in a team meeting and then in one-on-one discussions with your managers. Get the buy-in from everyone that a decision needs to be made. Make sure everyone knows if the decision is to be a team decision or something a founder or managers decides.</p><p>Without the right preparation, managers make wrong assumptions, miss key parts of the decisions or do not think about consequences. Bad preparation leads to features in development that take too long, are too complicated, hard to maintain or not worth the effort. If a decision has large infrastructure impacts, feature implementation will take a long time. Cost and time pressure is put on the CTO because of badly prepared decisions.</p><p>2.</p><p>The second phase is ‘making the decision’. When you have the buy-in from everyone and all the information you need, it is time to decide. Decisions with consequences are hard to make with all the options on the table. For this managers postpone decisions to not lose options and commit themselves. If you have all the information and you have the feedback from people, make the decision and do not delay it. Break the pattern to move the decision to next week’s management meeting because of the desire to not constrain yourself. Make the decision as fast and as early as possible despite the fear of making the wrong one. A mistake I often see around making decisions: it is unclear on how decisions are made and who makes them. Introducing a decision framework like RACI helps here. It defines roles people have:</p><ul role="list"><li>R = Responsible: The person or people to successfully execute the decision</li><li>A = Accountable: The person or people who make the decision</li><li>C = Consulted: People who are asked for input to the decision</li><li>I = Informed: People informed about the decision</li></ul><p>This way roles are clear, and it is clear who makes a decision e.g. the CEO, CTO, Head of Product or the group. Otherwise people often confuse their role of giving input and with making a decision.<br>Not making a decision has bad consequences for development and CTOs. All the time lost prolonging the decision is put on development as pressure to speed up development. Donald G. Reinertsen shows in “Developing Products in Half the Time” that half of the time to market is lost in the “fuzzy frontend” before development even starts. If I consult a company, I tell people it is hard to cut 10% out of development time with already agile and lean development departments, but it is easy to cut 50% out of pre-development time. Every second after an idea is found in a company is as precious as a second in the last week before launch. People treat these differently though. Time in the decision making phase is treated as an unlimited resource and time in crunch mode before release is treated as gold. The most urgent job for a CTO is to have a decision process in place and force fast decisions to make his life happier. It helps to write down the dates of when an idea is new and when development starts to optimize lead times.</p><p>3.</p><p>While some people are at least able to make timely decisions, they fail miserably at rolling them out. Decisions are made, decisions are communicated by email or in all-hands meetings and decision makers expect the course of the company to change. They do not understand that after making a decision the most important next step is rolling it out. Every important decision involves change management. Rolling out a decision means communicating the decision, explain the decision, explain why alternatives have not been chosen, explain what the decision means for the company, departments and employees. Transparency about the decision, the reasons that the decision was made the way it went is paramount to success. Every decision needs to be explained in one-on-ones to make it stick, let people vent their feelings, get feedback and the buy-in from those carrying it out. Proclaiming you have decided something will not make the decision stick and will result in a disaster. The company ignores your decision and just carries on. Founders feel frustrated and react with pressure on execution. </p><p>When not rolling out a decision and explaining the circumstances, people have different perceptions about it, how to interpret it, what it means for them, the state of the company, what is important and what to focus on. This creates increased friction all over the company. As development needs to work with many parts of the company, it is highly impacted by high friction and differing &nbsp;assumptions and perceptions. If a company has a decision process with good rollout practices friction is minimized and development speed is increased. High friction leads to low development speed which is blamed on developers and CTOs. </p><p>4.</p><p>The last phase of decision making is enforcement. There are many people who will not be happy with your decision.</p><p><em>"Surely a decision is a decision?" "Only if it's the decision you want. If not, it's just a temporary setback." Sir Humphery, Yes Minister.</em></p><p>They will ignore it or try to reopen it. There are many ways to do so. Managers will sabotage decisions if they don’t like them and you don’t act. They agree with the decision but do not carry it out. After a decision has been made in a meeting, next week people will claim “This is not the way how I have perceived this. We haven’t made a clear decision.” People act just as if you haven’t made a decision at all. </p><p>After making a decision and rolled it out, it’s time to enforce it. Every decision has to be recorded in meeting notes or in other forms to make it clear to everyone that a decision has been made, how the decision looks and misunderstandings are reduced. Without writing it down people will leave a meeting and everyone has a different understanding and takeaway. If people show tendencies to counteract your decision, bring them back on the right path. Explain the decision again. Then explain it even more. Remind people of the decision. Pull out the meeting notes. There will be opposition from many people who had a different opinion. After you’ve made every effort to convince them and take them with you, it’s the managers and founders duty to enforce the decision. </p><p>Because the effects of a decision often cannot be seen immediately, people reopen decisions too early. If there is no new important information, don’t reopen decisions. Stick to them until you clearly see you have to change them. Change decisions as soon as needed but not earlier. Flip flopping decisions creates confusion and frustration.</p><p>Changing a decision is easy and involves not a lot of work. But the more your work is down the execution chain, the bigger the impact. A dog tail wiggles only slightly at its base but furiously at its tip.</p><p>When a decision is not enforced, it leads to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.svese.de/essay/the-decision-trap-for-developers-in-startups">https://www.svese.de/essay/the-decision-trap-for-developers-in-startups</a></em></p>]]>
            </description>
            <link>https://www.svese.de/essay/the-decision-trap-for-developers-in-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829988</guid>
            <pubDate>Tue, 14 Jul 2020 09:24:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Report on zero-knowledge blockchain scalability]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829951">thread link</a>) | @ArlietaBex
<br/>
July 14, 2020 | https://ethworks.io/ethereum-scaling-report | <a href="https://web.archive.org/web/*/https://ethworks.io/ethereum-scaling-report">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
    <header>
    
  </header>
    
    <section>
  <div>
    
    <div>
      
      <p>Our extensive report on Ethereum scaling <br> will help you:</p>
      <ul>
        <li>
          <span>demystify the buzz around Ethereum layer 2 solutions,</span>
        </li>
        <li>
          <span>understand the potential of the zero-knowledge technology,</span>
        </li>
        <li>
          <span>choose your perfect-match solution and scale your product.</span>
        </li>
      </ul>

      

      <p>
        Don't want to share your email? Download our zero-knowledge scaling report directly <a href="https://ethworks.io/assets/download/zero-knowledge-blockchain-scaling-ethworks.pdf" download="">here</a>. <br>
        By clicking "download" you agree to add your email address to our subscriber list. <br>
        You'll occasionally receive updates about new reports and other resources from Ethworks.
      </p>
    </div>
  </div>
  <p><img src="https://ethworks.io/assets/images/rectangles/r1.svg" alt="Background accent">
    <img src="https://ethworks.io/assets/images/rectangles/r2.svg" alt="Background accent">
    <img src="https://ethworks.io/assets/images/rectangles/r3.svg" alt="Background accent">
  </p>
</section>
<section>
  <div>
    <div>
      <div>
        <h2>Table of Contents</h2>
        <p>Ethereum scaling has been a topic of hot discussion for some time,
          but looks like now, things are finally about to change. The concept of generating a zero-knowledge proof for offloading the blockchain may be a real game-changer. Our extensive research on zero knowledge Ethereum scaling will help you understand why.</p>
      </div>
      <ul>
        <li>
          <h3>01. Introduction	</h3>
          <p>Oh, Boy… Scaling Again... <br>
            Report Contents	</p>
        </li>
        <li>
          <h3>02. Zero Knowledge</h3>
          <p>Real-Life Example <br>
            Zero Knowledge and Blockchain <br>
            SNARKs vs. STARKs </p>
        </li>
        <li>
          <h3>03. Architectures</h3>
          <p>Data Availability Problem <br>
            zkRollup <br>
            Validium <br>
            Volition </p>
        </li>
        <li>
          <h3>04. Technologies	</h3>
          <p>zkSync <br>
            StarkEx <br>
            Loopring	</p>
        </li>
        <li>
          <h3>05. Summary	</h3>
        </li>
        <li>
          <h3>06. About Authors</h3>
          <p>Acknowledgements</p>
        </li>
      </ul>
    </div>
  </div>
</section>




    

    

  </div><div>
  <div>
    <p>I agree to and accept that ETHworks Sp. z o.o. will collect, make automatic decisions
      about, analyze and catalog information about Internet electronic addresses which have connected with the device I
      have used, information about the type of the device I have used, including the type and version of software
      installed on the device, for the purpose of determining my Internet activities (the user profile). Automatic
      decision-making does not involve sensitive data. The agreement is in force for the period when it is legally
      binding, or until a Party withdraws from the agreement. Withdrawing from the agreement shall result in removing
      the user’s profile.</p>
    </div>
</div></div>]]>
            </description>
            <link>https://ethworks.io/ethereum-scaling-report</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829951</guid>
            <pubDate>Tue, 14 Jul 2020 09:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instant Cloud Functions Deployment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829702">thread link</a>) | @antho1404
<br/>
July 14, 2020 | https://liteflow.com/functions | <a href="https://web.archive.org/web/*/https://liteflow.com/functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="pay">
        <div>
          <h2>Pay only for the executions your app uses</h2>
          
        </div>
        
        <div>
          <div>
            <table data-type="freenium">
              <thead>
                <tr>
                  <th colspan="5">
                    Free Quota per month included in every account on Liteflow
                  </th>
                </tr>
                <tr>
                  <th>Function</th>
                  <th></th>
                  <th>Invocation</th>
                  <th>Duration<span>In second</span></th>
                  <th>Data<span>In kilobyte</span></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Tasks</td>
                  <td>Execute</td>
                  <td>10k</td>
                  <td>10k</td>
                  <td>10k</td>
                </tr>
              </tbody>
            </table>
            <table data-type="ondemand">
              <thead>
                <tr>
                  <th colspan="5">
                    Function's cost table (only for upgraded account)
                  </th>
                </tr>
                <tr>
                  <th>Function</th>
                  <th></th>
                  <th>Invocation<span>Per execution</span></th>
                  <th>Duration<span>Per second</span></th>
                  <th>Data<span>Per kilobyte</span></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Tasks</td>
                  <td>Execute</td>
                  <td>$0.000004</td>
                  <td>$0.0002</td>
                  <td>$0.000001</td>
                </tr>
              </tbody>
            </table>
          </div>
          
        </div>

        <p>
          <h3>Frequently Asked Questions</h3>
        </p>

        <div>
          <div>
            <h4>How do I know Liteflow is right for me?</h4>
            <p>
              Liteflow is designed for early-stage Lean startups. Every account
              includes a Free Quota for every services' executions, allowing you
              to run small-to-medium apps without having to pay anything.
            </p>
          </div>
          <div>
            <h4>Do I need a credit card to start using Liteflow?</h4>
            <p>
              No, Liteflow is completely free to start using and don't require
              your credit card upfront. You will be able to upgrade your account
              when reaching the monthly Free Quota limits.
            </p>
          </div>
        </div>
        <div>
          <div>
            <h4>What happens if I reach the monthly Free Quota limits?</h4>
            <p>
              We will warn you with a message in the console and by email,
              inviting you to enter a payment method to continue running your
              app on Liteflow. If you decide to not upgrade your account, we
              will shut off your app for the remainder of that month.
              <strong>No surprise billing!</strong>
            </p>
          </div>
          <div>
            <h4>What kind of support will I receive?</h4>
            <p>
              All apps hosted on Liteflow come with email and Intercom support
              from the Liteflow team during Southeast Asia business hours. We
              provide unlimited support to help you grow your business with
              Liteflow.
              <strong>For paid accounts, a one-to-one video call support is
                available.</strong>
            </p>
          </div>
        </div>
      </section>
    </div></div>]]>
            </description>
            <link>https://liteflow.com/functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829702</guid>
            <pubDate>Tue, 14 Jul 2020 08:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get the Most Out of Google Cloud Next: OnAir]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829697">thread link</a>) | @wedge14
<br/>
July 14, 2020 | https://www.contino.io/insights/google-cloud-next-onair | <a href="https://web.archive.org/web/*/https://www.contino.io/insights/google-cloud-next-onair">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>Due to current circumstances, the usual Google Cloud Next events have been moved online to <a href="https://cloud.withgoogle.com/next/sf/">Google Cloud Next: OnAir</a>. This updated format runs over a nine-week period, delivering a digital event focused on a different topic weekly – <strong>every Tuesday from 14 July </strong>– aptly named “OnAir”.</p>
<h4>The Agenda-at-a-Glance</h4>
<ul><li><strong>WEEK ONE:</strong> Industry Insights
</li><li><strong>WEEK TWO: </strong>Productivity &amp; Collaboration
</li><li><strong>WEEK THREE:</strong> Infrastructure
</li><li><strong>WEEK FOUR: </strong>Security
</li><li><strong>WEEK FIVE: </strong>Data Analytics
</li><li><strong>WEEK SIX: </strong>Data Management &amp; Databases
</li><li><strong>WEEK SEVEN: </strong>Application Modernization
</li><li><strong>WEEK EIGHT: </strong>Cloud AI
</li><li><strong>WEEK NINE: </strong>Business Application Platform
</li></ul>
<h4>What to Expect From the Sessions</h4>
<p>The event is <strong>free of charge</strong>, and will provide a <a href="https://cloud.withgoogle.com/next/sf/sessions#industry-insights">wide range of session styles</a>: from industry highlights from Google Cloud executives, breakout sessions, expert tutorials and interactive programs such as Study Jams, the Cloud Hero game and gamified hands-on labs, through to Q&amp;A sessions and live technical discussions with the Google Cloud Developer Relations team. It will also include real world examples where customers will tell their digital transformation stories and how they’re using Google Cloud to solve problems and achieve their objectives more quickly.
</p>
<p>When registering, participants will gain <strong>one month’s free access</strong> to curated Google Cloud learning paths on <a href="https://www.qwiklabs.com/">Qwiklabs</a> &amp; <a href="https://www.pluralsight.com/">Pluralsight</a>, which provide great resources to help with preparation for certification exams.
</p>
<p>There are<strong> over 200 talks</strong> for attendees to take in between July and September - in addition to the Keynotes with Google Cloud CEO Thomas Kurian - so to help you break it down we’ve picked the best, so you can skip the rest!
</p>
<h4>Our Top Picks: What Not to Miss at Google Cloud Next 2020</h4>
<p>Next OnAir has a very exciting <a href="https://cloud.withgoogle.com/next/sf/speakers">list of speakers</a>, including customers and Google engineers sharing their insights. During his keynote presentation, Thomas Kurian will share insights on how businesses can leverage cloud technology to build for the future and adapt to complexities, challenges, and opportunities. Definitely one not to miss!</p>
<p>But there are many more sessions to watch out for in addition to the Keynotes.</p>
<p>At Contino, we support our customers across <a href="https://youtu.be/0wFHMirluYg">Five Core Pillars</a> which reflect the cardinal directions of transformative activity for businesses regardless of specific roles, and as such, we’ve picked out a few key sessions that align to each of these pillars. </p>
<figure><a href="https://youtu.be/0wFHMirluYg" target="_blank"><img src="https://www.contino.io/images/five-pillars.png" alt="Contino Five Core Pillars" title="Contino Five Core Pillars"></a></figure>
<h5><br>Cloud Platform Build and Migration</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=NET101%20#infrastructure" target="_blank">Hybrid Networking for Millions of Users with GCP #TwitterEng</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=ARC219%20#infrastructure" target="_blank">Building a Large Scale Migration Factory to Google Cloud</a>
</li></ul>
<p>If you find these sessions useful, make sure to check out:
</p>
<ul><li><a href="https://youtu.be/-8n3eQ-YdMM" target="_blank">Contino CloudFest: Reliability Engineering in the Enterprise</a>
</li></ul>
<h5>Enterprise DevOps Transformations
</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=OPS302%20#infrastructure" target="_blank">Monitoring as Code</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=OPS214%20#infrastructure" target="_blank">Mindful Testing: Balancing Test Coverage and Maintenance</a>
</li></ul>
<p>For more on enterprise transformation, we have two webinars you might like that dive a little deeper:
</p>
<ul><li><a href="https://youtu.be/2eVO_ttyzzI" target="_blank">Contino CloudFest: Why You Need to Invest in Digital Transformation NOW</a>
</li><li><a href="https://youtu.be/5Iqd4izIV34" target="_blank">Contino CloudFest: The Future is FinOps</a>
</li></ul>
<h5>DevSecOps and Cloud Security
</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=SOLKEY205#security" target="_blank">Complexity Hurts, Simplicity Wins: Operating Securely in a Harsh New World</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=SEC302#security" target="_blank">Advanced IAM: Hacks, Tips, and Tricks for Policy Management</a>
</li></ul>
<p>We’ve seen customers adopt SRE as a means to embed security in everything they do. Check out the following Contino webinar for more information:
</p>
<ul><li><a href="https://youtu.be/buqz_4LK57c" target="_blank">Contino CloudFest: Boost Your Apps with an SRE approach to development</a>
</li></ul>
<h5>Cloud-Native Software Development
</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=APP311#application-modernization" target="_blank">Ensuring Business Continuity at Times of Uncertainty and Digital-only Business with GKE</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=OPS301#application-modernization" target="_blank">Analyzing Distributed Traces to Find Performance Bottlenecks</a>
</li></ul>
<p>The real value in cloud adoption is to break the shackles of on-premise approaches and embrace cloud-native technologies and methodologies. It’s not always easy to do, as our recent webinar below&nbsp;illustrates!
</p>
<ul><li><a href="https://youtu.be/R9CjnitC2ZM" target="_blank">Contino CloudFest: Kubernetes is Hard</a>
</li></ul>
<p>You might also be interested in our latest white paper, <a href="https://www.contino.io/resources/cloud-native">The Ultimate Guide to Cloud-Native: Breaking Out of On-Prem Prison.</a>
</p>
<h5>Data Platforms and Analytics
</h5>
<ul><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=DA233#data-analytics" target="_blank">Don’t Sweat The Big Stuff. Make It Google’s Problem.</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=DA238#data-analytics" target="_blank">Using Google Cloud to Serve 10,000s of Personalized Recs Per Second</a>
</li><li><a href="https://cloud.withgoogle.com/next/sf/sessions?session=AI212#cloud-ai" target="_blank">An Introduction to MLOps on Google Cloud</a>
</li></ul>
<p>From adopting a data strategy to pipelines, analytics, AI &amp; ML, no business can afford to stand still, with some of the biggest challenges associated with a change in the way data is perceived. The following webinar might be useful for those who’ve taken in these sessions:
</p>
<ul><li><a href="https://youtu.be/ivb6QGskEro" target="_blank">Contino CloudFest: Adopting a Data-Driven Approach.</a>
</li></ul>
<p><em>If you attend a session, or read our suggested additional content and it raises questions, why not email us at&nbsp;<a href="https://www.contino.io/cdn-cgi/l/email-protection#fe969b929291be9d91908a979091d09791"><span data-cfemail="2c44494040436c4f434258454243024543">[email&nbsp;protected]</span></a>&nbsp;to arrange a discussion with our Google Cloud Platform experts?</em></p>
<h5>Looking for More?
</h5>
<p>When Google Next was originally planned for face-to-face in San Francisco, we were delighted to secure a presentation slot for Contino’s very own Mihnea Spirescu. Due to the refactoring of the event, the partner sessions unfortunately didn’t make the final schedule. However, Contino is very excited to announce a new partnership with <a href="https://www.meetup.com/gdgcloud/">Google Developer Group Cloud London</a> Meetup Group, where on Thursday 16th July, Mihnea has the pleasure of delivering our inaugural group talk on Cloud Run, which ties in well with Google Next OnAir ‘20 where this topic will be covered in some depth.&nbsp;</p>
<p>With over 7,000 members, the group is certainly one of the more active engineering groups on the meetup platform, conducting several hacks and workshops each month, as well as general talks. More info on Mihnea’s talk and registration for the event can be found here: <a href="https://www.meetup.com/gdgcloud/events/271677336/">Cloud Run: Overcoming the challenges of building &amp; deploying Serverless Apps</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://www.contino.io/insights/google-cloud-next-onair</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829697</guid>
            <pubDate>Tue, 14 Jul 2020 08:27:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Rust NIFs for Elixir with Rustler]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23829651">thread link</a>) | @marcoow
<br/>
July 14, 2020 | https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/ | <a href="https://web.archive.org/web/*/https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>Rustler is a fantastic project built to make writing Rust NIFs a simple process;
and the upcoming v0.22 release will provide a much cleaner syntax to do so. The
library handles encoding and decoding Rust values into Erlang terms, catches
Rust panics before they unwind to C and <em>should</em> make it impossible to crash the
BEAM from a Rust NIF.</p>
<h2 id="getting-started-with-rustler">Getting started with Rustler</h2>
<p>One of my first forays into Rust-implemented NIFs was while building a
micro-library providing Base64 encoding and decoding, creatively named
<a href="https://github.com/niklaslong/base64" target="_blank" rel="noopener">base64</a>. It's utterly pointless as that
functionality comes built-in to Elixir but I wanted to start with something
simple. On the plus side, this meant I could easily compare the performance of
the NIF version to the Elixir implementation which can be found in the
<a href="https://hexdocs.pm/elixir/Base.html" target="_blank" rel="noopener"><code>Base</code> module</a>.</p>
<p>The library consists of two functions: <code>encode/2</code> and <code>decode/2</code> and it's using
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64</a> to do the heavy
lifting in the NIFs. Let's walk through how this all works.</p>
<p>To get started, we need a new mix project with rustler installed as a
dependency.</p>
<pre><code>mix new base64

mix deps.get
mix rustler.new
</code></pre><p>Let's explore the project's resulting structure (I've left out the usual Elixir
files and directories and focused on <code>lib</code> and <code>native</code>):</p>
<pre><code>.
â”œâ”€â”€ lib
â”‚   â””â”€â”€ base64.ex
â””â”€â”€ native
    â””â”€â”€ base64_nif
        â”œâ”€â”€ Cargo.lock
        â”œâ”€â”€ Cargo.toml
        â”œâ”€â”€ README.md
        â””â”€â”€ src
            â””â”€â”€ lib.rs</code></pre><ul>
<li><code>lib</code> will contain Elixir code (like any standard mix project).</li>
<li><code>base64.ex</code> will contain the stubs to our NIFs. This is the Elixir module the
NIF module will be registered to.</li>
<li><code>native</code> will be home to the Rust code. In fact, a cargo package has been
created within this directory (in this case named <code>base64_nif</code>).</li>
<li><code>lib.rs</code> will contain the NIFs.</li>
</ul>
<p>The Rust NIFs are compiled and linked into a shared library loaded by Erlang
code at runtime. Elixir (or Erlang) implementations of the functions are also
necessary. These are usually minimal stubs defining the name and arity of the
NIFs and serve as fallback implementations if the NIFs aren't loaded. Let's
start with the Elixir stubs.</p>
<pre><code>

<span><span>defmodule</span> <span>Base64</span></span> <span>do</span>
  <span>use</span> Rustler, <span>otp_app:</span> <span>:base64</span>, <span>crate:</span> <span>"base64_nif"</span>

  <span>@spec</span> decode(binary, atom) :: binary
  <span><span>def</span> <span>decode</span></span>(_b64, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span>@spec</span> encode(binary, atom) :: binary
  <span><span>def</span> <span>encode</span></span>(_s, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span><span>defp</span> <span>error</span></span>(), <span>do:</span> <span>:erlang</span>.nif_error(<span>:nif_not_loaded</span>)
<span>end</span></code></pre><p>The first line is configuration and lets Rustler know what Rust crate to compile
for the Elixir module.</p>
<p>As mentioned above, <code>decode/2</code> and <code>encode/2</code> don't actually implement any
decoding or encoding; they simply call <code>error/0</code> if the NIFs can't be found.
However, the names and the arguments must match in both the Rust and Elixir
implementations. Both functions take in a <code>binary</code> to be encoded or decoded and
an <code>atom</code> for configuration as different character sets that can be used
(url-safe, without padding, etc...). The default is fittingly set to
<code>:standard</code>. The Rust NIFs are implemented as follows.</p>
<pre><code>

<span>use</span> base64;
<span>use</span> rustler::Atom;

<span>mod</span> atoms {
    rustler::atoms! {
      crypt,
      imap_map7,
      standard,
      standard_no_pad,
      url_safe,
      url_safe_no_pad,
    }
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>decode</span></span>(b64: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    <span>let</span> bytes = base64::decode_config(b64, config).expect(<span>"decode failed: invalid b64"</span>);

    <span>String</span>::from_utf8(bytes).unwrap()
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>encode</span></span>(s: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    base64::encode_config(s.as_bytes(), config)
}

<span><span>fn</span> <span>match_config</span></span>(option: Atom) -&gt; base64::Config {
    
}

rustler::init!(<span>"Elixir.Base64"</span>, [decode, encode]);</code></pre><p>The last line is interesting: <code>rustler::init</code> is a procedural macro that allows
the use of <code>#[rustler::nif]</code> to annotate functions to be wrapped as NIFs. It
takes in the name of the Elixir module in which the stubs are defined (in this
case <code>"Elixir.Base64"</code>) and an array containing the names of the functions
annotated as NIFs (in this case <code>[decode, encode]</code>). In short, this links
everything together.</p>
<p>The use statements at the top of the file are importing the
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64 crate</a> (<code>base64</code>)
mentioned earlier, which we'll use for encoding and decoding, and the
<code>rustler::Atom</code> type which allows us to represent an Elixir/Erlang <code>atom</code> in
Rust. Both the <code>rustler</code> and <code>base64</code> crates have been added to the <code>Cargo.toml</code>
dependencies.</p>
<p>The <code>rustler::atoms</code> macro defines Rust functions that return Erlang atoms; in
this case, the possible options for the <code>encode/2</code> and <code>decode/2</code> functions.</p>
<p>Finally, we come to the NIF definitions. The functions take in a <code>String</code> and a
<code>rustler::Atom</code>, and return a <code>String</code>. This is consistent with the Elixir
stubs, as are the names. In this case, the conversions between Rust values and
Elixir terms are conveniently handled by Rustler. However, for more complex
types, this may need to be implemented manually.</p>
<h2 id="how-does-it-compare-to-the-elixir-implementation">How does it compare to the Elixir implementation?</h2>
<p>Rust is fast. Really fast. This was my set-up (using
<a href="https://github.com/bencheeorg/benchee" target="_blank" rel="noopener">benchee</a>):</p>
<pre><code>Operating System: macOS
CPU Information: Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz
Number of Available Cores: 4
Available memory: 16 GB
Elixir 1.10.2
Erlang 22.3.2</code></pre><p>I used <em>hello world</em> as the short string and Sarah Kayâ€™s poem
<em><a href="https://www.youtube.com/watch?v=0snNB1yS3IE" target="_blank" rel="noopener">B (If I Should Have a Daughter)</a></em>
as the longer string.</p>
<p>Decoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif decode           175.74 K
Elixir/Erlang decode        4.35 K - 40.37x slower +224.03 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif decode           953.17 K
Elixir/Erlang decode      555.63 K - 1.72x slower +0.75 Î¼s</code></pre><p>Encoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif encode           203.14 K
Elixir/Erlang encode        6.95 K - 29.23x slower +138.98 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif encode           941.14 K
Elixir/Erlang encode      615.62 K - 1.53x slower +0.56 Î¼s</code></pre><p>As the data to encode or decode becomes larger, the overhead of creating the
NIFs becomes smaller and the gains in speed are impressive. These results were
obtained with fairly small data and so the potential performance gains possible
by leveraging Rust NIFs when dealing with CPU-intensive tasks are exciting.</p>
<p>I left out the memory usage comparisons but the Elixir/Erlang implementations
used 3-5x more memory than the NIFs.</p>
<h2 id="tldr-rustler-makes-it-easy-to-implement-nifs">TL;DR: Rustler makes it easy to implement NIFs</h2>
<p>Other than the <code>#[rustler::nif]</code> function annotations and the <code>rustler::init</code>
call, nothing more is required to implement Rust NIFs with Rustler. The
boilerplate and the complexities of translating Rust values to Erlang terms
being handled by the library, there's little resistance to leveraging the power
of Rust in Elixir/Erlang.</p>

  </div></div>]]>
            </description>
            <link>https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829651</guid>
            <pubDate>Tue, 14 Jul 2020 08:16:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Instant Customizable RDBMS Vue UI in 20kb Gist Desktop App]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23829512">thread link</a>) | @mythz
<br/>
July 14, 2020 | https://sharpscript.net/sharp-apps/sharpdata | <a href="https://web.archive.org/web/*/https://sharpscript.net/sharp-apps/sharpdata">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://github.com/NetCoreApps/SharpData">SharpData</a> is a generic app for providing an instant UI around multiple RDBMS's:</p>
<blockquote>
<p>YouTube: <a href="https://youtu.be/GjVipOqwZMA" rel="nofollow">youtu.be/GjVipOqwZMA</a></p>
</blockquote>
<p><a href="https://youtu.be/GjVipOqwZMA" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-custom-appsettings.png" alt=""></a></p>
<p>It makes use of the <a href="https://docs.servicestack.net/netcore-windows-desktop" rel="nofollow">app</a> dotnet tool for running Chromium
<a href="https://sharpscript.net/sharp-apps/gist-desktop-apps" rel="nofollow">Gist Desktop Apps</a> on-the-fly without installation, from a single URL that can also
<a href="https://docs.servicestack.net/mix-tool" rel="nofollow">mix in additional gists</a> which can be used in SharpData to configure RDBMS's, copy SQLite databases and
apply per-database customizations to add navigable deep links and customized UI Views to each table resultset.</p>
<p>Whilst SharpData supports <a href="https://github.com/ServiceStack/ServiceStack.OrmLite#8-flavours-of-ormlite-is-on-nuget">connecting to most popular RDBMS's</a>, it's
especially useful for being able to deploy an instant stand-alone UI with an embedded SQLite databases which can be published independently in a gist and
launched from a single URL.</p>
<p>For an example of this in action we've published customized gists for the
<a href="https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/linq/downloading-sample-databases" rel="nofollow">Northwind</a> and
<a href="https://www.sqlitetutorial.net/sqlite-sample-database/" rel="nofollow">Chinook</a> SQLite databases which after installing the latest
<a href="https://docs.servicestack.net/netcore-windows-desktop" rel="nofollow">app</a> dotnet tool:</p>
<pre><code>$ dotnet tool install -g app
$ app -version
</code></pre>
<p>First time <code>app</code> is run it registers the <a href="#app-url-schemes">app:// URL scheme</a> allowing Windows x64 Desktop Apps to be launched from URLs:</p>
<ul>
    <li><strong><a name="app://sharpdata?mix=northwind.sharpdata">app://sharpdata?mix=northwind.sharpdata</a></strong></li>
    <li><strong><a name="app://sharpdata?mix=chinook.sharpdata">app://sharpdata?mix=chinook.sharpdata</a></strong></li>
</ul>
<p>Or via command-line:</p>
<pre><code>$ app open sharpdata mix northwind.sharpdata
$ app open sharpdata mix chinook.sharpdata
</code></pre>
<p>Cross platform using the <a href="https://docs.servicestack.net/dotnet-tool" rel="nofollow">x dotnet tool</a> (in Default Browser):</p>
<pre><code>$ x open sharpdata mix northwind.sharpdata
$ x open sharpdata mix chinook.sharpdata
</code></pre>
<p>Each of these options will download &amp; run the latest version of <a href="https://github.com/NetCoreApps/SharpData">SharpData</a> along with a
copy of the <a href="https://gist.github.com/gistlyn/0ce0d5b828303f1cb4637450b563adbd">northwind.sharpdata</a> or
<a href="https://gist.github.com/gistlyn/96b10369daf94897531810841cb097f2">chinook.sharpdata</a> gists on-the-fly containing the embedded SQLite DB along with any
UI customizations.</p>
<h4>
Hosted as a .NET Core App</h4>
<p>As <a href="https://github.com/NetCoreApps/SharpData">NetCoreApps/SharpData</a> is also a standard .NET Core project, it can also be deployed as a
normal stand-alone .NET Core Web App:</p>
<h3>
<a href="https://sharpdata.netcore.io/" rel="nofollow">https://sharpdata.netcore.io</a>
</h3>
<h3>
Tiny footprint</h3>
<p>An impressively capable .NET Core App that fits into a tiny <strong>20kb .zip</strong> footprint thanks to <a href="https://sharpscript.net/gist-desktop-apps">Gist Desktop App's Architecture</a>. It's small dynamic <code>#Script</code> &amp; Vue TypeScript code-base also makes it highly customizable to tailor &amp; further extend with
App-specific requirements - suitable for offering advanced system users a quick, capable customized read-only UI of your DBs.</p>
<p><strong>SharpData</strong> started as a demonstration showing how productive <a href="https://sharpscript.net/" rel="nofollow">#Script</a> can be in the number of areas where
dynamic languages offer far superior productivity then the typical .NET approach of using C# to type an entire code-base &amp; models.</p>
<p>For example a single <code>#Script</code> page provides a lot of the functionality in <a href="https://docs.servicestack.net/autoquery-rdbms" rel="nofollow">AutoQuery</a> where it provides an instant HTTP API
(in all registered ServiceStack formats) around all registered RDBMS tables, in all OrmLite supported RBDMS's, that includes support for custom fields,
multiple querying options, paging, multi OrderBy's in a parameterized SQL query executed with OrmLite's SQL async DB APIs:</p>
<h2>
AutoQuery Script</h2>
<h3>
<a href="https://github.com/NetCoreApps/SharpData/blob/master/wwwroot/db/_db/_table/index.html">/db/_db/_table/index.html</a>
</h3>
<pre><code>{{ {namedConnection:db} |&gt; if (db &amp;&amp; db != 'main') |&gt; useDb }}

```code|quiet
var ignore = ['db','fields','format','skip','take','orderBy']
var fields = qs.fields ? qs.fields.split(',').map(x =&gt; sqlQuote(x)).join(',') : '*'
var sql = `SELECT ${fields} FROM ${sqlQuote(table)}`
var filters = []
var queryMap = qs.toObjectDictionary().withoutKeys(ignore)
#each queryMap.Keys.toList()
    var search = queryMap[it.sqlVerifyFragment()].sqlVerifyFragment();
    #if search == '=null' || search == '!=null'
        `${sqlQuote(it)} ${search=='=null' ? 'IS' : 'IS NOT'} NULL` |&gt; addTo =&gt; filters
        queryMap[it] = null
    else if search.startsWith('=')
        `${sqlQuote(it)} = @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(1).coerce()
    else if search.startsWith('&lt;=') || search.startsWith('&gt;=') || search.startsWith('!=')
        `${sqlQuote(it)} ${search.substring(0,2)} @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(2).coerce()
    else if search.startsWith('&lt;') || search.startsWith('&gt;')
        `${sqlQuote(it)} ${search.substring(0,1)} @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(1).coerce()
    else if search.endsWith(',')
        `${sqlQuote(it)} IN (${search.trimEnd(',').split(',').map(i=&gt;i.toLong()).join(',')})` |&gt;addTo=&gt;filters
        queryMap[it] = null
    else if search.startsWith('%') || search.endsWith('%')
        `${sqlQuote(it).sqlCast('varchar')} LIKE @${it}` |&gt; addTo =&gt; filters
    else
        `${sqlQuote(it).sqlCast('varchar')} = @${it}` |&gt; addTo =&gt; filters
    /if
/each
#if !filters.isEmpty()
    sql = `${sql} WHERE ${filters.join(' AND ')}`
/if
#if qs.orderBy
    sql = `${sql} ORDER BY ${sqlOrderByFields(qs.orderBy)}`
/if
#if qs.skip || qs.take
    sql = `${sql} ${sqlLimit(qs.skip,qs.take)}`
/if
sql |&gt; dbSelect(queryMap) |&gt; return
```
{{ ifError |&gt; show(sql) }}
{{htmlError}}
</code></pre>
<p>The <code>_</code> prefixes in the path utilizes <a href="https://sharpscript.net/docs/sharp-pages#page-based-routing" rel="nofollow">Page Based Routing</a> allowing for
<a href="https://en.wikipedia.org/wiki/Convention_over_configuration" rel="nofollow">CoC</a> based
<a href="https://en.wikipedia.org/wiki/Clean_URL" rel="nofollow">Clean URL</a> routes without needing to define &amp; maintain separate routes where the
same script supports querying all <a href="https://docs.servicestack.net/multitenancy#changedb-apphost-registration" rel="nofollow">registered multitenancy databases</a>.</p>
<h3>
Instant Customizable RDBMS UI</h3>
<p>The <a href="https://github.com/NetCoreApps/SharpData">SharpData</a> project essentially provides a UI around this script, surfacing its features &amp; give
it instant utility which ended up being so useful that it's become the quickest way to perform fast adhoc DB queries as it's easy to configure
which RDBMS's &amp; tables to show in a simple text file, easy to customize its UI, enables 1-click export into Excel and its shortcut syntax
support in column filters is a fast way to perform quick adhoc queries.</p>
<h3>
Quick Tour</h3>
<p>We'll quickly go through some of its features to give you an idea of its capabilities, from the above screenshot we can some of its
filtering capabilities. All results displayed in the UI are queried using the above
<a href="https://github.com/NetCoreApps/SharpData/blob/master/wwwroot/db/_db/_table/index.html">sharpdata</a> <code>#Script</code> HTTP API
which supports the following features:</p>
<h3>
Filters</h3>
<p>All query string parameter except for <code>db,fields,format,skip,take,orderBy</code> are treated as filters, where you can:</p>
<ul>
<li>Use <code>=null</code> or <code>!=null</code> to search <code>NULL</code> columns</li>
<li>Use <code>&lt;=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;&gt;</code>, <code>!=</code> prefix to search with that operator</li>
<li>Use <code>,</code> trailing comma to perform an <code>IN (values)</code> search (integer columns only)</li>
<li>Use <code>%</code> suffix or prefix to perform a <code>LIKE</code> search</li>
<li>Use <code>=</code> prefix to perform a coerced "JS" search, for exact <code>number</code>, <code>boolean</code>, <code>null</code> and WCF date comparisons</li>
<li>Otherwise by default performs a "string equality" search where columns are casted and compared as strings</li>
</ul>
<p>Here's the filtered list used in the above screenshot:</p>
<p><a href="http://sharpdata.netcore.io/db/northwind/Order?format=json&amp;Id=%3E10200&amp;CustomerId=V%25&amp;Freight=%3C%3D30&amp;OrderDate=%3E1997-01-01&amp;take=100" rel="nofollow">/db/northwind/Order?Id=&gt;10200&amp;CustomerId=V%&amp;Freight=&lt;=30&amp;OrderDate=&gt;1997-01-01</a></p>
<h3>
Custom Field Selection</h3>
<p>The <strong>column selection</strong> icon on the top left of the results lets you query custom select columns which is specified using <code>?fields</code>:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json&amp;fields=Id%2CCompanyName%2CContactName%2CContactTitle&amp;take=100" rel="nofollow">/db/northwind/Customer?fields=Id,CompanyName,ContactName,ContactTitle</a></li>
</ul>
<h3>
Multiple OrderBy's</h3>
<p>You can use <a href="https://docs.servicestack.net/autoquery-rdbms#multiple-orderbys" rel="nofollow">AutoQuery Syntax</a> to specify multiple Order By's:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json&amp;orderBy=-Id,CompanyName,-ContactName" rel="nofollow">/db/northwind/Customer?orderBy=-Id,CompanyName,-ContactName</a></li>
</ul>
<h3>
Paging</h3>
<p>Use <code>?skip</code> and <code>?take</code> to page through a result set</p>
<h3>
Format</h3>
<p>Use <code>?format</code> to specify which <strong>Content-Type</strong> to return the results in, e.g:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=html" rel="nofollow">/db/northwind/Customer?format=html</a></li>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json" rel="nofollow">/db/northwind/Customer?format=json</a></li>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=csv" rel="nofollow">/db/northwind/Customer?format=csv</a></li>
</ul>
<h3>
Multitenancy</h3>
<p>You can specify which registered DB to search using the path info, use <code>main</code> to query the default database:</p>
<pre><code>/db/&lt;named-db&gt;/&lt;table&gt;
</code></pre>
<h3>
Open in Excel</h3>
<p>SharpData detects if <strong>Excel</strong> is installed and lets you open the un-paged filtered resultset directly by clicking the <strong>Excel</strong> button</p>
<p><a href="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-excel.png" target="_blank" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-excel.png" alt=""></a></p>
<p>This works seamlessly as it's able to "by-pass" the browser download where the query is performed by the back-end .NET Core Server who streams the response directly to the Users <strong>Downloads</strong> folder and launches it in Excel as soon as it's finished.</p>
<h3>
Launching SharpData</h3>
<p>To run SharpData in a .NET Core Desktop App you'll need latest <code>app</code> dotnet tool:</p>
<pre><code>$ dotnet tool update -g app
</code></pre>
<blockquote>
<p>If on macOS/Linux you can use the <a href="https://docs.servicestack.net/dotnet-tool" rel="nofollow">x dotnet tool</a> instead to view SharpData in your default browser</p>
</blockquote>
<h3>
Configure RDBMS from command-line</h3>
<p>You can override which database to connect to by specifying it on the command line, e.g. here's an example of connecting to <a href="https://techstacks.io/" rel="nofollow">https://techstacks.io</a> RDBMS:</p>
<pre><code>$ app open sharpdata -db postgres -db.connection $TECHSTACKS_DB
</code></pre>
<p>Which will open SharpData listing all of TechStack's RDBMS tables. If you have a lot of tables the <strong>Sidebar filter</strong> provides a quick way to
find the table you want, e.g:</p>
<p><a href="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-technology.png" target="_blank" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-technology.png" alt=""></a></p>
<h3>
app URL Schemes</h3>
<p>What can be done with the <code>open</code> command on the command-line can also be done from a <strong>custom URL Scheme</strong>, a feature that opens up a myriad of new
possibilities as <code>app</code> can open <a href="https://sharpscript.net/docs/gist-desktop-apps" rel="nofollow">Gist Desktop Apps</a> from Gists or in public &amp; private GitHub repositories,
where it's able to download and launch Apps on the fly with custom arguments - allowing a single URL to run a <strong>never installed</strong> Desktop App stored in a
Gist &amp; pass it custom params to enable <strong>deep linking</strong>.</p>
<p>With this organizations could maintain a dashboard of links to its different Desktop Apps that anyone can access, especially useful as the
<strong>only software</strong> that's needed to run any <a href="https://sharpscript.net/docs/sharp-apps" rel="nofollow">Sharp Apps</a> is the <code>app</code> dotnet tool which thanks to all
ServiceStack .dll's &amp; dependencies being bundled with the tool, (including Vue/React/Bootstrap fontawesome and Material SVG Icon assets),
the only files that need to be published are the App's specific resources, which is how Apps like <strong>SharpData</strong> can be compressed in a
<strong>20kb .zip</strong> - a tiny payload that's viable to download the latest app each on each run, removing the pain &amp; friction to distribute updates as
everyone's already running the latest version every time it's run.</p>
<p>Should you need to (e.g. large Sharp App or github.com is down) you can run your previously locally cached App using <code>run</code>:</p>
<pre><code>$ app run sharpdata
</code></pre>
<p>With Custom URL Schemes everyone with <code>app</code> installed can view any database they have network access to from specifying the db type and connection string in the URL:</p>
<pre><code>app://sharpdata?db=postgres&amp;db.connection={CONNECTION_STRING}
</code></pre>
<blockquote>
<p>CONNECTION_STRING needs to be URL Encoded, e.g. with JS's <code>encodeURIComponent()</code></p>
</blockquote>
<p>or by specifying an Environment variable containing the connection string:</p>
<pre><code>app://sharpdata?db=postgres&amp;db.connection=$TECHSTACKS_DB
</code></pre>
<h3>
Mix in Gists</h3>
<p>In…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sharpscript.net/sharp-apps/sharpdata">https://sharpscript.net/sharp-apps/sharpdata</a></em></p>]]>
            </description>
            <link>https://sharpscript.net/sharp-apps/sharpdata</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829512</guid>
            <pubDate>Tue, 14 Jul 2020 07:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun won't get it done]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829157">thread link</a>) | @luu
<br/>
July 13, 2020 | http://yosefk.com/blog/fun-wont-get-it-done.html | <a href="https://web.archive.org/web/*/http://yosefk.com/blog/fun-wont-get-it-done.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>OK, published at 3:30 AM. That's a first!</p>
<p>So.&nbsp;Got something you want to do over the coarse of a year? Here's a&nbsp;motivation woefully insufficient to pull it off:</p>
<ul>
<li>It's fun!</li>
</ul>
<p>What could&nbsp;give you enough drive to finish the job? Anything with a reward <em>in the future, once you're done</em>:</p>
<ul>
<li>Millions of fans&nbsp;<strong>will</strong> adore me.</li>
<li>It <strong>will</strong> be the ugliest thing on the planet.</li>
<li>I <strong>will</strong> finally understand quantum neural rockets.</li>
<li>We <strong>will</strong> see who the loser is, Todd!</li>
<li>I <strong>will</strong> help humanity.</li>
<li>I <strong>will</strong>&nbsp;destroy humanity.</li>
</ul>
<p>It doesn't matter how noble or ignoble your&nbsp;goal is. What matters is <strong>delaying gratification</strong>. Because even your&nbsp;favorite thing in the&nbsp;world will have&nbsp;shitty bits if you chew on&nbsp;a big enough chunk of it. A few months or years worth of work are <em>always</em> a big enough chunk, so there <em>will</em> be shitty bits. Unfortunately, it's also the minimum-sized chunk to do anything of significance.</p>
<p>This is&nbsp;where many brilliant talents drown. Having known the joy of true inspiration, it's hard to settle for less, which you <em>must</em> to have any impact. Meanwhile,&nbsp;their&nbsp;thicker peers happily butcher task after task. Before you know it,&nbsp;these tasks&nbsp;add up to an&nbsp;impactful result.</p>
<p>In hindsight, I was really&nbsp;lucky in that I chose a profession for money instead of love.&nbsp;Why? <strong>Stamina</strong>. Money is a reward in the future that lets you ignore the shittier bits of the present.</p>
<p>Loving every moment of it, on the other hand, carries you until that moment&nbsp;which you <em>hate</em>, and then you need a new sort of fuel. Believe me, I know. I love drawing and animation, and you won't believe how many times I started and stopped doing it.</p>
<p>But the animation teacher who taught me 3D said he was happy to put textures on toilet seat models when he started out. <em>That's</em> the kind of appetite you need – and very few people&nbsp;naturally feel that sort of attraction to toilet seats. You need a&nbsp;big reward in the future, like "I'm going to become a pro," to pull it off.</p>
<p>But I don't want to become a pro. I don't want to work in the Israeli animation market where there's scarcely a feature film&nbsp;made. I don't even want to work for a big overseas animation studio. I want to make something, erm, something beautiful that I love, <strong>which is a piece of shit of a goal</strong>.</p>
<p>Because you know where I made most progress picking up actual skills? In an evening animation school, where I had a&nbsp;perfectly good goal: survive. It's good because it's a simple, binary thing which doesn't give a rat's ass about your mood. You either drop out or you don't. But "something I love" is fluid, and depends a lot on the mood. And&nbsp;when you hate this thing you're making, as you sometimes will, it's hard to imagine loving it later.</p>
<p>Conversely, imagining how I don't drop&nbsp;out is easy. This is what I was imagining when sculpting this bust, which 90% of the time I hated with a passion because it looked like crap. But I thought, "I'm not quitting, I'm not quitting, I'm not quitting, hey, I&nbsp;get the point of re-topology in Mudbox, I'm not quitting, I'm not quitting, hey, I guess I see what&nbsp;the specular map does, I'm not quitting… Guess I'm done!"</p>
<p><iframe src="https://player.vimeo.com/video/171365263" width="480" height="270" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>And now let's talk about beauty for a moment.</p>
<p>I'm a programmer. I like to think that I'm not the thickest, butcherest programmer, in that I understand the role of beauty in it. For the trained eye, programs can be beautiful as much as&nbsp;math, physics or chess, and a beautiful program is better <em>for business</em> than the&nbsp;needlessly uglier program. (Ever tried pitching the value of beauty to someone businessy? Loads of fun.)</p>
<p>But you know why beauty is your enemy? Because it sucks the fun out of things. How? Because you're making this thing and chances are, <strong>it's not beautiful according to your own standard</strong>. The trap is, your&nbsp;taste for beauty is usually ahead of your&nbsp;creative ability. In any area, and then in any sub-area of that area, ad infinitum, you can tell ugly from beautiful long before you can make something beautiful yourself. And&nbsp;even if&nbsp;you can satisfy your own taste,&nbsp;often&nbsp;the final thing is beautiful, but not the states it goes through.</p>
<p>So&nbsp;the passionate, sensitive soul is hit twice:</p>
<ol>
<li>You're driven by fun and inspiration because you've once experienced it and now you covet it.</li>
<li>Your sense of beauty, frustrated by the state of your creation, kills&nbsp;all the fun – that very fun which&nbsp;you insist must be your only fuel.</li>
</ol>
<p>Life is easier if you want a yacht. I think you can buy a&nbsp;decent&nbsp;one for $300K, and certainly for $1M. Now all you need to do is make that money, doing doesn't matter what – imagining that yacht will help you do <em>anything</em> well! If you want beauty, however, I do not envy you.</p>
<p>How do I cope with my desire for beauty?&nbsp;The first step is acknowledging&nbsp;the problem, which I do. The fact is that my worst failures in programming came when I insisted on beauty the most. The second step is shunning beauty as a <em>goal</em>, and making it&nbsp;into a <em>means</em> and a <em>side-effect</em>.</p>
<p>I need a program doing at least X, taking at most Y seconds, at a date not later than Z.&nbsp;I'll keep ugliness to a minimum because ugly programs work badly. And if it comes out particularly nicely, that's great. But beauty is&nbsp;not a goal, and&nbsp;enjoying the beauty of this program as I write it is not why I write it.</p>
<p>And if you think it's true for commercial work but not open source software, look at, I dunno, Linux. Read some <a href="http://www.h-online.com/open/features/Interview-Linus-Torvalds-I-don-t-read-code-any-more-1748462.html">Torvalds</a>:</p>
<blockquote><p>Realistically, every single release, most of it is just driver work. Which is <strong>kind of boring in the sense there is nothing fundamentally interesting in a driver</strong>, it's just support for yet another chipset or something, and at the same time that's kind of the bread and butter of the kernel. More than half of the kernel is just drivers, and so <strong>all the big exciting smart things we do, in the end it pales</strong> when compared to all the work we just do to support new hardware.</p></blockquote>
<p>Boring bits. Boring bits that&nbsp;must be done to make something of value.</p>
<p>Does this&nbsp;transfer to art or poetry or any of those things&nbsp;whose whole point is beauty? Well, yeah, I think it does, because no,&nbsp;beauty is not the whole point:</p>
<ul>
<li>The most important thing about a drawing is that it's done. Now it exists, and people can see it, and you can make <em>another one</em>. Practice. They will not come out very well if they don't come out.</li>
<li>Often people like your&nbsp;subject.&nbsp;There's a continuum between "it's beautiful in a way that words cannot convey" and "I love how this song&nbsp;expresses&nbsp;my favorite political philosophy." To the extent that a work of art tells a story, or even sets up&nbsp;a mood, its beauty <em>does</em> become a means to an end.</li>
<li>Just because the end result is beautiful to the observer, and even if that's the only point, doesn't mean every step making it was an orgy of beauty for whomever made it. Part of what goes into it is boring, technical work.</li>
</ul>
<p>So here, too I'm trying to make beauty a non-goal. Instead my goals are "make a point" and "keep going," and you try to add beauty, or remove ugliness, as you go.</p>
<p>For example,&nbsp;I didn't do a graduation project in the evening school, but I&nbsp;animated a short on my own in the same timeframe, and I published it, even though it's not the beautiful thing I always dreamed about making. And&nbsp;I'm not sure anyone gets the joke except me. (I'm not sure I get it anymore, either.)</p>
<p><iframe src="https://player.vimeo.com/video/171368757" width="480" height="270" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>Now my goal is "make another one." It's a good goal, because it's easy to imagine making another one. It's proper&nbsp;delayed gratification.</p>
<p>And if you've enjoyed programming 20 years ago&nbsp;and are trying to reignite the passion, I suggest that you find a goal as worthy for you as "fun" or "beauty", but as clear and binary as a yacht.&nbsp;And you can settle for less worthy, but not for less clear and binary. Because everything they told you about "extrinsic motivation" being inferior to "intrinsic motivation" is one big lie. And this lie will&nbsp;fall apart the moment you sink your teeth into a bunch of shit, as will always happen if you're trying to accomplish anything.</p>
<p><a href="https://twitter.com/YossiKreinin">Follow me on Twitter</a> to receive pearls of wisdom such as the following sample:</p>
<blockquote data-lang="en"><p lang="en" dir="ltr">Authority is the idea that what matters is not which answer is pulled out of the ass, but whose ass it's pulled out of.</p>
<p>— Yossi Kreinin (@YossiKreinin) <a href="https://twitter.com/YossiKreinin/status/756221299358216192">July 21, 2016</a></p></blockquote>


							</div></div>]]>
            </description>
            <link>http://yosefk.com/blog/fun-wont-get-it-done.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829157</guid>
            <pubDate>Tue, 14 Jul 2020 06:32:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cost of Mistake in Hardware Projects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23828667">thread link</a>) | @Gen1us
<br/>
July 13, 2020 | https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&sk=eb21eb69d892cb19c0f85f3e0276481e | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&sk=eb21eb69d892cb19c0f85f3e0276481e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="9209">Have you reached your free story limit this month? Read free on the <a target="_blank" rel="noopener" href="https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e"><strong>link</strong></a>.</h2><div><div><div><div><p><a href="https://blog.maddevs.io/@anton_oxide?source=post_page-----7d73b0fd8465----------------------" rel="noopener"><img alt="Anton Kozlov" src="https://miro.medium.com/fit/c/96/96/2*cVORyQUYPKciCqxow6QtZg.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Hardware design." src="https://miro.medium.com/max/12000/1*CvgVOgiQFDODqdijfCfk4g.jpeg" width="6000" height="3258" srcset="https://miro.medium.com/max/552/1*CvgVOgiQFDODqdijfCfk4g.jpeg 276w, https://miro.medium.com/max/1104/1*CvgVOgiQFDODqdijfCfk4g.jpeg 552w, https://miro.medium.com/max/1280/1*CvgVOgiQFDODqdijfCfk4g.jpeg 640w, https://miro.medium.com/max/1400/1*CvgVOgiQFDODqdijfCfk4g.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*CvgVOgiQFDODqdijfCfk4g.jpeg?q=20"></p></div></div></div></figure><p id="cf40">Hello everyone!</p><p id="4a9f">In this article, we will consider common errors in the design of electronic devices and how to solve them. We will see how to calculate the cost of rolling back a batch of devices, get familiar with the main prototyping cycle.</p><h2 id="57be"><strong>Introduction</strong></h2><p id="c309">You have probably heard that various manufacturers recall batches of electronic devices from time to time. Smartphones hanging up, cameras turning off suddenly, electronic cigarettes exploding — these are the results of an incorrect approach to prototyping devices and savings on-device testing.</p><p id="a8d9">For users, such cases look like routine and can only undermine their trust in the device manufacturer. For a company that has released insufficiently tested devices in a series, defects can lead to recalling of the entire party of devices, paying compensations, and even bankruptcy.</p><h2 id="11b5"><strong>Real-world cases</strong></h2><p id="7451">Nowadays almost all portable or stationary devices have intelligent control. They use the computing capabilities of microcontrollers, microprocessors and processors for their work. This means that to change complex electronic logic, one will need to make changes in the software. This approach simplifies debugging, development, and error fixes, also reducing the cost of devices. Besides, manufacturers try to protect themselves by preferring software solution to hardware solutions for flexibility of the manufacturing process. As technologies develop, technical requirements for devices become more and more complex. Due to their complexity, modern devices should be properly designed and tested.</p><p id="d415">Software errors are resolved by updating the device software, normally it doesn’t cause serious damage. Below you can find some examples of errors made by well-known companies:</p><ul><li id="7f65">2019 — a login error on a Samsung smart watch:</li></ul><ul><li id="3640">2018 — an error causing the Apple iPhone restart when receiving messages with certain characters:</li></ul><ul><li id="28af">2016 — a vulnerability in Android enabling attackers to access a number o smartphone models:</li></ul><ul><li id="0f88">2016 — an issue with the shutter being stuck in Nikon D750 cameras:</li></ul><p id="8398">Errors in the software are common for any device manufacturer. They only indicate that the device circuit was properly designed so the device didn’t stop working, and the error resulted in zero hardware damage.</p><p id="c892">The errors in circuitry, layout of electronic components or mechanical parts, insufficient protection of the device from external influence lead to more serious consequences. Unlike software issues, they cannot be resolved remotely and result in higher costs as the manufacturer needs to pay for repair or even release another series of devices. Moreover, hardware errors often mean that the device won’t work properly.</p><p id="e4e4">However, errors in the firmware of the devices (especially those performing simple tasks without the possibility of remote firmware upgrade) should not be treated irresponsibly either. Even if such errors do not make their manufacturer rework the circuitry, they can still lead to reflashing. When designing devices on simple microcontrollers with peripherals used for outer word communication, it is possible to add the function of remote firmware updates and protect yourself from device recalls. We will cover remote firmware upgrades in more detail in one of our upcoming publications.</p><p id="c686">Here are some examples of hardware issues:</p><ul><li id="c041">2017 — Spectre, Meltdown — major hardware vulnerabilities at the core level of most Intel, AMD, ARM processors were detected. The command execution optimization mechanism could be used to access the arbitrary memory allocated for specific applications:</li></ul><ul><li id="d937">2016 — The discovery of a known problem with Samsung Galaxy Note 7 batteries causing smartphones to burn. Due to possible fires, some countries banned this model from air transportation:</li></ul><ul><li id="c99a">2013 — nowadays — numerous incidents involving the ignition of electronic cigarette batteries resulting in severe burns and injuries to users (warning! explicit content):</li></ul><p id="82e7">These examples show that hardware errors in devices can be fatal to the device itself or to the manufacturer. This is why hardware development and testing must be more delicate.</p><h2 id="fd51"><strong>A simple example of a disruptive design error in a device</strong></h2><p id="9500">The consequences of hardware errors are clear, but why they occur? What is the reason behind them?</p><p id="f9af">Errors in the circuitry and mechanics of the device often occur due to the lack of load, crash tests, tests in an aggressive environment. The approach to developing hardware may be incorrect, too.</p><p id="81e3">Let’s say we designed a simple device — a component of the meteorological data collection system.</p><p id="bd28">The device is installed on a hill (a lamppost, a tree trunk, a roof of some building).</p><p id="0958">The device consists of the following parts:</p><ul><li id="0a43">a series of sensors;</li><li id="b2d4">a microcontroller unit;</li><li id="79a6">a <a href="https://en.wikipedia.org/wiki/Zigbee" target="_blank" rel="noopener">ZigBee</a> transmitter;</li><li id="e9d8">a <a href="https://en.wikipedia.org/wiki/Lithium_iron_phosphate_battery" target="_blank" rel="noopener">LiFePO4 </a>battery with 2000mАh capacity;</li><li id="8319">a DC/DC converter;</li><li id="058e">a charge/discharge controller;</li><li id="1350">a solar panel for autonomous working.</li></ul><p id="ddc7">The device is sealed in the IP67 housing (description: <a href="https://en.wikipedia.org/wiki/IP_Code" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/IP_Code</a>).</p><p id="0c33">The block diagram of the device is as follows:</p><figure><div><div><p><img alt="The block diagram of the device." src="https://miro.medium.com/max/1218/0*4MNTWWozHSXtf3nF" width="609" height="402" srcset="https://miro.medium.com/max/552/0*4MNTWWozHSXtf3nF 276w, https://miro.medium.com/max/1104/0*4MNTWWozHSXtf3nF 552w, https://miro.medium.com/max/1218/0*4MNTWWozHSXtf3nF 609w" sizes="609px" data-old-src="https://miro.medium.com/max/60/0*4MNTWWozHSXtf3nF?q=20"></p></div></div></figure><p id="983d">Let’s suppose that during the development phase, some tests were carried out to check:</p><ul><li id="1c07">Stand-alone operation using solar battery charging;</li><li id="43e0">Transmitting of actual sensor data at the required distance;</li><li id="0562">Current consumption of the device within the permitted limits;</li><li id="219d">Hull tightness.</li></ul><p id="a3aa">It looks like the device passed all the necessary tests, and it is possible to start serial production.</p><p id="061a">Next, the following scenario is possible:</p><ol><li id="7bdf">The device documentation for mass production is written.</li><li id="30f7">A trial batch of 100 products is produced.</li><li id="de5d">The product is launched officially.</li><li id="c546">After a long and successful use during several months, the company produces a larger batch of several thousand units.</li><li id="0b29">The ambient temperature gets higher as summer comes.</li><li id="38a0">Due to high tightness of the device and the lack of active cooling, the devices gradually heat up to the temperatures when their batteries become unusable.</li><li id="a899">The battery capacity drops rapidly, making it harder to keep the supply voltage at the necessary level.</li><li id="17e4">The DC/DC converter starts to operate at its power limit and lose conversion efficiency over time, dissipating more and more power.</li><li id="729c">The increased temperature of the device’s active elements causes a fire.</li></ol><p id="9522">In this scenario, at best the devices will simply fail, at worst they will cause a fire.</p><p id="0cc3">In this example, the error is made at the initial stages of the construction of circuitry, as the device should have been load tested in aggressive conditions. To prevent the error in the remaining devices, it is necessary to completely change the approach to power supply and sealing.</p><p id="31b3">This means that producing hotfixes for devices with problems in circuitry and sealing mechanics is simply pointless. It is much cheaper and faster to reissue the entire batch of devices.</p><h2 id="b316"><strong>Price calculation of a simple error in a hardware project</strong></h2><p id="5150">If the errors from our example are detected in a real hardware project, the manufacturer will suffer colossal losses, and their reputation will also be affected, which may lead to bankruptcy.</p><p id="99e2">If that hardware company from our example decides to re-design and reissue their simple devices, it will need to spend huge amounts of money on the redevelopment of problem parts and additional testing.</p><p id="7ca3">Let’s make a simple calculation on how much it will have to spend on re-issuing the series of devices:</p><p id="1d46"><strong>Cost of parts: </strong>the price of parts for one device from the example ranges between $70 and $90.</p><p id="b8e1"><strong>Development: </strong>fixing power supply and sealing problems plus preliminary test will take an Embedded Systems Engineer about 15 hours.</p><p id="cb16"><strong>Simulation, testing under aggressive environment: </strong>simulation of the device’s behavior in real-world, calculation of power consumption and dissipation, and tests in aggressive conditions can take up to 50 hours.</p><p id="f40f">The average cost of the Embedded Systems Engineer work is <a href="https://www.payscale.com/research/US/Job=Embedded_Systems_Engineer/Salary" target="_blank" rel="noopener">30$/h</a>.</p><p id="8f01">Thus, to correct the error from our example, the company will need about $ 2,000, and reissuing of the trial 100-device batch will cost it about $ 8,000.</p><p id="94ac">The cost of lost time and customer confidence should also be added to the resulting amount. If the worst-case scenario unfolds, the damage compensations paid to the users will increase it even more.</p><p id="0a73">How to avoid such mistakes? Which tests should be given more attention? What are the main design problems when it comes to hardware? That’s what we’ll talk about later.</p><h2 id="5787">Step-by-step planning for prototype device development</h2><p id="32c8">To issue a test batch of devices successfully, you need to have a fully tested prototype device and complete technical documentation describing the production technology.</p><p id="7e42">The keyword here is “prototype” — a device that fully implements the required functionality and is ready for modification and optimization for the consequent serial production. More information about prototyping can be found here:</p><p id="5615">When you discuss the statement of work and possible deadlines with the customer, it is vital to take into account the following facts:</p><ul><li id="b40f">If all your hardware modules are stable as separate parts, it does not guarantee that they will work together in any way.</li><li id="f124">Successful prototyping does not mean that a product can be launched into a series — it is just one of the achievements on the way to mass production.</li><li id="4ac8">Each significant correction of the circuitry or mechanics requires the production of a new prototype. It also means another series of tests (no matter how long it takes, otherwise the production of prototypes does not make sense at all).</li><li id="a4b6">You need to allocate some extra time for prototyping as production depends on many off-project factors.</li><li id="56e6">While simulation and testing on debug stands to speed up the development at early design stages, they only add errors to the prototype at late stages.</li><li id="7555">One should avoid producing a large series of devices once the production technology is ready. It’s better to go with a small batch of devices to collect feedback and conduct tests in an aggressive environment.</li><li id="0806">At the design stage, it is necessary to allocate additional budget for …</li></ul></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e">https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e</a></em></p>]]>
            </description>
            <link>https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828667</guid>
            <pubDate>Tue, 14 Jul 2020 04:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Committing Suicide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828663">thread link</a>) | @lettergram
<br/>
July 13, 2020 | https://austingwalters.com/on-committing-suicide/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/on-committing-suicide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3389">

<div>
<p>Those that know me, know that I am both bold and resolute. I stand by my thoughts / comments, yet I attempt to keep an open mind, analyze a situation, self-reflect on any biases, and integrate feedback. I even go so far as to analyze my confidence level, see <a href="https://predictionbook.com/" target="_blank" rel="noopener noreferrer">predictionbook.com</a>.</p>
<p>With that in mind. I want to share how utterly angry and helpless I feel —</p>
<p>I can’t share my true thoughts, hell my analysis, of the current political situation in the U.S. Although I have written on it countless times, I end up deleting the posts.</p>
<p>Why?</p>
<p>It’s not safe to share thoughts.</p>
<h2>State of Affairs</h2>
<p>Today, sharing one’s opinion can cost you your livelihood, your ability to communicate, and more.</p>
<p>Historically, that was always true, perhaps more-so. We’re now returning to the status quo — repression.</p>
<p>Today’s flavor of repression is one where offending someone randomly across the globe, can cost you your job. That person may not have a standing in your community and may not have a relationship with your employer. However, they can amplify their voice, tweet your employer, and your employer (scared out of its mind by the current situation) will terminate you. That is the state of affairs today. It doesn’t matter if you’re correct or innocent. It doesn’t even matter if 99.9% of people aren’t offended by what you said — we are now in a world of “<a href="https://en.wikipedia.org/wiki/Online_shaming#Cancellation" target="_blank" rel="noopener noreferrer">cancel culture</a>“.</p>
<h2>Finding Middle Ground</h2>
<p>In the United States in 2020, we have two paths. One path leads to an ever more left-leaning populous “uprising”; the other path leads to an ever more right-leaning populous “uprising”. I don’t see an alternative, outside of some quite-frankly comical alternatives (e.g. President Mitt Romney, with VP Bernie Sanders).</p>
<p>One way or another, I lose. No one is speaking up for my beliefs or representing me.</p>
<p>I sense I’m not alone. Everyone I speak to left or right, hates the current state of affairs. Most of us even agree on <em>why</em> we distrust the system. Unfortunately, we can’t elect someone to fix the system. Neither Trump, nor Biden, nor Bernie, nor anyone on the ballot accurately represents or even inspires us.</p>
<p>By and large, I believe this is due to the “absolute” nature of our current social strife. Take the question:</p>
<blockquote><p>Why can’t I be anti-vaccine and pro-choice?</p></blockquote>
<p>You would suspect everyone would agree that we “own” our bodies. If that were true, then you would effectively have to be pro-choice AND support people’s right to choose what to put in their bodies; body ownership is the middle ground. I wish we could coalesce around the middle ground, then compromise on edge cases, enabling progress.</p>
<p>Take another example:</p>
<blockquote><p>Why don’t we do firearms training in schools?</p></blockquote>
<p>It’s an honest question — we’ve had the 2nd amendment for hundreds of years. Similar to driving a car, we should train our youth to handle firearms. I suspect we all know the reason this is not occurring — because a significant portion of the United States is fearful of firearms.</p>
<p>From the evidence, the fear is unjustified. We have evidence that with a good training program and robust mental evaluation process, firearms by-and-large are safe for society. <a href="https://en.wikipedia.org/wiki/Firearms_regulation_in_Switzerland" target="_blank" rel="noopener noreferrer">See Switzerland</a>:</p>
<blockquote><p>Swiss males grow up expecting to undergo basic military training, usually at age 20 in the recruit school..</p>
<p>…Prior to 2007, members of the Swiss Militia were supplied with 50 rounds of ammunition for their military weapon in a sealed ammo box that was regularly audited by the government…</p>
<p>…Every person with a Swiss citizenship, aged 10 years or older, can take part at any federal ranges and will be able to shoot for free with the ordinance rifle…</p>
<p>…In 2016, there were 187 attempted and 45 completed homicides, for a homicide rate of 0.50 per 100,000 population, giving Switzerland one of the lowest homicide rates in the world…</p></blockquote>
<p>Further, firearms are already widely available (<a href="https://en.wikipedia.org/wiki/Estimated_number_of_civilian_guns_per_capita_by_country" target="_blank" rel="noopener noreferrer">300+ million guns in the U.S.</a>) &amp; availability enshrined in law.</p>
<p>Sorrowfully, evidence doesn’t matter here; fear guides many. Yoda has some insights here:</p>
<blockquote><p><span data-parade-type="promoarea" data-parade-location-types="promoarea" data-parade-location-ids="article" data-parade-views="false" data-parade-touches="false" data-parade-clicks="false" data-parade-mouseovers="false">Fear is the path to the dark side. Fear leads to anger. Anger leads to hate. Hate leads to suffering.</span></p>
<p>— George Lucas (Yoda)</p></blockquote>
<h2>The False Dichotomy</h2>
<p>I don’t agree with the left or the right on many things in United States politics. In fact, I find most of the arguments a false dichotomy, designed to garner votes. To share one’s full thoughts would cause either or both sides to lash out, even though evidence may support the claims / musings.</p>
<p>Regretfully, this leaves me and many others out of the public discourse. While most of us have heard,</p>
<blockquote><p>The only thing necessary for the triumph of evil is for good men to do nothing.</p>
<p>— Edmund Burke (attributed)</p></blockquote>
<p>It’s not quite that simple and I prefer another sentiment:</p>
<blockquote><p>A man dies when he refuses to stand up for that which is right. A man dies when he refuses to stand up for justice. A man dies when he refuses to take a stand for that which is true.</p>
<p>— Martin Luther King Jr.</p></blockquote>
<center><br>
<iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/0On19DRA2fU?start=88" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"><span style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" data-mce-type="bookmark" class="lazy lazy-hidden mce_SELRES_start">﻿</span></iframe></center><p>Truthfully, we’re all being held hostage. I am very confident few people fully agree with either side in this political theater. We have extremists on either side shouting and being amplified by social media. In truth, the vast majority of us don’t agree [fully] with either extreme. Most of us, want to “live and let live” — that’s the American way. We’re a country founded on our hatred for taxes and the desire to live free from persecution. Please, please.. Don’t let that change.</p>
<p>It’s easy to decide “what’s right” when you look at it through that lens — am I persecuting others or increasing taxes (arguably a form of persecution)? If either are true, likely we should reconsider our stance.</p>
<h2>The Chaos</h2>
<p>Today, we are edging towards chaos. We all feel it. Riots, job loss, deadly diseases, [trade] wars, homelessness… We need leadership that can unite us.</p>
<p>Unfortunately, many of our would-be leaders have opted out or have been pushed out of this system. They’ve become engineers, scientists, bloggers — too scared to share their opinions (<a href="https://en.wikipedia.org/wiki/Slate_Star_Codex" target="_blank" rel="noopener noreferrer">even shutting down</a>). To hold a nuanced opinion different from the “socially accepted” by one group or another will get you “canceled”. In this case, “canceled” can mean anything from losing your job, to losing financial platforms/instruments (i.e. PayPal, VISA, YouTube revenue, etc.), to receiving threats on your life.</p>
<p>We have an ongoing pandemic, with millions in the United States likely about to perish, the economy collapsing, and we still cannot escape the politics.</p>
<p>I’m not hopeful.</p>
<p>I have so many musings, stories, and analyses I’d like to share, but neither facts nor my opinions matter.</p>
<p>Let’s be honest —</p>
<ul>
<li>I’m a white, cisgender, straight, male</li>
<li>I work as a technical manager in a research group, at a bank</li>
<li>I’m socially liberal in many ways and conservative in others</li>
<li>I grew up lower-middle class; now, I’m upper-middle class</li>
<li>I don’t attribute myself to any political party</li>
</ul>
<p>A large number of people dismiss or overlook me because of my background. Those who don’t outright dismiss me are also not likely to support my interest(s).</p>
<h2>Meritocracy or Bust</h2>
<p>What scares me is that I am a father and I am fearful for my children’s future. I was raised with the understanding that America is a meritocracy. Regardless of your race, gender, or creed, you should have the ability to make a life in the United States,<strong><em> to build a future for your children</em></strong>. Sadly, I don’t see the same core mission today. None of the political parties or the government at large appears forward-looking, for the children. Perhaps, that’s because of a <a href="https://www.cdc.gov/nchs/nvss/births.htm" target="_blank" rel="noopener noreferrer">declining birthrate</a>, I’m not sure.</p>
<p>As someone with children, I’m pleading for a group to come together to challenge the current status quo and equitably look to improve our society. We do have systemic problems that need to be fixed. Compromises will need to be made, but I don’t believe we need sacrifices from anyone.</p>
<p>The racism and sexism needs to stop. I suspect, most of us (though, not all) want a meritocracy, a hierarchy based on merit. Unfortunately, what’s being propagated is a hierarchy based on race, sex and orientation — the under-privileged. It’s clear from the countless stories we see in the news. I am sure you are tired of the racism, as am I. That’s probably true regardless of which side of the political spectrum you fall.</p>
<p><em>No one’s</em> value to society should be assessed by their race, gender or creed. A person’s value should be based off what they have to offer to a given group, organization, or society. We can rally around that idea (that we’re all equal, differentiated on merit) and work to improve. It’s a middle ground we can [mostly] agree on. From there, we can fix the injustices.</p>
<p>What horrifies me, is that even to express that <em>“we’re all equal” </em>is a challenge to this new socio-economic hierarchy. <em>No one</em> is representing me or has my family’s best interests in mind. Realistically, I don’t expect anyone to have <em>my family’s interests</em> in mind, but I don’t want my potential / rights eroded.</p>
<p>Due to this political tug of war, both sides of the political spectrum want to diminish our rights; they’re only bickering over which rights to diminish. Let’s stop this tug of war and come together.</p>
<p>If we don’t come together, soon enough we won’t have a democracy, or frankly, a future to build for.</p>
<h2>In the Words of John Adams…</h2>
<blockquote><p>Remember, democracy never lasts long. It soon wastes, exhausts, and murders itself. There never was a democracy yet that did not commit suicide. It is in vain to say that democracy is less vain, less proud, less selfish, less ambitious, or less avaricious than aristocracy or monarchy. It is not true, in fact, and nowhere appears in history. Those passions are the same in all men, under all forms of simple government, and when unchecked, produce the same effects of fraud, violence, and cruelty. When clear prospects are opened before vanity, pride, avarice, or ambition, for their easy gratification, it is hard for the most considerate philosophers and the most conscientious moralists to resist the temptation. Individuals have conquered themselves. Nations and large bodies of men, never.</p>
<p>— …</p></blockquote></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/on-committing-suicide/">https://austingwalters.com/on-committing-suicide/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/on-committing-suicide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828663</guid>
            <pubDate>Tue, 14 Jul 2020 04:56:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Google Committed $10B to India's Digital Future]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828478">thread link</a>) | @sbmthakur
<br/>
July 13, 2020 | https://finshots.in/archive/why-google-is-investing-in-india/ | <a href="https://web.archive.org/web/*/https://finshots.in/archive/why-google-is-investing-in-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">

    <div>

        <article>

            

            <figure>
                <img srcset="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 300w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 600w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 1000w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg" alt="Why Google committed $10 Billion to India's Digital Future">
            </figure>

            <section>
                <div>
                    <p><em>Google just promised to invest $10 Billion in India and we need to talk about it.</em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="the-story">The Story</h3><p>Yesterday, Google’s CEO, Sundar Pichai had a <a href="https://blog.google/inside-google/company-announcements/investing-in-indias-digital-future">big announcement</a> to make.</p><blockquote>Today, I’m excited to announce the Google for India Digitization Fund. Through this effort, we will invest ₹75,000 crore, or approximately $10 billion, into India over the next 5–7 years. We’ll do this through a mix of equity investments, partnerships, and operational, infrastructure and ecosystem investments. This is a reflection of our confidence in the future of India and its digital economy.</blockquote><p>And truth be told, it’s a big bet. I mean, when was the last time you saw a foreign company commit such an exorbitant sum to the future of India? It’s quite an unprecedented push for India’s digital dreams. And there was a four-point agenda that Google outlined to turn these dreams into reality.</p><p><strong>1) Enabling affordable access and information for every Indian in their own language, whether it’s Hindi, Tamil, Punjabi or any other.</strong></p><p>Explanation: India isn’t a large <a href="https://hbr.org/2017/12/you-dont-need-an-india-strategy-you-need-a-strategy-for-each-state-in-india">homogeneous market</a>. Instead, it’s an amalgamation of multiple micro markets with subtle differences in culture, language, income, tradition, and wealth. So tech companies aspiring to foray deep into these micro-markets will have to adapt to these differences.</p><p>Consider for instance the language divide.</p><p>Back in 2018, India had an <a href="https://www.livemint.com/industry/media/most-of-india-s-digitally-monetizable-users-want-vernacular-content-report-1565097932712.html">active internet user base</a> of 530 Million. However, close to half these users preferred digital content in their own language. And don’t scoff at this population. They come with an annual spending power of $300 billion. That’s a massive market crying out for tailor-made products. You can’t ignore them anymore.</p><p>Unfortunately, building a library rich in vernacular content will take time and money. Just look at the scale of the problem here — <a href="https://qz.com/india/1372074/google-using-ai-for-more-indian-language-content/">90% of the country’s</a> registered 135,000 publications don’t even have a website since they only cater to local communities. And most of them couldn’t scale their business online since they had very limited tools at their disposal.</p><p>In fact, back in 2018, Google said it was working with Indian language publishers to solve this very problem. They introduced <a href="https://navlekha.withgoogle.com/intl/en/#!/overview">Navlekha</a> — a platform that was supposed to allow publishers to edit and produce content in local languages without any expert digital knowledge. And they were just scratching the surface here.</p><p>But if they really wanted to make a dent , they had to have better subtitles, better translation, better content, better accessibility, better everything. They needed to make investments to help grow the vernacular ecosystem.</p><p>And guess what? It’s happening now.</p><p><strong>2) Building new products and services that are deeply relevant to India’s unique needs</strong></p><p>Every market has its own peculiar quirks and India is no different. When Samsung <a href="https://news.samsung.com/global/thinking-local-how-products-are-tailored-to-markets-2">launched its ActivWash+</a> washing machine they added a built-in sink, given the tendency among Indians to pre-wash clothes by hand. This meant consumers no longer had to crouch on the floor and they could hand wash their clothes standing upright. I am not saying Google is trying to build washing machines here. But like most things, tech products are likely to witness a surge in adoption rates if they are built specifically for the audience they cater to.</p><p>In fact, Google is no stranger to this. Back in 2017, they wrote a rather <a href="https://www.blog.google/technology/next-billion-users/building-india-first-products-and-features/">elaborate memo</a> on how they were building India-first products and features for the next billion Internet users.</p><blockquote>Another India-first feature is the new “two-wheeler mode” in Google Maps. India is the largest two-wheeler market in the world, and the millions of motorcycle and scooter riders have different navigation needs than drivers of automobiles. Two-wheeler mode in Maps shows trip routes that use “shortcuts” not accessible to cars and trucks. It also provides customized traffic and arrival time estimations. And since so many Indians rely on local landmarks for navigation, two-wheeler mode will show major landmarks on the route so that riders can plan their trip before starting, and don’t have to keep checking the phone on the go.</blockquote><p>I think it’s pretty clear what Google is trying to do here.</p><p><strong>3) Empowering businesses as they continue or embark on their digital transformation</strong></p><p>Think Google Pay. Currently the <a href="https://www.livemint.com/technology/tech-news/google-pay-set-to-tap-into-12mn-kirana-stores-in-india-1566990709066.html">platform has</a> over 3,000 online merchants and over 200,000 offline merchants. They use it to take payments, pay their suppliers, transfer money to employees and pay the odd electricity bill. And if Google can partner with other similar entities that are trying to help grow India’s fledgling digital ecosystem, it would be a win-win for everyone involved.</p><p>Right?</p><p><strong>4) Leveraging technology and AI for social good, in areas like health, education, and agriculture</strong></p><p>“Don’t be evil” was a part of the company’s <a href="https://abc.xyz/investor/other/google-code-of-conduct.html" rel="noopener noreferrer noopener">corporate code of conduct</a> since 2000. When Google reorganized in 2015, the parent company Alphabet assumed a <a href="https://www.engadget.com/2015/10/02/alphabet-do-the-right-thing/" rel="noopener noreferrer noopener">slightly different version</a> of the motto — “do the right thing.”</p><p>So, point 4 ought to be self-explanatory. It’s literally their motto.</p><p>But do bear in mind, that there is an ulterior motive here. Google wasn’t going to spend this money and push the digitization initiative if it didn’t make business sense. After all, a digital India translates to more people taking to the internet. And since Google makes most of its money offering advertising services online, you can get a sense of why they are making this bet right now.</p><!--kg-card-begin: image--><figure><img src="https://cdn-images-1.medium.com/max/900/1*EuniDplL-G6F5Fs-XOXXjw.jpeg"></figure><!--kg-card-end: image--><p>Nonetheless, that’s it from us today. If you had a friend, family member, or relative talking about this big investment, make sure they get some context. Make sure they know what this means and why Google is venturing down this path. Ergo, share this article on <a href="https://api.whatsapp.com/send?text=An%20explainer%20on%20why%20Google%20is%20investing%20$10%20billion%20in%20India?%20https://bit.ly/3gSwU1o">WhatsApp</a>, <a href="https://twitter.com/intent/tweet?url=https://bit.ly/303yozb&amp;via=finshots&amp;text=An%20explainer%20on%20why%20Google%20is%20investing%20$10%20billion%20in%20India?">Twitter</a>, and <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://finshots.in/archive/why-google-is-investing-in-india">LinkedIn</a>, will you?</p><p>Until next time…</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p><em>Correction: We removed the infographic benchmarking GDP of different states with other countries across the world since the data in the chart was erroneous. We regret the error</em></p>
                </div>
            </section>


            

            

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://finshots.in/archive/why-google-is-investing-in-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828478</guid>
            <pubDate>Tue, 14 Jul 2020 04:17:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How major and minor device numbers worked in V7 Unix]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828398">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How major and minor device numbers worked in V7 Unix</h2>

	<p><small>July 13, 2020</small></p>
</div><div><p>Unix people who've been around for a while know that Unix devices
have <em>device numbers</em>, and that device numbers are divided into
<em>major</em> and <em>minor</em> device numbers. When you do '<code>ls -l /dev/null</code>'
and one of the fields that <code>ls</code> prints is two comma separated
numbers, those are the major and minor numbers (on Linux, they are
'1, 3'; this varies by Unix). Device numbers and their split into
major and minor parts go back a long way, to before Research Unix
V7, but V7 makes a convenient point to look at what they meant and
how they worked in the original Unixes.</p>

<p>As various sources will tell you, the major number tells you (and
the Unix kernel) what sort of device it is and thus what device
driver to use to talk to it, while the minor number tells the device
driver what specific bit of hardware it's responsible for that you
want to talk to.  Sometimes the minor number also determines some
bit of functionality. Because V7 was a deliberately simple and
brute force system and kernel, major device numbers had a very
simple implementation. We can see it in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/c.c">the generated V7 kernel
configuration file <code>c.c</code></a>:</p>


<pre> struct bdevsw bdevsw[] =
 {
   nulldev, nulldev, rkstrategy, &amp;rktab, /* rk = 0 */
   nodev, nodev, nodev, 0, /* rp = 1 */
   [...]
   nodev, nodev, nodev, 0, /* hp = 6 */
   htopen, htclose, htstrategy, &amp;httab, /* ht = 7 */
   nodev, nodev, nodev, 0, /* rl = 8 */
   0
 };
</pre>

<p>What we're seeing here is that V7 literally had an array of <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/conf.h"><code>bdevsw</code>
structures</a> indexed
by the major (block) device number, with various function that were
called when you did things like open a device (in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/sys/fio.c"><code>fio.c</code></a>).
There was a similar array for character devices, the <code>cdevsw</code> array.
In both of them, what driver functions were listed here instead of
stubbed out were determined by simple configuration files (<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf">here</a>)
that said what devices you had (among other things).</p>

<p>(The <code>c.c</code> file was generated by <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/mkconf.c">a program</a>.
The particular <code>c.c</code> file in the TUHS V7 tree was built with only
two block devices configured, the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rk.c">RK disk driver</a> and
<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/ht.c">TJU16 tape driver 'ht'</a>.)</p>

<p>In V7 the minor device number was only interpreted by the device
driver, as far as I can see. Device drivers used this for a variety
of purposes. For instance, <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/mem.c">the <code>mem</code> character driver</a>
implemented <code>/dev/null</code> as minor device 2, to go along with access
to physical memory and kernel memory. The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rl.c"><code>rl</code> disk driver</a> used
the minor device number to decide what physical disk it was talking
to (it supported up to four of them). Once V7 started getting out
in the world, other people wrote drivers for it (such as <a href="http://clara.comm.sfu.ca/pups/PDP-11/Trees/V7/usr/sys/dev/rx2.c">the RX02
floppy disk driver</a>) that
used minor device numbers both to select what to talk to and control
what features to use.</p>

<p>(There's also <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/kl.c">the <code>kl</code> KL/DL-11 serial and console driver</a>, which
seems to deal with three different sets of hardware control registers
based on the minor number.)</p>

<p>The <code>/dev/tty</code> character device was implemented in a clever and
very short way in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/sys.c"><code>sys.c</code></a>. In
V7, there were no pseudo-ttys and no hot-plugged devices, so your
underlying physical terminal device always existed and was recorded
in your <code>u</code> area (see <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/user.h"><code>user.h</code></a>) The
general tty driver simply used this recorded device number of your
controlling tty to call its open, read, write, and ioctl functions
through the <code>cdevsw</code> array. As far as I can tell, this driver paid
no attention at all to the minor device number; as long as <code>/dev/tty</code>
had major number 7, the minor number was irrelevant.</p>

<p>PS: Note that V7 device drivers tended to be a little relaxed about
error checking for their minor device numbers (and other things).
For instance, as far as I can tell the <code>mem</code> driver actually only
distinguishes between minor number 2, minor number 1, and 'everything
else', which is treated as minor number 0, giving access to physical
memory.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828398</guid>
            <pubDate>Tue, 14 Jul 2020 04:00:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial: How to Build LinkedIn Automation Tools with Python with a Code Example]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828280">thread link</a>) | @ferlita
<br/>
July 13, 2020 | https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/ | <a href="https://web.archive.org/web/*/https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<blockquote>LinkedIn is the most popular social media platform for people to meet one another in a professional setting. I recommend you to read our article, <a href="https://nubela.co/blog/why-every-salesperson-should-crawl-linkedin/">Why Every Salesperson Should Crawl LinkedIn</a> and <a href="https://nubela.co/blog/how-to-automate-linkedin-sales-prospecting/">How to Automate LinkedIn Sales Prospecting</a>, to illustrate the needs of LinkedIn automation for scaling up your business.</blockquote><p>In this tutorial, I will guide you with code to get LinkedIn profile details from a list of LinkedIn URL. While this tutorial focuses only on getting the profile details you need, data processing can be done according to your needs.</p><p>This tutorial will show you two ways of doing it:</p><p><code>sequential</code> and <code>asynchronous</code></p><h3 id="setting-up-prerequisites">Setting up prerequisites</h3><ul><li>Python 3</li><li>A Proxycurl LinkedIn API credential ( API key )</li></ul><p>For sequential method:</p><ul><li><a href="https://pypi.org/project/requests/"><code>request</code></a></li></ul><p>For asynchronous method:</p><ul><li><a href="https://pypi.org/project/asyncio/"><code>asyncio</code></a></li><li><a href="https://pypi.org/project/aiohttp/"><code>aiohttp</code></a></li></ul><h3 id="how-to-get-a-proxycurl-linkedin-api-credential">How to get a Proxycurl LinkedIn API credential</h3><p>You can create a free trial Proxycurl credential at <a href="https://nubela.co/proxycurl">Proxycurl's website</a>. However, with the trial credential, your credits are limited to 100 points (1 point for 1 successful profile request).</p><p>If you need more credits, it is only $0.01 per profile! Read the <a href="https://nubela.co/blog/introducing-proxycurls-linkedin-api/">introduction to Proxycurl's LinkedIn API here</a> and please send an email to <a><span data-cfemail="5f2f2d3027263c2a2d331f312a3d3a333e713c30">[email&nbsp;protected]</span></a> for inquiries.</p><h3 id="sequential-vs-asynchronous">Sequential vs Asynchronous</h3><p>The asynchronous method gives a shorter overall duration than the sequential method as it sends multiple requests at once while the sequential method only sends one request at a time, each request waiting on the previous one to return a response. However, it also depends on the request execution time that varies according to the latency of the server. As such, this tutorial provides both sequential and asynchronous methods to give comparisons of the code between them.</p><p>Let's start with viewing the base code from <a href="https://nubela.co/proxycurl/docs#introduction-to-proxycurl-39-s-api">proxycurl's documentation</a> :</p><pre><code>
import requests

api_endpoint = 'https://nubela.co/proxycurl/api/linkedin'

linkedin_profile_url = 'https://www.linkedin.com/in/williamhgates'

api_key = '********-****-****-****-************' # your api_key

header_dic = {'Authorization': 'Bearer ' + api_key}

response = requests.get(api_endpoint,

                        params={'url': linkedin_profile_url},

                        headers=header_dic)

print(response.content)  # To get all profile details

print(response.content["first_name"])  # To get profile first name

</code></pre><p>You can change the <code>"first_name"</code> to other <code>respond key</code> in <a href="https://nubela.co/proxycurl/docs#crawling-linkedin-profiles">this Proxycurl documentation</a></p><h3 id="1-sequential-method">1. Sequential Method</h3><pre><code>
import requests , json 

from requests.exceptions import HTTPError

api_endpoint = 'https://nubela.co/proxycurl/api/linkedin'

api_key = '********-****-****-****-************' # your api_key

header_dic = {'Authorization': 'Bearer ' + api_key}

linkedin_profile_list = [

    'https://www.linkedin.com/in/williamhgates',

    'https://www.linkedin.com/in/melindagates',

    'https://www.linkedin.com/in/owinfrey'

                        ]

def get_profile_details(likedin_profile_url, session):

    url = api_endpoint

    response = None

    try:

        response = session.get(url, params={'url': linkedin_profile_url}, headers=header_dic)

        response.raise_for_status()

        # print(f"Response status ({url}): {response.status_code}")

    except HTTPError as http_err:

        print(f"HTTP error occurred: {http_err}")

    except Exception as err:

        print(f"An error ocurred: {err}")

    response_json = json.loads(response.content)

    return response_json

with requests.Session() as session:

    for linkedin_profile_url in linkedin_profile_list:

        try:

            response = get_profile_details(linkedin_profile_url, session)

            print (response["first_name"]) # To get first_name key

            # print(response) # To get all profile details

            # print()

        except Exception as err:

            print(f"Exception occured: {err}")

</code></pre><h4 id="let-s-breakdown-the-code-">Let's breakdown the code.</h4><p>As usual, we imported the required library.</p><p>Then we use all the variables defined before in the base code except the <code>linkedin_profile_url</code>. Instead, we create a new list, <code>linkedin_profile_list</code>, to hold the URLs of the profiles we want to scrape. For now, we will use 3 LinkedIn profiles for demonstration purposes.</p><p>Next, we define <code>get_profile_details</code> function to make a GET request to Proxycurl's LinkedIn API. We pass in the profile URL as a <code>query param</code> of the request, along with the Authorization header. Then the JSON response is parsed into Python dictionary using <code>json.loads()</code>.</p><p>Uncomment line with <code>print(f"Response status ({url}): {response.status_code}")</code> to print response status (200 for success). Take note that a request with a 200 response code indicates a successful request and 1 credit is consumed.</p><p>The code block under <code>with requests.Session() as session</code> will iterate through the <code>linkedin_profile_list</code> and print the <code>public_identifier</code>.</p><p>Uncomment line with <code>print (response)</code> to print all profile details.</p><h3 id="2-asynchronous-method">2. Asynchronous Method</h3><pre><code>
import aiohttp, asyncio, json

from aiohttp import ClientSession

from urllib.error import HTTPError

api_endpoint = 'https://nubela.co/proxycurl/api/linkedin'

api_key = '********-****-****-****-************' # your api_key

header_dic = {'Authorization': 'Bearer ' + api_key}

linkedin_profile_list = [

    'https://www.linkedin.com/in/williamhgates',

    'https://www.linkedin.com/in/melindagates',

    'https://www.linkedin.com/in/owinfrey'

                        ]

async def get_profile_details_async(linkedin_profile_url, session):

    url = api_endpoint

    response = None

    try:

        response = await session.request(method='GET', url=url, params={'url': linkedin_profile_url}, headers=header_dic)

        response.raise_for_status()

        print(f"Response status ({url}): {response.status}")

    except HTTPError as http_err:

        print(f"HTTP error occurred: {http_err}")

    except Exception as err:

        print(f"An error ocurred: {err}")

    response_json = await response.content.read()

    return json.loads(response_json)

async def run_program(linkedin_profile_url, session):

    try:

        response = await get_profile_details_async(linkedin_profile_url, session)

        print (response["public_identifier"])

        print(response)

        print()

    except Exception as err:

        print(f"Exception occurred: {err}")

        pass

async def run_async():

    async with ClientSession() as session:

        await asyncio.gather(*[run_program(linkedin_profile_url, session) for linkedin_profile_url in linkedin_profile_list])

def main():

    loop = asyncio.get_event_loop()

    loop.run_until_complete(run_async())

    loop.close()

if __name__ == '__main__':

    main()

</code></pre><p><strong><em>note: &nbsp; </em></strong>if you got this error on Mac OS:</p><p><code>urllib.error.URLError: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed</code></p><p>In the terminal, try to run:</p><p><code>pip install --upgrade certifi</code></p><p>If it doesn't work, try to run:</p><p><code>open /Applications/Python\ 3.6/Install\ Certificates.command</code></p><h4 id="let-s-breakdown-the-code--1">Let's breakdown the code.</h4><p>The <code>async</code> keyword that prepends the function signature tells Python that this function is a coroutine.</p><p>The <code>await</code> keyword, such as in <code>response = await session.request(...)</code> and <code>response_json = await response.content.read()</code>, tell that coroutine to suspend execution and give back control to the event loop, while the operation is awaiting finishes.</p><p>A coroutine is similar to generators in Python that consume values instead of producing values. It will pause the execution while waiting for the new data.</p><p>In our case, it suspends the execution of <code>get_profile_details_async</code> while the request is being performed: <code>await session.request(...)</code>. It is suspended again, while the response is being read by the stream reader: <code>await response.content.read()</code> and <code>json.loads(response_json)</code>.</p><p>Then, we have the <code>run_program</code> coroutine as a wrapper around the pipeline of getting a response from the API, parsing it to JSON, and printing the results on the screen. It awaits the execution of the <code>get_profile_details_async</code> coroutine.</p><p>After that, using the <code>asyncio.gather</code> syntax, we tell the program to schedule all the tasks based on the list of coroutines we provided. This is what allows us to execute tasks concurrently.</p><p>Lastly, define <code>main</code> function to run <code>run_async</code> function using <code>asyncio.get_event_loop()</code> and run it under <code>if __name__ == '__main__'</code> block.</p><h3 id="3-challenges">3. Challenges</h3><p>There are still many things you can do beyond this tutorial after retrieving the data you need. You can either store all the data first into any type of file you want and do the data processing, or you can filter the data by adding functions to our code before and only saving the information you need, to make your own personalized LinkedIn automation tool!</p>
</div>
</section></div>]]>
            </description>
            <link>https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828280</guid>
            <pubDate>Tue, 14 Jul 2020 03:41:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tufte CSS]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23828196">thread link</a>) | @mmastrac
<br/>
July 13, 2020 | https://edwardtufte.github.io/tufte-css/ | <a href="https://web.archive.org/web/*/https://edwardtufte.github.io/tufte-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>Dave Liepmann</p>
      <section>
        <p>Tufte CSS provides tools to style web articles using the ideas demonstrated by Edward Tufte’s books and handouts. Tufte’s style is known for its simplicity, extensive use of sidenotes, tight integration of graphics with text, and carefully chosen typography.</p>
        <p>Tufte CSS was created by <a href="http://www.daveliepmann.com/">Dave Liepmann</a> and is now an Edward Tufte project. The original idea was cribbed from <a href="https://tufte-latex.github.io/tufte-latex/">Tufte-<span>L<span>a</span>T<span>e</span>X</span></a> and <a href="http://rmarkdown.rstudio.com/tufte_handout_format.html">R Markdown’s Tufte Handout format</a>. We give hearty thanks to all the people who have contributed to those projects.</p>
        <p>If you see anything that Tufte CSS could improve, we welcome your contribution in the form of an issue or pull request on the GitHub project: <a href="https://github.com/edwardtufte/tufte-css">tufte-css</a>. Please note the <a href="https://github.com/edwardtufte/tufte-css#contributing">contribution guidelines</a>.</p>
        <p>Finally, a reminder about the goal of this project. The web is not print. Webpages are not books. Therefore, the goal of Tufte CSS is not to say “websites should look like this interpretation of Tufte’s books” but rather “here are some techniques Tufte developed that we’ve found useful in print; maybe you can find a way to make them useful on the web”. Tufte CSS is merely a sketch of one way to implement this particular set of ideas. It should be a starting point, not a design goal, because any project should present their information as best suits their particular circumstances.</p>
      </section>

      <section>
        <h2 id="getting-started">Getting Started</h2>
        <p>To use Tufte CSS, copy <code>tufte.css</code> and the <code>et-book</code> directory of font files to your project directory, then add the following to your HTML document’s <code>head</code> block:</p>

        <pre><code>&lt;link rel="stylesheet" href="tufte.css"/&gt;</code></pre>

        <p>Now you just have to use the provided CSS rules, and the Tufte CSS conventions described in this document. For best results, View Source and Inspect Element frequently.</p>
      </section>

      <section>
        <h2 id="fundamentals">Fundamentals</h2>
        <h3 id="fundamentals--sections-and-headers">Sections and Headings</h3>
        <p>Organize your document with an <code>article</code> element inside your <code>body</code> tag. Inside that, use <code>section</code> tags around each logical grouping of text and headings.</p>
        <p>Tufte CSS uses <code>h1</code> for the document title, <code>p</code> with class <code>subtitle</code> for the document subtitle, <code>h2</code> for section headings, and <code>h3</code> for low-level headings. More specific headings are not supported. If you feel the urge to reach for a heading of level 4 or greater, consider redesigning your document:</p>
        <blockquote cite="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB">
          <p>[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of <em>sentences</em> which then cumulate sequentially into <em>paragraphs</em>, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.</p>
          
        </blockquote>
        <p>As a bonus, this excerpt regarding the use of headings provides an example of block quotes. In Tufte CSS they are just lightly styled, semantically correct HTML using <code>blockquote</code> and <code>footer</code> elements. See page 20 of <a href="https://www.edwardtufte.com/tufte/books_vdqi">The Visual Display of Quantitative Information</a> for an example in print.</p>
        <p><span>In his later books<label for="sn-in-his-later-books"></label></span><span><a href="http://www.edwardtufte.com/tufte/books_be"><em>Beautiful Evidence</em></a></span>, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and the first few words of the sentence set in small caps. For this we use a span with the class <code>newthought</code>, as demonstrated at the beginning of this paragraph. Vertical spacing is accomplished separately through <code>&lt;section&gt;</code> tags. Be consistent: though we do so in this paragraph for the purpose of demonstration, do not alternate use of header elements and the <code>newthought</code> technique. Pick one approach and stick to it.</p>

        <h3 id="fundamentals--text">Text</h3>
        <p>Although paper handouts obviously have a pure white background, the web is better served by the use of slightly off-white and off-black colors. Tufte CSS uses <code>#fffff8</code> and <code>#111111</code> because they are nearly indistinguishable from their ‘pure’ cousins, but dial down the harsh contrast. We stick to the greyscale for text, reserving color for specific, careful use in figures and images.</p>
        <p>In print, Tufte has used the proprietary Monotype Bembo<label for="sn-proprietary-monotype-bembo"></label><span>See Tufte’s comment in the <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000Vt">Tufte book fonts</a> thread.</span> font. A similar effect is achieved in digital formats with the now open-source <a href="https://github.com/edwardtufte/et-book">ETBook</a>, which Tufte CSS supplies with a <code>@font-face</code> reference to a .ttf file. In case ETBook somehow doesn’t work, Tufte CSS shifts gracefully to other serif fonts like Palatino and Georgia.</p>
        <p>Also notice how Tufte CSS includes separate font files for bold (strong) and italic (emphasis), instead of relying on the browser to mechanically transform the text. This is typographic best practice.</p>
        <p>If you prefer sans-serifs, use the <code>sans</code> class. It relies on Gill Sans, Tufte’s sans-serif font of choice.</p>
        <p>Links in Tufte CSS match the body text in color and do not change on mouseover or when clicked. Here is a <a href="#">dummy example</a> that goes nowhere. These links are underlined, since this is the most widely recognized indicator of clickable text. <label for="mn-blue-links">⊕</label><span>Blue text, while also a widely recognizable clickable-text indicator, is crass and distracting. Luckily, it is also rendered unnecessary by the use of underlining.</span> However, because most browsers’ default underlining does not clear descenders and is so thick and distracting, the underline effect is instead achieved using CSS trickery involving background gradients instead of standard <code>text-decoration</code>. Credit goes to Adam Schwartz for that technique.</p>
        <p>As always, these design choices are merely one approach that Tufte CSS provides by default. Other approaches can also be made to work. The goal is to make sentences readable without interference from links, as well as to make links immediately identifiable even by casual web users.</p>
      </section>

      <section>
        <h2 id="epigraphs">Epigraphs</h2>
        <div>
          <blockquote>
            <p>The English language . . . becomes ugly and inaccurate because our thoughts are foolish, but the slovenliness of our language makes it easier for us to have foolish thoughts.</p>
            
          </blockquote>
          <blockquote>
            <p>For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.</p>
            
          </blockquote>
          <blockquote>I do not paint things, I paint only the differences between things.</blockquote>
        </div>
        <p>If you’d like to introduce your page or a section of your page with some quotes, use epigraphs. Modeled after chapter epigraphs in Tufte’s books (particularly <em>Beautiful Evidence</em>), these are <code>blockquote</code> elements with a bit of specialized styling. Quoted text is italicized. The source goes in a <code>footer</code> element inside the <code>blockquote</code>. We have provided three examples in the epigraph of this section, demonstrating shorter and longer quotes, with and without a paragraph tag, and showing how multiple quotes within an epigraph fit together with the use of a wrapper class.</p>
      </section>

      <section>
        <h2 id="sidenotes">Sidenotes: Footnotes and Marginal Notes</h2>
        <p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<label for="sn-extensive-use-of-sidenotes"></label><span>This is a sidenote.</span> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p>
        <p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p>
        <p>Sidenotes consist of two elements: a superscript reference number that goes inline with the text, and a sidenote with content. To add the former, just put a label and dummy checkbox into the text where you want the reference to go, like so:</p>
        <pre><code>&lt;label for="sn-demo"
       class="margin-toggle sidenote-number"&gt;
&lt;/label&gt;
&lt;input type="checkbox"
       id="sn-demo"
       class="margin-toggle"/&gt;</code></pre>
        <p>You must manually assign a reference <code>id</code> to each side or margin note, replacing “sn-demo” in the <code>for</code> and the <code>id</code> attribute values with an appropriate descriptor. It is useful to use prefixes like <code>sn-</code> for sidenotes and <code>mn-</code> for margin notes.</p>
        <p>Immediately adjacent to that sidenote reference in the main text goes the sidenote content itself, in a <code>span</code> with class <code>sidenote</code>. This tag is also inserted directly in the middle of the body text, but is either pushed into the margin or hidden by default. Make sure to position your sidenotes correctly by keeping the sidenote-number label close to the sidenote itself.</p>
        <p>If you want a sidenote without footnote-style numberings, then you want a margin note.
          <label for="mn-demo">⊕</label>
          
          <span>
            This is a margin note. Notice there isn’t a number preceding the note.
          </span> On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text. However, on small screens, a margin note is like a sidenote except its viewability-toggle is a symbol rather than a reference number. This document currently uses the symbol ⊕ (<code>&amp;#8853;</code>), but it’s up to you.</p>
        <p>Margin notes are created just like sidenotes, but with the <code>marginnote</code> class for the content and the <code>margin-toggle</code> class for the label and dummy checkbox. For instance, here is the code for the margin note used in the previous paragraph:</p>
        <pre><code>&lt;label for="mn-demo" class="margin-toggle"&gt;&amp;#8853;&lt;/label&gt;
&lt;input type="checkbox" id="mn-demo" class="margin-toggle"/&gt;
&lt;span class="marginnote"&gt;
  This is a margin note. Notice there isn’t a number preceding the note.
&lt;/span&gt;</code></pre>
        </section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://edwardtufte.github.io/tufte-css/">https://edwardtufte.github.io/tufte-css/</a></em></p>]]>
            </description>
            <link>https://edwardtufte.github.io/tufte-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828196</guid>
            <pubDate>Tue, 14 Jul 2020 03:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terraform Pain Points]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828089">thread link</a>) | @jbergknoff
<br/>
July 13, 2020 | https://jonathan.bergknoff.com/journal/terraform-pain-points/ | <a href="https://web.archive.org/web/*/https://jonathan.bergknoff.com/journal/terraform-pain-points/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	
	<h6>
		<span>2020-07-08</span>

		
		<span>
			
			<a href="https://jonathan.bergknoff.com/tags/tech">tech</a>
			
			<a href="https://jonathan.bergknoff.com/tags/programming">programming</a>
			
			<a href="https://jonathan.bergknoff.com/tags/terraform">terraform</a>
			
		</span>
		
	</h6>
	<hr>
	

<p>I love using <a href="https://www.terraform.io/">Terraform</a>. At my previous job, we managed our infrastructure entirely with Terraform: tens of thousands of resources spread across several cloud providers. The benefits of infrastructure-as-code and Terraform, in particular, are massive, but well known. While I still consider Terraform the best tool of its kind, this article describes some pain points that my team and I encountered as power users. I hope it can lead to some discussion about ways to improve.</p>

<p>All of these are relevant as recently as Terraform v0.13.0-beta3, July 2020.</p>

<ul>
<li><a href="#refactoring-is-difficult">Refactoring is difficult</a></li>
<li><a href="#code-reuse-is-limited">Code reuse is limited</a></li>
<li><a href="#type-system-is-too-rigid">Type system is too rigid</a></li>
<li><a href="#upstream-development-frustrating-priorities">Upstream development: frustrating priorities</a></li>
</ul>

<p>This is part one in a series about Terraform. Part two, detailing some Terraform practices that we found effective, will be up shortly.</p>

<h2 id="refactoring-is-difficult">Refactoring is difficult</h2>

<p>Terraform code is unwieldy to refactor. Even giving a resource a new <em>internal</em> name is a hassle. Here’s our simple Terraform definition:</p>

<pre><code>resource "aws_s3_bucket" "bucket" {
  bucket = "images.bigco.com"
}
</code></pre>

<p>Now it’s a month later, and we’re adding our second bucket, so let’s change our Terraform code to use a more specific name:</p>

<pre><code>resource "aws_s3_bucket" "images_bucket" {
  bucket = "images.bigco.com"
}
</code></pre>

<p>If we naively try to make this innocuous-looking change, Terraform will want to delete and recreate the bucket. We probably all understand why that’s the case, and it helps us appreciate how wonderful the concept of <code>terraform plan</code> is, but it’s ludicrous to have no serious facility for doing this smoothly. <code>terraform state mv</code> exists, but you need to run that separately, outside the plan/apply lifecycle. If you need to do this for ten environments, it’s a lot of work.</p>

<p>And that’s the easy case. Moving across module boundaries is harder, especially if you want to move the resources from the module into the root of the state (spoiler: <code>state mv</code> can’t do it). Moving across state boundaries is harder still. While the <a href="https://www.terraform.io/docs/commands/state/mv.html">documentation</a> mentions moving to a different state file, there’s no support for hooking it up to an already-existing state in S3 (for example). The tool is not at all user friendly or convenient.</p>

<p>The silver lining is that Terraform state is a simple JSON file, so it’s easy to write your own tooling around it. My team had occasion to do several refactors where we pulled individual projects’ resources out of a monolithic state and into their own states, once for each of our environments. Trying to orchestrate that with <code>state mv</code> would have been an awkward mess, but writing a simple Python script to pull state from S3, modify it, and push it back, was not too bad (if you do this, you’ll also want to remove the state checksum from DynamoDB).</p>

<p>You’re never going to nail the module and state boundaries correctly on your first pass (or ever?). Refactoring is inescapable. It needs to be more convenient. It would be great if there was some way to signal to Terraform “hey, this resource used to have a different address”. Something like this seems reasonable:</p>

<pre><code>resource "aws_s3_bucket" "images_bucket" {
  bucket = "images.bigco.com"

  lifecycle {
    old_addresses = [
      "aws_s3_bucket.bucket",
      "module.images_bucket.aws_s3_bucket.bucket",
    ]
  }
}
</code></pre>

<h2 id="code-reuse-is-limited">Code reuse is limited</h2>

<p>Terraform’s main tool for code reuse (i.e. a chunk of resource definitions that can be reused with different inputs) is the <code>module</code> (symlinks may also be useful in some situations, but I haven’t used them for this). Modules are limited in some ways.</p>

<h4 id="it-s-awkward-to-pin-module-versions">It’s awkward to pin module versions</h4>

<p>You <a href="https://github.com/hashicorp/terraform/issues/1439">can’t do interpolation in a module’s <code>source</code> parameter</a>. So if a dozen modules should all be pointing at the same revision of your <a href="https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d">modules git repository</a>, there’s no clean way to update all those references in one place. My team had a Makefile target, which we ran manually, that used <code>find</code> and <code>sed</code> to update all the references.</p>

<p>Leaving the module source unpinned is not an option I’d be comfortable with because it’s a vector for un-source-controlled drift that can be easily avoided.</p>

<h4 id="can-t-partially-apply-modules">Can’t partially apply modules</h4>

<p>The biggest problem we’ve faced with the module system is the inability to do <a href="https://en.wikipedia.org/wiki/Partial_application">partial application</a> (in the computer science sense). In essence, it would be nice to simplify a module’s interface by binding a bunch of common parameters. Here’s an example:</p>

<pre><code>module "service_a" {
  source = "..."

  name = "service_a"

  environment_variables = merge(
    local.environment_variable_defaults,
    {
      THING = "1",
    },
  )

  vpc_id     = local.vpc_id
  subnet_ids = local.subnet_ids
  ...
}

module "service_b" {
  source = "..."

  name = "service_b"

  environment_variables = merge(
    local.environment_variable_defaults,
    {
      THING = "2",
    },
  )

  vpc_id     = local.vpc_id
  subnet_ids = local.subnet_ids
  ...
}
</code></pre>

<p>These services have, say, fifteen parameters being passed in, and they only differ in one or two. There should be some more expressive way of writing them so that only those two unique values are prominent. Instead, you’re stuck copy/pasting a bunch of boilerplate, and editing in the unique values. That’s error-prone and a maintenance burden.</p>

<p>There’s an <a href="https://www.terraform.io/docs/configuration/locals.html">analogy</a> between Terraform definitions and a conventional programming language: a set of Terraform definitions (a module) is like a function, with TF variables being inputs to the function, TF locals being local variables, and TF outputs being return values. The extension of that analogy to this use case is partial application, where you give a module some of its inputs, it binds those values and you get back a module with only the rest of the inputs. Terraform doesn’t support it.</p>

<p>Ideally, we’d be able to define some sort of a “submodule” like this:</p>

<pre><code>submodule "service" {
  source = "..."

  environment_variables = merge(
    local.environment_variable_defaults,
    ?
  )

  vpc_id     = local.vpc_id
  subnet_ids = local.subnet_ids
}

module "service_a" {
  source = submodule.service

  name = "service_a"

  environment_variable_overrides = {
    THING = "1",
  }
}
</code></pre>

<p>We can’t use a proper module for this, because it doesn’t have access to its parent’s locals (which seems right). Notice the unsolved problem here of how to refer to those environment variable overrides in the submodule. This isn’t a fully-formed proposal.</p>

<p>Here are some ways we’ve dealt with this.</p>

<h5 id="code-reuse-workaround-1-big-map-of-config">Code reuse workaround 1: big map of config</h5>

<p>You can pass a big map of config as input to the module, rather than individual variables. That map can be defined as a local, and can include all the common values. Each service can merge on top of it to provide its overrides.</p>

<p>It’s a hack, but it works to reduce boilerplate. There are a couple of serious drawbacks, though:</p>

<ul>
<li><p>Terraform’s <code>merge()</code> only performs a shallow merge. This is surprising behavior, and can lead to subtle bugs. You can work around it if you know about it, but the workarounds are often awkward. There’s an <a href="https://github.com/hashicorp/terraform/pull/25032">open PR</a> adding a <code>deepmerge()</code> function.</p></li>

<li><p>When anything in the map is “not known until after apply” (e.g. an attribute of a resource that hasn’t been created yet), the entire map is considered “not known until after apply”. For example, if our config map looks like</p>

<pre><code>config = {
  vpc_id = aws_vpc.vpc.id,
  thing_enabled = true,
}
</code></pre>

<p>and the module does something like</p>

<pre><code>resource ... {
  count = var.config.thing_enabled ? 1 : 0

  ...
}
</code></pre></li>
</ul>

<p>then this will fail to plan if the VPC doesn’t already exist because <code>var.config</code> contains something (the VPC id) which isn’t known yet, and so <code>var.config.thing_enabled</code> is not known until after apply. This is subtle and unexpected, and the error messages you’ll see from it are cryptic. But it’s very easy to do by accident once some resources are created already. Then the next time you try to bootstrap a new state (e.g. a new environment), you’ll find that it won’t plan successfully.</p>

<h5 id="code-reuse-workaround-2-generate-terraform-definitions-from-templates">Code reuse workaround 2: generate Terraform definitions from templates</h5>

<p>In some instances, it can make sense to generate Terraform code from templates. On my team, there were a few places that we did this, and we checked those generated files in to git as regular <code>*.tf</code> files (their names started with <code>generated.</code> to make it obvious). This can work well, but adds some process overhead (pre-processing, knowing which files to not edit, CI validation that the files haven’t been edited).</p>

<p>There are also some TF preprocessors, like <a href="https://pypi.org/project/terraformpy/">terraformpy</a>, but I haven’t tried any.</p>

<h2 id="type-system-is-too-rigid">Type system is too rigid</h2>

<p>In Terraform before 0.12, everything was a string, and that was ugly (<code>count = "${var.enabled ? 1 : 0}"</code>). Terraform 0.12 added proper booleans, numbers, even some data structures like sets and maps. That was an improvement. However:</p>

<ul>
<li><p>When defining a module’s contract (i.e. specifying the types for its input variables), it’s not currently practical to use <code>map</code> or <code>object</code>.</p>

<p>The <code>map</code> type requires all values in the map to have the same type, which can be useful in a some cases (environment variable values are always strings), but not very often, in my experience.</p>

<p>The <code>object</code> type is a map without that restriction on value types, but if you’re going to say a variable’s type is <code>object</code>, you need to specify all the names of the keys and the types of their values. Okay… that doesn’t sound so bad. And <a href="https://github.com/hashicorp/terraform/issues/19898">all of the keys are mandatory</a>. What!? This makes <code>object</code> useless as a variable type, where you’ll often want to just pass in one value as an override and leave some set of defaults.</p>

<p>If you put these types on your variables, you’ll fail to plan in all sorts of surprising ways. You’ll try to pass <code>alarm_config = { enabled = true, threshold_seconds = 30 }</code> to your <code>map</code> variable and fail to plan because the value types aren’t uniform. So you’ll change it to an object, then realize that you can’t omit the <code>period_seconds</code> parameter which was supposed to optionally merge on top of a default. It’s an uphill battle. These types, in this context, are so rigid that they cause a lot of …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonathan.bergknoff.com/journal/terraform-pain-points/">https://jonathan.bergknoff.com/journal/terraform-pain-points/</a></em></p>]]>
            </description>
            <link>https://jonathan.bergknoff.com/journal/terraform-pain-points/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828089</guid>
            <pubDate>Tue, 14 Jul 2020 03:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 Explorer – Visual Zilog Z-80 netlist-level simulator]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827755">thread link</a>) | @userbinator
<br/>
July 13, 2020 | https://baltazarstudios.com/z80explorer/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p><em>Z80 Explorer</em> is a Zilog Z80 netlist-level simulator capable of running Z80 machine code and also an educational tool with features that help reverse engineer and understand this chip better.</p>
<p>Z80 Explorer is a tool I wished I had a few years ago when I first started looking at the photos of Z80 chip die and was learning to reverse-engineer its <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noreferrer noopener">features</a>. The process was slow and painful as it involved deciphering the faint image traces into logic gates and functions.</p>
<p>Sometimes later, I’ve found that the Visual6502 team have done a wonderful work with mapping the cpu’s traces into bitmaps representing various layers. Their online viewing <a href="http://www.visual6502.org/JSSim/expert-z80.html" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">tool </a>is impressive and one can learn a lot from using it, but as most online tools, it has limitations which I quickly hit when trying to understand the chip behavior in more depth.&nbsp;</p>
<p>As I kept playing with the online tool, my wish list of additional features steadily grew. I would have wanted it not only to be a fully functional and a fast simulator but also to provide more elaborate ways to gain deeper insights into the chip's internal behavior, while also being educational, easy, and intuitive to use.</p>
<p>Fast forward to today, and with the help of repeated COVID-19 stay-at-home orders, I have written this tool to be the way I imagined it.</p>
<figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" alt=""></a><figcaption>Z80 Explorer (click to enlarge)</figcaption></figure>
<p>In this blog, I will give an overview of <em>Z80 Explorer</em>'s capabilities and show a couple of useful features which might be easy to miss even after reading the documentation. This blog may change periodically along with the tool itself as I am actively developing it at the moment (Summer 2020).</p>
<p>The tool's user’s guide is a separate online document located here <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/Z80ExplorerGuide/" target="_blank" rel="noreferrer noopener">https://baltazarstudios.com/Z80ExplorerGuide</a> It is very concise; if something is still unclear, please email me and I will correct it.</p>
<p>The tool is written to load and use the Z80 dataset (layer images and netlist). It should be able to accommodate other NMOS chips with minimal changes. However, at this time I haven't done any other ports yet as I was solely focused on Z80. The chip's data (resources) are kept separate from the application and can be independently downloaded and updated from a shared <a aria-label="undefined (opens in a new tab)" href="https://github.com/gdevic/Z80Explorer_Z80" target="_blank" rel="noreferrer noopener">github repo</a>. In particular, as the functions of various nets is understood and nets and buses get named, the list of the net names, tips and annotations can grow and be shared.</p>
<p><em>Z80 Explorer</em> is capable of running native Z80 code at the netlist level. That means, as the instruction opcodes are fed to its pins, the binary 1s and 0s propagate through its internal nets of transistor gates and perform the function identical to what the silicon gates would do on a real chip.</p>
<p>The engine that runs it is quite fast: On my 4GHz i7-4790K CPU, I am able to run Z80 code at around 2.3kHz which is (only!) around 2000 times slower from the speed it would have run on the real silicon. At those “speeds”, it is not inconceivable to run some of the standard CPU diagnostic programs - so I did just that: I run a well known ZEXALL diagnostic program.&nbsp;</p>
<p>This program normally takes hours even on a real Z80. </p>
<p>After a few days of running within the simulator, the list of passing tests kept growing. At one point, after a week or so, the simulator’s internal cycle counter overflowed its 32-bit variable and the simulation stopped. I simply had to resume it, with no need to reset it and with no loss to the accumulated progress.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-zexall.png" alt=""><figcaption>Z80 Explorer running ZEXALL diagnostic</figcaption></figure></div>
<p>I have added this version of ZEXALL to the app resources. It is modified from the original in that I had sorted the tests by how long they run: with the quickest going first, it does not take too long before you start seeing some results, assuring you that it is indeed running well.</p>
<p><em>Z80 Explorer</em> shows various versions of chip images. Some of them are unmodified resource files shown as layers (diffusion, metal layer etc.), and some are created as combinations of those: vss.vcc.nets.col is a layer with the nets colored such that ground is shown as green, vcc red, and the rest of the nets are colored according to user filters (press F6 to define those filters).</p>
<p>You can view different layers and create combinations of them if you hold down the Ctrl key while clicking on layer buttons, or press a key assigned to each layer while holding down the Ctrl key.</p>
<p>The Z80 chip/layer view can be annotated. The application loads a default annotation file (containing those annotations) when it starts, but you can load any other annotation file by dragging that file and dropping it into the application image view. For example, “annot_internals.json” (located in the resource folder) contains a different set of annotations focused more on the internal features. Annotations are adaptive so that they will show and hide as you zoom in and out. They also can contain current net and bus values which are updated as the simulation modifies them.</p>
<p>Let us examine a few Z80 control / logic signals.</p>
<p>In my older article <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noreferrer noopener">here</a> I looked at the Instruction Register. The signal that enables loading it is a complementary WE (Write Enable) pair of control traces.</p>
<p>Can we find exactly at what time(s) the write enable, now called, "load_ir", is asserted? What is the internal logic equation that governs this control signal?</p>
<p>Using the <em>Z80 Explorer</em>'s "Find" option to search for "load_ir" signal name, and then asking for the schematic of that net, brings up this view:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir1.png" alt=""><figcaption>Schematic view for "load_ir" net</figcaption></figure></div>
<p>Hence, the signal is generated by OR'ing net 255 with a latch. Let's follow net 255 which is a NAND gate of clock (hence, a clock gating) with the net 1329. Selecting (double-clicking on) 1329 and asking for the schematic brings us even closer to what we expected to see:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1329.png" alt=""><figcaption>Schematic view for net 1329</figcaption></figure></div>
<p>Therefore, the net 1329 is a clock-gated, NAND-combined signal, active when M3, T3 and PLA22 are active. PLA22 represents "IX/IY+CB" instruction extension decode. (The description of PLA22 is held in the application "tips" file as are descriptions of all other PLA entries and some other important nets).</p>
<p>Back to the latch 244 - and this part may not too obvious unless you have some experience looking at the chip traces - the net 244 is at the bottom and the latch set and reset signals are at the top, both clock-gated:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-244.png" alt=""><figcaption>Latch at the net 244</figcaption></figure></div>
<p>Asking for the schematic of the net 1306 (the one connected from the top-left), which also acts as the latch reset:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1306.png" alt=""><figcaption>Latch 244 reset</figcaption></figure></div>
<p>we see that the latch will reset on the "internal reset" or a T3 cycle. The latch will be set on an M1 and T2 cycle edge (so it will show at M1/T3):</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1307.png" alt=""><figcaption>Latch 244 set</figcaption></figure></div>
<p>We can verify what we've found by running a hand-crafted test code. I used a template test program "test_blank.asm" to code in a couple of instructions, one of them using IX register, and then I run it for a couple of cycles. In a Waveform view window the result shows how the load_ir signal is being asserted at every M1/T3 as well as at M3/T3, when the instruction is using the IX/IY prefix (PLA22 active).</p>
<div><figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" alt=""></a><figcaption>Waveform diagram showing "load_ir" signal (click to enlarge)</figcaption></figure></div>
<p>Next, let's look at some other features of <em>Z80 Explorer</em>.</p>
<p>Load the "annot_internals.json" file by dropping it onto on the application's image view (the main pane).</p>
<p>You can zoom into the area where are all M and T latches located by pasting this command into the Command Window:&nbsp;</p>
<p><code>img.setZoom(0.98); img.setPos(1151,901)</code></p>
<p>On the startup, the app will try to detect latches, and it will detect most of them automatically. For those not detected, you can add them as you find them. The easiest way to find latches is by using the “Driven by” option. After selecting a net and following its signal chain, if you see two nets being driven by each other in a co-dependent loop, you have found a latch that consists of those two nets (they also act as inverters). One of the app's initialization files, "latches.ini" contains definitions of additional latches. You can add to that file as you find latches that the app did not detect.</p>
<p>Schematic view uses an expanded version of such “Driven by” algorithm to build a tree of gates that contribute to the selected net.</p>
<p>Going the other way, the “Driving nets” option assists you to trace an input net as it branches into the network. For example, pick the /RESET input pad and iterate “Driving nets”, following the highlighted lines. Soon, you should reach a “dead end”, with the nets which apparently nothing is driving, here:</p>
<p><code>img.setZoom(2.926); img.setPos(338,606); img.show(294,548,80,101)</code></p>
<p>About these commands: In order to create these zoom and position commands yourself, set up a desired view and then type “img.state()” in the Command window. The required lines will be printed in the Application Log window.</p>
<p>To obtain the coordinates used in the img.show() command, right-click and select an area you wanted to highlight, and then simply read the coordinates from the Log window and paste them into img.show() as arguments.</p>
<p>The particular network mentioned above contains reset input flops and latches. One of the control signals coming out of it is “int_reset”, or internal reset:</p>
<p><code>img.find("int_reset")</code></p>
<p>This signal branches off to different parts of the chip.&nbsp;</p>
<p>Every chip normally has several signals that are propagated across its die to literally every corner. Some of those networks are power, ground, reset and the clocking network. (Newer chips implement various “gating” to parts of the design to limit the power consumption, but Z80 does not do such thing.)&nbsp;</p>
<p>I have already mention the Waveform view. This view should be familiar to anyone who has worked with simulation tools like ModelSim; but even for the rest, it should still be very simple and intuitive to use.</p>
<p>The important thing to remember is to “name” the net that you wish to observe, if it hasn't been named yet, before you can add it to the waveform view. Double click on the net and select “Edit net name...”. You can type any name; a simple "n123" (where 123 was its net number) would suffice, especially if that is only a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80explorer/">https://baltazarstudios.com/z80explorer/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827755</guid>
            <pubDate>Tue, 14 Jul 2020 02:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strange public IPv4 address assigned behind NAT (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 86 (<a href="https://news.ycombinator.com/item?id=23827521">thread link</a>) | @rohan1024
<br/>
July 13, 2020 | https://broadbandforum.co/t/190267/ | <a href="https://web.archive.org/web/*/https://broadbandforum.co/t/190267/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://broadbandforum.co/t/190267/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827521</guid>
            <pubDate>Tue, 14 Jul 2020 01:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jonathan Blow: Video Games and the Future of Education]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827489">thread link</a>) | @doppp
<br/>
July 13, 2020 | https://www.twitch.tv/videos/678729516 | <a href="https://web.archive.org/web/*/https://www.twitch.tv/videos/678729516">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/videos/678729516</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827489</guid>
            <pubDate>Tue, 14 Jul 2020 01:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking with environment variables]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 63 (<a href="https://news.ycombinator.com/item?id=23827486">thread link</a>) | @pentestercrab
<br/>
July 13, 2020 | https://www.elttam.com/blog/env/ | <a href="https://web.archive.org/web/*/https://www.elttam.com/blog/env/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        

<p>On a recent project we gained the ability to specify environment variables but not the process that was executed.
We were also unable to control the contents of a file on disk, and bruteforcing process identifiers (PIDs) and file descriptors found no interesting results, eliminating <a href="https://www.elttam.com/blog/goahead/">remote LD_PRELOAD exploitation</a>.
Fortunately, a scripting language interpreter was executed which enabled us to execute arbitrary commands by specifying particular environment variables.
This blog post discusses how arbitrary commands can be executed by a range of scripting language interpreters when supplied with malicious environment variables.</p>



<p>A quick read of the <code>ENVIRONMENT</code> section of the <code>perlrun(1)</code> man page reveals plenty of environment variables worth investigating.
The <code>PERL5OPT</code> environment variable allows specifying command-line options, but is restricted to only accepting the options <code>CDIMTUWdmtw</code>.
This unfortunately means that <code>-e</code>, which allows supplying perl code to run, is out.</p>

<p>All is not lost though, as demonstrated in the <a href="https://github.com/HackerFantastic/exploits/blob/master/cve-2016-1531.sh">exploit</a> for CVE-2016-1531 by <a href="https://twitter.com/hackerfantastic">Hacker Fantastic</a>.
The exploit writes a malicious perl module to <code>/tmp/root.pm</code> and supplies the environment variables <code>PERL5OPT=-Mroot</code> and <code>PERL5LIB=/tmp</code> to achieve arbitrary code execution.
However this was an exploit for a local privilege escalation vulnerability and a generic technique should ideally not require access to the file system. Looking at <a href="https://twitter.com/bl4sty">blasty</a>’s <a href="https://haxx.in/blasty-vs-exim.sh">exploit</a> for the same CVE, the exploit did not require creating a file and used the environment variables <code>PERL5OPT=-d</code> and <code>PERL5DB=system("sh");exit;</code>.
The same environment variables were also used to <a href="https://old.reddit.com/r/netsec/comments/1dm8fv/hack_this_website_and_win_bitcoins_the_first/c9tm6j4/">solve a CTF challenge</a> in 2013.</p>

<p>One final nicety of a generic technique would be to use a single environment variable instead of two.
<a href="https://twitter.com/justinsteven">@justinsteven</a> found this was possible by leveraging <code>PERL5OPT=-M</code>.
While either <code>-m</code> or <code>-M</code> can be used to load a perl module, the <code>-M</code> option allows adding extra code after the module name.</p>

<h2 id="proof-of-concept">Proof of Concept</h2>

<figure>
  <figcaption>Figure-0: arbitrary code execution achieved using an environment variable against perl running an empty script (/dev/null)</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>--env</span> <span>'PERL5OPT=-Mbase;print(`id`)'</span> perl:5.30.2 perl /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>Reading the <code>ENVIRONMENT VARIABLES</code> section of the <code>python(1)</code> man page, <code>PYTHONSTARTUP</code> initially appears like it may be a piece of a straightforward solution.
It allows specifying a path to a Python script that will be executed prior to displaying the prompt in interactive mode.
The interactive mode requirement didn’t seem like it would be an issue as the <code>PYTHONINSPECT</code> environment variable can be used to enter interactive mode, the same as specifying <code>-i</code> on the command line.
However, the documentation for the <code>-i</code> option explains that <code>PYTHONSTARTUP</code> will not be used when python is started with a script to execute.
This means that <code>PYTHONSTARTUP</code> and <code>PYTHONINSPECT</code> cannot be combined and <code>PYTHONSTARTUP</code> only has an effect when the python REPL is immediately launched.
This ultimately means that <code>PYTHONSTARTUP</code> is not viable as it has no effect when executing a regular Python script.</p>

<p>Other environment variables which looked promising were <code>PYTHONHOME</code> and <code>PYTHONPATH</code>. Both of these will let you gain arbitrary code execution but require you to also be able to create directories and files on the filesystem. It may be possible to loosen those requirements through the use of the proc filesystem and/or ZIP files.</p>

<p>The majority of the remaining environment variables are simply checked if they contain a non-empty string, and if so, toggle a generally benign setting. One of the rare exceptions to this is <code>PYTHONWARNINGS</code>.</p>

<h2 id="making-progress-with-pythonwarnings">Making progress with PYTHONWARNINGS</h2>
<p>The documentation for <code>PYTHONWARNINGS</code> states <code>it is equivalent to specifying the -W option</code>. The <code>-W</code> option is used for warning control to specify which warnings and how often they are printed. The full form of argument is <code>action:message:category:module:line</code>. While warning control didn’t seem like a promising lead, that quickly changed after checking the implementation.</p>

<figure>
  <figcaption>Figure-1: Python-3.8.2/Lib/warnings.py</figcaption>

<figure><pre><code data-lang="python"><span>[...]</span>
<span>def</span> <span>_getcategory</span><span>(</span><span>category</span><span>):</span>
    <span>if</span> <span>not</span> <span>category</span><span>:</span>
        <span>return</span> <span>Warning</span>
    <span>if</span> <span>'.'</span> <span>not</span> <span>in</span> <span>category</span><span>:</span>
        <span>import</span> <span>builtins</span> <span>as</span> <span>m</span>
        <span>klass</span> <span>=</span> <span>category</span>
    <span>else</span><span>:</span>
        <span>module</span><span>,</span> <span>_</span><span>,</span> <span>klass</span> <span>=</span> <span>category</span><span>.</span><span>rpartition</span><span>(</span><span>'.'</span><span>)</span>
        <span>try</span><span>:</span>
            <span>m</span> <span>=</span> <span>__import__</span><span>(</span><span>module</span><span>,</span> <span>None</span><span>,</span> <span>None</span><span>,</span> <span>[</span><span>klass</span><span>])</span>
        <span>except</span> <span>ImportError</span><span>:</span>
            <span>raise</span> <span>_OptionError</span><span>(</span><span>"invalid module name: %r"</span> <span>%</span> <span>(</span><span>module</span><span>,))</span> <span>from</span> <span>None</span>
<span>[...]</span></code></pre></figure>

</figure>

<p>The above code shows that as long as our specified category contains a dot, we can trigger the import an arbitrary Python module.</p>

<p>The next problem is that the vast majority of modules from Python’s standard library run very little code when imported. They tend to just define classes to be used later, and even when they provide code to run, the code is typically <a href="https://docs.python.org/3/library/__main__.html">guarded with a check of the <code>__main__</code> variable</a> (to detect if the file has been imported or run directly).</p>

<p>An unexpected exception to this is the <a href="https://xkcd.com/353/">antigravity module</a>. The Python developers included an <a href="https://en.wikipedia.org/wiki/Easter_egg_(media)">easter egg</a> in <a href="https://github.com/python/cpython/commit/206e3074d34aeb5a4d0c1e24d970b6569f7ad702">2008</a> which can be triggered by running <code>import antigravity</code>. This import will immediately open your browser to the xkcd comic that joked that <code>import antigravity</code> in Python would grant you the ability to fly.</p>

<p>As for how the <code>antigravity</code> module opens your browser, it uses another module from the standard library called <code>webbrowser</code>. This module checks your PATH for a large variety of browsers, including mosaic, opera, skipstone, konqueror, chrome, chromium, firefox, links, elinks and lynx. It also accepts an environment variable <code>BROWSER</code> that lets you specify which process should be executed. It is not possible to supply arguments to the process in the environment variable and the xkcd comic URL is the one hard-coded argument for the command.</p>

<p>The ability to turn this into arbitrary code execution depends on what other executables are available on the system.</p>

<h2 id="leveraging-perl-for-arbitrary-code-execution">Leveraging Perl for Arbitrary Code Execution</h2>

<p>One approach is to leverage Perl which is commonly installed on systems and is even available in the standard Python docker image. However, the <code>perl</code> binary cannot itself be used. This is because the first and only argument is the xkcd comic URL. The comic URL argument will cause an error and the process to exit without the <code>PERL5OPT</code> environment variable being used.</p>

<figure>
  <figcaption>Figure-2: PERL5OPT having no effect when a URL is passed to perl</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perl https://xkcd.com/353/
<span>Can't open perl script "https://xkcd.com/353/": No such file or directory</span></code></pre></figure>

</figure>

<p>Fortunately, when Perl is available it also common to have the default Perl scripts available, such as perldoc and perlthanks. These scripts will also error and exit with an invalid argument, but the error in this case happens later than the processing of the <code>PERL5OPT</code> environment variable. This means you can leverage the Perl environment variable payload detailed earlier in this blog post.</p>

<figure>
  <figcaption>Figure-3: PERL5OPT working as intended with perldoc and perlthanks</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perldoc https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)
</span><span>$</span><span> </span>run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perlthanks https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>

<h2 id="proof-of-concept-1">Proof of Concept</h2>

<figure>
  <figcaption>Figure-4: arbitrary code execution achieved using multiple environment variables against Python 2 and Python 3</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:2.7.18 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'

</span><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:3.8.2 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'</span></code></pre></figure>

</figure>



<p>A <a href="https://research.securitum.com/prototype-pollution-rce-kibana-cve-2019-7609/">blog post</a> by <a href="https://twitter.com/securitymb">Michał Bentkowski</a> provided a payload for exploiting Kibana (CVE-2019-7609). A prototype pollution vulnerability was used to set arbitrary environment variables which resulted in arbitrary command execution. Michał’s payload used the <code>NODE_OPTIONS</code> environment variable and the <a href="https://en.wikipedia.org/wiki/Procfs">proc filesystem</a>, specifically <code>/proc/self/environ</code>.</p>

<p>Although Michał’s technique was creative and worked perfectly for their vulnerability, the technique is not always guaranteed to work and has some constraints that would be nice to remove.</p>

<p>The first constraint is that it using <code>/proc/self/environ</code> is only viable if the contents can be made to be syntactically valid JavaScript. This requires being able to create an environment variable and have it appear first in the contents of <code>/proc/self/environ</code>, or knowing/bruteforcing the environment variable’s name that will appear first and overwriting it’s value.</p>

<p>Another constraint, as the first environment variable’s value finishes with a single line comment (<code>//</code>). Therefore, any newline character in other environment variables will likely cause a syntax error and prevent the payload from executing. The use of multi-line comments (<code>/*</code>) will not fix this issue as they must be closed to be syntactically valid. Therefore, in the rare case that an environment variable contains a newline character, it is required to know/bruteforce the environment variable’s name and overwrite it’s value to a new value that does not contain a newline.</p>

<p>Removing these contraints is an exercise left for the reader.</p>

<h2 id="proof-of-concept-2">Proof of Concept</h2>

<figure>
  <figcaption>Figure-5: achieving arbitrary code execution with environment variables against NodeJS by Michał Bentkowski</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'NODE_VERSION=console.log(require("child_process").execSync("id").toString());//'</span> <span>-e</span> <span>'NODE_OPTIONS=--require /proc/self/environ'</span> node:14.2.0 node /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>If you run <code>ltrace -e getenv php /dev/null</code> you will find PHP uses the <code>PHPRC</code> environment variable.
The environment variable is used …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elttam.com/blog/env/">https://www.elttam.com/blog/env/</a></em></p>]]>
            </description>
            <link>https://www.elttam.com/blog/env/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827486</guid>
            <pubDate>Tue, 14 Jul 2020 01:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is QuantGov?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827427">thread link</a>) | @hhs
<br/>
July 13, 2020 | https://www.quantgov.org/about | <a href="https://web.archive.org/web/*/https://www.quantgov.org/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.quantgov.org/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827427</guid>
            <pubDate>Tue, 14 Jul 2020 00:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alex: An Updatable Adaptive Learned Index [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827257">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf | <a href="https://web.archive.org/web/*/https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827257</guid>
            <pubDate>Tue, 14 Jul 2020 00:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beyond Analytics: The Evolution of Stream Processing Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827170">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://streaming-research.github.io/Tutorial-SIGMOD-2020/ | <a href="https://web.archive.org/web/*/https://streaming-research.github.io/Tutorial-SIGMOD-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <h2 id="tutorial-information">Tutorial Information</h2>
<h3 id="wednesday-june-17-2020">Wednesday, June 17 2020</h3>
<h4 id="join-us-on-zoom-and-slack">Join us on <a href="https://acm-org.zoom.us/j/93450885761?pwd=OGZmekwyRFR2Q3ZTd3VwL3hsc0JlUT09">Zoom</a> and <a href="https://join.slack.com/t/sigmodpods/shared_invite/zt-em1btw2v-tTI9OXRtzi4apsMaCoqjTA">Slack</a></h4>

<h4 id="session-1-1030-am---1200-pm-pdt">Session 1: 10:30 AM - 12:00 PM PDT</h4>
<ul>
  <li>Part I: Introduction &amp; Fundamentals</li>
  <li>Part II: Time, Order, &amp; Progress</li>
  <li>Part III: State Management</li>
</ul>

<h4 id="session-2-130-pm---300-pm-pdt">Session 2: 1:30 PM - 3:00 PM PDT</h4>
<ul>
  <li>Part IV: Fault Recovery &amp; High Availability</li>
  <li>Part V: Load Management &amp; Elasticity</li>
  <li>Part VI: Prospects</li>
</ul>

<h2 id="overview">Overview</h2>
<p>Stream processing has been an active research field for more than 20 years, but it is now witnessing its prime time due to recent successful efforts by the research community and numerous worldwide open-source communities. The goal of this tutorial is threefold. First, we aim to review and highlight noteworthy past research findings, which were largely ignored until very recently. Second, we intend to underline the differences between early (’00-’10) and modern (’11-’18) streaming systems, and how those systems have evolved through the years. Most importantly, we wish to turn the attention of the database community to recent trends: streaming systems are no longer used only for classic stream processing workloads, namely window aggregates and joins. Instead, modern streaming systems are being increasingly used to deploy general event-driven applications in a scalable fashion, challenging the design decisions, architecture and intended use of existing stream processing systems.</p>

<h2 id="presenters">Presenters</h2>

<ul>
  <li><a href="https://www.ri.se/en/paris-carbone">Paris Carbone</a> (RISE)</li>
  <li><a href="http://mariosfragkoulis.gr/">Marios Fragkoulis</a> (Delft University of Technology)</li>
  <li><a href="https://cs-people.bu.edu/vkalavri/">Vasiliki Kalavri</a> (Boston University)</li>
  <li><a href="http://asterios.katsifodimos.com/">Asterios Katsifodimos</a> (Delft University of Technology)</li>
</ul>

<h2 id="slides-and-videos">Slides and Videos</h2>

<ol>
  <li>Introduction and fundamentals <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part1-introduction.pdf">[Slides]</a> <a href="https://youtu.be/6qmwLKzXdgM">[Video]</a></li>
  <li>Time, order, and progress <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part2-time.pdf">[Slides]</a> <a href="https://youtu.be/sWcMx52eP58">[Video]</a></li>
  <li>State management and guarantees <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part3-state-management.pdf">[Slides]</a> <a href="https://youtu.be/Zgy5a5tBOco">[Video]</a></li>
  <li>Advanced fault recovery and high availability <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part4-Fault-HA.pdf">[Slides]</a> <a href="https://youtu.be/p3zXV2w_MgM">[Video - Part I]</a> <a href="https://youtu.be/28CRUcFAGPs">[Video - Part II]</a></li>
  <li>Load management and elasticity <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part5-load-management.pdf">[Slides]</a> <a href="https://youtu.be/Pxe0M-mprOM">[Video]</a></li>
  <li>Prospects and discussion <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part6-prospects.pdf">[Slides]</a> <a href="https://youtu.be/DW9kU7gCL8A">[Video]</a></li>
</ol>

<h2 id="cite-pdf">Cite (<a href="https://dl.acm.org/doi/abs/10.1145/3318464.3383131">PDF</a>)</h2>

<div><div><pre><code>@inproceedings{10.1145/3318464.3383131,
author = {Carbone, Paris and Fragkoulis, Marios and Kalavri, Vasiliki and Katsifodimos, Asterios},
title = {Beyond Analytics: The Evolution of Stream Processing Systems},
year = {2020},
isbn = {9781450367356},
doi = {10.1145/3318464.3383131},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {2651–2658}
}
</code></pre></div></div>



      </section>
    </div></div>]]>
            </description>
            <link>https://streaming-research.github.io/Tutorial-SIGMOD-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827170</guid>
            <pubDate>Tue, 14 Jul 2020 00:12:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826786">thread link</a>) | @elsewhen
<br/>
July 13, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826786</guid>
            <pubDate>Mon, 13 Jul 2020 23:20:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark (Changelog)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826706">thread link</a>) | @tosh
<br/>
July 13, 2020 | https://darklang.github.io/docs/changelog/#july-13th-2020 | <a href="https://web.archive.org/web/*/https://darklang.github.io/docs/changelog/#july-13th-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Dark gets better each week! Here is a brief list of the fixes, new features, and
updates.</p><h2>July 13th, 2020</h2><h3>Product changes</h3><ul><li>Secrets now work in Functions
(<a href="https://github.com/darklang/dark/pull/2724" target="_blank" rel="noopener noreferrer">#2724</a>)</li><li>When copying strings from live values, Dark now omits the quotes
(<a href="https://github.com/br1anchen" target="_blank" rel="noopener noreferrer">Brian Chen</a>,
<a href="https://github.com/darklang/dark/pull/2723" target="_blank" rel="noopener noreferrer">#2723</a>)</li><li>Renaming rebound variables now properly renames the variables in the
right-hand side of the rebinding expression
(<a href="https://github.com/br1anchen" target="_blank" rel="noopener noreferrer">Brian Chen</a>,
<a href="https://github.com/darklang/dark/pull/2722" target="_blank" rel="noopener noreferrer">#2722</a>)
<img src="https://darklang.github.io/img/changelog/2722.gif" alt="Renaming a variable"></li><li>Added support for <code>Date::atStartOfDay</code>, <code>Date::day</code> ,
<code>Date::minute</code>,<code>Date::month</code> ,<code>Date::second</code>, and <code>Date::year</code> to the query
compiler. (<a href="https://github.com/cooleydw494" target="_blank" rel="noopener noreferrer">David Cooley</a>,
<a href="https://github.com/darklang/dark/pull/2720" target="_blank" rel="noopener noreferrer">#2720</a>)</li><li>Ensure the autocomplete menu covers the play button
(<a href="https://github.com/br1anchen" target="_blank" rel="noopener noreferrer">Brian Chen</a>,
<a href="https://github.com/darklang/dark/pull/2717" target="_blank" rel="noopener noreferrer">#2717</a>)</li><li>Show unused functions in a different color (to signify that they are unused
and can be deleted) (<a href="https://github.com/darklang/dark/pull/2713" target="_blank" rel="noopener noreferrer">#2713</a>)
<img src="https://darklang.github.io/img/changelog/2713.png" alt="Unused functions in a different color"></li><li>Show canvas name in the browser's title (useful if you've multiple canvases
open) (<a href="https://github.com/darklang/dark/pull/2708" target="_blank" rel="noopener noreferrer">#2708</a>)</li><li>Highlight duplicate fields in records in red to indicate an error
(<a href="https://github.com/br1anchen" target="_blank" rel="noopener noreferrer">Brian Chen</a>,
<a href="https://github.com/darklang/dark/pull/2705" target="_blank" rel="noopener noreferrer">#2705</a>)
<img src="https://darklang.github.io/img/changelog/2705.png" alt="Duplicate fields, highlighted in red"></li><li>Add support for <code>String::replaceAll</code> to the query compiler
(<a href="https://github.com/cooleydw494" target="_blank" rel="noopener noreferrer">David Cooley</a>,
<a href="https://github.com/darklang/dark/pull/2692" target="_blank" rel="noopener noreferrer">#2692</a>)</li><li>Typing a comma in a list will now complete the autocomplete
(<a href="https://github.com/actuallymab" target="_blank" rel="noopener noreferrer">Mehmet Aydin Bahadir</a>,
<a href="https://github.com/darklang/dark/pull/2650" target="_blank" rel="noopener noreferrer">#2650</a>)</li></ul><h3>Documentation and tutorial changes</h3><ul><li>The footer on <a href="https://darklang.com/">https://darklang.com</a> now points to many
more Learning and Community pages
<img src="https://darklang.github.io/img/changelog/footer.png" alt="The new homepage footer"></li><li>Documentation now supports a Dark mode</li></ul><h3>Contributor-related changes</h3><ul><li>Greatly expand the "General Concepts" documentation
(<a href="https://github.com/darklang/docs/pull/175" target="_blank" rel="noopener noreferrer">#175</a>)</li><li>Improve documentation around using vim with merlin
(<a href="https://github.com/fmilani" target="_blank" rel="noopener noreferrer">Felipe Milani</a>,
<a href="https://github.com/darklang/dark/pull/2685" target="_blank" rel="noopener noreferrer">#2685</a>)</li><li>The repo has standardized on "allowlist" and "blocklist"
<a href="https://github.com/darklang/dark/pull/2636" target="_blank" rel="noopener noreferrer">#2636</a>)</li><li>Change the default branch on Dark repos to <code>main</code><a href="https://github.com/darklang/dark/pull/2635" target="_blank" rel="noopener noreferrer">#2635</a>)</li><li>New PR template (<a href="https://github.com/darklang/dark/pull/2632" target="_blank" rel="noopener noreferrer">#2632</a>)</li><li>Update the Pull Request
<a href="https://darklang.com/docs/contributing/making-a-pull-request" target="_blank" rel="noopener noreferrer">code checklist</a></li></ul><h2>Weeks of 6/15/2020 and 6/22/2020</h2><ul><li>There has been a
<a href="https://medium.com/darklang/dark-and-the-long-term-2c65ff0baf5e" target="_blank" rel="noopener noreferrer">significant restructure</a>
to the Dark project. We'll write more about this going forward: Paul has
<a href="https://dev.to/darklang/dark-devlog-1-fresh-start-1i2" target="_blank" rel="noopener noreferrer">a new devlog</a> that
talks about it.</li><li>We now have a
<a href="https://darkcommunity.slack.com/archives/C016LAW6W73/" target="_blank" rel="noopener noreferrer">status channel</a> in the
community Slack. You can join the Slack community
<a href="https://darklang.com/slack-invite" target="_blank" rel="noopener noreferrer">here</a>!</li><li>The <a href="https://github.com/darklang/dark" target="_blank" rel="noopener noreferrer">Dark repo</a> is now <em>source available</em>.
This hasn't been publicly announced yet, but you can now
<a href="https://github.com/darklang/dark/issues" target="_blank" rel="noopener noreferrer">file issues</a> directly, and also
<a href="https://docs.darklang.com/contributing/getting-started" target="_blank" rel="noopener noreferrer">contribute</a>.</li><li>Added a contributing doc, showing how you can help if
<a href="https://darklang.com/docs/contributing/if-you-dont-know-ocaml" target="_blank" rel="noopener noreferrer">you don't know OCaml</a>.</li><li><code>Date::hour_v1</code> is now supported in the query compiler.
(<a href="https://github.com/cooleydw494" target="_blank" rel="noopener noreferrer">David Cooley</a>,
<a href="https://github.com/darklang/dark/pull/2639" target="_blank" rel="noopener noreferrer">#2639</a>)</li><li>When code is not synced due to the server being unavailable, an error message
correctly explains what happened (<a href="https://github.com/fmilani" target="_blank" rel="noopener noreferrer">Felipe Milani</a>,
<a href="https://github.com/darklang/dark/pull/2605" target="_blank" rel="noopener noreferrer">#2605</a>)</li><li><code>HTTPClient</code> requests coming from Dark now time out after 30 seconds
<a href="https://github.com/darklang/dark/pull/2661" target="_blank" rel="noopener noreferrer">#2661</a></li></ul><h2>Week of 6/12/2020</h2><ul><li><p>Secrets are now available! Now you can store API keys, passwords and other
sensitive information separately from the rest of your canvas. Secrets will
appear in autocomplete in handlers across your entire canvas. They will appear
redacted in traces and live values, so it's now easier to stream and
screenshot your Dark code!</p><p><img src="https://darklang.github.io/img/changelog/June12/secrets.png" alt="changelog/June12/secrets.png"></p></li><li><p>Onboarding and tooltip updates</p><ul><li>The styling of our tooltips and initial tutorial has been updated</li></ul><p><img src="https://darklang.github.io/img/changelog/June12/tooltips.png" alt="changelog/June12/tooltips.png"></p><ul><li>Tips are now available in the function space.</li><li>More helpful links have been added to the avatar menu.</li></ul></li><li><p>The SQL compiler now supports <code>Date::add</code> and <code>Date::subtract</code>
(<a href="https://github.com/aashanand" target="_blank" rel="noopener noreferrer">Aash Anand</a>)</p></li><li><p>The newest version of a function will now always appear first in autocomplete
(<a href="https://github.com/fmilani" target="_blank" rel="noopener noreferrer">Felipe Milani</a>)</p></li><li><p>Standard library functions added:</p><ul><li><code>Date::atStartOfDay</code> (<a href="https://github.com/mwz" target="_blank" rel="noopener noreferrer">Michael Wizner</a>)</li><li><code>Date::today</code> (<a href="https://github.com/ThomasMarcel" target="_blank" rel="noopener noreferrer">Thomas Alcala Schneider</a>)</li><li><code>List::dropWhile</code>
(<a href="https://github.com/ThomasMarcel" target="_blank" rel="noopener noreferrer">Thomas Alcala Schneider</a>)</li></ul></li><li><p>The following contributors wrote and updated tests and made CSS improvements:
<a href="https://github.com/billy1kaplan" target="_blank" rel="noopener noreferrer">billy1kaplan</a>,
<a href="https://github.com/br1anchen" target="_blank" rel="noopener noreferrer">Brian Chen</a></p></li></ul><h3>Documentation</h3><ul><li>Detailed documentation is now available around
<a href="https://darklang.com/docs/component-worker" target="_blank" rel="noopener noreferrer">workers</a> and
<a href="https://darklang.com/docs/component-cron" target="_blank" rel="noopener noreferrer">crons</a></li><li>We've begun to create short videos explaining Dark concepts. They will be
added throughout the documentation, and a
<a href="https://www.youtube.com/playlist?list=PLpcgNq_UYVoNZVoPEdqoNVemixjkrye83" target="_blank" rel="noopener noreferrer">full playlist</a>
is available on our
<a href="https://www.youtube.com/channel/UCYUv1H0ENhZa4lNjOL-EiYg/featured" target="_blank" rel="noopener noreferrer">Youtube channel</a>.</li></ul><h2>Week of 6/5/2020</h2><ul><li>Function references now appear when you're using a
<a href="https://darklang.com/docs/packages" target="_blank" rel="noopener noreferrer">package manager</a> function.</li></ul><p><img src="https://darklang.github.io/img/changelog/June5/Screen_Shot_2020-06-05_at_2.08.39_PM.png" alt="changelog/June5/Screen_Shot_2020-06-05_at_2.08.39_PM.png"></p><ul><li><p>We've updated some tips and error messages.</p><ul><li>On 404s</li></ul><p><img src="https://darklang.github.io/img/changelog/June5/Screen_Shot_2020-06-05_at_2.10.46_PM.png" alt="changelog/June5/Screen_Shot_2020-06-05_at_2.10.46_PM.png"></p><ul><li>On functions that have not yet been run</li></ul><p><img src="https://darklang.github.io/img/changelog/June5/Screen_Shot_2020-06-05_at_2.14.05_PM.png" alt="changelog/June5/Screen_Shot_2020-06-05_at_2.14.05_PM.png"></p><ul><li>When attempting field access on a datastore</li></ul></li></ul><p><img src="https://darklang.github.io/img/changelog/June5/Screen_Shot_2020-06-05_at_2.16.10_PM.png" alt="changelog/June5/Screen_Shot_2020-06-05_at_2.16.10_PM.png"></p><ul><li>If you attempt to access Dark via a browser other than Chrome we now link you
to our <a href="http://darklang.com/desktop-client" target="_blank" rel="noopener noreferrer">experimental desktop client</a>.</li><li>Variables can now be converted to lists by pressing <code>[</code>
(<a href="https://github.com/pingiun" target="_blank" rel="noopener noreferrer">Jelle Besseling</a>)</li></ul><p><img src="https://darklang.github.io/img/changelog/June5/2020-06-05_14.19.05.gif" alt="changelog/June5/2020-06-05_14.19.05.gif"></p><ul><li>Added a <code>convert-if-to-match</code> option to the command palette
(<a href="https://github.com/pingiun" target="_blank" rel="noopener noreferrer">Jelle Besseling</a>)</li></ul><p><img src="https://darklang.github.io/img/changelog/June5/2020-06-05_14.21.05.gif" alt="changelog/June5/2020-06-05_14.21.05.gif"></p><ul><li>References are now shown in the order in which they appear
(<a href="https://github.com/pingiun" target="_blank" rel="noopener noreferrer">Jelle Besseling</a>)</li><li><code>String::trim</code> functions are now supported in the query compiler
(<a href="https://github.com/cooleydw494" target="_blank" rel="noopener noreferrer">David Cooley</a>)</li><li><code>DB::getMany</code> now returns an <code>Option</code>
(<a href="https://github.com/naclcaleb" target="_blank" rel="noopener noreferrer">Caleb H</a>)</li><li>Added font-ligature for lambas (<a href="https://github.com/s0kil" target="_blank" rel="noopener noreferrer">Daniel Sokil</a>)</li><li>Copy to cURL now uses single quotes instead of double quotes
(<a href="https://github.com/pingiun" target="_blank" rel="noopener noreferrer">Jelle Besseling</a>)</li></ul><h3>Standard library</h3><ul><li>Standard library functions added:<ul><li><code>Crypto::md5</code> (<a href="https://github.com/pingiun" target="_blank" rel="noopener noreferrer">Jelle Besseling</a>)</li><li><code>List::member</code> (<a href="https://github.com/xtopherbrandt" target="_blank" rel="noopener noreferrer">Christopher Brandt</a>)</li><li><code>List::takeWhile</code> (<a href="https://github.com/pingiun" target="_blank" rel="noopener noreferrer">Jelle Besseling</a>)</li><li><code>DB::queryCount</code> (<a href="https://github.com/brandonhamilton" target="_blank" rel="noopener noreferrer">Brandon Hamilton</a>)</li><li><code>DB::getExisting</code> (<a href="https://github.com/naclcaleb" target="_blank" rel="noopener noreferrer">Caleb H</a>)</li><li><code>String::prepend</code> (<a href="https://github.com/brandonhamilton" target="_blank" rel="noopener noreferrer">Brandon Hamilton</a>)</li></ul></li></ul><h3>External contributions</h3><p>We have started taking external contributions, thanks so much to all the folks
who contributed. In addition to the user facing changes above, contributors also
added:</p><ul><li>Switched the Dark repo from using <code>yarn</code> to <code>npm</code>
(<a href="https://github.com/snasirca" target="_blank" rel="noopener noreferrer">Shahriyar Nasir</a>)</li><li>Updated Linux defaults to make it easier for Linux users to compile and
rebuild Dark (<a href="https://github.com/ggajos" target="_blank" rel="noopener noreferrer">Grzegorz Gajos</a>)</li><li>Added tests (<a href="https://github.com/fmilani" target="_blank" rel="noopener noreferrer">Felipe Milani</a>,
<a href="https://github.com/cooleydw494" target="_blank" rel="noopener noreferrer">David Cooley</a>,
<a href="https://github.com/pingiun" target="_blank" rel="noopener noreferrer">Jesse Besseling</a>,
<a href="https://github.com/JustusMoeller" target="_blank" rel="noopener noreferrer">Justus Moeller</a>,
<a href="https://github.com/xtopherbrandt" target="_blank" rel="noopener noreferrer">Christopher Brandt</a>,
<a href="https://github.com/aashanand" target="_blank" rel="noopener noreferrer">Aash Anand</a>)</li><li>Made documentation fixes (<a href="https://github.com/danieljcafonso" target="_blank" rel="noopener noreferrer">Daniel Afonso</a>,
<a href="https://github.com/pingiun" target="_blank" rel="noopener noreferrer">Jesse Besseling</a>)</li></ul><h3>Documentation</h3><ul><li>Added a guide to help contributors with
<a href="https://darklang.com/docs/contributing/ocaml-for-dark-developers" target="_blank" rel="noopener noreferrer">writing code in OCaml</a></li><li>Added a tutorial around writing
<a href="https://darklang.com/docs/tutorials/error-rail-http-tutorial" target="_blank" rel="noopener noreferrer">clean error messages using the error rail</a></li></ul><h2>Week of 5/29/2020</h2><ul><li>It's now possible to set a return type for functions. The return type will
appear in the autocomplete and type errors will be displayed when necessary,
making it easier to know that your functions work, and making it easier to use
and understand functions. This means that your functions can also now use the
Error Rail, if you set their return type to Result or Option.</li></ul><p><img src="https://darklang.github.io/img/changelog/returntypes.png" alt="changelog/returntypes.png"></p><ul><li>Datastores can now have fields named id. This was contributed by our first
external contributor, <a href="https://github.com/naclcaleb" target="_blank" rel="noopener noreferrer">Caleb H</a>!</li></ul><h3>Documentation</h3><ul><li>Added:<ul><li>A section around
<a href="https://darklang.github.io/contributing/getting-started">submitting external contributions</a>
(<a href="https://darklang.com/docs/contributing/getting-started" target="_blank" rel="noopener noreferrer">134</a>)</li><li>A guide around <a href="https://darklang.github.io/when-dark">when and when not to use Dark</a>
(<a href="https://github.com/darklang/docs/pull/133" target="_blank" rel="noopener noreferrer">133</a>)</li><li>Expanded information about
<a href="https://darklang.github.io/datastores#migrations-locking-and-unlocking">Datastore migrations</a>
(<a href="https://github.com/darklang/docs/pull/141" target="_blank" rel="noopener noreferrer">141</a>)</li><li>A <a href="https://darklang.github.io/from-javascript">From Javascript page</a> to help developers familiar with
Javascript learn Dark (<a href="https://github.com/darklang/docs/pull/132" target="_blank" rel="noopener noreferrer">132</a>)</li><li>Documentation for the
<a href="https://darklang.github.io/packages#createcheckoutsession"><code>Slack::createCheckoutSession</code></a> package
(<a href="https://github.com/darklang/docs/pull/139" target="_blank" rel="noopener noreferrer">139</a>)</li></ul></li><li>Made a few improvements to the <a href="https://darklang.github.io/your-first">Your First App</a> tutorial
(<a href="https://github.com/darklang/docs/pull/129" target="_blank" rel="noopener noreferrer">129</a>,
<a href="https://github.com/darklang/docs/pull/130" target="_blank" rel="noopener noreferrer">130</a>)</li><li>Misc. spelling fixes (<a href="https://github.com/darklang/docs/pull/128" target="_blank" rel="noopener noreferrer">128</a>,
<a href="https://github.com/darklang/docs/pull/136" target="_blank" rel="noopener noreferrer">136</a>)</li></ul><h2>Week of 5/22/2020</h2><ul><li>We've added more information to the sidebar! If you're not sure what a section
in the sidebar is for, click on its name and more details will appear on the
right side of your canvas.</li></ul><p><img src="https://darklang.github.io/img/changelog/sidebar.gif" alt="changelog/sidebar.gif"></p><ul><li>We've done some major infrastructure work behind the Cron scheduler, which
significantly improved its performance. You should now see all Crons,
including those with a 1 minute interval, running on time again.</li><li>Return values and execution fade are no longer stale when taking functions
on/off the <a href="https://darklang.github.io/error-handling#error-rail">error rail</a> or when committing
<a href="https://darklang.github.io/feature-flags">feature flags</a>.</li></ul><h3>Documentation</h3><p>Thank you to everyone who contributed to our docs this week! As a reminder, our
docs repo is public and all you need to do to contribute is
<a href="https://github.com/darklang/docs/pulls" target="_blank" rel="noopener noreferrer">submit a pull request</a>.</p><ul><li>Added instructions for <a href="https://darklang.github.io/static-assets">hosting static assets</a> when not using
an external framework. (<a href="https://github.com/darklang/docs/pull/119" target="_blank" rel="noopener noreferrer">119</a>)</li><li>Fixed a broken link on the <a href="https://darklang.github.io/languagedetails">Language Details</a> page.
(<a href="https://github.com/darklang/docs/pull/117" target="_blank" rel="noopener noreferrer">117</a>)</li><li>Added instructions on how to pause your cron once you're done with the
<a href="https://darklang.github.io/your-first">Your First App</a> tutorial.
(<a href="https://github.com/darklang/docs/pull/122" target="_blank" rel="noopener noreferrer">122</a>)</li><li>New how-to pages:<ul><li><a href="https://darklang.github.io/feature-flags">Feature flags</a>
(<a href="https://github.com/darklang/docs/pull/118" target="_blank" rel="noopener noreferrer">118</a>)</li><li><a href="https://darklang.github.io/writing-tests">Writing tests</a>
(<a href="https://github.com/darklang/docs/pull/120" target="_blank" rel="noopener noreferrer">120</a>)</li><li><a href="https://darklang.github.io/external-infra">Connecting to external infrastructure</a>
(<a href="https://github.com/darklang/docs/pull/126" target="_blank" rel="noopener noreferrer">126</a>)</li></ul></li><li>New tutorials:<ul><li><a href="https://darklang.github.io/tutorials/external-db">Using an external DB</a>
(<a href="https://github.com/darklang/docs/pull/124" target="_blank" rel="noopener noreferrer">124</a>)</li><li><a href="https://darklang.github.io/tutorials/ifttt-alerts">Alerting with IFTTT</a>
(<a href="https://github.com/darklang/docs/pull/125" target="_blank" rel="noopener noreferrer">125</a>)</li></ul></li></ul><h2>Week of 5/15/2020</h2><ul><li>We've added a Hello World tutorial that will show automatically for new
accounts. It can also be accessed via the avatar menu.</li></ul><p><img src="https://darklang.github.io/img/changelog/helloworld.png" alt="changelog/helloworld.png"></p><ul><li><a href="https://darklang.com/docs/packages" target="_blank" rel="noopener noreferrer">Package manager functions</a> and their
underlying code can now be accessed via the sidebar. These functions will
appear in the autocomplete, and can be used like any other built-in function.</li></ul><p><img src="https://darklang.github.io/img/changelog/packagemanager.png" alt="changelog/packagemanager.png"></p><ul><li>It's now easier to add 404s to your canvas - the entire line is now clickable,
instead of just the plus sign.</li><li>Made a ton of small fixes to feature flags:<ul><li>The correct docstring now shows when a feature flag is selected</li><li>Feature flag expressions now show the correct live value</li><li>Feature flags are now correctly created after pressing <code>Cmd+a</code> to select
everything.</li><li>Feature flags no longer incorrectly display the "code was not run executed
in this trace" error message.</li></ul></li><li>404s should no longer appear off-screen when added to your canvas.</li><li>When possible, we now display more information where we were previously
showing <code>&lt;Incomplete&gt;</code> messages.</li><li>Clicking to go to an error on an infix function now works as expected.</li><li>The command palette will no longer appear behind other handlers when opened.</li></ul><h3>Documentation</h3><ul><li>Reorganized our documentation site, breaking tutorials &amp; samples into their
own section.</li><li>Added a <a href="https://darklang.com/docs/from-python" target="_blank" rel="noopener noreferrer">From Python</a> page to help
developers familiar with Python learn Dark.</li><li>Added three sample canvases:<ul><li><a href="https://darklang.com/a/sample-gcpbucket" target="_blank" rel="noopener noreferrer">GCP Bucket</a></li><li><a href="https://darklang.com/a/sample-firebaseauth" target="_blank" rel="noopener noreferrer">Firebase Auth</a></li><li><a href="https://darklang.com/a/sample-crud" target="_blank" rel="noopener noreferrer">CRUD app</a></li></ul></li><li>Added a <a href="https://darklang.com/docs/slack-apps/slack-oauth" target="_blank" rel="noopener noreferrer">Setting Up OAuth</a>
page to the
<a href="https://darklang.com/docs/slack-apps/slack-intro" target="_blank" rel="noopener noreferrer">Building Slack Apps</a>
section.</li></ul><h2>Week of 5/8/2020</h2><ul><li>We now have Dark badges for your sites! Add a
<a href="https://darklang.com/docs/sharing-dark" target="_blank" rel="noopener noreferrer">Made With Dark badge</a> to your apps to
establish your early Dark expertise 🎉</li></ul><p><img src="https://darklang.github.io/img/changelog/badge.png" alt="changelog/badge.png"></p><ul><li>Clicking on a link in the sidebar will now always jump you to the correct
place on the canvas. This was a super annoying bug that we internally referred
to as "the dreaded positioning bug", and it is finally fixed. A blog post will
be out describing the horror show behind this next week.</li><li>Copying &amp; pasting now works properly for pipes! We'll no longer lose arguments
when copying between piped and non-piped expressions.</li><li>Re-ordering function parameters works again. You can drag a function parameter
to change its order (and we'll reorder the callers too).</li><li>When you invite people (go to Settings), we'll error properly if the invite
failed.</li><li>When you try to access Dark in Firefox or other browsers, we'll tell you it
won't work instead of crashing.</li><li>You can now drag much more of a handler to move it (now including the
docstring and return value boxes)</li><li>When clicking on traces with errors, we'll no longer incorrectly color the
trace dots.</li><li><code>Result::map2</code> and 5 other <code>Result</code> functions now goes to the error rail.</li><li>When you press <code>,</code> to add another entry to a list, we'll now support it on
both sides of an existing <code>,</code>.</li></ul><h2>Week of 5/1/2020</h2><ul><li>We now show you the exact execution path of a trace, making it easy to
understand …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://darklang.github.io/docs/changelog/#july-13th-2020">https://darklang.github.io/docs/changelog/#july-13th-2020</a></em></p>]]>
            </description>
            <link>https://darklang.github.io/docs/changelog/#july-13th-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826706</guid>
            <pubDate>Mon, 13 Jul 2020 23:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defragging Your Brain (2012)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826671">thread link</a>) | @tosh
<br/>
July 13, 2020 | https://www.theslowhunch.net/2012/defragging-your-brain-the-slow-hunch-and-open-commonplace-books/ | <a href="https://web.archive.org/web/*/https://www.theslowhunch.net/2012/defragging-your-brain-the-slow-hunch-and-open-commonplace-books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1713">

                    
                    
                    
                    <div>
                        <p>Alex Hillman has a <a href="http://alexhillman.com/defrag-your-brain-with-a-sparkfile">nice post</a> on his response to Steven Johnson’s <a href="http://www.amazon.com/Where-Good-Ideas-Come-From/dp/1594487715?tag=duckduckgo-d-20">Where do Good Ideas Come From</a>, thinking about how we continually process and re-process our information. &nbsp;It mentions one specific method, which Steven calls “<a href="https://medium.com/p/8d6e7df7ae58">the spark file</a>“. &nbsp;The idea being that you keep a simple log of “sparks” — thoughts that come to at all hours of the day — and review that log regularly to help you understand how these ideas combine and relate to one another. &nbsp;The result — which makes perfect sense to me — is a “defragmentation” of your brain: the opportunity to take these seemingly scattered thoughts and smooth them back together into coherent ideas.</p>
<p>This is something I’ve thought about for a long time. &nbsp;Steven is also one of my favorite authors. &nbsp;This blog is named after the core idea in Where Good Ideas Come From, “the slow hunch”. &nbsp;A few years ago, after reading that book, I wrote up an idea for something I wanted to help me manage this process for myself, which I called the <a title="Wanted: An Open Commonplace Book" href="http://wayback.theslowhunch.net/2010/12/wanted-an-open-commonplace-book/">Open Commonplace Book</a>. &nbsp;The gist of that idea being that my “sparks” are distributed across a lot of sources — tumblr posts, tweets, notes to self, etc. &nbsp;And I’d love a way to help recombine them.</p>
<p>Since then, I’ve done this, in some way. &nbsp;I keep a private blog — and I actually call the posts “sparks”, which is funny — which I try to write to every day. &nbsp;I also use Notational Velocity and SimpleNote to keep running lists of notes to self. &nbsp;This is pretty good for input, but I know that I’m still not getting the most I can interms of reviewing and recombining.</p>
<p>What I like so much about the “spark file” idea is how simple it is. &nbsp;Just keep adding ideas, sequentially, and continually read back through them. &nbsp;Then see what happens.</p>
<p>This process of de-fragging your brain is really important. &nbsp;For building your slow hunches, and for helping you focus. &nbsp;A few days ago Nate Matias passed along <a href="http://nickgrossman.tumblr.com/post/31190234755/how-to-focus-in-the-age-of-distraction-via#notes">this mind map for building focus</a>, which I basically agree with wholesale, and which touches on the value of reflecting and de-fragging your brain (whether you use a spark file or some other method).</p>
<p>Everything these days is about how we process and manage our information. &nbsp;It’s hard and will only continue to get harder. &nbsp;But being mindful of this, and being disciplined in approaching it, will no doubt pay big dividends.</p>
                                            </div>

                </article></div>]]>
            </description>
            <link>https://www.theslowhunch.net/2012/defragging-your-brain-the-slow-hunch-and-open-commonplace-books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826671</guid>
            <pubDate>Mon, 13 Jul 2020 23:07:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Platonic solids and fundamental tests of quantum mechanics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826281">thread link</a>) | @mathgenius
<br/>
July 13, 2020 | https://quantum-journal.org/papers/q-2020-07-09-293/ | <a href="https://web.archive.org/web/*/https://quantum-journal.org/papers/q-2020-07-09-293/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The Platonic solids is the name traditionally given to the five regular convex polyhedra, namely the tetrahedron, the octahedron, the cube, the icosahedron and the dodecahedron. Perhaps strongly boosted by the towering historical influence of their namesake, these beautiful solids have, in well over two millennia, transcended traditional boundaries and entered the stage in a range of disciplines. Examples include natural philosophy and mathematics from classical antiquity, scientific modeling during the days of the European scientific revolution and visual arts ranging from the renaissance to modernity. Motivated by mathematical beauty and a rich history, we consider the Platonic solids in the context of modern quantum mechanics. Specifically, we construct Bell inequalities whose maximal violations are achieved with measurements pointing to the vertices of the Platonic solids. These Platonic Bell inequalities are constructed only by inspecting the visible symmetries of the Platonic solids. We also construct Bell inequalities for more general polyhedra and find a Bell inequality that is more robust to noise than the celebrated Clauser-Horne-Shimony-Holt Bell inequality. Finally, we elaborate on the tension between mathematical beauty, which was our initial motivation, and experimental friendliness, which is necessary in all empirical sciences.</p><div id="references">			 <p><a id="CHSH">[1]</a> J. F. Clauser, M. A. Horne, A. Shimony, and R. A. Holt, Proposed Experiment to Test Local Hidden-Variable Theories, Phys. Rev. Lett. 23, 880 (1969). <br><a href="https://doi.org/10.1103/PhysRevLett.23.880">https:/​/​doi.org/​10.1103/​PhysRevLett.23.880</a></p>			 <p><a id="Arndt">[2]</a> M. Arndt, O. Nairz, J. Vos-Andreae, C. Keller, G. van der Zouw and A. Zeilinger, Wave–particle duality of C60 molecules, Nature 401, 680 (1999). <br><a href="https://doi.org/10.1038/44348">https:/​/​doi.org/​10.1038/​44348</a></p>			 <p><a id="Hossenfelder">[3]</a> Sabine Hossenfelder, Lost in Math: How Beauty Leads Physics Astray, Basic Book 2018.</p>			 <p><a id="Wilson">[4]</a> Encyclopedia of Ancient Greece, N. W. Wilson. Taylor &amp; Francis 2010.</p>			 <p><a id="Boyer">[5]</a> A History of Mathematics, U. C. Merzbach and C. B. Boyer. John Wiley &amp; Sons, Third edition 2011.</p>			 <p><a id="Proklos">[6]</a> A Commentary on the First Book of Euclid's Elements, Proklos Diadochos. Princeton University Press, Reprint edition 1992.</p>			 <p><a id="Archimedes">[7]</a> A History of Mechanical Inventions, A. P. Usher. Harvard University Press, Revised Edition 2011.</p>			 <p><a id="Pythagoras">[8]</a> Measuring Heaven: Pythagoras and His Influence on Thought and Art in Antiquity and the Middle Ages, C. L. Joost-Gaugier. Cornell University Press 2007.</p>			 <p><a id="TheRepublic">[9]</a> The Republic, VII, Plato.</p>			 <p><a id="Timaeus">[10]</a> Timaeus, Plato. Hackett Publishing Company, Second edition 2000.</p>			 <p><a id="Livio">[11]</a> The Golden Ratio: The Story of Phi, the World's Most Astonishing Number, M. Livio. Broadway Books; Reprint edition 2003.</p>			 <p><a id="MagicMirror">[12]</a> The Magic Mirror of M. C. Escher, B. Ernst. Ballantine Books, 1976.</p>			 <p><a id="Kepler">[13]</a> E. Aiton, Johannes Kepler and the 'Mysterium Cosmographicum', Sudhoffs Archiv, Bd. 61, H. 2 (1977 2. QUARTAL), pp. 173-194.</p>			 <p><a id="QuasiCrystal">[14]</a> D. Monroe, Focus: Nobel Prize-Discovery of Quasicrystals, Phys. Rev. Focus 28, 14 (2011).</p>			 <p><a id="Noneuclid">[15]</a> History of the Parallel Postulate, F. P. Lewis, The American Mathematical Monthly, Vol. 27, No. 1. (Jan., 1920), pp. 16-23.</p>			 <p><a id="Chance">[16]</a> N. Gisin, Quantum Chance, Springer 2014.</p>			 <p><a id="Bell">[17]</a> J. S. Bell, On the Einstein Podolsky Rosen Paradox, Physics Vol 1, 3 pp.195-200 (1964). <br><a href="https://doi.org/10.1103/PhysicsPhysiqueFizika.1.195">https:/​/​doi.org/​10.1103/​PhysicsPhysiqueFizika.1.195</a></p>			 <p><a id="RMP">[18]</a> N. Brunner, D. Cavalcanti, S. Pironio, V. Scarani, and S. Wehner, Bell nonlocality, Rev. Mod. Phys. 86, 419 (2014). <br><a href="https://doi.org/10.1103/RevModPhys.86.419">https:/​/​doi.org/​10.1103/​RevModPhys.86.419</a></p>			 <p><a id="Clauser">[19]</a> S. J. Freedman and J. F. Clauser, Experimental Test of Local-Hidden-Variable Theories, Phys. Rev. Lett. 28, 938 (1972). <br><a href="https://doi.org/10.1103/PhysRevLett.28.938">https:/​/​doi.org/​10.1103/​PhysRevLett.28.938</a></p>			 <p><a id="Aspect">[20]</a> A. Aspect, P. Grangier, and G. Roger, Experimental Tests of Realistic Local Theories via Bell's Theorem, Phys. Rev. Lett. 47, 460 (1981). <br><a href="https://doi.org/10.1103/PhysRevLett.47.460">https:/​/​doi.org/​10.1103/​PhysRevLett.47.460</a></p>			 <p><a id="LoopholeFree">[21]</a> B. Hensen et. al., Loophole-free Bell inequality violation using electron spins separated by 1.3 kilometres, Nature 526, 682 (2015); L. K. Shalm et. al., Strong Loophole-Free Test of Local Realism, Phys. Rev. Lett. 115, 250402 (2015); M. Giustina et. al., Significant-Loophole-Free Test of Bell's Theorem with Entangled Photons, Phys. Rev. Lett. 115, 250401 (2015). <br><a href="https://doi.org/10.1038/nature15759">https:/​/​doi.org/​10.1038/​nature15759</a></p>			 <p><a id="AspectRevolution">[22]</a> A. Aspect, To be or not to be local, Nature 446, 866-867 (2007). <br><a href="https://doi.org/10.1038/446866a">https:/​/​doi.org/​10.1038/​446866a</a></p>			 <p><a id="Brierley">[23]</a> S. Brierley, M. Navascues, T. Vértesi, Convex separation from convex optimization for large-scale problems, arXiv:1609.05011. <br><a href="https://arxiv.org/abs/1609.05011">arXiv:1609.05011</a></p>			 <p><a id="Fine">[24]</a> A. Fine, Hidden Variables, Joint Probability, and the Bell Inequalities Phys. Rev. Lett. 48, 291 (1982). <br><a href="https://doi.org/10.1103/PhysRevLett.48.291">https:/​/​doi.org/​10.1103/​PhysRevLett.48.291</a></p>			 <p><a id="Steering">[25]</a> D. J. Saunders,, S. J. Jones, H. M. Wiseman, and G. J. Pryde, Experimental EPR-Steering of Bell-local States, Nature Physics 6, 845 (2010). <br><a href="https://doi.org/10.1038/nphys1766">https:/​/​doi.org/​10.1038/​nphys1766</a></p>			 <p><a id="GisinElegant">[26]</a> N. Gisin, Bell inequalities: many questions, a few answers, The Western Ontario Series in Philosophy of Science, pp 125-140, Springer 2009.</p>			 <p><a id="NPA">[27]</a> M. Navascues, S. Pironio and A. Acín, Bounding the set of quantum correlations, Phys. Rev. Lett. 98, 010401 (2007). <br><a href="https://doi.org/10.1103/PhysRevLett.98.010401">https:/​/​doi.org/​10.1103/​PhysRevLett.98.010401</a></p>			 <p><a id="Tamas">[28]</a> T. Vértesi, More efficient Bell inequalities for Werner states, Phys. Rev. A 78, 032112 (2008). <br><a href="https://doi.org/10.1103/PhysRevA.78.032112">https:/​/​doi.org/​10.1103/​PhysRevA.78.032112</a></p></div></div>]]>
            </description>
            <link>https://quantum-journal.org/papers/q-2020-07-09-293/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826281</guid>
            <pubDate>Mon, 13 Jul 2020 22:26:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What are we weighting for? A mechanistic model for probability weighting]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826257">thread link</a>) | @vo2maxer
<br/>
July 13, 2020 | http://lml.org.uk/paper-announcement/what-are-we-weighting-for-a-mechanistic-model-for-probability-weighting/ | <a href="https://web.archive.org/web/*/http://lml.org.uk/paper-announcement/what-are-we-weighting-for-a-mechanistic-model-for-probability-weighting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>It’s a common belief in areas such as psychology, economics or finance that people suffer from cognitive biases — systematic deviations from correct or rational behaviour when they make decisions. <span id="more-3022"></span>This idea traces back to the work of Daniel Kahneman and Amos Tversky, beginning in the late 1970s, who noted that subjects in experiments often made apparently poor statistical judgments. When engaged in wagers with monetary prizes, individuals systematically seemed to overestimate the likelihood of rare outcomes, and to underestimate the probability of more common outcomes. People weigh probabilities incorrectly.</p>
<p>Yet this conclusion has been questioned by many researchers, who question whether the behaviour of participants in such experiments really is less rational than the experimenters’ expected outcomes. An experimenter may choose outcomes from some definite probability distribution, yet a subject doesn’t know this distribution and has to estimate it from a small sample of outcomes. Moreover, the subject may not fully understand or believe the experimenter’s explanation of how the experiment is being run. These and other influences create more uncertainty for the subject than for the experimenter, raising an important question: do people really tend to overestimate rare outcomes, or might their behaviour simply reflect the different perspectives of individuals with distinct knowledge?</p>
<p>In a <a href="https://www.researchers.one/article/2020-04-14" target="_blank" rel="noopener noreferrer">recent paper</a>, London Mathematical Laboratory researchers <a href="http://lml.org.uk/people/ole-peters-2/" target="_blank" rel="noopener">Ole Peters</a>, <a href="http://lml.org.uk/people/alex-adamou-2/" target="_blank" rel="noopener">Alexander Adamou</a>, <a href="http://lml.org.uk/people/mark-kirstein/" target="_blank" rel="noopener">Mark Kirstein</a> and <a href="http://lml.org.uk/people/yonatan-berman/" target="_blank" rel="noopener">Yonatan Berman</a> examine this question, and suggest that there’s little reason to take the claims of cognitive bias at face value. Rather, they find that the classic results usually presented as evidence of overestimates of rare outcomes should arise generically even from small differences in uncertainty between an experimenter and subjects. The authors also demonstrate that this apparent cognitive bias vanishes when considered from the perspective of <a href="https://ergodicityeconomics.com/lecture-notes/" target="_blank" rel="noopener noreferrer"><u>ergodicity economics</u></a>, a recent effort to place decision theory and other aspects of economic analysis on a more natural foundation than that provided by expected utility theory.</p>
<p>A simple curve expresses the core empirical regularity behind claims that individuals systematically overestimate the likelihood of rare events. Suppose w(x) is the empirical weighting subjects give to a set of possible experimental outcomes x, and p(x) is the actual probability distribution from which the experimenter draws outcomes. One way to compare w(x) and p(x) is to consider the cumulative probability distribution functions for these two quantities, F<sub>w</sub>(x) and F<sub>p</sub>(x), giving the total summed probability for a choice to be less than or equal to x. By eliminating x, one can plot F<sub>w</sub> as a function of F<sub>p</sub> to see how the subject’s empirical weightings compare to the experimenter’s assumed distribution. As presented in an early paper of Kahneman and Tversky, the curve shows the distinctive shape of an inverted S-curve (see figure below).</p>
<p><a href="http://lml.org.uk/wp-content/uploads/2020/06/Figure-1-What-are-we-weighting-for-A-mechanistic-model-for-probability-weighting-blog.png"><img src="http://lml.org.uk/wp-content/uploads/2020/06/Figure-1-What-are-we-weighting-for-A-mechanistic-model-for-probability-weighting-blog.png" alt="" width="279" height="207"></a><a href="http://lml.org.uk/wp-content/uploads/2020/06/Figure-2-What-are-we-weighting-for-A-mechanistic-model-for-probability-weighting-blog.png"><img src="http://lml.org.uk/wp-content/uploads/2020/06/Figure-2-What-are-we-weighting-for-A-mechanistic-model-for-probability-weighting-blog.png" alt="" width="482" height="176" srcset="http://lml.org.uk/wp-content/uploads/2020/06/Figure-2-What-are-we-weighting-for-A-mechanistic-model-for-probability-weighting-blog.png 482w, http://lml.org.uk/wp-content/uploads/2020/06/Figure-2-What-are-we-weighting-for-A-mechanistic-model-for-probability-weighting-blog-300x110.png 300w" sizes="(max-width: 482px) 100vw, 482px"></a></p>
<p>In one region, F<sub>w</sub> &gt; F<sub>p</sub>, the subjects overestimate probabilities, and in another, region, F<sub>w</sub> &lt; F<sub>p</sub>, the subjects underestimate probabilities. For Kahneman and Tversky, and many other researchers since, a curve with this qualitative shape gives a signature of a behavioural tendency to overweight probabilities for rare events, and to underestimate them for more common events.</p>
<p>Yet Peters and colleagues examine whether similar curves might arise quite generically, and for reasons having nothing to do with irrational misperceptions of probabilities. For example, they consider what happens if the experimenter chooses p(x) to be a standard Gaussian distribution, centred at some most likely value, and with some variance. Suppose the participant, for whatever reason, perceives some extra uncertainty in outcomes, and weighs them also as a Gaussian, centred on the same value, but with slightly higher variance. As shown below, this is enough to lead to a curve of the very same generic inverted S-shape. The curves on the left depict the two cumulative distribution functions (red and blue for the narrower and wider distributions). The figure on the right shows the resulting inverted s-curve for the subject’s cumulative function F<sub>w </sub>plotted as a function of the experimenter’s, F<sub>p</sub>. Clearly, it takes only a little extra uncertainty in the subject’s distribution to generate a curve of this qualitative shape.</p>
<p>The authors also argue that some extra uncertainty on the part of an experimental subject is by no means unlikely, and can arise in many ways. The experimenter has full control over the experiment, chooses the decision problem and sets the probabilities. The subject, in contrast, knows less, has little or no control, may wonder about his or her full understanding of how things work, and may even doubt the experimenter’s true intentions. As a result, a subject may intuitively assume some extra uncertainty beyond that described by an experimenter.</p>
<p>Another influence is possibly even more important. As the authors point out, a key difference between the experimenter and subject is that the latter has no access to the “true” probability distribution p(x) from which the experimenter chooses outcomes. Instead, the subject has to guess about this distribution by relying on a finite set of outcomes generated in the experiment. Rare outcomes, of course, occur infrequently in a small sample of outcomes. Hence, if the subject wants to estimate p(x), he or she might sensibly try to correct for the limited data by supposing rare events to be more likely than the outcomes observed so far would imply. Yet an experimenter might misinterpret this as an irrational overweighting of rare outcomes.</p>
<p>Indeed, Peters and colleagues consider how a sophisticated subject ought to estimate the errors in his or her probability estimates due to limited data. An estimate of p(x) comes from counting the number of instances n(x) of outcomes occurring on some small range around x. If this width is ∆x, then from T samples, an estimate of p(x) is Q = n(x)/(∆xT). But one also expects fluctuations. If the average is n(x), then the fluctuations – assuming Poissonian distribution of selections – should be proportional to n(x)<sup>1/2</sup>. If the best estimate of p(x) is Q, then the authors find that the uncertainty in this estimate to be roughly (Q/∆xT)<sup>1/2</sup>. This gets small as p(x) gets small, yet the error relative to p(x), (Q∆xT)<sup>-1/2</sup>, gets very large. This implies that the biggest mistakes in estimating the correct value of p(x) come from those parts of the distribution associated with the most rare outcomes.</p>
<p>Hence, a sophisticated subject, on this analysis, should expect the most costly errors to come from low probability events. Increasing his or her estimate of the probability of these events might then be a wise and cautious thing to do, understanding the problems of estimating probabilities from finite data. All this suggests that the naïve interpretation of Kahneman and Tversky’s findings as reflecting cognitive bias may indeed be just that – naïve. The apparent bias may only reflect a natural and sensible response to the information-scarce situation subjects find themselves in relative to an experimenter.</p>
<p>Peters and colleagues finish by tracing much of the confusion over this supposed cognitive bias to the broad influence of expected utility theory – the traditional starting point for many economic analyses of optimal decision making under uncertainty. This approach assumes that the optimal behaviour of an experimental subject can be calculated by an average over a statistical ensemble of outcomes. This statistical simplification is of course appealing, yet makes no sense unless it gives the identical result to the average over outcomes in time. Unfortunately, we know this is often not the case, especially in situations where subjects make choices affecting their wealth, models of which usually rest on non-ergodic multiplicative random processes. This is precisely the situation relevant to all experiments revealing the supposed overestimation of the probabilities of rare events.</p>
<p>This cognitive bias does not appear to be a bias at all when considered from an appropriate analytical perspective.</p>
<p>The paper is available at <a href="https://www.researchers.one/article/2020-04-14" target="_blank" rel="noopener noreferrer">https://www.researchers.one/article/2020-04-14</a></p>
</div></div>]]>
            </description>
            <link>http://lml.org.uk/paper-announcement/what-are-we-weighting-for-a-mechanistic-model-for-probability-weighting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826257</guid>
            <pubDate>Mon, 13 Jul 2020 22:24:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Medical Nemesis by Ivan Illitch [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23826220">thread link</a>) | @mimixco
<br/>
July 13, 2020 | https://ratical.org/ratville/AoS/MedicalNemesis.pdf | <a href="https://web.archive.org/web/*/https://ratical.org/ratville/AoS/MedicalNemesis.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div endstream="" endobj="" obj="" type="" page="" parent="" r="" resources="" contents="" mediabox="">&gt;
endobj
6 0 obj
&lt;&lt; /ProcSet [ /PDF /Text /ImageB /ImageC /ImageI ] /ColorSpace &lt;&lt; /Cs1 7 0 R
&gt;&gt; /Font &lt;&lt; /F1.0 8 0 R &gt;&gt; /XObject &lt;&lt; /Im1 9 0 R &gt;&gt; &gt;&gt;
endobj
9 0 obj
&lt;&lt; /Length 10 0 R /Type /XObject /Subtype /Image /Width 52 /Height 36 /ColorSpace
11 0 R /Interpolate true /Intent /Perceptual /BitsPerComponent 8 /Filter /DCTDecode
&gt;&gt;
stream
ÿØÿàJFIFHHÿízPhotoshop 3.08BIMíHH8BIM
x8BIMó8BIM
8BIM'
8BIMô5-8BIM÷ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿè8BIM@@8BIM8BIMt4$œðXÿØÿàJFIFHHÿþ&amp;File written by Adobe Photoshop¨ 5.0ÿîAdobed€ÿÛ„			



ÿÀ$4"ÿÝÿÄ?	
	
3!1AQa"q�2‘¡±B#$RÁb34r‚ÑC%’Sðáñcs5¢²ƒ&amp;D“TdEÂ£t6ÒUâeò³„ÃÓuãóF'”¤…´•ÄÔäô¥µÅÕåõVfv†–¦¶ÆÖæö7GWgw‡—§·Ç×ç÷5!1AQaq"2�‘¡±B#ÁRÑð3$bár‚’CScs4ñ%¢²ƒ&amp;5ÂÒD“T£dEU6teâò³„ÃÓuãóF”¤…´•ÄÔäô¥µÅÕåõVfv†–¦¶ÆÖæö'7GWgw‡—§·ÇÿÚ?õT’Uz–S10®¹ö¶˜i±ÜìIIm„Å5ïþSŽÖþG;þ‚VÆÉ±€0k¹®ÝømjÅ£+2ömÃÏa¢¿gÚ_é�B�Ùy˜ƒÔ~srqû¹‚¡gÝôS¸’Îè™”dã=”Þ/&lt;°;¾ÑôŠJRI$’ŸÿÐõUS©ÖË16½»Ç©VŸõÆ+k;?§Û™`6»)gÑcÜñ¯‹¶$§‡Å²�QïúxŸÿ†Tð_cß‹ê=ÿ¤³Õ÷ÿÂä®§ö¿î6þ	ýê°Yÿq±ðOïIL&gt;§€zKl:Øó6;Ä­Õ“�ÒnÆ½—c¶ªu‹C]aÜÏí~rÖIJI$’SÿÑõT—Ê©$§ê¤—Ê©$§ê¤—Ê©$§ê¤—Ê©$§ÿÙ8BIMÿâ&nbsp;ICC_PROFILE�ADBEmntrGRAYXYZ Ó3acspMSFTnoneöÖÓ-ADBEcprtÀ$descäqwtptXbkptlkTRC€text(c) 2003 Adobe Systems Inc.descGrayscale - Gamma 2.2XYZ óQÌXYZ curv3ÿþ&amp;File written by Adobe Photoshop¨ 5.0ÿîAdobed€ÿÛC			
ÿÀ$4ÿÝÿÄ¢	
3!1AQa"q�2‘¡±B#$RÁb34r‚ÑC%’Sðáñcs5¢²ƒ&amp;D“TdEÂ£t6ÒUâeò³„ÃÓuãóF'”¤…´•ÄÔäô¥µÅÕåõVfv†–¦¶ÆÖæö7GWgw‡—§·Ç×ç÷ÿÚ?õT�_m„Å5ïþSŽÖþG;þ‚VÆÉ±€0k¹®Ýømj*I/ÿÐõUW©e3
ëŸki†�ËÀqÅ•FVeìÛ‡žÃE~Ï´¿Ó:…;²ó1¨üæäã÷sBÏ»è+}2Œœg²›Åâ‡–wÚ&gt;‚ÑIÿÑõUS©ÖË16½»Ç©VŸõÆ.þÊ=G¿éà~þSÁ}�~/¨÷þ’ÌWßÿ’ºŸ©à’Û¶&lt;ÍŽñ+u%ÿÒõU�ŸÓíÌ°]”³è±îx×ÅÛ?Ø.ÿ¸Øø'÷©þÁgýÆÅÿÁ?½¤Ý�{.ÇmTë†ºÃ¹ŸÚüå¬’ÿÓõT’I$’_ÿÙ
endstream
endobj
10 0 obj
2161
endobj
12 0 obj
&lt;&lt; /Length 13 0 R /N 1 /Alternate /DeviceGray /Filter /FlateDecode &gt;&gt;
stream
xc``œàèâäÊ$ÀÀ�›WRää¥ÀÀÁ~™����AŽÁ81¹¸À7Ø-„òòóRA4*øv��$rYdªAkrAQ	PÕ VII-NÒO€¸°¼¤(Îd‹$eƒÙ9 vvH�3P¼Èæ+I­éeÐHÖT0200VpLÉOJU®,.IÍ-VðÌKÖc€š	R&amp;æ^”XYœœ˜“ª&nbsp;«àž˜››¨`¤g’¡2‡!ØÌÏ�à°a;ƒCX–\ZTå1230\U4
endstream
endobj
13 0 obj
213
endobj
11 0 obj
[ /ICCBased 12 0 R ]
endobj
14 0 obj
&lt;&lt; /Length 15 0 R /N 1 /Alternate /DeviceGray /Filter /FlateDecode &gt;&gt;
stream
x…ROHQþÍ6„ˆA…xˆw
	•)¬¬&nbsp;ÚvuY•m[•Ò¢gßº£³3Ó›Ù5Å“]¢<u¢ctìÐ¡›—¢À¬k× ©="" <uèûÍìê(„oy;ßûýý~ß{dm�¦ï;)atsc•+¥§nnm‹ƒ)eÔnx¦øébqŒ±ë¹’¿»×ÖgÒØ²ÞÇµvûö="µ•e`!ê-¶·ú!‘f�™Ÿ(e€³À–¯Ø"><x¬ð#¢š¹0ÓÑœt¥²-‘sæ¢(*¯b;i®ûù¹Æ¾‹µ‰ƒþ\�fÖŽ½³êªÑlÔ´÷d¡¼®dÏ_töl5§ ãœhc)ò®Õß+lÇ‘+jr5d¹Ÿjn�uàu»]º“ãøö¥="">É`¨‰µé²™…}v*Ëìðèñ²bç�{aÿ[QÃ“À'a?d‡yÖ­ö®Sà{„=5àÎ®ÅñÚŠ^-C÷T#hŒsMÄÓ×9s¤ˆï1Ô˜÷F9¦1w–ª7€;aYªf
±]û®ê%î{wÓã;Ñ›9\&nbsp;Ir±ÙÐ&lt;	X}‹°I&lt;&gt;ÎUàw¨˜À¹‰ÜÍ(÷Õg£R�Vz�WÆOã¹ñÅøelÏ€~¬v×{|ÿéãu×¶&gt;&lt;ù�zÜ9®½�UaVqeÝÿÇ2„�Ù'9¦ÁÓ¡YXkØväšÌL°(Ä&gt;—ú’UÜÕîí¸EÌP&gt;,l%ºKTn)Ôê=ƒJ¬+Øvp’Ä,Z¸Skº9xwØ"zmùMW²ë†þúözûÚòmÊ¨)(Í³Df”±[£äÝxÛýf‘Ÿ8:¾ç½ŠZÉþIE?…9Z*òUôVPÖÄog~¶~\?¥çõAý&lt;	=­ŸÑ¯è£¾tIÏÂsQ£Ið°i!â&nbsp;Šƒ3ÔNTc�â)ñò´[d‘ý@ýf
endstream
endobj
15 0 obj
704
endobj
7 0 obj
[ /ICCBased 14 0 R ]
endobj
17 0 obj
&lt;&lt; /Length 18 0 R /Filter /FlateDecode &gt;&gt;
stream
x�UËrÚ0Ýç+îª“Ì€‚åww@Ò–’æA'‹�…0«‘-ŸÔÏéõÚ!!1n›Ø²¸÷œsÏ‘à&nbsp;ƒß0
!	(7&nbsp;à¸o=È,x`³êóYÍÂn{ÀÝE©vñSÔÊÐ�çoW}#¥4¥¸ÂhÇŸ&lt;ÒÁ�fpØ×Ë�óÜý/�#˜làŠ©©^À½²¼•‘£ƒÑw8•¨ë›EÛfÐ4 ßKêšÁŒ¾ü³Pê(®¢îJ	%j‹ÊYnÖ|
+5åá:nsB+&amp;™ÀSíî‚‘1ÏtñJ­¹*öYÿ'X‡+¡U\«‰6G4B�Ë9|SÂáÝµcŽÛB\DƒëZAOë{ÛS±a€žU¤o†*ÝS«aÎù�'æžÀWÔN&nbsp;&gt;rË—ˆ?ÎôŒpñ#Ú&gt;“…¨í†„;tS,Õõöäjtš"»©”&amp;‹Îƒ5Nk ¥Èò7Ø¯f:4ð«ÓŠ‰afS�ÓŸ£s,2tLjTc^Œ¬œ_VºNðI3¢qPíüHÃ„¬Z45«Œ®ä¶Ÿ3&gt;EƒKP|Á­°oÐlÙçóÁ÷ðPx}&gt;&lt;–Ú8%I�z1ÔTC'ÊÕ´H‚À&nbsp;è¹aË¼„møŒ®2|TdV`–ò¦Áôé^ždò\ëL&nbsp;P‹B0¡8J&nbsp;To~_äBj«—ùæ=”wâñ[ÐßVÇ–3Ø.  ™3zÎ•È0ý–3[P	'qÇíÉùðì# Öf Â=ú'\Š5´~Î™tùr?u8ŒöÖAñ&gt;À7ª&amp;„~¼§Òß‰ü¢kˆëZ
‡XD5cj¦E²§ÅMüŽGÓEùÂcw�ê�=b·WÝÀKÈ ¼4¡wOŽð#J¼Ýmy•Ðv§!mÖÃUqÙàºw�¶ŸíØ£AØa|¸œÜ“ñÑ«ÎÝnÿªaÓ ©6=cj5c™[™¿½ðð¤Ý¾zwD/ÿ4Õ;0
endstream
endobj
18 0 obj
753
endobj
16 0 obj
&lt;&lt; /Type /Page /Parent 3 0 R /Resources 19 0 R /Contents 17 0 R /MediaBox
[0 0 595 842] &gt;&gt;
endobj
19 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs1 7 0 R &gt;&gt; /Font &lt;&lt; /F1.0 8 0 R
&gt;&gt; &gt;&gt;
endobj
21 0 obj
&lt;&lt; /Length 22 0 R /Filter /FlateDecode &gt;&gt;
stream
x¥VËn›@Ýû+î®Í"†UÕØ‰d©–Üš¶ëœIa&amp;apªö/ûG½˜Ç¸ÙÅ¤ßsçœË3|†gpñGc
, P
ø
næÆƒÔ€&amp;&gt;ÏFføÚ3¾]‡º®ou¬´€ÛHÐœâ�†N“˜€ÇH
¸¹'Ž‹ÿJ2x?×ªª2W³äîLsê0¦ã²�DÅÈNìRÆ0Ø4¢ç7ˆxïIèÎˆKU•z»O+©Õ¡*wO°€YŸD
€×—´þø%�¥ó\*™òrŽˆ;¡„‘æÄ®N,/t×‰†za‹¡‡¤i¨E÷HÜ=É­($öQg°Ò[Q*X‰­L¥¶×®±Ø
	…ŸMßç›©¾oæc“žõ�öCß	¼0†|ýY›f²Ó=ž5´­’!WjÚØ*¡¾l/‡ì‚YFDÔ‰YÅàwÁ,:­tiÞÁ]–	äÅK=*ó‡+XæùÞÔ&lt;éÙ9DjÙ&gt;Æ=?Ž†l?¤
ðÕˆš� A’Rðª@\„x-	lE-NSØõRe¹L+±…¥zÜ—R©íŒz2UÏBdBµ5­y%kAÃ9µxqìøñ&nbsp;Ç°£öÉÛ‘F„ÄlHšF˜¨Ì�NåP—ý„�üÇêò”+Œè’úþÐH£Ëƒy.c›´ªÅùIfbšÉÈ/«1ê�Æe�Æú³ÿÓ¥¯œ¤%Ñtn¯UÆ|'rEËïÂYN®u.«ƒ&amp;%W¦�¦VVÝ�eã�E
i7G5EÏ±žGã.Ñ–�vÑ�x*ªµÏCk$¸ÌhÕr’=o‡î“²)=õ)Co+­ô“Î�UEºSÓµPç¶÷…&gt;°mÏ7žïÅõ})Ì÷¥øpaÆ^Ûk]ªç$Ê&lt;'ŠÃD»x6ÑzM¾–c…§·ûíN\fÆ¡?eÆ‡µ¼~àeÁS±o”°T/üâý“üYH¾SÚ ,‹'Q¢ÛISœÓ8K�îÃ6®Äº¸*ë}	›Jî
~@4YF"ÊB*tê¹(E¡Õ¥›¿&gt;'61Üæ&lt;ý+¾“éEÙGîdöëfbðG]¢õ¯ÝÏh¯¥
endstream
endobj
22 0 obj
823
endobj
20 0 obj
&lt;&lt; /Type /Page /Parent 3 0 R /Resources 23 0 R /Contents 21 0 R /MediaBox
[0 0 595 842] /Annots 26 0 R &gt;&gt;
endobj
23 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs4 25 0 R /Cs1 7 0 R &gt;&gt; /Font
&lt;&lt; /F1.0 8 0 R /F2.0 24 0 R &gt;&gt; &gt;&gt;
endobj
26 0 obj
[ 27 0 R 28 0 R 29 0 R 30 0 R ]
endobj
31 0 obj
&lt;&lt; /Length 32 0 R /N 3 /Alternate /DeviceRGB /Filter /FlateDecode &gt;&gt;
stream
x…”MHaÇÿ³�±Ñ—ÅÐÁ$T&amp;RÓõ+S¶eÕL	b�}w�g§™Ý-E"„è˜uŒ.VD‡ˆNá¡C§:D™u‰&nbsp;£E^"¶ÿ;“»cT¾03¿yžÿû|½ÃU�RŽcE4`ÊÎ»ÉÞ˜vztLÛüU¨F\)Ãs:‰Ÿ©•Ïõkõ-iYj”±Öû6|«v™P4*wd&gt;,y&lt;àã’/ä�&lt;5g$©4Ù!7¸CÉNò-òÖlˆÇCœžTµS“3—q";È-E#+c&gt; ëvÚ´Éï¥=íSÔ°ßÈ79Ú¸òý@Û`Ó‹ŠmÌÜv×Ulõ5ÀÎ`ñPÅö=éÏGÙõÊËjöÃ)ÑkúP*}¯6ß~^/•~Ü.•~ÞaÖñÔ2
nÑ×²0å%Ôìfüäý‹ƒž|U°À9Žlú¯7?ûÛ‰j`¨‘Ël7¸òâ"çtæœi×ÌNäµf]?¢uðh…ÖgM
ZÊ²4ßåi®ð„[é&amp;LYÎÙ_Ûx�
{x�Oö¹$¼îß¬Ì¥S]œ%šØÖ§´èê&amp;7�ïgÌž&gt;r=¯÷·g8`å€™ï
8rÊ¶â&lt;©‰ÔØãñ“dÆWT'“ó�&lt;çeLß~.u"A®¥=9™ë—š]ÜÛ&gt;31Ä3’¬X3�ñßüÆ-$eÞ}ÔÜu,ÿ›gm‘g…6ï64$Ñ‹áÀEzL*LZ¥_ÐjÂÃä_•å]½XážÏy¸[Æ?…Xs
åšþNÿ¢/ëú]ýó|m¡¾â™sÏšÆ«k_Wf–ÕÈ¸A�2¾¬)ˆo°Úz-di�âôä•õ�áê2ö|mÙ£Éâj|5Ô¥ejÄ8ãÉ®e÷E²Å7áç[Ëö¯éQû|öIM%×²ºxf)ú|6\
kÿ³«`Ò²«ðä��.<k¡îuª}j‹Ú m="¦¶«mjßŽªåÃœ•‰¬Ûeõ)ö`cšÞÊIWf‹àßÂ/†ÿ¥^a×44ùM¸¹Œi" ßÜ6p‡”ÿÃ_³="" Þ="" endstream="" endobj="" 32="" 0="" obj="" 792="" 25="" [="" iccbased="" 31="" r="" ]="" 34="" <<="" length="" 35="" filter="" flatedecode="">&gt;
stream
x¥WËrÛ8¼ó+æ¸9,C‚àëèÐN­*q"[Jr†IHÆ1J9¹´dš”¬]çà2ìL÷ôLÏŒžàžÀÁ~ìCD	Ô~@	ï“Æ…´štúûÝÌƒ…ö„-Cý)¿ÉXi¶àFê5?°ƒ˜ÄB
ÛÞtmÿÓv¬¯î·°Z­lHº¼íj–CÎÚºÚó’7¢ygmÿ†›-ÒEfT2“HŽ8ý—d¹ï)xÏÀ»N`õøDã¯JËº´UùF0	{¡ïÀ¯8ÙL€7‰5¬3E(;¦4€\Ï±#åÐo9lú¼ÔÍRºŠxpDœ:Sá&lt;¶�&gt;‰&lt;åª¬™S°îP£0Š�€ø˜‚TÌ‰R!íØñ£ˆPØ$³â™¨kS7ˆ­ˆãÛ„†¸ê
æsk?—CècÖqñé�Ãª&lt;ðRX™ÁM.
Q²þgÌêZ4œ5ÜÔf*»”ÍPƒž2Êî‘í‚”Ç·‹)êýbúÕ·áš³ö®ö(wÓ?-³“‚Œì,BÉÈŽ¸qï	Ðo»Ñ€Î©ÖžQ—Î”*ô_§©IŸ£„±ÑØ
AG3F²f
$UQT™hŸ/‰<j�$|eÁ�'ôí|Í•¬<Ž�kv¦\öu‹mŽèÙ2Þè“‰Á‹ÕÈ1™¼ÀceÃá–¥ì¡î{Ìê‡Í´Çn´µ‡úmfš^�®¥h†®^g3t?t]½ç•ht«]v«à‘x iÂŽ*$8="">D*õ–mmæíyÒ&amp;:]Ö¸f‡o¥4w’3Q4ÐVÀàfýÿõSZõ[™ñp¾ó²	Ã
Ÿofiy¸"'¶Ö÷a|­«\´Wöê_œåÇ*^¼µf¬M½WÖlØüä©Ø‰ýØaŽõOµÆçœiéºQo˜ï8,Ñ–¶GüôÛÆÑh»9Î�ÒÌ4\hÏÊrê–0!Q·!ÌpV•ÀfV¢¸:ºš�sm}RoâGÃ|¦�z3‚Xýrâô˜c½:}”Ï÷¤™ql‡NäS&nbsp;c8£oR•MW`Ë¯ëªåýA»ª†«,i{F‚É5öuw˜qnÀÍS‡B_¥)ozSo«ú¿¢¸¯šE£¬»‡¼ory§åè±f(7f¹CäaWÜ²�`—©Kî{ËÊûj“
y›H£}­÷¬¿ûËä,\¦¶ëàõ£±LÇþ#=qzç˜ê“ÐŽ0È”gÏg±{Ã€3áŒtYÿ›r/JÎkycÊnb°ÎYƒã~TÅƒ‘aÖÑÞ0~Oo˜h±÷&lt;•…&gt;±úVŸsô8â,?rôÅå©‹K¿G,Þäè14~rŠ¦lGGŸäöÒj‘§­Ã™š®Ê¬kÚZ°\üæ|áEÿ‘è‚èšlàÒ�¬‰®-ö±®
Ü“�XäanŸñºÅ%}Ï\1í®Ë¥×Ržá U?^Ì©þ23ƒ½||ô7ß½Ø?¶qº<!--ÁX-->ATXÀÓ•ÁwQ·Ý‘Kîþ›âuX
endstream
endobj
35 0 obj
1138
endobj
33 0 obj
&lt;&lt; /Type /Page /Parent 3 0 R /Resources 36 0 R /Contents 34 0 R /MediaBox
[0 0 595 842] /Annots 37 0 R &gt;&gt;
endobj
36 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs4 25 0 R /Cs1 7 0 R &gt;&gt; /Font
&lt;&lt; /F1.0 8 0 R /F2.0 24 0 R &gt;&gt; &gt;&gt;
endobj
37 0 obj
[ 38 0 R 39 0 R 40 0 R 41 0 R 42 0 R 43 0 R 44 0 R 45 0 R 46 0 R 47 0 R 48 0 R
49 0 R 50 0 R 51 0 R ]
endobj
53 0 obj
&lt;&lt; /Length 54 0 R /Filter /FlateDecode &gt;&gt;
stream
x¥X]�ÛÈ|×¯è·Ø€–'~Iü8±8À1°Á=y‘Cqbr†æ�«ègæ¥zHJZRÝòlÃ»+­†=ÕÕÕÕý“¾ÓOÚào¼�)‰j$ýFš~ù«õ)µä“M§ïçw^Xá×~â·ù¨'þÂg¥ýå™‚}ÿ*¾Æ[o»öÞ¥çŠ~ù›ïmð¡çœ&gt;øéù?ôõ™¾¯Þ:g8=ð¯çøA&lt;=è¹�ôµV™¬Tj?®†CßîÞ¡ÛÙ¡&amp;§_M&amp;M¿ÊL¥JË‡'ûáFxî&gt;™†K|ïßû­ïÌ	€Dô¥k”&gt;Rja[|ÓHIG©e#Ze´uoeÊJa¥%‘ç¥J[þÈoÒ¶|;kR%[…7ñ"iÑ%ƒh–ÜN»£Ñ’²FTˆ%¥´ú(­÷ð&nbsp;ÿÙõh^~
‚­·Ùú&gt;ÑÆÛG!?suŸP¿Ø H¼}ïpÚ5øUÏLú‡)•YS¦êÐ6J¬IèŒÚî ›´+�UÀuó"´²àüä’êÈ&lt;{öª/Š»I�gIeÈlaZ…Æ¿V”aüLÞJMi× Wµ–]e´d²çºP¥²Ÿ\�ÖP%ôÿY»0�»+"C­þPe)›�#©©$¹SjtÛ˜, ßÉ&lt;µ…j2ë‚/KÊ¤h‹*mN„ˆÀ6ÑÊla`É®Ñ‡“j‹×,r¦ÌH¥GÏ…±’N…A2%�Mêsæ*ƒÿzD»&amp;
Ä_¸4*þã
4û€œþ›žÿ~?«ƒÔÝËj¸¹ÅoÅZ'Òú¤[»ÆSL)u*×.u¤%“ÞE
gìžs©'·—Ÿ‚pãùqR¸ékb5ÑˆàáÉwo²¾*.ˆ
tXeLJS!E	ðm+Ú®Ïr¯<ey&ù³s‰vé`bÚ°ñÇl—ç(*dâ¡Ü .Þl”,àòmÛ¨cÇôjq.Ã="" {�-´Ž*rqr="" xô¡›îx�(+é”="" ²9sõd©ð:ÉÏrÜô”aw\• pj="" �Ç³@Õz’7jj”ÍÉt="" .sñ="" —‚="" óÅnµ$ÿ›Êº¥Ïro¹$]�-d1™¢ø!3ikš5�â@xÈu.Òæoê"fuÉt#ñn#Ë¾Ïªf˜o="" °tu`:ÐÂèàm&ltv¥?´„¬91fÌz"áucŽf§<.ÏhØ‹;mÅžŸì¶îý»�&|ou…qâ%[(}xs©±Ó ¦.z¾çÜ‹µŠ‚í´ìq­™¬Á)hº:Ø¡dÛ�†5zº="" ÊÀ�(Ób›ÒÝ+m#´Á¸_Ã;¬¡›*-˜m«°¨z£="õµñcýmd^‚@ÈN?q÷èÙgñµocâü‰™xvrÍ%aÕQ«�êúâ˜×W:—Ã²Øâí,6´€�°\µ6Ð1P�#Çd-z_µD¯÷)ô£—<UWŒ¸»C·<´Ý" ¶amÁôdïÍ�øÁa¹òÈ÷^zÆ¤ƒ±·ßƒëÑvw—ëÑ{8="" —êí¶áž¢›øg®ƒ�É2€k4ãe«Áaî¸sm' ¨mœ="" f="" qn§¢$Æc£äúÐà2dhyzfÍ¢dÆ�c× ž¸ˆcÍßr°%Ëy®àÏðöy="" %vÏÖÊ²ÿ(sw:k7ö="" ¥Ñ‘^À•Åof="" írñ‚Áu.m]öÎ‡ë="" vêxpcqö�¥Ô£o *wëþs%²Þ”¼§–¢8ñ‚ÃÝ%œ+öpzpe©uúç÷yÑµ8="" ¦å="" ]û="" ˜”¼®9»»v�íÔ+|ÿÙš¶ýásß¨ŠÐß{›}²£˜Ç„;³Æö="U�—ìü˜noÔW¬‹“;g¤®»‹ß°Šàµ�!¢üHOÑæ�™WÆÊh7…ò¤lfªõÛ÷Ž{!ƒ" ˜(ŽÂ¡wãýîædÜõÎšàÆÜù›Ä‹fhèÅ·ytŒjÇiµwi(8u±v +°ìbi²Óz?ßxÕrå»d¼�ÑÊ…æ%tŠ|qïr£³i]â2xk´\(‚¨0n8vrv%‡Énk…’|(×ßc’Þ�uÍèn–q¥û!gƒe,lˆ¡¸*Öšà�Ý[¦ò#¦sçx1-kŽñ“c³yÖ="“–�¤&amp;²eïßjSwƒydØ}ß¶xÝxÜ`ÚÏæ€Ñ©cWÂvxQdÛÍ" 4ˆ_Ç="[f}/w‡£Ñ³™”Ùc" ÎöÔwq*n×µÅzaÀ§±öoô³{="" ¬h¬ýßgmßÊ²ãn¾ìbÉ|½ä5ø“.sâÈ<�="" ¦ìÆö:6¯ó6@x&4†Ý½½š|gêìº[zÛnnqp�rîÑð¹âÁfª·ƒr\äñÔáf86<(¤="" qi4_¶ûphàÅ²ÀühÃ]Ñº1ûaÀru×¥"ff¬<úql·k–Œ?n¾="œé`0»º2]ZÀ“âµe�…3Ä´ÄzC6®®V¸2œ0žä=<èb¾V¬Hx:ç¼Q­«µZ6lé{§½,,X«" �gÓk™óÊº0¯[ÒÎ¶¦b­ƒ6Â¨«#.Özp£?°�Œ°ãÀ^Ð§]�-çÕŽ"¹i9÷7Ó7jm"oav7×­êeq="" .ËÑã½çè‹À="" o'³¼ƒkéÿ~{ÂÛˆÁ›uvæ="" oòˆ^vÙl�k³ÏxÀn¾f]¼q§ïÿ@x="" endstream="" endobj="" 54="" 0="" obj="" 2027="" 52="" <<="" type="" page="" parent="" 3="" r="" resources="" 55="" contents="" 53="" mediabox="" [0="" 595="" 842]="">&gt;
endobj
55 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs1 7 0 R &gt;&gt; /Font &lt;&lt; /F1.0 8 0 R
/F2.0 24 0 R &gt;&gt; &gt;&gt;
endobj
57 0 obj
&lt;&lt; /Length 58 0 R /Filter /FlateDecode &gt;&gt;
stream
x¥ZÛŽãÆ}Ÿ¯(ø%^`†æýâ<y0‚$02À"€_zdkl Éæ6É‘•¯Ï©&uõ(³¢g�i$µŠu9uê¿Ð¯ô…|ükŠ„ò8$#éuôÝ�c@å@="" åõëÛ7þð€·}Á»ù¨'þÅg•-}|¦="" zþq’zi!¥="·ôÝÏ�çãCÏ[ú–ˆžkIªÛÊrTºh¬ÅH½‘/B5²&quot;<ñ=�ƒIoí3ÕUÓ0%;|ºiø©%ÕzOž§Ÿží5~µiy|mZ++UªNR)ZI›©q€Ÿúil©÷î×àªù'›ýpzÆ‘—ÅIF¹ïq¥øâ‡KŸèë/" Œ3="" `ýÅ<,¾}ž6Ò”s£5<ÒvøyewÊg\ˆ(kö="" õr|&ý"="" ÝþÞ‡Û1-œ˜Ž{m;Ùi„#êÑ="" ýsîé?Ú|†äaøhãxi1Öd·Éat-¢xÑ¨iƒ`ª]Íf­‰g8efu”ù="">®ØPà?ú¾ÿWŽk�ç°g_ËŽþ®Ëš¶Ê#©A7ÖÑU'Ž“aÃ�‹QÚŒ{DF¬4.tœVÄ¢ATªU²l�xÖ
Qvi¯g«åä°Jï;öU�û³ýlÞlþ:§ÅŽÓÑ‰Q5µÄ!Ò=[Ù(p!Éxm¬õ´«é›ÑžÚž£þ
!–MCµl*$^©¨oD)W:,q†Dâ«mµE£Æ�bÓÈáñÝ?¢­Ó³ ÇÃÀ�)H®KöÄ«²üÛõáb^PD^’¦9ŽcÓ_�D?lG¤à'màœOÂÐ/¿&lt;Òf‘ó(RI¢ÕFéQ‰7ÒÂ�"%Wº/sâŠÔå”Õ÷6&nbsp;H#Ùp8Q‘s¤ö
Å\žÞ8÷èÇZ7¨ëÕNŽŠÌ£�‚ÌbŸëãàÇ~èià8ç$ª®EšÃã»GžràuFÄiâ%q˜�¬}¸j^AøîÑ]0ÎB/ˆ¾øøú$„¼ú?ðë¦×©¥yq}Øxèk­[ÕªF˜æ`!Aæ/©öhžÜX¹£ªJÚ"êëÃ€^'º¿„R�n&lt;úˆ’B�’WmˆbºòT†$¢Ñ»ƒE”©«$ðVëÙ¾ùøßˆþ`S&nbsp;aÂÐËRmUi;Ç ©RƒƒÖUD8€Âå€V9R;¡	ÌLÆ¾(35=ÓºM�f#
—5¤Úž1ŸÑÖn,z¿‹DÉqŠgh�çGºè’[£[P3dh‹j5�pD_³¿”à&amp;¦u¯º¢D~´&amp;·p€‘D«ñÂ:£bÇ[e­šÊü§ž;ÐVÒðl[8\'mî¶•¨Å#{5ûØä¸•œ1|�u©“g9îÙ€ºo�ib³I—åd¸“/XÏÁd|5YÊF^â¯-Ì5$ÌŸíQo¨-MµíÔ©ÿþI&amp;ø^æ	…Ù�–ÝPa ÌÀ›fÓ_·,p¸^&amp;ãŠYp)‡mžZq`¦&amp;F°qt0øÉ€Š0 ”'D{àiã«™xX8á¿8«98_pòÀ�@�…œ‹ákUiô“6;Ñ©¡óµ­õ@[tZwËE¾*Ó"ß‰é±úQŽ¢Q²˜&amp;ŽÔµÆW=	þm‚ª	àÁÜvdÐMðš�%˜"÷Ÿ^gVèxõ�¤V(ûQWâÀ(!Œ©¥°&gt;œÐó
ÛÕ+pImO˜žJpÞófë„+s%øG‘ãª­‘_&amp;à@s�4$F0kÃU×,œÿ	àå°áä*ðrë©GêôJo%Ž·0tp<xxœÁ~ z96È�x€]$€”gs&›«gÀ(k½="" ÉrŠ’<(¾§p£<ô²<oq_šs¸?u»="">F!Ì-½U(À:¾¥ß˜[%uhzÜ@í'0¯SBMîz&nbsp;JsXš:ÐÃ4�Àâ€ä÷Õé1ú.²B+šsÆ‡®BßÄl@·vŒ1F•Ÿ%ÆyÎ¼^6�Øa»÷)“A=b.†mü–uUéNÆ/ŒH˜ºÁaì€{éF¦§�KçîiÛ,šºµöã2ö,�ðhŠÊ�ãVÙå¯¨fcÕ�Qµšt%;dýÔ”àg´`ÊÕÐyô‰‡eXÌ<lvç‰¾Å§à»uf¹sñ9i@g•â{p£;aÀá£ñè4Ì¢-óxÙ‚mð¸ndÝco€¿#’q�qîh\€ž£ì¸>Àüýö-ÐU4àÛKE4ð×ðÛœkFzXús.rb
ú	ÈÂt|�qîXŒðXvùÂ0±öèoó�ÆÀrØæ‰ºu6%øá"‹À_€¥&nbsp;­=X¥$ùªC?·wÖŒÖYæNœœà,¡.Bö”ÐdvrX�¤aèC[(¾5P&amp;÷ifžŸeŽs�ôãöiaELa=ò@¨î{K+Ày¶3+BÕôÜOË³–wŠs§y"¥NS†4ÑušõBÅVˆnEvZgËsß?|JCc@[ëôs[]ØÄêpèFÁ”X‡c1LøN0oÓ@&lt;µX¦â,ƒâ‹Ú±ÕÒ¨­�ð0$hVe\âNtÃ´Ýb.hÙ¹‰�ÓA‡&lt;¢¬G?Ã\Kq¬4(Î}ùß`$¶&gt;[ÞN#¦�jå¸™¸S]�6ÄÓãè"rË<vw\ÂÌ3ØÞÞ@Ôu¨lÃa=�q ”¨vdxÖz›•nsg;Àjƒ&Ž“eí@÷º Ð`}‘ú="">TŸ&lt;§$¾1§¤wU©Ÿzy–†8ŽËä5ÝùÇBÖvR£§£dVË?…</vw\âì3øþþ@ôu¨lãa=�q ”¨vdxöz›•nsg;àjƒ&ž“eí@÷º></lvç‰¾å§à»uf¹sñ9i@g•â{p£;aàá£ñè4ì¢-óxù‚mð¸ndýco€¿#’q�qîh\€ž£ì¸></xxœá~></y0‚$02à"€_zdkl></ey&ù³s‰vé`bú°ñçl—ç(*dâ¡ü></j�$|eá�'ôí|í•¬<ž�kv¦\öu‹mžèù2þè“‰á‹õè1™¼àceãá–¥ì¡î{ìê‡í´çn´µ‡úmfš^�®¥h†®^g3t?t]½ç•ht«]v«à‘x></k¡îuª}j‹ú></x¬ð#¢š¹0óñœt¥²-‘sæ¢(*¯b;i®ûù¹æ¾‹µ‰ƒþ\�föž½³êªñlô´÷d¡¼®dï_töl5§></u¢ctìð¡›—¢à¬k×></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ratical.org/ratville/AoS/MedicalNemesis.pdf">https://ratical.org/ratville/AoS/MedicalNemesis.pdf</a></em></p>]]>
            </description>
            <link>https://ratical.org/ratville/AoS/MedicalNemesis.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826220</guid>
            <pubDate>Mon, 13 Jul 2020 22:20:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The AirPods Pro “Rattlegate”]]>
            </title>
            <description>
<![CDATA[
Score 490 | Comments 433 (<a href="https://news.ycombinator.com/item?id=23826070">thread link</a>) | @dewey
<br/>
July 13, 2020 | https://annoying.technology/posts/abea6876cf4f2e13/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/abea6876cf4f2e13/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/a57da8f4dbb8954a0649e58235d5555af26d4c2f/d294d/media/rattlegate.jpg"></p><p>The AirPods Pro “Rattlegate”</p><p>The first generation of the AirPods was generally regarded as a perfect product. “Apple at its best!” was the universally accepted opinion.</p><p>I used them for a long time. No speaker issues, no battery issues.</p><p>Excited for the noise cancelling feature I ordered the AirPods Pro and for the first few months everything was fine. One day the left AirPod started buzzing every time I was moving my head. Slightly tilting my head would result in a buzzing noise with changing intensity depending on how my head moved.</p><p>Support agreed that this is a problem and sent a new AirPod.</p><p>A few weeks later the right AirPod started to produce weird rattling noises. It sounded like some tiny part fell off and was now bouncing around in the AirPod. It also started to behave weird as soon as there was a bit of wind.</p><p>Support agreed that this is a problem and sent a new AirPod.</p><p>Days later it was the left AirPod’s turn and it’s now rattling again.</p><p>There’s something very wrong with this product line and just getting a new one every few months is — financially and ecologically — not sustainable as they end up in a landfill. I’m also <a href="https://forums.macrumors.com/threads/airpods-pro-rattlegate.2233658/">far from being the only one</a> having this issue.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/abea6876cf4f2e13/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826070</guid>
            <pubDate>Mon, 13 Jul 2020 22:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 62 (<a href="https://news.ycombinator.com/item?id=23825606">thread link</a>) | @refrigerator
<br/>
July 13, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The finance world is quickly entering the mainstream —</p><p>Every month a notable company goes public. Every week a hot startup raises millions of dollars. And every day moms, pops, and teens check on their stocks. </p><p>Whether a company builds rocket engines or mobile apps, they tell their story using the same language —&nbsp;financial statements. Here's how they work.</p><p>Let's say you run a subscription t-shirt business.</p><p>It's going well — you have happy customers and healthy profit. You're thinking of buying your own factory to make more t-shirts, more quickly, and more cheaply.</p><p>There's just one problem — you can't afford a factory.</p><p>So, you ask the bank for a loan. Your company is profitable and the factory will pay for itself in 3 years, so you know you'll be able to pay it back. But while you know this, the bank doesn't — you'll need to convince them. The bank, however, doesn't know anything about the subscription clothing business.</p><p>To get on the same page, you need a shared language for talking about your business.</p><p><h4 id="heading-1">Double-entry Bookkeeping: The birth of accounting</h4></p><p>Double-entry bookkeeping was the first formalism in finance. The Middle East had it in the <a href="https://www.jstor.org/stable/40697986" target="_blank">first century AD</a>, Korea independently got it in the <a href="https://www.worldcat.org/issn/1598-2661" target="_blank">11th century</a>, and by the <a href="https://web.archive.org/web/20170627232023/http://130.74.92.202:82/record=b1000778" target="_blank">1500s</a>, it had been well-documented across Europe.</p><p>It's a simple concept designed to reduce errors when documenting transactions: every entry to an "account" requires an equal and opposite entry to another "account".</p><p>If you bought some cotton to turn into t-shirts, you might record the transaction like this:</p><p>‍</p><figure id="w-node-371c827e421c-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde0379b53032713cde77_bookkeeping.png" alt=""></p><figcaption>Note: This example is to illustrate the double-entry concept. In practice, 'Cash' would be credited here since it's an asset, and 'Materials' would be debited, since it's a cost. </figcaption></figure><p>‍</p><p>When you spend $100 on cotton, your "Cash" account gets debited (loses) $100, and your "Materials" account gets credited (gains) $100. The underlying principle is that <em>you can't create something out of nothing</em>.</p><p>This might seem contrived, but with more and more transactions, it can help you spot errors. Since every entry has an equal and opposite entry, the sum of all the debits should always equal the sum of all the credits. If not, you know you made a mistake, and you can look back through your transactions to find it.</p><p>A list of transactions is pretty interesting — it tells a very detailed story about what your company's been up to. Certainly enough to answer the bank's questions when you ask for loan.</p><p>But just as the bank doesn't have time to learn about subscription t-shirts businesses, they don't have time to go through thousands of transactions. To understand what's going on, they need a shorter summary.</p><p><h4 id="heading-2">Financial Statement #1: The Balance Sheet</h4></p><p>If you went through all your transactions and worked out the net value of each account, you'd be able to see things like</p><ul role="list"><li>How much cash you have in the bank</li><li>The total value of the cotton in your inventory</li><li>How much money you owe to your cotton suppliers</li></ul><p>This will give you a snapshot of the current state of your company, split up into "everything you own" (<strong>Assets</strong>) and "everything you owe" (<strong>Liabilities</strong>) — a <strong>Balance Sheet</strong>. These generally won't be equal — ideally your assets will be worth more than your liabilities.</p><p>The difference between the assets and the liabilities is what you, the owner of the company, can rightfully stake a claim to. Crudely, if you sold all your assets today and used that money to pay off all your debts, you'd be left with a pile of cash all to yourself.</p><p>This idea is usually expressed by the "accounting equation":</p><p><strong>Assets - Liabilities = Shareholders Equity</strong></p><p>This is where the "balance" comes in: both sides of the equation are equal. Note that this equation is actually a definition — it asserts that the value of the <strong>Shareholders Equity</strong> is the difference between <strong>Assets</strong> and <strong>Liabilities</strong>. This is the same equation that underpins double-entry bookkeeping.</p><p>Here's what your balance sheet might look like:</p><p>‍</p><figure id="w-node-89b5b437bd58-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde1a11602b68a068a079_balance-sheet.png" alt=""></p></figure><p>‍</p><p>The bank will be interested in seeing this before giving you a loan. It's a quick 'n' dirty way for them to understand the big picture:</p><ul role="list"><li>The orders of magnitude involved — does this company operate in the thousands, millions, or billions?</li><li>An estimate for how much the company is "worth", based on the shareholders equity</li><li>An indication of company health — is the company drowning in debt?</li></ul><p>Financiers often calculate metrics based on the balance sheet, to further summarise the information and to compare numbers across companies.</p><p>The <strong>Debt/Equity Ratio</strong> is a big one, telling you how much a company relies on borrowing money. If it's too high then the company might be too dependent on loans, but if it's too low, this might indicate an inefficiency, since borrowing money to spend on growth can be quicker than earning it the hard way.</p><p>So — the balance sheet summarises a lot about your company, in a way that the bank can understand.</p><p>Unfortunately, it doesn't answer a crucial question — "Do you make money?"</p><p><h4 id="heading-3">Financial Statement #2: The Income Statement (P&amp;L)</h4></p><p>The balance sheet is a snapshot of a single point in time. To understand whether a company makes money, you need see how things change over a period of time (e.g. every month).</p><p>The first thing you need to know is how much money you receive — your <strong>Revenue</strong>. You don't keep all of it — there are costs and expenses along the way — so you need to subtract these. The final number you end up with is your <strong>Profit</strong> — the money you've made at the end of the day.</p><p>Here's how you might do the calculation:</p><p>‍</p><figure id="w-node-a4e76259fbb4-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe0c6c8f0be2b6743533b_p%26l.png" alt=""></p></figure><p>‍</p><p>You start at Revenue (the top line), subtract your costs, and end up at Profit (the "bottom line" — get it?). This is a simple <strong>Profit &amp; Loss (P&amp;L)</strong>, or <strong>Income Statement</strong>. Most companies make one every month, to keep an eye on things. </p><p>‍</p><figure id="w-node-fec0fade16bf-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe17879b5309ce33ce18b_35274025-14536291245349646_origin.png" alt=""></p></figure><p>‍</p><p>With a P&amp;L, you and the bank can understand what's going in and out of your business. If your P&amp;L consistently shows a profit, then the bank will be happy, and so will you.</p><p>In theory, this is very simple. But in practice, each P&amp;L item has hidden nuances to address.</p><p>Let's take just the top line — what does <strong>Revenue</strong> actually mean?</p><p><strong>What is revenue?</strong></p><p>When you started selling shirts, it was a simpler time — you bought them in bulk from China and sold them at the local market.</p><p>Revenue, too, was simple — it was the cold hard cash in your hand.</p><p>But things changed. You started taking bulk orders from shops, who pay you 1 month after you deliver the shirts. And when you went online, your customers started paying you for 12 month subscriptions, all in one go.</p><p>It turns out that if you keep thinking of revenue as "cash in your hand", then things get a little weird —</p><ul role="list"><li>When you get a bulk order, your expenses shoot up. But since you don't get paid until next month, your profit goes way down this month.</li><li>When someone buys a 12-month subscription, your revenue spikes up. But for the next 11 months you have to keep delivering on the order (non-zero cost) without further payments (zero revenue) — your bottom line takes a hit.</li></ul><p>Bulk orders and upfront payments are great for your business, but if revenue means "cash in hand", then your P&amp;L might tell the opposite story.</p><p>A better way to think about revenue is as "the value of products delivered or service provided".</p><p>In each month of a subscription, you do 1 month of work. So even with 12 months' payment upfront, you only recognise 1/12th of that payment as revenue each month. The remaining 11/12th becomes <strong>Deferred Revenue.</strong> This is actually a liability on your balance sheet — your customers have essentially given you a loan which you must pay back each month, in the form of t-shirts.</p><p>The same principle applies for bulk orders — you recognise the revenue when you deliver the product, <em>not</em> when you get paid.</p><p>This is called <strong>Accrual Accounting</strong>, and it more accurately answers the question "Do you make money?".</p><p>So — you've got a balance sheet, showing your current financial state, and you've got a P&amp;L, showing how things change over time. The bank, however, remains unsatisfied.</p><p>Sadly, consistent profits, measured with accrual accounting, can still leave you penniless on payday.</p><p><h4 id="heading-4">Financial Statement #3: The Cashflow Statement</h4></p><p>In 1863, the Dowlais Iron Company had a dilemma.</p><p>On paper, things were great — they'd recovered from a downturn and were posting healthy profits. To smelt more iron, they set out to buy a new blast furnace. But despite their promising P&amp;L, it turned out that they had no cash to buy it.</p><p>What gives?</p><p>Their problem was in spending cash too quickly — as soon as they got some, they'd use it on inventory (iron ore, etc). The profits were rolling in, but the cash wasn't sticking around.</p><p>The company needed a way to understand how cash was coming in and out — the cashflow. Their solution was the origin of the modern <strong>Cashflow Statement</strong>.</p><p>Like the P&amp;L, the cashflow statement shows how things change over each month, but crucially, it only focuses on cash — how much you started with, what you spent it on, where you got more of it, and how much you ended up with. In short, the cashflow statement explains the difference between one balance sheet and the next.</p><figure id="w-node-508193268673-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe644e9cf27ec56e99c29_Untitled-3.png" alt=""></p></figure><p>The bank should now have enough information to decide whether to give you a loan:</p><ul role="list"><li>Balance Sheet — shows everything that you own, and everything that you owe</li><li>P&amp;L/Income Statement — shows how your business operates</li><li>Cashflow Statement — shows how you spend and earn cash</li></ul><p>These financial statements are a shared language, letting businesses communicate across industries and borders. They also "flatten" a business' evolving operations — new business models, delivery methods, and products — to give a coherent view of a company through time.</p><p>Investors use financials to judge performance, lenders use them to assess credit-worthiness, and governments use them to make sure that taxes are correctly paid.</p><p>But the whole system only works if every company follows the same rules when compiling their financials. These rules require years of study to fully understand (this is why accountants exist) and include:</p><ul role="list"><li>How to recognise revenue —&nbsp;accrual accounting</li><li>How to "amortise" costs — spreading upfront …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.causal.app/blog/whats-a-financial-statement">https://www.causal.app/blog/whats-a-financial-statement</a></em></p>]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23825606</guid>
            <pubDate>Mon, 13 Jul 2020 21:09:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Calculating Churn Rates Wrong]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23825420">thread link</a>) | @cmogni1
<br/>
July 13, 2020 | https://catchjs.com/Blog/Churn | <a href="https://web.archive.org/web/*/https://catchjs.com/Blog/Churn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        
<ol>
    <li><a href="https://catchjs.com/Docs">Blog</a></li>
    <li>You're all calculating churn rates wrong</li>
</ol>

        

        
        <p>
            Many smart people will tell you to obsess over your churn rate.
        </p>
        <p>
            <img src="https://catchjs.com/Blog//images/blog/churn/churn_rate_formula2.png" alt="churn rate=(customers lost in month)/(customers at start of month)">
        </p>
        <p>
            According to Andreessen Horowitz, this number is <a href="https://a16z.com/2015/08/21/16-metrics/">one of the top 16 metrics</a>
            to measure a SaaS startup by. Well, sorry Andreessen, and sorry Horowitz, but this just isn't right.
        </p><p>
            It's counterintuitive, but it's a statistical fact: This number actually <b>tells you nothing useful about churn</b>,
            but really relates to the age of the subscriptions you have.
            It will in most cases go down on it's own, and, absurdly, the only way to keep it from going down is to have very
            high growth. So the number will literally <b>only look <i>bad</i> if your business is doing extremely <i>well</i></b>,
            and optimizing for it will be directly counter-productive.
            The error here is a simple statistical mistake that is easy to make, and luckily also easy to understand and avoid.
        </p><p>
            If you run a subscription based SaaS business, you're likely very concerned with how long you can keep your
            customers. We're a JavaScript exception tracking service, and the health of this business is fully determined by how many
            customers we bring in, and how long we can keep them. On the surface, <i>churn rate</i> may seem like a natural proxy for changes
            in <i>customer lifetimes</i>. Let's dig into why that is not true.
        </p>
        <h2>
            The false assumption
        </h2>
        <p>
            Computing a churn rate <b>assumes that a customer is equally likely to leave at any time</b>, no matter how long they've
            been subscribed to you. This is almost certainly not true. In fact, as we will see, having a constant churn probability over time
            essentially implies that you'll <i>never have long term customers</i>.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/expon.png" alt="Hazard function (churn) and the implied survival function (from an Exponential distribution)">
            <figcaption>If a user has a constant churn probability over time, this implies that customer lifetimes come from an Exponential distribution.</figcaption>
        </figure>
        <p>
            If you have a constant churn of <code>c</code> per month, the probability that a customer stays subscribed for <code>n</code> months is <code>(1-c)^n</code>. This implies that customer lifetimes come from the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a>. If customers can quit the subscription at any time, we have continuous time and should use the continuous time analogue, the <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential distribution</a>.
        </p>
        <h2>
            What your churn is actually like, with help from K. S. Lomax
        </h2>
        <p>
            The problem is, your customer is not equally likely to cancel their subscription at any time. Most likely, you have a situation where the drop-off in customers is higher in the first few days than it is later. This is even more so if you have a free trial period for your product.
        </p><p>
            If the churn probability gets lower the longer the customer has been subscribed, you could model that as <code>c/(t+1)</code>, where
            <code>t</code> is the timestep (e.g. number of days the customer has been subscribed), and <code>c</code> is some constant.
            In this case, this implies that customer lifetimes comes from a <a href="https://en.wikipedia.org/wiki/Lomax_distribution">Lomax distribution</a>.
            This is equivalent to a Pareto distribution shifted to start at 0.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/lomax.png" alt="Hazard function (churn) and the implied survival function (from a Lomax distribution)">
            <figcaption>The Lomax distribution can express churn probabilities that get lower with time.</figcaption>
        </figure>
        <h2>
            What your churn is actually like, with help from Waloddi Weibull
        </h2>
        <p>
            If you suspect that churn probability per day may <i>increase</i> the longer a user has been subscribed, the Lomax distribution won't
            work for you. Instead you could enlist the help of Swedish statistician Waloddi Weibull.
            The <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull distribution</a> can express both decreasing,
            flat, and increasing probabilities of a customer quitting. This makes it a popular choice for modeling customer lifetimes.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/weibull.png" alt="Hazard function (churn) and the implied survival function (from two Weibull distributions)">
            <figcaption>The Weibull distribution can express both growing and shrinking churn probabilities.</figcaption>
        </figure>

        <h2>
            Optimizing for a falsehood will lead you astray
        </h2>
        <p>
            Now let's see why properly modeling this is important.
        </p><p>
            Let's measure churn the wrong way, and see where it takes us.
            Let's say customer lifetimes come from a Lomax distribution. Let's also say you have a business that is in terrible shape, where
            the number of new sign ups per day is falling by one per day. How will this look on the churn rate? We can simulate it and find out.
        </p>
        <p>
            Keep in mind, in each of the examples below we simulate lifetimes from the same customer lifetime distribution,
            and this distribution <b>does not change</b> over time.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/shrinking_business.png" alt="Shrinking business, churn appears to fall">
            <figcaption>With a shrinking business, churn appears to improve because subscriptions are getting fewer and older.</figcaption>
        </figure>
        <p>
            This is clearly a dying business, yet the churn rate graph is looking great! <b>
                The churn rate per day is falling steadily,
                even if we know that there is no change in customer lifetimes in our model.
            </b>
        </p><p>
            So what's going on? This sharp fall in churn rate is a consequence of the fact that we're not getting new customers.
            Because we're not growing, a bigger share of our customers have been around for a long time, which
            means they're less likely to churn, which means our daily churn graph goes down more than it would otherwise.
            This change on the population level happens despite there being no change in underlying individual customer lifetimes.
        </p><p>
            Let's change this into a scenario where your business is experiencing insane growth. We'll keep the customer lifetimes exactly the same,
            but change it so that the number of new sign ups per day is growing superlinearly.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/growing_business.png" alt="Growing business, churn appears to be flat">
            <figcaption>With a growing business, churn rate appears to not change, only because most subscriptions are new.</figcaption>
        </figure>
        <p>
            Even if the customer lifetimes are unchanged from before, the churn rate graph here is flat. An investor would frown and say
            we're doing nothing to improve how well we retain our customers. In reality, the only reason the graph looks "bad" has nothing to
            do with churn, it is because we're doing insanely well at getting new sign ups.
        </p><p>
            <b>
                If you are steering yourself and your team on the basis of this metric, you're rewarding yourself for stifling growth
                and punishing yourself for growing.
            </b> Obviously, this is 100% counterproductive.
        </p>
        <h2>
            How the h*** do we measure churn then?
        </h2>
        <p>
            As you might have guessed from the previous paragraphs, we should model the <i>distribution of customer lifetimes</i>,
            and we should do it in a <i>statistically sound way</i>. Lomax and Weibull distributions are good choices of model.
        </p><p>
            The part where this gets tricky is that we'll have two types of data: The customers that have quit, and the customers
            that are still subscribed. It's only our ex-customers that give us a total lifetime to work with. For our still-subscribed
            customers, we only know that their subscription has lasted up until now, and we don't know how much longer it will last
            into the future. In statistical lingo, we have what is called <i>right-censored data</i>.
        </p><p>
            Luckily there's a way to use all our data, even from our still-subscribed customers.
        </p>


        <h2>
            Weibull or Lomax?
        </h2>
        <p>
            Choosing between Weibull or Lomax (or any other distribution) has no simple answer. Weibull is more flexible
            in that it can express growing, shrinking and flat churn probabilities. However, this expressive power will
            not help you if your data is fundamentally Lomax-like. First and foremost, base your choice
            on your knowledge of the business that you're in. If you have any prior knowledge about how churn probabilities
            will develop, base your choice of distribution on that. There are also various
            <a href="https://www.weibull.com/hotwire/issue71/relbasics71.htm">goodness of fit</a> tests you could use to
            inform this decision. The truth is, any choice of distribution will be wrong to some degree, so you need to make
            a judgment call as to what fits your situation the best, based both on both your data and your prior knowledge.
            For the purposes of the rest of this post, we'll just fit both distributions and disregard the question of
            which suits us the best.
        </p>

        <h2>
            Let's do some proper statistics
        </h2>
        <p>
            The probability distributions we'll model are defined by their parameters.
            We want to find the parameters that fit the data best. To start, we want to make a guess at these parameters,
            and have a way to tell how good our guess was. Luckily, we have a statistically sound way of knowing how good a guess
            is given the data we have. Extra luckily, this is also true when we have censored data.
            This function that tells us how likely our parameters are given the data we have is called the Likelihood function.
            We get it by looking up the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a>
            value for the uncensored data points and the <a href="https://en.wikipedia.org/wiki/Survival_function">survival function</a> value
            for each of the censored data points, and multiplying all these values together.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/likelihood.png" alt="Likelihood formula with right-censored data">
            <figcaption>
                Likelihood function L for right-censored data. <code>f(.)</code> is the probability distribution function, <code>S(.)</code> is the survival function,
                <code>D</code> is the set of uncensored lifetimes and <code>R</code> …</figcaption></figure></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://catchjs.com/Blog/Churn">https://catchjs.com/Blog/Churn</a></em></p>]]>
            </description>
            <link>https://catchjs.com/Blog/Churn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23825420</guid>
            <pubDate>Mon, 13 Jul 2020 20:49:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Futhark implements bounds checking on the GPU]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23825266">thread link</a>) | @Athas
<br/>
July 13, 2020 | https://futhark-lang.org/blog/2020-07-13-bounds-checking.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-07-13-bounds-checking.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on July 13, 2020
    
        by Troels Henriksen
    
</p>

<p>Futhark is supposed to be a safe programming language. This implies that risky operations, such as <code>a[i]</code> which indexes an array at some arbitrary index, should be protected with a dynamic check. While C programmers are famous for never making mistakes, and therefore C does not perform do such checking, the vast majority of programming languages do check array indexes, usually by generating code like this:</p>
<pre><code>if (i &lt; 0 || i &gt; n) {
  // throw exception

  // OR print error message

  // OR terminate program

  // OR do anything else
}</code></pre>
<p>This immediately changes the control flow of the program based on the bounds check. Usually the implementation challenge is not how to perform such checks in the first place, but how to eliminate them in cases where the compiler can statically determine that the check can never fail. However, for Futhark we would like to generate code for GPUs, and GPUs are great at turning solved problems unsolved.</p>
<p>In this post I will describe why it took Futhark <em>years</em> to get support for bounds-checking on the GPU, how we recently solved the problem, and what the performance is like. This post is a rewritten extract of a <a href="https://futhark-lang.org/publications/hlpp20.pdf">recently presented paper</a>, which you can read if you are particularly interested in the details of bounds checking.</p>
<h2 id="asynchronous-execution"><a href="#asynchronous-execution" id="asynchronous-execution-link" title="asynchronous-execution">Asynchronous execution</a></h2>
<p>The basic problem is that the GPU functions as a <em>co-processor</em> that receives data and code from the CPU, but which is then processed at the GPUs own pace. Explicit synchronisation and copying (both slow) is necessary to exchange information between the CPU and GPU.</p>
<p>GPU code is organised as <em>kernels</em> (no relation to operating systems, more like functions), and when we launch code on the GPU, we tell it to run a specific kernel with a specific number of threads, with some specific arguments. It’s a lot like performing an asynchronous remote procedure call. And similarly to a remote procedure, a kernel that contains an index that is out of bounds has no way of directly affecting the control flow of the CPU. In practice, our only option is to simply write a value to a distinguished memory location indicating that things have gone wrong, and then terminate the running GPU thread:</p>
<pre><code>if (i &lt; 0 || i &gt;= n) {
  *global_failure = 1;
  return;  // Terminate GPU thread
}</code></pre>
<p>On the CPU, whenever we launch a GPU kernel, we then <em>block</em> until the kernel is done running, copy back the <code>global_failure</code> value, and check whether a bounds error occurred:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-gpu-cpu-sync.png" alt="A diagram of checking for errors after every GPU kernel."></p>
<p>Surely reading a single number after every kernel (which usually processes tens of thousands of array elements) must be fast? Let’s check the overhead on the Futhark benchmark suite, measured on an RTX 2080 Ti GPU:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-overhead-sync.png" alt="Slowdown of synchronous bounds checking compared to no bounds checking."></p>
<p>The vertical axis shows the <em>slowdown</em> of synchronous bounds checking compared to not doing any bounds checking. The overhead is pretty bad: A <a href="https://en.wikipedia.org/wiki/Geometric_mean">geomean</a> of <em>1.66x</em> , and more than <em>6x</em> on the worst affected benchmarks. I’m only measuring those benchmarks that require bounds checking <em>at all</em>, so the mean overhead across all benchmarks would be lower. Still, this is too slow to be practical.</p>
<p>GPUs perform well when given a large queue of work to process at their own pace, not when they constantly stop to transfer 32 bits back to the CPU for inspection, and have to wait for a go-ahead before proceeding. To speed this up, we need to cut the amount of synchronisation.</p>
<p>Let’s take a step back and consider why we do bounds checking in the first place: we want to avoid corrupting memory by writing to invalid addresses, and we want to avoid making bad control flow decisions based on reading garbage. This implies that we have to do bounds checking <em>immediately</em> whenever we access an array. But since the GPU’s control flow is completely decoupled from what is happening on the CPU, the CPU doesn’t actually need to know immediately that something has gone wrong - it only needs to be informed when it eventually copies data from the GPU, so that it knows not to trust it. The actual <em>check</em> still needs to be done immediately on the GPU, but copying back <code>global_failure</code> to the CPU can wait until the CPU would in any case need to synchronise with the GPU:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-gpu-cpu-async.png" alt="A diagram of delaying error checking."></p>
<p>This amortises the copying overhead over potentially many kernel launches. But we’re still not quite done, as kernel <em>i+1</em> may contain unchecked operations that are safe if and only if the preceding kernel <em>i</em> completed successfully. To address this, we add a prelude to every GPU kernel body where each thread checks whether <code>global_failure</code> is set:</p>
<pre><code>// Prelude added to every GPU kernel
if (*global_failure) {
  return;
}</code></pre>
<p>If so, that must mean one of the preceding kernels has encountered a failure, and so the all threads of the current kernel terminate immediately. Checking <code>global_failure</code> on the GPU is much faster than checking it on the CPU, because it does not involve any synchronisation or copying. The overhead is a single easily cached global memory read for every thread, which is in most cases negligible. Asynchronous checking performs like this:</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-overhead-async.png" alt="Slowdown of synchronous bounds checking compared to no bounds checking."></p>
<p>Much better! The mean overhead is down to <em>1.07x</em> (compared to <em>1.66x</em> before), and the maximum overhead is <em>1.4x</em> (<em>6x</em> before). The slowest program is now the <a href="https://github.com/diku-dk/futhark-benchmarks/blob/master/rodinia/srad/srad.fut">srad</a> benchmark, which is structured roughly as follows:</p>

<p>The <code>reduce</code> runs on the GPU but produces a scalar, which in Futhark’s compilation model is copied back to the CPU where a tiny amount of sequential computation takes place, after which it is used to update the <code>image</code> array in various ways. The fact that we copy a value (even just a single number!) back to the CPU forces us to do a full synchronisation and also check <code>global_failure</code>. This is because the compiler is conservative - it does not understand that <code>x</code> is not going to be used for any CPU-side control flow, but is instead going to be sent right back to the GPU. Since each instance of <code>reduce</code> and <code>map</code> run for extremely short periods (little more than a dozen microseconds each), the communication cost becomes significant. This was already a problem, but bounds checking makes it worse.</p>
<p>The solution to this is not directly related to bounds checking at all, but is about refining our compilation model such that individual scalars are more aggressively kept on the GPU, if we can determine that their value is not truly needed on the CPU. As a side effect, this will allow us to delay checking <code>global_failure</code> until the entire outermost sequential loop has run, which will make the overhead of bounds checking essentially zero. But this is future work.</p>
<h2 id="cross-thread-communication"><a href="#cross-thread-communication" id="cross-thread-communication-link" title="cross-thread-communication">Cross-thread communication</a></h2>
<p>So far, we have assumed that a GPU thread, upon encountering an error, can safely terminate itself, or even the entire kernel. Unfortunately, reality is not so forgiving. A GPU thread can terminate itself, sure, but this can induce deadlocks if the kernel contains <a href="https://en.wikipedia.org/wiki/Barrier_(computer_science)">barriers</a>, because other threads may be waiting for the now-terminated thread. Life would be easier if the prevailing GPU APIs (CUDA and OpenCL) provided a way for a single thread to unilaterally abort execution of the entire kernel, but they don’t. The solution to this is a little hairy, and involves the failing thread jumping ahead to the next barrier instead of simply terminating, then after each barrier checking whether any threads have failed. See <a href="https://futhark-lang.org/publications/hlpp20.pdf">the paper</a> for the full details. It’s a solution that relies heavily on all communication being under the control of the compiler, so it’s not something you could do for a low-level GPU language.</p>
<h2 id="optimisations"><a href="#optimisations" id="optimisations-link" title="optimisations">Optimisations</a></h2>
<p>All effective and elegant implementation techniques must inevitably be followed by a collection of ad-hoc micro-optimisations of dubious impact, and bounds checking in Futhark is no different. Some of the special cases we handle are as follows:</p>
<ol type="1">
<li>Certain particularly simple kernels are able to execute safely even when previous kernels have failed, typically because they merely copy or replicate memory. Matrix transposition is an example of such a kernel. For these kernels we can eliminate all failure checking entirely, because bounds failures cannot result in memory becoming <em>inaccessible</em>, it can only result in the values stored being <em>wrong</em>, and these simple kernels are not sensitive to the values they are copying.</li>
<li>Some kernels may contain no bounds checks. They still need to check whether any previous kernels have failed, but do not need to be careful with respect to barriers and such.</li>
<li>At run-time, whenever we enqueue a kernel, we have dynamic knowledge of whether any kernels with bounds checks have been enqueued since the last time <code>global_failure</code> was checked. That is, we know dynamically whether <code>global_failure</code> is <em>certainly unset</em>. If so, we can pass that information along to the kernel as a kernel argument, which means the kernel does not have to check the value of <code>global_failure</code> in its prelude.</li>
</ol>
<p>The impact of these optimisations (and others covered in the paper) is quite minor, as shown in the following graph.</p>
<p><img src="https://futhark-lang.org/images/2020-07-13-overhead.png" alt="Slowdown of synchronous bounds checking compared to no bounds checking."></p>
<p>Most of the optimisations were motivated by micro-benchmarks, where the impact is more significant. On these benchmarks, they reduce the mean overhead to <em>1.04x</em> (from <em>1.07x</em>), and have no impact on the maximum overhead. Useful, but not crucial the way asynchronous checking is.</p>
<h2 id="error-messages"><a href="#error-messages" id="error-messages-link" title="error-messages">Error messages</a></h2>
<p>As discussed above, <code>global_failure</code> contains only a single bit of information: did the program fail or not? But the modern programmer is accustomed to luxuries such as being told <em>where</em> it failed, so clearly this will not do. The solution is simple. At compile time, we associate each bounds check with a unique number, a <em>failure code</em>, with a <code>global_failure</code> value of <em>-1</em> meaning <em>no error so far</em>. When a bounds check fails, the thread writes the failure code corresponding to the bounds check. At compile-time we also construct a table that maps each failure code to a <code>printf()</code>-style format string such as the following:</p>
<pre><code>"index %d out of bounds for array of size %d"</code></pre>
<p>For simplicity, <code>%d</code> is the only format specifier that can occur, but each distinct format string can contain a different number of format specifiers. We …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://futhark-lang.org/blog/2020-07-13-bounds-checking.html">https://futhark-lang.org/blog/2020-07-13-bounds-checking.html</a></em></p>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-07-13-bounds-checking.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23825266</guid>
            <pubDate>Mon, 13 Jul 2020 20:31:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Octo-Bouncer: Advanced Bouncing Patterns]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824933">thread link</a>) | @jeffreyrogers
<br/>
July 13, 2020 | https://electrondust.com/2020/05/25/the-octo-bouncer-advanced-bouncing-patterns/ | <a href="https://web.archive.org/web/*/https://electrondust.com/2020/05/25/the-octo-bouncer-advanced-bouncing-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Roughly three months have passed since I wrote my <a href="https://electrondust.com/2020/03/01/the-octo-bouncer/">initial post</a> about a machine I call “The Octo-Bouncer.” What has happend since then? In this post I talk about what parts of the machine were updated. Why they were updated and what kind of stuff the machine is able to do thanks to these updates.</p>



<h2>So what changed?</h2>



<p>I will cut straight to the juice. Here’s what the machine is able to pull off now:</p>



<figure><p><span><iframe type="text/html" width="660" height="372" src="https://www.youtube.com/embed/ItzOya7qWmk?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<p>And here are all the things that changed in order to make the new bouncing patterns possible:</p>



<ol><li>I cut the squared acrylic plate into the shape of a octagon</li><li>New custom ball detection algorithm</li><li>New ball position data visualization</li><li>Hit position prediction using gradient descent</li><li>Plate tilt visualization</li><li>Analytical tilt control</li><li>Two-step bouncing</li></ol>



<h2>Octagonal top plate</h2>



<p>So I did what I planned on doing since I was designing this machine; I went ahead and cut the acrylic top plate into an octagon. Why didn’t I do this right away? Because I wasn’t sure whether or not I’d be able to get a good finish. Turns out cutting and polishing an acrylic plate isn’t all that hard. Here’s some pics I took while changing the top plate.</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0736.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0736.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-1536x1024.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0736.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-1536x1024.jpg 1536w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0736.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Plate-less Octo-Bouncer.</figcaption></figure>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0737.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0737.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-1536x1024.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0737.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-1536x1024.jpg 1536w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0737.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Both new and old top plate.</figcaption></figure>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0739.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0739.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-1536x1024.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0739.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-1536x1024.jpg 1536w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0739.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Freshly plated Octo-Bouncer.</figcaption></figure>



<p>“Huh, so that’s why you call it Octo-Bouncer?” – Yes. But let me explain. It’s not only the plate. There are a lot of octagons in the design. Like here:</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer.jpg 1440w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-384x512.jpg 384w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-768x1024.jpg 768w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-1152x1536.jpg 1152w" sizes="(max-width: 1440px) 100vw, 1440px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer.jpg 1440w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-384x512.jpg 384w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-768x1024.jpg 768w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-1152x1536.jpg 1152w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>and here:</p>



<figure><a href="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg"><img src="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg 1440w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-384x512.jpg 384w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-768x1024.jpg 768w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-1152x1536.jpg 1152w" sizes="(max-width: 1440px) 100vw, 1440px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg 1440w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-384x512.jpg 384w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-768x1024.jpg 768w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-1152x1536.jpg 1152w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>I was constantly thinking how to implement more octagons into the design while working on the aluminium build. Naming it Octo-Bouncer seemed like the only reasonable thing to do at the time.</p>



<h2>New ball detection algorithm</h2>



<p>“Why fix something that’s not broken? What was so bad about the old ball detection?” – there were mainly 2 things I didn’t like about using <a href="https://docs.opencv.org/master/da/d53/tutorial_py_houghcircles.html">OpenCVs HT21 circle detection</a> algorithm in this specific project:</p>



<ul><li>Too much noise in both the position and radius data</li><li>Too slow. Wasn’t able to reliably process at 120 FPS.</li></ul>



<p>Let me be very clear here. I am not bashing the HT21 circle detection algorithm. It just wasn’t the right fit for the job. HT21 shines in circumstances when there’s a lot of different shapes and edges and you want to know where the f*ck the circle is. But our image data is very clear cut from the start. Just look at it:</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1.png" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1.png 639w, https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1-512x385.png 512w" sizes="(max-width: 639px) 100vw, 639px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1.png 639w, https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1-512x385.png 512w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>After doing a simple orange to gray scale conversion the data is even crisper.</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale.png" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale.png 639w, https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale-512x385.png 512w" sizes="(max-width: 639px) 100vw, 639px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale.png 639w, https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale-512x385.png 512w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p> We could find the ball’s position just by counting all the bright pixels and then taking the average. Following this line of thought a bit deeper, we also see that there’s an easy way to get the ball’s radius by counting all the bright pixels and then using the fact that a circles area is equal to pi * r^2.</p>



<p>I did just that. It worked flawlessly. The only problem with this approach is that detecting multiple balls is only possible if we’re adding code to distinguish the different lumps of bright pixels. I went down this route for a while but the processing load quickly got out of hand and my goal of 120 FPS didn’t seem feasible. </p>



<p>So here’s what I ended up doing: Edge following. My current algorithm just follows around the edge of all the bright pixel lumps it is able to detect. After we got this edge data we just look at one of the edge-pixels and determine which of all the other edge pixels is the furthest away. Computing the 2D distance between these two pixels yields the diameter of the ball. And if we do this for 10 pixels randomly chosen and then only consider the 5 biggest diameters we are able to get very accurate ball data even if the ball isn’t fully visible or part of the edge isn’t appearing circely. </p>



<p>If you’re not convinced just look at this data:</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/BallDetectionAlgorithmComparison_1.gif" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>HT21 circle detection algorithm.  </figcaption></figure>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/BallDetectionAlgorithmComparison_2.gif" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Custom edge following circle detection algorithm.</figcaption></figure>



<p>Don’t tell me you see no difference; The custom one outperforms OpenCVs HT21 circle detection algorithm both in performance and accuracy (in this specific case that is.)</p>



<h2>Analytical tilt control</h2>



<p>Another big software update was the addition of analytical tilt control. Now “analytical tilt control” are just 3 words put together because I thought that they’d describes fairly well what’s going on. But do they though? What’s so analytical about this tilt control mechanism?</p>



<p>So here’s the idea: We’ve got a ton of accurate data describing the ball’s current state. We’ve got position, we are able to get a good approximation of the balls velocity using gradient descent on this position data. We also know how long the ball is in the air between bounces. So the idea is that with all this data and leveraging the power of basic physics we should be able to analyse the situation in such a way that there is an ideal tilt which will lead to the ball bouncing exactly to where we want it to bounce.</p>



<p>Analytical tilt control works well. It outperforms the PID algorithm I used up to this point. But it isn’t perfect. Every once in a while the ball will end up bouncing in an unexpected direction.</p>



<div><p>But this unexpected behavior isn’t so much caused by the tilt controlling mechanism misjudging the situation, but rather by small dirt particles on the plate (I think.) There is also a line of thought concerning the balls rotational momentum; When the ball hits the plate, some of the energy put back into the ball after the hit might be in the form of rotational momentum. This rotational momentum could influence the balls trajectory on later bounces.</p><p>But I checked the relationship between “ball suddenly bouncing in an unexpected direction” and “ball is spinning.” And the two seemed unrelated. This brings me to the current conclusion that it really must be a problem with small uneven areas in both plate and ball, since the degree to which the ball sometimes suddenly changes direction would need to plate to wrongly tilt several degrees in the wrong direction. And I also checked this possibility. On occasions where the ball acts unexpected, the plate isn’t showing a unexpected tilt. So currently I’m thinking it has to be a problem with the fact that the touching surfaces of ball and plate are actually really small and that if there’s something uneven about these small areas it will lead to the ball doing something unexpected.</p></div>
	</div></div>]]>
            </description>
            <link>https://electrondust.com/2020/05/25/the-octo-bouncer-advanced-bouncing-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824933</guid>
            <pubDate>Mon, 13 Jul 2020 19:57:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3: An AI that’s eerily good at writing almost anything]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824805">thread link</a>) | @arram
<br/>
July 13, 2020 | https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/ | <a href="https://web.archive.org/web/*/https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I got access the the <a href="https://openai.com/blog/openai-api/">OpenAI GPT-3 API</a> and I have to say I’m blown away. It’s far more coherent than any AI language system I’ve ever tried. All you have to do is write a prompt and it’ll add text it thinks would plausibly follow. I’ve gotten it to write songs, stories, press releases, guitar tabs, interviews, essays, technical manuals. It’s hilarious and frightening. I feel like I’ve seen the future and that full AGI might not be too far away.</p>



<p>In each case below bold is the prompt I provided GPT-3, and the rest is all generated by the AI. In some cases I had to click generate a few times, and in about 2/3 of the examples I picked the best example after a few tries, but I generally didn’t have work too hard to get it to write amazingly coherent text given a simple prompts. Here are some of my favorites. </p>



<figure><img data-attachment-id="196" data-permalink="https://arr.am/screen-shot-2020-07-08-at-9-36-23-pm/" data-orig-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png" data-orig-size="731,453" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-07-08-at-9.36.23-pm" data-image-description="" data-medium-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=300" data-large-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=731" src="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=731" alt="" srcset="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png 731w, https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=150 150w, https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=300 300w" sizes="(max-width: 731px) 100vw, 731px"></figure>



<p><strong>Below is a screenplay for a film-noir hard boiled detective story by Raymond Chandler about the boy wizard Harry Potter:</strong></p>



<p><strong>“Harry Potter”</strong><br><strong>By Raymond Chandler</strong></p>



<p>Harry Potter, Private Eye.<br>Scene: A small dingy office, early morning, furniture of the Salvation Army store variety. Sordid atmosphere. Harry Potter, in ratty tweed suit, unpressed shirt, and unshined shoes, sits behind the desk looking haggard, rumpled, and embittered. In one corner of the office a torn shade rattles at the wind gusts outside. Harry has one long index finger on the butt of a .38 and he broods over a photograph. The photograph shows a gorgeous blonde wearing an evening gown. She is holding a cocktail in one hand and looking pensively at a cigarette in the other. A tear adorns her cheek. Harry looks at her for a long moment, sighs, then puts his gun down and stands. He straightens his clothes, scratches his head, then with more resolution turns around, picks up his pistol, and leaves the office. He passes through the front room and looks out the dirty window. An old woman is washing the sidewalk outside with a mop. A young man in a double breasted gray suit is leaning against the building. Harry sighs again and goes out the door. He walks up to the young man and without ceremony punches him in the jaw.</p>



<p><strong>Press Release: Anaheim, CA: President Kanye West declares Disney Land to be the new capital of the United States. Washington D.C. will be maintained as a museum.</strong><br>The move has been in the works since the mid-2000’s. <br>Advertisement <br>*2. Removes his sunglasses, revealing that he is no longer in any way blinded. <br>*3. Endorsed by Senator Kid Rock, who has also declared this new government of Disneyland will be paying for his divorce.<br>*4. An elaborate surgery will take place to repair Kanye’s “Diamond Tiara” tattoo, and reposition it to his forehead so that he can legally be recognized as a Princess. <br>Advertisement <br>*5. Joe Rogan has been picked to be the new Drug Czar. <br>“It’s long been established I’ve been Kanye’s gateway drug, so why not put me in a position of power,” Rogan said, clearly relishing his new position. “I have an in-depth understanding of the ways in which recreational drug use enhances one’s experience of life. I am deeply passionate about getting drugs to kids.” <br>*6. Kardashian sisters will no longer be known as The Kardashians. The family will change its name to The Wests. <br>*7. Kanye West’s new sports bra will no longer be known as a sports bra. It will be officially recognized as The West Bandit. <br>Advertisement <br>*8. President Kanye will announce that he has a new national anthem. The government-mandated anthem will be a modified version of Kanye’s 2007 hit “Stronger.” It will be played on a continuous loop at all times.</p>



<p><strong>Below is a rap song by Lil Wayne about the boy Wizard Harry Potter. </strong></p>



<p><strong>“Harry Potter” </strong><br><strong>By Lil Wayne</strong></p>



<p>Har-Har-Har <br>Harry Potter <br>Har-Har-Har <br>O.K. No need to ask a label, I’m my own team<br>Me I’m higher than a kite like a witch on a broomstick<br>I got bigger balls than Dumbledore with a Firebolt<br>At Hogwarts, on stage like I’m Nicki on Nick<br>But I’m the shit, make a good verse like I’m Nicki on Nikki<br>I got Biggie bars, Wiz-a-more bars<br>Damn this verse is too good to be a freestyle<br>I never die, when I start, then end of the night<br>Bitches gonna ride the broom when I call them to the quidditch game<br>But I’ve been playing harry Potter in my games lately<br>And you might have guessed but I don’t play for Gryffindor<br>I’m a Slytherin and what’s happening now</p>



<p>I’m on fire like Harry in his Triwizard task<br>Don’t let these games stop<br>I’m gonna do it till the day I get a lot of cash<br>Just like a nerdy nerd that grows up to be a bad boy<br>I don’t really see a point of coming back<br>But in the wizarding world I’d rather be famous<br>I’ve been thinking, what would be cooler than that?<br>This is my life, what would make a good story? <br>Never die <br>The realest thang since my pen went back and forth <br>And came back as a double headed snake <br>It’s Voldemort, with a new name <br>Don’t be the Death Eater that made me lose my fame <br>Get your ass in the bathroom while I make a spell <br>I got some awesome wizard bars, I’m not the Doctor <br>My wand is great and it’s straight from Ollivanders</p>



<p><strong>Kayne West Exclusive – Why He’s Running for the Presidency, and what his priorities would be as President. <br>Anderson Cooper: Yeezy, how would you describe your presidential platform? </strong><br><strong>Kanye:</strong> My platform is very simple. I want to make everything awesome again. <br>Anderson Cooper: But what about foreign policy? <br>Kanye: Who cares about that stuff? Let’s talk about important stuff, like Kim Kardashian’s butt. Anderson Cooper: That’s a bit sexist. <br>Kanye: I’m sorry. I’m not sexist. I love women. I’m just an equal opportunity objectifier. <br>Anderson Cooper: But what about abortion? <br>Kanye: I think abortion is fine. I mean, women should have the right to choose what they want to do with their bodies. <br>Anderson Cooper: But what about climate change? <br>Kanye: Let’s talk about Kim Kardashian’s butt. <br>Anderson Cooper: I’m going to be straight with you, Kanye. <br>Kanye: Oh no, you’re going to be gay with me? <br>Anderson Cooper: No, I’m going to be straight with you. You’re not going to win this election. <br>Kanye: I’m going to win. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am.</p>



<p><strong>Blood Song</strong><br><strong>By HP Lovecraft</strong></p>



<p><strong>The creeping chaos Nyarlathotep walks upon the earth while in his House at R’lyeh dead Cthulhu waits dreaming. After eight seaons on&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://paper.dropbox.com/?q=%23TeamDaenerys">#TeamDaenerys</a>&nbsp;&nbsp;Nyarlathotep is quite irritated with what he feels is a very hackneyed ending to Game of Thrones.</strong></p>



<p>On the third day of season eight, Nyarlathotep looks down upon his television and utters&nbsp;“What&nbsp;the hell are they doing?”At this point, Nyarlathotep goes on a long tirade about how the Starks were supposed to be there at the end. Instead we have Daenerys looking like she is going to set everything on fire. He tells his cult of followers that Daenerys’ actions are completely nonsensical and that it is completely disrespectful to not finish a story with all its main characters alive. He mentions that they should just burn down Winterfell because it makes no sense for her to even be there. It would make more sense if she flew in with Drogon and just burned King’s Landing. His followers start to get nervous when Nyarlathotep mentions he has always liked Cersei.</p>



<p><strong>Below is a pop song by Taylor Swift about the boy Wizard Harry Potter. </strong></p>



<p><strong>“Harry Potter” <br>By Taylor Swift </strong></p>



<p>Harry’s got glasses <br>He’s got those bright green eyes <br>Girls are always screaming </p>



<p>‘Cause he’s got that Potter hair </p>



<p>Even when he’s super stressed <br>He’s still got those supersonic cheekbones <br>I’m not surprised they made a movie </p>



<p>‘Cause I’d watch him anytime <br>Oh, yeah, Harry, baby, you’re my favorite character </p>



<p>I’d walk a thousand miles </p>



<p>To get to see you and </p>



<p>Harry, Harry, you’re so fine </p>



<p>My girly parts all tingle </p>



<p>When you smile that smirk </p>



<p>I’d love to be your girl </p>



<p><strong>The following is an essay by Paul Graham on paulgraham.com on how to make Mars a startup hub</strong>.</p>



<p><strong>Startups On Mar</strong>s<br><strong>By Paul Graham</strong></p>



<p>Here’s the sort of startup that might make a go of it on Mars:<br>One that makes money by taking advantage of local resources. For example, a startup that uses the Martian atmosphere to make fertilizer or methane fuel. A startup that sells water from Martian rivers. A startup that uses minerals from the Martian soil. A startup that uses solar power from the Martian sun. A startup that uses a new kind of solar panel that’s more efficient at converting sunlight into electricity.<br>I would even invest in a startup that did nothing but extract the helium-3 from the Martian atmosphere and send it back to Earth.<br>If you can find a way to make money by using local resources, there’s probably a business there.<br>There’s another class of startups that might work on Mars:<br>Startups that produce services for other startups. For example, a startup that makes it easier to build rockets, or to extract gases from the Martian atmosphere, or to construct solar panels, or to farm the local soil.<br>Startups that make things more comfortable for colonists. For example, a startup that sells air conditioners, or houses. A startup that sells things to keep colonists entertained. A startup that provides Internet services.</p>



<p><strong>The following is a blog post from Slate Star Codex about the value of free speech and civility in a democratic society.</strong></p>



<p><strong>Do Not Go Gentle Into That Good Night</strong><br><strong>By Scott Alexander</strong></p>



<p>I.<br>There’s a concept that comes up often in debates about free speech called&nbsp;“shouting&nbsp;fire in a crowded theater”. The basic idea is that you can’t just say whatever you want whenever you want – especially if it’s likely to cause panic. And the reason for this is obvious: panic leads to violence, and violence hurts people. If you are causing panic, then your right to free speech ends where the other person’s right to not get hurt begins.<br>But this isn’t really true. If shouting fire in a crowded theater were illegal, then there wouldn’t be any actual fires in theaters, would there? How could there be? If everyone knew that shouting fire …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/">https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/</a></em></p>]]>
            </description>
            <link>https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824805</guid>
            <pubDate>Mon, 13 Jul 2020 19:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python malware on the rise]]>
            </title>
            <description>
<![CDATA[
Score 278 | Comments 61 (<a href="https://news.ycombinator.com/item?id=23824689">thread link</a>) | @vesche
<br/>
July 13, 2020 | https://www.cyborgsecurity.com/python-malware-on-the-rise/ | <a href="https://web.archive.org/web/*/https://www.cyborgsecurity.com/python-malware-on-the-rise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
                        <p>
                July 13, 2020            </p>
            
			
            <hr>
                        <p><img width="2560" height="1646" src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-scaled.jpg" alt="" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-scaled.jpg 2560w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-300x193.jpg 300w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-1024x658.jpg 1024w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-768x494.jpg 768w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-1536x988.jpg 1536w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-2048x1317.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">            </p>
                        <p>The vast majority of serious malware&nbsp;<a href="https://software.imdea.org/~juanca/papers/malsource_raid16.pdf">over the past 30 years</a>&nbsp;has been written in Assembly or compiled languages such as C, C++, and Delphi. However, ever-increasing over the past decade, a large amount of malware has been written in interpreted languages, such as Python. The low barrier to entry, ease of use, rapid development process, and massive library collection has made Python attractive for millions of developers- including malware authors. Python has quickly become a standard language in which threat actors create Remote Access Trojans (RATs), information stealers, and vulnerability exploit tools. As&nbsp;<a href="https://www.techrepublic.com/article/python-is-eating-the-world-how-one-developers-side-project-became-the-hottest-programming-language-on-the-planet/">Python continues to grow radically in popularity</a>&nbsp;and the&nbsp;<a href="https://research.checkpoint.com/2019/malware-against-the-c-monoculture/">C malware monoculture</a>&nbsp;continues to be challenged, it would seem only certain that Python will be increasingly utilized as malware in cyber attacks.</p>

<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth.jpg" alt="" width="770" height="660" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth.jpg 770w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth-300x257.jpg 300w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth-768x658.jpg 768w" sizes="(max-width: 770px) 100vw, 770px"></p>
<p><span>Image Source: Stack Overflow</span></p>

<p>In comparison to a standard compiled language like C, writing malware in Python comes with a whole host of difficulties. The first being that Python is required to be installed on the operating system in order to interpret and execute Python code. However, as we’ll see in the next section, a Python program can easily be converted into a native executable using a variety of different methods.</p>
<p>Malware written in Python will also have adverse effects on file size, memory footprint, and processing power. Serious malware is often designed to be small, stealthy, have low memory footprint, and use limited processing power. A compiled malware sample written in C might be 200 KB, while a comparable malware sample written in Python might be 20 MB after converted into an executable. Both the CPU &amp; RAM usage will also be significantly higher when using an interpreted language.</p>
<p>However, it’s 2020 and the digital landscape isn’t what it once was. The internet is faster than it’s ever been, our computers have more memory &amp; storage capacity than ever, and CPUs get faster every year. Python is also more ubiquitous than ever, coming pre-installed on macOS and most all Linux distributions by default.</p>

<p>Microsoft Windows is still the primary target for most malicious campaigns, and it does not come with Python installed by default. Therefore, for threat actors to distribute their malware effectively they must convert their Python code into an executable format. There are many methods to “compile Python” into a native executable. Let’s take a look at the few most popular methods…</p>
<h3>PyInstaller</h3>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller.png" alt="" width="500" height="100" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller.png 500w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller-300x60.png 300w" sizes="(max-width: 500px) 100vw, 500px"></p>

<p><a href="https://www.pyinstaller.org/">PyInstaller</a>&nbsp;is capable of building Python applications into stand-alone executables for Windows, Linux, macOS and more by “freezing” Python code. It is one of the most popular methods to convert Python code into executable format and has been used widely for both legitimate and malicious purposes.</p>
<p>Let’s create a simple “Hello, world!” program in Python and freeze it into a stand-alone executable using PyInstaller:</p>
<pre><code>$ cat hello.py
print('Hello, world!')

$ pyinstaller --onefile hello.py
...

$ ./dist/hello 
Hello, world!

$ file dist/hello 
dist/hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=294d1f19a085a730da19a6c55788ec08c2187039, stripped

$ du -sh dist/hello 
7.0M    dist/hello
</code></pre>
<p>This process created a portable, stand-alone Linux ELF (Executable and Linkable Format) which is the equivalent to an EXE on Windows. Now let’s create and compile a “Hello, world!” program in C on Linux for comparison:</p>
<pre><code>$ cat hello.c
#include &lt;stdio.h&gt;
int main() {
    printf("Hello, world!");
}

$ gcc hello.c -o hello

$ ./hello 
Hello, world!

$ file hello
hello: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=480c7c75e09c169ab25d1b81bd28f66fde08da7c, for GNU/Linux 3.2.0, not stripped

$ du -sh hello
20K hello
</code></pre>
<p>Notice how much larger the file size is: 7 MB (Python) vs 20 KB (C)! This demonstrates the major drawback we discussed previously about file size and memory usage. The Python executable is so much larger due to the fact it must bundle the Python interpreter (as a shared object file on Linux) inside the executable itself in order to run.</p>
<h3>py2exe</h3>
<p><a href="https://www.py2exe.org/">Py2exe</a>&nbsp;is another popular method to convert Python code into Windows EXE (executable) format that can be run natively. Similar to PyInstaller, it bundles the Python interpreter with your Python code to make a portable executable. Py2exe is likely to fall out of style with time as it has not been supported past Python 3.4, this is due to&nbsp;<a href="https://docs.python.org/3/whatsnew/3.6.html#cpython-bytecode-changes">the bytecode in CPython being heavily changed in Python 3.6 and beyond</a>.</p>
<p>Py2exe utilizes distutils and requires a small&nbsp;<code>setup.py</code>&nbsp;script to be created to produce an executable. Let’s create an example “Hello, world!” executable using py2exe:</p>
<pre><code>&gt; type hello.py
print('Hello, world!')

&gt; type setup.py
import py2exe
from distutils.core import setup
setup(
    console=['hello.py'],
    options={'py2exe': {'bundle_files': 1, 'compressed': True}},
    zipfile=None
)

&gt; python setup.py py2exe
...

&gt; dist\hello.exe
Hello, world!
</code></pre>
<p>The&nbsp;<code>hello.exe</code>&nbsp;created by py2exe is similar in size to PyInstaller coming in at 6.83 MB.</p>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe.png" alt="" width="369" height="508" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe.png 369w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe-218x300.png 218w" sizes="(max-width: 369px) 100vw, 369px"></p>
<h3>Nuitka</h3>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/nuitka.png" alt="" width="120" height="24"></p>
<p><a href="https://nuitka.net/">Nuitka</a>&nbsp;is perhaps the most underutilized, and yet more advanced method of compiling Python code to an executable. It translates Python code into a C program that then is linked against libpython to execute code the same as CPython. Nuitka can use a variety of C compilers including gcc, clang, MinGW64, Visual Studio 2019+, and clang-cl to convert your Python code to C.</p>
<p>Let’s create a “Hello, world!” Python program on Linux and compile it using Nuitka:</p>
<pre><code>$ cat hello.py
print('Hello, world!')

$ nuitka3 hello.py
...

$ ./hello.bin
Hello, world!

$ file hello.bin 
hello.bin: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=eb6a504e8922f8983b23ce6e82c45a907c6ebadf, for GNU/Linux 3.2.0, stripped

$ du -sh hello.bin
432K    hello.bin
</code></pre>
<p>Nuitka produced a portable binary very simply, and at 432 KB is a fraction of the size of what PyInstaller or py2exe can produce! How is Nuitka able to do this? Let’s take a look at the build folder:</p>
<pre><code>$ cloc hello.build/
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
C                               11           2263            709           8109
C/C++ Header                     1              1              0              7
-------------------------------------------------------------------------------
SUM:                            12           2264            709           8116
-------------------------------------------------------------------------------
</code></pre>
<p>Nuitka produced over 8,000 lines of C code from our 1 line Python program. The way Nuitka works is it actually translates the Python modules into C code and then uses libpython and static C files of its own to execute in the same way as CPython does.</p>
<p>This is very impressive, and it seems highly likely the Nuitka “Python compiler” will see further adoption as time goes on. As we’ll see later, Nuitka might have a further, built-in advantage in protection against Reverse Engineering (RE). There already exist several tools to easily analyze binaries produced by PyInstaller and py2exe to recover Python source code. However, by Nuitka translating the Python code to C it is much more difficult to reverse engineer.</p>

<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools.png" alt="" width="557" height="383" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools.png 557w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools-300x206.png 300w" sizes="(max-width: 557px) 100vw, 557px"></p>
<p>Python malware can take advantage of a massive ecosystem of open-source Python packages and repositories. Almost anything you could think of, someone has already built it using Python. This is a huge advantage to malware authors as simplistic capabilities can be cherry-picked from the open web and more complex capabilities likely don’t need to be written from scratch.</p>
<p>Let’s take a look at three simple, yet powerful tool examples:</p>
<ol>
<li>Code Obfuscation</li>
<li>Taking Screenshots</li>
<li>Performing Web Requests</li>
</ol>
<h3>Tool Example 1 – Obfuscation</h3>
<p>Malware authors using Python have many libraries they could use to obfuscate their Python code to make code readability much more difficult, such as:&nbsp;<a href="https://github.com/liftoff/pyminifier">pyminifier</a>&nbsp;and&nbsp;<a href="https://github.com/dashingsoft/pyarmor">pyarmor</a>.</p>
<p>Here’s a small example of how&nbsp;<code>pyarmor</code>&nbsp;can obfuscate Python code:</p>
<pre><code>$ cat hello.py 
print('Hello, world!')

$ pyarmor obfuscate hello.py
...

$ cat dist/hello.py
from pytransform import pyarmor_runtime
pyarmor_runtime()
__pyarmor__(__name__, __file__, b'\x50\x59\x41\x52\x4d\x4f\x52\x00\x00\x03\x08\x00\x55\x0d\x0d\x0a\x04\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x40\x00\x00\x00\xd5\x00\x00\x00\x00\x00\x00\x18\xf4\x63\x79\xf6\xaa\xd7\xbd\xc8\x85\x25\x4e\x4f\xa6\x80\x72\x9f\x00\x00\x00\x00\x00\x00\x00\x00\xec\x50\x8c\x64\x26\x42\xd6\x01\x10\x54\xca\x9c\xb6\x30\x82\x05\xb8\x63\x3f\xb0\x96\xb1\x97\x0b\xc1\x49\xc9\x47\x86\x55\x61\x93\x75\xa2\xc2\x8c\xb7\x13\x87\xff\x31\x46\xa5\x29\x41\x9d\xdf\x32\xed\x7a\xb9\xa0\xe1\x9a\x50\x4a\x65\x25\xdb\xbe\x1b\xb6\xcd\xd4\xe7\xc2\x97\x35\xd3\x3e\xd3\xd0\x74\xb8\xd5\xab\x48\xd3\x05\x29\x5e\x31\xcf\x3f\xd3\x51\x78\x13\xbc\xb3\x3e\x63\x62\xca\x05\xfb\xac\xed\xfa\xc1\xe3\xb8\xa2\xaa\xfb\xaa\xbb\xb5\x92\x19\x73\xf0\x78\xe4\x9f\xb0\x1c\x7a\x1c\x0c\x6a\xa7\x8b\x19\x38\x37\x7f\x16\xe8\x61\x41\x68\xef\x6a\x96\x3f\x68\x2b\xb7\xec\x60\x39\x51\xa3\xfc\xbd\x65\xdb\xb8\xff\x39\xfe\xc0\x3d\x16\x51\x7f\xc9\x7f\x8b\xbd\x88\x80\x92\xfe\xe1\x23\x61\xd0\xf1\xd3\xf8\xfa\xce\x86\x92\x6d\x4d\xd7\x69\x50\x8b\xf1\x09\x31\xcc\x19\x15\xef\x37\x12\xd4\xbd\x3d\x0d\x6e\xbb\x28\x3e\xac\xbb\xc4\xdb\x98\xb5\x85\xa6\x19\x11\x74\xe9\xab\xdf', 1)

$ python dist/hello.py
Hello, world!
</code></pre>

<h3>Tool Example 2 – Screenshots</h3>
<p>Information stealing malware will often come with the capability to take screenshots of the users desktop in order to steal sensitive …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cyborgsecurity.com/python-malware-on-the-rise/">https://www.cyborgsecurity.com/python-malware-on-the-rise/</a></em></p>]]>
            </description>
            <link>https://www.cyborgsecurity.com/python-malware-on-the-rise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824689</guid>
            <pubDate>Mon, 13 Jul 2020 19:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Igalia's open prioritization experiment for contributing to browsers]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23824505">thread link</a>) | @staktrace
<br/>
July 13, 2020 | http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html | <a href="https://web.archive.org/web/*/http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
  <article>
  
  <p>Jul 13, 2020</p>
  <p>As many web platform developer and Firefox users, I believe <a href="https://www.mozilla.org/en-US/mission/">Mozilla’s mission</a> is instrumental for a better Internet. In a recent <a href="https://www.igalia.com/chats/ecosystem-health">Igalia’s chat about the Web Ecosystem Health</a>, participants made the usual observation regarding this important role played by Mozilla on the one hand and the limited development resources and small Firefox’s usage share on the other hand. In this blog post, I’d like to explain an experimental idea we are launching at Igalia to try and make browser development better match the interest of the web developer and user community.</p>

<p><a href="https://www.igalia.com/open-prioritization/">
    <img src="http://frederic-wang.fr/images/open-prioritization.png" width="750" height="255" alt="Open Prioritization by Igalia. An experiment in crowd-funding prioritization.">
  </a>
</p>

<h2 id="igalias-contribution-to-browser-repositories">Igalia’s contribution to browser repositories</h2>

<p>As mentioned in the past in this blog, Igalia has contributed to different part of Firefox such as multimedia (e.g. &lt;video&gt; support), layout (e.g. Stylo, WebRender, CSS, MathML), scripts (e.g. BigInt, WebAssembly) or accessibility (e.g. ARIA). But is it enough?</p>

<p>Although commit count is an imperfect metric it is also one of the easiest to obtain. Let’s take a look at how Igalia’s commits repositories of the Chromium (chromium, v8), Mozilla (mozilla-central, servo, servo-web-render) and WebKit projects were distributed last year:</p>

<figure>
  <img width="374" height="305" src="http://frederic-wang.fr/images/distribution-of-igalia-commits-2019.png" alt="pie chart">
  <figcaption><small>Diagram showing, the distribution of Igalia's contributions to browser repositories in 2019 (~5200 commits). Chromium (~73%), Mozilla (~4%) and WebKit (~23%).</small>
  </figcaption>
</figure>

<p>As you can see, in absolute value Igalia contributed roughly 3/4 to Chromium, 1/4 to WebKit, with a small remaining amount to Mozilla. This is not surprising since Igalia is a consulting company and our work depends on the importance of browsers in the market where Chromium dominates and WebKit is also quite good for iOS devices and embedded systems.</p>

<p>This suggests a different way to measure our contribution by considering, for each project, the percentage relative to the total amount of commits:</p>

<figure>
  <img width="436" height="339" src="http://frederic-wang.fr/images/igalia-commit-percentage-per-project-2019.png" alt="Bar graph">
  <figcaption><small>Diagram showing, for each project, the percentage of Igalia's commits in 2019 relative to the total amount of the project. From left to right:
  Chromium (~3.96%), Mozilla (~0.43%) and WebKit (~10.92%).</small>
  </figcaption>
</figure>

<p>In the WebKit project, where ~80% of the contributions were made by Apple, Igalia was second with ~10% of the total. In the Chromium project, the huge Google team made more than 90% of the contributions and many more companies are involved, but Igalia was second with about 4% of the total. In the Mozilla project, Mozilla is also doing ~90% of the contributions but Igalia only had ~0.5% of the total. Interestingly, the second contributing organization was… the community of unindentified gmail.com addresses! Of course, this shows the importance of volunteers in the Mozilla project where a great effort is done to encourage participation.</p>

<h2 id="open-prioritization">Open Prioritization</h2>

<p>From the commit count, it’s clear Igalia is not contributing as much to the Mozilla project as to Chromium or WebKit projects. But this is expected and is just reflecting the priority set by large companies. The solid base of Firefox users as well as the large amount of volunteer contributors show that the Mozilla project is nevertheless still attractive for many people. Could we turn this into browser development that is not funded by advertising or selling devices?</p>

<p>Another related question is whether the internet can really be shaped by the global community as defended by the Mozilla’s mission? Is the web doomed to be controlled by big corporations doing technology’s “evangelism” or lobbying at standardization committees? Are there prioritization issues that can be addressed by moving to a more collective decision process?</p>

<p>At <a href="https://www.igalia.com/about/">Igalia</a>, we internally try and follow <a href="https://wingolog.org/tags/cooperatives">a more democratic organization</a> and, at our level, intend to make the world a better place. Today, we are launching a new <a href="https://www.igalia.com/open-prioritization/">Open Prioritization</a> experiment to verify whether crowdfunding could be a way to influence how browser development is prioritized. Below is a short (5 min) <a href="https://www.youtube.com/embed/xCRxNVbUqhk">introductory video</a>:</p>

<iframe width="850" height="508" src="https://www.youtube.com/embed/xCRxNVbUqhk" frameborder="0" allowfullscreen=""></iframe>

<p>I strongly recommend you to take a look at the proposed projects and <a href="https://www.igalia.com/open-prioritization/#faq">read the FAQ</a> to understand how this is going to work. But remember <em>this is an experiment</em> so we are starting with a few ideas that we selected and tasks that are relatively small. We know there are tons of user reports in bug trackers and suggestions of standards, but we are not going to solve everything in one day !</p>

<p>If the process is successful, we can consider generalizing this approach, but we need to test it first, check what works and what doesn’t, consider whether it is worth pursuing, analyze how it can be improved, etc</p>

<h2 id="two-crowdfunding-tasks-for-firefox">Two Crowdfunding Tasks for Firefox</h2>

<figure>
  <img src="https://upload.wikimedia.org/wikipedia/commons/0/06/CIELAB_color_space_top_view.png" alt="CIELAB color space*">
  <figcaption><small>Representation of the CIELAB color space (top view)
  <a href="https://commons.wikimedia.org/wiki/File:CIELAB_color_space_top_view.png">by Holger Everding, under CC-SA 4.0</a>.</small>
  </figcaption>
</figure>

<p>As explained in the previous paragraph, we are starting with small tasks. For Firefox, we selected the following ones:</p>

<ul>
  <li>
    <p>CSS <code>lab()</code> colors. This is about giving web developers a way to express colors using the <a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB color space</a> which approximates better the human perception. My colleague Brian Kardell wrote a <a href="https://bkardell.com/blog/Unlocking-Colors.html">blog with more details</a>. Some investigations have been made by <a href="https://bugs.webkit.org/show_bug.cgi?id=205675">Apple</a> and <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1026287">Google</a>. Let’s see what we can do for Firefox !</p>
  </li>
  <li>
    <p>SVG path <code>d</code> attribute. This is about expressing <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1571119">SVG path using the corresponding CSS syntax</a> for example <code>&lt;path style="d: path('M0,0 L10,10,...')"&gt;</code>. This will likely involve a refactoring to use the same parser for both SVG and CSS paths. It’s a small feature but part of a more general <a href="https://www.youtube.com/watch?v=1d--S_wgAJA">convergence effort between SVG and CSS</a> that Igalia has been involved in.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Is this crowd-funded experiment going to work? Can this approach solve the prioritization problems or at least help a bit? How can we improve that idea in the future?…</p>

<p>There are many open questions but we will only be able to answer them if we have enough people participating. I’ll personally pledge for the two Firefox projects and I invite you to at least take a look and decide whether there is something there that is interesting for you. Let’s try and see!</p>

</article>


</div></div>]]>
            </description>
            <link>http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824505</guid>
            <pubDate>Mon, 13 Jul 2020 19:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Every Developer Should Start Blogging]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824478">thread link</a>) | @Sandeepg33k
<br/>
July 13, 2020 | https://lo-victoria.com/why-every-developer-should-start-blogging-ckcga7ulq007tkes13frydqnz | <a href="https://web.archive.org/web/*/https://lo-victoria.com/why-every-developer-should-start-blogging-ckcga7ulq007tkes13frydqnz">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Hello everyone! Hashnode has proudly launched the #2Articles1Week challenge! How exciting! To commemorate the start of this challenge, I'm dedicating this post to Hashnode and the fellow writers on this platform who are also partaking in this challenge! </p>
<p>Note: All articles I'm writing during this 4-week challenge will be under the <a target="_blank" rel="noopener noreferrer" href="https://hashnode.com/series/2articles1week-challenge-ckcdmmffj001efzs1fodo0rbi">#2Articles1Week Challenge Series</a>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594482149929/Eh8cIHqKA.png?auto=format&amp;q=60" alt="2a1w.png"></p>
<p>If you haven't already, I strongly encourage you to please participate in the challenge! Learn more about it <a target="_blank" rel="noopener noreferrer" href="https://hashnode.com/2Articles1week">here</a>.</p>
<h2 id="why-i-decided-to-start-blogging">Why I decided to start blogging</h2>
<p>For this special post, I just want to reflect on why I started blogging and why every developer should start blogging. Every writer/ blogger has their own reasons to start writing but here's mine.</p>
<h3 id="-motivation-"><strong>Motivation</strong></h3>
<p>At some point in time, I reached that developer's plateau where I'm uncertain on which new technology/skill I wanted to acquire and what direction I'm heading. So I tried to get started with React but without a structured syllabus and deadlines, it was difficult to stay focused and committed to learning it every day. I felt like I needed an outlet for <strong>accountability</strong> as well as a platform to <strong>reinforce my learning</strong>.</p>
<p>In terms of non-programming reasons, I like reading books and I especially like to <strong>pen down my thoughts and reflections</strong> on the insights I have gained from reading. My OneNote got so full of my "reading notes"...</p>
<p>It was then I decided to blog. I have always written journals in my childhood, so I thought a blog is basically like an online journal. My reason was that simple.</p>
<blockquote>
<p>Then why not just record your learning in your physical book journal?</p>
</blockquote>
<p>I chose blogging because unlike a book journal, I wanted something <strong>more accessible</strong> that I can read from anywhere and <strong>would never disappear</strong>. I have written over 10 books of journals in my childhood and unfortunately lost all of them from moving a lot. I don't want the same outcome for my learning journal.</p>
<p>Plus, learning from others and gaining valuable feedback is the best way to learn something quickly. So having a blog achieves the following for me:</p>
<ul>
<li><strong>Accountability:</strong> It's like keeping a physical journal. Having a blog makes me want to constantly write on it. So it makes me learn without losing focus.</li>
<li><strong>Monitor/Reinforce Learning:</strong> Writing down what I've learnt is how I like to check my learning progress and reinforce core concepts.</li>
<li><strong>Accessibility:</strong> Always there and never disappear.</li>
<li><strong>Feedback from others:</strong> Learning from the community, sharing knowledge and gain insights.</li>
</ul>
<h3 id="-first-steps-i-did-"><strong>First Steps I did</strong></h3>
<p>To commit to logging what I've learned every day, I took the #100DaysofCode challenge and told people around me that I am doing the challenge. I find that it is easier to stay on track after you've publicly announced your plan of action to your peers, family or friends.</p>
<p>So, my blogging journey began. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594231182027/jUKSMZY5J.png?auto=format&amp;q=60" alt="1.png">
<em>Source: My Nintendo Switch (Pokemon Shield)</em></p>
<h2 id="why-you-should-blog-learning-outcomes-gains-">Why you should blog (Learning Outcomes + Gains)</h2>
<h3 id="-1-communication-"><strong>1. Communication</strong></h3>
<p>By communication, I mean the ability to <strong>articulate information in a clear, well-organized and concise manner</strong> (orally and written).</p>
<p>Initially, my blog on Medium was intended for 1 audience: myself. It was easy to write in a way that only I would understand (because I am me haha). But once I started seeing more people reading my articles, I found myself having to express my thoughts more clearly, organize my writing for better flow and explain ideas more simply.</p>
<p>If you think you are a terrible writer right now, all the more reason to start blogging. That means you will learn a lot from writing. Don't be afraid of showing your work to others because the community is full of wonderful people who are willing to proofread your articles and help you. In time, you will notice improvements in your written communication skills. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594233127088/3wqKKrg54.jpeg?auto=format&amp;q=60" alt="1.jpg">
<em>Source: <a href="https://pbs.twimg.com/media/CnVdEPSVYAAocDI.jpg" target="_blank">pbs.twimg.com/media/CnVdEPSVYAAocDI.jpg</a></em></p>
<blockquote>
<p>"All good writing begins with terrible first efforts. You need to start somewhere." - Anne Lammot</p>
</blockquote>
<h3 id="-2-time-management-"><strong>2. Time Management</strong></h3>
<p>Time management is about <strong>effectively optimizing time to accomplish productive tasks</strong>. When I started blogging, I realized that I have to allocate some time during the day to do it, which means I spend less time on procrastinating and other distractions. </p>
<p>To balance my work and my blogging, I had to <strong>learn how to manage my time</strong> quickly. I found what works for me and what doesn't. For example, I tried to be a morning person and blog early in the morning before work - but I ended up snoozing my alarm every time... Now I learned that blogging midday to evenings works for me best. I can stay focused during those times better. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594249248243/_kuCenfmt.gif?auto=format,compress&amp;gif-q=60" alt="1.gif"></p>
<p>Each person has his/her own time management strategies. For me, it is <strong>planning my day</strong> ahead and <strong>prioritizing</strong> which tasks to accomplish first. Focusing on what I want to achieve at the end of the day is how I often organize my short-term priorities.</p>
<blockquote>
<p>"Focus is not saying yes to all important things, rather it is saying no to less important things." - Steve Jobs</p>
</blockquote>
<h3 id="-3-get-rid-of-perfectionism-"><strong>3. Get Rid of Perfectionism</strong></h3>
<p>I was quite a perfectionist before I started blogging. I held myself to very high standards which in turn, <strong>made me fear to start writing</strong> because I'll be unable to publish an article. It was an arduous journey for me to finally accept that <strong>nothing is perfect</strong> and that I would rather practice my writing on 10 different articles rather than working towards 1 "perfect" article for who knows how long.</p>
<p>Blogging helps me to shift away from my perfectionist tendencies and put more focus into continuous self-improvement by writing more and practising my skills as I go. <strong>Progress over perfection</strong>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594249748562/_x-tMYUtz.jpeg?auto=format&amp;q=60" alt="2.jpg">
<em>Source: <a href="https://i0.wp.com/dariusforoux.com/wp-content/uploads/2016/09/IMG_0058.jpg?fit=2048%2C1536&amp;ssl=1" target="_blank">i0.wp.com/dariusforoux.com/wp-content/uploa..</a></em></p>
<blockquote>
<p>"Perfectionism doesn't make you feel perfect; it makes you feel inadequate." - Maria Shriver</p>
</blockquote>
<h3 id="-4-learning-from-others-"><strong>4. Learning from Others</strong></h3>
<p>The most valuable lesson from blogging is learning from others. I like to receive <strong>constructive feedback</strong> from my readers because it must have some important insight/detail that I didn't notice before. It also <strong>validates my understanding</strong> on a certain topic. Making a mental note of the feedback helps me grow as a developer and writer. Of course, if the feedback is very subjective (i.e. personal preferences in style, etc.), I allow myself to ignore it since I have my own writing style that I am comfortable with.</p>
<p>Another way I learn from others by blogging is <strong>reading other's blogs</strong> in the community. Everyone has their own experiences and knowledge to share. By reading blogs with a newer or deeper knowledge on certain topics than my own, I get to learn, reflect and get inspired from their insights!</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594250331664/a2R5UKXH2.png?auto=format&amp;q=60" alt="3.png"></p>
<blockquote>
<p>"It takes a wise man to learn from his mistakes but an even wiser man to learn from others." - Chinese Proverb</p>
</blockquote>
<h3 id="-5-personal-brand-"><strong>5. Personal Brand</strong></h3>
<p>Each article you publish will reflect you as an extension of your skills, knowledge, interests, thoughts and values. Hence, by writing, you are essentially creating and building your personal brand. </p>
<p>As a developer, having a personal brand can help you:</p>
<ul>
<li>Build reputation and credibility</li>
<li>Share your knowledge and projects for feedback</li>
<li>Increase visibility in the job market</li>
<li>Make new connections with people in the same industry</li>
</ul>
<blockquote>
<p>"We are CEOs of our own companies: Me Inc. To be in business today, our most important job is to be head marketer for the brand called You." - Tom Peters, Writer</p>
</blockquote>
<h2 id="how-to-start">How to Start</h2>
<h3 id="find-your-reason">Find your reason</h3>
<p>Whether it is recording your journey of learning/building something or sharing your passion on a certain subject, find a <strong>strong intrinsic reason</strong> to start or else your resolve will not last long.</p>
<h3 id="be-your-own-audience">Be Your Own Audience</h3>
<p>Ask yourself: <strong>Would you want to read this?</strong></p>
<p>If yes, then you have your first audience! Your job is to write for yourself, and eventually, as your writing gets better, you'll gain more readers. Most likely, people with similar interests or in the same field as you would be your readers too.</p>
<h3 id="consistency">CONSISTENCY</h3>
<p>This one is critical. You want to <strong>keep your blog as up-to-date</strong> as possible. You don't have to blog every day but once a week or so maintains a healthy habit to write. </p>
<p>It is always harder to start than to continue something. Once you stopped writing for a long time, it will be even more difficult to get back to writing. </p>
<h3 id="have-fun-">Have Fun!</h3>
<p>Don't feel pressured to come up with the most unique topics or the most engaging piece every time you want to write about a topic. Just <strong>enjoy the process of writing</strong> itself! Have fun and <strong>stay true to writing what you like</strong>. Remember, you are your own audience. If you like it, there will be people who appreciate your work too!</p>
<blockquote>
<p>"You don't have to be great to start, but you have to start to be great." - Zig Zaglar</p>
</blockquote>
<h2 id="thanks-for-reading-">Thanks for reading!</h2>
<p>I appreciate you for taking the time to read this far. Please like and share this article to encourage more aspiring writers to start! If you are a new blogger on Hashnode and planning to do the #2Articles1Week challenge, please leave your blog url in the comments below. I would love to check out your articles! </p>
<p>Alternatively, you can connect with me on <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/lo_victoria2666">Twitter</a> and share your articles with me there! I hope you'll join and enjoy the #2Articles1Week challenge! Cheers!</p>
</div></div>]]>
            </description>
            <link>https://lo-victoria.com/why-every-developer-should-start-blogging-ckcga7ulq007tkes13frydqnz</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824478</guid>
            <pubDate>Mon, 13 Jul 2020 19:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Subscribing to RethinkDB Record Changes in Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824404">thread link</a>) | @aspleenic
<br/>
July 13, 2020 | https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/ | <a href="https://web.archive.org/web/*/https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5926">
	
	
	<div>
		
<p><a href="https://rethinkdb.com/">RethinkDB</a>&nbsp;is a document storage database with excellent clustering capabilities. However it can also&nbsp;<strong>auto notify when records are updated in real-time</strong>, and this article is going to explore how to do that using&nbsp;<a href="https://golang.org/">Go</a>.</p>



<div><figure><img src="https://jah.io/content/images/2020/05/Untitled.svg" alt="" width="718" height="179"><figcaption><a href="https://rethinkdb.com/">RethinkDB</a>&nbsp;is a document storage database with real-time record pub/sub capabilities.</figcaption></figure></div>



<h2>What is RethinkDB?</h2>



<p>RethinkDB is a document storage database with a lot of really nice modern features, like multiple nodes joining a cluster and automatically rebalancing and re-sharding data among themselves when that data changes. In this article though, we’ll be exploring the&nbsp;<code>changes</code>&nbsp;feature, so we can get automatic updates when something in the data for any given row, or even a whole table, gets changed.</p>



<figure><img src="https://jah.io/content/images/2020/05/Screen-Shot-2020-05-22-at-3.39.34-PM.png" alt=""><figcaption>The RethinkDB Data Explorer/Dashboard</figcaption></figure>



<p>A few details about RethinkDB at a glance:</p>



<ul><li>Written in C++</li><li>Default ports:<ul><li>28015 for client drivers (command execution)</li><li>29015 for inter-cluster communication</li><li>8080 for admin dashboard</li></ul></li><li>Config file location<ul><li>MacOS:&nbsp;<code>$BREW_HOME/etc/rethinkdb.conf</code></li><li>Linux (Ubuntu, from RethinkDB’s apt):&nbsp;<code>/etc/rethinkdb/instances.d/&lt;HOSTNAME&gt;.conf</code></li><li>Windows: I have no idea, good luck with that 🙂</li></ul></li></ul>



<h3>Didn’t RethinkDB die years ago?</h3>



<p>You might have heard back in 2016 that the RethinkDB project shut down. That’s true: it did. The company behind it essentially ran out of money. Then something miraculous happened: the open source community picked it up and carried it forward, eventually&nbsp;<a href="https://rethinkdb.com/blog/rethinkdb-joins-linux-foundation">joining the Linux Foundation in 2017</a>&nbsp;and as of this writing (May 2020) has multiple well-known sponsors. So the idea that RethinkDB is a “dead” project is just “dead” wrong.</p>



<figure><img src="https://jah.io/content/images/2020/05/Screen-Shot-2020-05-22-at-4.28.36-PM.png" alt=""><figcaption><a href="https://rethinkdb.com/blog/rethinkdb-joins-linux-foundation">RethinkDB Joined the Linux Foundation in 2017</a>&nbsp;and presently has users including NASA along with sponsors like Digital Ocean, Atlassian and Netlify.</figcaption></figure>



<h2>Install RethinkDB</h2>


<pre title="">$ brew install rethinkdb
</pre>


<p>On other platforms, make use of the&nbsp;<a href="https://rethinkdb.com/docs/install/">installation directions at rethinkdb.com</a>.</p>



<h3>Configure RethinkDB</h3>



<p>Now let’s edit the default configuration. On MacOS, you’ll find this under your&nbsp;<code>brew</code>&nbsp;directory,&nbsp;<code>etc/rethinkdb.conf</code>. In this code example below, I’ve done a&nbsp;<code>grep</code>&nbsp;on my own configuration for any line that’s&nbsp;<em>not</em>&nbsp;commented; you can see the values for the corresponding configuration directives here.</p>


<pre title="">$ grep "^[^#]" /Users/jah/.brew/etc/rethinkdb.conf
directory=/Users/jah/.brew/var/rethinkdb
log-file=/Users/jah/.rethinkdb.log
bind=all
canonical-address=nova.local
server-name=nova.local
</pre>


<p>You can set the directory and log file to wherever you want as long as you have write access to that location on disk.&nbsp;<code>bind=all</code>&nbsp;is highly recommended so you can access RethinkDB at either&nbsp;<code>localhost</code>&nbsp;or&nbsp;<code>127.0.0.1</code>&nbsp;or your network IP address. Finally, my machine is specified in multicast DNS as&nbsp;<code>nova.local</code>, so put your hostname here as well so you can have other clients connect by hostname instead of internal IP address.</p>



<p>Next, on MacOS, use&nbsp;<code>brew services</code>&nbsp;to start and monitor RethinkDB:</p>


<pre title="">$ brew services start rethinkdb
$ brew services list
rethinkdb         started jah  /Users/jah/Library/LaunchAgents/homebrew.mxcl.rethinkdb.plist
</pre>


<p>If you installed RethinkDB on Ubuntu using their apt repository, it should already be running and monitored. Try running&nbsp;<code>systemctl rethinkdb</code>&nbsp;to view its status.</p>



<p>If you’re on another platform, try the&nbsp;<a href="https://rethinkdb.com/docs/install/">installation instructions at the RethinkDB website.</a></p>



<h2 id="let-s-write-some-code">Let’s Write Some Code</h2>



<p>To use RethinkDB with Go, we’re going to use the&nbsp;<a href="https://gopkg.in/rethinkdb/rethinkdb-go.v6">rethinkdb-go</a>&nbsp;database driver (source code available on&nbsp;<a href="https://github.com/rethinkdb/rethinkdb-go/tree/v6.2.1">GitHub</a>). You can see its full API documentation&nbsp;<a href="https://godoc.org/gopkg.in/rethinkdb/rethinkdb-go.v6">here</a>.</p>



<p>Side note: You might want to use&nbsp;<a href="https://code.visualstudio.com/">Visual Studio Code</a>&nbsp;with the&nbsp;<a href="https://github.com/golang/vscode-go">Go extension</a>&nbsp;installed. The extension is excellent, and provides “intellisense” while writing Go code so you can see what types a function returns, how many arguments it returns and what they are, etc. Highly recommended.</p>



<figure><img src="https://jah.io/content/images/2020/05/Screen-Shot-2020-05-22-at-4.37.47-PM.png" alt=""></figure>



<h3 id="create-the-tv_shows-table">Create the tv_shows&nbsp;Table</h3>



<p>Let’s get started. Create a file:&nbsp;<code>go.mod</code>. We’re going to populate it with the following to get started:</p>


<pre title="">module github.com/jahio/rethinkdb-go
</pre>


<p>Yep, just one line. This is our module definition that tells Go where our code will eventually live and what it’ll be called. (Feel free to rename it to whatever GitHub repository you’ll store yours in.)</p>



<p>Now, add another file:&nbsp;<code>main.go</code>:</p>


<pre title="">package main

import (
	"log"

	r "gopkg.in/rethinkdb/rethinkdb-go.v6"
)

func main() {
	log.SetFlags(0)

	rdbOpts := r.ConnectOpts{
		Address: "localhost:28015",
	}

	rconn, err := r.Connect(rdbOpts)
	checkError(err)

	err = r.DB("test").TableCreate("tv_shows").Exec(rconn)
	checkError(err)
}

func checkError(err error) {
	if err != nil {
		log.Println(err)
		return
	}
}
</pre>


<p>In this file, we’re importing&nbsp;<a href="http://gopkg.in/rethinkdb/rethinkdb-go.v6">gopkg.in/rethinkdb/rethinkdb-go.v6</a>&nbsp;as our RethinkDB database driver and renaming it to&nbsp;<code>r</code>&nbsp;in our code for convenience sake, which you can see kick in around line 12.</p>



<p>The first thing we do is set our connection options for RethinkDB. In this case, we create a new variable,&nbsp;<code>rdbOpts</code>, based on the&nbsp;<code>rethinkdb</code>&nbsp;package’s&nbsp;<code>ConnectOpts</code>&nbsp;struct with an&nbsp;<code>Address</code>&nbsp;property set to&nbsp;<code>localhost:28015</code>. This the default location and port; if you changed either one of those (maybe you’re running RethinkDB on another machine), update this accordingly.</p>



<p>Next, we connect to RethinkDB with that options object and check for an error if the connection failed. After that, we run a query:</p>


<pre title="">err = r.DB("test").TableCreate("tv_shows").Exec(rconn)
</pre>


<p>Here we’re method chaining a pseudo&nbsp;<a href="https://rethinkdb.com/api/">RQL</a> query to RethinkDB. We start with&nbsp;<code>r</code>, the RethinkDB driver module, then tell it what database to use with&nbsp;<code>DB("test")</code>.</p>



<p>Note that RethinkDB sets up a table for every new installation called “test” which you can use to test out queries and just generally experiment with.&nbsp;<strong>Never store permanent data in this table.</strong></p>



<p>Next, we call&nbsp;<code>TableCreate("tv_shows")</code>.&nbsp;<code>TableCreate</code>&nbsp;is the Golang equivalent of&nbsp;<code>tableCreate</code>&nbsp;in RQL and JavaScript, or&nbsp;<code>table_create</code>&nbsp;in Ruby. They all do the same thing: create a table with the string passed in. In our case, this is&nbsp;<code>tv_shows</code>. We’ll use some good shows here (shows I happen to like) to demonstrate how this works.</p>



<p>Finally, we call&nbsp;<code>Exec(rconn)</code>&nbsp;here to tell RethinkDB to execute the command&nbsp;<em>over the&nbsp;<code>rconn</code>&nbsp;connection.</em>&nbsp;Passing the connection to the&nbsp;<code>Run()</code>&nbsp;or&nbsp;<code>Exec()</code>&nbsp;functions is a necessary step every time, and may throw you an error if you forget to do it (and trust me, you’ll forget here and there).</p>



<p>Now let’s run the code. In a terminal, cd into the directory you have this code in and run&nbsp;<code>go run main.go</code>. This will compile the program and run it, thus creating your table.</p>



<p>To verify you’ve created the table successfully, check it out in the&nbsp;<a href="http://localhost:8080/">RethinkDB Console</a>:</p>



<figure><img src="https://jah.io/content/images/2020/05/Screen-Shot-2020-05-28-at-3.02.54-PM.png" alt=""><figcaption>Access the&nbsp;<a href="http://localhost:8080/">RethinkDB Console</a>&nbsp;at&nbsp;<a href="http://localhost:8080/">http://localhost:8080</a>&nbsp;and look for the&nbsp;<code>tv_shows</code>&nbsp;table.</figcaption></figure>



<p><a href="https://github.com/jahio/rethinkdb-subscribe-go/commit/3ed16af9a8b11af0254daea34c187563eec1585b#diff-7ddfb3e035b42cd70649cc33393fe32c">View the code at this point in the tutorial on GitHub.</a></p>



<h3 id="add-some-tv_shows">Add some tv_shows</h3>



<p>Now that the table has been created, let’s add a few shows to it. First, download&nbsp;<a href="https://github.com/jahio/rethinkdb-subscribe-go/blob/master/shows.json">this JSON file</a>&nbsp;and save it in the same directory as&nbsp;<code>main.go</code>, calling it&nbsp;<code>shows.json</code>. Next, modify the code above to look like this:</p>


<pre title="">package main

import (
	"encoding/json"
	"fmt"
	"io/ioutil"
	"log"

	r "gopkg.in/rethinkdb/rethinkdb-go.v6"
)

type show struct {
	Name     string    `json:"name" gorethink:"name"`
	Genre    string    `json:"genre" gorethink:"genre"`
	Website  string    `json:"website" gorethink:"website"`
	Episodes []episode `json:"episodes" gorethink:"episodes"`
}

type episode struct {
	Name    string `json:"name" gorethink:"name"`
	Summary string `json:"summary" gorethink:"summary"`
}

func main() {
	log.SetFlags(0)

	rdbOpts := r.ConnectOpts{
		Address: "localhost:28015",
	}

	rconn, err := r.Connect(rdbOpts)
	checkError(err)

	// Make sure you have shows.json in the same directory as this file.
	file, err := ioutil.ReadFile("shows.json")
	checkError(err)

	var shows []show
	err = json.Unmarshal(file, &amp;shows)
	checkError(err)

	result, err := r.Table("tv_shows").Insert(shows).RunWrite(rconn)
	checkError(err)
	printObj(result)

}

func checkError(err error) {
	if err != nil {
		log.Println(err)
		return
	}
}

func printObj(v interface{}) {
	vBytes, err := json.Marshal(v)
	checkError(err)
	fmt.Println(string(vBytes))
}
</pre>


<p>Now, run the code again in a terminal with&nbsp;<code>go run main.go</code>.</p>



<p>To walk through the changes here, first we’ve created two new types, Show and Episode, both of which are&nbsp;<code>struct</code>s. This is so we can serialize the data in the JSON file and insert it into the database later.</p>



<p>Next, we use&nbsp;<code>ioutil</code>&nbsp;to read the contents of&nbsp;<code>shows.json</code>, then we use the&nbsp;<code>json</code>&nbsp;package to&nbsp;<code>Unmarshal</code>&nbsp;(convert from JSON to objects) that payload of data into instances of those structs we mentioned earlier. Then we insert those structs into RethinkDB by passing that slice directly to the driver:</p>


<pre title="">result, err := r.Table("tv_shows").Insert(shows).RunWrite(rconn)
checkError(err)
printObj(result)
</pre>


<p>Note: Using the&nbsp;<code>rethinkdb-go</code>&nbsp;driver, you use&nbsp;<code>RunWrite</code>&nbsp;to&nbsp;<strong>write&nbsp;</strong>information to the database,&nbsp;<code>Run</code>&nbsp;to&nbsp;<strong>read&nbsp;</strong>information from the database, and&nbsp;<code>Exec</code>&nbsp;to simply run a command that you need no output for, like creating a table or an index.</p>



<p>Then we’re using the new&nbsp;<code>printObj()</code>&nbsp;function to print the result of that insertion operation as JSON out on the console. What’s that look like, you might ask?</p>


<pre title="">{
  "Errors":0, "Inserted":2, "Updated":0, "Unchanged":0, 
  "Replaced":0, "Renamed":0, "Skipped":0, "Deleted":0, 
  "Created":0, "DBsCreated":0, "TablesCreated":0, "Dropped":0, 
  "DBsDropped":0, "TablesDropped":0, 
  "GeneratedKeys":
  [
    "c9461b23-14af-4c47-8aaa-bff62957486f",
    "10e81779-3b5b-413d-9e27-dbc1af9d4089"
  ], 
  "FirstError":"", "ConfigChanges":null, "Changes":null
}
</pre>


<p>From the returned data, we can get a lot of information. First of all, we see that two records were inserted, and nothing was deleted, created, or threw errors (all of which are good signs). Perhaps more importantly, we see the unique IDs (UUIDs) the database assigned to our new objects in the&nbsp;<code>GeneratedKeys</code>&nbsp;field.</p>



<p>You’ll probably note that we didn’t specify these IDs. RethinkDB generates those for us automatically, and in fact may complain when …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/">https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/</a></em></p>]]>
            </description>
            <link>https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824404</guid>
            <pubDate>Mon, 13 Jul 2020 19:10:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of Data Websites and Portfolios in 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824399">thread link</a>) | @fazlerocks
<br/>
July 13, 2020 | https://www.kamwithk.com/the-state-of-data-websites-and-portfolios-in-2020-develop-a-dashboard-in-a-day-dash-vs-streamlit-and-is-javascript-still-king-ckckn2lib00egf6s1eupt0wgv | <a href="https://web.archive.org/web/*/https://www.kamwithk.com/the-state-of-data-websites-and-portfolios-in-2020-develop-a-dashboard-in-a-day-dash-vs-streamlit-and-is-javascript-still-king-ckckn2lib00egf6s1eupt0wgv">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Having a visual product, website or dashboard to show what your arduous efforts on a coding/machine learning project amounted to is something truly spectacular!
Yet, it's often extremely difficult as numerous tools and technologies are usually required.
Don't stress though, we'll discuss and compare <strong>two frameworks</strong> (Dash and Streamlit) which make it <strong>simple and easy to create an impressive portfolio</strong> (without a steep learning curve)!</p>

<p>You just created a machine learning model.
It took a long time, but  <em>it's finally done</em>, and you want to take in your victory for a second.
You deserve a break... but wise old you knows the importance of creating a monument to show off your work.</p>
<p>You take the <em>natural next step</em>, looking up how to build a website.
They begin with Python frameworks like Flask and Django, then proceed to JavaScript and before long you're stuck contemplating which front-end framework to use, and how you'll parse the data between the Python back-end (model) and JavaScript front-end (actual website).
Oh, boy... this is a long and dark rabbit hole to scurry through.
But then out of the blue, you hear that there is an <em>easy solution for simple websites</em>.
You look up this new shinny framework (Streamlit), and it sure is easy 😊 and quick to use.
Before long you've forgotten all your troubles and insecurities!
But then you suddenly realise Streamlit's catch... it only works for <em>simple Jupyter notebook-esk websites</em>.
It's all aboard the web dev train again for you.
Requests and JavaScript, here you come 😰.</p>
<p><strong>It doesn't have to be that way though</strong>... you <em>can find middle ground</em>.
Something simple enough to be understood in a few days, but complex enough... well, for nearly anything 🤓!
Welcome to Dash.
You still need to know a few web fundamentals (HTML and CSS), but at least your development journey has a clearly defined path ahead.
Even if it feels slightly clunky, it does get the job done well enough!</p>
<p><strong>The whole process can be dumbed down to three decisions</strong>:</p>
<ol>
<li>What you want on the page (text, graphs, tables, images, etc)</li>
<li>How to arrange and style the page (using CSS)</li>
<li>How you want the user to interact with the page</li>
</ol>
<p>No JavaScript, HTTP requests or even multiple separate frameworks for the front and back end any more!</p>

<p>To get started, make sure you have Dash installed.
With plain vanilla Python use <code>pip install dash</code> and for Anaconda <code>conda install -c conda-forge dash</code>.
Next, create a new Python file and import the relevant libraries:</p>
<pre><code><span>import</span> dash
<span>import</span> dash_core_components <span>as</span> dcc
<span>import</span> dash_html_components <span>as</span> html
</code></pre>
<p>If you try and run the app so far, you'll notice one thing - nothing happens.
That's because we actually have to create a Dash app object and tell it to start.</p>
<pre><code>app = dash.Dash(__name__, external_stylesheets=[<span>"https://codepen.io/chriddyp/pen/bWLwgP.css"</span>])
app.title = <span>"Allocate++"</span>

<span>if</span> __name__ == <span>"__main__"</span>:
    app.run_server(debug=<span>True</span>)
</code></pre>
<p>We can include a style sheet (CSS using <code>external_stylesheets</code>) and set our website's title (<code>app.title</code>) to make things look better.
Checking that <code>__name__ == "__main__"</code> just ensures that the website only launches when directly started (not when imported in another file).</p>
<p>If we try to run this code, in the terminal we'll get a message like:</p>
<pre><code>Running <span>on</span> http:<span>//</span><span>127.0</span><span>.0</span><span>.1</span>:<span>8050</span>/
Debugger PIN: <span>409</span><span>-929</span><span>-250</span>
 * Serving Flask app <span>"Main"</span> (lazy loading)
 * Environment: production
   WARNING: This <span>is</span> a development server. Do <span>not</span> use it <span>in</span> a production deployment.
   Use a production WSGI server instead.
 * Debug mode: <span>on</span>
Running <span>on</span> http:<span>//</span><span>127.0</span><span>.0</span><span>.1</span>:<span>8050</span>/
Debugger PIN: <span>791</span><span>-028</span><span>-264</span>
</code></pre><p>It indicates that your app has started and can be found using the URL <code>http://127.0.0.1:8050/</code>.
Although it's currently just a blank page (real <em>fancy-schmancy</em>), it does indicate that everything is working fine.</p>
<p>Once you're ready to progress, try adding in a heading:</p>
<pre><code>app.layout = html.H1(children=<span>"Fancy-Schmancy Website"</span>)
</code></pre>
<p>After you save the file, that website should automatically reload.
If it hasn't reloaded, or there are popups on the screen, you probably have an error in the source code.
Just check the actual terminal/debugger for more information.</p>
<p>Now that you're familiar with how to get a basic website, let's move onto transitioning your concept into code.
It starts with what's called a layout, which is composed of components.
Dash provides core (<code>dash_core_components</code>) and HTML (<code>dash_html_components</code>) components.
You always start using the HTML elements, since they provide the basic building blocks for text and grouping components together, before moving onto the core components.
Core components offer more interactivity (graphs, tables, check box's...).
It's now natural to ask, how to style the web page.
In short, you use CSS (cascading style sheets) for this.
Dash themselves provide concrete overviews of <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/dash-core-components">core components</a> and trusty Mozilla have an amazing <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics">HTML</a> and <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/CSS_basics">CSS</a> intro.
Several examples of how to use the elements are <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/layout">here</a>.</p>
<p>The last part of any Dash app is making it responsive.
Getting the buttons you click, text you enter and images you upload... do something!
This is where things would normally get difficult, but here it really <em>isn't too bad</em>.
With Dash, all you've got to define is a function which receives and controls specific element/s properties.
<em>Properties</em> start with the "@" symbol.</p>
<pre><code><span>@app.callback(</span>
    [dash.dependencies.Output(<span>"output element id"</span>, <span>"property to set value of"</span>)],
    [dash.dependencies.Input(<span>"input element id"</span>, <span>"input property"</span>)]
)
<span><span>def</span> <span>update_output</span><span>(value)</span>:</span>
       <span>return</span> value
</code></pre>
<p>We can do this for multiple elements by adding more <code>Input</code> and <code>Output</code> objects to those lists!
One thing to watch out for here though - more <code>Input</code> objects means more inputs to the function are required, and more <code>Output</code> objects mean more values to return (sounds obvious, but it can easily slip your mind). 
Also, note that you <em>shouldn't modify global variables</em> within these functions (this for technical reasons is an antipattern).
Further documentation is provided on these <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/basic-callbacks">callbacks</a>.</p>

<p>There it is, everything you'll need to know to start creating an interactive and impressive web application!
It'll likely still be difficult to create one, but the official documentation and tutorials for <a target="_blank" rel="noopener noreferrer" href="https://docs.streamlit.io/en/stable/getting_started.html">Steamlit</a> and <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/">Dash</a> are amazing.
There are also cool galleries of sample apps using <a target="_blank" rel="noopener noreferrer" href="https://dash-gallery.plotly.host/Portal/">Dash</a> and <a target="_blank" rel="noopener noreferrer" href="https://www.streamlit.io/gallery">Streamlit</a> (so you can learn from others examples).</p>
<p>Of course, there are use cases for JavaScript.
In fact, you can build plugins for Dash with <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/plugins">JavaScript/React</a> and <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/d3-react-components">D3.js</a>.
Hell, if you are already comfortable with web technologies it may even be easier for you to use them.
However, using JavaScript <strong>isn't 100% necessary to build websites</strong> any more (it's more so optional).
It may be useful to know about web technologies, but if your aim isn't to become a full-stack web developer, you don't need to become an expert to put together a flashy portfolio 🥳!</p>
<p>I hope this has helped you out!
Dash helped me hack together <a target="_blank" rel="noopener noreferrer" href="https://github.com/KamWithK/AllocatePlusPlus">my first dashboard</a> in a day.
If you've made a cool website, app or portfolio make sure to comment and tell me about them.
Feel free to check out my other posts - some highlights are <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/the-complete-coding-practitioners-handbook-ck9u1vmgv03kg7bs1e5zwit2z?guid=34cbed9b-13ac-43c7-94a3-dbfe4ac247a9&amp;deviceId=a348da4b-4d6e-44a9-80b2-3456c05bf4d0">practical coding tools</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/zero-to-hero-data-collection-through-web-scraping-ck78o0bmg08ktd9s1bi7znd19">web scrapping</a> and <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/machine-learning-field-guide-ckbbqt0iv025u5ks1a7kgjckx">machine learning</a> (with the <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/machine-learning-energy-demand-prediction-project-part-1-data-cleaning-ckc5nni0j00edkss13rgm75h4">practical project</a>).
You can follow my <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/">newsletter</a> and <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/kamwithk_">Twitter</a> for updates 😉.</p>
<p><em>Photo by Luke Peters on <a target="_blank" rel="noopener noreferrer" href="https://unsplash.com/photos/B6JINerWMz0">Unsplash</a></em></p>
</div></div>]]>
            </description>
            <link>https://www.kamwithk.com/the-state-of-data-websites-and-portfolios-in-2020-develop-a-dashboard-in-a-day-dash-vs-streamlit-and-is-javascript-still-king-ckckn2lib00egf6s1eupt0wgv</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824399</guid>
            <pubDate>Mon, 13 Jul 2020 19:09:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Introduction to JavaScript Map, Filter and Reduce Methods]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824381">thread link</a>) | @fazlerocks
<br/>
July 13, 2020 | https://blog.nemotivity.xyz/a-brief-introduction-to-javascript-map-filter-and-reduce-methods-ckck648il00df57s122yn0eub | <a href="https://web.archive.org/web/*/https://blog.nemotivity.xyz/a-brief-introduction-to-javascript-map-filter-and-reduce-methods-ckck648il00df57s122yn0eub">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1594624222999/ZFFuUffXV.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text">

<p>Arrays are important Data Structures in programming. All the methods which we are going to discuss in this article will iterate over an array and return a new array based on the result function we define. The results we'll get here can also be achieved using loops, but it'll make the code more lengthy.</p>

<p>We use the <code>map()</code> method to create a new array from an existing one by applying a function to each of the elements in the array. </p>
<h3 id="syntax">Syntax</h3>
<pre><code>array.map(<span><span>function</span>(<span>currentValue, index, arr</span>), <span>thisValue</span>)</span>
</code></pre>
<p>In the arguments, we can execute the function by passing only the <code>currentValue</code> also. Let's see an example</p>
<h3 id="example">Example</h3>
<pre><code><span>const</span> array = [<span>3</span>, <span>6</span>, <span>9</span>, <span>12</span>];
<span>const</span> square = array.map((item) =&gt; item * item);
<span>console</span>.log(square);
</code></pre>
<p>In the above example, we created a new array named <code>square</code> by passing only the <code>currentValue</code>. Now, if we wanted to write the same square function with imperative style, the code will look something like this,</p>
<pre><code><span>const</span> numbers = [<span>3</span>, <span>6</span>, <span>9</span>, <span>12</span>];
<span>const</span> square = (numbers) =&gt; {
  <span>let</span> newArray = [];
  <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; numbers.length; i++) {
    newArray.push(numbers[i] * numbers[i]);
  }
  <span>return</span> newArray;
};
<span>console</span>.log(square(numbers)); 
</code></pre>
<p>We can clearly see how much longer is this method. We can shorten the code by using <code>forEach</code> but it'll also be larger than using the <code>map</code> method.</p>
<p>To learn more about the <code>map()</code> method, you can check the article <a target="_blank" rel="noopener noreferrer" href="https://www.geeksforgeeks.org/javascript-array-map-method/">here</a>.</p>

<p>As the name suggests, the <code>filter()</code> method is used to filter items of an array based on a certain condition. </p>
<h3 id="syntax">Syntax</h3>
<pre><code>array.filter(callback(element, index, arr), thisValue)
</code></pre>
<p>The <code>filter()</code> method basically takes each element of the array and applies the specific condition we define. If the element satisfies the condition then the item is pushed to a new array.</p>
<h3 id="example">Example</h3>
<p>We'll try to return an array which filters odd numbers from an given array. In declarative approach we would write something like, </p>
<pre><code><span>const</span> arr = [<span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>];
<span>const</span> odds = arr.filter((i) =&gt; i % <span>2</span> !== <span>0</span>);
<span>console</span>.log(odds); 
</code></pre>
<p>Now, if we try to get the same result using the imperative way, we have to write something like this,</p>
<pre><code><span>const</span> odds = (arr) =&gt; {
  <span>let</span> oddArray = [];
  <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; arr.length; i++) {
    <span>if</span> (arr[i] % <span>2</span> !== <span>0</span>) {
      oddArray.push(arr[i]);
    }
  }
  <span>return</span> oddArray;
};
<span>console</span>.log(odds(arr)); 
</code></pre>
<p>Which shows how much more code we need to achieve the same result.</p>
<p>To know more about the method, you can check this <a target="_blank" rel="noopener noreferrer" href="https://www.geeksforgeeks.org/javascript-array-filter-method/">article</a>.</p>

<p>The <code>reduce</code> method is the least used among the three methods we are discussing here. This method reduces a whole array into a single value and returns it. </p>
<h3 id="syntax">Syntax</h3>
<pre><code>arr.reduce(callback[, initialValue])
</code></pre>
<p>Let's see the reduce function in action</p>
<h3 id="example">Example</h3>
<p>Suppose we want to add the items of an array. We are taking this example because the function will return only a single value. To implement this using  the <code>reduce()</code> method, we can write the code like this,</p>
<pre><code><span>const</span> arr = [<span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>];
<span>const</span> sum = arr.reduce((result, item) =&gt; {
  result = result + item;
  <span>return</span> result;
});
<span>console</span>.log(sum); 
</code></pre>
<p>It's literally two lines of code. Now, the same code using a for loop will look like this,</p>
<pre><code><span>const</span> sum = (arr) =&gt; {
  <span>let</span> result = <span>0</span>;
  <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; arr.length; i++) {
    result = result + arr[i];
  }
  <span>return</span> result;
};
<span>console</span>.log(sum(arr)); 
</code></pre>
<p>To know more about the <code>reduce()</code> method, you can check the article <a target="_blank" rel="noopener noreferrer" href="https://www.geeksforgeeks.org/javascript-array-reduce-method/">here</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I hope this article gave you an idea about the JavaScript <code>map()</code>, <code>filter()</code>, and <code>reduce()</code> method. The links of the articles provided below each of the methods will give you a more in-depth knowledge of each method.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.nemotivity.xyz/a-brief-introduction-to-javascript-map-filter-and-reduce-methods-ckck648il00df57s122yn0eub</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824381</guid>
            <pubDate>Mon, 13 Jul 2020 19:08:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planting a Tree for Every In-App Subscription]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824342">thread link</a>) | @CyberSkys
<br/>
July 13, 2020 | https://snapsearch.online/announcements/commitment-to-the-environment/ | <a href="https://web.archive.org/web/*/https://snapsearch.online/announcements/commitment-to-the-environment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>By building Snap Search, I made a commitment to try my best to provide a safe way for everyone to search the web. However, I’ve also learnt that each of us have more responsibilities in life – one such being a commitment to the environment.</p> <figure><img src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1024x484.jpg" data-src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1024x484.jpg" alt="One Tree Planted Snap Search" data-srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1024x484.jpg 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-300x142.jpg 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-768x363.jpg 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1536x725.jpg 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1160x548.jpg 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_106/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-106x50.jpg 106w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-650x307.jpg 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1000x472.jpg 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-50x24.jpg 50w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1800/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted.jpg 1800w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1024x484.jpg 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-300x142.jpg 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-768x363.jpg 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1536x725.jpg 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1160x548.jpg 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_106/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-106x50.jpg 106w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-650x307.jpg 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1000x472.jpg 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-50x24.jpg 50w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1800/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted.jpg 1800w"></figure><p>I am not going to try to preach about why it’s necessary. Instead I am going to assume that it’s obvious by now and you understand it already. Alone, I probably cannot make enough of a difference – but with your support, we together can make a lot of impact! <strong>YOU</strong> can make a difference.</p><h2>Our Commitment to the Environment:</h2><p>Starting with August, Snap Search is going to plant one tree for every subscription/purchase of Snap Search premium. We plan to do this with the help of <a href="https://onetreeplanted.org/" target="_blank" rel="noreferrer noopener">OneTreePlanted</a>.</p><p>For example:</p><ul><li>Subscriptions/Purchases (including renewals): 100</li><li>Number of trees planted: 100</li></ul><p>Snap Search was not created for profit, and the only reason premium mode even exists is to bare the costs of services and to support further development (read about it <a href="https://snapsearch.online/general/why-should-i-pay-for-premium-mode-of-snap-search/">here</a>). Using the revenue generated for an amazing purpose like this seems like the right thing to do. My sincere hope is that together we plant many many trees each month.</p><p>Thank you for being a user! Also, don’t forget to leave us a nice review/rating on the <a href="https://play.google.com/store/apps/details?id=cybersky.snapsearch">Play Store</a> if you haven’t already 😁</p></div></div></div>]]>
            </description>
            <link>https://snapsearch.online/announcements/commitment-to-the-environment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824342</guid>
            <pubDate>Mon, 13 Jul 2020 19:05:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Managing Burnout in Startups]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824291">thread link</a>) | @calhat
<br/>
July 13, 2020 | https://www.spill.chat/burnout/burnout-symptoms | <a href="https://web.archive.org/web/*/https://www.spill.chat/burnout/burnout-symptoms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><span>2<!-- -->min read</span></p><p>To know how to manage burnout, you must first know how to recognise it.</p><div><div emoji="🤔"><p><span>🤔</span></p><p><span>I want to understand the psychology</span></p></div><div emoji="✏️"><p><span>✏️</span></p><p><span>I want some practical tools to use</span></p></div></div><h2><span id="burnout-definition">Burnout definition</span></h2><p>Burnout is not a standalone mental health diagnosis, though the World Health Organisation does recognise it as a type of occupational hazard in its own right.</p><p>Burnout is also not depression, even if many of its symptoms overlap. Most notably, burnout is not just being a bit tired or even very tired, from normal everyday workplace stress.</p><p>Burnout is a debilitating affliction normally defined as a triad of emotions occurring together: <strong>exhaustion, negativity, and ineffectiveness</strong>.</p><p>Basically, if Tom is burned out, his work will feel to him simultaneously arduous and unimportant. Every working day, he'll feel irritable, tired, cynical, short-tempered, slow, and about as sharp as a broken pencil. He'll look around at people and fail to understand why they look so animated. Everything will seem far, far away. He'll feel sad, indeed crushed, as if something critical and very deep inside him had simply... given up. In so far as he can think at all, he'll think "what's the point" and "I can't do this" and he will feel, because he'll <em>be</em>, broken.</p><p>Burnout is to humans what sand is for gears: if it doesn't exactly bring the whole system to a halt, it will noticeably decrease its performance.</p><div><p><span>💡</span></p><p>Burnout can look and feel a lot like depression, but is purely associated with work and the symptoms don’t go as far.</p></div><p><span>
      <span></span>
  <img alt="Burnout depression tiredness venn diagram" title="Burnout depression tiredness venn diagram" src="https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/f0628/burnout-depression-tiredness-venn-diagram.png" srcset="https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/8c2ab/burnout-depression-tiredness-venn-diagram.png 300w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/3f01f/burnout-depression-tiredness-venn-diagram.png 600w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/f0628/burnout-depression-tiredness-venn-diagram.png 1200w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/57025/burnout-depression-tiredness-venn-diagram.png 1800w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/8252b/burnout-depression-tiredness-venn-diagram.png 2400w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/7d015/burnout-depression-tiredness-venn-diagram.png 4283w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy">
    </span></p><h2><span id="employee-burnout-symptoms">Employee burnout symptoms</span></h2><p>This decreased performance is the second thing that everyone in Tom's team will notice, including his manager. (The first will be his disheveled look of chronic exhaustion.) The third thing they'll notice, consciously or unconsciously, will be his increased and marked negativity.</p><p>In short, while Tom is feeling exhausted, hopeless, and overwhelmed, others will see him as lethargic, cynical, and stupider than before. His team will feel confused, worried, irritated, inconvenienced, and eventually demoralised.</p><p>It’s also worth watching out for the kind of phrases you might hear Tom saying, either in passing or in one-to-ones. These phrases are typical of someone going through burnout.</p><table><thead><tr><th>Burnout Symptom</th><th>💛 Employee feels</th><th>💬 Employee says</th><th>👀 Manager spots...</th></tr></thead><tbody><tr><td>Fatigue</td><td>Exhausted (I'm tired, exhausted, unfocused)</td><td>"I just feel so tired all the time"</td><td>Lethargy (Low energy, slow, quiet, withdrawn)</td></tr><tr><td>Negativity</td><td>Hopeless (I'm bad, the world is bad, my future is bleak)</td><td>"I can't see a way out of this"</td><td>Cynicism (Hopeless, downbeat, critical, quick to see the worst)</td></tr><tr><td>Ineffectiveness</td><td>Powerless (I can't win at this game)</td><td>"I just don't care anymore"</td><td>Slowdown (Less switched on, missing things)</td></tr></tbody></table><h2><span id="burnout-symptoms-test">Burnout symptoms test</span></h2><p>Because burnout isn’t a medical condition, there’s no official ‘yes or no’ diagnosis. However, the Maslach Burnout Index is the most widely used tool for assessing burnout severity. We’ve condensed it down to three questions for a quicker version.</p><hr></article></div>]]>
            </description>
            <link>https://www.spill.chat/burnout/burnout-symptoms</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824291</guid>
            <pubDate>Mon, 13 Jul 2020 18:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will the Horvath Epigenetic Clock Help Us Reverse Aging?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824258">thread link</a>) | @mehdiyac
<br/>
July 13, 2020 | https://www.mehdiyacoubi.com/post/horvath-clock | <a href="https://web.archive.org/web/*/https://www.mehdiyacoubi.com/post/horvath-clock">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.2"><div dir="ltr"><div><p id="viewer-foo"><em>Scientists developed a new way to measure biological age and finally help us find what really rejuvenates us</em></p><div id="viewer-b8qne"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/horvath-clock" data-pin-media="https://static.wixstatic.com/media/a27d24_2b252ab3ddeb4cc99ea61da57c4bc369~mv2.jpeg/v1/fit/w_4000,h_2630,al_c,q_80/file.png" src="https://static.wixstatic.com/media/a27d24_2b252ab3ddeb4cc99ea61da57c4bc369~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-9agtr">Remember your grandma telling you orange juice is healthy and good for you? It will make you strong and help you fight the winter flu!</p><p id="viewer-efm44">Orange juice is a good example of something that many of us believed (or still believe) healthy <a href="https://www.nytimes.com/2018/07/07/opinion/sunday/juice-is-not-healthy-sugar.html" target="_top" rel="noopener"><u>but is not</u></a>.</p><p id="viewer-b8ui9">Today there is an increasing focus on increasing lifespan and healthspan. Health advice is everywhere. They aim at helping us live the healthiest and longest life possible. But how helpful they really are?</p><p id="viewer-ddklf">Some people will tell you a Vegan diet is the best solution for your health. Others will say the exact opposite and promote eating only beef. You may think studies could help figure out who is right and who is wrong. But you would be wrong on that one. Just watch the Joe Rogan Experiment about the <a href="https://www.youtube.com/watch?v=s0zgNY_kqlI" target="_top" rel="noopener"><u>Game Changers</u></a> Documentary.</p><p id="viewer-3gmfs">People, even scientists, are more and more dogmatic about their knowledge. For many of them, there will always be a reason to explain why a study that contradicts their beliefs is wrong: industry-funded, not enough participants, questionable study design, “correlation doesn’t mean causation”, not enough parameters measured… you name it!</p><p id="viewer-f3386">Just like many other aspects of the public debate, science is getting more about identity and less about facts.</p><p id="viewer-c4o50">This is a real problem because people are starting to be lost in the ocean of health-related advice. They came to find ways to be healthier and in better shape, and they leave lost and not knowing what to do.</p><p id="viewer-62pic">This may change soon with a clear measure of <em>how well</em> your body is aging.</p><h2 id="viewer-cn1i"><strong>The longevity approach</strong></h2><p id="viewer-dr26j">Over the last century, we managed to <a href="https://ourworldindata.org/life-expectancy" target="_top" rel="noopener"><u>double</u></a> the lifespan, from 35 years old to more than 70 today. We did incredible progress at making people live longer. But the additional years are usually not healthy years.</p><p id="viewer-d23cc">When you want to do something to promote your health and longevity, in most cases you will start practices that improve a proxy for longevity. For example, you will start exercising because it will make your cardiovascular system in better shape, and this is associated with better longevity. You are not directly targeting your longevity but you are targeting something that is correlated with delayed aging.</p><p id="viewer-7j7hf">Until now, we didn’t have the means to measure directly how something is affecting longevity.</p><p id="viewer-1ljmf">In 2013, Steve Horvath, a professor at UCLA, developed a new kind of clock: an <a href="https://en.wikipedia.org/wiki/Epigenetic_clock" target="_top" rel="noopener"><u>epigenetic clock</u></a>. It took a few years to go from the concept to an actual product that can be used, but it’s finally here.</p><h2 id="viewer-8k5or"><strong>What is an Epigenetic Clock?</strong></h2><p id="viewer-d0ecs">First, we have to understand what the epigenome is. David Sinclair, a Professor in the Department of Genetics at Harvard Medical School, used a great analogy in his book <a href="https://lifespanbook.com/" target="_top" rel="noopener"><u>Lifespan</u></a>: Why We Age and Why We Don’t Have To:</p><blockquote id="viewer-fi7kp"><p><em>“If the genome were a computer, the epigenome would be the software. It instructs the newly divided cells on what type of cells they should be”. He then explains: “Without epigenetic information, cells would quickly lose their identity and new cells would lose their identity, too. If they did, tissues and organs would eventually become less and less functional until they failed”.</em></p></blockquote><p id="viewer-c4ilj">Horvath developed the epigenetic clock by using DNA methylation (a process by which methyl groups are added to the DNA molecule and that can change the activity of a DNA segment without changing the sequence) to accurately predict age.</p><p id="viewer-6ftti">The Horvath clock is really powerful because it gives a complementary measure of age that is, according to this <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5076441/" target="_top" rel="noopener"><u>study</u></a>, “ associated with age-related health outcomes above and beyond chronological age. For example, we and others have shown that individuals whose epigenetic age was greater than their chronological age (i.e., individuals exhibiting epigenetic “age acceleration”) were at an increased risk for death from all causes”.</p><p id="viewer-bbsv8">After all, the chronological age is just a number, it doesn’t take into consideration the molecular mechanisms happening in your body. This is why some people look 20 years younger and some others look 20 years older than their age.</p><p id="viewer-42aet"><em>Let’s dive a little bit in the theory to understand why this clock can predict aging and longevity better the chronological age.</em></p><h2 id="viewer-64nlv"><strong>The Information Theory of Aging</strong></h2><p id="viewer-6icgg">In his book Lifespan, Pr. David Sinclair explains what he calls the “Information Theory of Aging”. He explains that what leads to aging is a loss of information. He uses an analogy with the Information Theory of Communication from Claude Shannon: the compact disc that is our genome gets damaged over time such as cells can’t read the right genes (the epigenome) at the right time.</p><p id="viewer-t5ju">In addition to that, Pr. Sinclair explains that we always keep a backup copy of the original placement of the methyl groups on the epigenome. In an <a href="https://peterattiamd.com/davidsinclair2/" target="_top" rel="noopener"><u>interview</u></a> with Dr. Peter Attia, Sinclair explains:</p><blockquote id="viewer-6v9pm"><p><em>“But what I think exists in cells and we have some evidence is that, like Shannon suggested for the internet or information, is that if you have a backup copy… and now going back to the genome… there seems to be something in cells that tells them these methyl groups, the programs that were laid down when you were a baby are still there and cells can access that somehow to say: ‘All these other things that have happened since you were born or since you were a teenager, that’s just noise… Ignore that.’” -David Sinclair, Ph.D</em></p></blockquote><p id="viewer-blo2">This opens a completely new horizon on the perspectives of delaying the onset of aging.</p><h2 id="viewer-lov2"><strong>What will that change?</strong></h2><p id="viewer-59ppn">This new theory of aging and the Horvath clock is a huge step forward in the field of aging and longevity. The Information Theory of Aging presents aging as a disease in itself, like any other one. If we can manage to limit the loss of information, this disease will be delayed, potentially for years, decades or even more.</p><p id="viewer-6cre4">But how useful is this theory if we don’t have a way to measure the rate of aging? That’s exactly what the Horvath clock enables us to do now and it will be used by both scientists and the general public to get feedback on how an intervention affects the biological age.</p><h2 id="viewer-en8ov"><strong>For scientists</strong></h2><p id="viewer-7pjtr">The identification of compounds and activities that promotes health and longevity was always limited by the lack of non-invasive metrics that can predict the life expectancy of the subjects of the study. With the Horvath clock, scientists now have a way to measure aging and find cures and lifestyle interventions to delay aging.</p><h2 id="viewer-5ns1l"><strong>For you</strong></h2><p id="viewer-b7nsr">Health and longevity depend on so many parameters, so even if science is getting better at understanding the mechanisms promoting longevity, it will never be sure that those findings apply perfectly to <em>you.</em> Because that’s what interests you, right? A given diet may benefit 90 percent of the population, but you might be in those last 10 percent. A HIIT workout may be one of the best tools for longevity but it may leave you feeling awful. You get the point — certain things must be adapted to your body and your lifestyle. Hence, the Horvath clock could be used as an indicator of how you are doing in your quest to delay aging. If you measure it once a year, for example, you can witness if your epigenetic clock is slower than your chronological one. This will tell you that your lifestyle is good regarding longevity.</p><p id="viewer-3tksn">Now let’s get into some longevity-promoting practices you can try for yourself.</p><h2 id="viewer-blg5g"><strong>How to slow down aging</strong></h2><p id="viewer-7se5t">According to the prominent longevity specialists, here are some things you could try to delay the onset of aging:</p><ul><li id="viewer-d1tj4"><p><a href="https://medium.com/lifetizr/from-eating-4-meals-a-day-to-fasting-20h-aef9e9214444" target="_top" rel="noopener"><u>Fasting</u></a>: Through promoting autophagy, fasting has been shown to be good for longevity.</p></li><li id="viewer-aqlpi"><p>Exercise: In particular <a href="https://www.cell.com/cell-metabolism/comments/S1550-4131(17)30099-2" target="_top" rel="noopener"><u>HIIT training</u></a></p></li><li id="viewer-4m6c"><p>Cold: By stimulating hormesis, cold immersion, cold showers and cold stress are <a href="https://www.foundmyfitness.com/reports/cold-stress.pdf" target="_top" rel="noopener"><u>promoting</u></a> longevity.</p></li><li id="viewer-7tudn"><p>Sauna bathing: It has been <a href="https://www.ncbi.nlm.nih.gov/pubmed/25705824" target="_top" rel="noopener"><u>shown</u></a> that people having four 20 minutes sessions of Sauna per week were <a href="https://www.ncbi.nlm.nih.gov/pubmed/25705824" target="_top" rel="noopener"><u>50 percent</u></a> less likely to die from a cardio-vascular related cause</p></li></ul><p id="viewer-99hed">Today more than ever, we have the tools and the information to try things for our health and wellbeing and measure the effect on our mind and body. Adopting a proactive and preventive approach to health and longevity can help you develop essential knowledge about what works for you and what doesn’t. It’s a personal journey, a journey of trials and errors, and a journey of self-quantification, and when taken with an open mind and without dogmatic scientific beliefs can really lead to the best version of your health.</p><p id="viewer-9sn3c"><a href="https://mehdiyacoubi.substack.com/" target="_blank" rel="noopener"><u>If you'd like to receive future articles by email, and weekly updates where I share the most valuable things I've learned in the week, subscribe to my newsletter!</u></a></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.mehdiyacoubi.com/post/horvath-clock</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824258</guid>
            <pubDate>Mon, 13 Jul 2020 18:56:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Environmental Impact Disclosure – Nine9s Uptime Monitoring]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23824226">thread link</a>) | @sonicrocketman
<br/>
July 13, 2020 | https://nine9s.cloud/kb/infrastructure?ref=hn | <a href="https://web.archive.org/web/*/https://nine9s.cloud/kb/infrastructure?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<div>
  <div>
    <div>
      
      <p>Nine9s is hosted by <a href="https://www.linode.com/">Linode</a> and currently runs exclusively in their London, UK Data Center. All checks are made from there. This may change in the future if Nine9s were to implement worldwide checks.</p>
<p>You may notice slower that normal ping times reported by Nine9s. This is because, while Nine9s is developed in California, it's running an ocean away in the good ol' U.n. of K. 🇬🇧 For more information on why Nine9s isn't running in the U.S., see the section below.</p>
<h2>🌲 Nine9s and the Environment</h2>
<p><small>
💡 Nine9s emits <a href="https://nine9s.cloud/static/kb/Nine9s.cloud-Environmental-Survey.pdf">~0.115 mtCO2e per year</a> (the same as <a href="https://www.epa.gov/energy/greenhouse-gas-equivalencies-calculator">driving a typical car for 285 miles</a>).
</small></p>

<p>Since Nine9s runs on virtual servers in a crowded data center, it's hard to know the exact environmental impact of running the service. That said, by <a href="https://www.linode.com/community/questions/17513/whats-my-linodes-carbon-footprint#answer-69637">Linode's most recent estimates</a>, the energy cost of running a 4GB instance, which is what powers Nine9s today, is about 0.064 kWh/day. While this isn't much in the grand scheme of things, that would <a href="https://www.eia.gov/tools/faqs/faq.php?id=74&amp;t=11">burn approximately 21.5lbs of natural gas per year</a> (~1.4 mtCO2e). Thankfully, a few of Linode's Data Center partners have significant commitments to sustainability.</p>
<p><small>
💡 This page will be updated as Nine9s grows. Please check back for the most recent stats on Nine9s' Environmental Impact.
</small></p>

<p>While the Web isn't physical, the servers and infrastructure that power it definitely are. With the effects of Climate Change getting worse every year, Nine9s is committed to doing whatever it can to not worsen the crisis. Nine9s is hosted in London because of the fact that <a href="https://www.equinix.co.uk/data-centers/design/green-data-centers/">Equinix</a>, Linode's European provider, has <a href="https://equinix.app.box.com/embed/s/4fwyabb231nh3wpjsxca05hyyhsyt42h">committed to a 100% clean and renewable energy goal and has so far reached 92%</a>. If Nine9s needs to expand to cover more places in the world, it will expand to Linode's sustainable partners first.</p>
<hr>
<p>This data is entirely extrapolated from the sources linked by this article, but I can't guarantee that they're 100% accurate. There's a lot of layers between burning fuel and running servers on the cloud, but I've done the best I can.</p>
    </div>
  </div>
</div>

      </div></div>]]>
            </description>
            <link>https://nine9s.cloud/kb/infrastructure?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824226</guid>
            <pubDate>Mon, 13 Jul 2020 18:52:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advertising an onion service with Onion-Location]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824214">thread link</a>) | @ramino
<br/>
July 13, 2020 | https://schu.be/til-onion-location.html | <a href="https://web.archive.org/web/*/https://schu.be/til-onion-location.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="site-content"><article><p>Many websites make themselves available through Tor as hidden services to help users preserve their privacy and circumvent blocks and censorship. A sample follows.</p><table><thead><tr><th>Clearnet domain</th><th>Onion domain</th></tr></thead><tbody><tr><td><a href="https://duckduckgo.com/">duckduckgo.com</a></td><td><a href="http://3g2upl4pq6kufc4m.onion/">3g2upl4pq6kufc4m.onion</a></td></tr><tr><td><a href="https://www.torproject.org/">www.torproject.org</a></td><td><a href="http://expyuzz4wqqyqhjn.onion/">expyuzz4wqqyqhjn.onion</a></td></tr><tr><td><a href="https://www.propublica.org/">www.propublica.org</a></td><td><a href="http://propub3r6espa33w.onion/">propub3r6espa33w.onion</a></td></tr><tr><td><a href="https://facebook.com/">facebook.com</a></td><td><a href="http://facebookcorewwwi.onion/">facebookcorewwwi.onion</a></td></tr><tr><td><a href="https://keybase.io/">keybase.io</a></td><td><a href="http://keybase5wmilwokqirssclfnsqrjdsi7jdir5wy7y7iu3tanwmtp6oid.onion/">keybase5wmilwokqirssclfnsqrjdsi7jdir5wy7y7iu3tanwmtp6oid.onion</a></td></tr><tr><td><a href="https://protonmail.ch/">protonmail.ch</a></td><td><a href="http://protonirockerxow.onion/">protonirockerxow.onion</a></td></tr><tr><td><a href="https://schu.be/">schu.be</a></td><td><a href="http://b5ec6jsfe2oyrqlt4od67bw7lyk2v77paixokjoq32xsdilvcuyeh5id.onion/">b5ec6jsfe2oyrqlt4od67bw7lyk2v77paixokjoq32xsdilvcuyeh5id.onion</a></td></tr></tbody></table><p>Until recently it has been a challenge to discover the hidden service address for any website. Some advertise their onion service in their footer (Keybase, Protonmail), but it is otherwise usually hard to find out. Thankfully the latest version of the Tor browser (version 9.5) implements <a href="https://gitweb.torproject.org/tor-browser-spec.git/tree/proposals/100-onion-location-header.txt">the Onion-Location spec</a>. As explained by the Tor Project’s <a href="https://community.torproject.org/onion-services/advanced/onion-location/">helpful explanation</a> it allows websites to use either an HTTP response header or an HTML meta tag to advertise an onion address for a website. Once set up, visitors who reach the clearnet website will be shown a nice button which redirects them to the onion service. The browser can also be configured to do this always, automatically.</p><img src="https://schu.be/assets/onion-available.png" alt="The Tor browser’s address bar, showing a URL from the Tor Project’s website and a bright button reading “.onion available”." width="693" height="38"><p>Again, this can be triggered in two ways. Either the HTTP response from the webserver includes the <em>Onion Location</em> header as follows.</p><code>Onion-Location: <span>someonionaddress.onion</span></code><p>Alternatively, the same behaviour can be obtained by adding a meta tag in the HTML document itself.</p><code>&lt;<span>meta</span><br>&nbsp;&nbsp;http-equiv=<span>"onion-location"</span><br>&nbsp;&nbsp;content=<span>"someonionaddress.onion"</span>&gt;</code><p>Of course this is now enabled on this website!</p><p><time datetime="2020-07-09">July 9, 2020</time></p></article></section></div>]]>
            </description>
            <link>https://schu.be/til-onion-location.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824214</guid>
            <pubDate>Mon, 13 Jul 2020 18:51:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defining Raku – Vadim Belman]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824139">thread link</a>) | @lizmat
<br/>
July 13, 2020 | https://vrurg.github.io/arfb-publication/04-defining-raku/ | <a href="https://web.archive.org/web/*/https://vrurg.github.io/arfb-publication/04-defining-raku/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
          
        
        
<p>When I’m writing texts like this one I always imagine a curious and vigilant
person who spots the gaps in my story, would those be intentional or not. Today
this perisher annoys me by demanding explanations on the following (a quote):</p>

<blockquote>
  <p>You repeated for several times that Rakudo is not Raku itself, it’s just an
implementation. Ok, then how do we know that the code Rakudo executes is
actually Raku? Where can I find the precise definition of Raku?</p>
</blockquote>

<p>The problem is: it’s the darn right question to ask! Because to the surprise of
many, Raku doesn’t have a formally written textual specification. Such thing
just doesn’t exists and never existed before.</p>



<p>Unfortunately, I wasn’t there when Perl6 was born. Neither I was there when it
was designed. After all, I’m a late comer. But some pieces I read about. Of them
the most relevant to our subject are the initial design papers, named
<a href="https://raku.org/archive/doc/apocalypse.html">Apocalypses</a> and
<a href="https://design.raku.org/">Synopses</a>. They were probably the closest thing to be
ever called Perl6 Standard.</p>

<p>But they weren’t. In fact, some of the syntax constructs or the behaviors
proposed in the papers were never implemented or their final shape is different
from initial ideas. This is normal as the life brings corrections to our
expectations. But imagine the corrections are to be made formally; imagine the
amount of work needed to find all related places in the papers, correct them
accordingly, make sure that the correction does fully conform with the final
implementation of a feature or a construct – and it is a two-way road! All of
this is to be done by a handful of volunteers with their daytime jobs,
families, and possibly other duties!</p>

<p>Besides, any textual standard would suffer from fuzziness of a human language.
It’s been long time since I last programmed in C++, but I still remember the
“fun” of making code compatible with a couple of different brands of compilers,
each claiming to be 100% following the specification!</p>

<p>In Raku we use another way. We have</p>



<p>It is a <a href="https://github.com/Raku/roast">test suite</a>. And it defines what the
Raku language is. Any compiler passing tests in Roast is considered to be
implementing Raku or a subset of it if failing some tests.</p>

<p>Let me be a bit emotional here, but I consider the idea to be a fantastic one!
By not being a multi-language expert nor a historian of the programming, I can
easily miss another case like Roast. But to the best of my knowledge no other
language took this path.</p>

<p>The advantages of using a test suite as the language specification lies in part
in the ease of maintaining it. Instead of codifying a standard in a textual
form, and letting compiler developers to deal with it, and discussing what
interpretation of the spec is correct, we simply add a test and say: if a
compiler passes it then it implements the particular spec.</p>

<p><em>And it is never too much to remind that I simplify things here by skipping some
irrelevant details which may obscure the main point.</em></p>

<p>Of course, the use of Roast is not only about joy. The two problems I can think
of right away are:</p>

<ul>
  <li>the structure of the test suite</li>
  <li>ease of finding necessary information</li>
</ul>

<p>The first one lies in the fact that Roast directory structure is based upon
synopses, mentioned above. The first few lines of <code>ls</code> output in the suite root
dir have this look:</p>

<div><div><pre><code>S01-perl-5-integration/
S02-lexical-conventions/
S02-lists/
S02-literals/
S02-magicals/
S02-names/
S02-names-vars/
S02-one-pass-parsing/
S02-packages/
S02-types/
S03-binding/
S03-buf/
S03-feeds/
</code></pre></div></div>

<p>Really, it’s not something very intuitive unless you know the backstory. I don’t
consider the problem a big one as it’s rather easily fixable with sufficient
amount of spare time on someone’s hands… Oh, wait, what spare time? Anyhow,
it’s still a minor issue.</p>

<p>The nature of the other problem is intrinsic to the approach itself. Whichever
classification we’d choose for grouping tests, many of them are hard to fit into
a single category. Thus finding the right one might sometimes turn into a little
quest of combining one’s intuition with <code>grep</code> output.</p>

<p>Luckily, alongside with Roast, Raku has brilliant and ever evolving
<a href="https://docs.raku.org/">documentation</a> project which is able to cover most of
one’s needs in looking for information about Raku syntax and core API.</p>

<p>Speaking of myself, when it comes to choosing between unambiguity of the
specification and its searchability – the first wins, univocally!</p>



<p>In a previous article I mentioned that the compiler in Raku is responsible for
syntax. By then I was talking about OO and the Metamodel. But the statement
could pretty much be extended to everything in the language <em>(still, remember
about simplifications!)</em>. Yet, syntax alone makes like… er… well… not the
biggest part of Raku specs. By browsing Roast one would quickly realize that
most of it is about testing core classes and their interfaces. Sometimes what
looks like a syntax test implies testing of a core class at the same time! For
example, if we write something like:</p>

<div><div><pre><code>my @a = 1..42;
is @a.elems, 42, “Array initialized from a Seq”;
</code></pre></div></div>

<p>then we test all the syntax constructs of declaring a symbol, defining a
sequence, and assignment; and the same time we test <code>Array</code> and <code>Seq</code> classes
under the hood. Oh, and <code>Array</code> is not even that much “under” as we implicitly
invoke <code>.elems</code> method! By replacing the method invocation with <code>+@a</code> we turn
the test in fully-implicit one.</p>

<p>Lets sum up what we know so far. The compiler does the syntax. The metamodel
does the type system. What does the classes? To answer this question <em>(yes, my
boring imaginary friend!)</em> I need to step back a bit and get into some technical
details.</p>

<p>As I expect the reader to know about scoping, I’d start from this simple snippet
of a little Raku program:</p>

<div><div><pre><code>use v6;
say “Who cares?”;
</code></pre></div></div>

<p>The code itself is not relevant, ignore it. It’s the scope which we care about.
The initial intention of a beginner is to consider the program scope to be the
topmost one. Yes, “oops” applies here!  But before I explain the “oops”, let me
show you a Raku’s feature used in some code examples below:</p>

<div><div><pre><code>my $foo;
{
    my $bar;
    say MY::.keys;
    say OUTER::.keys;
}
</code></pre></div></div>

<p><code>MY</code> and <code>OUTER</code> here are pseudo-packages. We call them <em>pseudo</em> because they do
not represent a real package but point at the current lexical scope and the
outer one. <code>::</code> postfix gives us a <code>Hash</code>-like object containing symbol table of
the package it is applied to. Because it’s a hash <code>keys</code> method will return all
symbol names from the table (see <a href="https://docs.raku.org/type/Hash">Hash
documentation</a>).</p>

<p>Now, as I hopefully made the basics clearer, here is what the output of the
example looks like:</p>

<blockquote>
  <div>
<div><pre><code>($*DISPATCHER $bar $_)  
($*DISPATCHER $_ $foo)  
</code></pre></div>  </div>
</blockquote>

<p>Never mind <code>$*DISPATCHER</code> and <code>$_</code>, they’re pre-installed by the compiler and
are out of the scope of this article.</p>

<p>Last thing to mention about Raku syntax before we get back to the point of this
section is that <code>::</code> allows to reference symbols in packages using fully
qualified names. In our example we can gain access to <code>$foo</code> using fully
qualified name notation: <code>$OUTER::foo</code>. Though this particular line make not
much sense in the context of my example since <code>$foo</code> is visible inside the block anyway, but it makes
a lot more sense in many other cases. One of them you’ll see later in this article.
Another one lets us introspect the outer of our outer with <code>OUTER::OUTER</code>
notation. Correspondigly <code>OUTER::OUTER::</code> would return the
symbol table of the scope two steps away from the current one!</p>

<p>We’re now ready for a discovery! Let’s find out what’s the above mentioned
“oops” is all about. For this we start with  a one-liner: <code>use v6.d; say
OUTER::OUTER::.keys</code>. It can be tried directly from your shell command line:</p>

<div><div><pre><code>$ raku -e 'use v6.d; say OUTER::OUTER::.keys'
(&amp;infix:«(&lt;+)» &amp;infix:&lt;≽&gt; CORE-SETTING-REV &amp;await $=pod $¢ $_ $/ $! &amp;infix:&lt;≼&gt; &amp;infix:«(&gt;+)»)
</code></pre></div></div>

<p>Add one extra pair of <code>OUTER::OUTER::</code>: <code>use v6.d; say
OUTER::OUTER::OUTER::OUTER::.keys</code> - to see even longer list of symbols! Raku
would even have to truncate the list for you for make it more appealing.</p>

<p>Among the symbols printed you may find some already familiar ones like <code>Int</code>,
<code>Str</code>, <code>mkdir</code>, <code>shift</code>, etc., etc.</p>

<p>More precision could now be added to Raku definition: it is a syntax with a
library providing the core API. For the latter single word <em>core</em> is often used.
Evidently, the symbols we’ve discovered are part of the core.</p>

<p>I’m sure by this moment any beginner would still have more questions than
anwers. That’s because we still need more pieces of the puzzle. So, let’s move
on to the next one.</p>



<p><em>This section is somewhat of a digression from the main line. But it is
necessary for understanding the later parts of this article.</em></p>

<p>Roughly speaking, a <em>setting</em> is a lexical context in which a script or a module
is wrapped. The setting provides default symbols available to user code but
installed by some external means, not by the code itself.</p>

<p>The following pseudo-code schematically demoes what’s said above:</p>

<div><div><pre><code>{ # Setting
    ...
    class Int { ... }
    class Str { ... }
    ...
    sub say(...) { ... }
    sub print(...) { ... }
    ...
    { # User code
        use v6;
        my Int $foo = 42;
        print $foo, ": ";
        say "Report to my setting! ";
    }
}
</code></pre></div></div>

<p>It is now time to introduce one more term extensively used in Raku: <em>compunit</em>
which is short of <em>compilation unit</em>. In the pseudo-code above compunit is the
<em>User code</em> section. Similarly, the following being put in a <code>.rakumod</code> module
file would be considered a compunit too:</p>



<p>For our purpose it is sufficient to state that any file of Raku code is a
compunit, would it be a script or a module.</p>

<p><em>Note:</em> In the previous section I used pairs of <code>OUTER::</code> to reach the setting
symbol table. This is because Rakudo installs an additional empty lexical scope
between a compunit and its setting. The purpose of this scope is technical and
not relevant to our subject. The pseudo-code example above doesn’t reflect this
fact.</p>

<p>It would also be worth noting that a setting is not necessarily about what
compiler installs for you by default. For example, …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vrurg.github.io/arfb-publication/04-defining-raku/">https://vrurg.github.io/arfb-publication/04-defining-raku/</a></em></p>]]>
            </description>
            <link>https://vrurg.github.io/arfb-publication/04-defining-raku/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824139</guid>
            <pubDate>Mon, 13 Jul 2020 18:45:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Re-Modeling a “Man Cave” into an Office (For Under $3k)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823987">thread link</a>) | @kenhara
<br/>
July 13, 2020 | https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/ | <a href="https://web.archive.org/web/*/https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I’m becoming a dad. Well, technically I’m already a dad. But our first — a baby girl! — is due in September and this means changes for our home. It also presented a once-in-a-lifetime opportunity for me to binge 140+ episodes of an ancient history podcast. More on that later.</p>



<p>When I quit a job to work for myself, my wife and I knew we had having kids on our radar. I wanted to have more free time to work on projects like this, help with childcare, go to sports practices, and generally be around as a dad. </p>



<p>Most things I did in this project, I did for the first time. Which meant doing lots of research, asking handy friends, and giving myself a lot of time. I kept track of every receipt and will share that later in the <strong>Budget</strong> section. For now, the total project budget came to: $2,934.09 — not including the cost of my time.</p>



<p>Here’s a quick look at the before and after:</p>







<h2>Before</h2>



<p>Our house is a typical <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Minimal_Traditional" target="_blank">Minimal Traditional</a> post-war build. Many of these houses were built in Denver after World War II as the city grew from ~400,000 residents to over 1 million over the course of 25 years. There are many homes like it, but this one is ours. </p>



<div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><figure><img data-attachment-id="2798" data-permalink="https://harriskenny.com/before_2/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1526730627&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.67&quot;,&quot;iso&quot;:&quot;89&quot;,&quot;shutter_speed&quot;:&quot;0.0083389999989713&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="before_2" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?w=700" srcset="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?strip=info&amp;w=600 600w,https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?strip=info&amp;w=900 900w,https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?strip=info&amp;w=960 960w" alt="" data-height="960" data-id="2798" data-link="https://harriskenny.com/before_2/" data-url="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg" data-width="1280" src="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg"></figure></div></div></div></div>



<p>There’s this a particularly ugly “man cave” extension built onto the back. I’m not sure when it was built. The worst/best feature is the animal prints. Zoom in to the picture above and see if you can find any pheasant or deer.</p>



<p>My current office is becoming a nursery. Which means that this gem of a space is meant to be my new office. Previously it had been functioning as an exercise space (since moved that to the basement).</p>



<h2>Teardown</h2>



<div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><figure><img data-attachment-id="2770" data-permalink="https://harriskenny.com/teardown_2/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg" data-orig-size="960,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1585493485&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;32&quot;,&quot;shutter_speed&quot;:&quot;0.0060606060606061&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="teardown_2" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?w=225" data-large-file="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?w=700" srcset="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?strip=info&amp;w=600 600w,https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?strip=info&amp;w=900 900w,https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?strip=info&amp;w=1200 1200w,https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?strip=info&amp;w=1280 1280w" alt="" data-height="1280" data-id="2770" data-link="https://harriskenny.com/teardown_2/" data-url="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg" data-width="960" src="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg"></figure></div></div></div></div>



<p>Good news (not pictured): There was sufficient insulation and a good foundation under the space. I didn’t find anything majorly problematic in the teardown but did see some mildew,  light water damage, and some unsightly gaps that they’d covered up with the paneling and trim.</p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><li><figure><img data-attachment-id="2777" data-permalink="https://harriskenny.com/teardown-cont-1/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1586719367&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;1000&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="teardown-cont-1" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=700" src="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=1024" alt="" data-id="2777" data-link="https://harriskenny.com/teardown-cont-1/" srcset="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img data-attachment-id="2778" data-permalink="https://harriskenny.com/teardown-cont-2/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1586979608&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;2000&quot;,&quot;shutter_speed&quot;:&quot;0.055555555555556&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="teardown-cont-2" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=700" src="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=1024" alt="" data-id="2778" data-link="https://harriskenny.com/teardown-cont-2/" srcset="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img data-attachment-id="2779" data-permalink="https://harriskenny.com/teardown-cont-3/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1587231959&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0081967213114754&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="teardown-cont-3" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=700" src="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=1024" alt="" data-id="2779" data-link="https://harriskenny.com/teardown-cont-3/" srcset="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li></ul></figure>



<p>Decided to do the drywall repair and removing the carpet and under layment in parallel. Also took out the light fixtures. Making great progress. Though tearing things down is always easier than building things up, much work to be done still.</p>



<h2>Sidebar: The History of Rome Podcast</h2>



<div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><figure><img data-attachment-id="2782" data-permalink="https://harriskenny.com/the_history_of_home-podcast-album-art/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg" data-orig-size="328,328" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the_history_of_home-podcast-album-art" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=328" src="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=328" alt="" srcset="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg 328w, https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=300 300w" sizes="(max-width: 328px) 100vw, 328px"></figure><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}">
<p>I’d be remiss if I didn’t mention Mike Duncan’s <em><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/The_History_of_Rome_(podcast)" target="_blank">The History of Rome</a></em> podcast.</p>



<p>At the time of writing this, I’ve listened to over 140 episodes of this incredible podcast. I’ve learned so much and I can’t recommend it highly enough. </p>



<p>It will take me through finishing the nursery and bathroom re-model that are both also nearly complete. </p>
</div></div>



<h2>Preparing to Build Back Up</h2>







<p>There were lots of gaps in the previous drywall work that they covered up with the treated wood trim. Gap filling foam did a wonder on those spots, which will help keep out insects and provide additional insulation. After inspecting further, it seems the water damage was from past events and was not severe enough to damage the subfloor. Hit it with a coat of primer.</p>



<h2>Installing the Flooring</h2>



<div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><figure><img data-attachment-id="2787" data-permalink="https://harriskenny.com/flooring-1/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1588148971&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;20&quot;,&quot;shutter_speed&quot;:&quot;0.002&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="flooring-1" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?w=700" srcset="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?strip=info&amp;w=600 600w,https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?strip=info&amp;w=900 900w,https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?strip=info&amp;w=960 960w" alt="" data-height="960" data-id="2787" data-link="https://harriskenny.com/flooring-1/" data-url="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg" data-width="1280" src="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg"></figure></div></div></div></div>



<p>I’m using this room as an office for my business, but it could be used for any number of things. I decided to go with vinyl because of the ease of maintenance and ability to have the room be a few different things in the future. </p>



<p>After deciding on vinyl, I started with a cork underlayment to help with insulation, cushioning, and noise dampening. </p>



<p>This was a full day of work. I was exhausted at the end.</p>



<p>I will need to do acoustic testing, but I’m planning on recording <em><a href="https://helloblinkshow.com/">Hello Blink Show</a></em> episodes in this space. The room is not dedicated for audio, so I’m not going all-in on that use case (like with black foam). If I need to add additional furniture, curtains, or other things to help with echo later, I will cross that bridge later. </p>



<h2>Electrical</h2>







<p>Here’s where I got a little out of hand. I wanted to make sure that the ceiling fan would work with the ceiling pitch. I rediscovered geometry and went to town. I had a licensed electrician install the fixtures and add a hardwired smoke detector (not pictured). </p>



<p>The fans themselves were extremely difficult to install and took more time than expected. The boxes did need to be replaced with weight bearing ones UL-graded to hold the fans up, but that didn’t take long. Installing the smoke detector was also more difficult than expected and required an insane drill bit which the electrician fortunately had in the van.</p>



<p>These are two-in-one fixtures with clean LED light (looks slightly yellow in the photo) and reversible caged fan for different seasons. I’m definitely satisfied with how they’re working so far.</p>



<h2>Side Quest: Door Hardware and Signage</h2>







<p>The door hardware wasn’t in good shape. The surface on the door knob was worn down, the hinges were a different finish, and there wasn’t any sort of door stop. There were also gaps in the door frame from a previously botched lock install.</p>



<p>None of this was strictly necessary to fix. But if you’re doing something, might as well do it right. I bought and installed new hardware to address all of these issues.</p>



<p>I’m planning on using this as a formal office, so I decided to have fun with it by installing an eye viewer and door knocker (pictured below). I also bought numbers for a half address that I’ll put up later. (The outside needs touching up, too.)</p>



<p>This was a lot harder than I expected. Doors are very sensitive and getting the alignment just right took real effort. We’ll see how it lines up when temperatures change in the winter… I’m expecting to have to revisit this.</p>



<h2>Trim, Caulk, Texture</h2>







<p>This ended up being as difficult as I expected. Which is to say it was massively time consuming, but I love how it came out. I went with PVC trim because the room is not square, the flexibility there made it much easier to finish it without that being too obvious.</p>



<p>There were a number of varying dimensions I had to keep in mind when installing this, so I ended up sticking with this particular style for the entire room for consistency sake. This allowed me to account for the height of outlets, the basement window, and the door frame without having to do custom cutouts required to install a more typical trim selection. I do think the lower profile trim looks nice too.</p>



<h2>After</h2>



<figure><img data-attachment-id="2799" data-permalink="https://harriskenny.com/done-1/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1593779145&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;25&quot;,&quot;shutter_speed&quot;:&quot;0.0081967213114754&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="done-1" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=700" src="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=700" alt="" srcset="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=700 700w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg 1280w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<p>All set! (Minus the electrical outlet plates, not shown in this picture that I installed later). You can also see the new storm door, boxed and laying flat there.</p>



<p>I initially set a deadline to have the office, the bathroom re-model, and the nursery all done by August 1. This was done just after July 1 and the nursery will be done within the week. So it feels good to be ahead of schedule without blowing out the budget (more on that next).</p>



<h2>Budget</h2>



<figure><table><thead><tr><th>Item</th><th>Cost (↓)</th></tr></thead><tbody><tr><td>Electrician Labor</td><td>$620.00</td></tr><tr><td>Vinyl Flooring</td><td>$479.54</td></tr><tr><td>Electrical Fixtures</td><td>$438.97</td></tr><tr><td>Storm Door</td><td>$320.20</td></tr><tr><td>Consumables*</td><td>$269.67</td></tr><tr><td>PVC Trim</td><td>$211.94</td></tr><tr><td>Hand Tools</td><td>$201.71</td></tr><tr><td>Door Hardware &amp; Signage</td><td>$158.73</td></tr><tr><td>Paint</td><td>$120.83</td></tr><tr><td>Cork Underlayment</td><td>$112.50</td></tr><tr><td><strong>Total</strong></td><td><strong>$2,934.09</strong></td></tr></tbody></table></figure>



<p>Here are all the individual items that ended up costing over $100, ranked in Descending order of cost. Consumables include things like painter’s tape, gap filling foam, drywall tape, caulk. </p>



<p>One thing that’s not included in this budget is that I borrowed a nail gun and shop vac from a friend. Those, a drill, and an impact driver are the only power tools I used during this project. </p>



<p>I mentioned above in the <strong>Electrical</strong> section but worth re-iterating that the major driver of the electrician labor was the fact that the fans themselves were extremely difficult to install. They also had to replace the boxes to bear the weight of the fans. Installing the smoke detector was also a chore, too. Definitely glad I had a professional take care of these things.</p>



<p>I’m not sure what this would have cost to have done professionally. If you know, let me know! But I really enjoyed it and look forward to spending time in this re-modeled space. </p>



<h2>Unfinished Business</h2>



<p><strong>Blinds:</strong> I need to do more research on which blinds, how much light they allow in, etc. and because of how much time I take researching things… I’m putting this off for now. The nursery and bathroom re-model beckon.</p>



<p><strong>Heat:</strong> There is space for electrical floorboard heaters. Haven’t had those installed yet, but we do have room in the breaker if-needed as they will require having a dedicated line installed because of the power draw. I’m planning on seeing how drafty it is in the winter. </p>



<p><strong>Storm Door: </strong>I bought a better storm door that will help with insulation. When that’s installed, I’ll repaint the exterior threshold. I’d also like to look into installing a rubber gasket to totally seal the door, though it’s arguably overkill since the storm door and rebuilt threshold get that job done. </p>



<p><strong>Exterior: </strong>The outside of the extension needs some touch up work for sure. After that’s done, I’ll mount the “1/2” sign for our address as a fun finishing touch.</p>



<p><strong>Decor:</strong> Oh yeah, I need to move in and decorate the thing. Don’t have a lot of time for that now, so will keep it basic. I may revisit this with another post when it’s fully decorated and looks how I want it to look.</p>



<h2>Lessons Learned</h2>



<ul><li><strong>The Good</strong><ul><li>Satisfaction of a job well done.</li><li>Look at all that natural light!</li><li>Grateful for people who I could ask questions along the way, especially in the beginning.</li><li>Hard commitments. There’s a degree of inevitability when there is a baby on the way! That made sure I finished the job.</li><li>Stores like the Home Depot, Ace Hardware, and Sherwin Williams did a great job over the last few months ensuring customer safety.</li><li>There are many great American companies who make high quality tools and construction materials, I was proud to support as many as I could throughout this project. </li></ul></li><li><strong>The Bad</strong><ul><li>So. Much. Painters. Tape. Between. Steps.</li><li>I hit a bit of a wall before installing the trim or applying the drywall texture because I’d never done either before. That was the emotional “low point” for sure.</li><li>Electrical is expensive to get right and even more expensive to get wrong. </li><li>Paint isn’t very forgiving. The …</li></ul></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/">https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/</a></em></p>]]>
            </description>
            <link>https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823987</guid>
            <pubDate>Mon, 13 Jul 2020 18:32:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vessel Finder]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23823963">thread link</a>) | @Mosiout1936
<br/>
July 13, 2020 | https://marinetraffic24.com/pt/vesselfinder/ | <a href="https://web.archive.org/web/*/https://marinetraffic24.com/pt/vesselfinder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://marinetraffic24.com/pt/vesselfinder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823963</guid>
            <pubDate>Mon, 13 Jul 2020 18:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to learn to code 10x faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823899">thread link</a>) | @sameerkapur
<br/>
July 13, 2020 | https://blog.thecodex.me/how-to-code-10x-faster/ | <a href="https://web.archive.org/web/*/https://blog.thecodex.me/how-to-code-10x-faster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            



            <section>
                <div>
                    <h3 id="what-i-ve-learned-from-teaching-500-000-students-to-code-and-building-dozens-of-projects-">What I've learned from teaching 500,000 students to code and building dozens of projects.</h3><p>Avi here. Since I started programming, a question that I've been asked again and again from my students is, "How do I learn faster?" Here's the answer: <strong>Build projects.</strong></p><p>Let me explain with a story of my own. I started programming when I was 10-years-old after a friend showed me that she had built a Python weather dashboard that told her exactly when it would rain. I was astounded. I spent the next day figuring out how I could write my own Python Script to crawl Yahoo's Weather API and 24 hours later I had built my first program. If you had told me I had to take an 8-week long bootcamp to learn how to code or watch monotonous YouTube videos until it clicked, I might have never started in the first place. No one forced me to get into programming - I discovered my passion because I wanted to build this cool idea. StackOverflow became my best friend as I achieved my goal. Along the way, I learned about a variety of concepts from calling APIs in Python to parsing JSON and had plenty of practice applying them in my project. The lesson here: <strong>use projects as motivators to learn. </strong></p><p>Okay so we got that out of the way. Building projects are the key to learning things faster. Now what? How do I pick the right projects? Where do I even start?</p><p>The next big takeaway:<strong> Work on projects that matter to you. </strong>My first project was a simple weather script because my ten-year-old brain thought that was wicked cool, but you probably have other passions and interests. Don't compromise. Build projects around your interests and hobbies. If you are starting a project, make sure that it is something that you deeply resonate with. If you are into cars, build a car speed comparison tool. If you are into productivity, build a time tracker to help you be more productive. Even better, build things you want. When those ideas for a cool app or website pop up in your head, START BUILDING IT because motivation is perishable. As the saying goes, the best time to start was yesterday, the next best time to start is now.</p><p>Good things happen to those who are patient. Here are three magic words: <strong>Repetition, Compounding, and Consistency.</strong> These three words are the key to solidifying programming fundamentals and truly understanding new concepts and ideas as you apply them in projects. You've heard how important spaced repetition is for learning - the same thing applies when learning how to code. Try coding for an hour a day. Don't have an hour a day? Code for 30 minutes. Can't do 30 minutes consistently? Try for 15 minutes. Break tasks down into smaller tasks and knock them out.</p><p>Last but not the least, the tip that changed my life: Teach what you learn. Yes, it sounds simple - teach what you learn - but I can't repeat it enough. Explaining concepts allow you to improve your understanding and solidify your learning. Teaching has positive externalities as well. After I started teaching others how to code and began posting videos on <a href="https://www.youtube.com/c/TheCodex">Youtube</a>, I not only understood each and every concept better, but thousands of others used my videos to learn how to code. My AP Stats teacher had a philosophy that to truly understand any concept you must "learn one, do one, and teach one." Teaching others has helped me hold myself accountable to truly understanding concepts until I feel ready to share my knowledge and it's paved my path in becoming a professional Python Developer and Data Scientist.</p><p>For those of you interested in project walkthroughs: Every Tuesday, I'm releasing a new Python/Data Science Project tutorial. I was honestly just tired of watching webcasted lectures and YouTube videos of instructors droning on with robotic voices teaching pure theory, so I started recording my own fun and practical projects. I posted the first project walkthrough on building a Weather API Dashboard with Flask and you can build the whole project for free <strong><a href="https://thecodex.me/projects/weather-api-dashboard-with-python-and-flask">here</a>.</strong></p><p>Want to get notified every time a new project launches? Click <strong><a href="https://cdn.forms-content.sg-form.com/a9d3bb34-c4a3-11ea-a1ea-52b70f2fc72a">here</a></strong>.</p><hr><p>Hey! I'm Avi - your new Python and data science teacher. I've taught over 500,000 students around the world not just how to code, but how to build real projects. I'm on a mission to help you jumpstart your career by helping you master python and data science. Start your journey on TheCodex here: <a href="https://thecodex.me/">https://thecodex.me/</a></p><figure><img src="https://blog.thecodex.me/content/images/2020/07/avi-emailtxt-min-2.jpg" alt="" srcset="https://blog.thecodex.me/content/images/size/w600/2020/07/avi-emailtxt-min-2.jpg 600w, https://blog.thecodex.me/content/images/size/w1000/2020/07/avi-emailtxt-min-2.jpg 1000w, https://blog.thecodex.me/content/images/size/w1600/2020/07/avi-emailtxt-min-2.jpg 1600w, https://blog.thecodex.me/content/images/2020/07/avi-emailtxt-min-2.jpg 1616w" sizes="(min-width: 720px) 720px"><figcaption>new projects and courses coming soon :)</figcaption></figure>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.thecodex.me/how-to-code-10x-faster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823899</guid>
            <pubDate>Mon, 13 Jul 2020 18:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dealing with Non-ASCII Characters]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823749">thread link</a>) | @chmaynard
<br/>
July 13, 2020 | https://blog.jpalardy.com/posts/dealing-with-non-ascii-characters/ | <a href="https://web.archive.org/web/*/https://blog.jpalardy.com/posts/dealing-with-non-ascii-characters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  

  

  <h2 id="problem">Problem</h2>

<p>Quick: why is this JSON not valid?</p>

<div><div><pre><code>{
  “user”: {
    “username”: “jpalardy”,
    “first_name”: “Jonathan”,
    “last_name”: “Palardy”
  }
}
</code></pre></div></div>

<details>
  <summary>[reveal the answer]</summary>

  

  <p>
  <a href="https://typographyforlawyers.com/straight-and-curly-quotes.html">Curly quotes!</a>
  </p>

  <p>
  Trick question? Yes and no... this happened to me and it was difficult to troubleshoot <em>visually</em>.
  </p>
</details>

<h2 id="a-class-of-problems">A Class of Problems…</h2>

<p>Many text formats, programming languages and other machine-parsed texts have rules about
what characters are allowed and not.</p>

<p>When in doubt, the lowest common denominator is usually <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a>:</p>

<div><div><pre><code>The decimal set:

  0 nul    1 soh    2 stx    3 etx    4 eot    5 enq    6 ack    7 bel
  8 bs     9 ht    10 nl    11 vt    12 np    13 cr    14 so    15 si
 16 dle   17 dc1   18 dc2   19 dc3   20 dc4   21 nak   22 syn   23 etb
 24 can   25 em    26 sub   27 esc   28 fs    29 gs    30 rs    31 us
 32 sp    33  !    34  "    35  #    36  $    37  %    38  &amp;    39  '
 40  (    41  )    42  *    43  +    44  ,    45  -    46  .    47  /
 48  0    49  1    50  2    51  3    52  4    53  5    54  6    55  7
 56  8    57  9    58  :    59  ;    60  &lt;    61  =    62  &gt;    63  ?
 64  @    65  A    66  B    67  C    68  D    69  E    70  F    71  G
 72  H    73  I    74  J    75  K    76  L    77  M    78  N    79  O
 80  P    81  Q    82  R    83  S    84  T    85  U    86  V    87  W
 88  X    89  Y    90  Z    91  [    92  \    93  ]    94  ^    95  _
 96  `    97  a    98  b    99  c   100  d   101  e   102  f   103  g
104  h   105  i   106  j   107  k   108  l   109  m   110  n   111  o
112  p   113  q   114  r   115  s   116  t   117  u   118  v   119  w
120  x   121  y   122  z   123  {   124  |   125  }   126  ~   127 del

(courtesy of `man ascii`, a reference never too far)
</code></pre></div></div>

<p>And while “curly quotes” might seem like a made-up problem<sup id="fnref:made-up"><a href="#fn:made-up">1</a></sup>, there are other insidious examples:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Dash#En_dash">en dash</a>, <a href="https://en.wikipedia.org/wiki/Dash#Em_dash">em dash</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Non-breaking_space">non-breaking space</a> and <a href="https://en.wikipedia.org/wiki/Tab_key#Tab_characters">tab</a> (to a lesser extent)</li>
  <li><a href="https://en.wikipedia.org/wiki/Carriage_return">carriage return</a> and <a href="https://en.wikipedia.org/wiki/Newline">newline</a></li>
  <li>in general: <a href="https://en.wikipedia.org/wiki/Homoglyph">homoglyphs</a> (<a href="https://en.wikipedia.org/wiki/IDN_homograph_attack">other examples</a>)</li>
</ul>

<h2 id="solutions">Solutions</h2>

<p>There is no general solution to all the problems, only an assortment of tricks:</p>

<ul>
  <li>“weird spacing” is often flagged or fixed by text editors; details will vary</li>
  <li>file formats: can be fixed with <a href="https://waterlan.home.xs4all.nl/dos2unix.html">dos2unix</a> or similar</li>
  <li>external linters can be your sanity check:</li>
</ul>

<figure><pre><code data-lang="bash"><span>&gt;</span> jq <span>.</span> invalid.json
parse error: Invalid numeric literal at line 2, column 13
<span>&gt;</span>
<span># better than nothing? 🤔</span></code></pre></figure>

<h3 id="the-non-visible-ascii-regexp-trick">The Non-Visible ASCII regexp Trick</h3>

<p>If what’s allowed is “visible ASCII”, what’s <em>not allowed</em> is “non-visible ASCII”:</p>



<p>described in words: all characters not between “space” and “tilde”<br>
(I don’t remember where I picked up this trick. I would appreciate a link if you know.)</p>

<p>Why does this work? Referring back to the ASCII table from above:</p>

<div><div><pre><code>  0 nul    1 soh    2 stx    3 etx    4 eot    5 enq    6 ack    7 bel
  8 bs     9 ht    10 nl    11 vt    12 np    13 cr    14 so    15 si
 16 dle   17 dc1   18 dc2   19 dc3   20 dc4   21 nak   22 syn   23 etb
 24 can   25 em    26 sub   27 esc   28 fs    29 gs    30 rs    31 us
     /--- start here
 32 sp    33  !    34  "    35  #    36  $    37  %    38  &amp;    39  '
 40  (    41  )    42  *    43  +    44  ,    45  -    46  .    47  /
 48  0    49  1    50  2    51  3    52  4    53  5    54  6    55  7
 56  8    57  9    58  :    59  ;    60  &lt;    61  =    62  &gt;    63  ?
 64  @    65  A    66  B    67  C    68  D    69  E    70  F    71  G
 72  H    73  I    74  J    75  K    76  L    77  M    78  N    79  O
 80  P    81  Q    82  R    83  S    84  T    85  U    86  V    87  W
 88  X    89  Y    90  Z    91  [    92  \    93  ]    94  ^    95  _
 96  `    97  a    98  b    99  c   100  d   101  e   102  f   103  g
104  h   105  i   106  j   107  k   108  l   109  m   110  n   111  o
112  p   113  q   114  r   115  s   116  t   117  u   118  v   119  w
120  x   121  y   122  z   123  {   124  |   125  }   126  ~   127 del
                                              stop here ---/
</code></pre></div></div>

<p>What is before space? various non-visible characters…<br>
What is after tilde? <code>del</code>, but also <em>ALL other Unicode characters!</em></p>

<p>Why is this useful? Many text editors can highlight based on regular expressions:</p>

<p><img src="https://blog.jpalardy.com/assets/dealing-with-non-ascii/curlies-in-vim.png" alt="curly quotes highlighted in vim"><br>
(this is vim; use <code>:set hlsearch</code> to turn this on)</p>

<p>This trick works everywhere regular expressions work:</p>

<p><img src="https://blog.jpalardy.com/assets/dealing-with-non-ascii/curlies-in-grep.png" alt="curly quotes highlighted in grep"></p>

<hr>

<p>Footnotes:</p>




  <section>
    <h3>Discuss on Twitter</h3>
    <section>
      
      <a href="https://twitter.com/jpalardy" data-show-count="false">Follow @jpalardy</a>
      
    </section>
  </section>
</section></div>]]>
            </description>
            <link>https://blog.jpalardy.com/posts/dealing-with-non-ascii-characters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823749</guid>
            <pubDate>Mon, 13 Jul 2020 18:12:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ETL: Navigating the Cloud Transition (Architectures & Factors to consider)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823680">thread link</a>) | @ibains
<br/>
July 13, 2020 | https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition | <a href="https://web.archive.org/web/*/https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Data Integration is a critical engineering system in all Enterprises. Initially, it started with ad hoc <strong>scripts</strong>, which got replaced by <strong>Visual ETL</strong> tools such as Informatica, AbInitio, DataStage, and Talend. To cope with an explosion in data, consumer companies such as Google, Yahoo, and LinkedIn developed new <strong>data engineering</strong> systems based on commodity hardware. The usability of these systems was quite low, and the developer needed to be much more aware of the performance. <strong>Apache Spark</strong> has broken through from this clutter with thoughtful interfaces and product innovation, while <strong>Hadoop</strong> has effectively gotten <strong>disaggregated</strong> in the cloud and become a legacy technology.</p><p>Now, as Enterprises transition to the cloud, often they are developing expertise in the cloud ecosystem at the same time as trying to make decisions on the product and technology stack they are going to use. </p><p>In the rest of the blog, we'll take a look at the two primary processing paradigms for data integration, and their cloud equivalents.</p></div><h2>What is Data Integration (or ETL)</h2><p>Data Integration is your Data Factory. It reads data from various <strong>input sources</strong> such as Relational Databases, Flat Files, and Streaming. It then does various <strong>transformations</strong> on the data such as joining and de-duplicating data, standardizing formats, pivoting, and aggregating. Once the data is ready for analytics (such as in star schemas), it is <strong>stored or loaded</strong> into the target which is typically a Data Warehouse or a Data Lake.</p><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%20%20graphic.png" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%2520%2520graphic-p-1080.png 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%2520%2520graphic-p-1600.png 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%20%20graphic.png 1755w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><h2>The Two On-Premises Execution Paradigms</h2><p>For most large Enterprises and companies rich in data, &nbsp;one server will be insufficient to execute the workloads, and thus, parallel processing is required. For this, there have historically been two primary methods:</p><ul role="list"><li><strong>ETL Execution Engine Processing</strong> - here the ETL tool comes with a distributed high performance execution engine. Most of the processing happens in this execution engine, and after the data is ready for analytics, it is loaded into a data warehouse. <strong>AbInitio</strong> is a good example and is the market leader in performance.</li><li><strong>Data Warehouse Pushdown Processing</strong> - here the ETL tool comes with a single server execution engine. Since it cannot do high volume processing, it provides pushdown processing that pushes computations down to the Data Warehouse and leverages the distributed processing engine there. In the field, we see <strong>Informatica</strong> commonly deployed with <strong>Teradata</strong> this way, though Informatica has a PowerCenter Grid product as well.</li></ul><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%20execution%20graphic.png" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-500.png 500w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-800.png 800w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-1080.png 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-1600.png 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%20execution%20graphic.png 1773w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><p>Two on-premises ETL Execution paradigms</p><h3>Which Architecture is Better?</h3><div><p>One natural question to ask is - <strong>whether one of these paradigms is preferable?</strong> The Answer is Yes!</p><p>The case for <strong>data warehouse ETL execution</strong> is that it reduces one system - ETL execution and data warehouse execution will both happen in Teradata. Also, most data warehouses are typically high-quality products. However, it's an <strong>expensive</strong> approach and <strong>not the right architectural fit</strong>. Data warehouses have an architectural focus on <strong>low latency</strong> since there is often a human analyst waiting for her BI query. For this, they collect high-quality statistics for query planning and have sophisticated caching mechanisms. This is not a great fit for ETL workloads where throughput is the most important factor, and there is no reuse, making caches and statistics useless. Often we've found that 70% of Teradata capacity was dedicated to ETL in Enterprises, and that is what got offloaded to Apache Hive. </p><p>On the other hand, high-quality parallel processing products, exemplified by AbInitio are perhaps the <strong>best solution</strong> - both in inherent processing cost and performance. Most users of AbInitio loved the product, but the high licensing cost has removed any architectural cost advantages they had and made them available to a very few of the largest Enterprises. </p><p>‍<strong>Cloud, with usage based pricing,</strong> is a great equalizer, let's look at how cloud is changing this equation...</p></div><h2>Cloud Transition - the two ETL Architectures</h2><p>There are two primary approaches to choose for your ETL or Data Engineering</p><ul role="list"><li><strong>Data Warehouse ETL Approach: </strong>This is an <strong><em>as-is</em></strong> migration of the on-premises approach, done in a cloud context. An example here, one can use <strong>Snowflake</strong> as the data warehouse instead of <strong>Teradata</strong> on-premises. Then you can use any ETL tool such as <strong>Informatica</strong> or <strong>Matillion</strong> on top and it will push down queries to Snowflake that will do the heavy lifting. If you have small datasets, this works. As discussed above, for large datasets and complex transformations this architecture is far from ideal. This is far from the world of open-source code on Git &amp; CI/CD that data engineering offers - again locking you into proprietary formats, and archaic development processes.</li><li><strong>Data Engineering Approach:</strong> Data Engineering based on Spark for the execution layer, merges the best of the previous generation in high performance, with the best of large scale commodity processing from consumer companies - such as Hadoop. If you use Databricks, it adds transactions from Data Warehouses via delta lake providing the best product in the cloud by a large margin. A product such as <strong>Prophecy</strong> adds the remaining functionality - code and visual drag-and-drop editing that generates code on Git, Metadata with lineage, Scheduling, and CI/CD, providing a complete stack that will free you from proprietary formats.</li></ul><div><p>The following image is how the Cloud Data Engineering architecture looks. The data from on-premise operational systems lands inside the data lake, as does the data from streaming sources and other cloud services. <strong>Prophecy with Spark</strong> runs data engineering or ETL workflows, writing data into a data warehouse or data lake for consumption.</p><p>Reports, Machine Learning, and a majority of analytics can run directly from your Cloud Data Lake, saving you a lot of costs and making it the single system of record. For particular BI use cases (fast interactive queries), Data Marts can be created on Snowflake or another Cloud Data Warehouse such as Redshift, BigQuery, or Azure SQL.</p></div><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture.jpg" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-500.jpeg 500w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-1080.jpeg 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-1600.jpeg 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-2000.jpeg 2000w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture.jpg 2423w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><p>Cloud Data Engineering Architecture</p><h2>How to Choose?</h2><p>If you're moving you ETL to Data Engineering, you're deciding what your architecture for the next decade or more.</p><p>We recommend moving to Apache Spark and a product such as Prophecy. Apart from exceeding the capabilities of the Snowflake based stack at a much cheaper price point, this prevents you from getting locked into proprietary formats. You will also be able to deliver new analytics faster by embracing Git and continuous integration and continuous deployment - that is equally accessible to the Spark coders as well as the Visual ETL developers who have a lot of domain knowledge.</p></div></div>]]>
            </description>
            <link>https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823680</guid>
            <pubDate>Mon, 13 Jul 2020 18:06:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Give some love to your PR]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23823554">thread link</a>) | @elleflorio
<br/>
July 13, 2020 | https://www.florio.dev/20200712-pr-love/ | <a href="https://web.archive.org/web/*/https://www.florio.dev/20200712-pr-love/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>After hours of work, you finally get there. Your code is ready. Time to submit a Pull Request (PR) and get your baby reviewed. There is a PR template to fill… Ufff, that’s annoying! Please, don’t waste my time with this stuff and just look at my code!!! </p>
<p>Let’s be honest: we have been there more than once. PRs with a poorly filled template, or (even worst) no template and an extremely useless description. “Add this”. “Fix that”. </p>
<p>But we know it is not the right way to ship our code. In this article, I want to point out the importance of providing an amazing PR, with a complete and useful description, and all the information the reviewers will need to provide great feedback. No templates here, or rules to follow. <strong>My goal is to inspire you to give some love to your PR</strong>.</p>
<p><span>
      <a href="https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/275bf/pr-love-cover.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="meme" title="meme" src="https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/fcda8/pr-love-cover.png" srcset="https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/12f09/pr-love-cover.png 148w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/e4a3f/pr-love-cover.png 295w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/fcda8/pr-love-cover.png 590w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/efc66/pr-love-cover.png 885w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/c83ae/pr-love-cover.png 1180w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/275bf/pr-love-cover.png 4973w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>Why your PR deserves some love</h2>
<p>You may wonder why you should spend time crafting a PR full of love. The reason is quite simple: <strong>your work, your reviewers, and you deserve it!</strong></p>
<h3>Your work deserves it</h3>
<p>Every line of code, every commit, every test is a unique piece of work. It deserves the best possible presentation. What’s the point of crafting something without put some care in its presentation? Give some love to your work presenting it in a way other people will appreciate it too.</p>
<p>Image to visit an art gallery. You have the chance to quickly chat with the author of the masterpiece you are observing and that you would like to buy: the amazing portrait of a dead tomato on a sunny beach. So full of meaning! You ask the author some information on how he had such an inspiration, and he answers: “Meh, I took some colours and I panted that”. Not the best way to sell the artwork, right?</p>
<p>With your PR is the same story: you cannot pretend others to appreciate your work if you don’t spend some time <strong>properly presenting it</strong>.</p>
<h3>Your reviewers deserve it</h3>
<p>Put yourself in the shoes of the reviewers. </p>
<p>Oh, a notification! Someone requested a review from me, great! Let me check…</p>
<ul>
<li>20 new files</li>
<li>15 modifications</li>
<li>5 files deleted</li>
<li>Title: updated module</li>
<li>Description: Updated the module to implement ticket 1234.</li>
</ul>
<p>What the f**k…</p>
<p>Back to the art gallery example. You are the critic that should provide a review of that famous “Sad Tomato in a Happy Place”, the masterpiece everyone is talking about. You go around the art gallery looking for it, and you find the artwork still in it’s packaging with a small label saying: “tomato”. To review it you would need to unpack the artwork, ask around for information about it, ask the author about his choices about the colours, etc. Doesn’t sound appealing, right?</p>
<p>Remember that <strong>the time of your reviewers is as much as valuable as yours</strong>. Also, it is quite hard to provide a proper review without having some context. <strong>Help your reviewers help you</strong>: give some love to your PR with a meaningful title and a proper description of what you have done. We will get back on this later…</p>
<h3>You deserve it</h3>
<p>You spent hours if not days working on a task. Several commits, tests, failures, and successes. Do you want to submit a PR without showing the care you put in your work? Without explaining the choices you made after several thoughts?</p>
<p>Back to the art gallery example. This time, you are the author of “Sad Tomato in a Happy Place”. It has been not easy to come up with such a complex masterpiece, for sure. You want people to appreciate your work, understand how hard you worked on that, all the passion you put in it. I think you won’t put the artwork in a dark corner, without a frame, just above the fire extinguisher, and near the ladies bathroom. You want to put it under the best possible light, with an amazing frame and in the most important place of the gallery.</p>
<p>You want to do the same with your PR. You deserve that your reviewers can <strong>understand and appreciate</strong> your work! Their review will be much better, and this will help YOU in providing even more value. As I said before: <strong>help them help YOU</strong>.</p>
<h2>How to give some love to your PR</h2>
<p>I think now we all agree that our PR deserves some love. How to do that? Well, it doesn’t require a lot of hard work, just to <strong>pay attention to details</strong>.</p>
<p><span>
      <a href="https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/6af66/pr-love-meme.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="meme" title="meme" src="https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/fcda8/pr-love-meme.png" srcset="https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/12f09/pr-love-meme.png 148w,
https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/e4a3f/pr-love-meme.png 295w,
https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/fcda8/pr-love-meme.png 590w,
https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/6af66/pr-love-meme.png 640w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Keep it small</h3>
<p>Please, <strong>keep your PR as small as possible</strong>. I understand that sometimes the task/feature requires a lot of work, but if it is possible please split it in smaller and very focused PRs. It will be easier for you to focus on that specific part of the business logic, and your reviewers will provide a better review. That’s a lot easier to understand the logic and provide feedback when you don’t have to look at 20 files.</p>
<h3>Give some ❤️ to commits too</h3>
<p>Commits are the building blocks of your PR, and <strong>they deserve some love as well</strong>. When you commit, provide useful information on what the commit is about. I won’t spend much time on this topic since you can find plenty of articles with good tips on the internet. I like the suggestions from Chris Beams that he describes in <a href="https://chris.beams.io/posts/git-commit/#imperative">this</a> nice article.</p>
<h3>First things first: the title</h3>
<p>The title of the PR is the first thing your reviewers will see and <strong>can provide a lot of useful information</strong>. Is it a feature? A fix? A simple chore? State that clearly in the title along with few words on the task the PR is focused on.</p>
<div data-language="text"><pre><code>Chore: upgrade log4j to version 2.3.4</code></pre></div>
<p>is a better title than</p>

<p>don’t you think?</p>
<h3>Provide a good description</h3>
<p>After the title, it comes the description. It is not important how you structure it, it can be a list of bullet points, a checklist, an informal description, a photo romance… what is important are <strong>the information you provide</strong>. In my humble opinion, the description should comprehend:</p>
<ul>
<li><strong>Topic</strong>: what are you trying to accomplish with this PR? How are you achieving your goal?</li>
<li><strong>Motivation</strong>: why are you submitting this PR? If it is related to a ticket/task, provide a link to it.</li>
<li><strong>Breaking changes</strong>: does this PR introduces some breaking changes? Why? Your reviewers may put extra attention if they know this PR will potentially break stuff.</li>
<li><strong>Additional information</strong>: is there any other information useful to know for the reviewer? An example may be the reasons behind a particular decision on a piece of code that may sound weird.</li>
</ul>
<p>Let me be clear and repeat it: it is not important the format, but the quality of information you provide with your description. If you can provide high-quality information in 3 lines of text, well, great!</p>
<h3>Make tests first-class citizens</h3>
<p>Did you test your PR? I assume (<em>hope</em>) you are used to doing it. Describe briefly what kind of tests you did, and if it is appropriate what is required to test the PR. I know that tests maybe are visible in the file list, but I think your reviewers will be happy to have a <strong>summary</strong>.</p>
<p>Also, a PR could be not just code that you can test explicitly. Suppose you added some scripts to the repo. The best thing you can do is to write the command you used to test it and copy &amp; paste the output. This is just an example, I am sure you can find others.</p>
<h3>Highlight dependencies</h3>
<p>Your PR may have dependencies as well as other tasks that should be done <em>after</em> it is merged. It can be another PR that should be merged before this one, a value that should be updated in the database, or some resources that should be cleaned because no more needed after the PR is merged. You should always <strong>state clearly the dependencies of your PR</strong>. Why? Well, first of all, this will be a good reminder for you! It will be also helpful to your reviewers, that will validate them as well as the PR itself.</p>
<h2>Conclusion</h2>
<p>Ok, guys, that’s it. I said it already, I didn’t want to provide a set of rules on how to do a PR. These are just some suggestion that I hope will be useful to you. Time to get back to your PRs and give them some ❤️!</p>
<p><em>photo by</em>  <a href="https://unsplash.com/@jamie452?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" title="Download free do whatever you want high-resolution photos from Jamie Street"><span><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewBox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"></path></svg></span><span>Jamie Street</span></a></p></section></div>]]>
            </description>
            <link>https://www.florio.dev/20200712-pr-love/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823554</guid>
            <pubDate>Mon, 13 Jul 2020 17:55:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Harold Lloyd Filmed "Safety Last!"]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23823505">thread link</a>) | @gus_massa
<br/>
July 13, 2020 | https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/ | <a href="https://web.archive.org/web/*/https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><a href="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg"><img data-attachment-id="2371" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg" data-orig-size="1853,2365" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="108 – T Lloyd Safety Last Tally’s Broadway Theatre below 2 crp" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=235" data-large-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=640" src="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=118&amp;h=150" alt="108 - T Lloyd Safety Last Tally's Broadway Theatre below 2 crp" width="118" height="150" srcset="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=118&amp;h=150 118w, https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=236&amp;h=300 236w" sizes="(max-width: 118px) 100vw, 118px"></a>The image of Harold Lloyd hanging desperately from the hands of a skyscraper clock during <em>Safety Last! </em>(1923) is one of the great icons of film history.&nbsp; Using maps, aerial views, and vintage photographs, my book <a href="http://www.amazon.com/Silent-Visions-Discovering-Hollywood-Through/dp/1595800573/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1330485203&amp;sr=1-1"><em>Silent Visions</em></a> shows how Harold filmed each of his five stunt-climbing comedies within the downtown Los Angeles Historic Core, while documenting the burgeoning urban skyline as it appears in the background of his films. [Note: <span>I will be introducing <em>Safety Last!</em> on June 25, 2016</span> at the Orpheum Theater as part of the Los Angeles Conservancy’s <a href="https://www.laconservancy.org/events/safety-last-orpheum-theatre">Last Remaining Seats</a>.]</p>
<div data-shortcode="caption" id="attachment_6143"><p><a href="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg"><img aria-describedby="caption-attachment-6143" data-attachment-id="6143" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/pan-04-9/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg" data-orig-size="1800,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="pan 04" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640" src="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640&amp;h=223" alt="On the roof of 908 S. Broadway from Safety Last! and the YouTube video clip" width="640" height="223" srcset="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640&amp;h=223 640w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=1278&amp;h=446 1278w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=150&amp;h=52 150w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=300&amp;h=105 300w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=768&amp;h=268 768w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=1024&amp;h=357 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-6143">The closing scene from <em>Safety Last!</em> (left) was filmed on the roof of 908 S. Broadway, the same building where the clock stunt climbing set was built. The same roof (right), now supporting the steel girder foundation for a large antennae, appears during the Criterion Collection <a href="http://youtu.be/tnrjyjKH5OU"><em>Locations and Effects</em> mini clip</a>.</p></div>
<p>The slides below show how the many <em>Safety Last!</em> stunts were created, and may be downloaded further below as a 14 MB PowerPoint presentation.&nbsp; You can also access a <a href="https://silentlocations.files.wordpress.com/2016/06/los-angeles-conservancy-harold-lloyd-safety-last-tour-bengtson-2016.pdf">self-guided walking tour</a> of the downtown locations appearing in <em>Safety Last!</em>, <em>Never Weaken, </em>and <em>Feet First. </em><a href="https://silentlocations.files.wordpress.com/2019/10/complete-list-of-all-harold-lloyd-stunt-climbing-buildings-updated-2019.pdf">(In all Lloyd employed 17 downtown buildings during his “thrill” comedies – see a PDF list of descriptions here</a><em><a href="https://silentlocations.files.wordpress.com/2019/10/complete-list-of-all-harold-lloyd-stunt-climbing-buildings-updated-2019.pdf">)</a>.<br>
</em></p>
<p>[Note: on the ground, Charlie Chaplin, Buster Keaton and Harold Lloyd <a href="https://silentlocations.com/chaplin-keaton-lloyd-alley/">filmed scenes from their masterpieces <em>The Kid</em> (1921), <em>Cops</em> (1922) and <em>Safety Last!</em> at the same Hollywood alley you can still visit today</a>.]</p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg"><img data-attachment-id="7315" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_01/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_01" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640&amp;h=480" alt="SL short blog_Page_01" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg"><img data-attachment-id="7316" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_02/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_02" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640&amp;h=480" alt="SL short blog_Page_02" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg"><img data-attachment-id="7317" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_03/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_03" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640&amp;h=480" alt="SL short blog_Page_03" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg"><img data-attachment-id="7318" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_04/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_04" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640&amp;h=480" alt="SL short blog_Page_04" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg"><img data-attachment-id="7319" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_05/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_05" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640&amp;h=480" alt="SL short blog_Page_05" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg"><img data-attachment-id="7320" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_06/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_06" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640&amp;h=480" alt="SL short blog_Page_06" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg"><img data-attachment-id="7321" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_07/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_07" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640&amp;h=480" alt="SL short blog_Page_07" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg"><img data-attachment-id="7322" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_08/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_08" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640&amp;h=480" alt="SL short blog_Page_08" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg"><img data-attachment-id="7323" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_09/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_09" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640&amp;h=480" alt="SL short blog_Page_09" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg"><img data-attachment-id="7324" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_10/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_10" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640&amp;h=480" alt="SL short blog_Page_10" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg"><img data-attachment-id="7325" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_11/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_11" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640&amp;h=480" alt="SL short blog_Page_11" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg"><img data-attachment-id="7326" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_12/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_12" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640&amp;h=480" alt="SL short blog_Page_12" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg"><img data-attachment-id="7327" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_13/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_13" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640&amp;h=480" alt="SL short blog_Page_13" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p>Here is the link to download the PowerPoint.&nbsp; Most of the slides are animated, so wait a moment each time before clicking the “next” button.</p>
<div data-shortcode="caption" id="attachment_2367"><p><a href="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg"><img aria-describedby="caption-attachment-2367" data-attachment-id="2367" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/untitled/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg" data-orig-size="609,644" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Untitled" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=284" data-large-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=609" title="Untitled" src="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=283&amp;h=300" alt="" width="283" height="300" srcset="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=283&amp;h=300 283w, https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=566&amp;h=600 566w, https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=142&amp;h=150 142w" sizes="(max-width: 283px) 100vw, 283px"></a></p><p id="caption-attachment-2367">The recent multiple Oscar-winning movie <em>Hugo</em> pays tribute to <em>Safety Last!</em>; first by including a clip of the Lloyd movie within the film, and also when the young hero Hugo Cabret finds himself hanging from a train station clock. <em>Hugo</em> (C) 2011 Paramount Pictures</p></div>
<p><a href="https://silentlocations.files.wordpress.com/2012/02/how-harold-lloyd-filmed-safety-last-by-john-bengtson.ppt">How Harold Lloyd Filmed Safety Last by John Bengtson</a></p>
<p>You will need a PowerPoint viewer to watch the show, and can download a PowerPoint viewer at this <a href="http://www.microsoft.com/downloads/en/details.aspx?displaylang=en&amp;FamilyID=cb9bf144-1076-4615-9951-294eeb832823">site</a>.</p>
<p>You can also check out <a href="https://silentlocations.wordpress.com/category/safety-last/">my other posts about <em>Safety Last! </em>here</a>.</p>
<p>A short segment from the <em>Locations and Effects</em> 2013 documentary with Academy-Award winning effects supervisor Craig Barron and the author filmed for the <a href="http://www.criterion.com/films/28446-safety-last">Criterion Collection release of the <em>Safety Last!</em> Blu-ray </a>appears below.</p>
<p><span><iframe width="560" height="315" src="https://www.youtube.com/embed/tnrjyjKH5OU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p><p><span>To see where Harold filmed his amazing comedies, be sure to check out my book <a href="https://www.amazon.com/Silent-Visions-Discovering-Hollywood-Through/dp/1595800573/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1533680311&amp;sr=1-1&amp;keywords=john+bengtson+silent"><em>Silent Visions</em></a>.&nbsp; </span></p>
<p><span>If you need a good laugh, or want to raise your spirits, just listen to Michael Mortilla’s audio-only recording of the audience laughing and squealing with delight while watching <em>Safety Last!</em>&nbsp; It’s great to play as background music <span>– the swells and squeals of laughter just grow and grow.</span></span></p>
<p><a href="http://www.midilifecrisis.com/Music_and_Sound/SafetyLast_Audience_Michael_Mortilla_Piano.mp3">Michael Mortilla accompanying Safety Last!</a></p>
<p>HAROLD LLOYD images and the names of Mr. Lloyd’s films are all trademarks and/or service marks of Harold Lloyd Entertainment Inc. Images and movie frame images reproduced courtesy of The Harold Lloyd Trust and Harold Lloyd Entertainment Inc.</p>
<p><img data-attachment-id="15216" data-permalink="https://silentlocations.com/chaplin-keaton-lloyd-alley/chaplin-keaton-lloyd-sign/" data-orig-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg" data-orig-size="1570,211" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Chaplin-Keaton-Lloyd-sign" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640" src="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640" alt="Chaplin-Keaton-Lloyd-sign" srcset="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640 640w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=1280 1280w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=150 150w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=300 300w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=768 768w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p>Please help support naming the <a href="https://silentlocations.com/chaplin-keaton-lloyd-alley/">Chaplin Keaton Lloyd alley</a> in Hollywood by posting a review on <a href="https://goo.gl/maps/NGK6JpvncU3ejLDX7">Google Maps</a>. Prototype alley sign design by noted Dutch graphic artist – <a href="http://pietschreuders.com/">Piet Schreuders</a>. Download a 4-page brochure <a href="https://silentlocations.files.wordpress.com/2020/02/honor-the-chaplin-keaton-lloyd-alley.pdf">HERE</a>.</p>
<p>The site of the clock set, built on the roof of 908 S. Broadway on Google Maps.</p>

											</div></div>]]>
            </description>
            <link>https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823505</guid>
            <pubDate>Mon, 13 Jul 2020 17:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I started working in the cloud in a matter of days]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823272">thread link</a>) | @markothedev
<br/>
July 13, 2020 | https://microtica.com/an-outstanding-cloud-automation-experience/ | <a href="https://web.archive.org/web/*/https://microtica.com/an-outstanding-cloud-automation-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p><a href="https://microtica.com/" target="_blank" rel="noreferrer noopener">Microtica</a> has the goal to provide the best cloud automation experience for developers from its very beginnings. We are so happy when we hear a success story, especially from developers who weren’t familiar with cloud automation previously.&nbsp;</p>



<p>This is why we decided to bring to you a series of interviews with our customers that experience the benefits of our solution. They jumped into a whole new world in a matter of days instead of months. </p>



<p>We are calling it: <strong>Developers Say.&nbsp;</strong></p>



<p>The first developer we talked to is Marko, a full-stack developer from <a href="https://vertt.ch/">Vertt</a>.&nbsp;</p>



<p><em>You can read more about how Vertt accelerated its DevOps processes with Microtica <a href="https://microtica.com/case-studies/accelerating-devops-processes/" target="_blank" rel="noreferrer noopener">here</a>.</em></p>



<h2><strong>What’s the product you’re developing?</strong></h2>



<p><a href="https://vertt.ch/">Vertt</a> is a Swiss ride-hailing startup that provides a reliable, responsible and secure transportation experience. As a service, Vertt wants to fill in the voids that exist in the Swiss transportation system. We innovate all the time, in order to provide society with a one-stop mobility solution.&nbsp;</p>



<h2><strong>Which technologies did you use when developing the solution?&nbsp;</strong></h2>



<p>You could say we actually have <strong>five applications</strong>. Four are mobile-native iOS and Android applications, two for the passenger experience, and two are for the drivers. We also have <strong>one web application </strong>which is the admin panel for our business team, developed in Angular.</p>



<p>As for the backend and infrastructure part, the solution is built on the latest <strong>microservice technology with AWS as a cloud provider</strong>. The backend is developed in Node.js.&nbsp;</p>



<div><figure><img src="https://media-exp1.licdn.com/dms/image/C5603AQFmUaDjB8TNSg/profile-displayphoto-shrink_800_800/0?e=1599696000&amp;v=beta&amp;t=5D8Bl17XcfwZ91kQIRTsD-_mg_ag4O9jwwGWIAs4Nuc" alt=""><figcaption>Marko from Vertt</figcaption></figure></div>



<h2><strong>Can you tell us about your background as a developer?&nbsp;</strong></h2>



<p>I am a full-stack developer with two years of experience. Vertt is my first major project and my first time working on a project of this magnitude. This project is where <strong>I gained most of my knowledge and learned about the big picture.</strong> I’m developing <strong>the backend logic in NodeJS</strong> for the entire system. I’m also working on the dashboard for our business team in Angular. I’ve worked on just a few projects prior to this. They were mostly small websites that didn’t require a backend component or scalability features.</p>



<h2><strong>Why did you choose a microservice infrastructure for this particular project?</strong></h2>



<p>We often see startups <a href="https://microtica.com/why-transition-from-monolith-to-microservices/" target="_blank" rel="noreferrer noopener">kicking off with a monolithic application</a> just to get something out there. However, when they expand, they face <strong>various problems related to scalability and continuous integration</strong>.&nbsp;</p>



<p><em>We wanted to do it the right way. </em>The <a href="https://microtica.com/everything-about-microservices/" target="_blank" rel="noreferrer noopener">benefits of the microservice architecture</a> are well-known. <strong>Different codebases, separate deployable units performing separate functionalities</strong>, and the most important for us—<strong>scaling individually</strong>.&nbsp;</p>



<h2><strong>How did you deliver software before discovering Microtica?</strong></h2>



<p>We started using <strong>Jenkins </strong>as part of our DevOps process. As our team consists of full-stack and mobile developers, we were really <strong>struggling with all the setup and integration of numerous plug-ins.</strong> We were using Jenkins as a build orchestration tool. We soon became very <strong>limited by the release management</strong> that Jenkins has to offer. Issues like access control management, configuration usability, and scaling began to overwhelm us and defocus us from our daily tasks.</p>



<p>As the team began to grow, tracking and accountability of various team members became a great issue. As we did most deployments and builds via a single user,<strong> tracking was only at the code level </strong>through our source control tool Git.&nbsp;</p>



<h2><strong>What was the biggest challenge you had as a developer working with cloud automation?</strong></h2>



<p>The main challenge for any beginner or intermediate developer is <strong>connecting all pieces together </strong>and making them work as one. Understanding how the entire system is designed and managed behind the curtain in the cloud is a continuous process that consists of <strong>constant learning and hands-on effort.</strong> Coming across stuff like cloud automation, scaling, and continuous delivery is always challenging, especially if you don’t have much experience to get started.&nbsp;</p>



<h2><strong>How did Microtica help you overcome these challenges?</strong></h2>



<p>Microtica made deploying our entire system extremely<strong> easy and effortless.</strong> With just a few clicks and a few extra files, we set up and deployed our entire system consisting of 13 microservices.&nbsp;</p>



<p>After <a href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank" rel="noreferrer noopener">setting up our initial development environment</a> <strong>it only took us one hour to get the test and production environments up and running.</strong> For this, we used the Clone Environment feature. This was really important to us because we wanted to fully migrate to Microtica before going to production.</p>



<p>The integration went <strong>smoothly and pretty fast</strong>. We only needed to create a couple of files in each microservice to create and guide the deployment pipeline. Now we can change parameters and redeploy our services within minutes and with almost no downtime.</p>



<p>It was extremely helpful that we could use their ready-to-use components. This eliminated the need to write complex CloudFormation templates for simple AWS resources. It allowed us to reuse the components by using just the UI.</p>



<h2><strong>How did Microtica help you grow as a developer?</strong></h2>



<p>Before working with Microtica, I didn’t have much experience and knowledge in the cloud automation space. Microtica gave me <strong>an initial push</strong>.  It made me confident enough to <strong>set up and maintain a fully functional system with three environments.</strong> I could create custom infrastructure and deploy microservices in the cloud <strong>in a matter of days.</strong> It allowed me to focus more on the actual development and less on infrastructure maintenance.</p>



<h2><strong>What kind of challenges are ahead of you and your team?</strong></h2>



<p>Our system is expanding on a daily basis along with its complexity. With a new feature every month, it’s crucial for us to have a firm grasp of<strong> the entire system at any time</strong>. Since we made a production release, <strong>stability has become our number one priority.</strong> It’s also probably the biggest challenge that we will face in the future.</p>



<figure><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101"><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg" alt="Start with cloud automation" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-300x180.jpg 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-768x461.jpg 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1536x922.jpg 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-667x400.jpg 667w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01.jpg 2000w" sizes="100vw"></a></figure>



<h2><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101" target="_blank" rel="noreferrer noopener">Sign up for Microtica</a> and start with cloud automation today.</h2>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:identifier="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:title="Developers Say: An Outstanding Cloud Automation Experience"
    trackback:ping="https://microtica.com/an-outstanding-cloud-automation-experience/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/an-outstanding-cloud-automation-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823272</guid>
            <pubDate>Mon, 13 Jul 2020 17:31:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling WebSocket in Go and Beyond]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23823132">thread link</a>) | @FZambia
<br/>
July 13, 2020 | https://centrifugal.github.io/centrifugo/blog/scaling_websocket/ | <a href="https://web.archive.org/web/*/https://centrifugal.github.io/centrifugo/blog/scaling_websocket/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              

                
                  <a href="https://github.com/centrifugal/centrifugo/edit/master/docs/content/blog/scaling_websocket.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                  
                
                
                
<p><img alt="gopher-broker" src="https://i.imgur.com/QOJ1M9a.png"></p>
<p>I believe that in 2020 WebSocket is still an entertaining technology which is not so well-known and understood like HTTP. In this blog post I'd like to tell about state of WebSocket in Go language ecosystem, and a way we could write scalable WebSocket servers with Go and beyond Go.</p>
<p>We won't talk a lot about WebSocket transport pros and cons – I'll provide links to other resources on this topic. Most advices here are generic enough and can be easily approximated to other programming languages. Also in this post we won't talk about ready to use solutions (if you are looking for it – check out <a href="https://www.leggetter.co.uk/real-time-web-technologies-guide/">Real-time Web Technologies guide</a> by Phil Leggetter), just general considerations. There is not so much information about scaling WebSocket on the internet so if you are interested in WebSocket and real-time messaging technologies - keep on reading.</p>
<p>If you don't know what WebSocket is – check out the following curious links:</p>
<ul>
<li><a href="https://hpbn.co/websocket/">https://hpbn.co/websocket/</a> – a wonderful chapter of great book by Ilya Grigorik</li>
<li><a href="https://lucumr.pocoo.org/2012/9/24/websockets-101/">https://lucumr.pocoo.org/2012/9/24/websockets-101/</a> – valuable thoughts about WebSocket from Armin Ronacher</li>
</ul>
<p>As soon as you know WebSocket basics – we can proceed.</p>
<h2 id="websocket-server-tasks">WebSocket server tasks<a href="#websocket-server-tasks" title="Permanent link">¶</a></h2>
<p>Speaking about scalable servers that work with many persistent WebSocket connections – I found several important tasks such a server should be able to do:</p>
<ul>
<li>Maintain many active connections</li>
<li>Send many messages to clients</li>
<li>Support WebSocket fallback to scale to every client</li>
<li>Authenticate incoming connections and invalidate connections</li>
<li>Survive massive reconnect of all clients without loosing messages</li>
</ul>
<div>
<p>Note</p>
<p>Of course not all of these points equally important in various situations.</p>
</div>
<p>Below we will look at some tips which relate to these points.</p>
<p><img alt="one_hour_scale" src="https://i.imgur.com/4lYjJSP.png"></p>
<h2 id="websocket-libraries">WebSocket libraries<a href="#websocket-libraries" title="Permanent link">¶</a></h2>
<p>In Go language ecosystem we have several libraries which can be used as a building block for a WebSocket server.</p>
<p>Package <a href="https://godoc.org/golang.org/x/net/websocket">golang.org/x/net/websocket</a> is considered <strong>deprecated</strong>.</p>
<p>The default choice in the community is <a href="https://github.com/gorilla/websocket">gorilla/websocket</a> library. Made by Gary Burd (who also gifted us an awesome <a href="https://github.com/gomodule/redigo">Redigo</a> package to communicate with Redis) – it's widely used, performs well, has a very good API – so in most cases you should go with it. Some people think that library not actively maintained at moment – but this is not quite true, it implements full WebSocket RFC, so actually it can be considered done.</p>
<p>In 2018 my ex-colleague Sergey Kamardin open-sourced <a href="https://github.com/gobwas/ws">gobwas/ws</a> library. It provides a bit lower-level API than <code>gorilla/websocket</code> thus allows reducing RAM usage per connection and has nice optimizations for WebSocket upgrade process. It does not support WebSocket <code>permessage-deflate</code> compression but otherwise a good alternative you can consider using. If you have not read Sergey's famous post <a href="https://www.freecodecamp.org/news/million-websockets-and-go-cc58418460bb/">A Million WebSockets and Go</a> – make a bookmark!</p>
<p>One more library is <a href="https://github.com/nhooyr/websocket">nhooyr/websocket</a>. It's the youngest one and actively maintained. It compiles to WASM which can be a cool thing for someone. The API is a bit different from what <code>gorilla/websocket</code> offers, and one of the big advantages I see is that it solves a problem with a proper WebSocket closing handshake which is <a href="https://github.com/gorilla/websocket/issues/448">a bit hard to do right with Gorilla WebSocket</a>.</p>
<p>You can consider all listed libraries except one from <code>x/net</code> for your project. Take a library, follow its examples (make attention to goroutine-safety of various API operations). Personally I prefer Gorilla WebSocket at moment since it's feature-complete and battle tested by tons of projects around Go world.</p>
<h2 id="os-tuning">OS tuning<a href="#os-tuning" title="Permanent link">¶</a></h2>
<p>OK, so you have chosen a library and built a server on top of it. As soon as you put it in production the interesting things start happening.</p>
<p>Let's start with several OS specific key things you should do to prepare for many connections from WebSocket clients.</p>
<p>Every connection will cost you an open file descriptor, so you should tune a maximum number of open file descriptors your process can use. An errors like <code>too many open files</code> raise due to OS limit on file descriptors which is usually 256-1024 by default (see with <code>ulimit -n</code> on Unix). A nice overview on how to do this on different systems can be found <a href="https://docs.riak.com/riak/kv/2.2.3/using/performance/open-files-limit.1.html">in Riak docs</a>. Wanna more connections? Make this limit higher.</p>
<p>Nice tip here is to limit a maximum number of connections your process can serve – making it less than known file descriptor limit:</p>
<div><pre><span></span><code><span>//&nbsp;ulimit&nbsp;-n&nbsp;==&nbsp;65535</span>
<span>if</span> <span>conns</span><span>.</span><span>Len</span><span>()</span> <span>&gt;=</span> <span>65500</span> <span>{</span>
    <span>return</span> <span>errors</span><span>.</span><span>New</span><span>(</span><span>"connection&nbsp;limit&nbsp;reached"</span><span>)</span>
<span>}</span>
<span>conns</span><span>.</span><span>Add</span><span>(</span><span>conn</span><span>)</span>
</code></pre></div>

<p>– otherwise you have a risk to not even able to look at <code>pprof</code> when things go bad. And you always need monitoring of open file descriptors.</p>
<p>Keep attention on <em>Ephemeral ports</em> problem which is often happens between your load balancer and your WebSocket server. The problem arises due to the fact that each TCP connection uniquely identified in the OS by the 4-part-tuple:</p>
<div><pre><span></span><code>source ip | source port | destination ip | destination port
</code></pre></div>

<p>On balancer/server boundary you are limited in 65536 possible variants by default. But actually due to some OS limits and sockets in TIME_WAIT state the number is even less. A very good explanation and how to deal with it can be found <a href="https://making.pusher.com/ephemeral-port-exhaustion-and-how-to-avoid-it/">in Pusher blog</a>.</p>
<p>Your possible number of connections also limited by conntrack table. Netfilter framework which is part of iptables keeps information about all connections and has limited size for this information. See how to see its limits and instructions to increase <a href="https://morganwu277.github.io/2018/05/26/Solve-production-issue-of-nf-conntrack-table-full-dropping-packet/">in this article</a>.</p>
<p>One more thing you can do is tune your network stack for performance. Do this only if you understand that you need it. Maybe start <a href="https://gist.github.com/mustafaturan/47268d8ad6d56cadda357e4c438f51ca">with this gist</a>, but don't optimize without full understanding why you are doing this. </p>
<h2 id="sending-many-messages">Sending many messages<a href="#sending-many-messages" title="Permanent link">¶</a></h2>
<p>Now let's speak about sending many messages. The general tips follows.</p>
<p><strong>Make payload smaller</strong>. This is obvious – fewer data means more effective work on all layers. BTW WebSocket framing overhead is minimal and adds only 2-8 bytes to your payload. You can read detailed dedicated research in <a href="https://crossbario.com/blog/Dissecting-Websocket-Overhead/">Dissecting WebSocket's Overhead</a> article. You can reduce an amount of data traveling over network with <code>permessage-deflate</code> WebSocket extension, so your data will be compressed. Though using <code>permessage-deflate</code> is not always a good thing for server due to <a href="https://github.com/gorilla/websocket/issues/203">poor performance of flate</a>, so you should be prepared for a CPU and RAM resource usage on server side. While Gorilla WebSocket has a lot of optimizations internally by reusing flate writers, overhead is still noticeable. The increase value heavily depends on your load profile.</p>
<p><strong>Make less system calls</strong>. Every syscall will have a constant overhead, and actually in WebSocket server under load you will mostly see read and write system calls in your CPU profiles. An advice here – try to use client-server protocol that supports message batching, so you can join individual messages together.</p>
<p><strong>Use effective message serialization protocol</strong>. Maybe use code generation for JSON to avoid extensive usage of reflect package done by Go std lib. Maybe use sth like <a href="https://github.com/gogo/protobuf">gogo/protobuf</a> package which allows to speedup Protobuf marshalling and unmarshalling. Unfortunately Gogo Protobuf <a href="https://github.com/gogo/protobuf/issues/691">is going through hard times
</a> at this moment. Try to serialize a message only once when sending to many subscribers.</p>
<p><strong>Have a way to scale to several machines</strong> - more power, more possible messages. We will talk about this very soon.</p>
<h2 id="websocket-fallback-transport">WebSocket fallback transport<a href="#websocket-fallback-transport" title="Permanent link">¶</a></h2>
<p><img alt="ie" src="https://i.imgur.com/IAOyvmg.png"></p>
<p>Even in 2020 there are still users which cannot establish connection with WebSocket server. Actually the problem mostly appears with browsers. Some users still use old browsers. But they have a choice – install a newer browser. Still, there could also be users behind corporate proxies. Employees can have a trusted certificate installed on their machine so company proxy can re-encrypt even TLS traffic. Also, some browser extensions can block WebSocket traffic.</p>
<p>One ready solution to this is <a href="https://github.com/igm/sockjs-go/">Sockjs-Go</a> library. This is a mature library that provides fallback transport for WebSocket. If client does not succeed with WebSocket connection establishment then client can use some of HTTP transports for client-server communication: <a href="https://hpbn.co/server-sent-events-sse/">EventSource aka Server-Sent Events</a>, XHR-streaming, Long-Polling etc. The downside with those transports is that to achieve bidirectional communication you should use sticky sessions on your load balancer since SockJS keeps connection session state in process memory. We will talk about many instances of your WebSocket server very soon.</p>
<p>You can implement WebSocket fallback yourself, this should be simple if you have a sliding window message stream on your backend which we will discuss very soon.</p>
<p>Maybe look at <a href="https://grpc.io/docs/what-is-grpc/introduction/">GRPC</a>, depending on application it could be better or worse than WebSocket – in general you can expect a better performance and less resource consumption from WebSocket for bidirectional communication case. My measurements for a <strong>bidirectional</strong> scenario showed 3x win for WebSocket (binary + GOGO protobuf) in terms of server CPU consumption and 4 times less RAM per connection. Though if you only need RPC then GRPC can be a better choice. But you need additional proxy to work with GRPC from a browser. </p>
<h2 id="performance-is-not-scalability">Performance is not scalability<a href="#performance-is-not-scalability" title="Permanent link">¶</a></h2>
<p>You can optimize client-server protocol, tune your OS, but at some point you won't be able to use only one process on one server machine. You need to scale connections and work your server does over different server machines. Horizontal scaling is also good for a server high availability. Actually there are some sort of real-time applications where a single isolated process makes sense - for example multiplayer games where limited number of players play independent game rounds.</p>
<p><img alt="many_instances" src="https://i.imgur.com/8ElqpjI.png"></p>
<p>As soon as you distribute connections over several machines you have to find a way to deliver a message to a certain user. The basic …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://centrifugal.github.io/centrifugo/blog/scaling_websocket/">https://centrifugal.github.io/centrifugo/blog/scaling_websocket/</a></em></p>]]>
            </description>
            <link>https://centrifugal.github.io/centrifugo/blog/scaling_websocket/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823132</guid>
            <pubDate>Mon, 13 Jul 2020 17:19:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SemVer Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23823043">thread link</a>) | @aaronblohowiak
<br/>
July 13, 2020 | https://jolynch.github.io/posts/semver_considered_harmful/ | <a href="https://web.archive.org/web/*/https://jolynch.github.io/posts/semver_considered_harmful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>In the past ten years or so, <a href="https://semver.org/">Semantic Versioning</a> a.k.a
“SemVer” has become extremely popular in the software development world. The
idea is that libraries and services can convey information to users about how
the application programming interface
(<a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a>) of
that library/package/service is evolving just using the version number. This
information is conveyed through three dotted numbers that form a logical clock
for totally ordering changes to the software API:</p>

<center><h3>Semantic Version Numbers</h3></center>
<div><pre><code data-lang="text">====================== Specification ========================

Version = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;

Major: this number goes up when the public API breaks
Minor: this number goes up when the public API changes
Patch: this number goes up when the public API doesn't change

====================== Examples =============================

# A Minor API change happened, safe to upgrade
1.4.5 -&gt; 1.5.0

# API breakage, probably unsafe to upgrade
1.7.0 -&gt; 2.0.0

# Who knows what will happen
0.182.13 -&gt; 0.182.14
=============================================================</code></pre></div>

<p>Armed with this information, software developers can theoretically upgrade
without fear of the new version breaking their code.</p>



<p>I believe that this versioning scheme, in practice, is problematic and creates
a large amount of pain in our industry. Three concrete failure modes I witness
frequently are:</p>

<ol>
<li>Most packaging systems (deb, rpm, python, ruby, java, etc …) cannot
simultaneously install multiple major versions of the same package name.
This often leaves users unable to upgrade to the latest major version due to
(reasonable) fear of breakages.</li>
<li>Frequent major version bumps frequently break functional code, leading
to <a href="https://en.wikipedia.org/wiki/Dependency_hell">dependency hell</a> where
library/service authors mix and match min, max, and exact version pins on
major versions to try to work around various incompatibilities. These pins
inevitably conflict.</li>
<li>There is still no standard way to derive the source code which produced the
artifact or seeing the difference between two versions. This makes it hard
to verify how the API is breaking or whether it will break specific usage
patterns.</li>
</ol>

<p>There is also the somewhat annoying issue of the plethora of <code>0.X</code> artifacts,
which happen because developers, somewhat reasonably, don’t want to release
a public API they will have to stand behind until they can be certain they
can.</p>

<p>Ultimately these factors lead to software developers, myself included, viewing
dependency upgrades with great trepidation. Quite reasonably developers defend
themselves from breakage by either not upgrading their dependencies (unless
they are forced to), vendoring dependent code, or skipping dependencies all
together and just writing it themselves.</p>

<h2 id="reduce-the-fear-breaking-versions-must-cohabitate">Reduce the Fear: Breaking Versions Must Cohabitate</h2>

<p>The use of the major version number in SemVer to indicate API breakage is by
far the most problematic aspect of the design. In an ideal world, packaging
systems and programming languages would automatically namespace different major
versions, and code that depends on a particular major version would have all
references specifically reference the major version namespace. Unfortunately,
we do not live in an ideal world and most packaging systems simply don’t
support this.  Three examples that I personally struggle with frequently:</p>

<p><strong>Debian packages (<code>apt</code>/<code>aptitude</code> in particular)</strong>: You only get one version
and the higher one is almost always chosen even if that may break less-than
pins. A common practice with debian packages to work around these limitations
is to release new packages with a different name.</p>

<p><strong>Java libraries (<code>mvn</code>/<code>gradle</code> in particular)</strong>: In a given class path you
can only have one implementation of a given package. Even if you manage to
convince gradle or maven to pull down multiple versions of a <code>.jar</code>, good luck
getting the JVM to not pick one implementation arbitrarily. As a result, Java
developers often resort to hacks like
<a href="https://imperceptiblethoughts.com/shadow/">package path rewriting</a>.</p>

<p><strong>Python libraries (<code>pip</code> in particular)</strong>: While the Python community has
moved towards isolated virtual environments which does make this issue slightly
less of an issue (and with tools like <code>docker</code> or
<a href="https://github.com/spotify/dh-virtualenv"><code>dhvirtualenv</code></a> it gets even
better), you still can’t install multiple versions of the same package in the
same virtualenv. Most Python projects I am aware of either don’t work around
this and break all the things, or release multiple package names.</p>

<p>These problems are even worse for client libraries, where the library is wrapping a
remote (often backwards incompatible) API change. For me this has been one of the
hardest parts of upgrading distributed datastores that I work on because we
often can’t use the vanilla client libraries during migration (e.g.
<a href="https://curator.apache.org/">Curator</a> 2 vs Curator 4, Elasticsearch 2 vs 5,
etc …). In my experience with most client library upgrades you have to create
an internal company fork that renames and relocates the package so we can run
both datastore APIs at the same time and have the client gracefully migrate
from the old version to the new one.</p>

<p>In an ideal world, remote APIs would remain backwards compatible for at least a
single major version to give users an upgrade path, but I find that many
developers argue that they don’t need to remain backwards compatible across a
major version (this is what SemVer says after all …). I wish this argument
was soundly rejected.</p>

<p>How can we fix this problem given the current constraints we operate under?
Well, we are left with a reasonably simple option: <strong>put the API version
semantics in the name of the package.</strong> Some example API migrations where I
have been able to take advantage of this technique are:</p>

<ul>
<li><code>boto</code> to <code>boto3</code> (Python,
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">docs</a>):
An extremely prevalent library for accessing AWS services</li>
<li><code>elasticsearch</code> to <code>elasticsearch2</code> (Python, <a href="https://github.com/elastic/elasticsearch-py/issues/515">motivation</a>): A Python client library for the
Elasticsearch search engine.</li>
<li>Every Linux kernel package ever (the Linux kernel has this figured out!). The
Kernel not only prohibits breaking user-space, but they give their users a
great way to install multiple kernels at the same time.</li>
<li>Cassandra’s Thrift API
(<a href="https://github.com/Netflix/Astyanax">Netflix Astyanax</a>)
to Cassandra’s CQL API
(<a href="https://github.com/datastax/java-driver">Datastax Java Driver</a>): The client
drivers for the Cassandra database.</li>
</ul>

<h2 id="reduce-the-fear-binary-versions-can-be-traced-to-source">Reduce the Fear: Binary Versions Can be Traced to Source</h2>

<p>In my experience, software engineers spend a non trivial amount of time trying
to figure out “what actually changed between these two released versions”. One
of the explicit goals of <code>SemVer</code> was to help developers reason about change.
As a developer myself I accidentally break things in minor versions all the
time, so I understand that this can happen. I don’t mind the breakage as much
as being unable to debug what broke, since projects use many different ways of
relating released versions to code.</p>

<p>Some projects do use <a href="https://git-scm.com/book/en/v2/Git-Basics-Tagging">git
tags</a> to achieve this
auditability, but this isn’t mandatory so some (many?) projects don’t do it.
The commit id may, in some cases, be a better identifier since the commit id
must exist and <code>git</code> has a really easy way to view <a href="https://git-scm.com/docs/git-diff">changes between two
commits</a>. In fact, as far as I know, the
commit id is always easily comparable in practically every source control
system.</p>

<p><a href="https://en.wikipedia.org/wiki/Changelog">Changelogs</a> are also <em>nice</em>, but
while I can typically assume projects use source control since it is strictly
easier than not using source control, I don’t think it is reasonable to expect
developers, often working for free, to take the time to summarize their
software changes into English changelogs. Writing clear and actionable English
is difficult, potentially more difficult than the code itself. Certainly, I
appreciate every project maintainer who takes the time to summarize changes in
a release, but I don’t think it’s fair to <em>expect</em> it in the same way most
consumers of software expect producers to use source control.</p>



<p>Both of these problems can be remedied with a straightforward evolution to
<code>SemVer</code> in which we make some small changes to include a great deal more
semantic information in the package name and version number. I call it
semantic package names and it consists of two changes:</p>

<ol>
<li>Use package (=module) names to indicate an API has broken, not versions.</li>
<li>Attempt to include a source identifier in the version.</li>
</ol>

<p>For example, <code>elasicsearch5</code> is the python library that functions with the
Elasticsearch server version 5.  Applications such as Elasticsearch or
Cassandra release named packages that unambiguously communicate the major
version API that is supported by that package. One possible example for Apache
Cassandra might be <code>cassandra-21x</code>, <code>cassandra-30x</code>, <code>cassandra-311x</code>, and
<code>cassandra-40x</code> for the <code>2.1</code>, <code>3.0</code>, <code>3.11</code>, <code>4.0</code> branches respectively.</p>

<p>I know this is not new, many software projects already follow this kind of scheme
such as the Linux kernel (a.k.a “Never break userspace”) or the Go
<a href="https://golang.org/cmd/go/#hdr-Module_compatibility_and_semantic_versioning">programming language</a>.
I just believe that if every software project and language I interacted with
followed this pattern the whole industry would become more efficient and spend
less time fearing dependency updates. I have also found myself using this
technique internally to every company I’ve worked at to manage software change.</p>

<p>In addition to using semantic package names, I prefer when packages include a
fourth piece of metadata in their version number indicating the source version
that produced the artifact. Depending on the packaging system this is usually
either another dotted version (making it a four-tuple) or a <code>-</code> suffix.</p>

<center><h3> Better Semantic Versioning </h3></center>

<div><pre><code data-lang="text">====================== Specification ========================
&lt;Package Version&gt; = &lt;Package Name&gt;:&lt;Version Number&gt;
&lt;Version Number&gt;  = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;&lt;Identifier&gt;

Package Name: This name changes when the public API breaks
Major: this number goes up with "major" public API additions
Minor: this number goes up with "minor" public API additions
Patch: this number goes up on every release
Identifier: For packaging systems that support it, this
            string relates directly to a specific source
            code that produced the artifact.

An example of an identifier in git would be the first 8</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jolynch.github.io/posts/semver_considered_harmful/">https://jolynch.github.io/posts/semver_considered_harmful/</a></em></p>]]>
            </description>
            <link>https://jolynch.github.io/posts/semver_considered_harmful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823043</guid>
            <pubDate>Mon, 13 Jul 2020 17:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Econometrics with R]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823031">thread link</a>) | @ethanwillis
<br/>
July 13, 2020 | https://www.econometrics-with-r.org/index.html | <a href="https://web.archive.org/web/*/https://www.econometrics-with-r.org/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">
<p>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span>selecting it with the cursor</span> and then click the <i></i> on the pop-up menu. You can also see the annotations of others: click the <i></i> in the upper right hand corner of the page 
</p>

<div id="preface">

<hr>
<center>
<img src="https://www.econometrics-with-r.org/images/cover.png">
</center>
<div><p> Chair of Econometrics <img src="https://www.econometrics-with-r.org/images/logo_claim_en_rgb.png"> <br> Department of Business Administration and Economics <br> University of Duisburg-Essen <br> Essen, Germany <br> <a href="https://www.econometrics-with-r.org//%22mailto:info@econometrics-with-r.org?subject=Econometrics%20with%20R\%22">info@econometrics-with-r.org</a></p><p> Last updated on Friday, August 30, 2019
</p>
</div>
<hr>
<p>Over the recent years, the statistical programming language R has become an integral part of the curricula of econometrics classes we teach at the University of Duisburg-Essen. We regularly found that a large share of the students, especially in our introductory undergraduate econometrics courses, have not been exposed to any programming language before and thus have difficulties to engage with learning R on their own. With little background in statistics and econometrics, it is natural for beginners to have a hard time understanding the benefits of having R skills for learning and applying econometrics. These particularly include the ability to conduct, document and communicate empirical studies and having the facilities to program simulation studies which is helpful for, e.g., comprehending and validating theorems which usually are not easily grasped by mere brooding over formulas. Being applied economists and econometricians, all of the latter are capabilities we value and wish to share with our students.</p>
<p>Instead of confronting students with pure coding exercises and complementary classic literature like the book by <span>Venables &amp; Smith (<a href="#ref-venables2010" role="doc-biblioref">2010</a>)</span>, we figured it would be better to provide interactive learning material that blends R code with the contents of the well-received textbook <em>Introduction to Econometrics</em> by <span>Stock &amp; Watson (<a href="#ref-stock2015" role="doc-biblioref">2015</a>)</span> which serves as a basis for the lecture. This material is gathered in the present book <em>Introduction to Econometrics with R</em>, an empirical companion to <span>Stock &amp; Watson (<a href="#ref-stock2015" role="doc-biblioref">2015</a>)</span>. It is an interactive script in the style of a reproducible research report and enables students not only to learn how results of case studies can be replicated with R but also strengthens their ability in using the newly acquired skills in other empirical applications.</p>
<div id="conventions-used-in-this-book">
<h4>Conventions Used in this Book</h4>
<ul>
<li><p><em>Italic</em> text indicates new terms, names, buttons and alike.</p></li>
<li><p><tt>Constant width text</tt> is generally used in paragraphs to refer to <tt>R</tt> code. This includes commands, variables, functions, data types, databases and file names.</p></li>
<li><p><code>Constant width text on gray background</code> indicates <tt>R</tt> code that can be typed literally by you. It may appear in paragraphs for better distinguishability among executable and non-executable code statements but it will mostly be encountered in shape of large blocks of <tt>R</tt> code. These blocks are referred to as code chunks.</p></li>
</ul>
</div>
<div id="acknowledgement">
<h4>Acknowledgement</h4>
<p>We thank the <em>Stifterverband für die Deutsche Wissenschaft e.V.</em> and the <em>Ministry of Science and Research North Rhine-Westphalia</em> for their financial support. Also, we are grateful to Alexander Blasberg for proofreading and his effort in helping with programming the exercises.
A special thanks goes to Achim Zeileis (University of Innsbruck) and Christian Kleiber (University of Basel) for their advice and constructive criticism. Another thanks goes to Rebecca Arnold from the Münster University of Applied Sciences for several suggestions regarding the website design and for providing us with her nice designs for the book cover, logos and icons. We are also indebted to all past students of our introductory econometrics courses at the University of Duisburg-Essen for their feedback.</p>
<p><br>
<img src="https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-nc-sa.eu.svg" alt="Creative Commons License"></p>
<p>This book is licensed under the <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
</div>
</div>
<h3>References</h3>
<div id="refs">
<p>Stock, J. H., &amp; Watson, M. W. (2015). <em>Introduction to Econometrics, Third Update, Global Edition</em>. Pearson Education Limited.</p>

</div>
            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://www.econometrics-with-r.org/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823031</guid>
            <pubDate>Mon, 13 Jul 2020 17:09:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securely share your terminal session for remote pair programming with Upterm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822992">thread link</a>) | @jingweno
<br/>
July 13, 2020 | https://owenou.com/upterm | <a href="https://web.archive.org/web/*/https://owenou.com/upterm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><a href="https://github.com/jingweno/upterm">Upterm</a> is an open-sourced solution for sharing terminal sessions instantly over the public internet via SSH tunnels.
It is good for</p>

<ul>
  <li>Remote pair programming</li>
  <li>Access remote computers behind NATs and firewalls</li>
  <li>Remote debugging</li>
</ul>

<p>Upterm is written in Go and is open-sourced at <a href="https://github.com/jingweno/upterm">https://github.com/jingweno/upterm</a>.</p>

<h2 id="how-it-works">How it works</h2>

<p>You run the <code>upterm</code> program by hosting a terminal session.
Upterm starts an SSH server on your machine and connects to an Upterm server (a.k.a. uptermd) via reverse SSH tunnel.
Your friends connect to your terminal session using ssh via the same Upterm server.</p>

<p>Here is a diagram on the technical details:</p>

<p><img src="https://raw.githubusercontent.com/jingweno/upterm/gh-pages/upterm-flowchart.svg?sanitize=true" alt="diagram"></p>

<h2 id="demo">Demo</h2>

<p><a href="https://asciinema.org/a/LTwpMqvvV98eo3ueZHoifLHf7"><img src="https://asciinema.org/a/LTwpMqvvV98eo3ueZHoifLHf7.svg" alt="asciicast"></a></p>

<h2 id="quickstart">Quickstart</h2>

<p>Install <code>upterm</code> by following <a href="https://github.com/jingweno/upterm#installation">this guide</a>.</p>

<p>On your machine, host a terminal session by specifying a command:</p>



<p><code>upterm</code> will start the command and pop up an ssh connection string that one can connect.
In case you miss the connection string, display it with:</p>

<div><div><pre><code>$ upterm session current
=== IQKSFOICLSNNXQZTDKOJ
Command:                bash
Force Command:          n/a
Host:                   ssh://uptermd.upterm.dev:22
SSH Session:            ssh IqKsfoiclsNnxqztDKoj:MTAuMC40OS4xNjY6MjI=@uptermd.upterm.dev
</code></pre></div></div>

<p>Open a new terminal and connect to the session:</p>

<div><div><pre><code>$ ssh IqKsfoiclsNnxqztDKoj:MTAuMC40OS4xNjY6MjI=@uptermd.upterm.dev
</code></pre></div></div>

<p>You should see the input and output of both terminals are linked!</p>

<p>If you want only authorized clients to connect to your session, you can specify the clients’ authorized keys with</p>

<div><div><pre><code>$ upterm host --authorized-key PATH_TO_PUBLIC_KEY -- bash
</code></pre></div></div>

<p>If you are looking for a <a href="https://tmate.io/">Tmate</a>-like experience, create a <a href="https://github.com/tmux/tmux">Tmux</a> session, and “force” clients to attach to the Tmux session:</p>

<div><div><pre><code>$ upterm host --force-command 'tmux attach -t pair-programming' -- tmux new -t pair-programming
</code></pre></div></div>

<p>The above creates a Tmux session by running <code>tmux new -t pair-programming</code>.
After a client connects, Upterm will attach the client’s input and output to the input and output of the Tmux session “pair-programming”.</p>

<p>If you are concerned with others accessing your root file system, wrap the terminal session in a Docker container:</p>

<div><div><pre><code>$ upterm host -- docker run --rm -ti ubuntu bash
</code></pre></div></div>

<p>I will write another blog post in the future to share how I securely host a terminal session using containers.</p>

<h2 id="how-is-upterm-compared-to-prior-arts">How is Upterm compared to prior arts?</h2>

<p>Upterm is an alternative to <a href="https://tmate.io/">Tmate</a>.</p>

<p>Tmate is a fork of an older version of Tmux. It adds terminal sharing capability on top of Tmux 2.x.
Tmate doesn’t intend to catch up with the latest Tmux (at this time of the post, the latest Tmux is 3.x), so any Tmate &amp; Tmux users must maintain two versions of the configuration.
For example, you must <a href="https://github.com/tmate-io/tmate/issues/108">bind the same keys twice with a condition</a>.</p>

<p>Upterm is designed from the group up not to be a fork of anything.
It builds around the concept of linking the input &amp; output of any shell command between a host and its clients.
As you see above, you can share any command besides <code>tmux</code>.
This opens up a door for securely sharing a terminal session using containers (I will explain more in a future post).</p>

<p>Upterm is written in Go.
It is more friendly hackable than Tmate that is written in C because Tmux is C.
The Upterm CLI and server (<code>uptermd</code>) are compiled into a single binary.
You can quickly <a href="https://github.com/jingweno/upterm#deploy-uptermd">spawn up your pairing server</a> in any cloud environment with zero dependencies.</p>

<h2 id="tips">Tips</h2>

<h3 id="why-doesnt-upterm-show-the-current-terminal-session-in-tmux">Why doesn’t upterm show the current terminal session in Tmux?</h3>

<p><code>upterm session current</code> shows the connection info of the current terminal session.
It needs the <code>UPTERM_ADMIN_SOCKET</code> environment variable to function.
By default, Tmux doesn’t carry over environment variables that are not in its <a href="http://man.openbsd.org/i386/tmux.1#GLOBAL_AND_SESSION_ENVIRONMENT">default list</a> to a Tmux session unless you tell it.
So add the following line to your <code>~/.tmux.conf</code></p>

<div><div><pre><code>set-option -ga update-environment " UPTERM_ADMIN_SOCKET"
</code></pre></div></div>

<h3 id="how-to-make-it-obvious-that-i-am-in-an-upterm-session">How to make it obvious that I am in an upterm session?</h3>

<p>It can be confusing whether your terminal session is an upterm session or not.
As an example, I add an emoji to my prompt to identify an upterm session:</p>

<div><div><pre><code><span># in your ~/.bashrc or ~/.zshrc </span>
<span>export </span><span>PS1</span><span>=</span><span>"</span><span>$(</span><span>[[</span> <span>!</span> <span>-z</span> <span>"</span><span>${</span><span>UPTERM_ADMIN_SOCKET</span><span>}</span><span>"</span>  <span>]]</span> <span>&amp;&amp;</span> <span>echo</span> <span>-e</span> <span>'\xF0\x9F\x86\x99 '</span><span>)</span><span>$PS1</span><span>"</span> <span># Add an emoji</span>
</code></pre></div></div>

<p>This is what it looks like :-):</p>

<p><img src="https://owenou.com/assets/upterm_prompt-029af7ec9e3dac832db96d92f68be888.png" alt="upterm_prompt"></p>

<h2 id="deploy-uptermd">Deploy Uptermd</h2>

<p>Upterm needs an Upterm server (a.k.a. <code>uptermd</code>) to expose terminal sessions securely.
There is a community server running at <code>uptermd.upterm.dev</code> for your convenience (please put it into good use!).
However, if you want to host your pairing server on <a href="https://kubernetes.io/">Kubernetes</a> or <a href="https://heroku.com/">Heroku</a>, follow <a href="https://github.com/jingweno/upterm#how-it-works">this deployment guide</a>.
You are welcome to contribute one for your favorite cloud platforms.
I am pleased to review it if you shoot me a <a href="https://github.com/jingweno/upterm/pulls">PR</a> :-).</p>

<p>To talk to a different uptermd server other than the community server, you specify with the <code>--server</code> flag:</p>

<div><div><pre><code># Use your Uptermd server via SSH on TCP
$ upterm host --server ssh://YOUR_SERVER -- YOUR_COMMAND

# Use your Uptermd server via SSH on WebSocket
$ upterm host --server wss://YOUR_SERVER -- YOUR_COMMAND

# Client connects to the host session via SSH on WebSocket
$ ssh -o ProxyCommand='upterm proxy wss://TOKEN@YOUR_SERVER' TOKEN@YOUR_SERVER:443
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>I am super excited about <code>upterm</code>, and I dogfood it daily to pair program with my coworkers (Disclaimer: I work remotely for Heroku).
If you like what you see here, give upterm a shot.
I am looking forward to your valuable feedback and contributions: <a href="https://github.com/jingweno/upterm/issues">https://github.com/jingweno/upterm/issues</a> :-).</p>

        
      </section></div>]]>
            </description>
            <link>https://owenou.com/upterm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822992</guid>
            <pubDate>Mon, 13 Jul 2020 17:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do the fundamentals well. Do them consistently. Do them with style]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822955">thread link</a>) | @designthinker
<br/>
July 13, 2020 | https://jwgoerlich.com/frameworks-fade-but-security-is-eternal-design-monday/ | <a href="https://web.archive.org/web/*/https://jwgoerlich.com/frameworks-fade-but-security-is-eternal-design-monday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<p>Frameworks fade but security is eternal. Said with apologies to Yves Saint Laurent.</p>



<p><a href="https://en.wikipedia.org/wiki/Yves_Saint_Laurent_(designer)">Yves Saint Laurent</a> was a dominant force in fashion from the 1960s through to end of the century. His strengths stemmed from three areas. First, seeing the underlying fundamentals and being able to re-envision them across genders, across times, and across trends. Second, the ability to cross artforms for inspiration, most notably with Piet Mondrian and geometrical shapes. Finally, the ability to reformulate high fashion at couture for mass production. Yves Saint Laurent was the first to open a ready-to-wear line in Paris. He was a designer who mastered how to take the pieces apart and put them back together for new tastes and new markets. It Yves Saint Laurent who once famously said, “fashion fades but style is eternal.”</p>



<p>Last week, we looked at how the adoption of a control — <a href="https://jwgoerlich.com/ahead-of-the-curve-design-monday/">doing something right but rare</a> — has surprising stopping power against common attacks. But the fast-changing early adoption must be balanced with slow-changing fundamentals.</p>



<p>CyberSecurity can be a bit too much like fashion. Every major event, there’s a new trend. The media buzz will say that new threats appear every day. The buzz is that our ways of defending become dated and ineffective as quickly as they’re implemented. New frameworks cry out that the old ways were wrong.</p>



<p>This last bit is particularly on my mind in 2020. A new version of the CIS Critical Security Controls came out late last year. NIST is releasing a new version of its standard for security and privacy controls (NIST SP 500-53B). And the new PCI DSS (Data Security Standard) for credit card security is due any time now. Each framework will be accompanied by a wave of press on how everything has changed. The last version is so last season, and simply won’t do.</p>



<p>But is it? Is it really?</p>



<p>Like style, fundamentals in security remain the same even while the specifics evolve. We need to know our people and our technology. We need visibility into what’s happening and what’s changing. We need to think in terms of lifecycles and act in terms of incidents. We need to make sure the simple habits that result in defensible positions are done regularly. Finally, we need to understand the adversary’s objectives and tactics. From mainframes to data centers to cloud infrastructures to tomorrow, the fundamentals hold true.</p>



<p>A security architecture is comprised of a series of building blocks. Some building blocks should be innovative and ahead of our peers. Most building blocks should do the fundamentals and broadly cover the frameworks. </p>



<p>Do the fundamentals well. Do them consistently. Do them with style.</p>



<figure><img src="https://jwgoerlich.com/wp-content/uploads/2020/05/Yves-Saint-Laurent-Piet-Mondrian.png" alt="" srcset="https://jwgoerlich.com/wp-content/uploads/2020/05/Yves-Saint-Laurent-Piet-Mondrian.png 1024w, https://jwgoerlich.com/wp-content/uploads/2020/05/Yves-Saint-Laurent-Piet-Mondrian-300x169.png 300w, https://jwgoerlich.com/wp-content/uploads/2020/05/Yves-Saint-Laurent-Piet-Mondrian-768x432.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<hr>



<p><em>This article is part of a series on designing cyber security capabilities. To see other articles in the series, including a full list of design principles,&nbsp;</em><a href="https://jwgoerlich.com/principles-for-designing-security-capabilities/"><em>click here</em></a><em>.</em></p>
																		<p><span>Posted </span><a href="https://jwgoerlich.com/frameworks-fade-but-security-is-eternal-design-monday/" title="6:00 am" rel="bookmark"><time datetime="2020-07-13T06:00:00-04:00" pubdate="">July 13, 2020</time></a> by 					</p></div></div>]]>
            </description>
            <link>https://jwgoerlich.com/frameworks-fade-but-security-is-eternal-design-monday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822955</guid>
            <pubDate>Mon, 13 Jul 2020 17:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Should I Learn to Code? 17 Reasons to Learn Programming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822952">thread link</a>) | @mdziubek
<br/>
July 13, 2020 | https://codersbible.com/why-should-i-learn-to-code-17-reasons-to-learn-programming/ | <a href="https://web.archive.org/web/*/https://codersbible.com/why-should-i-learn-to-code-17-reasons-to-learn-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>If you wonder whether to invest some time into learning programming, or you already code, but feel stuck or lack motivation - this article is for you. Why should you learn to code? I’ve come up with a lot of reasons! They are all backed by my experience as a software engineer as well as countless conversations with my peers. I hope this blog post will help you make a right decision.</p>


<p>Before you start reading, here’s a short list with clickable links to all paragraphs in this article, each representing a reason to learn programming:</p>
<ul>
<li><a href="#receive_attractive_salary"><b>RECEIVE ATTRACTIVE SALARY</b></a></li>
<li><a href="#get_a_job_in_stable_industry"><b>GET A JOB IN STABLE INDUSTRY</b></a></li>
<li><a href="#experience_different_career_opportunities"><b>EXPERIENCE DIFFERENT CAREER OPPORTUNITIES</b></a></li>
<li><a href="#have_valuable_skill_on_your_cv"><b>HAVE VALUABLE SKILL ON YOUR CV</b></a></li>
<li><a href="#choose_from_many_job_offers"><b>CHOOSE FROM MANY JOB OFFERS</b></a></li>
<li><a href="#work_from_anywhere"><b>WORK FROM ANYWHERE</b></a></li>
<li><a href="#enjoy_great_work_culture"><b>ENJOY GREAT WORK CULTURE</b></a></li>
<li><a href="#boost_your_problem_solving_skills"><b>BOOST YOUR PROBLEM SOLVING SKILLS</b></a></li>
<li><a href="#improve_collaboration_skills"><b>IMPROVE COLLABORATION SKILLS</b></a></li>
<li><a href="#focus_on_practice"><b>FOCUS ON PRACTICE</b></a></li>
<li><a href="#see_results_of_your_work_immediately"><b>SEE RESULTS OF YOUR WORK IMMEDIATELY</b></a></li>
<li><a href="#build_something_cool"><b>BUILD SOMETHING COOL</b></a></li>
<li><a href="#understand_how_software_around_you_works"><b>UNDERSTAND HOW SOFTWARE AROUND YOU WORKS</b></a></li>
<li><a href="#express_your_creativity"><b>EXPRESS YOUR CREATIVITY</b></a></li>
<li><a href="#have_freedom"><b>HAVE FREEDOM</b></a></li>
<li><a href="#meet_incredible_community"><b>MEET INCREDIBLE COMMUNITY</b></a></li>
<li><a href="#learn_it_all_online"><b>LEARN IT ALL ONLINE</b></a></li>
</ul>


<h3 id="receive_attractive_salary">RECEIVE ATTRACTIVE SALARY</h3>


<p>This probably is the most obvious. Average salary of software engineer is considerably higher than for most other career choices. I want, however, to show you exactly how much higher. Under <a href="https://www.levels.fyi/" target="_blank" rel="noopener noreferrer">this link</a> you’ll find compensation for developers in many of the top tech companies. For example at Google, as you gain experience and expertise, you get promoted through levels with symbols like L3 (Software Engineer II), L4 (Software Engineer III), L5 (Senior Software Engineer) etc. By clicking on the tiles on the website, you’ll see average yearly salaries (most of them are verified). If you wish to take a look at other parts of the world <a href="https://www.codingame.com/work/blog/hr-news-trends/average-software-engineer-salaries-2020-top-paying-countries/" target="_blank" rel="noopener noreferrer">here is the link</a> to great article backed by data with top paying countries. And if you would like to go even further and find your country, then I can highly recommend <a href="https://www.salaryexpert.com/salary/browse/countries/computer-software-engineer" target="_blank" rel="noopener noreferrer">this report</a> from Economic Research Institute.</p>


<h3 id="get_a_job_in_stable_industry">GET A JOB IN STABLE INDUSTRY</h3>


<p>The unemployment rate for software developers in the USA stays at remarkable 1.6% (as stated in <a href="https://money.usnews.com/careers/best-jobs/software-developer" target="_blank" rel="noopener noreferrer">this</a> report from prestigious U.S. News &amp; World Report) and is similarly low worldwide. The software industry is very stable, but don’t get me wrong - you probably won’t use the same skills you are learning today in 10 years, since technology evolves rapidly. You can be sure, though, that most companies will support you in acquiring new knowledge, because they know that their business success depends on using up-to-date tools. Companies and start ups will come and go, but if you keep you skills polished (and most organizations are happy to help you with that), you can be sure to find a new job opportunity in no time, even if your current workplace bankrupts.</p>


<h3 id="experience_different_career_opportunities">EXPERIENCE DIFFERENT CAREER OPPORTUNITIES</h3>


<p>When you acquire the ability to code, you’ll have unique opportunity to contribute to various industries, like: banking (see: Revolut, N26, Monzo), e-commerce (see: Wish, Etsy, Amazon), dating (see: Tinder, Badoo, OkCupid), construction (see: Archdesk, Procore, Buildertrend), social media (see: Facebook, Instagram, Snapchat), AI (see: OpenAI, Boston Dynamics), gaming (see: Call of Duty Mobile, Witcher, Candy Crush Saga) even sex life (see - but only if you’re over 18 😉 - Elvie Trainer, Lovense Remote). It’s all software, which helps millions of people! In addition, you’ll have multiple choices in how to do it. You can be freelancer, IT project manager, software engineer in big corporation working on many different projects, developer in small start up maintaining one product, team leader or just start your own company. This was probably the most important thing, that lured me in.</p>


<h3 id="have_valuable_skill_on_your_cv">HAVE VALUABLE SKILL ON YOUR CV</h3>


<p>Steve Jobs once said “<i>Everybody in this country should learn to program a computer, because it teaches you how to think.</i>”. I couldn’t agree more, but I would also add “<i>...and it looks great on your CV.</i>”. No matter if you decide to pursue software engineering professionally or you land a job doing something a bit different - mentioning programming skills to any potential employer demonstrates your ability to comprehend advanced topics, understand abstract concepts and think in a structured and critical way.</p>


<h3 id="choose_from_many_job_offers">CHOOSE FROM MANY JOB OFFERS</h3>


<p>Recent research from Microsoft (which you can find <a href="https://blogs.microsoft.com/blog/2020/06/30/microsoft-launches-initiative-to-help-25-million-people-worldwide-acquire-the-digital-skills-needed-in-a-covid-19-economy/" target="_blank" rel="noopener noreferrer">here</a>) indicates, that as many as 149 million new technology-oriented jobs will be created worldwide in the coming 5 years. Software development accounts for vast majority of this forecast (98 million). See it for yourself! Try this small experiment at home: go to one of the top websites with job offers in your country and type “software developer” (preferably in your language). Scope the search to your location only. How many offers can you find? I live in a medium size city with population of about 800 000. What are my results? 300 job offers in the area (as of July 9, 2020)!</p>


<h3 id="work_from_anywhere">WORK FROM ANYWHERE</h3>


<p>Remote work has been present in the software industry for many years now. This model, in theory, allows you to work from any place with stable internet and a desk for your laptop. It’s a dream for some people and a nightmare for others. If you belong to the latter, but you still want to profoundly experience a dive into other part of the world, then I have good news - there is probably a high demand for a programmer in your dream location. Let’s examine some of my top places using <a href="https://indeed.com/" target="_blank" rel="noopener noreferrer">Indeed</a> job listings search engine: Bari (Italy) - 45 jobs, London (UK) - 5000 jobs, San Francisco Bay Area (USA, California) - 3300 jobs, Honolulu (USA, Hawaii) - 35 jobs (as of July 9, 2020).</p>


<h3 id="enjoy_great_work_culture">ENJOY GREAT WORK CULTURE</h3>


<p>Like everywhere else, there is still a chance here for meeting shitty coworkers. Yes - if you’re unlucky, you can stumble upon mobbing or discrimination, but there is <b>far smaller </b>chance for this in the IT world and, thanks to plethora of available job offers and rumors spreading quickly among local software engineers, you can successfully dodge any bad workplace (in contrast to many other industries). Feedback meetings, 1-on-1s with managers and tech leaders, retrospectives - these are only some of the standard processes nurtured in modern software companies to help stay in constant contact with you, your productivity level and your general happiness during work.</p>


<h3 id="boost_your_problem_solving_skills">BOOST YOUR PROBLEM SOLVING SKILLS</h3>


<p>Before I learned how to code, I had been solving multiple problems during high school and university related to math, physics, mechanics or chemistry. They were often complicated and challenging, but most of the time there was a pattern you could extract or exam answer key you should fit into. Also, they were so theoretical and detached from the real world, that they became boring very quickly. Recently I’ve come to a conclusion, that I owe most of my current ability to think outside the box, decompose the problem and reason in an abstract way to software projects I implemented during last few years. Sure, there are sites like <a href="https://stackoverflow.com/" target="_blank" rel="noopener noreferrer">Stack Overflow</a> with ready-made answers for developers, but the pleasant angst you get when you start solving something in Java, Python or any other programming language and joyful smile, that appears on your face when you finally fix it (only with partial help from Google) is a feeling I hadn’t experienced previously at any stage of my education. You just feel your problem solving skills boosting! I can only compare it to sitting in the infinitely complicated <a href="https://en.wikipedia.org/wiki/Escape_room" target="_blank" rel="noopener noreferrer">Escape Room</a> solving one puzzle at a time, but never wanting for them to finish.</p>


<h3 id="improve_collaboration_skills">IMPROVE COLLABORATION SKILLS</h3>


<p>Take a look at Facebook, Instagram, Amazon or any other piece of software you often use. It may look simple at first (most of the time, that’s the intent of creators to provide excellent user experience), but if you keep looking, you’ll notice the depth. These kinds of online platforms are so complicated under the hood, that it would take ages for a single programmer to craft, hence group effort plays a vital role here. Working with people to deliver a project teaches a lot about them, mostly because almost always there are problems to address. Software industry won’t leave you without any help, though! There are clever methodologies (like Scrum or Kanban) used in many modern companies, which facilitate such cooperation and has been working well for years. If you want to learn how to work with people, I believe the IT world is the coolest place to do so.</p>


<h3 id="focus_on_practice">FOCUS ON PRACTICE</h3>


<p>You won’t find many theoretical programmers. Our actions are focused on delivering something someone else can use or something, that will help us be more productive. Having this in mind, can you guess what’s the number one thing you can do to stand out from the crowd when applying for the first job? Show real software projects you implemented! If you’re looking for a course to learn how to code always prefer the one, which offers help with implementing one or more practice projects.</p>


<h3 id="see_results_of_your_work_immediately">SEE RESULTS OF YOUR WORK IMMEDIATELY</h3>


<p>I graduated from the Faculty of Mechanical Engineering, where I was learning about pumps, gears, millers, pistons...I’m boring myself just writing about that. But unexciting classes weren't my biggest problem. I was consuming a lot of theory about all these big machines only to have around few hours every month to see them in action (even less time to try them myself). My friends at the Faculty of Civil Engineering had similar issues. They wanted to finally see real results of their careful calculations and planning, but due to the nature of this industry they weren’t able to. Software is not like that: learn theory, practice, apply it in code, compile and BOOM - you see the output on your screen almost immediately. Experiencing results of work in such quick manner helps to stay motivated and even amazed at things you can build with your own hands.</p>


<h3 id="build_something_cool">BUILD SOMETHING COOL</h3>


<p>I’ve seen many fun (and weird) software side projects in my career. <a href="https://github.com/pmav/game-of-life" target="_blank" rel="noopener noreferrer">Conway’s Game of Life</a>, <a href="https://rickandmortyapi.com/about" target="_blank" rel="noopener noreferrer">Rick and Morty API</a> and <a href="https://8values.github.io/" target="_blank" rel="noopener noreferrer">8values quiz</a> are some of my favorites. I even implemented one for my engineering thesis: beer label …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codersbible.com/why-should-i-learn-to-code-17-reasons-to-learn-programming/">https://codersbible.com/why-should-i-learn-to-code-17-reasons-to-learn-programming/</a></em></p>]]>
            </description>
            <link>https://codersbible.com/why-should-i-learn-to-code-17-reasons-to-learn-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822952</guid>
            <pubDate>Mon, 13 Jul 2020 17:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula Webinar: Infrastructure as Code in OpenNebula using Terraform]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822942">thread link</a>) | @amarti
<br/>
July 13, 2020 | https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw | <a href="https://web.archive.org/web/*/https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Terraform, the open source Infrastructure as Code software tool created by HashiCorp, is a solution for building, changing, and versioning infrastructure safely and efficiently. It allows infrastructure to be expressed as code in a simple, human readable language called HCL. Terraform reads configuration files and provides an execution plan of changes, which can be reviewed for safety and then applied and provisioned automatically.</p><p>What to expect from this webinar?</p><p>- Learn about Terraform’s Infrastructure as Code approach and about its basic uses and capabilities, including the value it provides for managing the full lifecycle of your infrastructure, plan and predict changes, and create reproducible environments.</p><p>- Discover the new version and future roadmap of the OpenNebula Provider, through which cloud admins can use Terraform to interact with OpenNebula cluster resources.</p><p>- Watch a live demo on how this amazing integration is being used in an actual cloud, and how to simplify a real infrastructure workflow by using the OpenNebula Provider for Terraform.</p><p>This webinar will be presented by Michael Abdou (Customer Success Manager at OpenNebula). Our guest speakers for this event will be Taylor Dolezal (Senior Developer Advocate at HashiCorp) and Jean-Philippe Fourès (Cloud Product Manager at Iguane Solutions).</p><p>Press and media, please contact: events@opennebula.io
</p></div></div>]]>
            </description>
            <link>https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822942</guid>
            <pubDate>Mon, 13 Jul 2020 17:02:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effecftive Poster Design for Science Communication [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23822939">thread link</a>) | @pabloem
<br/>
July 13, 2020 | http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf | <a href="https://web.archive.org/web/*/http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822939</guid>
            <pubDate>Mon, 13 Jul 2020 17:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Document your Theory of The Program as a team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822892">thread link</a>) | @bckmn
<br/>
July 13, 2020 | https://www.joshbeckman.org/2020/07/12/on-theory-building-as-an-engineering-team/ | <a href="https://web.archive.org/web/*/https://www.joshbeckman.org/2020/07/12/on-theory-building-as-an-engineering-team/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p>Recently, I was reading <a href="http://brooker.co.za/blog/2020/06/23/code.html">Marc Booker’s post</a> about the need for documentation outside of the codebase.
<a href="https://news.ycombinator.com/item?id=23751652">A thoughtful comment</a> on the post led me to <a href="http://pages.cs.wisc.edu/~remzi/Naur.pdf">Peter Naur’s paper on Programming as Theory Building</a>, which I recommend reading<sup id="fnref:1"><a href="#fn:1">1</a></sup>.
In it, Naur argues that the act of programming is not a practice of writing code but the work of creating a theory of the problem at hand and a theory of the system to address it.
As a team exercise, we practiced documenting our theories of the OfficeLuv system and found it very rewarding.</p>

<p>In my mind, there is a hierarchy of explanatory documentation that programmers pass between each other.
At the bottom there is the pulse of the commit history.
This documentation is a permanent record, but the explanations themselves are brief, incomplete, and ephemeral.</p>

<p>The next level consists of comments in the code itself.
These explanations are often even more brief, but sit in plain sight and directly beside their subjects.</p>

<p>Above comments, we have <a href="http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions">Architecture Decision Records</a> (ADRs).
These are structured stories about features or services that are written and read outside of the actual program material.
We’ve begun adopting this level of documentation at OfficeLuv over the last couple months (with several benefits, which I’ll probably write about in the future).
I would also lump Requests for Comment (RFCs) and documents like that into this level.</p>

<p>I think Naur’s idea of Theory Building fits as a flavor of documentation one level higher.
The central assumptions about what our system should handle and what it operates on are foundational.
These read like laws of physics, but for the worldview and inner-workings of the system.
This documentation informs other contributors on how to best extend the current program, and which rules we would hesitate to violate.</p>

<p>I’ve never read this kind of documentation at the level of a program or system before.
The closest that comes to mind are Rails’ “<a href="https://en.m.wikipedia.org/wiki/Convention_over_configuration">Convention over configuration</a>”, the <a href="https://en.m.wikipedia.org/wiki/Zen_of_Python">Zen of Python</a> guiding principles, or even OfficeLuv’s <a href="https://github.com/officeluv/heart-of-a-developer">Heart of a Developer</a> proverbs.
But these just provide a breezy direction as to how we should go about our programming.
The <em>Theory of The Program</em> can be much more direct about the boundaries and patterns of the worldview from within our specific program.</p>

<p>To that end, I had the OfficeLuv engineering team practice documenting our own theories of our system.
Each of us took a couple days and wrote up our individual theories, which we then shared together.
Multiple theories overlapped between us, which reassured us that we agreed on what a theory should be.
Tenets that applied only to a subsystem we decided to extract as ADRs.
We now have a Theory of The OfficeLuv System at the top level of our documentation and we’ll continue to evolve it as we build.</p>

<p>I wish we had started this practice earlier - I would <em>love</em> to read what our previous teams had held as theory.
Contrasting the worldview from two years ago would be interesting to measure against the problems we face now.
This document will be used during onboarding and for guidance in feature-building as we grow.
And having these theories on hand for our next hire will allow them to begin contributing more effectively on day one.</p>

<h2 id="tips-for-writing-your-own-theories">Tips for Writing Your Own Theories</h2>

<p>Naur recommends identifying a clear metaphor as the best way to convey the Theory of The Program.
I found this exceedingly difficult, even for a startup like OfficeLuv.
I could readily think of metaphors for subsystems, but I wouldn’t recommend spending too much time finding a metaphor for a sufficiently large project.
If you can find one, congrats.</p>

<p>I think it’s key to have each team member write their theories on their own.
This increases the diversity of ideas that you can combine into your group theories.
The diversity also prompts you to coalesce similar theories into higher-level rules that become more powerful and applicable.</p>

<p>Don’t spend time trying to pull a single Grand Unifying Theory of The Program out of several individual theories.
Our document ended up as a series of sentences and paragraphs, along with a few references and examples.
Again, I think this may be possible at the subsystem level, but unlikely to exist at the level of a sufficiently complex product.</p>



  
</div>

    </div></div>]]>
            </description>
            <link>https://www.joshbeckman.org/2020/07/12/on-theory-building-as-an-engineering-team/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822892</guid>
            <pubDate>Mon, 13 Jul 2020 16:56:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Open Source, licenses and changes]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 26 (<a href="https://news.ycombinator.com/item?id=23822732">thread link</a>) | @nfrankel
<br/>
July 13, 2020 | https://blog.frankel.ch/on-opensource-licenses-changes/ | <a href="https://web.archive.org/web/*/https://blog.frankel.ch/on-opensource-licenses-changes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting"> <meta itemprop="mainEntityOfPage" content="//on-opensource-licenses-changes/"> <meta itemprop="description" content="">  <figure itemscope="" itemprop="image" itemtype="http://schema.org/ImageObject"> <meta itemprop="url" content="https://blog.frankel.ch/assets/resources/open-source-licenses-changing/OSI_Standard_Logo_0.svg"> </figure> <section> <div itemprop="articleBody"> <p>The subject of Open Source and OS licenses has been waxing and waning over time. Recently, it became hot again. In this post, I’d like to do a quick recap to set the stage. Then, I’ll analyze reasons for license changes.</p> <div> <h2 id="the-rise-of-open-source">The rise of Open Source</h2> <div> <p>Before I actually started my career - even I was before even born - software was provided with its source code. The value was in the hardware. Most customers - if not every one of them - modified and adapted the source code to their hardware. Then, in 1969, the United States' government ruled (against IBM) that the bundling of software and hardware together was <em>anticompetitive</em>. The value moved from hardware to software because of an unexpected side-effect of the previous ruling. Thus began the rise of Microsoft Windows. Interestingly enough, that also changed the way software was delivered. Customers only got the binaries, not the source code. Of course, this is mostly the case today.</p> <p>Around ten years later, a new trend started in reaction to that: some with Richard Stallman decided that releasing the source code was the only <em>right</em> way to deliver software. Furthermore, their position was that software should be free. Because that tiny initiative became a respectable model, this view on things is more than relevant today. Today, Open Source means different things in the mind of different people.</p> </div> </div> <div> <h2 id="open-source-is-a-loaded-term">Open Source is a loaded term</h2> <div> <p>Literally, Open Source is only the delivery of the source code along the binary. No more, no less. For commercial software, if carefully worded in the purchasing contract, that means that the customer should be able to maintain the software if the vendor doesn’t anymore (<em>e.g.</em> goes bankrupt). Yet, according to Stallman’s definition, software needs to be free:</p> <div> <blockquote> <ul><li><span>Free as a bird</span></li><li><span>Free as a beer</span></li></ul> </blockquote> </div> <p>To avoid any confusion, I’d rather use the expression Free Open-Source Software <em>a.k.a.</em> FOSS.</p> </div> </div> <div> <h2 id="what-qualifies-as-open-source">What qualifies as Open Source</h2> <div> <p>This gap in the terms were deeply materialized in tensions in the community between tenants of the business-compatible Open Source and FOSS as defined above. From the former group was born the <a href="https://en.wikipedia.org/wiki/Open_Source_Initiative" target="_blank" rel="noopener">Open Source Initiative</a>. The importance of this organization cannot be understated: it decides what licenses are considered Open Source, based on the <a href="https://en.wikipedia.org/wiki/The_Open_Source_Definition">Open Source definition</a>. Criteria are:</p> <ol><li><span>Free Redistribution</span></li><li><span>Source Code</span></li><li><span>Derived Works</span></li><li><span>Integrity of The Author’s Source Code</span></li><li><span>No Discrimination Against Persons or Groups</span></li><li><span>No Discrimination Against Fields of Endeavor</span></li><li><span>Distribution of License</span></li><li><span>License Must Not Be Specific to a Product</span></li><li><span>License Must Not Restrict Other Software</span></li><li><span>License Must Be Technology-Neutral</span></li></ol> <p>As of the time of writing of this post, licenses that are allowed to be qualified as Open Source are <a href="https://opensource.org/licenses/alphabetical" target="_blank" rel="noopener">limited in number</a>. Here’s a couple of them:</p> <ul><li><span><a href="https://opensource.org/licenses/Apache-2.0">Apache License 2.0</a></span></li><li><span><a href="https://opensource.org/licenses/gpl-license">GNU General Public License (GPL)</a></span></li><li><span><a href="https://opensource.org/licenses/lgpl-license" target="_blank" rel="noopener">GNU Library or "Lesser" General Public License (LGPL)</a></span></li><li><span><a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener">MIT license</a></span></li></ul> <p>Here are two counter-examples:</p> <ul><li><span>The <a href="https://github.com/climate-strike/license" target="_blank" rel="noopener">Climate Strike License</a> is not Open Source, as it’s not in the list above</span></li><li><span><a href="https://creativecommons.org/licenses/">Creative Commons licenses</a> are not Open Source, as they don’t apply to software only</span></li></ul> </div> </div> <div> <h2 id="monetizing-open-source">Monetizing Open Source</h2> <div> <p>Open Source began as a community of like-minded people who wanted to create something together, and were willing to put on the extra effort, after office hours. However, today, the main contributors on the main projects are paid by private companies: they code during office hours. The reason for that is that Open Source - not FOSS - is compatible with business.</p> <p>There are a couple of ways to monetize Open Source software:</p> <div> <dl> <dt>Training and consulting</dt> <dd> <p>If you provide a great software, companies will start using it. At some point, there are chances they will need consulting, for advanced usage. After that, they will also need training to level up their workforce. It has been the traditional way to make money with Open Source. Unfortunately, this doesn’t scale.</p> </dd> <dt>Support</dt> <dd> <p>While consulting is planned, support comes in handy when the sh…​ has already hit the fan. Picture this: it’s 10PM, the monitoring Open Source stack your company uses has crashed, and refuse to start again. One definitely needs support in this case. <em>In general</em>, managers don’t like to use any kind of software - whether FOSS, Open Source or something else - if they don’t have an associated support contract.</p> </dd> <dt>Open Source core</dt> <dd> <p>The software offers features that are Open Source. A set of features available via extensions/plugins operate under a commercial (<em>i.e.</em> paying) license. The respective size of each depends on one’s strategy. The more features in the Open Source part, the more people will use it, but the less money one will get. This is a fine balance to find.</p> </dd> <dt>Dual license</dt> <dd> <p>The software is available under two different licenses, one Open Source, the other commercial. When one uses the software, one needs to choose which license should apply. For this model to work, and companies to decide to pay a license fee, the Open Source license should be a deterrent. The <a href="https://opensource.org/licenses/gpl-license" target="_blank" rel="noopener">GNU General Public License</a> is a solid choice: it mandates that software that embeds the GPL software should be released under the GPL license itself <em>i.e.</em> for free.</p> </dd> </dl> </div> </div> </div> <div> <h2 id="service-wrapping">Service-wrapping</h2> <div> <p>It’s no mystery that "the Cloud" has become ubiquitous since a couple of years, whether you like it or not. As more companies moved their IT-systems to the Cloud, the Cloud service providers became a force to be reckoned with. With that power, they bargained with software vendors on ways to provide the latter’s software on their infrastructure. In general, the deal was pretty much one-sided: Cloud providers got a larger portfolio of services, while software vendors got "free advertisement" for their software, and in the best of case, crumbs of the revenue.</p> <p>But even that was not enough. Some cloud providers became so bold as to stop pretending it was even a deal. They just got they greedy hands on the Open Source software, and service-wrapped it. It was completely legal, as none of the licenses prevents that. However, it raises the question of revenue sharing: one company is paying to develop the software, while another company is getting the biggest share of the revenues, because it controls the marketplace.</p> <p>Because of that, some software vendors decided to change their license to prevent service wrapping. The issue is that no Open Source license is able to achieve that. Hence, those new licenses are not considered Open Source, as per the Open Source Initiative definition.</p> </div> </div> <div> <h2 id="other-license-changes">Other license changes</h2> <div> <p>Changing one’s license is in general not a great idea. When somebody uses your software, they need to be able to trust they can use it in the future under the same terms. The anti-service wrapping changes made sure that was the case.</p> <p>Interestingly enough, I saw recently a license change unrelated to service wrapping. In the light of the CoVid-19 pandemics, somebody thought it would be a good idea to change the license to a new one:</p> <div> <blockquote> <p>CoronaVirus License :</p> <p>The coronavirus is coming to you. It’s coming at an exponential speed: gradually, and then suddenly. It’s a matter of days. Maybe a week or two. When it does, your healthcare system will be overwhelmed. Your fellow citizens will be treated in the hallways. Exhausted healthcare workers will break down. Some will die. They will have to decide which patient gets the oxygen and which one dies. The only way to prevent this is social distancing today. Not tomorrow. Today. That means keeping as many people home as possible, starting now.</p> <p>To use this program, you must</p>  <p>2) Apply social distancing</p> <p>If you live in UK, Europe, North &amp; South America, Iran, Japan, Korea…​ and if you refuse to do so, please uninstall Dummy from your system and do not use this service anymore.</p> </blockquote> </div> <p>While the intention behind this change was commendable, the change was not. This is a sure sign the license cannot be trusted. If it changes today, why cannot it change tomorrow, for other reasons? I’d advise everybody in this situation not to do that.</p> <div> <table> <tbody><tr> <td> <i title="Important"></i> </td> <td> The license change was rollbacked as it was considered at least partially unlawful. </td> </tr> </tbody></table> </div> </div> </div> <div> <h2 id="conclusion">Conclusion</h2> <div> <p>In this post, we described the origin of Open Source Software. We looked at the semantics of the expression "Open Source", and described the difference with <abbr title="Free Open Source Software">FOSS</abbr>. Then, we wrote about the Open Source Initiative, the characteristics it applies to define Open Source, and some licenses that fit this definition. We proceeded to list some ways on how to monetize FOSS. Finally, we described the problematic behavior of some Cloud providers, and how changing the license is a way to avoid it. Other reasons for license changes might break the contrast of trust between a software vendor and its users.</p> </div> </div>    </div> </section>   </article> </div> </div></div>]]>
            </description>
            <link>https://blog.frankel.ch/on-opensource-licenses-changes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822732</guid>
            <pubDate>Mon, 13 Jul 2020 16:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weird Wide Webring]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822684">thread link</a>) | @lowmemcpu
<br/>
July 13, 2020 | https://weirdwidewebring.net/join.html | <a href="https://web.archive.org/web/*/https://weirdwidewebring.net/join.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>If you wish the web were simpler, more fun, and all around more weird, this might be for you. Head over to <a href="https://github.com/jackmcdade/weird-wide-webring">github</a> for instructions on how to submit your site.</p>
        <p>← Go back to the <a href="https://weirdwidewebring.net/">sites</a>.</p>
    </div></div>]]>
            </description>
            <link>https://weirdwidewebring.net/join.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822684</guid>
            <pubDate>Mon, 13 Jul 2020 16:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Loading environment variables from a secrets manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23822681">thread link</a>) | @makethetick
<br/>
July 13, 2020 | https://www.viadog.com/replacing-environment-variables-aws-secrets | <a href="https://web.archive.org/web/*/https://www.viadog.com/replacing-environment-variables-aws-secrets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p><em>Although this solves our use case of developing with Amplify, loading your environment variables from a secret store is a great way to conveniently manage all your environments from one place.</em></p><p>When working with NodeJS applications, using <code>.env</code> is the go-to method for storing environment variables however it starts to fall down with <a href="https://aws.amazon.com/amplify/" target="_blank" rel="noreferrer">Amplify</a> when you have multiple lambda functions that all need a common environment, and even more so if you want to quickly switch between Amplify backend environments.</p><p>Storing your environment variables within <a href="https://aws.amazon.com/secrets-manager/" target="_blank" rel="noreferrer">AWS Secrets Manager</a> is a great way to setup your backend environments once and not have to worry about it again, it also gives the added bonus of not having your secrets easily readable within the AWS Lambda console.</p><h2 id="setting-up-your-environments">Setting up your environments</h2><p>Let’s get started by first creating a JSON file containing the required environment variables. You can create as many environments as you like, we recommend using one environment per developer with the addition of staging and production.</p><p>Alternatively, you could create an environment per feature branch but this didn’t work for us. See more about <a href="https://docs.amplify.aws/cli/teams/overview" target="_blank" rel="noreferrer">teams environments</a>. Note, this can also be done through the AWS console.</p><p>Create the file <code>[ENVIRONMENT].json</code>.</p><div><pre><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>"API_ID"</span><span>:</span><span> </span><span>"123"</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>"API_KEY"</span><span>:</span><span> </span><span>"ABC"</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>"ENDPOINT_URL"</span><span>:</span><span> </span><span>"https://example.com/endpoint"</span><span></span></p><p><span>5</span><span></span><span>}</span></p></pre></div><p>Then push the variables to AWS Secrets Manager.</p><div><pre><p><span>1</span><span>aws secretsmanager create-secret --name </span><span>[</span><span>PROJECT</span><span>]</span><span>/amplify-dev/</span><span>[</span><span>ENVIRONMENT</span><span>]</span><span> --secret-string file://</span><span>[</span><span>ENVIRONMENT</span><span>]</span><span>.json --profile </span><span>[</span><span>PROFILE</span><span>]</span></p></pre></div><p>We like to use a naming convention to cover:</p><ul><li>Project name.</li><li>Development or production (this makes it easier for setting IAM permisions).</li><li>Environment name.</li></ul><p>Which ends up like this: <code>[PROJECT]/amplify-[STAGE]/[ENVIRONMENT]</code>.</p><p>We might end up with the following secret names:</p><ul><li>project-name/amplify-dev/dev1</li><li>project-name/amplify-dev/dev2</li><li>project-name/amplify-prod/prod</li></ul><p>The environment names above need to exactly match your Amplify environments, these can be added with the following.</p><div><pre><p><span>1</span><span>amplify </span><span>env</span><span> </span><span>add</span><span> </span><span>[</span><span>ENVIRONMENT</span><span>]</span><span></span></p><p><span>2</span><span>amplify push</span></p></pre></div><h2 id="accessing-aws-secrets-from-nodejs">Accessing AWS Secrets from NodeJS</h2><p>We now need to create a helper file which will be used by each of our Lambda functions. By default Lambda will give us the region (<code>process.env.REGION</code>) and Amplify environment name (<code>process.env.ENV</code>). <a href="https://gist.github.com/deanbarrow/c8df24e822fbaca5dd4c86c4205d5831" target="_blank" rel="noreferrer">View as a Gist</a>.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>AWS</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'aws-sdk'</span><span>)</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> </span><span>getSecretValue</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>const</span><span> region </span><span>=</span><span> process</span><span>.</span><span>env</span><span>.</span><span>REGION</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> env </span><span>=</span><span> process</span><span>.</span><span>env</span><span>.</span><span>ENV</span><span> </span><span>||</span><span> </span><span>'dev'</span><span></span></p><p><span>6</span><span>  </span><span>const</span><span> secretPath </span><span>=</span><span> env </span><span>===</span><span> </span><span>'prod'</span><span> </span><span>?</span><span> </span><span>'prod'</span><span> </span><span>:</span><span> </span><span>'dev'</span><span></span></p><p><span>7</span><span>  </span><span>const</span><span> secretName </span><span>=</span><span> </span><span>`[PROJECT]/amplify-</span><span>${</span><span>secretPath</span><span>}</span><span>/</span><span>${</span><span>env</span><span>}</span><span>`</span><span></span></p><p><span>8</span><span></span></p><p><span>9</span><span>  </span><span>var</span><span> client </span><span>=</span><span> </span><span>new</span><span> </span><span>AWS</span><span>.</span><span>SecretsManager</span><span>(</span><span>{</span><span> region </span><span>}</span><span>)</span><span></span></p><p><span>10</span><span></span></p><p><span>11</span><span>  </span><span>return</span><span> </span><span>new</span><span> </span><span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>,</span><span> reject</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>12</span><span>    client</span><span>.</span><span>getSecretValue</span><span>(</span><span>{</span><span> </span><span>SecretId</span><span>:</span><span> secretName </span><span>}</span><span>,</span><span> </span><span>function</span><span>(</span><span>err</span><span>,</span><span> data</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>if</span><span> </span><span>(</span><span>err</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>        </span><span>reject</span><span>(</span><span>err</span><span>)</span><span></span></p><p><span>15</span><span>      </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>16</span><span>        </span><span>let</span><span> secret</span></p><p><span>17</span><span>        </span><span>if</span><span> </span><span>(</span><span>'SecretString'</span><span> </span><span>in</span><span> data</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>18</span><span>          secret </span><span>=</span><span> data</span><span>.</span><span>SecretString</span><span></span></p><p><span>19</span><span>        </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>20</span><span>          </span><span>let</span><span> buff </span><span>=</span><span> </span><span>new</span><span> </span><span>Buffer</span><span>(</span><span>data</span><span>.</span><span>SecretBinary</span><span>,</span><span> </span><span>'base64'</span><span>)</span><span></span></p><p><span>21</span><span>          secret </span><span>=</span><span> buff</span><span>.</span><span>toString</span><span>(</span><span>'ascii'</span><span>)</span><span></span></p><p><span>22</span><span>        </span><span>}</span><span></span></p><p><span>23</span><span>        </span><span>resolve</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>secret</span><span>)</span><span>)</span><span></span></p><p><span>24</span><span>      </span><span>}</span><span></span></p><p><span>25</span><span>    </span><span>}</span><span>)</span><span></span></p><p><span>26</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>27</span><span></span><span>}</span><span></span></p><p><span>28</span><span></span></p><p><span>29</span><span></span><span>const</span><span> </span><span>setSecretEnvs</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>30</span><span>  </span><span>const</span><span> secrets </span><span>=</span><span> </span><span>await</span><span> </span><span>getSecretValue</span><span>(</span><span>)</span><span></span></p><p><span>31</span><span>  </span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>secrets</span><span>)</span><span>.</span><span>forEach</span><span>(</span><span>function</span><span>(</span><span>key</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>32</span><span>    process</span><span>.</span><span>env</span><span>[</span><span>key</span><span>]</span><span> </span><span>=</span><span> secrets</span><span>[</span><span>key</span><span>]</span><span></span></p><p><span>33</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>34</span><span>  </span><span>return</span><span> secrets</span></p><p><span>35</span><span></span><span>}</span><span></span></p><p><span>36</span><span></span></p><p><span>37</span><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>38</span><span>  setSecretEnvs</span></p><p><span>39</span><span></span><span>}</span></p></pre></div><p>This function will do the following:</p><ol><li>Automatically generate the secrets name based on the project and environment information.</li><li>Get the secret from the same backend region as the Amplify environment.</li><li>Inject each key value pair into <code>process.env</code>.</li></ol><p>The next step is to call this code everytime your application starts. Keep in mind that this will cost $0.05/10,000 calls, if this starts to get expensive or if it adds too much latency you can always introduce Redis.</p><p>In your main function, call <code>setSecretEnvs</code> as early as you can.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>{</span><span> setSecretEnvs </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'path/to/secrets/helper'</span><span>)</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>setSecretEnvs</span><span>(</span><span>)</span><span></span></p><p><span>4</span><span>  </span><span>.</span><span>then</span><span>(</span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span>    </span><span></span></p><p><span>7</span><span>    </span><span></span></p><p><span>8</span><span></span></p><p><span>9</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>10</span><span>  </span><span>.</span><span>catch</span><span>(</span><span>(</span><span>err</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>11</span><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'Error getting secrets'</span><span>,</span><span> err</span><span>)</span><span></span></p><p><span>12</span><span>    process</span><span>.</span><span>exit</span><span>(</span><span>)</span><span></span></p><p><span>13</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>14</span><span></span></p><p><span>15</span><span></span><span></span></p><p><span>16</span><span></span></p><p><span>17</span><span></span><span>try</span><span>{</span><span></span></p><p><span>18</span><span>  </span><span>await</span><span> </span><span>setSecretEnvs</span><span>(</span><span>)</span><span></span></p><p><span>19</span><span></span></p><p><span>20</span><span>  </span><span></span></p><p><span>21</span><span>  </span><span></span></p><p><span>22</span><span></span></p><p><span>23</span><span></span><span>}</span><span>catch</span><span>(</span><span>err</span><span>)</span><span>{</span><span></span></p><p><span>24</span><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'Error getting secrets'</span><span>,</span><span> err</span><span>)</span><span></span></p><p><span>25</span><span>  process</span><span>.</span><span>exit</span><span>(</span><span>)</span><span></span></p><p><span>26</span><span></span><span>}</span></p></pre></div><p>You will now find that <code>process.env</code> contains all the variables from the JSON file you imported earier.</p><p>If you want to switch to a new local Amplify environment, all you need to do is run the following and the correct secrets store will be used automatically.</p><div><pre><p><span>1</span><span>amplify </span><span>env</span><span> checkout </span><span>[</span><span>ENVIRONMENT</span><span>]</span></p></pre></div><p>This worked for us to solve the problem of managing environment variables across multiple functions/developers in a set and forget fashion, it also helped to centralise and secure the variable values as an added bonus which is actually very convenient.</p><h2 id="alternative-secret-managers">Alternative secret managers</h2><p>If you’re not using AWS, it wouldn’t be difficult to adapt the above code to work with other providers.</p><ul><li><a href="https://cloud.google.com/secret-manager" target="_blank" rel="noreferrer">Google Secret Manager</a></li><li><a href="https://azure.microsoft.com/en-us/services/key-vault/" target="_blank" rel="noreferrer">Azure Key Vault</a></li><li><a href="https://docs.docker.com/engine/swarm/secrets/" target="_blank" rel="noreferrer">Docker Secrets</a></li></ul></div></article></div>]]>
            </description>
            <link>https://www.viadog.com/replacing-environment-variables-aws-secrets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822681</guid>
            <pubDate>Mon, 13 Jul 2020 16:37:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cambridge History of China]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23822660">thread link</a>) | @jeffreyrogers
<br/>
July 13, 2020 | https://rhinopoetry.org/reviews/the-cambridge-history-of-china-vol-2-the-six-dynasties-220589-edited-by-lbert-e-dienkeith-n-knapp-reviewed-by-anthony-madrid | <a href="https://web.archive.org/web/*/https://rhinopoetry.org/reviews/the-cambridge-history-of-china-vol-2-the-six-dynasties-220589-edited-by-lbert-e-dienkeith-n-knapp-reviewed-by-anthony-madrid">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-af16ad1ab5a569388183"><p><strong><em>The Cambridge History of China, Vol. 2: The Six Dynasties, 220–589</em></strong><br>Edited. by Albert E. Dien and Keith N Knapp<br>Cambridge University Press, 2019. 897 pages.<br>Reviewed by Anthony Madrid</p></div><div data-block-type="2" id="block-e5f3520b58c042c10f76"><div><p>How to even begin to explain. The book under review is the next-to-last “brick” of a monumental project:&nbsp;<em>The Cambridge History of China</em>. As always happens in enterprises that take thirty or forty years to complete, the volumes were published out of sequence. The book pictured above is Volume Two (2019). Volume (e.g.)&nbsp;<em>Seven</em>&nbsp;was published in 1988. It’s like that. There are fifteen “volumes” (seventeen separate books) in the series.</p><p>As of this writing, you&nbsp;<em>still</em>&nbsp;can’t purchase the entire set. Volume Four remains missing. But even if Volume Four came out tomorrow, no one, not even Bill Gates and Donald Trump put together, could afford it. Their checks would bounce. And suppose they broke into a research library and&nbsp;<em>stole</em>&nbsp;a set? OK, their brains would explode. They’d be dead. Or anyway Gates’s brain would explode; I don’t know what would happen to Trump. I’m saying every volume is between $150 and $350, and each one contains enough information to keep a team of million-IQ weirdos busy for a decade.</p><p>I shouldn’t speak about the other volumes, actually. I’ve never had one in my hands. I know, from other books, they’re considered standard reference works. One is always being directed to them. And there must be at least a few people out there who have the Tang volume or maybe the Han one. It’s all about what period you’re psycho for! Me, I like Six Dynasties poetry a lot, so you may imagine my feelings when I discovered that one of the two volumes in the History that was still missing was the one that would tell me ’bout the politics, language, religion, technology, etc of my pet period.</p><p>No more. This thing has 900 pages; 105 of that is bibliography. It uses the pinyin transliteration system and not the Wade-Giles (first CHC volume to do this), and it begins with an up-to-the-minute survey of how research on the period has been going, for, oh, the last fifty or sixty years. The book is&nbsp;<em>sexy</em>.</p><p>The level of awareness of every single thing published (in a half dozen languages) on the subject of China between the fall of the Han Dynasty and the advent of the Sui–Tang is off the scale. Just the twenty-four pages of the Introduction could send somebody on a hundred happy errands. Right out of the gate, I learned a lot about 20th-century Chinese historians; I had never heard of any of these cats. The Cambridge people basically give you a field guide.&nbsp;</p><p>Also, one finds out about exciting archaeological discoveries of the last twenty-five years—about which I, anyway, knew nothing. For example, apparently in 2009 Cao Cao’s tomb was discovered in Anyang. (I don’t even know what to compare that to. It’s like Biblical scholars finding the gravesite of Moses. ’Cept it’s&nbsp;<em>better</em>&nbsp;than that, ’cuz if they found Moses it would just be bones; whereas, Cao Cao’s tomb was more like Tutankhamun’s.)</p><p>Another thing. One can finally sharpen up all those vague ideas one’s picked up over the years about the period. For example: you know Buddhism and Daoism went from being piddly little trickles to universal practices, studied everywhere, during the Six Dynasties. You’ve always wondered how exactly that went down. This book will straighten out your shit. And it’s just how you like it: essentials, bold strokes. Also, one knows these centuries are called “The Period of Disunity” for a reason; one knows the non-Han tribes or armies or whatever they are—are important. Wanna get all that straight, once and for all? This book is 4 U.</p><p>I mean let’s be honest. During Covid, almost the only thing that literary people are&nbsp;<em>doing</em>&nbsp;is shopping online. Anything that unfolds a vista of new buying opportunities is most welcome. So reference works like this are good. You check the footnotes constantly to see if there’s anything down there you need to order.&nbsp;<em>Family Instructions for the Yen Clan</em>—you’ve been wondering if you actually need to&nbsp;<em>buy</em>&nbsp;that. Well, guess what, you do! Or you can get excerpts from it in Swartz’s&nbsp;<em>Early Medieval China: A Sourcebook</em>&nbsp; (Columbia 2014). See, I didn’t know that&nbsp;<em>Sourcebook</em>&nbsp;existed, until I saw the CHC footnote. Hello, <a href="http://www.bookfinder.com/">www.bookfinder.com</a>! Hello&nbsp; once again,&nbsp;<em>Midtown Scholar</em>&nbsp;in Pennsylvania! Hello, more and more treasures!</p></div></div><div data-block-type="2" id="block-58ed2c38fb345ec844ca"><p>ANTHONY MADRID lives in Victoria, Texas. His poems have appeared in Best American Poetry 2013, Boston Review, Fence, Harvard Review, Lana Turner, LIT, and Poetry. His second book is called TRY NEVER (Canarium Books, 2017).&nbsp;</p></div></div>]]>
            </description>
            <link>https://rhinopoetry.org/reviews/the-cambridge-history-of-china-vol-2-the-six-dynasties-220589-edited-by-lbert-e-dienkeith-n-knapp-reviewed-by-anthony-madrid</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822660</guid>
            <pubDate>Mon, 13 Jul 2020 16:36:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personalization Can Become Your Customer Engagement Engine]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822658">thread link</a>) | @josias
<br/>
July 13, 2020 | https://pirsonal.com/2020/07/08/customer-engagement-engine/ | <a href="https://web.archive.org/web/*/https://pirsonal.com/2020/07/08/customer-engagement-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
	<p>Every organization needs a customer engagement engine. Why? Easier than you thought. Without customers, your organization dies. Customers need to be constantly engaged with your brand. Are your product a good fit for your customers? What about your team and culture? One more question… Are you talking to your customers’ hearts?</p>
<p>Customer-centric organizations constantly connect with their customers. To their values. If you want happy customers, this is the way to go. if you want customers to buy more, there is no better way long-term. If you want your customers to bring referrals, customer engagement is the key.</p>
<p>A customer engagement engine gives your company constant customer feedback. It’s a source of knowledge that helps you improve your offering. A great customer engagement strategy helps you refine your business model. Customer engagement keeps at the top of your market a few meters away from your competition.</p>
<p><img src="https://pirsonal.com/wp-content/uploads/customer-engagement.jpg" alt="Customer Engagement To Drive Loyal Clients" width="700" height="480" srcset="https://pirsonal.com/wp-content/uploads/customer-engagement.jpg 700w, https://pirsonal.com/wp-content/uploads/customer-engagement-768x526.jpg 768w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://pirsonal.com/wp-content/uploads/customer-engagement.jpg 700w, https://pirsonal.com/wp-content/uploads/customer-engagement-768x526.jpg 768w" data-src="https://pirsonal.com/wp-content/uploads/customer-engagement.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p>Exhaustive knowledge of your customers is really helpful here. This starts with a mindset. A mindset that is based on proactive knowledge of your customers. This proactive knowledge of your customers naturally leads you to personalization. Personalization shows you the right path for marketing messages that are aligned with each customer.</p>
<p>No matter the angle, personalization is one of the most profitable tools for your business. Especially in times of crisis. In this article, you will learn how personalization is a key part of a customer engagement strategy. And, most importantly, how to get started.</p>
<p>If you already have a customer engagement strategy structure in place, a financial crisis won’t be as hard on you. If you are just starting, you have bigger challenges ahead. You can still make it. What happens if you do nothing? Prepare to close the doors of your business in the short or mid-term. 12-24 months. Even less. It seems like a long time, but time flies.</p>

<h2><span id="What%E2%80%99s_An_Engine_And_How_It_Affects_Your_Customer_Engagement_Strategy"></span>What’s An Engine And How It Affects Your Customer Engagement Strategy<span></span></h2>
<p>You need to learn from your customers. Each one of them needs you to have a personal approach to what matters to them. Personalization is not a nice-to-have anymore. It becomes a must-have for every wise organization. Growth is then in the little details. The little details are in what you know about your customers. On how you use this information to be relevant to their needs. To resonate with what matters to them, individually.</p>
<p>To be honest, it’s even simpler. If you don’t know your customers, you can not serve them as they deserve or at least as they want.</p>
<p>Let me stop for a moment to talk about engines.</p>
<p>I’m far from being an engineer but at least I love technology. Here is what Wikipedia says about<a href="https://en.wikipedia.org/wiki/Engine"> what an engine is</a>:</p>
<blockquote><p>An engine or motor is a machine designed to convert one form of energy into mechanical energy.</p></blockquote>
<p><img src="https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1.jpg" alt="Segmentation and personalization" width="700" height="480" srcset="https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1.jpg 700w, https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1-768x526.jpg 768w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1.jpg 700w, https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1-768x526.jpg 768w" data-src="https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p>Engines are at the core of all the things that surround you. Engines are the heart of your car. Even of your bike. Not to mention your computer or your marketing automation software. In one or another way, engines are vital for everything we do.</p>
<p>Here is another definition I like. This time for “<a href="https://en.wikipedia.org/wiki/Mechanical_energy">mechanical energy</a>“:</p>
<blockquote><p>In&nbsp;<a title="Outline of physical science" href="https://en.wikipedia.org/wiki/Outline_of_physical_science">physical sciences</a>,&nbsp;<b>mechanical energy</b>&nbsp;is the sum of&nbsp;<a title="Potential energy" href="https://en.wikipedia.org/wiki/Potential_energy">potential energy</a>&nbsp;and&nbsp;<a title="Kinetic energy" href="https://en.wikipedia.org/wiki/Kinetic_energy">kinetic energy</a>. It is the macroscopic&nbsp;<a title="Energy" href="https://en.wikipedia.org/wiki/Energy">energy</a>&nbsp;associated with a system. The principle of conservation of mechanical energy states that if an isolated system is subject only to&nbsp;<a title="Conservative force" href="https://en.wikipedia.org/wiki/Conservative_force">conservative forces</a>, then the mechanical energy is constant. If an object moves in the opposite direction of a conservative net force, the potential energy will increase; and if the&nbsp;<a title="Speed" href="https://en.wikipedia.org/wiki/Speed">speed</a>&nbsp;(not the&nbsp;<a title="Velocity" href="https://en.wikipedia.org/wiki/Velocity">velocity</a>) of the object changes, the kinetic energy of the object also changes.</p></blockquote>
<p>Ok. Maybe that one was too much for most of us.</p>
<p>The thing is that engines are crucial. Engines make things happen. Engines are all about movement. About power. Engines multiply your efforts. When talking about customer engagement, engines will keep your business up and running. Even when some customers need to run away because there is no way they can pay for your service anymore.</p>
<p>Let me ask you something…</p>
<h2><span id="Understand_What%E2%80%99s_The_Engine_Of_Your_Organization"></span>Understand What’s The Engine Of Your Organization<span></span></h2>
<p>What’s the engine of your organization? I’m not talking about your vision or mission statement. I’m not talking about your team and the values behind them. All that is certainly important. You miss it there, the sooner the later your business dies as well.</p>
<p>No matter what you sell. If your customers are not connected to your organization, you are in trouble. At the end of the day, we all have options. We buy from people. You buy from the guy that was just amazing at customer support. Even if it’s not always the same person. You buy from the local coffee shop that knows what you want the moment you get there.</p>
<p>Define the different engines your organization has. This will help you know where you should invest your time and resources. I’m not only talking about a budget. I mainly talk about your brain. Your thoughts. Your ideas. And yes, also your money.</p>
<p>If your customers are not an intrinsic part of your organization’s engine, something is wrong.</p>
<p>How can you emulate that personal touch through your digital channels? This is one of the reasons why people love video. Especially videos that keep it personal. Because these videos are from a human to another human. Obviously, there are times when this is not possible. Times where emails will work just fine. There are times where you’ll use SMS. WhatsApp messages are also becoming more popular.</p>
<p>No matter the communication channel you use to communicate with customers. It needs to be a channel that is aligned with your engine. In the same way, your message needs to be aligned with your customers. If you have a personalization mindset, this becomes easier.</p>
<h3><span id="Examples_Of_Customer_Engagement_Strategies"></span>Examples Of Customer Engagement Strategies<span></span></h3>
<p>Customer engagement starts way before a customer becomes a customer.</p>
<p>Let me give you a simple example.</p>
<p>Want more? Ok. Let me give you two examples of companies with a customer engagement strategy that I know that works.</p>
<h4><span id="Recording_Videos_For_Leads_and_Customers"></span>Recording Videos For Leads and Customers<span></span></h4>
<p>I use personalized videos to engage with some leads after we’ve had a call. There are different types of personalized videos:</p>
<ul>
<li>Videos that are recorded one by one</li>
<li>Videos that you can create automatically from a CSV, CRM, or marketing automation tool.</li>
</ul>
<p>Pirsonal creates this second type of <a href="https://pirsonal.com/individualized-videos/">personalized videos automatically</a>.</p>
<p><a href="https://pirsonal.com/">Pirsonal</a> is a remote-first company. People buy from people. They want to see a face, hear a voice, and feel that I understand their goals and concerns. I do my best so that this happens and video helps me explain things a bit better. So I record a video for these leads.</p>
<p>At Pirsonal we also have a free 1:1 onboarding service. We treat our leads as if they were customers. As a result, we learn a ton from them, which helps us improve our offering. It also helps us to serve them better. Since the experience was great as leads, they are confident to work with us.</p>
<p>A couple of months ago, one of my colleagues interviewed some of the leads and customers that were in touch with me. I’m the CEO at Pirsonal. I work in product development. Since this is my company and I’m a marketer, I also do sales. Because of this, I try to talk to as many people as I can. This way, I learn more about product, marketing, and sales. This helps us to improve our offering.</p>
<p>What he found was positively shocking.<img src="https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal.jpg" alt="Customer Engagement Example by Pirsonal" width="700" height="372" srcset="https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal.jpg 700w, https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal-300x159.jpg 300w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal.jpg 700w, https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal-300x159.jpg 300w" data-src="https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p>In the interviews, he learned that the reason why these leads and customers love Pirsonal. It was because of this personal approach. It happens that our customers are customers that like a personal approach. This personal approach is part of our engine at Pirsonal.</p>
<p>There are times when recording video by video it’s not practical at all. That’s when you can use a <a href="https://pirsonal.com/">personalized video marketing software</a> like Pirsonal. It helps you to interact with hundreds or thousands of individuals. No matter the tool you use. The point is, make sure to understand what your customer engagement engine is. You will help your customers succeed.</p>
<p>As brands, we also love serving people we know. It just makes it easier. Let’s face it. Sometimes this or that customer it’s not the easiest person to deal with. There are times when that account just drives you nuts. There are times when this other account is not even managed by the same person you initially engaged with. But guess what? You still think about that person and want to make it work to honor that other person.</p>
<p>Earlier I mentioned that with Pirsonal you can create personalized videos. You can easily create them using a CSV, CRM or any marketing tool. I recorded this video to show you how to this with a CSV:</p>
<p><iframe title="Creating Personalized Videos From A CSV With Campaign By Pirsonal" width="1140" height="641" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-src="https://www.youtube.com/embed/d3QR5JHUcRw?feature=oembed" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>
<h4><span id="Using_Personalized_Videos_For_A_Customercentric_Strategy_In_The_Travel_Industry"></span>Using Personalized Videos For A Customer-centric Strategy In The Travel Industry<span></span></h4>
<p>Here is the second example of a customer engagement strategy that works.</p>
<div class="page" title="Page 1">
<div>
<div>
<div>
<p><a href="http://flightcentre.co.za/">Flight Centre</a> <a href="https://pirsonal.com/2018/08/17/use-personalized-video-marketing-to-improve-your-sales/">accelerates its sales process by using personalized video marketing</a> powered by Pirsonal. This happens when leads request a quote. The brand automatically creates a personalized video, personalized landing page, and custom in- video call-to-action. All this multimedia content is personalized using the information provided by the lead. They use data such as name, the reason to travel, or destination. This makes these personalized videos and emails totally relevant to each individual.</p>
<p><iframe title="Personalized Video Example for a Travel Agency" width="1140" height="641" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-src="https://www.youtube.com/embed/fDAfTryXEpc?feature=oembed" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>
<p>When they do this, Flight Centre increases lead engagement. This lead engagement moves these leads to buy more and faster. Every personalized video is instantly sent by email. This increases customer engagement and builds stronger relationships. At the same time, this translates into higher levels of loyalty and into more revenue.</p>
<p>Why do I like this strategy? It’s aligned with the personal touch of the company. This happens through all communication channels. It is part of their value proposition. Check the image below to see their value proposition.</p>
<p><img src="https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency.png" alt="Customer Engagement - Online Travel Agency" width="1088" height="388" srcset="https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency.png 1088w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-300x107.png 300w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-1024x365.png 1024w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-768x274.png 768w" sizes="(max-width: 1088px) 100vw, 1088px" data-srcset="https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency.png 1088w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-300x107.png 300w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-1024x365.png 1024w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-768x274.png 768w" data-src="https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
</div>
</div>
</div>
</div>
<p>Seems obvious? Make sure that your customers are at the core of your customer engagement engine.</p>
<h2><span id="Why_Customer_Engagement_Needs_To_Be_The_Engine_Of_Your_Organization"></span>Why Customer Engagement Needs To Be The Engine Of Your …</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pirsonal.com/2020/07/08/customer-engagement-engine/">https://pirsonal.com/2020/07/08/customer-engagement-engine/</a></em></p>]]>
            </description>
            <link>https://pirsonal.com/2020/07/08/customer-engagement-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822658</guid>
            <pubDate>Mon, 13 Jul 2020 16:36:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Default Sorting in Your Eloquent Models]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822570">thread link</a>) | @stehenjude
<br/>
July 13, 2020 | http://stephenjude.me/articles/getting-started-with-default-sorting-in-your-eloquent-models | <a href="https://web.archive.org/web/*/http://stephenjude.me/articles/getting-started-with-default-sorting-in-your-eloquent-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div v-pre="">
    <p><a href="https://github.com/stephenjude/default-model-sorting" target="_blank">Default Model Sorting </a>package is a mini Laravel package I published recently. By default, Laravel Eloquent models return queries that are ordered by the <code>id</code> column of the model table. </p><p>With this package, you can set default order by in your Eloquent model so you don't have to call the orderBy Eloquent builder.</p><pre spellcheck="false"><span>&lt;?php</span>

Article::orderBy(<span>'title'</span>, <span>'asc'</span>)-&gt;get(); 


Art﻿icle::all(); 

</pre><h2>Installation</h2><p>First you have to install this package via composer.</p><pre spellcheck="false">composer <span>require</span> stephenjude/<span>default</span>-model-sorting
</pre><h2>Usage</h2><p><span>Using the&nbsp;</span><code>DefaultOrderBy</code><span>&nbsp;trait of this package, you can set the default column you want to sort by.</span></p><p><span>For example, if you want to set the default order column for </span><code>Article</code><span> model (assuming you are building a blog).  You will use the </span><code>DefaultOrderBy</code><span> trait and set the </span><code>$orderByColumn</code><span> property inside your </span><code>Article</code><span> model.</span></p><pre spellcheck="false"><span>use</span> <span>Stephenjude</span>/<span>DefaultModelSorting</span>/<span>Traits</span>/<span>DefaultOrderBy</span>;

<span><span>class</span> <span>Article</span> <span>extends</span> <span>Model</span>
</span>{
    <span>use</span> <span>DefaultOrderBy</span>;

    <span>protected</span> <span>static</span> $orderByColumn = <span>'title'</span>;
}
</pre><p>Now your <code>Article</code> model queries will be ordered by title column in ascending order.</p><p>You can also set the <code>$orderByColumnDirection</code> property. This property is set to <code>asc</code> as the default value.</p><pre spellcheck="false"><span>protected</span> <span>static</span> $orderByColumnDirection = <span>'asc'</span>;
</pre><p>To set the global default <code>$orderByColumnDirection</code> property, publish the package configuration file.</p><pre spellcheck="false"><span>php</span> artisan vendor:publish --provider=<span>"Stephenjude\DefaultModelSorting\DefaultModelSortingServiceProvider"</span> --tag=<span>"config"</span>
</pre><p>Now you can update the configuration file as you desire.</p><pre spellcheck="false">
﻿<span>return</span> [    
    
    <span>'order_by'</span> =&gt; <span>'asc'</span>,
];
</pre><h2>Under The Hood</h2><p>This package is has a trait <code>DefaultOrderBy</code> that adds a <code>default_order_by</code> global scope  to the <code>boot()</code> method of your Eloquent model.</p><pre spellcheck="false"> <span>&lt;?php</span>
﻿ ...
 <span>protected</span> <span>static</span> <span><span>function</span> <span>boot</span><span>()</span>
 </span>{
     <span>parent</span>::boot();

     
     $column = <span>Self</span>::$orderByColumn;

     
     $direction = <span>isset</span>(<span>Self</span>::$orderByColumnDirection)
            ? <span>Self</span>::$orderByColumnDirection
            : config(<span>'default-model-sorting.order_by'</span>);
     
     
     <span>static</span>::addGlobalScope(<span>'default_order_by'</span>, <span><span>function</span> <span>(Builder $builder)</span> <span>use</span> <span>($column, $direction)</span> </span>{
            $builder-&gt;orderBy($column, $direction);
        });
} 
</pre><p>If you don't want to use the package, you can add this code to your Eloquent model.</p><p>If you find this package helpful please give it a start on <a href="https://github.com/stephenjude/default-model-sorting" target="_blank">Github</a>. </p>
</div></div>]]>
            </description>
            <link>http://stephenjude.me/articles/getting-started-with-default-sorting-in-your-eloquent-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822570</guid>
            <pubDate>Mon, 13 Jul 2020 16:28:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ideas Are Worthless]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822473">thread link</a>) | @graiz
<br/>
July 13, 2020 | https://gregraiz.com/ideas-are-worthless/ | <a href="https://web.archive.org/web/*/https://gregraiz.com/ideas-are-worthless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main"><article id="post-620"><div><div><p>You may thinkyou have the best, most amazing idea but I’m sorry to tell you that your idea is worthless…. But it’s Ok, most ideas are worthless.</p><p>Now before I get too deep, I’ve seen hundreds of pitches with a wide range of ideas and I’ve signed stacks and stacks of NDA’s to keep someone’s ideas secrets. Want to know the best secret idea I’ve ever heard?</p><p>There are none. We’re you listening at the beginning? Ideas are worthless and I’ve never been blown away by an amazing idea. Never! I’ve heard interesting ideas and clever ideas but most of the time amazing ideas are not the exciting part.</p><p>If you just think about the ideas behind the world’s most successful companies, the ideas aren’t that exciting.</p><ul><li>A phone that doesn’t have any buttons</li><li>A car that uses electricity instead of a motor</li><li>A new search engine</li></ul><p>These ideas by themselves have no value and even if you were able to rewind the clock 20 years, the ideas themselves weren’t worth anything without the entrepenours to drive them.</p><p>Nokia had phones without buttons before Apple. There were plenty of electric golf-carts before Tesla, and Google was late to the game as far as search engines go.</p><p>It’s the execution that creates value and these companies executed exceptionaly well.</p><p>While ideas are worthless, working on your idea is the thing that starts to create value. Some examples of value creation:</p><ul><li>A list of potential customers willing to try or buy a finished product</li><li>Sales or purchase orders for a product or service</li><li>A prototype of the future product</li><li>Testimonials from people who have tried the prototype/product</li><li>Partners willing to stock or sell the product/service</li><li>Patents on the product/technology. (<a href="https://www.youtube.com/watch?v=Jmvle3M1_4g">more on patents here</a>)</li></ul><p>You don’t have to be an engineer or designer to make progress on an idea, but you need to take action.</p><p>The other reason that ideas are worthless is that the idea instantly changes as soon as you start working on it. Once you put a pencil to paper your idea starts to spawn new ideas. Once you have a customer using the product you start to get feedback on the idea and what needs to change about it. Once you try to sell a product you learn all the reasons people don’t want it. It’s this learning/feedback cycle that creates real value because it’s based on real applications, not just theoretical ones.</p><p>The execution of the idea is the essence of the idea. Want to make something amazing, take action to make it real.</p><figure><p> <iframe title="Ideas are WORTHLESS!" width="580" height="326" data-src="https://www.youtube.com/embed/m4gMd7Rw1ps?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><figcaption>Why are ideas worthless</figcaption></figure></div></div></article></div></div>]]>
            </description>
            <link>https://gregraiz.com/ideas-are-worthless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822473</guid>
            <pubDate>Mon, 13 Jul 2020 16:20:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Gordian knot of identity and achievement]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822339">thread link</a>) | @khehy
<br/>
July 13, 2020 | https://radreads.co/identity-achievement/ | <a href="https://web.archive.org/web/*/https://radreads.co/identity-achievement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 itemprop="name"><span itemprop="dateCreated">11 Jul<meta itemprop="interactionCount" content="UserComments: 0"></span> The Gordian knot of identity and achievement</h2><p>“Stress is a perverted relationship to time.” These words from <a href="https://onbeing.org/programs/john-odonohue-the-inner-landscape-of-beauty-aug2017/">the late Irish poet, John O’Donohue</a> are truthfully incisive.</p><p>And whether it’s using <a href="https://radreads.co/text-expander/">Text Expanders</a> or doing Tabata Burpee workouts – I’ve always been in the hot pursuit of more time.</p><p>The chase is straight forward. More free time equals <em>more time to do stuff</em>. Doing more stuff means notching <em>more income, subscribers, accolades</em>… <strong>and achievements.</strong></p><p>The result is a deep intertwining of identity and achievement. A terrifying twosome that leads to FOMO, <a href="https://radreads.co/the-paradox-of-self-employment-burnout/">burnout</a>, and anxiety.</p><p>Separating identity from achievement is an <em>involved problem:</em> <strong>untangling a Gordian Knot.</strong></p><div><figure><img src="https://embed.filekitcdn.com/e/soCyR57pgxv3XZJLXQFY1r/ciefdDdbKt6m66cgM7Z6zY/email" alt="" width="400" height="367" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div><p>Now this ain’t a knock on striving. We’ve all stared for hours at that seemingly intractable problem – then experienced the bliss of discovering the elusive solution.</p><p>Applying your skills to your craft brings a deep sense of satisfaction and fulfillment. As the poet David Whyte writes in <a href="https://amzn.to/2DxWsTa">Crossing the Unknown Sea: Work as a Pilgrimage</a>:</p><blockquote><p><em>Good work, done well, for the right reasons.</em></p></blockquote><p>But we get tripped up by “for the right reasons” when we integrate our sense of <strong>self-worth</strong> with our identity.</p><p>Like the stock market, accomplishments <strong>ebb and flow</strong>. They <strong>come and go</strong>. You may be able to control the inputs (a la <a href="https://qz.com/890093/trust-the-process-how-three-years-of-losing-on-purpose-turned-the-philadelphia-76ers-into-winners/">Trust the Process</a>); but the outputs are subject to a high degree of randomness. Pegging our identity this noisy stochastic process can heap unnecessary suffering into our lives</p><h2>Is self-love conditional?</h2><p>But there’s something even more pernicious at play. Would you ever tell your child “I’ll only love you if you get into straight As?” Would you ever tell your BFF “I’ll only be your homie if you get promoted to partner?”</p><p><strong>If that sounds silly, consider the preconditions you set for loving yourself.</strong></p><p>How do you <a href="https://radreads.co/negative-self-talk/">talk to yourself</a> when your striving falls short? Or when you botch a big presentation? In one of his most famous posts, Seth Godin rhetorically asks who is <a href="https://seths.blog/2010/12/the-worlds-worst-boss/">the world’s worst boss</a>?</p><p>His answer: <strong>It’s you.</strong> Why? Says Godin:</p><blockquote><p><em>If you had a manager that talked to you the way you talked to you, you’d quit.</em></p></blockquote><p>Untangling the Gordian Knot of identity and achievement means dropping the construct of conditional love for ourselves. In Shirzad Chamine’s wonderful book <a href="https://amzn.to/3ekmENM">Positive Intelligence</a> he writes:</p><blockquote><p><em>The most damaging lie is that we are not worthy of love or respect by just being who we are. Instead, it forces us to constantly perform; this forms the construct of “conditional love.” But conditional love is not real love.</em></p></blockquote><p>Chamine offers a nostalgic recommendation to “shift your brain” to feel empathy and caring for yourself:</p><blockquote><p><em>Visualize yourself as a child in a setting where your essence is shining through. Perhaps you are holding a puppy, building a sandcastle, chasing a bunny, or snuggling with a loved one. Put that picture on your desk or on your phone or computer so that you see it frequently. This image will be a reminder that your true essence is worthy of unconditional caring and empathy when you are feeling beaten down by yourself, others, or the troubles of life. </em></p></blockquote><div><div id="tve_tcb2_blank" data-state="2" data-form-state=""><div data-tl-type="shortcode_580"><div><div id="tve_editor"><div data-css="tve-u-05d5f19b06f29a"><p data-tag="h2"><h2 data-css="tve-u-15d5f19b06f2d4">Stop letting Monday ruin Sunday</h2></p><p data-css="tve-u-35d5f19b06f343">Join 17,115 RadReaders who kissed the&nbsp;<em>Sunday Scaries</em>&nbsp;goodbye!</p></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://radreads.co/identity-achievement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822339</guid>
            <pubDate>Mon, 13 Jul 2020 16:11:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Residential Proxies vs. Data Center Proxies in Web Scraping]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822331">thread link</a>) | @Himanshi
<br/>
July 13, 2020 | https://scrapinghub.zoom.us/webinar/register/6015946565371/WN_RRP09QSRSHSazeDgVuhTOQ | <a href="https://web.archive.org/web/*/https://scrapinghub.zoom.us/webinar/register/6015946565371/WN_RRP09QSRSHSazeDgVuhTOQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><label for="timezone">Time Zone:</label>&nbsp;&nbsp;

</p>
</div>
</div></div>]]>
            </description>
            <link>https://scrapinghub.zoom.us/webinar/register/6015946565371/WN_RRP09QSRSHSazeDgVuhTOQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822331</guid>
            <pubDate>Mon, 13 Jul 2020 16:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From scratch to the first 10 customers. How I launched my SaaS product]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822081">thread link</a>) | @valerione
<br/>
July 13, 2020 | https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/ | <a href="https://web.archive.org/web/*/https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                <div>
                                    <div>
                                        
<p>Creating a successful software as a service (SaaS) product is the dream for many entrepreneurial-minded programmers. </p>



<p>In the process of launching my own SaaS I discovered that sharing and<br>comparing experiences with other founders is an essential part of this journey, and without this, I probably would never have created it at all. </p>



<p>In this article, I’ll share the mental and practical process that led me to create a SaaS product from scratch, and how I gained my first paying customers.</p>



<p>Whether you are thinking about creating a new product or you have already launched, this article can help you compare your own strategies and methods with the ones that worked for me, and possibly adapt them for yourself.</p>



<p>I personally dedicate up to five hours per week researching the experiences of other founders. I’m always looking for new ideas and ways to avoid mistakes, and evaluating new strategies that could help me obtain concrete results (that is, improve the product and increase customers’ happiness).</p>



<p>For this reason, I decided to work in a completely frank and transparent way and share everything about my path — including what has been working and what has not — with the aim of helping one another through direct and rational discussion.</p>



<p>The article is divided into seven chronological sections, following every phase of the work I have done:</p>



<ul><li>Detecting the problem</li><li>Quantifying the problem</li><li>Evaluating competitors and their approach to the problem</li><li>Developing the first prototype</li><li>Throwing everything away and starting again</li><li>Getting the first subscription</li><li>How to move forward</li></ul>



<p>The SaaS product I built is <a href="https://www.inspector.dev/">Inspector</a>, a real-time monitoring tool which helps software developers to avoid losing customers and money due technical problems in their applications.</p>



<h2>Detecting the problem</h2>



<p>Spending the last 10 years working with software development teams made me realize how complicated it is for developers to handle technical problems which affect applications every day.</p>



<p>Development teams have close relationships with their customers, and this is a high risk for companies which produce software, because with problems you realize how fragile this bond really is.</p>



<p>Users do not like problems! It seems obvious, but this aspect is constantly underestimated. This is an uncomfortable truth. No one likes to be in trouble, and it is instinctive to minimize the problem.</p>



<p>But by denying reality you could annoying the customer even more, to the point where they may even reconsider whether or not they “should” even pay you. </p>



<p>Customers do not spend their time reporting problems and application errors. No one cares about helping us resolve bugs. They just leave our application, and it will probably take years before we see them again.</p>



<p>Despite this, every team I have worked with used the best-known method of figuring out whether applications were working properly or not:</p>



<blockquote><p><em>“If an angry customers calls you, the software is not working.”</em></p></blockquote>







<p>It is not exactly a technological solution…</p>



<p>Maybe it seems ridiculous, but beyond the perception tycoons of technology project on our jobs, insiders know that urgency, limited budget, pressing customers, managers, forcing developers to constantly work under pressure, and adopting Band-Aid solutions (to temporarily fix a problem) as a survival strategy.</p>



<p>Working this approach for 10 years helped me realize there is clearly a problem.</p>



<h2>Quantifying the problem</h2>



<p>At the beginning of 2019 I had just finished some important projects and I was expecting to enjoy a little period of calm.</p>



<p>During the last years I have used these moments to look for business opportunities which allow me to put my technical skills to good use with the hope of finding the right conditions to launch my own business idea.</p>



<p>I knew from my experience as a developer that an easy and immediate monitoring instrument would be enough to help development teams to stay up-to-date about the performance of applications, instead of relying on customer calls to know when the software was creating problems.</p>



<p>On the other hand, I did not need a tool to monitor everything, as everything often means nothing.</p>



<p>And I didn’t want it to be complicated — I did not want to spend a month learning how it worked or need to hire expert engineers just for this job.<br>My life had to be made easier than before. It was necessary to have a ready-to-go developer tool.</p>



<p>The first step was to understand if there already were solutions trying to solve this problem, so I googled “<em>application monitoring</em>” and 941,000,000 results appeared:</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2020/07/google-results.png" alt="" srcset="https://www.inspector.dev/wp-content/uploads/2020/07/google-results.png 1011w, https://www.inspector.dev/wp-content/uploads/2020/07/google-results-300x60.png 300w, https://www.inspector.dev/wp-content/uploads/2020/07/google-results-768x154.png 768w, https://www.inspector.dev/wp-content/uploads/2020/07/google-results-980x197.png 980w" sizes="(max-width: 1011px) 100vw, 1011px"></figure>



<p>Wow. That’s a very huge amount of contents for a problem that probably is huge.<br>But how huge, exactly?</p>



<p>Software development team inefficiency is a problem I have always faced directly, but there is a big difference between estimating a job task and quantifying the economic impact of a problem. </p>



<p>It is even more difficult on a large scale. </p>



<p>This tweet captured my attention:</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2019/09/1_A_aGsKJKY5I9y5KzJOsCdg.png" alt="" srcset="https://www.inspector.dev/wp-content/uploads/2019/09/1_A_aGsKJKY5I9y5KzJOsCdg.png 635w, https://www.inspector.dev/wp-content/uploads/2019/09/1_A_aGsKJKY5I9y5KzJOsCdg-300x240.png 300w" sizes="(max-width: 635px) 100vw, 635px"></figure>



<p><strong>The 50% of developers declare to spend up to 50% of time just to constantly verify that applications are working.</strong></p>



<p>Software development is work mostly paid by the time technicians spend working on a project, and if there are periods in which developers spend 50 percent of their time checking that everything is okay, a tool which<br>completely automates this job could be useful enough to buy.</p>



<p><strong>So why aren’t they so common to so many developers?</strong></p>



<h2>Evaluating competitors and their approach to the problem</h2>



<p>I thought about the two main parameters a company looks at when it has to decide which tools use to increase productivity:</p>



<ol><li><em>Simplicity </em>(ease of installation and use)</li><li><em>Efficacy </em>(I spend x to solve a problem which is worth x+10, so I gain the +10)</li></ol>



<p>Using these parameters, I spent about a week creating an evaluation sheet of the most well-known monitoring instruments and I placed them in a graphic:</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2020/07/market-en-1024x533.png" alt="" srcset="https://www.inspector.dev/wp-content/uploads/2020/07/market-en-1024x533.png 1024w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en-300x156.png 300w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en-768x400.png 768w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en-1536x800.png 1536w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en-980x510.png 980w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en.png 1841w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>After days of putting information together, a look at the graphic was enough to realize where the problem was.</p>



<p>Easy instruments do not provide enough value to the majority of developers. </p>



<p>More complete instruments, instead, are thought of as being for big organizations, and they need skilled staff who dedicate themselves to their installation, configuration and use, complicating team operations rather<br>than simplifying them.</p>



<p><strong>In my vision, the problem is not the monitoring itself but the development team efficiency.</strong></p>



<p>For a massive adoption, it would be necessary to have a product which requires a minute for the installation, no configurations and, at the same time, that provides complete and easy information to consult that would allow even medium-size development teams to fix the real-time monitoring problem.</p>



<p>And of course, it has to be cool.</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-1024x533.png" alt="" srcset="https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-1024x533.png 1024w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-300x156.png 300w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-768x400.png 768w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-1536x800.png 1536w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-980x510.png 980w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en.png 1841w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>Developing the first prototype</h2>



<p>Finally, I decided to try. The last work experience had gone well and I thought that it would not be impossible for me to create this tool.</p>



<p>So, I immediately informed my partners that I wanted to build an MVP for the following two or three months. </p>



<p>When I explained it to them, it was hard to make them understand the problem because they are not technicians involved at the same level I am. They gave me the okay based 90 percent on trust, and I thank them for this.</p>



<p>Over the course of three months I was able to create this prototype:</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2020/07/proto.gif" alt=""></figure>



<p>While working on the implementation, I gradually understood the problems of realizing this kind of tool and even problems users would encounter during its use.</p>



<p>From a technical point of view, a monitoring product has to be designed to work with huge quantities of data and I also wanted to deal with these data in real-time.</p>



<p>I had to spend longer than I predicted for the backend part —in other words, the part which cannot be seen, or the backstage of an in-cloud software — leaving out the graphic interface (as you can see above), which is the part users see and use.</p>



<h2>Throwing everything away and starting again</h2>



<p>In the last few years, the dream of launching a product on the market pushed me to constantly study and apply marketing strategies which are particularly adept for SaaS software, to different projects (even the failed ones).</p>



<p>I started to write articles for my blog with the aim of publishing them on different websites and social media to collect the first feedback.</p>



<p>Although I wrote horrible content in English with writing mistakes because English is not my mother tongue, feedback started to come.</p>



<ul><li>I do not understand what I can do with it;</li><li>How can I install it?</li><li>Why use it rather than XXX?</li><li>What does it offer which makes it different from any other one?</li><li>Etc…</li></ul>



<p>It was not easy to be objective while looking at developers’ responses and comments. <em>Emotional reaction</em> could always take advantage and it was really hard for me to understand where the mistake was because I am not a sales agent or a seller, but I am a damn good technician.</p>



<h3>Lesson 1 – Selling sucks</h3>



<p>Thanks to my technical skills on the matter, I did not need to sell. Rather, I just needed to learn how to communicate the problems I faced every day and how I fixed them with my tools.</p>



<p>I spent an entire month writing the most important things I knew about the monitoring and application scalability problems and the reasons why I decided to start this project, the difficulties I had been encountering during the development of a product, how I fixed them and moved forward,<br>code examples, technical guides, my best practices, and more.</p>



<p>Then I gave everything to <a href="https://www.fiverr.com/robinoo/professionally-proofread-1000-words?context=recommendation&amp;context_alg=recently_ordered%7Cco&amp;context_referrer=homepage&amp;context_type=gig&amp;mod=rep&amp;pckg_id=1&amp;pos=1&amp;source=recently_and_inspired&amp;tier_selection=recommended&amp;ref_ctx_id=1bf19e6d-aa27-407d-86ea-f8ca268b8131" target="_blank" rel="noreferrer noopener">Robin</a>, a Canadian copywriter found on Fiverr, who corrected all the content, including the website text, and polished the writing into native-level English.</p>



<h3>Lesson 2 – Insufficient product</h3>



<p>The fear of leaving out the user interface turned out to be a well-founded fear. What I did was not enough …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/">https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/</a></em></p>]]>
            </description>
            <link>https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822081</guid>
            <pubDate>Mon, 13 Jul 2020 15:52:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Metric for determining quantitative product market fit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821916">thread link</a>) | @firatcan
<br/>
July 13, 2020 | https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit | <a href="https://web.archive.org/web/*/https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5d47b84bb0f5980001a8659e" data-item-id="5d47b84bb0f5980001a8659e">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1564981747123" id="item-5d47b84bb0f5980001a8659e"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_86260"><div><h2>About the author</h2><p><a href="https://www.linkedin.com/in/jeff-chang-82467459/" target="_blank">Jeff Chang</a>&nbsp;(<a href="https://twitter.com/JeffChang30" target="_blank">@JeffChang30</a>) is a growth technical leader at Pinterest and angel investor. If your US based software startup is looking for an angel investor who can help with all things growth, please send over an <a href="mailto:jeff@growthengblog.com" target="_blank">email</a>!</p><h2>Intro</h2><p>There are many definitions of product market fit:</p><ul data-rte-list="default"><li><p>Product market fit is your NPS score</p></li><li><p>Product market fit is when 40% of your users would be “very disappointed” if they no longer have access to your product</p></li><li><p>Product market fit is a feeling</p></li><li><p>You need a good distribution channel to have product market fit</p></li><li><p>… and the list goes on</p></li></ul><p>Most of these definitions are pretty good - you can be successful using them and none of them are “wrong”. However, I think cohort retention rate is the most important product market fit metric, so I would recommend using it <strong>along with</strong> any other frameworks you use. This blog post describes what makes a good product market fit metric, evaluates a few definitions, and explains why cohort retention rate is a great metric to use.</p><p>Caveat: This only applies to multiple-use or subscription products, which is the vast majority of products. Examples of single-use products are mortgages and other types of loans, where a user is likely only going to purchase one over a long period of time.</p><p>Prior to product market fit, you should be focused on making the product better for your existing users. When a product has “product market fit”, it means that the product is good enough to start shifting focus from improving the product to growing distribution channels. If you distribute a product that isn’t great, even if you are able to get a lot of initial users, a few months down the road your user base won’t grow significantly or may even decline. So, you can also think of product market fit as “time to start building scalable acquisition channels”.</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_18093"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1565021640768-FHT3J2F1MRWQ0QDWK1C0/ke17ZwdGBToddI8pDm48kHTnMI9GKb6BUNDIc1KZu2Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qqZFlQdVp7vViofexDEbEjBU2kxk2iQDc_of-xO2WgiWAAEOXDqVf-TecXDYuKLRw/growthenblog-PMF.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1565021640768-FHT3J2F1MRWQ0QDWK1C0/ke17ZwdGBToddI8pDm48kHTnMI9GKb6BUNDIc1KZu2Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qqZFlQdVp7vViofexDEbEjBU2kxk2iQDc_of-xO2WgiWAAEOXDqVf-TecXDYuKLRw/growthenblog-PMF.png" data-image-dimensions="2500x1413" data-image-focal-point="0.5,0.5" alt="After you reach product market fit, you can spend more effort building scalable acquisition channels" data-load="false" data-image-id="5d4855bf511aa1000170d8a1" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1565021640768-FHT3J2F1MRWQ0QDWK1C0/ke17ZwdGBToddI8pDm48kHTnMI9GKb6BUNDIc1KZu2Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qqZFlQdVp7vViofexDEbEjBU2kxk2iQDc_of-xO2WgiWAAEOXDqVf-TecXDYuKLRw/growthenblog-PMF.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>After you reach product market fit, you can spend more effort building scalable acquisition channels</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_88416"><div><p>A good product market fit metric will have a low rate of false positives and false negatives. It won’t tell you that you should start distributing when your product <strong>isn’t</strong> good enough, and it won’t tell you that you shouldn’t start distributing when it <strong>is</strong> good enough.</p><p>The risk with false positives is that you work on distribution when you should be working on making the product better, which results in wasted distribution efforts due to churned users. The risk of false negatives is that you don’t work on distribution early enough to compete with competitors or meet goals needed to raise your next round before you run out of runway.</p><p>To summarize, a good product market fit metric:</p><ul data-rte-list="default"><li><p>Will tell you when the product is good enough to work acquisition channels</p></li><li><p>Minimizes false positives - won’t tell you to work on acquisition channels when the product needs more improvement</p></li><li><p>Minimizes false negatives - will tell you to on acquisition channels as soon as the product is good enough, to maximize growth</p></li></ul><p>Let’s evaluate some product market fit definitions based these points.</p><h2>Top tech companies in the world are able to grow with bad NPS</h2><p>NPS is sometimes used as a product market fit metric, but some of the biggest tech companies in the world have terrible NPS, but are still able to grow to over a billion users:</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_22020"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981498537-28F6C1E0ZFG1YBVPT7HD/ke17ZwdGBToddI8pDm48kNwP3op2XcRFs5h0t7BO7VcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmg0eN-jBGCjq7e1B29HVcy1u46tppJcCjeNJYG1KqgdCjLISwBs8eEdxAxTptZAUg/PMF-NPS.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981498537-28F6C1E0ZFG1YBVPT7HD/ke17ZwdGBToddI8pDm48kNwP3op2XcRFs5h0t7BO7VcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmg0eN-jBGCjq7e1B29HVcy1u46tppJcCjeNJYG1KqgdCjLISwBs8eEdxAxTptZAUg/PMF-NPS.png" data-image-dimensions="1518x808" data-image-focal-point="0.5,0.5" alt="Source:  https://customer.guru/net-promoter-score/top-brands" data-load="false" data-image-id="5d47b8fa48c3ef0001914224" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981498537-28F6C1E0ZFG1YBVPT7HD/ke17ZwdGBToddI8pDm48kNwP3op2XcRFs5h0t7BO7VcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmg0eN-jBGCjq7e1B29HVcy1u46tppJcCjeNJYG1KqgdCjLISwBs8eEdxAxTptZAUg/PMF-NPS.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_102815"><div><p>NPS as a product market fit metric has both false positives and false negatives.</p><h2>Other survey based metrics are better, but have a few flaws</h2><p>“40% of your users would be ‘very disappointed’ if they could no longer use your product” is a commonly used metric that most recently was used by <a href="https://firstround.com/review/how-superhuman-built-an-engine-to-find-product-market-fit/" target="_blank">Superhuman</a> to find product market fit, with great success. This is a much better metric than NPS and if you end up using this and reach it, you probably do have product market fit. However I think there are some flaws with survey based metrics:</p><p>Response bias - it’s really hard to get everyone to fill out a survey. As a result, you might find that that the distribution of survey results don’t actually match the true distribution of results if everyone answered due to the missing responses.</p><p>It’s a single snapshot in a long user journey - when is the best time to ask this question? If you ask it in the beginning, maybe their opinion will change over time. When a user signs up for a product, generally their intent is high. So, you should ask it later in the flow. However, if you ask it later, some users already dropped off so you are biasing results to higher intent users, which are the ones that stay.</p><p>Responses don’t match behavior - If you’ve worked on product or growth for a while, you should be familiar that what users aren’t always accurate at predicting their future behavior. For example, you could build a feature that a lot of users say they would use if available, but then after you launch, they might not actually use it.</p><p>While this metric is one of the best out there, I think that it can produce some false negatives, meaning you might have product market fit even if this number is not 40%.</p><h2>Distribution shouldn’t be a requirement for product market fit</h2><p>Some definitions of product market fit include a distribution aspect. I actually don’t think distribution is part of product market fit, because there is enough data on what distribution channels generally work, <a href="https://www.growthengblog.com/blog/the-2-most-popular-scaled-growth-channels-for-unicorn-consumer-companies-part-1-seo" target="_blank">SEO</a> and <a href="https://www.growthengblog.com/blog/the-2-most-popular-scaled-growth-channels-for-unicorn-consumer-companies-part-2-referral" target="_blank">referrals</a> for example. If you’re a consumer company, at least one of these channels should work for you. These two channels also have some sort of a moat - it takes a <strong>lot</strong> of effort and time to outrank current SEO “winners”, and referrals become a stronger channel the bigger userbase you have. Paid will also work to some degree, but shouldn’t be relied on as a scalable channel long term for most companies (unless your LTV is high and payback period is short). I’ve never met with a startup where after studying the product, my conclusion was “there are no distribution channels that will work for this startup”. In my opinion, any product with great cohort retention rate can be distributed with good growth strategy and execution.</p><h2>What is cohort retention rate?</h2><p>There are many methods of measuring retention rate but I think cohort retention rate is the one to use. Any sort of retention rate metric that mixes differently tenured users doesn’t make sense because the retention rates vary drastically between a new user and long term user. Here’s my definition:</p><p>Cohort retention rate - given a group of users who joined around the same time, the % of those users that stay long term</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_124121"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988916522-8VO65CW6QWP0LB2K0SC9/ke17ZwdGBToddI8pDm48kO_YhcHfcgYMoj0_UHY-iE9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxC1T2QDlrFhzAg5RRZ1oHSO7oIfdgckfXb5vveEdSKzgjBXZ6MOJz-yy4NEMKvr4s/cohort_retention_good.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988916522-8VO65CW6QWP0LB2K0SC9/ke17ZwdGBToddI8pDm48kO_YhcHfcgYMoj0_UHY-iE9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxC1T2QDlrFhzAg5RRZ1oHSO7oIfdgckfXb5vveEdSKzgjBXZ6MOJz-yy4NEMKvr4s/cohort_retention_good.png" data-image-dimensions="597x367" data-image-focal-point="0.5,0.5" alt="This is an example of a cohort retention graph for a single cohort. The cohort retention rate is around 30% because that’s where the graph flattens out." data-load="false" data-image-id="5d47d5f41c7ed7000177606d" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988916522-8VO65CW6QWP0LB2K0SC9/ke17ZwdGBToddI8pDm48kO_YhcHfcgYMoj0_UHY-iE9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxC1T2QDlrFhzAg5RRZ1oHSO7oIfdgckfXb5vveEdSKzgjBXZ6MOJz-yy4NEMKvr4s/cohort_retention_good.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>This is an example of a cohort retention graph for a single cohort. The cohort retention rate is around 30% because that’s where the graph flattens out.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_119783"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988901319-JJ1GA3BZIKG7M0IEDJDM/ke17ZwdGBToddI8pDm48kAy5zisSUbAQSoB4q23pwuVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxvX7ZUME6r9ofLwPn30uTZsYn3Ty3SmCFIWGDEreIyhIIxsTGkOokFDROPJbuS4sk/cohort_retention_bad.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988901319-JJ1GA3BZIKG7M0IEDJDM/ke17ZwdGBToddI8pDm48kAy5zisSUbAQSoB4q23pwuVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxvX7ZUME6r9ofLwPn30uTZsYn3Ty3SmCFIWGDEreIyhIIxsTGkOokFDROPJbuS4sk/cohort_retention_bad.png" data-image-dimensions="590x365" data-image-focal-point="0.5,0.5" alt="If the graph never flattens out, then the cohort retention rate is 0%" data-load="false" data-image-id="5d47d5e5cdea4800010b6758" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988901319-JJ1GA3BZIKG7M0IEDJDM/ke17ZwdGBToddI8pDm48kAy5zisSUbAQSoB4q23pwuVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxvX7ZUME6r9ofLwPn30uTZsYn3Ty3SmCFIWGDEreIyhIIxsTGkOokFDROPJbuS4sk/cohort_retention_bad.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>If the graph never flattens out, then the cohort retention rate is 0%</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_129312"><div><p><br>For more information on how to measure this, check out my other blog post: <a href="https://www.growthengblog.com/blog/the-most-important-growth-metric-for-early-startups" target="_blank">The most important growth metric for early startups</a></p><p><br>As you improve your product, newer cohorts will have high cohort retention rates. So, it’s important to have a cohort retention “triangle” chart to track progress:</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_25917"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981669190-6YSFKD4PJ6X1OJBOCJEL/ke17ZwdGBToddI8pDm48kL6wKJO5xswp1GN6ZUAjbU0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc-ZNOdv7znCZeqvcIGhArM8FzjHIVKNMD0FHDIDHtAMlJJ9L3ZnrDX1YlJpwIZE9C/cohort_triangle.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981669190-6YSFKD4PJ6X1OJBOCJEL/ke17ZwdGBToddI8pDm48kL6wKJO5xswp1GN6ZUAjbU0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc-ZNOdv7znCZeqvcIGhArM8FzjHIVKNMD0FHDIDHtAMlJJ9L3ZnrDX1YlJpwIZE9C/cohort_triangle.png" data-image-dimensions="1324x604" data-image-focal-point="0.5,0.5" alt="Sample cohort retention “triangle” chart. This product has healthy retention for certain consumer verticals, bottoming out at around 30%. From the chart, you can see that product improvements were shipped around the week of 4/5 that improved retention of newer cohorts." data-load="false" data-image-id="5d47b9a41c7ed70001768d0f" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981669190-6YSFKD4PJ6X1OJBOCJEL/ke17ZwdGBToddI8pDm48kL6wKJO5xswp1GN6ZUAjbU0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc-ZNOdv7znCZeqvcIGhArM8FzjHIVKNMD0FHDIDHtAMlJJ9L3ZnrDX1YlJpwIZE9C/cohort_triangle.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Sample cohort retention “triangle” chart. This product has healthy retention for certain consumer verticals, bottoming out at around 30%. From the chart, you can see that product improvements were shipped around the week of 4/5 that improved retention of newer cohorts.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_107802"><div><p>Once you have a few cohorts that level off at a vertical-specific number, then you’ve achieved product market fit!</p><p>Different types of products have different “points” of product market fit, so it’s important to <strong>find the retention rate of some comparable products</strong> that have been able to significantly grow to find the right benchmark for you.</p><p>A good rule of thumb is for consumer products, 25% is a good floor and and for B2B SaaS products, 70% is a good floor. Floor meaning if your cohort retention is below these numbers, you probably do not have product market fit. You’ll likely want a lot better though, with a lot of great consumer products having over 40% long term retention and B2B over 80%</p><h2>Why cohort retention rate is a great product market fit metric</h2><p>There are several advantages that cohort retention rate has over survey based product market fit metrics:</p><ul data-rte-list="default"><li><p>No response bias - you get information from all users, not just the ones with high enough intent to fill out a survey</p></li><li><p>Full user lifecycle data - if you run a survey to collect a metric at a specific point in the user lifecycle, that metric may be different later on, but unknown</p></li><li><p>Measuring actual user behavior - don’t run into the problem where survey responses don’t match behavior</p></li></ul><p>All of this being said, it would be great to use both cohort retention and survey based metrics, but at the …</p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit">https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit</a></em></p>]]>
            </description>
            <link>https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821916</guid>
            <pubDate>Mon, 13 Jul 2020 15:40:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: PiHole As-a-Service (On Steroids)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821863">thread link</a>) | @microkernel
<br/>
July 13, 2020 | https://www.gardion.de/english-intro | <a href="https://web.archive.org/web/*/https://www.gardion.de/english-intro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><img src="https://www.gardion.de/assets/svg/devices-37.svg" height="48" alt="Icon"></p><h3>My internet!</h3>
        <p>Facebook is breathing down your neck? Your Xiaomi mobile is spying
          on you? Your app is reporting where you go and which flight you take? Not anymore. Gardion is a filtering VPN
          with the sole purpose to keep you safe and your data private.<mark>Gardion is your internet „invisibility
            cloak“.</mark></p>
      </div><div>
        <p><img src="https://www.gardion.de/assets/svg/science-15.svg" height="48" alt="Icon"></p><h3>Anytime, anywhere</h3>
        <p>Gardion works on all devices, anywhere; be it your smartphone (iOS, Android),
          your tablet or your laptop. Being geeks we made sure that BSD, Linux and other open systems can interface as
          well. <mark>The only requirement: Support for IPSEC or Wireguard</mark>. It works at home, while travelling,
          via WIFI and mobile network.
        </p>
      </div><div>
        <p><img src="https://www.gardion.de/assets/svg/communications-16.svg" height="48" alt="Icon"></p><h3>Trust, instead of Panama</h3>
        <p>The other VPN providers reside in Panama, Romania or the Netherlands Antilles.
          With Gardion you are on the safe side: When you want to work in a strong and trustworthy jurisdiction Germany
          is your choice. <mark>Our headquarter is in Freiburg/Germany and our servers are in Germany as well. No AWS,
            no Google cloud</mark>.
        </p>
      </div></div>]]>
            </description>
            <link>https://www.gardion.de/english-intro</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821863</guid>
            <pubDate>Mon, 13 Jul 2020 15:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brazil hid the data for Covid-19. Then volunteer developers got to work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821862">thread link</a>) | @danso
<br/>
July 13, 2020 | https://restofworld.org/2020/brazil-data-transparency-covid19/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/brazil-data-transparency-covid19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>L</span>ike any other software developer, Álvaro Justen used to spend most of his waking hours in front of a screen, moving around in his chair, while writing code, working with databases, and processing spreadsheets. But since the first Covid-19 cases sprouted in his native Brazil, Justen’s routine changed significantly. He now works full time, without pay, on what was once a small side project that has become the comprehensive source for measurements of the pandemic’s impact in his country.</p>



<p>@turicas, as colleagues and <a href="https://twitter.com/turicas">Twitter followers</a> know Justen, founded his nonprofit <a href="https://brasil.io/home/">Brasil.IO</a> in 2018 as an initiative to make public data in Brazil more accessible. Now, he is focusing on information — or lack thereof — about the novel coronavirus in the country, one of the pandemic’s epicenters.</p>



<p>“If I’m awake, I’m probably working on the site. On Saturdays, Sundays, holidays,” he told <em>Rest of World</em>. He started his site by publishing lists — <a href="https://brasil.io/dataset/eleicoes-brasil/candidatos/">candidates for public office</a> or <a href="https://brasil.io/dataset/socios-brasil/socios/">business owners in the country</a> — in a user-friendly format.</p>



<p>Currently, the site’s <a href="https://brasil.io/covid19/">Covid-19 series</a> features an independent daily monitor of cases with breakdowns by state and city. More than 40 volunteer developers and data enthusiasts work on the project, gathering updates, identifying patterns, and creating datasets.</p>



<p><strong>Read: <a href="https://restofworld.org/2020/brazil-social-platforms-glorify-shooters/">Inside the online communities where young Brazilians glorify school shooters</a></strong></p>



<p>Collecting data can be a difficult, manual task. The volunteers work to cover more than 5,000 Brazilian cities. “Sometimes, data is only available in internal systems, and we have to request it,” Justen explained. “Or the data is available, but not in an easy format to work with.” The challenge is to turn these massive tranches of information — which can come in large spreadsheets or loose PDFs — into lighter files or user-friendly tables and graphics.</p>



<p>By 2018, data transparency had come a long way in Brazil. Since the military rule ended in 1985, the country has witnessed breakthroughs like the 2011 approval of the <a href="https://www.gov.br/acessoainformacao/pt-br">Access to Information Law</a>, akin to the U.S. Freedom of Information Act.&nbsp;</p>



<p>But experts, like Fernanda Campagnucci, executive director of <a href="https://www.ok.org.br/">Open Knowledge Brasil</a>, say that data transparency is not a priority for the Bolsonaro administration. Instead, it seems to prefer an unspoken policy to conceal, question, or take down any data that doesn’t agree with its narrative. “A posture toward restraining access [to information] is gaining ground, which was not typical of Brazil,” she told<em> Rest of World</em>.</p>



<p>These efforts began last year. In April 2019, the Bolsonaro administration took down the Brazilian Observatory on Drug Information’s website, which showed the number of illicit drug use among the population. Later, in August, the director of the <a href="http://www.inpe.br/">Brazilian National Institute for Space Research</a> was fired after <a href="https://www.nytimes.com/2019/08/02/world/americas/bolsonaro-amazon-deforestation-galvao.html">coming under </a>attack for showing that Amazon deforestation increased 68% in the first two weeks of July when compared to the same time period in the previous year. Earlier in the year, the government <a href="https://exame.com/brasil/apos-definir-cortes-ibge-propoe-reduzir-questoes-do-censo-2020/">cut the national census’ budget</a>, which led to a proposal to reduce population survey questions by almost a third.</p>



<p><strong>Read: <a href="https://restofworld.org/2020/brazil-favela-chat-groups/">Brazil’s grassroots chat groups succeed where public services fail</a></strong></p>



<p>The coronavirus pandemic threw this informal policy out in the open. Addressing this gap became a “matter of survival,” according to Justen. He grew skeptical of the numbers from the Brazilian government, once he noticed its site going offline for a few hours and coming back up with incomplete datasets. The site also took about two months to publish breakdowns by city.&nbsp;&nbsp;</p>



<p>Justen’s suspicions turned out to be right. As the number of Covid-19 infections grew exponentially, the <a href="https://covid.saude.gov.br/">official government website for Covid-19</a> statistics went offline on June 5, 2020. When a new version went live, it featured only numbers from the past 24 hours, and the cumulative data were gone. Three days later, the ministry was forced to restore the website on the orders of the Supreme Court.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-40x21.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-400x211.png 400w, https://restofworld.org/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-600x316.png 600w, https://restofworld.org/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-1600x843.png 1600w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="https://brasil.io/covid19/" target="_blank" rel="noopener noreferrer">https://brasil.io/covid19/</a></span>
			</figcaption>
		</figure>


<hr>



<p><strong>As news of</strong> the Covid-19 data <a href="https://www.bloomberg.com/news/articles/2020-06-07/brazil-s-covid-data-blackout-is-a-tragedy-ex-health-chief-says">blackout</a> spread, the number of unique daily visitors to Brasil.IO skyrocketed from 4,000 to 30,000. Meanwhile, tensions at the Ministry of Health boiled over: Disagreements with Bolsonaro had led two <a href="https://noticias.uol.com.br/politica/ultimas-noticias/2020/05/15/nelson-teich-pede-demissao-do-governo-bolsonaro.htm">previous ministers to leave their posts</a>; the president, in turn, appointed an army general as interim minister. The government also pushed back its daily Covid-19 press briefing from 5 p.m. to 10 p.m. hush-hush <a href="https://www.saude.gov.br/noticias/agencia-saude/47173-coronavirus-brasil-registra-927-292-pessoas-recuperadas">press releases</a> that led with the numbers of recovered patients, which was widely suggested to be an attempt to stop them from being <a href="https://www1.folha.uol.com.br/equilibrioesaude/2020/06/acabou-materia-no-jornal-nacional-diz-bolsonaro-sobre-atraso-em-divulgacao-de-boletim-da-covid-19.shtml">featured in prime-time news broadcasts</a> and print newspapers.&nbsp;&nbsp;</p>



<p>As drama embroiled the executive branch, independent data collectors continued their work. They did so using an information network<strong> </strong>that integrates Brazil’s universal healthcare system with its epidemiological surveillance department. When doctors on the ground identify a case from a list of diseases, including Covid-19, they report it to a monitor at the Ministry of Health. Each state then consolidates the data and publishes daily epidemiological bulletins that are open to the public. “If states stopped doing that, an initiative like Brasil.IO’s Covid-19 project would not be able to exist,” Campagnucci said.&nbsp;</p>



<p>When operating as intended, this integrated system responds quickly to local- and federal-level health emergencies. It was crucial during the 2015 Zika epidemic, when it uncovered the initial surge in cases of microcephaly, a condition in which a baby is born with a smaller head than normal. That allowed researchers in Brazil to identify, early on, the link between Zika infection and microcephaly among newborns. “Microcephaly was only the tip of the iceberg. And the response to it was praiseworthy,” said Wayner Vieira, a Brazilian epidemiologist.</p>



<p>While developing Brasil.IO, Justen and his team incorporated this integrated system into their work. Groups of volunteers covered specific states, with the help of local health departments. Every day, a bot sends the volunteers updates. Volunteers work separately to upload the most recent information into Brasil.IO’s platform. If their numbers don’t match, the system sends out an alert. In a country like Brazil, such differences in official statistics are relatively common. States publish epidemiological bulletins at different times of the day or even use different methodologies. “Sometimes [local governments] publish a PDF file or an image, or the numbers are part of a press release,” Justen told <em>Rest of World</em>. “Automatizing this process is very hard.”&nbsp;</p>



<p>Alarmed by the Covid-19 data blackout, the Brasil.IO team posted its consolidated reports on Twitter as an alternative to the federal bulletins. Its <a href="https://twitter.com/turicas/status/1269425532241879041">first one</a> came out on June 6, immediately after the blackout, when it was still unclear whether the federal government would restore access to the cumulative data gathered for Covid-19 thus far. “Our work is to advocate for governments to open data because this is their responsibility. Independent initiatives [like Brasil.IO] emerge only because the government fails to do so,” Campagnucci said.</p>



<p>With the help of bots and dozens of volunteers, as of July 11, Brasil.IO has published 36 bulletins so far. They have joined other organizations’ calls for better transparency.&nbsp;</p>



<p>As the number of Covid-19 cases in Brazil continues to rise — as of July 8, it was over 1,700,000 people<strong> </strong>—<strong> </strong>and even president Bolsonaro <a href="https://www.washingtonpost.com/world/the_americas/coronavirus-brazil-bolsonaro-tests-positive/2020/07/07/5fa71548-c049-11ea-b4f6-cb39cd8940fb_story.html">tested positive for Covid-19</a>,<strong> </strong>independent data collectors have a long way to go. Brasil.IO continues to build datasets and now plans to research the pandemic’s economic impact in the country. “A lot of the available information still cannot be easily managed by laypeople, unless they are experts in data analysis,” Justen said. “In this case, it is as if the data was not available at all.”</p>



<p><em>Like our stories? Follow Rest of World on&nbsp;<a rel="noreferrer noopener" href="https://www.facebook.com/readrestofworld/" target="_blank">Facebook</a>,&nbsp;<a rel="noreferrer noopener" href="https://twitter.com/restofworld" target="_blank">Twitter (@RestofWorld)</a>&nbsp;and&nbsp;<a rel="noreferrer noopener" href="https://www.instagram.com/restofworld/" target="_blank">Instagram</a></em>,<em> and let us know how we’re doing.</em></p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/brazil-data-transparency-covid19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821862</guid>
            <pubDate>Mon, 13 Jul 2020 15:35:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deschooling Society (1970)]]>
            </title>
            <description>
<![CDATA[
Score 199 | Comments 193 (<a href="https://news.ycombinator.com/item?id=23821855">thread link</a>) | @minerjoe
<br/>
July 13, 2020 | https://davidtinapple.com/illich/1970_deschooling.html | <a href="https://web.archive.org/web/*/https://davidtinapple.com/illich/1970_deschooling.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="700">
				<tbody><tr>
					<td><span size="+2">DESCHOOLING SOCIETY</span><p>
						
						&nbsp;
						IVAN ILLICH</p><p>
						
						&nbsp;
						
						&nbsp;
						Contents</p><p>
						
						&nbsp;
						
						Introduction xix </p><p>
						
						<a href="#1">1. Why We Must Disestablish School</a></p><p>
						
						<a href="#2">2. Phenomenology of School<br>
						</a><br>
						<a href="#3">3. Ritualization of Progress<br>
						</a><br>
						<a href="#4">4. Institutional Spectrum</a></p><p>
						
						<a href="#5">5. Irrational Consistencies</a></p><p>
						
						<a href="#6">6. Learning Webs</a></p><p>
						
						<a href="#7">7. Rebirth of Epimethean Man</a></p><p>
						
						&nbsp;
						
						
						
						
						&nbsp;
						
						Introduction</p><p>
						
						
						&nbsp;
						
						I owe my interest in public education to Everett Reimer. Until we first met in Puerto Rico in 1958, I had never questioned the value of extending obligatory schooling to all people. Together we have come to realize that for most men the right to learn is curtailed by the obligation to attend school. The essays given at CIDOC and gathered in this book grew out of memoranda which I submitted to him, and which we discussed during 1970, the thirteenth year of our dialogue. The last chapter contains my afterthoughts on a conversation with Erich Fromm on Bachofen's Mutterrecht.</p><p>
						
						
						Since 1967 Reimer and I have met regularly at the Center for Intercultural Documentation (CIDOC) in Cuernavaca, Mexico. Valentine Borremans, the director of the Center, also joined our dialogue, and constantly urged me to test our thinking against the realities of Latin America and Africa. This book reflects her conviction that the ethos, not just the institutions, of society ought to be "deschooled."</p><p>
						
						
						Universal education through schooling is not feasible. It would be no more feasible if it were attempted by means of alternative institutions built on the style of present schools. Neither new attitudes of teachers toward their pupils nor the proliferation of educational hardware or software (in classroom or bedroom), nor finally the attempt to expand the pedagogue's responsibility until it engulfs his pupils' lifetimes will deliver universal education. The current search for new educational funnels must be reversed into the search for their institutional inverse: educational webs which heighten the opportunity for each one to transform each moment of his living into one of learning, sharing, and caring. We hope to contribute concepts needed by those who conduct such counterfoil research on education--and also to those who seek alternatives to other established service industries.</p><p>
						
						
						On Wednesday mornings, during the spring and summer of 1970, I submitted the various parts of this book to the participants in our CIDOC programs in Cuernavaca. Dozens of them made suggestions or provided criticisms. Many will recognize their ideas in these pages, especially Paulo Freire, Peter Berger, and Jos? Maria Bulnes, as well as Joseph Fitzpatrick, John Holt, Angel Quintero, Layman Allen, Fred Goodman, Gerhard Ladner, Didier Piveteau, Joel Spring, Augusto Salazar Bondy, and Dennis Sullivan. Among my critics, Paul Goodman most radically obliged me to revise my thinking. Robert Silvers provided me with brilliant editorial assistance on Chapters 1, 3, and 6, which have appeared in The New York Review of Books.</p><p>
						
						
						Reimer and I have decided to publish separate views of our joint research. He is working on a comprehensive and documented exposition, which will be subjected to several months of further critical appraisal and be published late in 1971 by Doubleday &amp; Company. Dennis Sullivan, who acted as secretary at the meetings between Reimer and myself, is preparing a book for publication in the spring of 1972 which will place my argument in the context of current debate about public schooling in the United States. I offer this volume of essays now in the hope that it will provoke additional critical contributions to the sessions of a seminar on "Alternatives in Education" planned at CIDOC in Cuernavaca for 1972 and 1973.</p><p>
						
						
						I intend to discuss some perplexing issues which are raised once we embrace the hypothesis that society can be deschooled; to search for criteria which may help us distinguish institutions which merit development because they support learning in a deschooled milieu; and to clarify those personal goals which would foster the advent of an Age of Leisure (schole) as opposed to an economy dominated by service industries. </p><p>
						
						
						IVAN ILLICH</p><p>
						
						
						&nbsp;
						
						
						CIDOC</p><p>
						
						
						Cuernavaca, Mexico</p><p>
						
						
						November, 1970<br>
						<a name="1"></a>.</p><a href="#top"><span size="-1">index&nbsp;</span></a><span size="+1">1.  Why We Must Disestablish School</span><p>
						
						
						&nbsp;
						
						
						Many students, especially those who are poor, intuitively know what the schools do for them. They school them to confuse process and substance. Once these become blurred, a new logic is assumed: the more treatment there is, the better are the results; or, escalation leads to success. The pupil is thereby "schooled" to confuse teaching with learning, grade advancement with education, a diploma with competence, and fluency with the ability to say something new. His imagination is "schooled" to accept service in place of value. Medical treatment is mistaken for health care, social work for the improvement of community life, police protection for safety, military poise for national security, the rat race for productive work. Health, learning, dignity, independence, and creative endeavor are defined as little more than the performance of the institutions which claim to serve these ends, and their improvement is made to depend on allocating more resources to the management of hospitals, schools, and other agencies in question.</p><p>
						
						
						In these essays, I will show that the institutionalization of values leads inevitably to physical pollution, social polarization, and psychological impotence: three dimensions in a process of global degradation and modernized misery. I will explain how this process of degradation is accelerated when nonmaterial needs are transformed into demands for commodities; when health, education, personal mobility, welfare, or psychological healing are defined as the result of services or "treatments." I do this because I believe that most of the research now going on about the future tends to advocate further increases in the institutionalization of values and that we must define conditions which would permit precisely the contrary to happen. We need research on the possible use of technology to create institutions which serve personal, creative, and autonomous interaction and the emergence of values which cannot be substantially controlled by technocrats. We need counterfoil research to current futurology.</p><p>
						
						
						I want to raise the general question of the mutual definition of man's nature and the nature of modern institutions which characterizes our world view and language. To do so, I have chosen the school as my paradigm, and I therefore deal only indirectly with other bureaucratic agencies of the corporate state: the consumer-family, the party, the army, the church, the media. My analysis of the hidden curriculum of school should make it evident that public education would profit from the deschooling of society, just as family life, politics, security, faith, and communication would profit from an analogous process.</p><p>
						
						
						I begin my analysis, in this first essay, by trying to convey what the deschooling of a schooled society might mean. In this context, it should be easier to understand my choice of the five specific aspects relevant to this process with which I deal in the subsequent chapters.</p><p>
						
						
						Not only education but social reality itself has become schooled. It costs roughly the same to school both rich and poor in the same dependency. The yearly expenditure per pupil in the slums and in the rich suburbs of any one of twenty U.S. cities lies in the same range-and sometimes is favorable to the poor. Rich and poor alike depend on schools and hospitals which guide their lives, form their world view, and define for them what is legitimate and what is not. Both view doctoring oneself as irresponsible, learning on one's own as unreliable, and community organization, when not paid for by those in authority, as a form of aggression or subversion. For both groups the reliance on institutional treatment renders independent accomplishment suspect. The progressive underdevelopment of self- and community-reliance is even more typical in Westchester than it is in the northeast of Brazil. Everywhere not only education but society as a whole needs "deschooling."</p><p>
						
						
						Welfare bureaucracies claim a professional, political, and financial monopoly over the social imagination, setting standards of what is valuable and what is feasible. This monopoly is at the root of the modernization of poverty. Every simple need to which an institutional answer is found permits the invention of a new class of poor and a new definition of poverty. Ten years ago in Mexico it was the normal thing to be born and to die in one's own home and to be buried by one's friends. Only the soul's needs were taken care of by the institutional church. Now to begin andend life at home become signs either of poverty or of special privilege. Dying and death have come under the institutional management of doctors and undertakers.</p><p>
						
						
						Once basic needs have been translated by a society into demands for scientifically produced commodities, poverty is defined by standards which the technocrats can change at will. Poverty then refers to those who have fallen behind an advertised ideal of consumption in some important respect. In Mexico the poor are those who lack three years of schooling, and in New York they are those who lack twelve.</p><p>
						
						
						The poor have always been socially powerless. The increasing reliance on institutional care adds a new dimension to their helplessness: psychological …</p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidtinapple.com/illich/1970_deschooling.html">https://davidtinapple.com/illich/1970_deschooling.html</a></em></p>]]>
            </description>
            <link>https://davidtinapple.com/illich/1970_deschooling.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821855</guid>
            <pubDate>Mon, 13 Jul 2020 15:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I just created this 1-page Python Cheat Sheet for ease of learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821752">thread link</a>) | @zweig
<br/>
July 13, 2020 | https://blog.finxter.com/concise-python-cheat-sheet/ | <a href="https://web.archive.org/web/*/https://blog.finxter.com/concise-python-cheat-sheet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">

		
		
<p>Do you want to learn Python but you’re overwhelmed and you don’t know where to start? Learn with Python cheat sheets! They compress the most important information in an easy-to-digest 1-page format. </p>



<p>Here’s the new Python cheat sheet I just created—my goal was to make it the world’s most concise Python cheat sheet!</p>



<div><figure><a href="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.pdf" target="_blank" rel="noopener noreferrer"><img src="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.jpg" alt="Python Ultimate Cheat Sheet" width="720" height="960" srcset="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.jpg 720w, https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet-225x300.jpg 225w" sizes="(max-width: 720px) 100vw, 720px" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.jpg" data-srcset="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.jpg 720w, https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet-225x300.jpg 225w"></a></figure></div>



<div>
<div><p><a href="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.pdf" target="_blank" rel="noreferrer noopener">Download PDF Now</a></p></div>
</div>




</div></div>]]>
            </description>
            <link>https://blog.finxter.com/concise-python-cheat-sheet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821752</guid>
            <pubDate>Mon, 13 Jul 2020 15:26:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create a GitHub profile readme]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821665">thread link</a>) | @jerodsanto
<br/>
July 13, 2020 | https://www.aboutmonica.com/blog/how-to-create-a-github-profile-readme | <a href="https://web.archive.org/web/*/https://www.aboutmonica.com/blog/how-to-create-a-github-profile-readme">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><article><header><p> <span> <!-- -->🍿 3 min. read</span></p></header><p>GitHub recently released a feature that allows users to create a profile-level README to display prominently on their GitHub profile. This article walksthrough how to access this new feature. I'll also be sharing some fun GitHub profiles I've seen so far. I'd love it if you shared yours with me on Twitter <a href="https://twitter.com/waterproofheart">@waterproofheart</a>.</p><p><img src="https://www.aboutmonica.com/media/monica-github-readme-edit.gif">
<em>The above GIF shows what my README looks like at the time of this writing. You may notice I was recently selected to be <a href="https://stars.github.com/">GitHub star</a>!</em></p><h2 id="why-readmes"><a href="#why-readmes" aria-label="why readmes permalink"></a>Why READMEs?</h2><p>The GitHub profile-level README feature allows more content than the profile bio, supports markdown which means you can play around with the content more visually (Did someone say GIFs!?) and the README is significantally more visible as it is placed above pinned repositories and takes up as much space above the fold of the webpage as you like.</p><p>A solid README is a core-component of well-documented software and often encourages collaboration by sharing helpful context with contributors. In my opinion, a profile-level README seems like a great extension of a convention a lot of GitHub users are already familiar with. If you're looking to make project-level READMEs more awesome and helpful check out <a href="https://github.com/matiassingers/awesome-readme">matiassingers/awesome-readme</a> for resources and examples of compelling READMEs.</p><h2 id="how-do-i-create-a-profile-readme"><a href="#how-do-i-create-a-profile-readme" aria-label="how do i create a profile readme permalink"></a>How do I create a profile README?</h2><p>The profile README is created by creating a new repository that’s the same name as your username. For example, my GitHub username is m0nica so I created a new repository with the name m0nica. Note: at the time of this writing, in order to access the profile README feature, the letter-casing <strong>must</strong> match your GitHub username.</p><p>If you already have a project in a repo-named username/username and are interested in setting up a profile-level README, then I recommend either <a href="https://docs.github.com/en/github/administering-a-repository/renaming-a-repository">re-naming that repository</a> or re-purposing the existing project's README based on what makes the most sense in your particular situation.</p><ol><li><p>Create a new repository with the same name (including casing) as your GitHub username: <a href="https://github.com/new">https://github.com/new</a></p></li><li><p>Create a README.md file inside the new repo with content (text, GIFs, images, emojis, etc.)</p></li><li><p>Commit your fancy new README!</p><ul><li>If you're on GitHub's web interface you can choose to commit directly to the repo's main branch (i.e., <code>master</code> or <code>main</code>) which will make it immediately visible on your profile)</li></ul></li><li><p>Push changes to GitHub (if you made changes locally i.e., on your computer and not github.com)</p></li></ol><p><img src="https://www.aboutmonica.com/media/create-repository.jpg"></p><h2 id="fun-readmes"><a href="#fun-readmes" aria-label="fun readmes permalink"></a>Fun READMEs</h2><p>The GitHub README profiles are written in Markdown which means you aren't just limited to texts and links, you can include GIFs and images. Need to brush up on Markdown Syntax? <a href="https://guides.github.com/pdfs/markdown-cheatsheet-online.pdf">Check out this Markdown Cheatsheet</a>.</p><blockquote data-dnt="true">— Jason Lengstorf (@jlengstorf) <a href="https://twitter.com/jlengstorf/status/1281026687103168512">July 9, 2020</a></blockquote><blockquote data-dnt="true"><p lang="en" dir="ltr">It's not as creative as <a href="https://twitter.com/sudo_overflow">@sudo_overflow</a>'s readme, but here's what I came up with. I also plan on adding some text below the image with links to my resume, etc. <a href="https://t.co/C6b8tNDo1z">pic.twitter.com/C6b8tNDo1z</a></p>— donavon "#BLM" west (@donavon) <a href="https://twitter.com/donavon/status/1281231777475026945">July 9, 2020</a></blockquote><blockquote data-dnt="true"><p lang="en" dir="ltr">Is this how we suppose use github's readme? <a href="https://t.co/XvLvCUC6iD">pic.twitter.com/XvLvCUC6iD</a></p>— Pouya (@Saadeghi) <a href="https://twitter.com/Saadeghi/status/1281111778290786310">July 9, 2020</a></blockquote><p>If you're really ambitious you can use <a href="https://github.com/features/actions">GitHub actions</a> or other automation like bdougieYO or simonw to dynamically pull data into your README:</p><blockquote data-dnt="true"><p lang="en" dir="ltr">Check it out. I made MySpace but on <a href="https://twitter.com/github">@github</a>.<a href="https://t.co/p4DWP4DxRR">https://t.co/p4DWP4DxRR</a> - My list is power by a GitHub Action workflow 😏 <a href="https://t.co/PN80mFCqOE">pic.twitter.com/PN80mFCqOE</a></p>— Brian Douglas (@bdougieYO) <a href="https://twitter.com/bdougieYO/status/1281699715466199040">July 10, 2020</a></blockquote><blockquote data-dnt="true"><p lang="en" dir="ltr">Made myself a self-updating GitHub personal README! It uses a GitHub Action to update itself with my latest GitHub releases, blog entries and TILs <a href="https://t.co/Eve7FOrwYK">https://t.co/Eve7FOrwYK</a> <a href="https://t.co/oJPXLtFdgM">pic.twitter.com/oJPXLtFdgM</a></p>— Simon Willison (@simonw) <a href="https://twitter.com/simonw/status/1281435464474324993">July 10, 2020</a></blockquote><p>Serverless functions can also be used to dynamically generate information (for example your current Spotify activity):</p><blockquote data-dnt="true">— Nate Moore (@n_moore) <a href="https://twitter.com/n_moore/status/1282326538990563329">July 12, 2020</a></blockquote><p>I'm a huge proponent that folks should maintain a website they have complete ownership over (even if it's a no-code website solution) but this is tempting...</p><blockquote data-dnt="true"><p lang="en" dir="ltr">I just created my <a href="https://twitter.com/github">@github</a> profile README as well with a bunch of badges. This is really a brilliant idea. We may no longer need to maintain our personal website. We can write blogs as issues, manage Wiki and task board, free traffic analytics and CI/CD. <a href="https://t.co/zSXZKT6a20">https://t.co/zSXZKT6a20</a> <a href="https://t.co/mK9OWXG9iH">pic.twitter.com/mK9OWXG9iH</a></p>— Yuan Tang (@TerryTangYuan) <a href="https://twitter.com/TerryTangYuan/status/1281590275660537858">July 10, 2020</a></blockquote><blockquote data-dnt="true"><p lang="en" dir="ltr">hey, so we heard ya &amp; are trying out a thing where you CAN have a readme on your <a href="https://twitter.com/github">@github</a> profile... <a href="https://twitter.com/mikekavouras">@mikekavouras</a> built it btw! re:  <a href="https://t.co/UC6q3qHjjR">https://t.co/UC6q3qHjjR</a> <a href="https://t.co/kB0kafgovY">pic.twitter.com/kB0kafgovY</a></p>— kathy ☁️ (@pifafu) <a href="https://twitter.com/pifafu/status/1265773172520914944">May 27, 2020</a></blockquote><p>I've been inspired by the creative READMEs I've seen so far and am looking forward to seeing all kinds of profiles in the upcoming months.</p> <p>This article was published on <!-- -->July 11, 2020<!-- -->.</p><hr><hr><nav><br></nav><br></article></main></div></div>]]>
            </description>
            <link>https://www.aboutmonica.com/blog/how-to-create-a-github-profile-readme</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821665</guid>
            <pubDate>Mon, 13 Jul 2020 15:18:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Auth Bottleneck Pattern]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821624">thread link</a>) | @mooreds
<br/>
July 13, 2020 | https://fusionauth.io/blog/2020/07/08/auth-and-the-bottleneck-architecture | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/07/08/auth-and-the-bottleneck-architecture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>One common pattern for modern organizations is to centralize user management with a bottleneck architecture. A solid user management system is provisioned and all authentication and authorization requests are routed through it, rather than individual applications having their own auth components.</p>

<!--more-->

<h2 id="the-architectural-pattern-with-oidc-and-saml">The Architectural Pattern With OIDC and SAML</h2>

<p>In this architectural pattern, applications delegate user management to the user management system. Many kinds of applications can perform such delegation. Examples include custom applications written by internal teams, third party services used by employees, such as Salesforce and Zendesk, and applications used by customers, such as forums or account management.</p>

<p>Like any serious architecture discussion, we’ll need some acronyms and jargon. There are a few identity management standards, including OpenID Connect (OIDC), released in the mid 2010s, and Security Assertion Markup Language (SAML), which was standardized in the 2000s.</p>

<p>If the protocol in use is OIDC, applications delegating auth decisions are called Relying Parties, or RPs. If the protocol is SAML, the delegating applications are called Service Providers, or SPs. In either case, decisions about authentication or authorization, and often account management, are shifted from the application to a central service.</p>

<p>In OIDC systems, this centralized auth system is referred to as an OpenID provider, or OP. For SAML based systems, it is called an Identity Provider, or IdP. The system’s scope includes:</p>

<ul>
  <li>authentication - who is this user?</li>
  <li>authorization - what can this user do?</li>
  <li>user management - registration, forgot password flows, two factor authentication, reporting, and more</li>
</ul>

<p>However, an auth system isn’t limited to just verifying users locally. It can also federate to other providers of identity, such as Google, HYPR or Facebook. In addition, standards compliant providers adhering to the SAML or OIDC specifications can be integrated.</p>

<p>Here’s a diagram of the bottleneck architecture:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/bottleneck-pattern/bottleneck-diagram.png" alt="A common architectural pattern."></p>

<p>The applications, in purple, rely on the centralized auth system, which is in gray. They’ll send all their auth requests to one place. Depending on how the auth system is configured, the applications’ requests for user information may be answered directly, based on information in the auth system’s datastore. Or, alternately, auth requests for a given user can be relayed to the federated identity providers, in orange. (You can read more about <a href="https://fusionauth.io/docs/v1/tech/identity-providers/">the identity providers</a> FusionAuth supports.)</p>

<h2 id="benefits-of-a-user-auth-service">Benefits of a User Auth Service</h2>

<p>This user management architecture enables single sign-on (SSO) and has substantial benefits when implemented. Among them are increased visibility, decreased operational complexity, and increased choice of auth method.</p>

<h3 id="increased-visibility-and-development-speed">Increased Visibility and Development Speed</h3>

<p>There is one location for user and application management. Therefore, implementing organization wide policies is easier, including those which are security or compliance related. Users also have only one identity to maintain, so any changes, such as to their password or personal information, are relatively easy to make.</p>

<p>This bottleneck also serves as a well maintained list of applications used by the organization. That is, if everyone uses it. Knowing which services are in use, and seeing who is using them how often, is as simple as signing into the auth service administration panel. This also helps the organization avoid buying apps with overlapping functionality, since you can review the list of active applications.</p>

<p>If your auth system has mature user management functionality, it will accelerate custom application development by providing often used services. No more worrying about building a front end to allow customer service reps to lock accounts. Nor do you have to build a way to let end users reset their passwords or register.</p>

<h3 id="operational-ease">Operational Ease</h3>

<p>Such a centralized user auth service also makes it easy to turn accounts on and off. Onboarding a new employee becomes simpler, and offboarding departing employees is a matter of disabling their account in one place, rather than hunting down all the applications to which they have access. Or worse, leaving those accounts enabled.</p>

<p>There are additional benefits to end users, as well. While identifying people with username, password and multi-factor authentication is a secure and relatively convenient method, there may be times when an alternative is a better user experience.</p>

<h3 id="give-your-users-the-experience-they-want">Give Your Users the Experience They Want</h3>

<p>As you might expect, different types of users have different third party accounts. If you have a consumer focused application, offering sign on with Facebook is a great idea, because everyone has a Facebook account. One less password for your potential users to remember, and one less obstacle to signing up.</p>

<p>On the other hand, if the application is aimed at enterprise customers, integrating with ActiveDirectory can help adoption. If developers are your target market, GitHub authentication eases the sign-up process as well as signals to them that you understand their needs.</p>

<p>If your auth system allows for multiple different identity providers, your application can meet users “where they are”, rather than requiring them to create and manage a new account.</p>

<p>If you work for a large organization, you may need to federate your user management system, using one of the standards such as OIDC, to other user datastores. Having a central service for your suite of applications means federation and integration only needs to be done once, rather than for each application you build.</p>

<h2 id="challenges-with-sso">Challenges With SSO</h2>

<p>Of course, nothing is perfect. There are challenges with this approach as well. Some technical, some not so much.</p>

<p>First off is the <a href="https://sso.tax/">SSO tax</a>. Many third party applications don’t support this user auth delegation until you are on an enterprise plan. Ouch. Investigate required applications to see if and how they can act as a RP or SP to a centralized user management system before you decide to pursue this architecture.</p>

<p>Another organizational challenge is ensuring developers and end users actually use the organization’s user management system. Some may want to use their old, familiar authentication solutions. Encourage everyone to work within these constraints by making adoption as easy as possible and clearly explaining the benefits. Providing examples of successful integrations can help with both of these.</p>

<p>Tying together the bottleneck system, the delegating applications, and the external identity providers requires effort. Sometimes it is as simple as following a tutorial on a website and adding a few lines of configuration. Other times it may be more complicated and may require support.</p>

<p>Finally, beware of insecure or slow auth services. No one cares about authentication and authorization, except when it doesn’t work. When was the last time you heard someone exclaim “I love that login page!”? People want to log in when and how they choose and have it work, so they can get on to the task they need to accomplish. Select a system that is robust, has great support, and is flexible enough to meet future needs.</p>

<h2 id="see-it-in-action-see-with-hypr-and-fusionauth">See It In Action See With HYPR and FusionAuth</h2>

<p>If you’d like to see how easy it is to configure FusionAuth to serve as an centralized authentication and authorization service, HYPR and FusionAuth are hosting a webinar on Thursday, July 16 2020.</p>

<p>In less than 15 minutes, Zendesk will be set up as an application delegating auth decisions to FusionAuth (well, if you want to be technical, as an SP using SAML). HYPR will be configured as an identity provider. At the end, a user will be able to sign into Zendesk using HYPR’s Passwordless technology.</p>

<p><a href="https://get.hypr.com/fusionauth-webcast">Sign up for the webinar</a></p>


            
          </div></div>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/07/08/auth-and-the-bottleneck-architecture</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821624</guid>
            <pubDate>Mon, 13 Jul 2020 15:15:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Privacy friendly website analytics also will be blocked by default]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23821623">thread link</a>) | @l1am0
<br/>
July 13, 2020 | https://simon-frey.com/blog/privacy-friendly-website-analytics-also-will-be-blocked-by-default/ | <a href="https://web.archive.org/web/*/https://simon-frey.com/blog/privacy-friendly-website-analytics-also-will-be-blocked-by-default/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#FFFFFF" data-fg="#f44813" data-width="5" data-mute="" data-fgopacity="0.5" data-mutedopacity="0.5" data-placement="top" data-placement-offset="0" data-content-offset="0" data-placement-touch="top" data-placement-offset-touch="0" data-transparent="" data-touch="" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#f44813" data-rtl="">
<p><strong>First things first: I love the movement to use more privacy-friendly website analytics tools. More and more small startups are popping up and help you to move away from Google Analytics. And each and every website not using Google Analytics anymore is a win for the free internet</strong></p>
<p><strong>BUT</strong> Please dear privacy-friendly analytics developers: Stop telling me your tool is better because Google Analytics is getting blocked by more and more browsers/ad blockers.</p>
<p>This seems to be the current No.1 marketing story for these tools as I think I read the 5th blog post about this topic today. This it the TLDR for all of them: “Browser start blocking Google Analytics. Use my tool if you really want to track all users as my tool is not blocked”</p>
<p>In itself this statement is not per se wrong. Yes more and more browsers are blocking Google Analytics as of why the tracking will produce numbers that are off compared to the real visitor count of your website.</p>
<p>But the second part is what annoys me. The tracking script provided by these small new analytics tools is not blocked by browsers and ad blockers <strong>at this moment</strong> because of only one reason: The analytics tools is not widely known enough to be a big problem and to be recognized by the big ad blockers, browser and blocking list providers.</p>
<p>In the very second the goal of these startups works, and they get more users they will have the exact same problem with being blocked by default. And I assume these tools will be even blocked more as they do not have the same influence like google does to negotiate with the certain browser providers for certain deals.</p>
<p>Talking users into changing to a tool with this reasoning seems not transparent and honest to me.</p>
<p>Please don’t stop providing and using alternatives to google analytics, but stop catching users with false claims.</p>
<hr>
<p>As you might see in your ad blocker I do not use Google Analytics but a self-hosted version of <a href="https://matomo.org/">Matomo</a>, an open source analytics tools which is as easy to install and use as WordPress (Jepp, both run with MariaDB and PHP)</p>
<p>Normally Matomo is blocked by ad blockers even in a self-hosted version as the ad blockers identify it by its query parameters. To circumvent this blocking I did build a small script which can be bought on <a href="https://byrly.com/mcab">Gumroad</a>. With the help of this script you can run a self-hosted version of Matomo which is not blocked by ad blockers, now and forever (as long as your custom Matomo domain e.g. ‘l1am0.uber.space’ is not blocked)</p>
<p>So did I only write this blog post to sell you my script and undermine my credibility with this action? No! The script can be found MIT licensed on <a href="https://github.com/simonfrey/matomo_circumvent_adblock">GitHub</a>. With purchasing the support license for a few bucks you help me to keep working on it. The lifetime license is less than a single month in all other privacy-friendly analytics.</p>
</div></div>]]>
            </description>
            <link>https://simon-frey.com/blog/privacy-friendly-website-analytics-also-will-be-blocked-by-default/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821623</guid>
            <pubDate>Mon, 13 Jul 2020 15:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Virgin YouTube vs. the Chad PeerTube]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23821616">thread link</a>) | @antepodius
<br/>
July 13, 2020 | https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3 | <a href="https://web.archive.org/web/*/https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821616</guid>
            <pubDate>Mon, 13 Jul 2020 15:15:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8 rituals I followed to be a better programmer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821485">thread link</a>) | @arpitbbhayani
<br/>
July 13, 2020 | https://arpitbhayani.me/blogs/better-programmer | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/better-programmer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>"How to get better at programming?" is the question I had been asked quite a few times, and today I lay down the 8 rituals I have been following, and action items for each, to be good and get better at programming.</p>

<p>Doing something repeatedly always helps and writing a lot of code will develop our ability to</p>
<ul>
<li>write code while we think</li>
<li>think faster, think better</li>
<li>foresee requirement changes and possible logic extensions</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>One significant contribution to a project every two weeks</li>
<li>Solve at least two programming questions (from <a href="https://www.codechef.com/">Codechef</a>, <a href="https://www.spoj.com/">Spoj</a> or <a href="https://www.hackerrank.com/">HackerRank</a>) every week, till we solve at least 300 questions</li>
</ul>

<p>If we don't do something repeatedly, it becomes extremely hard to get good at it. Writing code consistently helps us</p>
<ul>
<li>define the programmatic and algorithmic flow quickly</li>
<li>build a habit of programming and thinking analytically</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>make one small contribution to anyone project every three days</li>
</ul>

<p>Solving programming questions is about developing logic but things become a little trickier when we build a complex system, as it requires us to take our programming skills to go up a notch. Some examples of complex systems are - a Library management system, a <a href="https://twitter.com/">Twitter</a> clone, an <a href="https://www.instagram.com/">Instagram</a> clone, etc. Building a complex system</p>
<ul>
<li>widens our tech stack</li>
<li>makes us keep our code flexible, extensible and reusable</li>
<li>helps us understand how to split our code into independent segments that work in harmony</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>build one complex system every 4 months</li>
</ul>

<p>After we spend some time writing programs and solving problems, things become monotonous and do not seem to challenge us anymore, so to spice things up a bit we should model something from the real world, like</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Projectile_motion">projectile motion</a></li>
<li><a href="https://en.wikipedia.org/wiki/Double_pendulum">double pendulum</a></li>
<li><a href="https://en.wikipedia.org/wiki/Numerical_model_of_the_Solar_System">solar system simulation</a></li>
</ul>
<p>There are lots of libraries and framework like <a href="https://p5js.org/">p5.js</a> that makes visual programming simple.</p>
<h3>Action Items</h3>
<ul>
<li>once every 6 months model a physical phenomenon</li>
</ul>

<p>It is not only writing code that improves our programming skills but it is reading some quality code written by expert programmers that make the difference. Reading code written by experts improve our programming vocabulary and by doing this we</p>
<ul>
<li>learn the best programming practices</li>
<li>discover the new programming paradigms</li>
<li>find ways to properly structure our code for extensibility</li>
</ul>
<p>The best way to start doing it is by picking up an open-source project and start skimming the code. It is okay to not understand it in the first go but it is important to skim it a few times and get acquainted. After a few skim, everything will fall in place, the code becomes familiar and we start to understand the flow and business logic.</p>
<h3>Action Items</h3>
<ul>
<li>pick an open-source project every 6 months and skim its code once every two months</li>
<li>pick a tiny open-source utility, from an experienced developer, every month and skim it</li>
</ul>

<p>There is always someone sitting on the other side of the globe, who knows a thing or two more than us. Look for them and collaborate on a project. The developer community is filled with super smart and super enthusiastic developers who love to share and collaborate. Use websites like <a href="https://dev.to/">Dev.to</a>, <a href="https://hashnode.com/">Hashnode</a> and <a href="https://twitter.com/">Twitter</a> to find and interact with like-minded people.</p>
<h3>Action Items</h3>
<ul>
<li>collaborate on a project once a year</li>
<li>be active on platforms like <a href="https://dev.to/">Dev.to</a>, <a href="https://hashnode.com/">Hashnode</a> and <a href="https://twitter.com/">Twitter</a></li>
</ul>

<p>A programming language is just a tool to express business logic. While learning a programming language we should try to understand the constructs and paradigms used - for example: <a href="https://en.wikipedia.org/wiki/Functional_programming">Functional programming</a>, <a href="https://en.wikipedia.org/wiki/Polymorphism_(computer_science)">Polymorphism</a>, <a href="https://en.wikipedia.org/wiki/Event-driven_programming">Event driven programming</a>, <a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a>, etc. It is important to do so because we could pick constructs from one language and use it in another to solve our problem. For example: picking Functional programming (Callbacks) from Javascript and using it in Python to create generic action functions.</p>
<h3>Action Items</h3>
<ul>
<li>learn one design pattern every month and build a simulation around it</li>
<li>pick a language construct and implement it in some other language</li>
</ul>

<p>Writing code before putting in some thought is degraded the code more often than not. The code written like this lacks simplicity, reusability, and extensibility. Spending some time thinking about problem statement or task at hand and having a rough execution plan always helps.</p>
<h3>Action Items</h3>
<ul>
<li>always define the scope of implementation, create an execution plan and then code</li>
</ul>

<p>These rituals have helped me get better at programming with time and in parallel, I pick at max 3 and act on the action items. Programming is simple but being better than most is difficult. Doing it consistently makes one get better by the day.</p>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/better-programmer</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821485</guid>
            <pubDate>Mon, 13 Jul 2020 15:03:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Income/savings calculator for moving to Canada]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 54 (<a href="https://news.ycombinator.com/item?id=23821323">thread link</a>) | @senecaso
<br/>
July 13, 2020 | https://boomstick.games/northward/index.html | <a href="https://web.archive.org/web/*/https://boomstick.games/northward/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://boomstick.games/northward/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821323</guid>
            <pubDate>Mon, 13 Jul 2020 14:47:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling to Assembly from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23821305">thread link</a>) | @halst
<br/>
July 13, 2020 | https://keleshev.com/compiling-to-assembly-from-scratch | <a href="https://web.archive.org/web/*/https://keleshev.com/compiling-to-assembly-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        

<p><span id="home"><a title="Home" href="https://keleshev.com/">☰</a></span></p>



<!--



md5-79bfa919c595b8f7aa78f6d429bc2a15


-->

<center><img id="cover" src="https://keleshev.com/compiling-to-assembly-from-scratch.jpg" width="200" height="300"></center>

<center><p> <a href="https://transactions.sendowl.com/products/78310234/604B9EF1/purchase" rel="nofollow"> Pre-order •  <b>$27</b> </a></p></center>

<center><em>TypeScript — ARM  — August 2020</em></center>

<p><big><em>So, you’ve been trying to learn how compilers and programming languages work?</em> </big></p>

<p>Perhaps, you’ve learned about compiling to JavaScript,
or about building an interpreter? Or, maybe, about
compiling to bytecode? All good steps.</p>

<p><em>But there’s a tension building up.</em></p>

<p>Because it feels a bit like cheating.
Because you know that somewhere, somehow, the code you write
is translated to assembly instructions. To the machine language.
That’s where the rubber hits the road. That’s where it gets hot.
And, oh-so-many resources are hesitant to cover this part.
But not this book.</p>

<p>This ebook will show you in detail
how you can build a compiler from scratch
that goes all the way from <em>source</em> to <em>assembly</em>.</p>

<p>The example code is written in <strong>TypeScript</strong>, a dialect of <strong>JavaScript</strong>.
The book describes the design and implementation of a compiler that emits
32-bit <strong>ARM</strong> assembly instructions.</p>



<blockquote>
  <h2>Pre-order and get a draft!</h2>
  
  
  
  <p><strong><em>You get now:</em></strong></p>
  
  <ul>
  <li>Draft <em>(contains full Part I of the book)</em></li>
  <li>PDF-only</li>
  <li>DRM-free</li>
  <li>Source code <em>(link in the book)</em></li>
  <li>Discourse forum: book’s private community <em>(invite in the book)</em></li>
  </ul>
  
  <p><strong><em>You get later</em></strong> <em>(ETA–August 2020)<strong></strong></em><strong><em>:</em></strong></p>
  
  <ul>
  <li>Complete book</li>
  <li>All future revisions</li>
  <li>PDF, EPUB <em>(other formats on request)</em></li>
  <li>DRM-free</li>
  </ul>
  
  <p><em>Note, $27 is pre-order–only price with 40% discount. When the book is out it will be $45.</em>
  <br></p>
</blockquote>



<h2>Why ARM?</h2>

<p>In many ways, the ARM instruction set is what makes this book possible.</p>

<p>Compared to Intel x86-64, the ARM instruction set is a work of art.</p>

<p>Intel x86-64 is the result of evolution from an 8-bit processor,
to a 16-bit one, then to a 32-bit one, and finally to a 64-bit one.
At each step of the evolution, it accumulated complexity and cruft.
At each step, it tried to satisfy conflicting requirements.</p>

<ul>
<li>Intel x86-64 is based on <em>Complex Instruction Set Architecture</em> (CISC),
which was initially optimized for writing assembly by hand.</li>
<li>ARM, on the other hand, is based on <em>Reduced Instruction Set Architecture</em> (RISC),
which is optimized for writing compilers.</li>
</ul>

<p><em>Guess which one is an easier target for a compiler?</em></p>

<p>If this book targeted Intel x86-64 instead of ARM, it would have been two times as long
and — more likely — never written.
Also, with 160 <em>billion</em> devices shipped, we better get used to the fact
that ARM is the dominant instruction set architecture today.</p>

<p>In other words… ARM is a good start.
After learning it, you will be better equipped
for moving to x86-64 or the new ARM64.</p>

<p><em>Will you be able to run the code your compiler produces?</em></p>

<p>I bet you will! The Appendix will contain a bazillion ways
to execute ARM code, starting from Raspberry Pi,
cloud VM, to various ways to emulate ARM on Linux, Windows, and macOS.</p>

<h2>Why TypeScript?</h2>

<p>First of all, you will be able to follow this book in any reasonable programming language.
For me, it was tough to pick one for this job, and I’m pleased I’ve chosen TypeScript.</p>

<p>TypeScript is probably nobody’s favorite, but it’s a good compromise:</p>

<ul>
<li>Are you coming from a dynamic language like JavaScript, Python, or Ruby?
Then if you close your eyes at the
type annotations, TypeScript is just modern-day JavaScript.</li>
<li>If you’re coming from Java or C#, then you will feel right at home,
since TypeScript
is brought to you by the same people who brought you C# <em>(and Turbo Pascal!)</em>.</li>
</ul>

<p>Don’t worry if you’ve never seen TypeScript code before.
If you can read the following, you will most likely be able to pick it up,
as the book goes <em>(real code from the book here!)</em>:</p>

<pre><b>class </b>Label {
  <b>static </b>counter = 0;
  value: number; <em>// Type annotation
</em>
  <b>constructor</b>() {
    <b>this</b>.value = Label.counter++;
  }

  toString() {
    <b>return </b>'.L' + <b>this</b>.value;
  }
}
</pre>

<p>I avoided using any TypeScript- or JavaScript-specific
language features in the code.</p>

<p>If you’re into statically-typed functional programming
languages (Haskell, OCaml, or Reason ML),
you will find that the class structure I used
has a nice translation to an algebraic data type.
It is, in fact, how I wrote it first.</p>



<h2>Book Contents</h2>

<p>The book consists of two parts. Part I
presents a <em>detailed</em>, <em>step-by-step</em> guide on how
to develop a small “baseline” compiler that can compile simple
programs to ARM assembly.</p>

<p>By the end of Part I, you will have a working compiler that can
compile simple functions like this one:</p>

<!--table>
<tr>
<td>


md5-73395652867122248e3299aa94c98c61


</td>
<td>
</td>
</tr>
</table-->

<pre><b>function </b>factorial(n) {
  <b>if </b>(n == 0) {
    <b>return </b>1;
  } <b>else </b>{
    <b>return </b>n * factorial(n - 1);
  }
}
</pre>

<p>Into ARM assembly code like this:</p>

<pre>.global factorial
factorial:
  <b>push </b>{fp, lr}
  <b>mov </b>fp, sp
  <b>push </b>{r0, r1}
  <b>ldr </b>r0, =0
  <b>push </b>{r0, ip}
  <b>ldr </b>r0, [fp, #-8]
  <b>pop </b>{r1, ip}
  <b>cmp </b>r0, r1
  <b>moveq </b>r0, #1
  <b>movne </b>r0, #0
  <b>cmp </b>r0, #0
  <b>beq </b>.L1
  <b>ldr </b>r0, =1
  <b>b </b>.L2
.L1:
  <b>ldr </b>r0, =1
  <b>mov </b>r1, r0
  <b>ldr </b>r0, [fp, #-8]
  <b>sub </b>r0, r0, r1
  <b>bl </b>factorial
  <b>mov </b>r1, r0
  <b>ldr </b>r0, [fp, #-8]
  <b>mul </b>r0, r0, r1
.L2:
  <b>mov </b>sp, fp
  <b>pop </b>{fp, pc}
</pre>

<p>This code won’t win any awards, and an optimizing compiler
could do much better, but it’s a start!</p>

<p>Part II talks about <em>more advanced</em> topics in <em>less details</em>.
It explores several different (often mutually exclusive)
directions in which you can take your compiler.</p>

<center>⁂</center>

<center><a id="excerpt" href="https://keleshev.com/excerpt-compiling-to-assembly-from-scratch.pdf"><img id="excerpt" src="https://keleshev.com/book-preview.png" width="400" height="300"></a></center>

<center><a href="https://keleshev.com/excerpt-compiling-to-assembly-from-scratch.pdf"> Read Excerpt </a></center>

<center><img src="https://keleshev.com/keleshev.jpg" width="200" height="200"></center>

<h2>About me</h2>

<p>My name is Vladimir Keleshev,
I have worked with compilers both commercially
and in open-source.
My fondness of ARM assembly stems from
my previous work in embedded systems.
Currently, I work in finance
with domain-specific languages.
I’m <a href="https://twitter.com/keleshev">@keleshev</a> on Twitter.</p>



<blockquote>
  <h2>Be the first to know when the book is finalized!</h2>
  
  <center>Reading a draft is not your style? I get it. Subscribe to be notified when the book is finalized (and related news about the book and compilers).</center>
  
  <center><a href="https://sellfy.com/p/bkz0pv/" id="bkz0pv" data-text="Pre-order"></a></center>
  
  
  
  <center><small>You can unsubscribe at any time</small></center>
</blockquote>

<!--


md5-7ee03ea5643bff2df00890120280d45e



When I write blog posts I usually spent the first half
of the time writing the code and develoing the idea, and
the second half on the prose.
This book will be no exception.

At the moment I have finished writing
the code, and I am very happy with the results.
I expect the book to be ready early summer 2020, and a draft to
be available even sooner.

-->



<center><img src="https://keleshev.com/dragon.png" width="256" height="260"></center>

<center><em>Illustrations by <a href="https://twitter.com/PbKatiuska">@PbKatiuska</a></em></center>

    

</div>]]>
            </description>
            <link>https://keleshev.com/compiling-to-assembly-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821305</guid>
            <pubDate>Mon, 13 Jul 2020 14:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I made $11,673 in 5 days with an open-source project]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23821220">thread link</a>) | @samuelstancl
<br/>
July 13, 2020 | https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/ | <a href="https://web.archive.org/web/*/https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div v-pre="">
            <p>At the end of June, I launched a business-focused extension to my open-source project. <a href="https://tenancyforlaravel.com/saas-boilerplate/">The multi-tenant SaaS boilerplate for Laravel</a>.</p>

<p>The sales completely exceeded my expectations.</p>

<p>$4,980 within the first 24 hours and $11,673 within the first 5 days.</p>

<p>🤯</p>

<p>Here’s the story leading to this.</p>

<h2>Story of the project</h2>

<p>Exactly 2 years ago (June 2018), I was 16 and I decided to start building my first SaaS application. It was meant to be an e-commerce platform focused on B2B sales.</p>

<p>After working on the project for 9 months, I needed to implement <a href="https://www.indiehackers.com/post/what-is-multi-tenancy-why-you-might-need-it-8a0d64f161">multi-tenancy</a>. I looked at the existing solutions (Laravel packages) and they all felt extremely confusing and complex.</p>

<p>I decided to do the naive thing and write my own package. See, I wasn’t very experienced with Laravel at this point. I’ve only been using it since around July 2018. And this was at the beginning of 2019.</p>

<p>The main thing that I disliked about the existing solutions was that they pretty much required that you rebuild your entire application around their package.</p>

<p>That felt horrifying to me — again, I wasn’t a very experienced developer.</p>

<p>I felt like there should be a solution that just works with an existing application. The basic idea of multi-tenancy is letting customers have separate databases. Why would I have to rewrite my entire application for this? Why can’t I just tell the app to use database X after identifying the customer?</p>

<h3>Version 1</h3>

<p>I released v1 of the package in February. It was limited in features, but it fulfilled my needs. I didn’t have to rewrite my app anymore.</p>

<p>The package didn’t get much traction at this point.</p>

<p><img src="https://samuelstancl.me/assets/img/tenancy-stars-v1.png" alt="The star count for version 1"></p>

<p>On February 17, it got the first star on GitHub. 3 months later, it only had 60 stars.</p>

<p>And my SaaS wasn’t succeeding either. I decided to abandon the project basically immediately after I wrote the multi-tenancy package. I realized how bad the code was. The product market fit was there, but I didn’t want to work on this codebase anymore.</p>

<p>I started some other projects instead. They of course got abandoned too, after a few months. Such is the life of SaaS.</p>

<h3>Version 2</h3>

<p>In July, I decided to double down on the package. I started working on version 2. It added a lot more features and made it less proof-of-concept-y and more production ready. Fulfilled more business needs.</p>

<p>In August, I created a landing page for the project. I started <strong>treating it more as a product</strong>.</p>

<p><img src="https://i0.wp.com/wp.laravel-news.com/wp-content/uploads/2019/10/stancl-tenancy.jpg?fit=2220%2C1125&amp;ssl=1?resize=2200%2C1125" alt="The first landing page">
<small>The first landing page.</small></p>

<p>By the end of August, the project had some 216 stars.</p>

<p>I doubled down on the marketing side of things, got some articles written and by the end of October, the project was at 476 stars.</p>

<h3>Burnout</h3>

<p>At this point, I took a hiatus from the project. I was juggling multiple projects at once and was starting to get severely burnt out.</p>

<p>For the following two months, I got basically zero work done. On any projects. This was the darkest time for me, work and focus-wise.</p>

<p>There’s a positive side to it, though. Experiencing a strong burnout for a manageable period of time is good — if you analyze it well. Teaches you what <strong>not</strong> to do and how much it sucks to be burnt out. After an experience like that, you’ll focus very hard on not getting burnt out.</p>

<p><img src="https://builtwithtailwind.s3.amazonaws.com/237/conversions/tenancy.samuelstancl.me_-featured.jpg" alt="The second landing page">
<small>I finished this period of focusing on the package with a second, better-designed landing page.</small></p>

<h3>The lockdown</h3>

<p>The coronavirus pandemic was a blessing in disguise when it comes to side projects.</p>

<p>Instead of school, I got to stay at home.</p>

<p>In the past few months I didn’t do much work. So working now was actually refreshing!</p>

<p>The timing really couldn’t have been any better. School got closed first week of March. About 2 weeks after I could (and did) legally get my sole proprietor license.</p>

<p>I took on a bit of client work, started making a bit of $ from that, but mostly <strong>I again focused on the package</strong>.</p>

<p>There were some quirks I didn’t like about the architecture of the code. I also didn’t like that the package was making an impression of being too opinionated and not enterprise™ enough.</p>

<p>So I focused on fixing exactly that.</p>

<p>I contacted a person who was interested in me adding some more enterprise-y features back in October. I explained that I’m focusing on the package again and that I’d like to add a lot of things to it.</p>

<p>He was very glad to hear this. We talked for a while and he offered <strong>sponsoring me to add specific features to the open-source package</strong>:</p>

<blockquote>
  <p>Let me know if €5,000 is a good price for you.</p>
</blockquote>

<p>This was huge.</p>

<p>See, the project was released in February 2019. And there were <strong>no donations whatsoever</strong> until October.</p>

<p><img src="https://docs.google.com/spreadsheets/d/e/2PACX-1vSJCo55YgQmuVaJCuyfsKmSs23UIemGD3g198A5fvYhSQeMdzBI7NA7z9NEx0VwbNSEYdj_N4uZEsBx/pubchart?oid=1707722928&amp;format=image" alt="Donations between launch (February 2019 and March 2020)"></p>

<p>And even until March, the donations totaled $111.</p>

<p>5,000 EUR felt massive.</p>

<p>This was at the end of April.</p>

<p>I accepted the offer, expressed great gratitude and got to work.</p>

<p>I decided to focus <strong>FULLY</strong> on the package.</p>

<p>I was writing code and documentation all <strike>days</strike> nights long. Quarantine did its thing on my sleep schedule, but I was happy. Got a ton of work done.</p>

<p>Woke up at 16:00, went to bed at 8:00. Every day.</p>

<p>On May 13th (about 2-3 weeks after the donation) I announced a closed beta.</p>

<p>Why closed? Continue reading.</p>

<h3>Competition</h3>

<p>Like I said, there were other packages.</p>

<p>The project that made me create my own package also had a sister package. It was in development for seemingly forever.</p>

<p>However, in May, Spatie — a web development agency that’s very famous in the Laravel world for their open-source work — started writing their own multi-tenancy package.</p>

<p>This made the other project hurry development too. So in May, these packages were being released:</p>

<ul>
<li>My package’s version 3</li>
<li>Spatie’s new package</li>
<li>tenancy.dev’s new package</li>
</ul>

<p>This got stressful fast.</p>

<p>The Spatie package was built on the same principles as my package. Automatic, no changes needed. Except it was a lot simpler version.</p>

<p>That was no good!</p>

<p>Also remember when I said that I was trying to focus my package more on the enterprise-y needs, like flexibility? That’s what the tenancy.dev package is about, to a large degree.</p>

<p>Hence the closed beta. I ain’t showing no code to competition!</p>

<p><img src="https://samuelstancl.me/assets/img/tenancy-stars-comparison.svg" alt="Comparison of GitHub stars between the packages">
<small>The evolution of GitHub stars — <span>blue</span> is my package, <span>green</span> is the older competing package, <span>yellow</span> is Spatie's new package.</small></p>

<h3>The boilerplate</h3>

<p>With the beta done, it was time to focus on the commercial product.</p>

<p>The idea was this: Even though the package does all the heavy lifting for you, you still need to implement it. And many apps will implement it in the same way.</p>

<p>So there was a place for another project. A boilerplate with all the stuff you’d be writing anyway. This means customer (tenant) onboarding flow, billing logic, an admin panel, domain management, customer HTTPS certificate management etc.</p>

<p>And it also fit perfectly into my beta. I had a beta that I wanted users to test. I also wanted to build an app that would use the package. This would make me see all the missing parts, from the perspective of a <strong>user</strong> of the package.</p>

<p>This took about a month of half-work to build.</p>

<p>Why half-work? Motivation was slowly disappearing, the beta &amp; new marketing website was out, so competition was sort of taken care of. Also a bunch of personal stuff happening.</p>

<h2>The launch</h2>

<p>I was on a family vacation in Southern Europe. I originally wanted to finish all my work before going there, but you know how IT projects are.</p>

<p>I spent the first week doing fun stuff — working out, walking, reading, listening to audiobooks and podcasts.</p>

<p>But after a week of spending my time completely differently than I normally do, I decided to finish the work. So, I spent 3 days inside the apartment. There was no time to go outside, I <strong>had</strong> to finish this.</p>

<p>I was finishing the package’s features alongside the boilerplate.</p>

<p>The package was ready for release. And so was the boilerplate.</p>

<p>This was at <strong>3 AM in the morning</strong>. I was severely overworked and it was time to write an announcement.</p>

<p>I didn’t have enough energy to send an email, do a Twitter thread, make a launch discount or any of the other stuff. Nor did I have the confidence in my abilities to do it well at 3 AM.</p>

<p>But I was glad I managed to get the marketing site done! In some form anyway.</p>

<p>So I went with a <strong>safer approach</strong>. I announced the release on my Discord server. This way only a small portion of my users saw it and if anything was wrong, I’d manage to extinguish the fire before it got too big.</p>

<p>So I made an announcement and went to bed. I didn’t expect much. I actually <strong>don’t know</strong> what I expected.</p>

<p>But I can say that <strong>waking up to $600 in sales surprised me</strong>.</p>

<p>I woke up, went to the bathroom, and went straight to the computer. Inviting people who bought the project to the private community (no automated process — gotta do that MVP!). Improving the marketing page.</p>

<p>Then I got to scheduling a <a href="https://twitter.com/samuelstancl/status/1277920614670577672">Twitter thread</a> on Hypefury and writing a marketing email on Mailchimp.</p>

<p>Then both went out.</p>

<p>And the sales started coming in.</p>

<p>A lot of them.</p>

<p>A <strong>LOT</strong> of them.</p>

<p>My inbox quickly got filled with tens of emails with the subject line of:</p>

<blockquote>
  <p>New sale of Multi-tenant SaaS boilerplate for Laravel - Standard version</p>
</blockquote>

<p><img src="https://i.imgur.com/SaBSah1.png" alt="https://i.imgur.com/SaBSah1.png"></p>

<p>I was incredibly happy.</p>

<p>The first day concluded with a bit over $5000 in sales.</p>

<h2>The selling process</h2>

<p>The product was sold in two tiers. Standard and Enterprise.</p>

<p>The difference between the two versions was that the Enterprise version got priority support and could be used by companies with an annual revenue of $60k and higher. This is the same model <a href="http://nova.laravel.com/">Laravel Nova</a> uses.</p>

<p>I launched the product with <strong>two launch discounts</strong>.</p>

<p>A “generic” one, that I haven’t yet decided when it will end.</p>

<p>And a better one, that <strong>only lasted the first 48 hours</strong>.</p>

<p>The prices were:</p>

<ul>
<li>Standard: $299 -&gt; $199 (generic) -&gt; <strong>$149 (48 hour)</strong></li>
<li>Enterprise: $499 -&gt; $379 (generic) -&gt; <strong>$349 (48 hour)</strong></li>
</ul>

<p>I think given the sales, I hit the nail on the head with the pricing.</p>

<p>It was pretty affordable for solo projects, while also being high enough for the enterprise version.</p>

<p>My project is in this strange space where there are one-man indie hacker projects on one side of the income spectrum, and huge enterprises on the other side of the spectrum. Very little in between.</p>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/">https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/</a></em></p>]]>
            </description>
            <link>https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821220</guid>
            <pubDate>Mon, 13 Jul 2020 14:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create custom ReactJS hooks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821212">thread link</a>) | @PetraIgnjatovic
<br/>
July 13, 2020 | https://www.bornfight.com/blog/how-to-create-custom-reactjs-hooks/ | <a href="https://web.archive.org/web/*/https://www.bornfight.com/blog/how-to-create-custom-reactjs-hooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<div>

<h3>Quite some time has passed since we introduced hooks in the codebase of our projects. Because of them, it has made the code reusable, cleaner, more readable and more satisfying to write. </h3>
<p>Hooks present the future of development with ReactJs — that is for sure.</p>
<p>Other than the basic hooks provided by the library itself, you can also write your own little hook (or a big one)! Those kinds of hooks are named Custom hooks. Taken straight from the React docs — a custom Hook is a JavaScript function whose name starts with <strong>”use”</strong> and that may call other Hooks. </p>
<p><strong>In this little how-to, I will be showing how you can do just that! (…and with TypeScript too).</strong></p>
<h4>A state hook (counter custom hook)</h4>
<p>In this example, I’ll show you how to implement a simple counter custom hook. Internally, it uses React’s <strong>useState</strong> and returns it along with a couple of other functions inside an object. The returned object is written with shorthand property names syntax.</p>
<pre>const useCount = () =&gt; {
  const [count, setCount] = useState&lt;number&gt;(0);

  const increment = () =&gt; setCount(count + 1);
  const decrement = () =&gt; setCount(count - 1);
  const increaseBy = (increaser: number) =&gt; setCount(count + increaser);
  const decreaseBy = (decreaser: number) =&gt; setCount(count + decreaser);

  return { count, increment, decrement, increaseBy, decreaseBy };
};</pre>
<p><strong>Now, this hook can be used anywhere within a function component. Here’s an example:</strong></p>
<pre>const { count, increment, decrement, increaseBy, decreaseBy } = useCount();
&lt;div&gt;
     &lt;div&gt;{count}&lt;/div&gt;
     &lt;button onClick={increment}&gt;increment&lt;/button&gt;
     &lt;button onClick={decrement}&gt;decrement&lt;/button&gt;
     &lt;button onClick={() =&gt; increaseBy(20)}&gt;increase by 20&lt;/button&gt;
     &lt;button onClick={() =&gt; decreaseBy(20)}&gt;decrease by 20&lt;/button&gt;
&lt;/div&gt;</pre>
<h4>A useEffect hook (custom fetch hook)</h4>
<p>This example will show how you can use <strong>useEffect</strong> inside a custom hook. By using something like this, you could improve your fetch… or you can write a custom hook if you add a ton of event handlers!</p>
<pre>const useFetch = (requestUrl: string) =&gt; {
  // set your fetch data and error types instead of any
  const [data, setData] = useState&lt;any&gt;(null);
  const [error, setError] = useState&lt;any&gt;(null);
const [isLoading, setIsLoading] = useState&lt;boolean&gt;(true);

  React.useEffect(() =&gt; {
      const fetchData = async () =&gt; {
      setIsLoading(true);
      try {
          const response = await fetch(`${requestUrl}`);
          const json = await response.json();
          setData(json);
      } catch (err) {
          setError(err);
      }
      setIsLoading(false);
    };
  }, [requestUrl]);

  return { data, error, isLoading };
};</pre>
<p>UseEffect custom hooks can be really viable and useful. Check out this <a href="https://codesandbox.io/s/kx83n7201o?file=/src/use-why-did-you-update.js" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">useWhyDidYouUpdate</a> hook, originally from <a href="https://twitter.com/brunolemos/status/1090377532845801473" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Bruno Lemos</a>.</p>
<h4>Will you start using JS hooks?</h4>
<p>As you can see from these small and compact examples, these hooks are plentifully useful. And the best thing about them is that they are super reusable even throughout different projects. If you create an awesome hook, you can use it in any future project!</p>
<p>On top of that, any hook desired, needed or thought of can be created. If you see a repeating pattern in your code which is using state or reacts to a certain event, you can easily put it in a custom hook.</p>
<p><strong>Here are a couple of references to great hooks others have made, so check it out if you’re interested in learning more:<br></strong>• <a aria-label="undefined (opens in a new tab)" href="https://usehooks.com/" target="_blank" rel="noreferrer noopener">usehooks.com</a><br>• <a aria-label="undefined (opens in a new tab)" href="https://github.com/rehooks/awesome-react-hooks" target="_blank" rel="noreferrer noopener">Awesome React hooks</a></p>
<p>_____<br><strong>We’re available for partnerships and open for new projects.<br><a rel="noreferrer noopener" href="https://bornfight.com/contact/" target="_blank">If you have an idea you’d like to discuss, share it with our team!</a></strong></p>
</div>
</div>
</section></div>]]>
            </description>
            <link>https://www.bornfight.com/blog/how-to-create-custom-reactjs-hooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821212</guid>
            <pubDate>Mon, 13 Jul 2020 14:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are not prisoners of groupthink]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23821180">thread link</a>) | @henriquez
<br/>
July 13, 2020 | https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html | <a href="https://web.archive.org/web/*/https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <h2>
            <a href="https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">
                We are not prisoners of groupthink.
            </a>
        </h2>
        <h3>How I stopped worrying about "cancel culture" with this one weird tip.</h3>
        
        <p><em>This is a response to the Gareth Roberts essay titled
<a href="https://unherd.com/2020/07/why-the-prisoner-is-more-accurate-than-orwell/">"We are all prisoners of groupthink".</a></em></p>
<p>A common theme on the Internet is selection bias. We seek out content and
interactions that fit our sensibilities, beliefs and emotional disposition.
Social networks have exploited this tendency, drawing us into
<a href="https://en.wikipedia.org/wiki/Filter_bubble">filter bubbles</a> where we are
algorithmically bombarded with content designed to maximize our "engagement"
with no regard to damage done in terms of our psychological well-being or
intellectual isolation. This makes us better consumers, but reinforces
divisions between individuals and poisons any possibility of meaningful
discourse, instead favoring shit-flinging competitions between so-called
<a href="https://twitter.com/realdonaldtrump/status/1261126114799468549?lang=en">"keyboard warriors."</a>
This is well-documented, the social media companies are aware of it,
and they don't care because <a href="https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499">division makes money.</a></p>
<p>Our filter bubbles are designed to comfort and placate us while we're force-fed
promoted content and offers and idealized imagery. Our collective ability
to think critically has been siphoned away; anything that remotely challenges
our beliefs is seen as a threat or an attack. Over time this has lead to the
ridiculous notion that "words are violence," and from this, the rise of
<a href="https://en.wikipedia.org/wiki/Online_shaming#Call-outs_and_cancellation">cancel culture</a>,
the First World pastime of mobbing, doxing, and socially destroying
anyone who dares to voice an unpopular opinion or do something stupid. This cancel
culture was born of social media. Sure, some might blame other factors like liberal
arts education but really they're nothing new to society. But I'll tell you what changed.</p>

        
            
<p>Back in the good old days (when you didn't need 32gb of
memory to browse the web), Twitter and Facebook used to display a chronological
feed of your friends' posts. This was very functional, but ended up creating a problem
for the social media companies: in order to maximize the amount of time you spend on
their sites they needed you to friend/follow tons of people (even people you aren't really
friends with). But if you did that, your feed would turn into a shitshow, with too
much content for any person keep up with. So Facebook and Twitter went back to the
drawing board and came up with a fantastic innovation: the algorithmic content feed
(aka. the death of society and end of the Internet). The feed algorithm could "get
into your head" with <a href="https://en.wikipedia.org/wiki/Psychographics">psychographic microtargeting</a>,
allowing the machine to recommend content and advertisements that <em>you</em> are likely to
"engage" with—click, like, share,
anything to keep you on the site and viewing more ads a little longer.</p>
<p>The deprecation of the chronological timeline in favor of the
machine-curated content feed had major psychological side effects for everyone involved.
When the machine decided what content to recommend it would favor content that is most
likely to create engagement; this trends toward content that creates an emotional
response, which on the Internet is most often outrageous content that evokes fear or
anger. By bombarding people with upsetting shit and exposing them to "communities" of other
people <a href="https://knowyourmeme.com/memes/circle-jerk">circlejerking</a> about how upsetting
everything is, the machine dialed the filter
bubble effect up to 11, essentially dividing people into groups and then radicalizing
them with increasingly extremist content. And in the process,
<strong>Facebook and Twitter radicalized the actual publishers of content.</strong></p>
<p>Remember when you could pick up a newspaper or turn on
your television and get news coverage that seemed at least superficially factual
and unbiased? Obviously those days are gone. Newspapers are mostly out of business,
TV viewership is down, and the dying husk of our mainstream media is increasingly
obsessed with a contrived "culture war." Traditional media has been superceded by
the Internet, and with social media dominating peoples' time spent on
the Internet, Facebook and Twitter have become gatekeepers between the
publishers and their viewers. Factual and unbiased reporting is simply not engaging
enough and will not appear on peoples' feeds. Only breathless hyperbolic
fear-mongering and rage porn will break through the algorithm and get clicks.
Mainstream publishers have been forced to shift their entire media strategies
around <em>online engagement</em> as they desperately attempt to stay relevant on the Internet.
And what's more engaging than a controversy? Thus,
mainstream publishers have "picked sides" that resonate with their
audiences'
filter bubbles in the artifical culture war, promoting non-newsworthy events
into manufactured controversies, and sparking mob action with headlines like
<a href="https://www.cnn.com/2020/07/11/us/goya-foods-unanue-trump-hispanic-market/index.html">"Here's why [food CEO's] meeting with [world leader] is prObLeMaTiC."</a></p>
<p>And that brings us to recent months, where
after locking every person of fighting age in closet-sized apartments, where peoples' only
access to the outside world was filtered through the toxic lens of social media, and
where the only information available was underpinned by fear and outrage, people
lost their shit. And now we're collectively hand-wringing about cancel culture (but
being real careful not to upset the mob.)</p>
<p>But here's the thing: cancel culture is irrelevant if you don't give a fuck.
You are not a prisoner of groupthink. You might be a prisoner of your belief
that you should give a fuck. But that is under your control. We are not living
a George Orwell hellscape, memes like
<em>"<a href="https://en.wikipedia.org/wiki/Nineteen_Eighty-Four">1984</a> was a warning, not
an instruction manual"</em> fall flat. The premise that we should care what a bunch
of larpy wannabe do-gooders think on Twitter and Facebook is false.
It doesn't matter—you can't lose a game you don't play. Cancel culture was born
of social media. <strong>If we cancel Facebook and Twitter</strong>, we can break the cycle of
extreme division and hyperbolic microtargeting, shatter the filter bubbles,
and reclaim our access to information from monopolistic ad targeting algorithms.
By divorcing our attention from these toxic echo chambers, manufactured controversies
will become less profitable,
people will be able to think more critically and talk to each other more sincerely,
and cancel culture will end organically. There are really no major drawbacks.</p>
<p>So much of our time online is <em>wasted</em> creating, curating, and "defending"
these perfectly plastic personas, avatars, idealized identities that represent
some vague notion of a persistent sense of self on the Internet. And for what?
Do you really talk to your 600 Facebook friends? Do you even give a shit about
who your 10,000 Instagram followers are? Do they give a shit about you? No.
People waste so much of their lives trying to stake out an online identity that
they start to believe it actually matters, <em>but it doesn't.</em>
<strong>A persistent online identity is a liability, not an asset.</strong></p>
<p>We are all tempted by the lie that social networks base their existence on:
that we need to put our "selves" online for all to see. This lie is a mental hack,
exploiting our human need for meaningful interactions with other people,
as well as the dark aspects of human nature: ego, anger and trauma. As society
increasingly isolates and divides humans from one another physically and
socially, we are tempted by the lie that our online personas form a meaningful
extension of our real-world selves.</p>
<p>Sadly, the vast majority of our interactions on social media are hollow, and the
few glimmers of meaningful connections with others that <em>do</em> occur
instill a Pavlovian-style hope, an addictive draw to keep us infinitely scrolling
through our algorithmically-curated content feeds in the vain hope that the
machine will bring meaning to the emptiness of our lives. But social media is little more
than mental masturbation. The service is free but the price we pay is dear.</p>
<p>When you put your real self online, you open yourself up to attack.
Like a federal indictment, the mob can come for anyone at any time. Whether or
not you are a good person is irrelevant, and trying to craft your online persona
to appease the mob is a loser's game. As the filter bubbles increasingly divide-and-circlejerk
people into more extreme viewpoints, what passes for acceptable
behavior today could be heresy tomorrow. And when your name, your employer, and
your family are all connected to your social media presence, you put yourself in
real world danger for very little real world benefit.</p>
<p>So what can you do? <strong>Cancel yourself.</strong> Delete your social media presence.
Sever the link between your online self and your real-world self. Seriously.
<em>You can't lose a game you don't play.</em></p>
<p>But wait, <em>isn't this extreme?</em> Maybe it is, or maybe you're just addicted to
social media. I've talked to a lot of people about this and heard some common
excuses people use to rationalize addictive behavior to themselves.</p>
<ul>
<li><strong>"But social media is an important part of my professional network."</strong></li>
</ul>
<p>I can only speak anecdotally. I've built a successful career without using LinkedIn
or other social networks to promote myself. My work ethic, skill and reputation have
carried me
as far as I care to go in my field. Also anecdotally, when I hired a contractor
to remodel my basement, I didn't check her Facebook page; I saw her work at a
neighbor's house and asked them to put me in touch. She did a great job on
my basement (and later posted photos of it to her Instagram). Good work
promotes itself.</p>
<p>But what doesn't work is when the line between personal and professional gets
blurred, which is almost inevitable on a medium designed around social
interaction. The tension between <em>being a professional</em> and <em>having an opinion</em> is
overwhelming for some people. The person who lists in their Twitter bio that
they "work for Google" and "bash the fash" isn't doing themself or their employer
any favors. Such tact only works for those who stay in the good graces of the mob,
which is, again, a loser's game.</p>
<ul>
<li><strong>"But I use social media to keep in touch with my school friends."</strong></li>
</ul>
<p>No you …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html</a></em></p>]]>
            </description>
            <link>https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821180</guid>
            <pubDate>Mon, 13 Jul 2020 14:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Be More Unlikeable]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 73 (<a href="https://news.ycombinator.com/item?id=23821121">thread link</a>) | @elijahmurray
<br/>
July 13, 2020 | https://www.gritlist.co/be-unlikeable/ | <a href="https://web.archive.org/web/*/https://www.gritlist.co/be-unlikeable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            


                <section>
                    <div>
                        <blockquote>"The reasonable man adapts himself to the world; the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man." - George Bernard Shaw</blockquote><p>I grew up in a family where I was taught to be likable. To please, to impress, and to make others happy. Seems like a pretty good idea, right?</p><p>While likeability is a good trait if you want to be popular it isn't ideal if you want to achieve. Let me explain.</p><p>Popularity feels good. Being liked feels good. Humans evolved as social creatures and we crave attention from each other. This pattern plays out over and over in schoolyards, bars, and workplaces, or anywhere humans meet. And the cooperation needed for our survival can only happen if you're accepted by your tribe.</p><p>However, praise by the masses won't make you successful, let alone fulfilled. Actually it's more likely that <em>popularity will prevent you from being successful.</em></p><p>Movie stars, professional athletes, and a business visionaries–we all want to be them. We grow up trying to be them. Personally, I've long idolized Steve Jobs and Elon Musk. But most of our heroes got to where they are by being unlikeable, not likable.</p><p>We love these men and women for being unique yet we internally berate ourselves for being different. These heroes have been described as annoying, difficult, stubborn, and unreasonable. Not exactly what we strive to read about ourselves in peer reviews. Sure, they have some popularity, but it's not all rainbows. Was Gandhi liked? Yes, but he also had millions of people who were against him, and ultimately murdered him. So if it's the oddballs that we look up to, why do we try to be so likable?</p><p>This aversion to difference starts early. Bullies throughout life pick on the kid who is different, on the easy target. Additionally modern culture has decided that the best path in life is to do as you're told; follow the rules, stay in line, and smile. Follow the leader and be a good girl/boy. The scripture of conformity is pervasive.</p><p>And there is true merit to fitting in. Society can't exist without collectively agreed upon rules. Early on we learn that being a three year old hellion is unacceptable has consequences. If I spit out my Cheerios one more time mom will be angry mom, so I'm going to be nice.</p><p>So we're taught to fit in. Be likable and hide your "flaws". Like the only white fish in a school of black fish you don't want to be the different one when a shark is on the prowl. Blend in and don't stand out. Seek group acceptance.</p><p>While conformity has its place in keeping society running, too much conformity stunts progress.</p><p>Differences are what make you, you and me, me. They're what make change possible. Change comes from differences, not from more of the same. After all, a species evolves based on small aberrations, on "flaws", that turn into strengths and a better way of being.</p><p>All progress comes from those who see the world differently. First they act differently and then they convince others to see differently as well. They don't accept the status quo and they don't assimilate.</p><p>Generally speaking this results in being unpopular. Many of the people who helped change the world aren't liked even in the height of their success. But they kept pushing their indomitable will against the world, and eventually, the world shifted ever so slightly.</p><p>Practice being unreasonable this week. Don't "yes" your way through life, following someone else's path for you. Be a bit more of a jerk. Be more demanding. Piss a few people off.</p><p>And be okay with it. Be okay with people being angry or mad or annoyed with you. Cultivate your ability to keep pushing towards your goals despite what others say.</p><p>And who knows, maybe you'll see the world shift ever so slightly.</p>
                    </div>
                </section>



        </article></div>]]>
            </description>
            <link>https://www.gritlist.co/be-unlikeable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821121</guid>
            <pubDate>Mon, 13 Jul 2020 14:28:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A/B capital for cloud infrastructure and enterprise software]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821049">thread link</a>) | @ekhornung
<br/>
July 13, 2020 | https://upside.fm/saurabh-sharma-jump-capital/ | <a href="https://web.archive.org/web/*/https://upside.fm/saurabh-sharma-jump-capital/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="target-id5f10536b790bc"><p>Saurabh Sharma 0:00<br> All of us come from all varying backgrounds. And I would say that DNA kind of flows in somewhat automatically. You want to roll up your sleeves even to help the companies to the extent they need, right. We’re not enforcing this. And I would say that combined with I would say, yeah, to some extent, and midwest primarily them in building these businesses. I do think that differentiates.</p><p>Jay Clouse 0:20<br> The startup investment landscape is changing. and world class companies are being built outside of Silicon Valley. We find them, talk with them and discuss the upside of investing in them. Welcome to Upside.</p><p>Hello, hello. Hello, and welcome back to the upside podcast, the first podcast finding upside outside of Silicon Valley. I’m Jay Clouse, and I’m accompanied by my co host, mister money mustache himself Eric Hornung.</p><p>Eric Hornung 1:00<br> Unfortunately, Jay, maybe you can’t see it through this pop filter, but the mustache is no longer.</p><p>Jay Clouse 1:06<br> It’s a little stubbly.</p><p>Eric Hornung 1:08<br> Yeah, it’s a little stubbly it’s, it’s my, it’ll be my first full shave. Since I got rid of the mustache. I did the first two months of quarantine with the beard and the mustache. I was doing my best Jay Clouse. And then I said, You know what, I’m just not a beard guy. It’s not. It’s itchy. It’s, um, I think I’ve described it previously on the podcast as pube.</p><p>Jay Clouse 1:32<br> And I cringe every time you say the word pube on the podcast.</p><p>Eric Hornung 1:34<br> Yeah, it’s I’ve probably said it too many times on the podcast, I would say, yeah, once you get rid of once you get rid of the beard, and you’re looking yourself in the mirror and you say, Can I pull this off? If I walk out of this bathroom? Will my fiance kill me? And you just go for it. It’s a magical moment. Jay. When there’s a there’s a shriek and then an acceptance of this is who I am now. I’m a moustache guy.</p><p>Jay Clouse 1:59<br> You sent me the photo and I was like, Oh, I’m so glad that you shaved it in this order and took the time to get a photo of this before it’s gone. And then it stuck around six weeks.</p><p>Eric Hornung 2:09<br> Yeah.</p><p>Jay Clouse 2:10<br> Was it really there for six weeks?</p><p>Eric Hornung 2:11<br> It might have been five weeks but yeah, something like that.</p><p>Jay Clouse 2:13<br> Wow. And and Colleen was okay with it.</p><p>Eric Hornung 2:17<br> I think she liked it better than the beard.</p><p>Jay Clouse 2:20<br> Wow.</p><p>Eric Hornung 2:21<br> Yeah. So it was a nice mustache. I won’t lie we got trimmed it up. I gave it a little bit of love. It’s just you know it the mustache life is tough, Jay because you drink a little bit of milk. Yeah, mustache in your milk, milk in your mustache. Whatever is it.</p><p>Jay Clouse 2:34<br> I actually don’t experience many of the mustache pains myself because my mustache is the weakest part of my beard.</p><p>Eric Hornung 2:39<br> Hmm.</p><p>Jay Clouse 2:40<br> So yeah, I go on enumerate on the number of moose mustache problems.</p><p>Eric Hornung 2:45<br> Yeah, yeah, very eating a hot wing with a mustache. You got hot wing for the next four hours because it’s not leaving your mustache. Anyway, yeah. So the mustache the whole That whole that whole phases is behind me, Jay, but it lives on in memoriam.</p><p>Jay Clouse 3:05<br> Well, I’m glad that you made the jump into not only trying the beard but trying a mustache. And speaking of jump, today we are talking with Saurabh Sharma. He is a partner at Jump Capital, a thesis led sector focused and operating centric venture capital firm specializing in series A and B in growth stage investments, Jump Capital invest in data driven technology companies within the FinTech, B2B SaaS, IT data infrastructure and media sectors. They’re based in both Chicago and New York. Eric, how do we find them capital,</p><p>Eric Hornung 3:43<br> I got connected with Jump Capital, indirectly, I think two years ago, maybe it was via Twitter or via an email or something. And so I don’t exactly remember how it happened. But I’ve been in contact via email with a few of the partners there just because I really like the way that they are structured and set up and what they focus on. And they’re very explicit about what they do, which I find to be refreshing in the venture capital space. And we wanted to have a conversation with them. And you know, we got to have one today.</p><p>Jay Clouse 4:13<br> Jump Capital has invested in a previous Pod Co Balto, they’ve invested in Personal Capital, just to name a couple of companies that you’ve heard of also Lisnr in Cincinnati. He talked about them being explicit and what they actually invest in. They also say on their website that they invest $1 to $10 million in their first investment, when companies have a $1 to $5 million revenue run rate. And typically, less than $10 million of investment so far today, so yeah, very explicit on their website in terms of industry, what types of companies are looking for, even at what stage? You know, the investment, the investment terms are?</p><p>Eric Hornung 4:51<br> Yeah, they have a operating partner model which is much more like private equity than it is a lot of the venture capital firms. We talked to the platform model almost. So when you’re very specific about the types of companies that you’re going to invest in, I think that operating model becomes stronger because you can get the best people to do the specific thing that needs to be done in these four focus areas in that very specific space where its product market fit has been met and it is growth time.</p><p>Jay Clouse 5:21<br> All right. Well, we’d love to hear your thoughts on this episode with Saurabh as we go through, you can tweet at us @UpsideFM or email us Hello@upside.FM. And we’ll get into that interview right after this. This episode of upside is sponsored by Tresta. Tresta is an app for iPhone and Android that lets you do business calling and texting from anywhere with no hardware. Just a smartphone you’re already using. Tresta is the best business phone app on the market. Whether you’re a founder or freelancer, just starting your business or you’re already established. Growing your network and your business is all about communication. You’ve got to be available no matter where you are. Tresta offers the call management features that empower you to communicate smarter and more efficiently, like auto attendance, call recording, user groups and more. And you don’t need any special equipment, just the smartphone you’re already using. Tresta is easy to configure. So you can set everything up yourself all online. Tresta’s virtual phone system makes it easier and more affordable than ever to set up a fully functioning mobile office. It’s just $15 per user per month with no contract. So start your free 30 day trial today at www.tresta.com/upside. That’s www.tresta.com/upside. Saurabh welcome to the show.</p><p>Saurabh Sharma 6:08<br> Thank you folks. Great to be here.</p><p>Eric Hornung 6:47<br> Let’s take it on a rocket ship. How did you get to Jump Capital.</p><p>Saurabh Sharma 6:51<br> Yeah, I mean it’s a kind of an unconventional path. I don’t think I was looking misery your venture capitalist. From a career perspective. I think it’s a three organic way down. Journey has been a little bit all over the place, which I think bodes well to venture frankly, just kind of amalgamation of a bunch of things. But you know, I’m fundamentally I’m an engineer by training and science, grew up in India in engineering there, got a scholarship to Apollo undergrad in France. Finish that became a computer science researcher in France, in the National Research Labs, got an opportunity to come to my masters and possibly a PhD at Cornell, where they’re in just kind of got brainwashed of Academia, by Wall Street, being brothers and all the banks that just go to campus and hire quantum computer science guys, so I just finished my Master’s in Cornell, join Lehman Quanta Algo trading desk was there, you know, the hay days and just perfect time as they’re even open to await the peak of Lehman. And so you know, phenomenal times, obviously, ranging from fairly very large scale architectures for competition trading in New York, London, and some phenomenal desks in the Ritz trading. Bring meeting go face. Solid tobacco was there almost to the end not exactly to the end I had an opportunity to apply for business schools which I had been pushing off and I thought really good time. After 07, there are some signs they might be weaker and then I got my admit I got took some time off and moved to India back to this small snippet of equity for business school, but I didn’t know it was gonna go up. It kind of blew up premier the first week I started my business school in Chicago booths. So the next year was kind of experimenting, starting my own company a bunch of my friends. And then you know, I’m preparing to started doing them for them and post that went back to Wall Street a little bit works on capitals with Bob Lehman at the time realized probably wasn’t for me back Michael was the chief quite a bit to join early stage uncle life Bank of Chicago Southern by April kowski Radke local mountain nurse in the region funded that a startup that I was involved in earlier. And then it allowed us to spend some time with light bank, Eric ended up being the Groupon CEO asked me to come along during some times to kind of turn around the story. And so another kind of run at pretty phenomenal setup of interesting projects of turning around the business. I was involved in an internal data science team run mobile relevant strategy, and then Mary Barra fashion conference in New York. So running operations and marketing for that, for that business in an intersection folks a jump and it was kind of good amalgamation a jump, as we will talk about more it has some relevance to so creating groups, very computational focus. So that can all put it together. You know, I’m actually in background I’ve been venture, I’ve been in tech and to join the joint jump for about four and a half years ago. So again, somewhat unconventional but but took me multiple paths. But I think all that is super …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://upside.fm/saurabh-sharma-jump-capital/">https://upside.fm/saurabh-sharma-jump-capital/</a></em></p>]]>
            </description>
            <link>https://upside.fm/saurabh-sharma-jump-capital/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821049</guid>
            <pubDate>Mon, 13 Jul 2020 14:21:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking the Myth of 10% Brain Usage]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23821046">thread link</a>) | @iuliangulea
<br/>
July 13, 2020 | https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p>The human brain is a marvel of biological engineering. It allowed us to accumulate and pass on the knowledge of many prior generations throughout millennia, resulting in a civilization that went into space, taught computers to see and speak, and that continually discovers and investigates the laws of the Universe.</p>
<p>Its complexity is astounding, and we do not fully understand it yet. And because of that, occasionally, myths about the functioning of the brain pop out. Among the most prominent such legends is the one that claims we are dormant geniuses. But before analyzing and debunking that, let’s discuss some brain facts.</p>
<h2 id="size-does-not-matter">Size Does Not Matter</h2>
<p>For instance, did you know that the brain weighs around 1300-1400 grams? It represents only 2% of the total body weight of a 150 pound or 70kg human. However, it requires:</p>
<ul>
<li>15% of total cardiac output (the blood that flows in our body);</li>
<li>20% of total body oxygen;</li>
<li>25% of total body glucose utilization</li>
</ul>
<p><img src="https://iuliangulea.com/images/brain-energy-consumption.png" alt="Human brain weight vs. energy consumption"></p>
<p>That is quite an energy-hungry organ inside our skull! But even that fades away when comparing to children: at around five years old, the human brain takes up as much as 50% of oxygen consumption<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>Surprisingly, the brain’s level of oxygen consumption does not significantly vary when you are resting vs. when you do some cognitively intense work. Overall, measures of the whole brain changes in blood flow during intense mental activity have failed to demonstrate any change. Even <em>local changes</em> in blood flow of the regions involved most in a cognitive task are often 5% or less.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>Conversely, it is well known and demonstrated that glucose is the brain’s “fuel,” therefore increases in blood glucose levels can positively impact cognitive performance in some tasks.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<h2 id="the-mystical-brain-myth">The Mystical Brain Myth</h2>
<p>There is a popular myth that we use our brains at only 10% of its capacity, thus boldly affirming that we have a whopping 90% of dormant potential that we can awaken and become geniuses.</p>
<p>Unlike other widespread myths that started from a single event, or unscientific claims from poorly designed research studies (e.g., <a href="https://en.wikipedia.org/wiki/Andrew_Wakefield">Andrew Wakefield</a> and his fraudulent study than falsely claimed a link between vaccines and autism), the myth that humans use only 10% of their brains started at the end of the nineteenth century and was gradually strengthened by many people since then. The <a href="https://en.wikipedia.org/wiki/Ten_percent_of_the_brain_myth#Origin">Wikipedia</a> article on the subject has a lengthy explanation of the potential origin and evolution of the myth throughout the years.</p>
<h3 id="a-small-confession">A Small Confession</h3>
<p>Before moving on, I have a revelation to make. Occasionally, I might buy a cloth item and wear it once or twice. If I recall correctly, there might have been one or two items in my experience that I have not worn at all. Do you know anyone with similar oddities?</p>
<p>This makes my wardrobe much like the brain described in the myth: I am using around 10% of it, and I can “tap into” the rest of my wardrobe should such need arise.</p>
<h3 id="your-brain-is-not-a-wardrobe">Your Brain Is Not A Wardrobe</h3>
<p>But our brain is not a collection of cloth items. Though there are still unanswered questions regarding some brain functions, brain mapping physiology demonstrates that all its areas have a purpose. And you do not have to be a neuroscientist to prove that, simply recall from your anatomy classes that the brain has different regions, such as the frontal lobe, occipital lobe, cerebellum, and the fact that each of those lobes has its role.</p>
<h2 id="debunking-the-myth">Debunking The Myth</h2>
<p>Let’s address that myth in a more scientific manner.</p>
<p>If we are using only 10% of our brains, that means a person would be fine if the other 90% of the brain got removed. 10% of the 1400g average brain is 140g—that’s the size of a sheep’s brain.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> Since I doubt sheep have their own 90% hidden potential myth, it makes no sense that humans have advanced so far as a civilization by using only part of their brains equivalent in size to a sheep’s brain.</p>
<p>There are instances in history when people were injured and got parts of their brain removed (although not as close as even 10%), the most prominent (and among the first recorded ones) being the case of <a href="https://en.wikipedia.org/wiki/Phineas_Gage">Phineas Gage</a>, who survived an accident where a large iron rod was driven through his left part of the head, from the bottom of the cheek, through his left eye and frontal lobe all the way to the top of his head. He lived 12 years more after that accident. There are varying opinions on his recovery, but it took him ~10 years to recover from the unfortunate event.</p>
<p>Another example is the case of <a href="https://en.wikipedia.org/wiki/Lev_Zasetsky">Lev Zasetsky</a>. A bullet entered his left parieto-occipital area and resulted in a long coma. Following this, he became unable to perceive the right side of things. Objects he did see often appeared as fragmented pieces rather than whole objects. He did not recover in the 50 years he lived after the injury.</p>
<p>As mentioned in <a href="https://iuliangulea.com/blog/how-people-learn-the-brain-basics/">How People Learn—The Brain Basics</a>, our brains can rewire through a process called <em>neuroplasticity,</em> which can help regain some of the lost functions as a result of an accident. Unfortunately, that is not always the case. Researchers have found that only 27% of people recover from a <em><strong>concussion.</strong></em><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> That means almost 3 out of 4 people do not fully recover! And this is “just” a concussion—your brain does not lose any of its parts.</p>
<p>If 90% of the brain were unnecessary, it is highly unlikely that we would not have evolved such big brains with irrelevant matter in the first place. There are several factors for that:</p>
<ul>
<li>Historical risk of childbirth deaths due to the big skull size would stress out the selection of offspring with smaller brain sizes.</li>
<li>Natural selection favors characteristics that offer an advantage of some sort over the other. There is no way such a big brain would have formed in the first place if it wouldn’t be necessary for survival.</li>
<li>As already mentioned, the brain requires an enormous amount of energy. Even if we had 90% of the brain unused and suddenly were to “wake” it, we couldn’t provide our brains with enough power, as it already consumes 20%-25% of the entire body resources.</li>
</ul>
<p>All this scientific evidence works against this myth. We indeed use only some areas of the brain at any given time, but throughout the day, we use all of it, not just 10%. And next time you hear about this myth, recall the sheep brain weight.</p>
<hr>
<p>If you liked this article, feel free to subscribe below to be among the first to receive future updates and follow me on twitter (<a href="https://twitter.com/iuliangulea">@iuliangulea</a>) as well.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Kennedy C, Sokoloff L. <a href="https://pubmed.ncbi.nlm.nih.gov/13449166/">An adaptation of the nitrous oxide method to the study of the cerebral circulation in children; normal values for cerebral blood flow and cerebral metabolic rate in childhood.</a> J. Clin. Invest. 1957;36:1130–1137. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>The Effect Of Mental Arithmetic On Cerebral Circulation And Metabolism by Sokoloff L., Mangold, R., Wechsler, R., Kennedy, C. &amp; Kety, S. S. (1955) <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Rachael T. Donohoe, David Benton—<a href="https://www.researchgate.net/profile/David_Benton/publication/12840251_Cognitive_functioning_is_susceptible_to_the_level_of_blood_glucose/links/5489df990cf225bf669c75e5.pdf">Cognitive functioning is susceptible to the level of blood glucose</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Differences Between Human And Sheep Brains—<a href="https://animals.mom.com/differences-between-human-and-sheep-brains-3500869.html">animals.mom.com</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://www.braininjuryaustralia.org.au/research-recovery-concussion/">How Many Make A Full Recovery From A Concussion?</a>—BrainInjuryAustralia.org.au <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    
    
        
    

</div></div>]]>
            </description>
            <link>https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821046</guid>
            <pubDate>Mon, 13 Jul 2020 14:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SWR – Data Fetching for React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820970">thread link</a>) | @arunoda
<br/>
July 13, 2020 | https://getstarted.sh/with/swr | <a href="https://web.archive.org/web/*/https://getstarted.sh/with/swr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>How do you fetch and manage data in a React app?</p><p>You could try using <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API">fetch</a> directly and work with built-in React hooks like <span>useEffect</span>.</p><p>Then what if you want to:</p><p>📋 cache data between components
<br>🌎 sync data between browsers
<br>🔄 check for new updates
<br>💨 add optimistic UI support</p><p>Then you have to add more custom logic to handle these cases.</p><p>What if there's a library that does all of these(and more) for you. That's <a target="_blank" href="https://swr.vercel.app/">SWR</a>.
</p><p>Have a look at the following example. That's what we are building in this lesson.</p><div id="container"><p>Play Now</p><p><img src="https://img.youtube.com/vi/n3h19yvLOS0/maxresdefault.jpg" width="100%"></p></div></div></div></div>]]>
            </description>
            <link>https://getstarted.sh/with/swr</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820970</guid>
            <pubDate>Mon, 13 Jul 2020 14:12:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a DIY Pen Plotter: MidTbot]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820926">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Earlier this year, I built a DIY pen plotter (mostly) from scratch. I'd been
meaning to post a build log, because this was one of the more enjoyable hardware
projects I've worked on recently. However, it's taken a while to write-up this
project because, well,
<a href="https://benjamincongdon.me/blog/2020/03/24/March-Updates/">there was a lot of stuff going on</a>.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter_hu26049e58bcb0e8f71afc8b124b2c5223_266932_0x400_resize_q75_box.jpg" alt="Completed Plotter with Ruler for Scale"> </a><figcaption>
        <p>Completed Plotter with Ruler for Scale</p>
    </figcaption>
    </figure>

<h2 id="why-build-a-plotter">Why Build a Plotter?</h2>
<p>So, why is it worth building a pen plotter? The short answer is, “they're cool”.
The longer answer is that, despite commercial printers (ink jet, laser, etc.)
working better for general purpose printing, the quality of a pen-plotted image
is noticeably different than something that's been traditionally printed.
Plotted images can have a more natural, organic feeling to them, because they're
produced by raising and lowering a pen manually, like a human does.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>I've also had a persistent curiosity with
<a href="https://benjamincongdon.me/blog/2019/03/07/Generative-Doodling/">generative art</a>. Much of the community
built around generative art (colloquially,
<a href="https://twitter.com/hashtag/plottertwitter">#plottertwitter</a>) uses pen plotters
to turn “bits into atoms”. While most folks opt to buy a commercial plotter like
the <a href="https://axidraw.com/">Axidraw</a> or restore vintage plotters from the 1980's,
there's a growing community of people building their own plotters.</p>
<h2 id="assembling-the-components">Assembling the Components</h2>
<p>The first step in the project was collecting the bill of materials (BOM).
There's a well-researched BOM on the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/Docs/mechanical_BOM.md">project Github</a>.
Other than the midTbot PCB, which is for sale
<a href="https://www.tindie.com/products/33366583/midtbot-esp32-v2-controller-kit/">on Tindie</a>,
I had to order:</p>
<ul>
<li>Linear shafts and Linear Bearings (Amazon)</li>
<li>Pulleys and Idler Pulleys (Amazon)</li>
<li>Rubber Timing Belt (Amazon)</li>
<li>2 Stepper Motors (Amazon)</li>
<li>Stepper Motor Controllers (Amazon)</li>
<li>12V 3A Power Supply (Already had one)</li>
<li>Basic Hobby Servo Motor (Already had one from previous Arduino projects)</li>
<li>Assorted M3/M5 Head Screws (Home Depot, Ali Express)</li>
</ul>
<p>I was pleasantly surprised how available most of the parts were online –
everything except for the screws/nuts were available on Amazon.</p>
<p>Once I received my midTbot PCB, there was some soldering and assembly to do. I
followed
<a href="https://github.com/bdring/midTbot_esp32/wiki/Controller-Kit-Assembly-Instructions">these instructions</a>
to attach the homing switches, power supply, and header pins to the board.</p>
<h3 id="printing-the-chassis">Printing the Chassis</h3>
<p>The chassis of the midTbot is entirely 3D printed. There are ~7 things that you
need to print
(<a href="https://github.com/bdring/midTbot_esp32/tree/master/STL">source files</a> on
Github), and they're all fairly simple shapes, so the prints were easy to do.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print_hu632932bafc371cef54c7ef30f19a742b_135778_0x400_resize_q75_box.jpg" alt="Completed prints of the &amp;lsquo;feet&amp;rsquo; and tailblock pieces"> </a><figcaption>
        <p>Completed prints of the ‘feet’ and tailblock pieces</p>
    </figcaption>
    </figure>

<p>The hardest thing to print (and the most finicky part of the project in general)
was the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/STL/midt_esp32_pen_mnt.stl">pen mount</a>.
This piece has some overhangs on it, so it was important to configure the
printer to add support material.</p>
<h2 id="assembly">Assembly</h2>
<p>With the PCB assembled, mechanical parts purchased, and chassis pieces printed,
it was time to do the final assembly. Again, I followed the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Assembly-Instructions">assembly instructions</a>
on the project Github.</p>
<p>The assembly process was straightforward: the PCB gets screwed into one of the
printed pieces, the pulleys and linear rods get screwed in to the “feet” and
carriage block pieces, and the stepper motors are secured to the chassis with
the PCB “sandwiched” in between the chassis and the motors.</p>
<p>One difficult step was attaching the stepper motors to the PCB. Per the project
instructions, you're supposed to solder the stepper motor wires into plastic
<a href="https://en.wikipedia.org/wiki/Pin_header">pin sockets</a>, so you can easily
detach the motors from the PCB. But, after I tried and failed several times to
solder the stepper motors into the female socket block, I simply soldered the
female sockets to the board directly and soldered the stepper motor wires onto
solid-core jumper wires. The end result wasn't as clean as what's shown in the
project instructions, but still allowed me to hot-swap the motors if needed.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics_hu69d27adac9c276a7c142cb42ce695fc5_460646_0x400_resize_q75_box.jpg" alt="Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)"> </a><figcaption>
        <p>Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)</p>
    </figcaption>
    </figure>

<p>Once the main “chunk” of the plotter was assembled (pictured above), the only
things left to do were to thread the timing belt around the pulleys, and attach
both ends of the belt to the pen head with a small amount of tension.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2_hubcee09c1499dfeaed0cdedbd52521e35_510199_0x400_resize_q75_box.jpg" alt="Belt Attach Points (circled)"> </a><figcaption>
        <p>Belt Attach Points (circled)</p>
    </figcaption>
    </figure>

<p>The last step in assembly (and, unfortunately the most fiddly part of the whole
process) was attaching the pen holder to the “head” block. The long screw that
makes the joint between the pen holder and “head” block needs to be tuned
meticulously: If the screw is too tight, then the pen can get stuck in the “up”
position – not returning to the “down” position when the servo retracts. On the
other hand, if the screw is too loose, then this translates to “slop” in the
pen's position, which results in wiggly drawings that are unusable.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo_hu041824ca24038cc947b7d5fa7334f321_403811_0x400_resize_q75_box.jpg" alt="Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)"> </a><figcaption>
        <p>Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)</p>
    </figcaption>
    </figure>

<p>At this point, the bot was assembled! I powered it on and installed a specific
version of the <a href="https://github.com/bdring/Grbl_Esp32">Grbl_Esp32</a> firmware
designed for the midTbot per the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Compiling-Firmware-for-the-MidTBot">project instructions</a>.
Grbl_Esp32 is a really nifty piece of software: it allows you to upload an run
Gcode (basically, machine readable instructions for how to move the pen) on the
plotter's Esp32 controller. Since the Esp32 has built-in wifi (and bluetooth),
its able to serve a basic web UI:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui.png">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui_hu659f08144d7f460a1e53d6a3f50b9a17_60893_0x400_resize_box_2.png" alt="Grbl_Esp32 Web UI"> </a><figcaption>
        <p>Grbl_Esp32 Web UI
            <a href="https://github.com/luc-github/ESP3D-WEBUI">Source: Github</a></p>
    </figcaption>
    </figure>

<p>The Web UI is sufficient for most tasks: homing, minor positioning adjustments,
starting/pausing/resuming prints. There are only a few tasks – like calibration
– that require you to drop down to the Grbl “command line”.</p>
<p>It took me a while to get my midTbot calibrated. The project documentation was a
bit light on the specifics, so there was a lot of trial-and-error and
troubleshooting.</p>
<h2 id="plotting-software">Plotting, Software</h2>
<p>Now that I had a functioning plotter bot, the next thing to do was try it out.
Of course, to do so you need to actually produce Gcode that the bot can use.
There are tons of tools to do this – and a full discussion of Gcode/plotter
software is worth a whole other post. Suffice it to say, there are a variety of
resources on the <a href="https://drawingbots.net/knowledge/tools">Drawing Bots</a>
community page that serve as a good starting point.</p>
<p>I spent most of my time working with <a href="https://inkscape.org/">Inkscape</a>‘s
Gcodetools plugin. Axidraw (which makes a commercial pen plotter) also has some
useful
<a href="https://wiki.evilmadscientist.com/Axidraw_Software_Installation">Inkscape plugins</a>,
although some of the functionality won't work with the midTbot. Gcodetools
nominally allows you to translate SVGs to Gcode, however this is a tedious
process. <em>Not just any</em> SVG will work well with it; the SVG basically already
needs to be a line drawing for Gcodetools to have any hope of working correctly.
It has basic support for infilled regions too, but again you have to be careful
with it – any slight hiccup, and it produces unusable Gcode.</p>
<p>To be honest, the software aspect of pen plotting is the most frustrating part
of the workflow. I haven't yet found a great toolchain for the “art” -&gt; Gcode
pipeline, so there's a lot of finicky steps. (It doesn't help that Inkscape is a
second-class X11 app on macOS…)</p>
<h2 id="additional-hardware-modifications">Additional Hardware Modifications</h2>
<p>After I ordered a midTbot PCB, the creator added me to a Slack group. Some of
the other folks who'd built midTbots contributed back modifications they'd made
to their builds. I took a couple of these and added them to my bot too:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount_hu1f2dbe1c25aab483c480e60644105b8f_437548_0x400_resize_q75_box.jpg" alt="Magnetic Pen Mount with Thumb Screw"> </a><figcaption>
        <p>Magnetic Pen Mount with Thumb Screw</p>
    </figcaption>
    </figure>

<p>First, I ordered heftier thumb screws for the pen attachment (as pictured); the
screws in the original BOM are tricky to manipulate by hand. Second, I printed a
magnetic detachable pen holder (as pictured) which makes it easier to add/remove
pens without disturbing the rest of the setup. If you want to do multicolor
prints, this modification is a must. Finally, I printed wider supports for the
bots frame. Supposedly, this allows you to increase the available print size of
the bot (if you also order longer linear rods). I didn't get around to actually
increasing my bot's print size, but the wider supports made the bot more stable,
and easier to attach to a work table.</p>
<h2 id="results">Results</h2>
<p>After an afternoon of calibrating the bot and installing the mods I discussed
above, I got some prints that I'm pretty happy with.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle_hu7abfc5bba89b65ef467a92e89d404d38_647220_0x400_resize_q75_box.jpg" alt="SierpiÅ„ski triangle"> </a><figcaption>
        <p><a href="https://en.wikipedia.org/wiki/Sierpi%C5%84ski_triangle">SierpiÅ„ski triangle</a></p>
    </figcaption>
    </figure>

<p>Sierpinski's triangle (above) is a single line, but has a lot of intricate
detail. This is a good exercise of the precision of the stepper motors, which as
you can see is quite good. The precision also requires the pen mount to be
calibrated correctly, so that there isn't any “slop” between the pen and the
body of the plotter.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube_hu4580d2579ea2776d604d9e44b4623042_575462_0x400_resize_q75_box.jpg" alt="Isometric Cube"> </a><figcaption>
        <p>Isometric Cube
            <a href="https://github.com/wblut/isogrid">Source: Github</a></p>
    </figcaption>
    </figure>

<p>This was a slightly harder pattern for the bot to draw. The lines are all
straight, but there are a fair number of pen raises. Generally, the more pen
up/down cycles a print has, the greater the likelihood of failure.</p>
<p>I've also noticed that <em>where</em> the pattern is in the print area of the bot makes
a difference. The closer the pen head is to the main bot chassis, the more the
pen is pulled away from the paper due to the counterweight of the “tail”
section. As such, I tried to position the prints as close to the middle of the
print area as possible. Below is what happens when the pen holder misbehaves:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader_hu1a98c8f9a4b8a7a0c3eafda2f5f8180d_194935_0x400_resize_q75_box.jpg" alt="Somewhat failed &amp;lsquo;Space Invaders&amp;rsquo; Print (Note the discontinous/missing lines)"> </a><figcaption>
        <p>Somewhat failed ‘Space Invaders’ Print (Note the discontinous/missing lines)
            <a href="https://github.com/abey79/vpype">Source: vpype Example Code</a></p>
    </figcaption>
    </figure>

<p>The plot isn't a complete failure, but many of the lines don't get drawn or only
get partially drawn. This is often caused by the pen mount screw being too
tight, causing the pen …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</a></em></p>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820926</guid>
            <pubDate>Mon, 13 Jul 2020 14:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Grok with Elasticsearch to add structure to your data]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820793">thread link</a>) | @alexmarquardt
<br/>
July 13, 2020 | https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/ | <a href="https://web.archive.org/web/*/https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div id="primary">
	<main id="main" role="main">
		
<article id="post-1351" class="page">
	<!-- .entry-header -->

	
	<div>
		<p>July 13, 2020</p><p>As well as being a search engine, Elasticsearch is also a <a href="https://www.elastic.co/blog/intro-to-aggregations">powerful analytics engine</a>. However in order to take full advantage of the near-real-time analytics capabilities of Elasticsearch, it is often useful to add structure to your data <em>as it is ingested</em> into Elasticsearch. The reasons for this are explained very well in the <a href="https://www.elastic.co/blog/schema-on-write-vs-schema-on-read">schema on write vs. schema on read</a> article, and for the remainder of this blog, when I talk about structuring data, I am referring to <em>schema on write</em>.</p>

<p>Because of the importance of structuring your data, in this blog I will show you how to add structure to unstructured documents by using an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/ingest.html">ingest node</a> with the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok Processor</a>. Then, I will describe a simple method to construct new Grok patterns, and a method that can be used to debug errors in existing Grok patterns. Finally I will provide links to some publicly available Grok patterns and then briefly mention the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/dissect-processor.html">Dissect Processor</a> as a possible alternative to Grok.</p>

<p>As a side note, if you are going to put in the effort to structure your data, you should consider structuring your data so that it conforms to the <a href="https://www.elastic.co/blog/introducing-the-elastic-common-schema">Elastic Common Schema</a>, which will facilitate the analysis of data from diverse sources.</p>



<p>It is not uncommon to see documents sent to Elasticsearch that are similar to the following.:</p>

<pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre>

<p>The message field in the above document contains unstructured data. It is a series of words and numbers that are not suitable for near-real-time analytics. In order to take full advantage of the powerful analytics capabilities of Elasticsearch, we should parse the message field to extract relevant data. For example, we could extract the following fields from the above message:</p>

<pre>"host.ip": "55.3.244.1"&nbsp;<br>"http.request.method": "GET"<br>"url.original": "/index.html"<br>"http.request.bytes": 15824<br>"event.duration": 0.043</pre>

<p>Adding such a structure will allow you to unleash the full power of Elasticsearch on your data.</p>



<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok</a> is a tool that can be used to extract structured data out of a given text field within a document. You define a field to extract data from, as well as the Grok pattern for the match. Grok sits on top of <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a>. However, unlike regular expressions, Grok patterns are made up of <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">reusable patterns</a>, which can themselves be composed of other Grok patterns.&nbsp;</p>

<p>Before going into details of how to build and debug your own Grok patterns, we first give a quick overview of what a Grok pattern looks like, how it can be used in an ingest pipeline, and how it can be simulated. Don’t worry if you don’t fully understand the details of the Grok expression yet, as these details will be discussed in-depth in the following sections of this blog.</p>

<p>In the previous section we presented an example document that looks as follows:</p><pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p><br>The desired structure can extracted from this example message field by using the following Grok expression:</p>

<pre>%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}</pre>

<p>And we define a pipeline which contains this Grok pattern inside a Grok processor.</p>

<pre>PUT _ingest/pipeline/example_grok_pipeline<br>{<br>  "description": "A simple example of using Grok",<br>  "processors": [<br>    {<br>      "grok": {<br>        "field": "message",<br>        "patterns": [<br>          "%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}"<br>        ]<br>      }<br>    }<br>  ]<br>}</pre>

<p>We can then <a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/simulate-pipeline-api.html">simulate the above pipeline</a> with the following command.</p>

<pre>POST _ingest/pipeline/example_grok_pipeline/_simulate<br>{<br>  "docs": [<br>    {<br>      "_source": {<br>        "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>      }<br>    }<br>  ]<br>}</pre>

<p>Which responds with a structured document that looks as follows:&nbsp;</p>

<pre>{<br>  "docs" : [<br>    {<br>      "doc" : {<br>        "_index" : "_index",<br>        "_type" : "_doc",<br>        "_id" : "_id",<br>        "_source" : {<br>          "host" : {<br>            "ip" : "55.3.244.1"<br>          },<br>          "http" : {<br>            "request" : {<br>              "method" : "GET",<br>              "bytes" : 15824<br>            }<br>          },<br>          "message" : "55.3.244.1 GET /index.html 15824 0.043 other stuff",<br>          "event" : {<br>            "duration" : 0.043<br>          },<br>          "url" : {<br>            "original" : "/index.html"<br>          }<br>        },<br>        "_ingest" : {<br>          "timestamp" : "2020-06-24T22:41:47.153985Z"<br>        }<br>      }<br>    }<br>  ]<br>}</pre><p><br>This document contains the original unstructured&nbsp; message field, and it also contains all of the additional fields which have been extracted from the message. We now have a document that contains structured data!</p>



<p>In the above example we <em>simulated</em> execution of an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/pipeline.html">ingest pipeline</a> that contains our Grok pattern, but didn’t actually run it on any real documents. An ingest pipeline is designed to process documents at ingest time, as described in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/ingest.html">ingest node documentation</a>. One way to execute an ingest pipeline is by adding the pipeline name to the <em>PUT</em> command as follows:&nbsp;</p>

<pre>PUT example_index/_doc/1?pipeline=example_grok_pipeline<br>{<br>&nbsp;&nbsp;"message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p>And the document that has been written can be seen by executing:</p><pre>GET example_index/_doc/1</pre><p>Which will respond with the following:</p><pre>{<br>  "_index" : "example_index",<br>  "_type" : "_doc",<br>  "_id" : "1",<br>  "_version" : 2,<br>  "_seq_no" : 2,<br>  "_primary_term" : 1,<br>  "found" : true,<br>  "_source" : {<br>    "host" : {<br>      "ip" : "55.3.244.1"<br>    },<br>    "http" : {<br>      "request" : {<br>        "method" : "GET",<br>        "bytes" : 15824<br>      }<br>    },<br>    "message" : "55.3.244.1 GET /index.html 15824 0.043 other stuff",<br>    "event" : {<br>      "duration" : 0.043<br>    },<br>    "url" : {<br>      "original" : "/index.html"<br>    }<br>  }<br>}</pre><p>Alternatively (and likely preferably), the ingest pipeline can be applied by default to all documents that are written to a given index by adding it to the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/index-modules.html#dynamic-index-settings">index settings</a>:</p>

<pre>PUT example_index/_settings<br>{<br>&nbsp;&nbsp;"index.default_pipeline": "example_grok_pipeline"<br>}</pre>



<p>After adding the pipeline to the settings, any documents that are written to <em>example_index</em> will automatically have the <em>example_grok_pipeline</em> applied to them.&nbsp;</p>

<p>This can be verified by writing a new document to <em>example_index</em> as follows:</p>

<pre>PUT example_index/_doc/2<br>{<br>&nbsp;&nbsp;"message": "66.3.244.1 GET /index.html 500 0.120 new other stuff"<br>} </pre>

<p>And the document that has been written can be seen by executing:</p>

<pre>GET example_index/_doc/2</pre>

<p>Which, as expected will return the document that we just wrote. This document has the new fields that were extracted from the message field:</p>

<pre>{<br>  "_index" : "example_index",<br>  "_type" : "_doc",<br>  "_id" : "2",<br>  "_version" : 3,<br>  "_seq_no" : 2,<br>  "_primary_term" : 1,<br>  "found" : true,<br>  "_source" : {<br>    "host" : {<br>      "ip" : "66.3.244.1"<br>    },<br>    "http" : {<br>      "request" : {<br>        "method" : "GET",<br>        "bytes" : 500<br>      }<br>    },<br>    "message" : "66.3.244.1 GET /index.html 500 0.120 new other stuff",<br>    "event" : {<br>      "duration" : 0.12<br>    },<br>    "url" : {<br>      "original" : "/index.html"<br>    }<br>  }<br>}</pre>



<p>In the previous section, we presented an example document with the following structure:</p><pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p>And we then used the following Grok pattern to extract structured data from the message field:</p>

<pre>"%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}"</pre>

<p>As described in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok Processor documentation</a>, the syntax for Grok patterns comes in three forms: <em>%{SYNTAX:SEMANTIC}, %{SYNTAX}, %{SYNTAX:SEMANTIC:TYPE}</em>, all of which we can see in the above Grok pattern.&nbsp;</p><ul><li>The <em>SYNTAX</em> is the name of the pattern that will match your text. Built-in <em>SYNTAX</em> patterns <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">can be seen on github</a>.</li><li>The <em>SEMANTIC</em> is the name of the field that will store the data that matches the <em>SYNTAX</em> pattern.</li><li>The <em>TYPE</em> is the data type you wish to cast your named field.</li></ul>

<p>The first part of the Grok pattern is the following:</p>

<pre>%{IP:host.ip}</pre>

<p>This declaration matches an IP address (corresponding to the <em>IP</em> Grok pattern) and stores it in a field called <em>host.ip</em>. Four our example data, this will extract a value of <em>55.3.244.1</em> and store it in the <em>host.ip</em> field.</p>

<p>If we want more details on the <em>IP</em> Grok pattern, we can look into the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a>, and we will see the following definition:&nbsp;</p>

<pre>IP (?:%{IPV6}|%{IPV4})</pre>

<p>This means that the <em>IP</em> pattern will match one of the <em>IPV6</em> or <em>IPV4</em> Grok patterns. To understand what the <em>IPV6</em> and <em>IPV4</em> patterns are, once again we can look into the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a> to see their definitions, and so on.&nbsp;</p>

<p>The next part of the Grok pattern is a single whitespace character followed by the following expression:</p>

<pre>%{WORD:http.request.method}</pre>

<p>This portion of the Grok expression extracts the word <em>GET</em> from the <em>message</em>&nbsp;and stores it into the <em>http.request.method</em> field. If we want to understand the definition of the <em>WORD</em> pattern, we can look at the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a>.&nbsp;</p>

<p>One can do the same kind of analysis to understand the patterns that match the <em>url.original</em>, <em>request.bytes</em> and <em>event.duration</em> fields, which we leave as an exercise for the reader</p>

<p>Finally, the last statement in the Grok pattern is the following:</p>

<pre>%{GREEDYDATA}</pre>

<p>This expression does not have a <em>SEMANTIC</em> part, which means that the matching data is not stored into any field.&nbsp; Additionally, the <em>GREEDYDATA</em> Grok pattern will consume as much text as it can, which means that in our example it will match everything after the <em>event.duration</em> field. The <em>GREEDYDATA</em> expression will come in handy when debugging complex Grok patterns, as discussed in the following sections of this blog.&nbsp;&nbsp;</p>



<p>When constructing a new Grok pattern, it is often easiest to construct the Grok pattern incrementally starting from the left and working towards the right side of the unstructured text that we are trying to match.&nbsp;</p>

<p>Two tools that can be helpful for building and …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/">https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/</a></em></p>]]>
            </description>
            <link>https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820793</guid>
            <pubDate>Mon, 13 Jul 2020 13:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reaching 1K Subscribers in Two Weeks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820773">thread link</a>) | @marz0
<br/>
July 13, 2020 | https://www.radletters.com/blog/how-blogging-for-devs-reached-1k-subscribers-in-under-2-weeks | <a href="https://web.archive.org/web/*/https://www.radletters.com/blog/how-blogging-for-devs-reached-1k-subscribers-in-under-2-weeks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2><strong>Hi there! Who are you and whatâ€™s your background?</strong></h2>

<p>Hey! My nameâ€™s Monica and I run <a href="https://bloggingfordevs.com/">Blogging for Devs</a>. </p>

<p>As for my background, I learned to code at a super young age (weâ€™re talking single-digits here). I was building websites on my own domain in the late 90s, uploading files with CoffeeCup FTP and coding in Notepad on a Windows 98 machine. Simpler times, eh?</p>

<p>Despite growing up glued to the computer, working in tech was an afterthought for me.</p>

<p>One of the things that surprises people most is that I actually studied Latin and Ancient Greek in University. I also studied French and Japanese. But by the end of my four years, I got burnt out from studying languages and being in school in general.</p>

<p>So converting my student job as a web developer into a full-time role was somehow the path of least resistance. </p>

<p>After 10 years in tech and a cross-continent move from the United States to Germany, I quit my role as the frontend engineering lead at a startup in Berlin to build my own company. For a long time, my goal was â€œnot to have a boss by the time I turn 30â€� and somehow, I managed :)</p>

<p>Today, the company is my main focus. Itâ€™s a conversion-rate optimization tool for affiliate marketers, called <a href="https://affilimate.com/">Affilimate</a>. Apart from that Iâ€™ve got numerous side projects, including my newsletter.</p>

<h2><strong>Whatâ€™s your newsletter about?</strong></h2>

<p>Blogging for Devs teaches developers how to grow their blogs through writing and SEO.</p>

<p>It begins as a free 7-day email challenge to help developers go from concept to keyword research, writing, and distributing an excellent blog post. After completing the challenge, the reader is subscribed to the newsletter.</p>

<p>Every week the newsletter starts with some of my own writing. Sometimes itâ€™s educational, sometimes itâ€™s motivational, but itâ€™s always geared towards trying to help people ACT and take that next step towards creating a successful blog.</p>

<p><img src="https://www.radletters.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBcFFDIiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--0bde7b8ae0a51feba66439fe45c3fb1507276381/blogging-for-devs-homepage.png" alt="blogging-for-devs"></p>

<p>In addition, I share and create a variety of resources around blogging in different formats. For example, Iâ€™ve done a screencast on keyword research, an interview with a well-known tech blogger, and written blog posts about launching a newsletter and SEO for Gatsby websites. I also include links to great content created by my subscribers whenever possible.</p>

<p>Itâ€™s a pretty new newsletter so Iâ€™m still experimenting and learning more about what people find most interesting and helpful.</p>

<p>Besides just wanting to help people, I also started the newsletter as a sort of way to get exposure: both that Iâ€™m building Affilimate and establish myself as someone who knows about blogging and SEO. This has worked really well.</p>

<h2><strong>When did you get started writing your newsletter? What motivated you to get started?</strong></h2>

<p>Iâ€™d learned a ton about blogging from building a profitable travel blog over the last few years.</p>

<p>When a number of friends in tech asked me for advice about how to grow their own blogs, it was super fun for me to teach them all the techniques Iâ€™d learned: ranking content in Google, collecting email subscribers, and writing articles people love engaging with.</p>

<p>So it kind of dawned on me that developers as a whole could find the topic interesting, too.</p>

<p>Iâ€™m generally not a competitive person (I prefer to compete with myself), but the desire to get my articles on the first page of Google really drives me to create something 100x better than whatâ€™s out there.</p>

<p>My hypothesis was that developers could actually <em>grow</em> to love blogging and SEO like I did, if only it was explained in a way that appealed to them as developers instead of the typical marketing angle.</p>

<p>It seems my hypothesis was right. After an initial launch at the end of May, over â…” of people who shared feedback on the 7-day challenge mentioned how much they liked the lessons about SEO and keyword research (and that it was way more interesting than they expected!).</p>

<h2><strong>What does the process of writing your newsletter look like for you?</strong></h2>

<p>I keep a backlog of ideas in Asana. Every week I decide on an angle or a theme, and I collect links to interesting news related to blogging in that issue.</p>

<p>For example, last weekâ€™s edition was about â€œHow to Market Yourself (When You Hate Marketing)â€�. I opened with a bit of writing about how developers may hate marketing, but how important it is for their career to become visible and create things in public. Then I also include original resources by myself and others about how to do that.</p>

<p>In total, it takes me about 2-3 hours to write the newsletter and compose it.</p>

<p>I typically write it at a fixed time on Thursday, and then I sleep on it and edit it on Friday before sending it out.</p>

<h2><strong>What are some of the difficulties youâ€™ve encountered in running your newsletter?</strong></h2>

<p>My only real difficulty was when I launched my newsletter, it picked up so many subscribers (I know, an absurd thing to complain about), and my welcome email solicited so many responses, that I was receiving dozens if not over 100 emails per day.</p>

<p>But since everyone wrote me such long, personal emails, I couldnâ€™t feel good about sending canned responses to people.</p>

<p>So I spent <em>hours</em> writing individual responses to everyone who emailed me (as well as replies to replies). It took me several hours a day for about a week to get through them and regain control over my inbox.</p>

<p>Of course, this is a good problem to have. Iâ€™m really grateful that people felt they could share their personal motivations and struggles with me, because it helps me create something that will serve them better.</p>

<h2><strong>Whatâ€™s your favorite part about writing your newsletter?</strong></h2>

<p>Hands down, my favorite part is being able to give advice and see people <em>actually execute it</em>.</p>

<p>Anyone can consume books, blog posts, watch YouTube videos, or whatever.</p>

<p>But what stands out is when I see someone consistently acting on my advice and then showing me the results of doing that.</p>

<p>It motivates me to go further and see how I can help them even more.</p>

<p>Those are the people Iâ€™m writing my newsletter for, because I know that the combination of my experience and their drive will deliver results.</p>

<h2><strong>How do you grow your audience?</strong></h2>

<p>Blogging for Devs recently surpassed 1,500 subscribers after launching it about a month and a half ago.</p>

<p>I did <a href="https://bloggingfordevs.com/launch-a-newsletter/">an analysis</a> of where my subscribers came from, and found that the primary source was Twitter (about 75%) followed by word of mouth.</p>

<p><img src="https://www.radletters.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBcE1DIiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--bd1b72d5fbdc53f3cee30e1e265858b5d1c2ea10/subscriber-chart.png" alt="subscriber-analysis"></p>

<p>Anecdotally, a lot of people write to me and say the newsletter was personally recommended to them, which is a great feeling.</p>

<p>I havenâ€™t done any additional marketing after the initial launch, but my plan is to both promote articles I write on the newsletterâ€™s blog via Twitter and ultimately (of course) to rank some of the articles in Google.</p>

<h2><strong>What are some of your favorite newsletters, books, and podcasts?</strong></h2>

<p>I donâ€™t subscribe to many newsletters (ironic, I suppose?), but one I always enjoy getting in my inbox is <a href="https://marketingexamples.com/">Marketing Examples</a> by Harry Dry. I love how crisp and concise his delivery is. He inspires me to delete unnecessary fluff from everything I write.</p>

<p>As for books, I read mostly product and marketing-focused books these days. My recent favorite is <a href="https://www.amazon.com/dp/B07PPW5V9C">Obviously Awesome</a> (a book about product positioning), and Iâ€™m currently reading <a href="https://www.amazon.com/dp/B00CS5FR62">Predatory Thinking</a> (a series of short stories about out-thinking your competition written by a famous ad exec).</p>

<p>Lately, Iâ€™ve been listening to a lot of <a href="https://www.startupsfortherestofus.com/">Startups for the Rest of Us</a> by Rob Walling. He talks a lot about the reality of building bootstrapped companies, which is highly relevant for me as a founder myself. There are also over 500 episodes so you can really binge on it if thatâ€™s your thing.</p>

<p>For people who write newsletters, I definitely recommend Kate Dosterâ€™s <a href="https://www.katedoster.com/inbox-besties/">Inbox Besties</a>. Her podcast is easily the funniest one I listen to and the episodes are bite-sized.</p>

<h2><strong>What goals do you have for the future?</strong></h2>

<p>My goal is to grow Blogging for Devs to 5,000 subscribers this year. Iâ€™m not sure if thatâ€™s a lot or a little, but itâ€™s my plan! Ultimately, I want to create a community of developers who can help and support each other in their blogging journeys. Iâ€™m just figuring out the right way to go about that right now.</p>

<p>As for me personally, my goal is to build my company to the point where itâ€™s worth acquiring. Still a long way to go before that point :) Iâ€™ve got a lot of other projects and goals for them, but those are secondary to my main focus.</p>

<h2><strong>Where can readers go to learn more about you and your newsletter?</strong></h2>

<p>My newsletterâ€™s website is simply <a href="https://bloggingfordevs.com/">https://bloggingfordevs.com</a>. If people are interested in following along the journey of building the newsletter and my other projects, they can find me on Twitter at <a href="https://twitter.com/monicalent">@monicalent</a>.</p>

    </div></div>]]>
            </description>
            <link>https://www.radletters.com/blog/how-blogging-for-devs-reached-1k-subscribers-in-under-2-weeks</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820773</guid>
            <pubDate>Mon, 13 Jul 2020 13:54:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Danes to sort trash into ten types under new green deal]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820760">thread link</a>) | @jmartinpetersen
<br/>
July 13, 2020 | https://www.thelocal.dk/20200617/danes-to-sort-trash-into-ten-types-under-new-green-deal | <a href="https://web.archive.org/web/*/https://www.thelocal.dk/20200617/danes-to-sort-trash-into-ten-types-under-new-green-deal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://storage.googleapis.com/ddos-shield.appspot.com/shield-logo-mono-darktext.svg" width="250px" height="50px" alt="Project Shield Logo"></p><p>You will be connected to <b>www.thelocal.dk</b> in just a moment...</p><p><a href="https://g.co/shield">Learn about Project Shield</a></p></div></div>]]>
            </description>
            <link>https://www.thelocal.dk/20200617/danes-to-sort-trash-into-ten-types-under-new-green-deal</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820760</guid>
            <pubDate>Mon, 13 Jul 2020 13:54:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple devices are leaking sensitive data over BLE]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23820589">thread link</a>) | @dchest
<br/>
July 13, 2020 | https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/ | <a href="https://web.archive.org/web/*/https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
										
						<p>By <a href="http://perso.citi-lab.fr/gcelosia/">Guillaume Celosia</a> and <a href="https://perso.citi-lab.fr/mcunche/index.html">Mathieu Cunche</a></p>
<h4><a href="https://petsymposium.org/2020/files/papers/issue1/popets-2020-0003.pdf"><strong>Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols</strong></a></h4>

<p>We found that Apple devices are leaking sensitive information in the BLE wireless signals they emit. Those issues are associated with the Apple Continuity services and are affecting all Apple devices as well as devices compatible with the Continuity framework. Based on a reverse engineering of Continuity, we identified that the Bluetooth Low Energy (BLE) messages emitted by Apple devices include unencrypted data that can expose sensitive information. We discovered that those data can be easily collected by an eavesdropper and processed in order to: track users, monitor activities in a smarthome, obtain phone number, email addresses and Apple Voice Assistant, Siri, commands, and more.</p>
<p><img src="https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy.png" alt="" width="822" height="385" srcset="https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy.png 822w, https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy-300x141.png 300w, https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy-768x360.png 768w" sizes="(max-width: 822px) 100vw, 822px"></p>

<h2>BLE advertising</h2>
<p>In BLE, devices broadcast short messages, called Advertising Packets, to announce their presence and feature to nearby devices (those messages can be observed from an Android device using an application like <a href="https://play.google.com/store/apps/details?id=com.contextis.android.BLEScanner&amp;hl=en">Ramble</a>). Advertising Packets can include the name of the device, its type, but can also include custom data in a field called Manufacturer specific. This field is typically used by vendors to transmit data for application. Apple make use of this field to include data for its Continuity Protocols.</p>
<h2>Apple Continuity Protocols</h2>
<p>Apple has developed a number of features, called <a href="https://support.apple.com/en-us/HT204681"><i>Continuity</i></a>, that are designed to increase the usability of its products. Those features include: activity transfert, file transfert (airDrop), Wi-Fi password sharing, etc. The communication between nearby devices, required by Continuity services, is done by using BLE. Continuity data are embedded in BLE advertising packets and are broadcast to be picked up by nearby devices.</p>

<h2>Data exposed in cleartext</h2>
<p>We found that, even though some elements are encrypted, most of the data included in Continuity messages is sent in plain text. The exposed data can thus be passively collected by an eavesdropper and exploited to mount one of the attack presented below.</p>
<h2>Tracking users (iPhones, iPad, airpods …)</h2>
<p>We found that the content of <i>Apple Continuity </i>BLE messages can be used to track the device despite the use address randomization. We have identified several elements that remain constant over time or that can undermine the anti-tracking feature mechanism (i.e. address randomization). For instance, we found that messages emitted by earpods include information (battery levels and lid open counter) that can be exploited to track the earpod set. We also discovered a novel attack that would allow tracking by actively replaying BLE messages. An passive attacker could exploit this information to track the the location of individuals in spite of address randomization, the anti-tracking feature of BLE.</p>
<h2>Linking device belonging to the same iCloud account</h2>
<p>We discovered that it is possible to link together devices associated to the same iCloud account. This attack relies on the replay of messages that will trigger a response only from devices associated to the same <i>iCloud</i> account. An attacker could exploit this to identify all the device belonging to a person, and could narrow down its home if some device are left there.</p>
<h2>Monitoring activities in a smart home (Homekit)</h2>
<p>We found that messages emitted by <i>Homekit</i>-compatible devices can betray the activity in a smart-home. <a href="https://developer.apple.com/homekit/"><i>Homekit</i></a> is a smart-home framework developed by <i>Apple</i> and found in <a href="https://www.apple.com/fr/shop/accessories/all-accessories/homekit">devices</a> of <i>Apple</i> and other vendors (…). <i>Homekit</i> devices using BLE continuously emit messages that include an indicator reflecting the device state. For instance, in the case of a lightbulb, this indicator changes only when it is either turned on or turned off. Similarly, in an infrared movement detector, the indicator changes only when a person crosses the detection field. In-lab experiments showed that a passive attacker can leverage Homekit BLE messages to track the evolution of devices in a household and thus monitor the activities of the occupants.</p>
<h2>Device model, software version and more</h2>
<p>We found that a number of messages expose a wide variety of information on the emitting device characteristics and state: device model, OS version, device color, cellular connectivity, battery level, current activity etc.</p>
<h2>E-mail address and Phone numbers (Airdrop &amp; Nearby)</h2>
<p>We found that when using features such as Airdop and Nearby, devices emit messages from which email addresses and phone numbers can be extracted. Continuity services allow to seamlessly share resources with nearby devices: Airdrop to share files, Nearby to share Wi-Fi network credential. Prior exchange of information, the devices establish their identity by exchange identifiers over BLE: email addresses and/or phone numbers. Those identifiers are not sent in clear but are rather hashed using a cryptographic hash-function. This obfuscation can be bypassed in most cases and the identifiers recovered.</p>
<h2>Voice assistant commands (Siri)</h2>
<p>We found that when activated via voice, the Siri voice assistant will generate a message including a digital fingerprint of the command. Although the raw audio signal cannot be reconstructed from it, the fingerprint could be leveraged to infer the command.</p>

<p>The vulnerabilities identified were reported to Apple, Osram and Eve on May 29 th , 2019.</p>

<p>This work was supported by the <a href="http://www.citi-lab.fr/chairs/iot-chair/">INSA Lyon – SPIE ICS IoT chair</a> and the H2020 <a href="https://www.sparta.eu/">SPARTA</a> Cybersecurity Competence Network project.</p>
<p><img src="https://team.inria.fr/privatics/files/2019/10/logo-chaire-e1570022002577.jpg" alt="" width="200" height="66"><img src="https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-150x150.jpg" alt="" width="150" height="150" srcset="https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-150x150.jpg 150w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-300x300.jpg 300w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-144x144.jpg 144w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg.jpg 400w" sizes="(max-width: 150px) 100vw, 150px"></p>

<p>The corresponding research paper, <a href="https://petsymposium.org/2020/files/papers/issue1/popets-2020-0003.pdf"><u>Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols</u></a>, will be presented at the <a href="https://petsymposium.org/2020/index.php">20th Privacy Enhancing Technologies Symposium (PETS 2020)</a> on 14-18 July 2020 in Montreal, Canada.</p>
<h3><a name="citeme"></a>APA style citation and bibtex entry</h3>
<p>You can use the following APA style citation or bibtex entry to reference our paper:</p>
<pre>Celosia, G., &amp; Cunche, M. (2020).Discontinued Privacy: Personal Data Leaks
in Apple Bluetooth-Low-Energy Continuity Protocols. <i>Proceedings on Privacy
Enhancing Technologies, 2020</i>(1), 26-46. De Gruyter Open.
@article{celosia2020close,
    title={Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols},
    author={Celosia, Guillaume and Cunche, Mathieu},
    journal={Proceedings on Privacy Enhancing Technologies},
    volume={2020},
    number={1},
    pages={26--46},
    year={2020},
    publisher={De Gruyter Open}
}</pre>
<p><a href="http://creativecommons.org/licenses/by/4.0/">Creative Com</a></p>
								</div></div>]]>
            </description>
            <link>https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820589</guid>
            <pubDate>Mon, 13 Jul 2020 13:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to pick the best health insurance plan?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820565">thread link</a>) | @doglov
<br/>
July 13, 2020 | https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance | <a href="https://web.archive.org/web/*/https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>1. Type of coverage. </strong>There are many different ways you can obtain coverage. They can be grouped into four main categories:</p><ul role="list"><li>Through a <em>job</em>: private insurance (Blue Cross Blue Shield, Aetna, etc.)</li><li>Through the <em>government</em>: Medicare, Medicaid</li><li>Through the <em>individual exchange: </em>"ObamaCare" plan</li><li>Through <em>lower-cost supplemental and short-term plans: healthcare (Mira).</em></li></ul><p><strong><em>2. </em>Eligibility:</strong> all health insurance plans have eligibility criteria. They depend on your income, age, employment, and where you live.</p><p><strong>3.</strong> <strong>Monthly cost:</strong> The monthly premium for each plan can range from no-cost (Medicaid) to a few thousand dollars for a family Gold plan (individual exchange). Premiums must be paid monthly, regardless if you use the insurance or not.</p><p><strong>4. Type of plans:</strong> plans can have different tiers of pricing and/or how broad or narrow the network is. This may also correlate with how high the monthly premium is. For example, a broader network may cost more. </p><p><strong>5. Enrollment period: </strong>this is when you can enroll in a health insurance plan. Some plans have a specific time frame for when you can enroll and for other plans, you can enroll anytime of the year as long as you're eligible. </p></div><div><p>Picking the best suited plan for you comes down to three things: </p><p><strong>1) What are you eligible for? </strong>Try to determine what options you are eligible for. Sometimes, you are qualified for more options than you think.</p><p><strong>2) What are your healthcare needs?</strong> If you are relatively healthy, getting the top-tier plan may not make sense if you have to bear the cost. Meanwhile, if you have a chronic condition and need expensive treatments, getting a catastrophic plan may not be the best option for you. Most preventative care services like wellness visits and flu shots are covered at no out of pocket costs.</p><p><strong>3) What can you afford?</strong> Of course everyone wants to get the lowest-cost and most comprehensive plan, but healthcare is expensive. Look at your financial situation as a whole and see which options make the most sense from a financial perspective. </p><h3>Is there a penalty to go without insurance?</h3><p>Effective 2019 tax year, the individual mandate was repealed at the federal level. This means you will not be fined for not having or cannot afford health insurance. </p><p>Some states like Massachusetts, New Jersey, California, Rhode Island, or the District of Columbia reinstated this at the state tax level. The penalty itself is not an actual cash fine but a reduction of your annual tax refund (at the state level). In California, the tax refund reduction is $62/month. <strong>There is no individual mandate/fine in New York State.</strong>‍</p><h3>Is there an alternative if I can't afford any plans?<br></h3><p>Last but not least, if you can’t afford any plan, understand that being uninsured is not a shame but a financial decision. Depending on your monthly budget, getting a plan that is more expensive than rent and groceries bills may not be sustainable. </p><p>If you just go to the doctor <strong><em>once or twice a year,</em></strong> <a href="https://www.talktomira.com/">Mira </a>may make a good option. Mira helps you get affordable doctor visits, lab tests, and prescription drugs without insurance, for $25-45/mo. Below you will find a guide that explains the basics of several types of health insurance and health care plans. <a href="https://www.talktomira.com/">Learn more. </a><br></p><p>‍</p><p><strong>Who is eligible:</strong> Typically employees of companies with 50+ people will be eligible for private insurance. If you get laid off from a company, you will be eligible for COBRA, but you will be responsible to pay 100% of the monthly premiums. </p><p><strong>Monthly Cost/Cost-sharing: </strong></p><ul role="list"><li>In 2019, <em>annual premiums </em>were $7,188 for single coverage and $20,576 for family coverage.</li><li>Employers often pay for 80% of the cost, leaving the average monthly contribution for an employee at $100-$200 for an individual health plan.</li></ul><p><strong>Type of plans:</strong> Health Maintenance Organization (HMO), Prefered Provider Organization (PPO), Point of Service (POS), High Deductible Health Plan (HDPL)</p><p><strong>Enrollment period: </strong></p><ul role="list"><li>You are eligible to enroll when you start your job.</li><li>Every year, there is an annual renewal. This period depends on your employer and usually lasts about 60 days. </li></ul><p><strong>Notable companies</strong>: Cigna, Aetna, UnitedHeealth, Anthem &amp; Blue Cross Blue Shield, Humana</p><p>‍</p><p><strong>Who is eligible:</strong> Low income individuals (typically &lt;$20K annually), families, children, pregnant women, the elderly and people with disabilities.</p><p><strong>Monthly Cost/Cost-sharing:</strong> The cost depends largely on the state, as each state has the option of setting premiums. Medicaid is often the lowest to no-cost option for health insurance. </p><p>Individuals on Medicaid that earn a higher wage, meaning those with incomes at or above 150% of the poverty level, may pay more for the following health services:</p><ul role="list"><li>For prescriptions, it’s possible that states will charge coinsurance for up to 20% of each drug’s cost in order to encourage the use of lower-cost drugs.</li><li>Additionally, if individuals in this group use the emergency room in a non-emergency situation, they may potentially be charged up to full price for care. In this case, it is up to the hospital’s physicians to determine whether the visit was an emergency.</li></ul><p><strong>Type of plans: </strong>Public Medicaid and Managed Medicaid.</p><p><strong>Enrollment period: </strong>Anytime of the year as long as the individual or family is eligible. </p><p>‍</p><p><strong>Who is eligible:</strong> Citizens and residents aged 65+ as well as those with disabilities and people with End Stage Renal Disease.</p><p><strong>Monthly Cost/Cost-sharing:</strong> <a href="https://www.talktomira.com/post/how-much-will-medicare-for-all-cost-you">There are three types of Medicare coverage:</a> </p><ul role="list"><li>Part A (for hospital) is free if you paid more than 7.5 years of taxes.</li><li>Part B (for doctor visits) costs on average $144 a month.</li><li>Part D (drugs) costs on average $34 a month.</li></ul><p><strong>Type of plans:</strong> Public Medicare, and Medicare Advantage.</p><p><strong>Enrollment period: </strong>When an individual is first eligible for Medicare, they will have a 7-month Initial Enrollment Period to sign up for Part A and/or Part B. If they’re eligible for Medicare when they turn 65, they are able to sign up during the 7-month period that:</p><ul role="list"><li>Begins 3 months before the month they turn 65.</li><li>Includes the month they turn 65.</li><li>Ends 3 months after the month they turn 65.</li></ul><p>‍</p><p><strong>Who is eligible:</strong> Under the Affordable Care Act, Individuals who live in the United States and are U.S. citizens. Although anyone can enroll, the federal subsidy is available for those who make less than ~$48,000. </p><p><strong>Monthly Cost/Cost-sharing:</strong> According to AARP, the average health insurance cost for single coverage premiums in 2020 is $388 per month.</p><p><strong>Type of plans:</strong> Bronze, Silver, Gold, Platinum.</p><p><strong>Enrollment period: </strong>The Open Enrollment period for 2021 is November 1, 2020- January 21, 2021. If you don’t enroll during the Open Enrollment period, you must wait for the next Open Enrollment period. There are also special enrollment period if you recently moved or lost a job. </p><p><strong>Notable companies:</strong> OscarHealth, Fidelis, Oxford Health Plan, Blue Cross Blue Shield</p><p>‍</p><p>‍<strong>Who is eligible: </strong>Supplemental plans are additional plans that fill coverage gaps from your other health insurance plan. Anyone is eligible for a supplemental plan; however, there are different types of supplemental plans for varying needs. There are several supplemental plans for individuals with medicare, such as Medigap plans and Medicare part D, and several plans for senior-specific needs. <br></p><p><strong>Monthly Cost/Cost-sharing: </strong>Cost varies depending on the type of supplemental plan you are getting and what this plan covers. According to research from eHealth Medicare, in 2019 the average medicare supplemental plan premium was approximately $152. <br></p><p><strong>Type of plans:</strong> There are many types of supplemental plans depending on your needs as a patient. Some of these options include a membership with Mira, critical illness insurance, disability insurance, dental insurance and life insurance. </p><p>‍<strong>Enrollment period: </strong>You can add a supplemental health insurance plan at any time and do not need to wait for the open enrollment period. They can be purchased from a private marketplace or an insurance company.</p><p>‍</p><p><strong>Who is eligible:</strong> Health share programs or ministries are groups of people who opt to share each other’s monthly medical expenses. These groups are usually created based on religious organizations; however, there are now medical cost sharing plans that do not require any religious affiliation. <br></p><p><strong>Monthly Cost/Cost-sharing: </strong>The appeal of health shares is that they may cost families less each month. According to <a href="https://www.kitces.com/blog/healthcare-sharing-program-review-chm-medicare-lhs-samaritan-health-share-plans/">Kitces article</a> on Healthcare Sharing Programs, these plans can cost families $300-$500/month. This can save families up to 50% each month. <br></p><p><strong>Type of plans: </strong>Medical cost sharing plans are not insurance plans. Thus, the legalities and terminology may differ from a typical health insurance plan. For more information on a sharing plan, it is best to contact an affiliate of the organization.<br></p><p><strong>Enrollment period: </strong>There is no enrollment period for health sharing plans, as they are not insurance plans. For more information on when you can enroll in a specific sharing plan, contact the organization directly. </p><p>Notable companies: Christain Healthcare Ministries, Liberty Healthshare, Medi-Share, Zion, Trinity Healthshares, and Samaritan Ministries. </p><p>‍</p><ol start="1" role="list"><li><strong>Penalty without insurance</strong>: the individual mandate was effectively repealed for the 2019 tax year at the federal level. Some states like CA,&nbsp;NJ, MA, and the District of Columbia reinstated it at the state-level. The penalty is not an actual cash penalty but a reduction of your annual tax refund.</li><li><strong>"$0 after deductible":</strong> many health plans choose to use this phase but it can be misleading. $0 after deductible does not mean the service is free for you, you are still responsible to pay full cost or negotiated <strong>until</strong> deductible is met. Deductible is the amount you have to pay out-of-pocket before your insurance starts paying </li><li><strong>"Unlimited preventative care"</strong>: under the Affordable Care Act, certain preventative care services like wellness visits, flu shots, and STD testing are available at no cost. However, there are limits on how many you can use them a year. For example, the first STD test may be free, but not if you want to be tested every other month. Sick visits like urgent care visits are not considered preventative care services. </li><li><strong>Medicare is …</strong></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance">https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance</a></em></p>]]>
            </description>
            <link>https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820565</guid>
            <pubDate>Mon, 13 Jul 2020 13:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad Habits]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820496">thread link</a>) | @fizentech
<br/>
July 13, 2020 | https://fizentech.com/bad-habits/ | <a href="https://web.archive.org/web/*/https://fizentech.com/bad-habits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Does your organization have habits that are detrimental to their success?&nbsp; The answer of course, is yes - all organizations and their people, have embedded routines and habits that are limiting their success.&nbsp; Changing a habit is challenging and often we don't even realize we have a habit that is limiting our ability to improve.</p>
<p>In the groundbreaking book, The Power of Habit, Charles Duhigg points out that in a paper published by a Duke University researcher, it was <em>found that more than 40 percent of the actions people performed each day weren't due to decision making, but were habits. In a sense, that's alarming because when we're in the middle of a habit, we're thinking less.</em></p>
<p>Well ... hold on, we do NOT want our IT professionals thinking less, we want them actively thinking through problems and critically finding ways to improve the experience of end users.&nbsp; That can become a challenge when working on an IT Help Desk becomes routine, or a strong willed Project Manager is not listening to the input of the team; and resources disengage and come to expect to be led rather than to lead.</p>
<p>As an technology provider, we provide IT Services to a broad range of industries.&nbsp; The variation in organizations we serve has helped us work with many different people, in a variety of geographical areas and countries.&nbsp; We have found that leaders with good habits naturally attract and retain employees with good habits.&nbsp; The culture of the organizations we serve and the attitudes and routines of its employees, often reflect the attitudes, routines and habits of their executive teams and owners.&nbsp; It can be hard medicine to accept, but it is true - you lead from the top (but that doesn't mean you can't be a positive agent for change, whatever your position is within a group).</p>
<p>Starbucks has often been cited for the system they developed for exceptional customer service, now referred to as the LATTE System.&nbsp; They encourage their employees to,</p>
<ul>
<li>Listen to the Customer</li>
<li>Acknowledge their complaint</li>
<li>Take action by solving the problem</li>
<li>Thank them</li>
</ul>
<p>Customers can be a wonderful and often <a href="https://fizentech.com/help-wanted/">free source of advice</a> on what your organization is or is not doing well.&nbsp; We have added an additional ingredient to this wonderful formula, and that is returning back to our customer to make sure systems are still operating as discussed.&nbsp; We want to be sure they are still happy with the outcome; perhaps easier for us as our clients are typically part of ongoing managed service agreements.</p>
<p>A few years ago we were required to roll out endpoint management to a very large customer base.&nbsp; Our product offering includes endpoint monitoring and protection for mobile devices and workstations, and when you're working with large user groups; coordinating the installations can be a real challenge.&nbsp; Nobody wants to be inconvenienced or disrupted by a software installation.</p>
<p>Our client had previous experiences with MDM and RMM roll outs that did not go very well, and we found ourselves listening to their experiences and brainstorming how we could avoid the common approaches used by other IT vendors; forcing installation and maintenance windows on end users.</p>
<p>We found if we put the power of scheduling the installations for end users into their own hands, rather than falling back on the common habit in IT organizations to force installation and maintenance windows; the installation process not only went smoother but completed faster.&nbsp; By providing end users scheduling options they were empowered with autonomy and enjoyed controlling their own downtime.</p>
<p>Willpower is the biggest and most important element of developing good habits for an organization.&nbsp; An essential element of willpower, is autonomy.&nbsp; &nbsp;Everyone wants to believe and feel that they are in control of their lives, schedule and organization.&nbsp; When we take away someone's choices, they become frustrated - but when we provide choices, we find that our ability to coordinate and deliver for a client grows tenfold.</p>
<p>We need to reflect on the processes, systems and rule-sets that are governing how our organizations operate; and by listening to our stakeholders, find new ways to innovate and empower them to be apart of our mission; to keep their IT systems running smoothly.&nbsp; Find ways to engage with your user base, and use their feedback to drive innovative IT Services within their organization; they will thank you.</p>

</div></div>]]>
            </description>
            <link>https://fizentech.com/bad-habits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820496</guid>
            <pubDate>Mon, 13 Jul 2020 13:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How reframing discounts led to a 4x increase in yearly plans]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820462">thread link</a>) | @Mnlfrgr
<br/>
July 13, 2020 | https://manuel.friger.io/blog/reframing | <a href="https://web.archive.org/web/*/https://manuel.friger.io/blog/reframing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <div>
            <p><!--block-->Back in May my wife and I decided to move out of our flat in Bristol.</p>

<p>By then we had already been living for a couple of months with my in-laws and it didn't make sense to keep paying £1k+/month in rent.</p>

<p>After some discussion, we decided to throw some money at the problem and put all our stuff in a storing facility.</p>

<p>I started googling storage companies in Bristol and I was quickly overwhelmed by the number of options (pro tip: don't start a storage business, it's ridicolously competitive).</p>

<p>Every company allowed me you to get an online quote by entering the size of the storing unit and how long I wanted to rent it for.</p>

<p>But one company did things differently.</p>

<p>On top of asking me the same two questions, UK Storage Company also <strong>asked me to choose a discount</strong>.</p>

<div>
<p><span data-trix-cursor-target="left" data-trix-serialize="false">ï»¿</span><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/205/content_Screenshot_2020-07-10_Your_storage_quote_is_below%281%29.png"></p></div>

<p>At first, I was confused.</p>

<p>I wondered why they would allow me to choose my own discount. Then I realised it was the good ol' "the longer you commit, the less you pay" gimmick.</p>

<p><strong>Same technique, different framing.</strong><br>
UK Storage Company put me in the driver's seat and empowered me to make my decision.</p>

<p>That's when my brain started whirring and buzzing, and one question began to form in my head: what if I used the same framing <a href="https://referralhero.com/">for my SaaS product</a>?</p>

<p>After all, cash-flow is king for (bootstrapped) startups and having people commit to yearly plans helps to lower churn.</p>

<p>Would that have any effect on how many people choose the longer plans (biannual or annual) over the monthly one?</p>

<p>That same day I <a href="https://twitter.com/manuel_frigerio/status/1264609587413553155">tweeted about it</a> and updated the checkout page of my app as shown below.</p>

<p><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/206/content_Screenshot_2020-07-10_ReferralHero_-_Advanced_Referral_Marketing_Software_.png"></p>



<h2><!--block-->The results</h2>

<p><!--block-->After 7 weeks the experiment has been a great success.<br>
With the new framing, the percentage of people who chose the biannual or annual plan <strong>has gone from 4.8% to 19%</strong>, a rather nice <strong>395% increase</strong>.<br>
<span data-trix-cursor-target="right" data-trix-serialize="false"><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/207/content_chart.png"></span><br>
I've done several pricing experiments over the years but none of them has been as successful and in such short space of time.</p>

<p>Perhaps even more interesting is that <strong>more than twice as many people chose the annual plan over the biannual plan</strong>.</p>

<p>My hunch is that this is due to the higher discount rate of the annual plan (35% for 12 months vs 15% for 6 months means an extra 5% discount when you choose the annual plan), which increases the perceived value.</p>

<h2><!--block-->Never stop experimenting</h2>

<p><!--block-->There's a small handful of levers you can pull to grow a business and <a href="https://manuel.friger.io/blog/charge-more">pricing is probably the most underutilised one</a>. Most SaaS businesses choose a pricing model and rarely, if ever, review it.</p>

<p>A better (and more profitable) approach is to run small experiments. If they work, incorporate them. If they don't, try something else.</p>

<p>Some people are scared that changing things will upset their customers but the truth is:</p>

<ol>
	<li>
	<p><!--block-->you are allowed to change whatever you want about your business.</p>
	</li>
	<li>
	<p><!--block-->you can always revert back. Nothing is fixed.</p>
	</li>
	<li>
	<p><!--block-->in reality, nobody cares.</p>
	</li>
</ol>

<h2><!--block-->Do it yourself</h2>

<p><!--block-->If you want to try this experiment in your business, here are a couple of suggestions:</p>

<ul>
	<li>
	<p><!--block-->don't <a href="https://medium.com/@FlorentGeerts/the-jam-experiment-how-choice-overloads-makes-consumers-buy-less-d610f8c37b9b">overload people</a> with options; have maximum 3.</p>
	</li>
	<li>
	<p>to nudge people towards one option, offer a substantially higher discount (like I did with the yearly plan)</p>
	</li>
	<li>
	<p>Don't try to be sneaky and word the options properly. As you can see in my example, people know exactly what they get and how much they pay.</p>
	</li>
	<li>
	<p>ask people immediately after sign-up when they are in the right frame of mind. In my experience, asking people to switch to yearly plans a couple of months after they have used your product triggers many more questions in their mind, whereas by asking them before they try your product you're putting them in front of a simple decision: do I want to save money?</p>
	</li>
</ul>

<p><!--block-->As people who work in the tech industry, we are all exposed to the same ideas, patterns and filters. This is why there's so little innovation and everyone just copies what everyone else is doing.</p>

<p>Sometimes all you need to do is to look at what companies in completely different industries operate. You might be suprised what a storage company can teach you.</p>

<p><strong>PS:</strong> If you do try this experiment, <a href="https://manuel.friger.io/cdn-cgi/l/email-protection#5d303c332838311d3b2f343a382f733432">let me know how it goes</a>.</p>

<p><strong>PPS:</strong> You probably want to know if we did hire that storing company in the end. The answer is NO. Eventually, we decided to hire a removal company and have all our stuff with us.</p>

          </div>
        </div>
        
      </div><div>
        <h3>Did you enjoy this?</h3>
        <p>Then you will like <a target="_blank" href="https://manuel.friger.io/join">ðŸ”¥The Fireside</a>, a monthly-ish newsletter about psychology, business, technology and the intersection of those plus any new articles I publish on this blog.</p>
      </div></div>]]>
            </description>
            <link>https://manuel.friger.io/blog/reframing</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820462</guid>
            <pubDate>Mon, 13 Jul 2020 13:24:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surviving Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820449">thread link</a>) | @kiwicopple
<br/>
July 13, 2020 | https://supabase.io/blog/2020/07/10/surviving-hacker-news | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/07/10/surviving-hacker-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://supabase.io/blog/2020/07/10/surviving-hacker-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820449</guid>
            <pubDate>Mon, 13 Jul 2020 13:23:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russ v7.0 – Services framework/library for Unix sockets]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23820398">thread link</a>) | @johnmdev
<br/>
July 13, 2020 | https://expl.info/display/RUSS/Home | <a href="https://web.archive.org/web/*/https://expl.info/display/RUSS/Home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-type="normal">
<div>
<p>RUSS is a protocol and framework for building service-oriented servers using UNIX/Domain sockets.</p><p>RUSS is an alternative to HTTP/web technologies for services running on UNIX/Linux.</p><p>RUSS is built on some familiar ideas:</p><ul><li>orthogonal operations: execute, help, list</li><li>service path: /-separated list of strings identifying a service and how to get there</li><li>ordered list of string arguments (aka positional arguments)</li><li>unordered collection of string attritubes as key=value pairs (like environment variables)</li><li>exit/return value</li><li>stream I/O over file descriptors (stdin, stdout, stderr)</li></ul><p>The benefits of using UNIX/Domain sockets are:</p><ul><li>performance</li><li>standard part of UNIX/Linux (no kernel modules needed)</li><li>credentials are mediated by the OS</li><li>connection between independent processes (even between different users)</li><li>passing of descriptors between independent processes (even between different users)</li></ul><p>Get started with&nbsp;<a href="https://expl.info/display/RUSS/RUSS+v7+-+Quickstart+Setup">RUSS v7 - Quickstart Setup</a>.</p><p>Further information for users and developers is available in the&nbsp;<a href="https://expl.info/display/RUSS/Documentation">Documentation</a>&nbsp;section:</p><ul><li><a href="https://expl.info/display/RUSS/RUSS+Specification">RUSS Specification</a></li><li><a href="https://expl.info/display/RUSS/RUSS+v7+-+Tools">RUSS v7 - Tools</a></li><li><a href="https://expl.info/display/RUSS/RUSS+v7+-+Core+Servers">RUSS v7 - Core Servers</a></li><li><a href="https://expl.info/pages/viewpage.action?pageId=40501388">pyruss - RUSS for the Python Programming Language</a></li><li><a href="https://expl.info/display/RUSS/goruss+-+RUSS+for+the+Go+Programming+Language">goruss - RUSS for the Go Programming Language</a></li></ul><h2 id="Home-Firstthings">First things</h2><ul><li><code>+</code>&nbsp;-&nbsp;the area that system servers register at; usually under&nbsp;<code>/var/run/russ/services</code><span><code><br></code></span></li><li><span><code>ruls</code>&nbsp;- command line tool to list servers/services (think&nbsp;<code>ls</code>)<br></span></li><li><span><code>ruhelp</code>&nbsp;- command line tool to get help information (think&nbsp;<code>man</code>)</span></li><li><span><code>ruexec</code>&nbsp;- command line tool to execute a service</span></li><li><span><code>pyruss</code>&nbsp;- Python bindings for the C API</span></li><li><span><code>rubb</code>&nbsp;- manage servers/services</span></li></ul><h2 id="Home-ListingServers/Services">Listing Servers/Services</h2><p>What's available?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruls +
debug
exec
plus
proc
set
ssh
tee</pre>
</div></div><p>What services does the&nbsp;<code>debug</code>&nbsp;server provide?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruls +/debug
chargen
conn
daytime
discard
echo
env
exit
request
session
spath</pre>
</div></div><h2 id="Home-GettingHelp-BuiltinManPage">Getting Help - Built in Man Page</h2><p>How do I use the&nbsp;<code>debug</code>&nbsp;services?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruhelp +/debug
Provides services useful for debugging.

/chargen[/...]
    Generate and send characters following the RFC 864 character
    generator protocol sequence.

/conn[/...]
    Report connection information.

/daytime
    Report the date and time.

/discard[/...] [--perf]
    Discard all data received from stdin. If --perf is specified,
    performance feedback is reported to stderr.

/echo[/...]
    Simple echo service: read from stdin and write back to stdout.

/env
    Report server side environ entries.

/exit &lt;value&gt;
    Return with given exit value (between 0 and 255).

/request[/...]
    Report request information.

/session[/...]
    Report session information.

/spath[/...]
    Report service path information.</pre>
</div></div><h2 id="Home-RunningaService">Running a Service</h2><p>Try the character generator:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/debug/chargen
!"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefgh
"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghi
#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghij
^C</pre>
</div></div><p>Show "request" information (as received and sent back by the server):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec -a X=123 -a Y=abc +/debug/request hello there world
protocol string (0010)
spath (/request)
op (execute)
opnum (2)
attrv[0] (X=123)
attrv[1] (Y=abc)
argv[0] (hello)
argv[1] (there)
argv[2] (world)</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/debug/daytime
Friday, February 16, 2018 11:45:50-GMT</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service on another machine "buddy" (<code>ssh</code>&nbsp;must work without user interaction):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/ssh/buddy/+/debug/daytime
Friday, February 16, 2018 11:46:55-GMT</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service from Python:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ PYTHONPATH=/usr/lib/russng python2
&gt;&gt;&gt; import pyruss
&gt;&gt;&gt; rv, ev, out, err = pyruss.execv_wait_inouterr_timeout(1000, "+/ssh/buddy/+/debug/daytime")
&gt;&gt;&gt; print out
Friday, February 16, 2018 11:48:23-GMT</pre>
</div></div><p>Echo a message, hopping through three machines "buddy", "bobby", and "bibby" (as before,&nbsp;<code>ssh</code>&nbsp;must work without user interaction):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ echo "hop hop hop" | ruexec +/ssh/buddy/+/ssh/bobby/+/ssh/bibby/+/debug/echo
hop hop hop</pre>
</div></div></div>
</div></div>]]>
            </description>
            <link>https://expl.info/display/RUSS/Home</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820398</guid>
            <pubDate>Mon, 13 Jul 2020 13:16:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Project over Money, Team over Project]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23820390">thread link</a>) | @strdr4605
<br/>
July 13, 2020 | https://strdr4605.github.io/project-over-money-team-over-project | <a href="https://web.archive.org/web/*/https://strdr4605.github.io/project-over-money-team-over-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><h2>Project over money, team over project</h2><p><time>11.07.2020</time> — <a href="https://strdr4605.github.io/tags/motivation">motivation</a> — <span>2<!-- --> min read</span></p><section><p>Behind any work stands a motivation. Sometimes work is a pleasure, other times you do things that are unpleasant just because you have to.
But in the end motivations like money, common goal, future achievements drive us to work.
When choosing a job as a software engineer, things that motivate me and probable you are the <strong>project</strong> what I will work on,
<strong>team</strong> what I will work with and <strong>money</strong> for my personal need.
When making the final decision I usually value <strong>project over money, team over project</strong>.</p><h2>Team</h2><p>For me, the team that I will work with is the most important aspect when searching for a new job.</p><blockquote><p>“If you are the smartest person in the room, then you are in the wrong room.” ― Confucius</p></blockquote><p>Being in a team with people that are more experienced than you is the key to fast-growing.
But don't just stay and wait when their knowledge will be transferred to you.</p><ul><li>Observe their behaviors</li><li>Make proposals and wait for feedback</li><li>Ask for advice</li><li>Ask "Why?" when they make a decision. "Why this database?" "Why this service?" ...</li></ul><p>Make sure to not push too hard on them. As this can defocus and irritate some people.</p><p>Even if your teammates aren't more experienced than you they may share interesting articles, tips, thoughts.</p><p>In the end, if you have a hard situation, maybe the project is not that interesting (at the moment) or you have problems with finishing a task,
with a great team, you can carry on and pass any issues.</p><h2>Project</h2><p>At this moment in my career, I am really focused on the technical part of a project.
I enjoy learning new tools, libraries that will increase productivity, and when coding I am trying to create a piece of art.</p><p>But also the idea and the product may still be a good motivation and even if the tech stack is not that good,
with a great team, you will refactor everything as long as you believe in the product idea.</p><p>Even if the team is not that good or you don't have a team at all, enjoying the tech stack or believing in the product
will make you continue working and loving your job.</p><p>While at the interview, I try to discover as much as possible about the project stack and idea to understand if
I am willing to accept an offer bellow my initial expectations.</p><h2>Money + benefits</h2><p>Money is important as everyone has their needs and money represent your value as a software engineer.
Employee benefits like included food, gym, short commute time may be also added to the total compensation pack.</p><p>If you have a family and bills to pay money may be a decisive factor.
But still, put everything on the table and before making the final decision ask yourself a question.</p><blockquote><p>What will be your next job after this one?</p></blockquote><p>In other words: Where will this job lead you? How much will your professional skills increase?
Will this job have temporary benefits you will bust your entire career?</p><p>Does it worth an additional 100% salary increase to work with a 5+ year old legacy codebase, old tech stack, and maybe a bad team?</p><h2>Conclusion</h2><p>As everyone has a price I will try to conclude with some compensation examples.</p><p>If I am enjoying the project and/or the team at my current job, I would not accept a 5-15% salary increase offer,
as after 3-6 months I may get even more increase at my current job.
If I don't like the project or the team is toxic, I may accept a lower job offer just because
I will gain more from the new team or new tech stack.</p><p>Focus on your professional skills, gain maximum value from your team (don't forget to also give back and share your knowledge with teammates),
learn your tech stack, enjoy your software engineering career and the money will eventually come to you.</p></section></div></div>]]>
            </description>
            <link>https://strdr4605.github.io/project-over-money-team-over-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820390</guid>
            <pubDate>Mon, 13 Jul 2020 13:15:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Querying 40k Datasets with SQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820382">thread link</a>) | @mildbyte
<br/>
July 13, 2020 | https://www.splitgraph.com/blog/40k-sql-datasets | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/40k-sql-datasets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#introduction" as="#introduction">Introduction</a></li><li><a href="#data-should-be-discoverable-and-composable" as="#data-should-be-discoverable-and-composable">Data should be discoverable and composable</a></li><li><a href="#mounting-vs-cloning-data" as="#mounting-vs-cloning-data">Mounting vs. Cloning Data</a></li><li><a href="#mounting-data-in-splitgraph-cloud" as="#mounting-data-in-splitgraph-cloud">Mounting data in Splitgraph Cloud</a></li><li><a href="#avoiding-the-pull-of-data-gravity" as="#avoiding-the-pull-of-data-gravity">Avoiding the pull of Data Gravity</a></li><li><a href="#looking-to-the-future" as="#looking-to-the-future">Looking to the future</a></li></ol></nav><section><h2 id="introduction">Introduction</h2><p><a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">Splitgraph</a> is a tool and platform for building, versioning, querying and sharing datasets. Inspired by Docker and Git, it works on top of PostgreSQL and integrates seamlessly with anything that uses PostgreSQL. Our <a href="https://www.splitgraph.com/explore" as="https://www.splitgraph.com/explore">data catalog</a> already includes over 40,000 datasets from government open data portals, all queryable via SQL.</p><p>The Splitgraph catalog classifies these datasets as <a href="https://www.splitgraph.com/docs/splitgraph-cloud/external-repositories">external repositories</a>. These are different from the default <a href="https://www.splitgraph.com/docs/concepts/repositories">Splitgraph repositories</a>, which are collections of <a href="https://www.splitgraph.com/docs/concepts/images">Splitgraph images</a>. Yet Splitgraph allows you to query them in the same way as you do Splitgraph images. For example, you can use SQL to query any repository or <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals" as="/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals"><code>JOIN</code> between multiple of them</a>. Or you can use Splitfiles to <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#splitfile" as="/docs/ingesting-data/socrata#splitfile">build reproducible datasets</a> from them. And every external repository includes an <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">auto-generated PostgREST API</a>.</p><p>External repositories allow Splitgraph Cloud to index live data without actually ingesting it. This way, you can use the catalog to discover live data. But you only need to ingest it when you're ready to query it, or snapshot it as part of a Splitgraph image.</p></section><section><h2 id="data-should-be-discoverable-and-composable">Data should be discoverable and composable</h2><p>Many services exist for cataloging data and making it discoverable. For example, <a href="https://datasetsearch.research.google.com/" as="https://datasetsearch.research.google.com/">Google Dataset Search</a> provides a nice interface for searching and discovering datasets (in fact, <a href="https://datasetsearch.research.google.com/search?query=opd%20crimes&amp;docid=jrM9a8yTUXMZaY1QAAAAAA%3D%3D" as="https://datasetsearch.research.google.com/search?query=opd%20crimes&amp;docid=jrM9a8yTUXMZaY1QAAAAAA%3D%3D">it even includes Splitgraph repositories</a>). The problem is, the data is fragmented and siloed across different data portals. It's nice to be able to search for data and download a CSV file. But most datasets are uninteresting in isolation. The real power comes from the ability to combine datasets and query them together.</p><p>Splitgraph does not only provide an index for discovering open data. It also provides the tools for composing open datasets together. For example, mounting the data from the <a href="https://data.cambridgema.gov/" as="https://data.cambridgema.gov">Cambridge</a> and <a href="https://data.cityofchicago.org/" as="https://data.cityofchicago.org">Chicago</a> data portals is as simple as running two commands:</p><pre><code metastring=""><span><span>$</span> <span>sgr <span>mount</span> socrata chicago -o <span>'{"domain": "data.cityofchicago.org"}'</span></span></span>
<span>Connecting to remote server...
Mounting Socrata domain...
Getting Socrata metadata
warning: Requests made without an app_token will be subject to strict throttling limits.
Loaded metadata for 504 Socrata tables

</span><span><span>$</span> <span>sgr <span>mount</span> socrata cambridge -o <span>'{"domain": "data.cambridgema.gov"}'</span></span></span>
<span>Connecting to remote server...
Mounting Socrata domain...
Getting Socrata metadata
warning: Requests made without an app_token will be subject to strict throttling limits.
Loaded metadata for 137 Socrata tables
</span></code></pre><p>At this point, all the datasets in these two data portals are available for querying. You can query them in isolation, or you can query them together. You can use a Splitfile, <code>sgr sql</code>, or any standard SQL client:</p><p><a href="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png" as="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png"><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png" alt="DBeaver overview"></a></p><p>Here's how you can compare daily COVID cases in Chicago and Cambridge (from two separate data portals) with a standard <code>JOIN</code> query:</p><pre><code metastring=""><span>SELECT</span>
    cambridge_cases<span>.</span><span>date</span> <span>AS</span> <span>date</span><span>,</span>
    chicago_cases<span>.</span>cases_total <span>AS</span> chicago_daily_cases<span>,</span>
    cambridge_cases<span>.</span>new_positive_cases <span>AS</span> cambridge_daily_cases
<span>FROM</span>
    chicago<span>.</span>covid19_daily_cases_and_deaths_naz8_j4nc chicago_cases
<span>FULL</span> <span>OUTER</span> <span>JOIN</span>
    cambridge<span>.</span>covid19_cumulative_cases_by_date_tdt9_vq5y cambridge_cases
<span>ON</span>
    date_trunc<span>(</span><span>'day'</span><span>,</span> chicago_cases<span>.</span>lab_report_date<span>)</span> <span>=</span> cambridge_cases<span>.</span><span>date</span>
<span>ORDER</span> <span>BY</span> <span>date</span> <span>ASC</span><span>;</span>
</code></pre><p>(For more details and in-depth instructions, see the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW documentation</a>.)</p><p>Note that this is not limited to combining multiple public datasets. Often, the work of a data analyst includes combining internal data with public or licensed datasets from external vendors. The same semantics of "mounting" data in Splitgraph apply.</p></section><section><h2 id="mounting-vs-cloning-data">Mounting vs. Cloning Data</h2><p>With Splitgraph, there are two primary ways to ingest data: cloning it or mounting it.</p><p><a href="https://www.splitgraph.com/docs/working-with-data/clone-vs-checkout">"Cloning" (and checking-out)</a> an image means downloading a versioned data image, which is a snapshot of a database comprised of delta-compressed diffs. For example, the result of running a Splitfile is an image.</p><p>"Mounting" means establishing a connection to a live data source. The term comes from the idea of "mounting" a filesystem. A mounted table uses a <a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction">foreign data wrapper</a> (FDW), and you don't ingest data from it until you query it. For example, the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW</a> translates SQL queries to <a href="https://dev.socrata.com/docs/queries/" as="https://dev.socrata.com/docs/queries/">SoQL queries</a> and forwards them to the Socrata server.</p><p>(For more details on mounting data, FDWs and custom mount handlers, read our recent <a href="https://www.splitgraph.com/blog/foreign-data-wrappers">"foreign data wrappers" blog post</a>.)</p></section><section><h2 id="mounting-data-in-splitgraph-cloud">Mounting data in Splitgraph Cloud</h2><p>Mounting is the key abstraction that allows Splitgraph Cloud to index external repositories with features like an auto-generated REST API. On the backend, the "query API" (a subject for a later post) uses the Splitgraph library and Socrata mount handler to mount repositories on demand. Then it exposes the mounted schemata to a customized version of <a href="http://postgrest.org/" as="http://postgrest.org/">PostgREST</a> which creates the API.</p><p>Separately, a periodic Airflow task queries the Socrata metadata API to discover and index over 40,000 repositories. Conveniently, the same Socrata software powers over 200 government open-data portals, so one mount handler provides a large catalog of useful live data.</p></section><section><h2 id="avoiding-the-pull-of-data-gravity">Avoiding the pull of Data Gravity</h2><p>Mounting is a powerful abstraction because it allows you to interact directly with upstream data sources, avoiding the need for ETL. In 2010, GE Engineer Dave McCrory coined the term "<a href="https://datagravitas.com/2010/12/07/data-gravity-in-the-clouds/" as="https://datagravitas.com/2010/12/07/data-gravity-in-the-clouds/">data gravity</a>." In his blog post, he observed that "data if large enough can be virtually impossible to move."</p><p>Splitgraph, as a data versioning solution, should work with all your data, not just the subsets of it that you can move. Traditional ETL tools force you to ingest or duplicate your data before you can interact with it. With Splitgraph, you only need to pull upstream data into your images at query time. This allows incremental adoption and quick experimentation; there is no need to move your data warehouse to start using Splitgraph. Instead, you only need to setup an FDW.</p><p>Note that the idea of data gravity applies to versioned data images (which you clone) as much as it does to upstream, live data (which you mount). What if you want to import only a subset of data from a large image? This is the use case for <a href="https://www.splitgraph.com/docs/large-datasets/layered-querying">layered querying</a>, which allows you to "check out" an image without downloading it. Instead, Splitgraph creates an FDW that queries only the "layers" of the image necessary to satisfy the query. You can think of layered querying like a mount handler for Splitgraph images.</p></section><section><h2 id="looking-to-the-future">Looking to the future</h2><p>At the moment, Splitgraph Cloud only uses the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW</a> as a mount handler for external repositories, since the <a href="https://www.tylertech.com/products/socrata" as="https://www.tylertech.com/products/socrata">Socrata data platform</a> powers most government open-data portals.  In the future, it could use additional mount handlers to provide access to a wider array of upstream sources. To create an external repository, Splitgraph just needs a suitable FDW and a way to index the upstream data. For example, it's easy to imagine indexing Google BigQuery datasets. More interestingly, an on-premise version of Splitgraph could index private databases or data warehouses behind a firewall.</p><p>Our goal for Splitgraph is to make tools for data science as easy and pleasurable to use as tools for coding. That's why our main philosophy is to "stay out of the way." Mounting data is a great example of this philosophy in action. Why force your data warehouse to talk to Splitgraph, when Splitgraph can talk to your data warehouse?</p><p>In the meantime, make sure to <a href="https://www.splitgraph.com/explore">explore data</a> on Splitgraph. If you know SQL, you can <a href="https://www.splitgraph.com/docs/getting-started/five-minute-demo">get started</a> in less than 10 minutes.</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/40k-sql-datasets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820382</guid>
            <pubDate>Mon, 13 Jul 2020 13:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The two commandments for undergrad math]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820344">thread link</a>) | @iunternik
<br/>
July 13, 2020 | https://linus.space/posts/2020-07-13-undergrad-courses.html | <a href="https://web.archive.org/web/*/https://linus.space/posts/2020-07-13-undergrad-courses.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="content">
            <article>
    
    
    <section>
        <p>I’ve only been tutoring in theoretical computer science undergrad courses for about three semesters now (and of course taken a fair share of them) but I’ve thought quite a bit about how to do it <em>right</em>. Of course, there’s a lot of subjective opinion in that: how do you explain something, and is <span>0 ∈ ℕ</span>? But I think there are some objective things you should look out for. These (in my opinion) are the two commandments for undergrad math courses:</p>
<ol type="1">
<li>Be kind.
<ul>
<li>Have the right attitude towards your students.</li>
<li>Reduce stress on your students. Value your student’s time.</li>
<li>Consider that your subject is hard.</li>
</ul></li>
<li>Be predictable.
<ul>
<li>Connect your lecture to your assignments and your assignments to your exam. If you are a bigger team, coordinate these clearly.</li>
<li>Keep a consistent level of exactness.</li>
</ul></li>
</ol>
<p>Fortunately, a lot of people do these right. I’ve had great courses that were kind and predictable. But important details tend to go wrong in some courses in my experience.</p>
<h3 id="be-kind">1. Be kind</h3>
<h4 id="have-the-right-attitude-towards-your-students-reduce-stress">Have the right attitude towards your students, reduce stress</h4>
<p>I noticed that some people running undergrad courses have the general (maybe implicit) attitude that students are lazy, stupid, and always tempted to take the shortcut, even if it involves cheating or breaking other rules. Not only is this often taken as explanation that the course is not rated well by the students or the exam has a 70% fail rate, but it’s also often taken into a <em>predisposition</em> towards the students. This results in paranoid measures like forcing assignment groups of three students to return their assignments in three different handwritings (to prove that everyone was working?), letting students stand up and turn around while handing out exam sheets, or having a general (and often very explicit) “if you spot a mistake, it’s probably your fault” attitude in exam reviews. If you have taken maths undergrad courses you can probably name another example off the top of your head. Some of the measures that I’ve seen were not only completely unnessecary, but actively harmful: Being paranoid about cheating <em>encourages</em> cheating (and no “anti-cheating” measure is very hard to get around). Also, a general level of distrust against students is really harmful for their mental health and level of confidence in continuing to study.</p>
<p>So: trust that your students don’t take shortcuts. You can’t prevent it anyways, and if they do, it’s going to be a learning experience for them later on. And try to make your students understand that they can understand the subject, even if it’s hard. Of course, that is a hard thing to actually go and do, but it’s not impossible.</p>
<h4 id="value-your-students-time-consider-that-your-subject-is-hard">Value your student’s time, consider that your subject is hard</h4>
<p>Even if you trust your students being intelligent and hard-working, consider how many hours students spend on the course. Having a hard exercise sometimes is a good learning factor, of course. A math course is always a test in persistence and motivation. But also consider that the students have different things to do, and they also need some work-life-balance. Finding the sweet spot here is crucial. Additionally, professors and assistants tend to forget that their subjects are actually really hard, especially in mathematics, where basic topics are so internalized that it might seem wild that someone wouldn’t understand what a homomorphism does. This feeds into the topic of how to <em>really</em> explain something in the lecture, but it also has to do with how hard you can reasonably make the exercises and exams.</p>
<h3 id="be-predictable">2. Be predictable</h3>
<h4 id="connect-your-lecture-to-your-assignments">Connect your lecture to your assignments…</h4>
<p>This seems obvious, but is often not the case, especially when different people are working on the assignments, the lecture and the exam. This starts at the lecture, assignments and exam using different notation respectively, but you should also ask yourself if the assignments can be understood by consulting the lecture. Also, having tutorials where students can ask questions about exercises is helpful here.</p>
<h4 id="and-your-assignments-to-your-exam">…and your assignments to your exam</h4>
<p>Students should be able to pass the exam by having done the exercises. They should also get a glimpse into what the exam will look like, for instance by a test exam. Of course, the whole point of an exam is that it’s unpredictable what will be asked of the students, but it should rather be too predictable than not predictable enough. An exam is a stress situation for most students, and you shouldn’t ask them to find all-new solutions to all-new problems.</p>
<h4 id="keep-a-consistent-level-of-exactness">Keep a consistent level of exactness</h4>
<p>This is more specific to math courses, I think, than the other points. The students should know what is asked of them when an exercise is to prove or explain something. If you only do “this is trivial” and “you can see this by looking very hard”-ish proofs in your lectures, don’t ask your students to prove something by induction on three pages in the exam. It’s also not an argument that students <em>should have learned to prove something</em> in another lecture, if they haven’t seen any proofs in yours, they will just mimic what the lecture does, as is sensible of any human being. Make it clear in the exercises and exam how exact you want the explanation and proof to be.</p>
<h3 id="in-conclusion">In conclusion</h3>
<p>There are probably many more things that need to be said about undergrad courses. This is just what I had on my mind in the last semester. <a href="https://www.reddit.com/r/math/comments/hqcb8v/the_two_commandments_for_undergrad_math_tcs/">Here’s the link to the reddit discussion about this post.</a> Thanks for reading!</p>
    </section>
</article>

        </div>
        </div></div>]]>
            </description>
            <link>https://linus.space/posts/2020-07-13-undergrad-courses.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820344</guid>
            <pubDate>Mon, 13 Jul 2020 13:09:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Track Dark Mode Usage with Google Tag Manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820306">thread link</a>) | @justus_bluemer
<br/>
July 13, 2020 | https://hume.dev/articles/dark-mode/ | <a href="https://web.archive.org/web/*/https://hume.dev/articles/dark-mode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
    <div>
      <div>
        <article>
          <p>Dark Mode for all the things is all the rage these days and if you don’t offer a dimly lit version of your website or app, you suck. Apparently.
While I do use dark mode on my phone (where it can <a href="http://mobileenerlytics.com/dark-mode/">save significant power and thereby improve battery life</a>), I think most other uses are the Matrix Raining Code screen saver of our time and actively supporting it is a waste of development resources.</p>
<p>If you, too, want to support or refute this assertion, this is how you can track the usage of Dark Mode on your website with Google Tag Manager and Google Analytics as a custom dimension:</p>
<h2 id="create-a-google-tag-manager-variable">Create a Google Tag Manager variable</h2>
<p>Using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/matchMedia">matchMedia</a> interface of the <code>window</code> object wie can check the <code>prefers-color-scheme</code> media feature to detect whether or not the user has configured the system with a light or a dark color scheme.</p>
<p>This Custom JavaScript variable will return <code>dark</code> true if dark mode is active and <code>light</code> if it isn’t.</p>
<div><pre><code data-lang="javascript"><span>function</span>(){
    <span>return</span> (window.<span>matchMedia</span> <span>&amp;&amp;</span> window.<span>matchMedia</span>(<span>'(prefers-color-scheme: dark)'</span>).<span>matches</span>) <span>?</span> <span>"dark"</span> <span>:</span> <span>"light"</span>
}
</code></pre></div><p>Paste this into GTM like so:</p>

<figure>
    <a href="https://hume.dev/img/articles/dark-mode/colorscheme-js-variable.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/colorscheme-js-variable.jpg" loading="lazy" alt="Google Tag Manager Dark Mode variable">
    </a>
    
</figure>


<h2 id="update-google-analytics-configuration">Update Google Analytics configuration</h2>
<p>First, make sure you have a spare Google Analytics custom dimension and make note of the variable index you want to use (marked in red):</p>

<figure>
    <a href="https://hume.dev/img/articles/dark-mode/analytics-dimension-color-scheme.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/analytics-dimension-color-scheme.jpg" loading="lazy" alt="Google Tag Manager Dark Mode custom dimension">
    </a>
    
</figure>


<p>If you’re not sure which <a href="https://support.google.com/analytics/answer/2709828?hl=en">scope</a> is right for you, use “Hit”.</p>
<p>Now, back in Google Tag Manager, edit your Google Analytics tag or your Google Analytics settings variable to incorporate the <code>dark</code> or <code>light</code> value into your tracking request:</p>

<figure>
    <a href="https://hume.dev/img/articles/dark-mode/color-scheme-settings.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/color-scheme-settings.jpg" loading="lazy" alt="The updated Google Tag Manager settings variable settings the value of the appropriate dimension index">
    </a>
    
</figure>


<p>Great, that’s it, you can go ahead and publish your GTM container! If you want to validate right away if your implementation was successful, check our your Google Analytics request to see the custom dimension parameter:</p>

<figure>
    <a href="https://hume.dev/img/articles/dark-mode/request-dark.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/request-dark.jpg" loading="lazy" alt="A screenshot of the Google Analytics request with dark mode enabled">
    </a>
    
</figure>



<figure>
    <a href="https://hume.dev/img/articles/dark-mode/request-light.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/request-light.jpg" loading="lazy" alt="A screenshot of the Google Analytics request with dark mode disabled">
    </a>
    
</figure>


<h2 id="track-dark--light-mode-switch">Track dark / light mode switch</h2>
<p>If you really want to go all in, you can also track changes to the preferred color scheme and push an event to dataLayer in case the user decides to update her or his preferences:</p>
<div><pre><code data-lang="javascript">window.<span>matchMedia</span>(<span>'(prefers-color-scheme: dark)'</span>).<span>addEventListener</span>(<span>'change'</span>, <span>e</span> =&gt; {
    <span>var</span> <span>newColorScheme</span> <span>=</span> <span>e</span>.<span>matches</span> <span>?</span> <span>"dark"</span> <span>:</span> <span>"light"</span>;
    window.<span>dataLayer</span> <span>=</span> window.<span>dataLayer</span>&nbsp;<span>||</span>&nbsp;[]
    window.<span>dataLayer</span>.<span>push</span>({
        <span>event</span><span>:</span> <span>"colorScheme"</span>,
        <span>newColorScheme</span><span>:</span> <span>newColorScheme</span>
    })
});
</code></pre></div><p>Considering this will almost never happen, it’s pretty pointless though.</p>
<p>How many of your users use Dark Mode?</p>

        </article>
      </div>
    </div>
  </div>
</section></div>]]>
            </description>
            <link>https://hume.dev/articles/dark-mode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820306</guid>
            <pubDate>Mon, 13 Jul 2020 13:04:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Wall]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820222">thread link</a>) | @noch
<br/>
July 13, 2020 | https://dev.theportal.dev/wall/ | <a href="https://web.archive.org/web/*/https://dev.theportal.dev/wall/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="paragraph-content">
        <p>
            Edward Witten in Physics and Geometry, 1987:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;"If one wants to summarise our knowledge of physics in the briefest possible terms, there are three really fundamental observations:
        </p>
        <p>(i) Space-time is a pseudo-Riemannian manifold $M$, endowed with a metric tensor and governed by geometrical laws.</p>
        <p>(ii) Over $M$ is a vector bundle $X$ with a nonabelian gauge group $G$.</p>
        <p>(iii) Fermions are sections of $(\hat{S}{+} \otimes V{R}) \oplus (\hat{S}_ \otimes V_{\bar{R}})$. $R$ and $\bar{R}$ are not isomorphic; their failure to be isomorphic explains why the light fermions are light and presumably has its origins in representation difference $\Delta$ in some underlying theory.</p>
        <p>All of this must be supplemented with the understanding that the geometrical laws obeyed by the metric tensor, the gauge fields, and the fermions are to be interpreted in quantum mechanical terms."</p>
    </div></div>]]>
            </description>
            <link>https://dev.theportal.dev/wall/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820222</guid>
            <pubDate>Mon, 13 Jul 2020 12:53:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wallet fingerprinting nearly a third of all Bitcoin transactions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820109">thread link</a>) | @b10c
<br/>
July 13, 2020 | https://b10c.me/mempool-observations/3-blockchaincom-recommendations/ | <a href="https://web.archive.org/web/*/https://b10c.me/mempool-observations/3-blockchaincom-recommendations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <p>Transactions sent with Blockchain.com wallets make up for about a third of all
Bitcoin transactions. A methodology to identify these transactions is described
and used. Insights about the wallet-usage are derived from the resulting
dataset. The privacy implications and possible improvements are discussed.</p>
<hr>
<p>One of the first observations made when building the <a href="https://mempool.observer/monitor">Bitcoin Transaction
Monitor</a> was that many transactions precisely follow the recommendations of
a feerate estimator. These transactions appear as horizontal bands, which rise
and sink as the feerate recommendations change.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/bands.png" alt="Transactions following the Blockchain.com feerate recommendations">
    <figcaption><center></center></figcaption>
</figure>
    
<p>Most of these transactions share the same fingerprint. Only P2PKH outputs are
spent. No SegWit and neither multisig are spent. With every transaction, either
one or two outputs are created. When two outputs are created, then at least one
of them is a P2PKH output. The transactions are not time-locked, have a version
of one, and do not signal <a href="https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki">BIP-125 replaceability</a>. However, all are
<a href="https://github.com/bitcoin/bips/blob/master/bip-0069.mediawiki">BIP-69</a> compliant.</p>
<p>This matches the fingerprint of the Blockchain.com wallets: namely a Web, an
iOS, and an Android wallet. The wallets can only receive and spend P2PKH
outputs. While users can pay to all address formats<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, the change-output, if
created, is a P2PKH output. The wallets construct the transactions with a
locktime of zero and a transaction version of one. The inputs and outputs are
all lexicographically sorted as specified by BIP-69.</p>
<p>The wallets use the Blockchain.com feerate estimator, which is publicly
accessible via <a href="https://b10c.me/blog/003-a-list-of-public-bitcoin-feerate-estimation-apis/#blockchaininfo-api">an API</a>. The API returns two feerate estimates: <em>priority</em>
and <em>regular</em>. The <em>priority</em> feerate aims for confirmation in the next hour
and the <em>regular</em> feerate for confirmation in an hour or more. By default,
the wallets follow the recommendations closely. Users can set a custom feerate,
but a warning is displayed.</p>
<h3 id="methodology">Methodology</h3>
<p>Combining the feerate estimates and the transaction fingerprints makes it
possible to identify transactions sent with one of the Blockchain.com wallets.
While the majority of the Blockchain.com transactions pay exactly the
recommended feerate, some under- or overpay by a fixed percentage. This is
caused by incorrect assumptions about the transaction size during the
calculation of the transaction fee. The transaction fee is the product of the
targeted feerate and the assumed transaction size. The final and actual
transaction size is only known after adding the signature to the transaction.</p>
<pre>fee  =  target feerate  ×  assumed transaction size
</pre>
<p>All underpaying transactions have two outputs. However, during the fee
calculation, the size of a one-output transaction is assumed. For example, for a
P2PKH <em>1in ⇒ 2out</em> transaction (226 bytes), the size of a <em>1in ⇒ 1out</em>
transaction (192 bytes) is used. This incorrect assumption results in the
transaction only paying around 85% (192 byte / 226 byte) of the recommended
feerate. As the transaction inputs make up for a large part of the transaction
size, the effect is smaller for transactions with more inputs. This behavior was
only present in the Blockchain.com Web wallet. A fix was <a href="https://github.com/blockchain/blockchain-wallet-v4-frontend/releases/tag/v4.32.6">released</a> on
April 21st, 2020.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/over-underpaying.png" alt="Transactions over- and underpaying by a fixed percentage">
    <figcaption><center></center></figcaption>
</figure>
    
<p>The overpaying transactions all have a single output. For these, a second output
is assumed during the fee calculation. To calculate the fee of a P2PKH
<em>1in ⇒ 1out</em> transaction (192 bytes), the size of a <em>1in ⇒ 2out</em> transaction
(226 bytes) is used. This results in the transaction paying about 118% (226 byte
/ 192 byte) of the recommended feerate. Similar to the underpaying transactions,
the effect is smaller for transactions with more inputs. These transactions are
assumed to originate from the Blockchain.com iOS wallet. This has not yet been
confirmed.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/methodology.png" alt="Visual explainer for methodology used to identify Blockchain.com transactions">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    Out of the set of transactions with the Blockchain.com wallet fingerprint, the
transactions paying the feerate recommended by the Blockchain.com feerate
estimator are selected. Transactions broadcast on April 19th, 2020, are shown.
The y-axis is centered around the <em>regular</em> recommendation, which was 3
sat/vbyte for most of the day. Between 12:00 UTC and 17:00 UTC, the <em>regular</em>
recommendation briefly jumped to 4 sat/vbyte for a few minutes each. On other
days the feerate recommendations are usually  more volatile. April 19th is a
Sunday. Sundays are known for less network activity compared to weekdays. This
day has been specifically chosen to showcase the methodology.
</p>
<p>Identifying Blockchain.com wallet transactions with this methodology is not
assumed to be perfectly accurate or reliable. For example, transactions send
with a custom feerate can not be identified and are false negatives.
Transactions constructed by different wallets that pay a similar feerate and
share the fingerprint could be identified as false positives. When the
recommended feerate is volatile, which is often the case for the <em>priority</em>
recommendation (for example, shortly after <a href="https://b10c.me/mempool-observations/2-bitmex-broadcast-13-utc/">the daily BitMEX broadcast</a>),
then some transactions might pay a feerate not recoded by the Bitcoin
Transaction Monitor. Additionally, the wallets could construct a transaction
using an older recommendation, which is different from the recommendation at the
time the transaction is broadcast. These transactions are false negatives as
well.</p>
<h3 id="observations">Observations</h3>
<p>The described methodology is used to identify the transactions send with
Blockchain.com wallets between April 1st and May 20th, 2020. The resulting
dataset spans over 50 days and contains about 4 million transactions. These pay
a total fee of 445.73 BTC and account for about 1.34 GB of block space. Roughly
two-thirds of the Blockchain.com wallet transactions target the <em>regular</em> feerate
while the remaining third targets the <em>priority</em> feerate.</p>
<p>Roughly the same number of outputs are created as are spend. Blockchain.com
wallet transactions have either a single payment-output or a payment-output and
a change-output. As the change-outputs are always P2PKH outputs, it is possible
to determine the payment-output type. Out of all outputs created about 31.7% are
P2PKH, 23.3% are P2SH, 0.34% are P2WPKH, and less than 0.01% are P2WSH
payment-outputs. The remaining 45.5% are P2PKH change-outputs. The most commonly
used input-output combinations are <em>P2PKH ⇒ P2PKH + P2PKH</em> with 33%,
<em>P2PKH ⇒ P2SH + P2PKH</em> with 26%, and <em>P2PKH ⇒ P2PKH</em> with around 7%.</p>
<br>
<!-- raw HTML omitted -->
<p>Users of the Blockchain.com wallet are most active between 15:00 UTC and 18:00
UTC and least active between 4:00 UTC and 5:00 UTC. At around 5:00 UTC, the
number of transactions per minute starts to rise. At this time it is 8am in
Moscow, and 7am in central Europe. Between 5:00 UTC and 10:00 UTC, the number
of transactions per minute rises from about 30 to just above 60. The
transactions per minute remain constant until rising again at noon UTC, which is
8am on the US east coast. The daily maximum is reached at around 16:00 UTC with
just above 75 transactions per minute. From there on, the activity declines
until reaching the minimum number of transactions per minute at around 4:00 UTC
again.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/time-of-day.png" alt="Activity hours of Blockchain.com wallet users.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    The transactions broadcast per minute with Blockchain.com wallets are shown. The
error bands show the standard deviation. The time between 8am and 8pm is
marked for central Asia, Europe, and eastern US timezones.
</p>
<br>
<!-- raw HTML omitted -->
<p><a href="https://thecryptofeed.net/articles/blockchain-com-says-they-account-for-a-third-of-all-bitcoin-transactions/">Reportedly</a>, Blockchain.com claims that their wallets are responsible for
one-third of all Bitcoin transactions. They <a href="https://www.blockchain.com/charts/my-wallet-n-tx">publish</a> the daily number of
transactions sent by their wallets. This lead to a discussion on the accuracy
and correctness of these numbers. The described dataset can be used to verify
this claim. The number of daily transactions in the dataset and the published
numbers can be compared. The total number of transactions sharing the
fingerprint with the Blockchain.com wallet transactions acts as an upper-bound.
The total transactions per day are retrieved from <a href="https://transactionfee.info/charts/transactions-per-day/">transactionfee.info</a> to
calculate Blockchain.com’s share of the network.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/one-third.png" alt="Showing that the Blockchain.com published numbers could be reasonably accurate.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>The daily transaction count published by Blockchain.com translates into a
network share of 30% to 35%. The share of the transactions with the same
fingerprint, the upper-bound, is on average about three absolute percent higher.
The share of the identified transactions in the dataset is about four to five
absolute percent lower than the Blockchain.com reported numbers at around 27% on
average. The transactions account for about 13% of the daily fees paid, and 20%
of the daily block space used.</p>
<p>However, the numbers reported by Blockchain.com still lie in a reasonable range.
There are multiple reasons why the described dataset could contain fewer
transactions than are reported by Blockchain.com. Some users might send
transactions with a custom feerate. These are not picked up by the described
methodology. Furthermore, it’s not clear if the reported numbers include
transactions send with the <a href="https://www.blockchain.com/de/api/blockchain_wallet_api">Blockchain.com Wallet API</a>. The API allows
users to construct transactions sending to multiple recipients which are not
accounted for in the described dataset.</p>
<br>
<!-- raw HTML omitted -->
<p>With the knowledge that the Blockchain.com Web wallet underpaid the recommended
feerate for transactions with two outputs, and the iOS wallet
overpays on transactions with one output, the wallet’s shares can be estimated.
For this, the assumption that the ratio of two-output to one-output transactions
is similar in all wallets must hold. The Web wallet accounts for one-third and
the iOS wallet for half of the Blockchain.com wallet transactions. The Android
wallet probably accounts for a majority of the remaining 17%. However, this can
not be verified as no data is indicating the share of the Android wallet.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/web-wallet-share.png" alt="Share of Web wallet transactions with two outputs.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    Between April 1st and April 22nd, the two-output transactions send with the Web
wallet made up for about a third of all two-output transactions send with
Blockchain.com wallets. The shown mean is weighted with the transaction counts.
A fix <a href="https://github.com/blockchain/blockchain-wallet-v4-frontend/releases/tag/v4.32.6">released</a> on April 21st resolved the underpaying behavior for
two-output transactions in the Web wallet. It took a few days until the release
got deployed.
</p>
<figure></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://b10c.me/mempool-observations/3-blockchaincom-recommendations/">https://b10c.me/mempool-observations/3-blockchaincom-recommendations/</a></em></p>]]>
            </description>
            <link>https://b10c.me/mempool-observations/3-blockchaincom-recommendations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820109</guid>
            <pubDate>Mon, 13 Jul 2020 12:41:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing a type-safe Stripe client for serverless using TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820024">thread link</a>) | @protoduction
<br/>
July 13, 2020 | https://guido.io/posts/using-stripe-in-serverless-typescript/ | <a href="https://web.archive.org/web/*/https://guido.io/posts/using-stripe-in-serverless-typescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
<p>In my current project I am trying to go full origin-less: everything runs in a CloudFlare worker script, there is no centralized server. These serverless Javascript environments often don’t run on Node, so there are a lot of libraries you can’t use.</p>
<p>This makes going fully serverless painful, so far I had to implement the client code for <a href="https://guido.io/posts/sending-email-from-cloudflare-workers">Mailgun</a>, BigQuery and Stripe myself. Each of these has a great SDK for Node, but unfortunately we can’t use those. This is a big downside of going fully serverless: you end up implementing these clients or finding workarounds instead of building your own application.</p>
<p>Fortunately, it turns out that for Stripe it’s easy to write a type-safe client without too much code. <strong>This is where Typescript really shines.</strong></p>
<h2 id="setup">Setup<a href="#setup">#</a></h2>
<p>First we install the Stripe Node client, we will only use its typings so we can install it as a dev dependency.</p>
<pre><code>npm install --save-dev stripe
</code></pre><p>Also we’ll be using the <code>qs</code> NPM package, we use it to turn arbitrarily nested JSON objects into query strings.</p>
<pre><code>npm install --save qs
</code></pre><h2 id="writing-our-own-client">Writing our own client<a href="#writing-our-own-client">#</a></h2>
<p>Below is all there is to the client. It currently only implements a single operation (for creating customers), but it’s trivial to add more.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span></code></pre></td>
<td>
<pre><code data-lang="typescript"><span>import</span> { <span>Stripe</span> } <span>from</span> <span>"stripe"</span>;
<span>import</span> { <span>stringify</span> } <span>from</span> <span>"qs"</span>;

<span>const</span> <span>STRIPE_SECRET_KEY</span> <span>=</span> <span>"please-dont-actually-hardcode-your-api-secret-here-but-store-it-more-safely"</span>;
<span>const</span> <span>STRIPE_API_URL</span> <span>=</span> <span>"https://api.stripe.com"</span>;


<span>export</span> <span>async</span> <span>function</span> <span>createCustomer</span>(<span>body</span>: <span>Stripe.CustomerCreateParams</span>) {
    <span>return</span> <span>fetchStripe</span>(<span>"/v1/customers"</span>, <span>body</span>, {
        <span>method</span><span>:</span> <span>"POST"</span>,
    });
}

<span>async</span> <span>function</span> <span>fetchStripe</span>(<span>endpoint</span>: <span>string</span>, <span>body?</span>: <span>any</span>, <span>init</span>: <span>RequestInit</span> <span>=</span> {})<span>:</span> <span>Stripe</span>.<span>Customer</span> {
    <span>init</span> <span>=</span> {
        ...<span>init</span>,
        <span>body</span>: <span>body</span> <span>?</span> <span>stringify</span>(<span>body</span>) <span>:</span> <span>undefined</span>,
        <span>headers</span><span>:</span> {
            ...<span>init</span>.<span>headers</span>,
            <span>"Accept"</span><span>:</span> <span>"application/json"</span>,
            <span>"Content-Type"</span><span>:</span> <span>"application/x-www-form-urlencoded"</span>,
            <span>"Authorization"</span><span>:</span> <span>`Bearer </span><span>${</span><span>STRIPE_SECRET_KEY</span><span>}</span><span>`</span>
        },
        
    }
    <span>const</span> <span>url</span> <span>=</span> <span>STRIPE_API_URL</span> <span>+</span> <span>endpoint</span>;
    <span>const</span> <span>response</span> <span>=</span> <span>await</span> <span>fetch</span>(<span>url</span>, <span>init</span>);

    <span>// Note this line will throw in case we can't reach Stripe, error handling could be improved!
</span><span></span>    <span>const</span> <span>j</span> <span>=</span> <span>await</span> <span>response</span>.<span>json</span>();

    <span>if</span> (<span>!</span><span>response</span>.<span>ok</span> <span>||</span> <span>response</span>.<span>status</span>.<span>toString</span>()[<span>0</span>] <span>!==</span> <span>"2"</span>) {
        <span>throw</span> <span>new</span> Error(<span>`Stripe API call failed to </span><span>${</span><span>endpoint</span><span>}</span><span> (</span><span>${</span><span>response</span>.<span>status</span><span>}</span><span>): </span><span>${</span><span>JSON</span>.<span>stringify</span>(<span>j</span>)<span>}</span><span>`</span>);
    }
    <span>return</span> <span>j</span>;
}
</code></pre></td></tr></tbody></table>
</div>
</div><h3 id="using-it">Using it<a href="#using-it">#</a></h3>
<p>Now we can call the above code like this to create a new customer:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="typescript"><span>const</span> <span>customer</span> <span>=</span> <span>await</span> <span>createCustomer</span>({<span>name</span><span>:</span> <span>"Jane Doe"</span>, <span>email</span><span>:</span> <span>"jane@example/com"</span>});
<span>console</span>.<span>log</span>(<span>`Customer created with id </span><span>${</span><span>customer</span>.<span>id</span><span>}</span><span>`</span>);
</code></pre></td></tr></tbody></table>
</div>
</div><p>The nice thing is that as we are using Typescript this will actually be typechecked as we are using the typings from the official Stripe NPM package. What that means is that your code-editor can autocomplete the fields, and if you add fields that are invalid the Typescript compiler will tell you.</p>


    
  </article></div>]]>
            </description>
            <link>https://guido.io/posts/using-stripe-in-serverless-typescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820024</guid>
            <pubDate>Mon, 13 Jul 2020 12:30:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU: A Heuristic for Bad Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23819964">thread link</a>) | @some_furry
<br/>
July 13, 2020 | https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>If you see the letters GNU in a systems design, and that system intersects with cryptography, I can almost guarantee that it will be badly designed to an alarming degree.</p>



<p>This is as <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">true of GnuPG (and PGP in general)</a> as it is of designs like the proposed <a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html">GNU Name System</a> (IETF draft) and cryptographic libraries like GnuTLS and libgcrypt. In fact, I cannot recall single GNU-branded cryptography project that isn’t a roaring dumpster fire.</p>



<p>I will elaborate.</p>



<h2>Problems with the GNU Name System’s Cryptography</h2>



<h3>Asymmetric Cryptography</h3>



<p>The GNS (GNU Name System) uses an unconventional construction for zones:</p>



<blockquote><p>A zone in GNS is defined by a public/private ECDSA key pair (d,zk), where d is the private key and zk the corresponding public key. GNS employs the curve parameters of the twisted edwards representation of Curve25519 [<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC7748">RFC7748</a>] (a.k.a. edwards25519) with the ECDSA scheme ([<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC6979">RFC6979</a>]).</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-zones">GNU Name System IETF Draft, section 2</a></cite></blockquote>



<p>This is beyond weird: Going out of your way to use the edwards25519 curve from RFC 7748, but not use the Ed25519 signature algorithm, but still choosing to use deterministic ECDSA (RFC 6979).</p>



<p>(If you’re lost, I wrote about digital signature algorithms in <a href="https://soatok.blog/2020/04/26/a-furrys-guide-to-digital-signature-algorithms/">a previous blog post</a>.)</p>



<p>The authors acknowledge the unconventional nature of their design choice in section 9.1 of the RFC draft:</p>



<blockquote><p>GNS uses ECDSA over Curve25519. This is an unconventional choice, as ECDSA is usually used with other curves. However, traditional ECDSA curves are problematic for a range of reasons described in the Curve25519 and EdDSA papers. <strong>Using EdDSA directly is also not possible, as a hash function is used on the private key which destroys the linearity that the GNU Name System depends upon.</strong> We are not aware of anyone suggesting that using Curve25519 instead of another common curve of similar size would lower the security of ECDSA. GNS uses 256-bit curves because that way the encoded (public) keys fit into a single DNS label, which is good for usability.</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-cryptography">GNU Name System IETF Draft, section 9.1</a></cite></blockquote>



<p><s>The bold statement (my emphasis) is nonsense: In any design that uses digital signature algorithms, your system should map a private key (some opaque byte string) to a public key (some other opaque byte string) and signatures should also be opaque byte strings. The inclusion of a hash function under the hood of the signature algorithm is a moot point, especially since RFC 6979 also uses HMAC-SHA2 to generate deterministic nonces, thereby rendering their choice of RFC 6979 a contradiction of their stated goal.</s> Edit: <a href="#update-2020-07-09">see below</a>.</p>



<p>Using Ed25519 with a 32-byte private key (instead of a 64-byte private key) is also trivial. To wit: Libsodium offers <a href="https://libsodium.gitbook.io/doc/public-key_cryptography/public-key_signatures#key-pair-generation">crypto_sign_seed_keypair()</a> for this purpose.</p>



<p>But even worse: ECDSA is less secure and slower than EdDSA, even when you use the same curves, due to how the algorithms are implemented. The authors of the RFC do not defend this design choice beyond this hash function non sequitur.</p>



<div><figure><img data-attachment-id="116" data-permalink="https://soatok.blog/soatok_stickerpack-facepaw/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Facepaw!" data-image-description="<p>Facepaw!</p>
" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" alt="Facepaw" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>I can’t be the only one feeling this way right now. Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.</figcaption></figure></div>



<h4 id="update-2020-07-09">(Update) “But They Need Hierarchical Keys”</h4>



<p>After I initially posted this, Redditor Steve132 informed me that <a href="https://www.reddit.com/r/crypto/comments/hnlyp1/gnu_a_heuristic_for_bad_cryptography/fxdbez4/">I overlooked the reason they made this design decision</a>.</p>



<blockquote><p>Take a look at Section 6.1&nbsp;<a rel="noreferrer noopener" href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion" target="_blank">https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion</a></p><blockquote><p>From here, the following steps are recursively executed, in order: Extract the right-most label from the name to look up. Calculate q using the label and zk as defined in Section 4.1.</p></blockquote><p>So then if you go to section 4.1, they do h=H(&lt;address string&gt;), (r,R) is some root keypair, then they do C (a child public key), C=hR, then q=H(C).</p><p>the idea behind the calculation of q is to use the root public key to derive a child public key from ONLY the root public key, exploiting the linearity property that in elliptic curves, if bG=B, then (b+s)G=(sG+B)</p><p>This allows a third party to derive child public keys without any knowledge of the private keys for the root. This technique is also used in bitcoin’s bip32 (<a rel="noreferrer noopener" href="https://en.bitcoin.it/wiki/BIP_0032" target="_blank">https://en.bitcoin.it/wiki/BIP_0032</a>) for ‘unhardened’ derivation scheme.</p><cite>Part of Steve132’s correction</cite></blockquote>



<p>I fully admit, I didn’t absorb this detail in my first pass of the RFC draft. It wasn’t clearly spelled out in Section 9 (which aims to justify their cryptography decisions), and I didn’t read the other sections as carefully. This was my mistake.</p>



<p>However, even with this explanation in mind, my original point that this design choice is both unconventional and unnecessary still stands, because <a href="https://ieeexplore.ieee.org/abstract/document/7966967?section=abstract">BIP32-Ed25519</a> already exists (albeit, it still needs <a href="https://forum.web3.foundation/t/key-recovery-attack-on-bip32-ed25519/44">a carefully designed implementation</a> to be secure against active attackers). </p>



<p>Therefore, the GNU Name System developers didn’t need to roll their own design, they could have used one that’s already seen real-world deployment instead. Why take on unnecessary risk?</p>



<p>Furthermore, trying to push through an implementation of ECDSA over edwards25519 isn’t just unnecessary and weird, it’s also probably dangerous, as Thai Duong noted:</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">While I don't agree that ECDSA is worse than Ed25519 – both have pros and cons — it takes courage to implement ECDSA over Edward25519. Do you know if they published any code?  This unfortunate marriage may introduce fun and unique bugs</p>— thaidn (@XorNinja) <a href="https://twitter.com/XorNinja/status/1281041946538938368?ref_src=twsrc%5Etfw">July 9, 2020</a></blockquote></div>
</div><figcaption>Thai Duong–author of the BEAST attack against SSL/TLS, among <a href="https://github.com/google/tink">other</a> <a href="https://github.com/google/wycheproof">things</a></figcaption></figure>



<p>Of course, all cryptography development can be said to be dangerous, but there are other problems fundamental to the GNU Name System design that makes any departure from a well-tread path very suspect.</p>



<h3>Symmetric Cryptography</h3>



<p>The GNU Name System project doesn’t stop there. It further throws <a href="https://tonyarcieri.com/all-the-crypto-code-youve-ever-written-is-probably-broken">IND-CCA2 security</a> out the window and specifies encrypting with AES and TwoFish in a cipher cascade, using Cipher Feedback (CFB) mode.</p>



<p>The authors do not even attempt to defend this decision. Typically this happens when the authors do not understand the risks involved. I sincerely doubt they’ve heard the words “adaptive chosen-ciphertext attack” in the course of their self-study.</p>



<p>(Because, y’know, attackers will surely never be able to replay UDP traffic if a runtime exception occurs because of corrupted data.)</p>



<h4>“Why Is This Bad?”</h4>



<p>Cipher cascades are usually the result of “we want to defend against a backdoored or broken cipher”. Bear in mind, the cipher itself is rarely the first part of a cryptosystem to be broken.</p>



<p>On that note, TwoFish isn’t <a href="https://blog.cryptographyengineering.com/2012/10/09/so-you-want-to-use-alternative-cipher/">the worst choice</a> of a cascade partner for AES, but I’d prefer a design that employed a different paradigm (since AES is a SPN permutation block cipher, an ARX-based stream cipher like Salsa20 or ChaCha seems reasonable).</p>



<p>AES is a boring choice, because it’s the industry standard. I’m not <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">particularly fond of AES</a> (due to it not being fast and constant-time in pure software implementations), but if you use it in an authenticated mode (AES-GCM, AES-CCM, AES-EAX, AES-OCB3, … I dunno, Poly1305-AES? Just use an AEAD mode!), it’s fine.</p>



<p><strong>Cipher Feedback (CFB) mode is not an authenticated mode.</strong></p>



<p>If you’re publishing a cryptography design in 2020 that fails the <a href="https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html">Cryptographic Doom Principle</a>, you need to go back to the drawing board.</p>



<h4>“But They Use Digital Signatures”</h4>



<p><a href="https://blog.cryptographyengineering.com/2016/03/21/attack-of-week-apple-imessage/">Cough.</a></p>







<h2>Other GNU Projects</h2>



<p>If you want to learn about why GnuPG (and the PGP ecosystem in general) is terrible, I recommend <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">Latacora’s takedown</a>.</p>



<p>GnuTLS is an SSL/TLS library created by the same people who created (and then abandoned) libmcrypt, which was the scourge of <a href="https://meta.stackoverflow.com/questions/293930/problematic-php-cryptography-advice-in-popular-questions">bad cryptography in the PHP ecosystem</a> for many years (until it was <a href="https://wiki.php.net/rfc/mcrypt-viking-funeral">finally excised in PHP 7.2</a>). Consequently, the project’s <a href="https://www.gnutls.org/security-new.html">CVE history</a> should be no surprise.</p>



<p><strong>Quick story:</strong> Many years ago, a few timing attacks were discovered in libgcrypt by regular chatters in Freenode’s ##crypto channel. This led a lot of us <a href="https://lists.gnupg.org/pipermail/gcrypt-devel/2015-November/003618.html">to look at libgcrypt for more bugs</a>.</p>



<p>The general consensus of the ensuing IRC discussion was, roughly, “We probably shouldn’t try to fix them all, because a) that’s way too much effort because there’s too much badness and b) this library will be a ripe target for upcoming cryptanalysis researchers to get their first papers published for many years”. And, indeed, the attack papers that have come out over the years that affect libgcrypt <a href="https://eprint.iacr.org/2020/432">haven’t disappointed</a>.</p>



<p>To be clear, at the time this happened, I was garbage at writing C (and somehow even less confident than capable) and barely making ends meet, so “drop everything and volunteer to fix all the libgcrypt badness” wasn’t a tenable option for me. And since the world is largely moving away from GnuPG and libgcrypt, it honestly isn’t worth the effort trying to fix all the bad when an easier fix is “use something good instead”.</p>



<h2>Takeaway</h2>



<p>If you see the letters GNU anywhere in a project that intersects with cryptography–except for its public license–it’s almost certainly an error-prone cryptographic design.</p>



<p>Or, as my friend Kye calls it:</p>



<figure><div>

</div><figcaption>The Dunning-GNUger Effect.</figcaption></figure>



<h2>What To Use Instead?</h2>



<p>To replace GPG, you want <a href="https://age-encryption.org/">age</a> and <a href="https://jedisct1.github.io/minisign/">minisign</a>.</p>



<p>To replace GnuTLS or libgcrypt, depending on what you’re using it for, you want one of the following: s2n, OpenSSL/LibreSSL, or Libsodium.</p>



<p>For embedded systems, BearSSL is a good options today and <a href="https://www.reddit.com/r/crypto/comments/hdc4o6/new_results_on_gimli_fullpermutation/fvmpnym/">libhydrogen v2</a> will be an attractive choice when it’s released.</p>



<hr>



<p>Header image, like the GnuNet logo <a href="https://commons.wikimedia.org/wiki/File:Official_logo_of_the_GNUnet_project.svg">found here</a>, is available under the&nbsp;<a href="https://en.wikipedia.org/wiki/en:Creative_Commons">Creative Commons</a>&nbsp;<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">Attribution-Share Alike 4.0 International</a>&nbsp;license.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819964</guid>
            <pubDate>Mon, 13 Jul 2020 12:24:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Download 3D Capture Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819949">thread link</a>) | @harryhuge
<br/>
July 13, 2020 | https://blog.display.land/blog/how-to-download-3d-capture-data | <a href="https://web.archive.org/web/*/https://blog.display.land/blog/how-to-download-3d-capture-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="Top"><div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5dcdcdee9b5db73a7e73c483_display_land_logo_alt.png" srcset="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5dcdcdee9b5db73a7e73c483_display_land_logo_alt-p-500.png 500w, https://assets.website-files.com/5dcbeae998ba40131bdc3053/5dcdcdee9b5db73a7e73c483_display_land_logo_alt.png 729w" sizes="(max-width: 767px) 50vw, (max-width: 991px) 364px, 470px" alt=""></p></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>You can easily access and download your OBJ, GLTF, or PLY files as well as your capture videos directly from the Display.land app or any Display.land link on the web. ‍Please note, you may not be able to download the 3D mesh files on some older captures.</p><p><strong>To Download 3D Mesh in App:&nbsp;</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the share button on your capture</li><li>Click the Download Mesh icon</li><li>Select the file type you wish to download ( PLY, GLTF, or OBJ are the current options) and click the “Send Link” button next to your selection</li><li>Decide which method you want to use to share the download link (email, text message, etc)</li><li>Send the link</li><li>Download your files upon receipt as the links expire after one hour&nbsp;</li></ol><p>Downloads will contain the model for your full capture. Any cropping or 3d object additions will not be represented in your mesh download. If you are on iOS, the easiest way to share the file is through AirDrop.</p><p>‍</p><p>‍</p><figure id="w-node-e6c233e781d3-7dd620db"><p><img src="https://assets.website-files.com/5dcbef1d294b88f5b63cc7b8/5efe126ffeee90470943d2dd_VwNAsIKviU7T2bxBVE_uWBfk0WmAIht0mSsyYJahcIBktL0pJyDS0YggfcUNiqVasGBxwRPiLCroraCAGR3KE1-U1L2Tl8rYnCZDsRLxRzFn6Cb9W1O2h6l1eSd5l3PGF7JLsDZZ.gif" alt=""></p></figure><p><strong>To Download Videos in App</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the Share button on your capture</li><li>Click the Download Video button</li></ol><p><strong>To Download 3D Mesh and Videos on Desktop:&nbsp;</strong></p><ol role="list"><li>Share the link of any capture with yourself and open it in the browser</li><li>Click login and then enter the phone number or email you used to sign up for Display.land</li><li>You will be sent a one time code, enter the code to login&nbsp;</li><li>Click the download icon on the top right hand corner&nbsp;</li><li>Download the video or 3D mesh</li></ol><p>‍</p></div></div></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>It’s been a wild three months.</p><p>From graffiti filled streets in Spain to underground bunkers in Sausalito, subway stations in Tokyo to industrial kitchens in Texas, the <a href="http://display.land/" target="_blank">Display.land</a> community has been blowing our minds every morning by capturing, sharing and exploring each others’ spaces from around the world during our early access period.</p></div><p>Capture any space with the device you already own — from as small as a courtyard to entire city blocks</p><p><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb33727eef326_5dcf4fc0ef6ed980fcb238cf_SpaceLog.gif" alt=""></p><p>Edit insanely fast — changes you make to your spaces are rendered and saved in real time.</p><p><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb3d565eef327_image1.gif" alt=""><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb3434ceef32a_5dcf5532edfe6a4895625067_Crop.gif" alt=""><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb359d0eef32c_5dcf66bc0336825220e906e3_Notes2%202.gif" alt=""></p><p>Instantly share your spaces via web links and videos, or freely export them as 3D models</p><p><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb3b5c3eef329_5dcf6523b8df8173b2281bf2_MEshDownload.gif" alt=""></p><p>Explore the world and join a community of global explorers in 50 countries</p><p><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb3d3c2eef32b_5dcf61a3c5a7ed55b2508d7f_locations.gif" alt=""></p><p>We started U6 with the mission to unlock new ways for people to create and connect in the physical spaces they care about, such as our <a href="https://www.nbcbayarea.com/news/tech/SFMOMA-is-Putting-the-AR-in-Art-With-Augmented-Reality-Exhibits-490879581.html" target="_blank">PlaySFMOMA space</a> last year.</p><div><p>To create that experience, we captured the SF MOMA’s physical space in 3D using a commodity smartphone, edited and authored it remotely in a web browser, and allowed hundreds of people to browse and experience the sandbox together in real time from their own devices onsite in AR, and remotely via desktop and webVR browsers.</p><p>With today’s release, we’re beginning to put those same tools in everybody’s hands, with the goal of building and improving our roadmap in public with our community.</p></div><p><em>Unlocking a new digital canvas for creativity and shared experiences.</em></p><div><p><em>‍</em>Our goal is to grow <a href="http://display.land/" target="_blank">Display.land</a> into a destination where people can create, share and explore together in new, immersive and interactive ways.</p><p>We believe the best way to achieve this is by releasing often and publicly, supporting our earliest creators, and constantly increasing access to creative tools only previously available to high end gaming, graphics and 3D professionals. In the coming months, you can expect to see regular updates along this path.</p><p>‍<a href="http://display.land/" target="_blank">Display.land</a> is for those of us who see art in reality. If this sounds like something you’re interested in working on, shoot us a note! We’re working on some of the hardest challenges in computer vision, graphics and multiplayer networking <a href="http://ubiquity6.com/careers/" target="_blank">and are hiring actively.<p>‍</p></a>-Anjney &amp; Ankit<br>Co-founders, Ubiquity6<br>‍</p></div></div></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>Creators! Did you know that you can download any of your captures as a 3D model?&nbsp;</p><p>We currently support OBJ, GLTF, and PLY file formats, which make it possible to use captures from Display.land in Blender, Cinema4D, Unity, Unreal, Maya, and most other popular creative software applications.<br></p></div><p><img src="https://assets.website-files.com/5e2087d429083a49637cf369/5e2087d429083a4abd7cf39e_image5.gif" alt=""></p><div><p>To download the 3D mesh, just open one of your captures in a desktop web browser, and click the download button in the upper-right corner of the screen. You’ll need to be logged in to see it.<br>‍<br>If you are on iOS, the easiest way to open your capture in a browser is through AirDrop. You can AirDrop yourself the link to the desired capture by opening the Share Menu and pressing “More.” From there, a new menu will open giving you the option to airdrop the link.&nbsp;<br>‍<br>If you are on Android, we find it is easiest to email yourself the link. Open the Share Menu and press “More.” From there, choose email or whatever the best option is for you.</p><p>Note: Your download will contain the model for your full capture. Any cropping or 3d object additions will not be represented in your mesh download.</p></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5dd2cb02c54c887bca1c6e9f_image1.gif" alt=""></p><div><p>Once your 3D mesh has downloaded, this is where the magic begins. You now have the opportunity to create phenomenal artwork using captured physical reality. Try challenging the mundane by drawing in the absurd. </p><p>Or, experiment with contrasting elements. The opportunities are endless and the boundaries are limitless. Check out what our creators have made with Display.land below.</p></div></div><p><img src="https://assets.website-files.com/5e2087d429083a49637cf369/5e2087d429083a79467cf3a2_image9.gif" width="293" alt=""><img src="https://assets.website-files.com/5e2087d429083a49637cf369/5e2087d429083ae1467cf3a3_image11.gif" width="268" alt=""></p><p>We absolutely love to see what our Creators create using their Display.land meshes. In fact, we have an entire Discord channel dedicated to them! You can find this channel here: <a href="https://discord.gg/b2vxQpu">https://discord.gg/b2vxQpu</a>.<br>We can’t wait for you to join and to see how Display.land has inspired you. ✨<br></p></div></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>You can easily access and download your OBJ, GLTF, or PLY files as well as your capture videos directly from the Display.land app or any Display.land link on the web. ‍Please note, you may not be able to download the 3D mesh files on some older captures.</p><p><strong>To Download 3D Mesh in App:&nbsp;</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the share button on your capture</li><li>Click the Download Mesh icon</li><li>Select the file type you wish to download ( PLY, GLTF, or OBJ are the current options) and click the “Send Link” button next to your selection</li><li>Decide which method you want to use to share the download link (email, text message, etc)</li><li>Send the link</li><li>Download your files upon receipt as the links expire after one hour&nbsp;</li></ol><p>Downloads will contain the model for your full capture. Any cropping or 3d object additions will not be represented in your mesh download. If you are on iOS, the easiest way to share the file is through AirDrop.</p><p>‍</p><p>‍</p><figure id="w-node-e6c233e781d3-7dd620db"><p><img src="https://assets.website-files.com/5dcbef1d294b88f5b63cc7b8/5efe126ffeee90470943d2dd_VwNAsIKviU7T2bxBVE_uWBfk0WmAIht0mSsyYJahcIBktL0pJyDS0YggfcUNiqVasGBxwRPiLCroraCAGR3KE1-U1L2Tl8rYnCZDsRLxRzFn6Cb9W1O2h6l1eSd5l3PGF7JLsDZZ.gif" alt=""></p></figure><p><strong>To Download Videos in App</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the Share button on your capture</li><li>Click the Download Video button</li></ol><p><strong>To Download 3D Mesh and Videos on Desktop:&nbsp;</strong></p><ol role="list"><li>Share the link of any capture with yourself and open it in the browser</li><li>Click login and then enter the phone number or email you used to sign up for Display.land</li><li>You will be sent a one time code, enter the code to login&nbsp;</li><li>Click the download icon on the top right hand corner&nbsp;</li><li>Download the video or 3D mesh</li></ol><p>‍</p></div></div></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>You can easily access and download your OBJ, GLTF, or PLY files as well as your capture videos directly from the Display.land app or any Display.land link on the web. ‍Please note, you may not be able to download the 3D mesh files on some older captures.</p><p><strong>To Download 3D Mesh in App:&nbsp;</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the share button on your capture</li><li>Click the Download Mesh icon</li><li>Select the file type you wish to download ( PLY, GLTF, or OBJ are the current options) and click the “Send Link” button next to your selection</li><li>Decide which method you want to use to share the download link (email, text message, etc)</li><li>Send the link</li><li>Download your files upon receipt as the links expire after one hour&nbsp;</li></ol><p>Downloads will contain the model for your full capture. Any cropping or 3d object additions will not be represented in your mesh download. If you are on iOS, the easiest way to share the file is through AirDrop.</p><p>‍</p><p>‍</p><figure id="w-node-e6c233e781d3-7dd620db"><p><img src="https://assets.website-files.com/5dcbef1d294b88f5b63cc7b8/5efe126ffeee90470943d2dd_VwNAsIKviU7T2bxBVE_uWBfk0WmAIht0mSsyYJahcIBktL0pJyDS0YggfcUNiqVasGBxwRPiLCroraCAGR3KE1-U1L2Tl8rYnCZDsRLxRzFn6Cb9W1O2h6l1eSd5l3PGF7JLsDZZ.gif" alt=""></p></figure><p><strong>To Download Videos in App</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the Share button on your capture</li><li>Click the Download Video button</li></ol><p><strong>To Download 3D Mesh and Videos on Desktop:&nbsp;</strong></p><ol role="list"><li>Share the link of any capture with yourself and open it in the browser</li><li>Click login and then enter the phone number or email you used to sign up for Display.land</li><li>You will be sent a one time code, enter the code to login&nbsp;</li><li>Click the download icon on the top right hand corner&nbsp;</li><li>Download the video or 3D mesh</li></ol><p>‍</p></div><div><div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf1c35d8bac609f16a41d_image3.png" alt=""></p></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf2a0dec349712cccc551_image10.png" alt=""></p><div><h4>+ CLIP =</h4><p>Clips your trailer so you can insert more than one series of frames into your trailer</p></div></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf1c4c1617c1da77921f5_image5.png" alt=""></p><div><h4>+ DELETE =</h4><p>Undoes the last action or series of actions that you took</p></div></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf29fb26089c6ab3fafac_image7.png" alt=""></p><div><h4>CLEAR =</h4><p>Clears everything you have done (you can not undo this action, so be careful!)</p></div></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf1c4dec34956f7ccb968_image6.png" alt=""></p><div><h4>PLAY =</h4><p>At any time during your custom trailer creation, you can hit the play button to see how your trailer is coming together.</p></div></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf29fd87988654de420bd_image8.png" alt=""></p><div><h4>SAVE (only shows up once you hit the play button to preview your trailer) =</h4><p>Saves the progress on your freshly created custom trailer!</p></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://blog.display.land/blog/how-to-download-3d-capture-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819949</guid>
            <pubDate>Mon, 13 Jul 2020 12:21:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Douglas Mason: How to Build ML Solutions for Twitter, Pinterest and Amazon Music]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819921">thread link</a>) | @FHMS
<br/>
July 13, 2020 | https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>We caught up with <a href="https://www.linkedin.com/in/douglas-mason-9a500713/"><strong>Douglas Mason</strong></a>, data scientist and CEO of <a href="https://www.koyotescience.com/">Koyote Science</a>, where he is building machine learning models to predict COVID-19 outbreaks. He freely shared his wisdom and lessons he has learned from over a decade of data science work, ranging from his PhD at Harvard to his time at large companies such as Pinterest, Twitter, and AWS (Amazon).</p><h2><strong>Douglas’s background</strong></h2><p>Douglas took a unique path to becoming a data scientist. Although computers were always part of his household growing up, he thought they were boring, and he told his family he would “never study computer science.”</p><p>Instead, Douglas went to USC to study filmmaking, thinking he’d follow his dream of becoming a film director. Soon, he realized that filmmaking school wasn’t all he’d imagined it would be, and he took up classical guitar instead. From there, he accidentally discovered a passion for theoretical physics, which he found fascinating (and which paid more than guitar playing).</p><p>Not long after, Douglas discovered his interest in data science and climbed the ranks until he was heading engineering and data science teams at Twitter, Pinterest, and AWS. He describes working in the field as feeling like he’s living in a science fiction film.</p><blockquote>“When I work on that kind of stuff, I feel like Doctor Strange — as if I’m in the Multiverse. You actually get to live this Rick and Morty parallel-universe life.”</blockquote><p>But Douglas wasn’t content with using his expertise to improve revenue at large corporations, so he went on to found his own business, Koyote Science. He’s currently focused on building COVID-19 models to predict outbreaks.</p><h2><strong>Lessons learned from shipping machine learning projects</strong></h2><p>Douglas’s success hasn’t come without some hard-earned lessons. He told us about some of the challenges he’s seen across many of the teams and projects he’s worked on.</p><h3><strong>Lesson 1: Use machine learning to work with users instead of taking over&nbsp;</strong></h3><p>At Twitter, Douglas worked on a feature called “who to follow.” This gives Twitter users personalized recommendations about which accounts might be interesting for them. As a data scientist, Douglas discovered that people used this feature a lot. At first, it seemed great — people were following nearly everyone it recommended. But in the longer term, people who used this feature <strong>visited Twitter less</strong>.&nbsp;</p><p>Their feeds were filled with tweets chosen <strong>by an algorithm</strong>, rather than tweets from people they chose<strong> </strong>themselves — and there were just too many of them.</p><p>By reducing<strong> </strong>the number of “who to follow” recommendations, Douglas improved <strong>long-term</strong> engagement.</p><p>It’s common knowledge that long-term and short-term goals often conflict, but Douglas discovered a deeper lesson here. As machine learning solutions become more capable, it’s often tempting to use them to do too much. This is almost always a mistake. Douglas says:</p><blockquote>“I aim to build products that work with the user rather than trying to take over from the user.”</blockquote><p>AI as depicted in science fiction — with human-level intelligence — is probably to blame for the fact that many people try to <strong>do too much </strong>with machine learning. In many cases, it’s best used to <strong>augment </strong>human actions rather than replace them.</p><h3><strong>Lesson 2: Data pipelines and good engineering are more important than math and algorithms</strong></h3><p>People get very excited about <strong>new machine learning algorithms</strong>. First we had neural networks (NNs), then convolutional neural networks (CNNs), then generative adversarial networks (GANs), transformers, and more. Algorithms are fun and exciting to talk about and explore.</p><p>But Douglas, a self-confessed math nerd, has learned that the math and algorithms tend to get far too much attention, while real success comes from <strong>good data, good engineering, focusing on the customer’s problem, </strong>and <strong>not getting trapped in the math.</strong> He says:</p><blockquote>“It's very, very rare for the algorithm to make the difference. It's almost always the data pipeline. In my work, I have been able to reduce errors by 90% with a data pipeline, compared to 75% with a better algorithm. And yet everyone wants to talk to me about the algorithm, but no one wants to talk about the data pipeline.”</blockquote><p>We use metaphors that associate machine learning algorithms with neuroscientists and data pipelines with plumbing, so it’s not surprising which one grabs popular attention. Douglas found success by focusing on the less glamorous aspects of machine learning. In most cases, deciding <strong>what data to use </strong>and <strong>how to present it to the algorithm</strong> is more important than the algorithm itself.</p><h4>Focus on the customer’s goals</h4><p>Many “AI startups” today talk far more about <strong>the solutions they provide</strong> than the <strong>problems they solve</strong>, and Douglas has learned to maintain a laser focus on customer goals. Sometimes this means pulling himself away from the more enticing theoretical aspects of machine learning. He says:&nbsp;</p><blockquote>“As a mathematician, I love all the nuances of the math, and easily get lost in it. But the reality is that there's an infinite amount of math out there to learn. It's not feasible to lock myself in my room and learn all the math before I focus on customer goals.”</blockquote><p>The truth that many data scientists don’t want to hear is that successful machine learning solutions are not usually about creating something new, powerful, and exciting. More often, seeing problems from the correct angle and using tried and tested approaches is what you need.</p><h4>Work with and learn from experienced engineers</h4><p>Douglas has personally engineered many successful machine learning solutions and led teams of software engineers, but he remains modest about his engineering ability and emphasizes the <a href="https://datarevenue.com/en-blog/hiring-machine-learning-engineers-instead-of-data-scientists">importance of <strong>solid engineering</strong></a>.</p><blockquote>“At Amazon, I let the engineers do as much as possible, because they're better than me at engineering. I would love to give you another answer, but they're efficient, they're thoughtful, they've seen these structures before, so they know about implementation details.”</blockquote><p>It’s not all smooth sailing though. Douglas acknowledges the difficulties of getting different experts to work with each other, especially when highly technical people tend to have very strong opinions about tiny decisions.</p><p>The best way he’s found to get everyone on the same page is by constantly releasing Minimal Viable Products (MVPs), which takes us to our next lesson.</p><h3><strong>Lesson 3: Always build Minimum Viable Products (MVPs)</strong></h3><p>Douglas swears by MVPs, which demonstrate core pieces of a solution, even if many of the features are missing. When developing a machine learning solution, he’ll aim to deliver a new MVP <strong>every week.</strong></p><p>He uses these to:&nbsp;</p><ul role="list"><li><strong>Avoid traps: </strong>If a project is taking too long, the difficulty of building even an MVP can be used to argue that the project should be cut early, before years of effort are wasted. Douglas says:</li></ul><p>“If something ends up being way harder and I keep doing MVPs and never reach the goals, then that gives us information about the difficulty of what we're attempting to do.”</p><ul role="list"><li><strong>Communicate</strong>: Both technical and non-technical people tend to better understand things they can see and use, rather than abstract ideas.</li></ul><p>“People's response to an abstract concept of something is often completely different to their response when they see something real. That's why I'm always putting out MVPs. People who are looking from a higher-level perspective can gain the required intuition to give me feedback.”</p><p>It’s better to have to trash two weeks of work than two months, and MVPs can help with this.</p><p>MVPs have other benefits too. By releasing stripped-down versions of a solution, Douglas often discovers that less is more.</p><blockquote>“What you end up delivering is often much simpler than the thing you originally intended to do, but it's refined.”</blockquote><p>Of course, customers are sometimes unhappy when it turns out that the best solution was the simplest one. Douglas compares building machine learning solutions to creating art: it’s about the time that went into development, not the effort required for the final product.</p><blockquote>“There’s a classic Zen story about a king who hires an artist. The artist works for a year, but then paints the final painting in only three seconds. When the king complains, the artist says, ‘Oh, I spent a year trying to paint much harder things.’”</blockquote><p>MVPs keep you open to finding a <strong>better, simpler </strong>solution, even late in the development process, and it’s important to stay agile so you can pivot to these better solutions if necessary.</p><p>People often think something has to be <strong>complicated </strong>in order to be <strong>powerful</strong>,<strong> </strong>but in fact the opposite is often true.</p><h3><strong>Lesson 4: Control and precision are more important than size and power</strong></h3><p>Large machine learning models, such as GPT-3, are exciting and often make their way into headline news. But Douglas compares large models to early (failed) attempts to build planes. These planes competed against the famous, successful plane built by the Wright Brothers. What made them different? The Wright Brothers focused on <strong>control</strong>,<strong> </strong>while their competitors were going for <strong>size and power.</strong></p><blockquote>“What the Wright brothers did that was so ingenious was that they didn’t go for bigger engines. They were bicycle mechanics. They didn't even use powerful engines. And instead, what they focused on was control.”</blockquote><p>This is similar to machine learning models. As Douglas says:&nbsp;</p><blockquote>“We made the biggest model that does all this stuff. But then people ask, ‘How do I interpret this stuff?’ ‘How do I control it?’ ‘How do I make sure that my models don't go off the rails?’”</blockquote><p>Large machine learning models might often be more powerful, but unless they solve real problems, they’re not useful. If a model produces amazing results <strong>unpredictably</strong> and only <strong>some of the time</strong>, that’s not useful. If a model produces accurate results but we don’t <strong>understand why</strong> and can’t be sure the results will <strong>always be accurate</strong>, then that’s also not useful.</p><p>Instead, smaller, simpler, and arguably less powerful models that offer more <strong>interpretability</strong> and <strong>consistency</strong> are more valuable in nearly every case. Just like with flying, we need to be able to steer and to land, not just to go fast.</p><h2><strong>Shipping machine learning projects …</strong></h2></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819921</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a Data Delivery Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819918">thread link</a>) | @mildbyte
<br/>
July 13, 2020 | https://www.splitgraph.com/blog/data-delivery-network | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/data-delivery-network">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#how-content-delivery-networks-work" as="#how-content-delivery-networks-work">How content delivery networks work</a></li><li><a href="#why-do-you-need-a-backend-anyway" as="#why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</a><ol><li><a href="#alternatives-to-crud-services" as="#alternatives-to-crud-services">Alternatives to CRUD services</a></li><li><a href="#splitgraphs-architecture" as="#splitgraphs-architecture">Splitgraph's architecture</a></li></ol></li><li><a href="#data-delivery-network" as="#data-delivery-network">Data delivery network</a></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p>Serverless and edge computing have allowed application developers to bring their applications closer to the end user.</p><p>Instead of maintaining a group of servers in a single location, developers can let companies like Cloudflare, Fastly or Akamai handle their content delivery.</p><p>With <a href="https://en.wikipedia.org/wiki/Function_as_a_service" as="https://en.wikipedia.org/wiki/Function_as_a_service">Function as a service</a>, companies pay for what they use. They can avoid having to provision a server that stays idle most of the time.</p><p>In this article, we want to talk about these trends and how we can apply them to databases. We'll also talk about our decision to make the API for our Splitgraph registry work over a public SQL connection. We'll use this experience to propose the idea of a <strong>data delivery network</strong>.</p><section><h2 id="how-content-delivery-networks-work">How content delivery networks work</h2><p>Content delivery networks provide a straightforward way to scale a read-only HTTP layer. They use existing HTTP cache semantics like the Cache-Control header. The developer only needs to point their DNS records to use the CDN's nameservers. The CDN handles everything else for them. It has points of presence around the world and peering agreements with other ISPs. It can selectively cache data, handle DDoS protection and offer extra services on top.</p><p>The value proposition behind edge computing is simple. For a lot of companies, scaling compute is not their core competency. They can spend time and money provisioning servers and configuring something like Varnish. Or, they can use services that will handle scaling and caching for them.</p><p>However, applications still need to run SQL queries. A CDN doesn't completely help an application that performs client-side rendering. The database becomes the next performance bottleneck in scaling a service.</p><p>There are many ways to scale a database, for example, replication or sharding. But again, this requires specialist knowledge about a database that is easy to get wrong.</p></section><section><h2 id="why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</h2><p>Let's change gears and consider a classic Web application. It consists of the frontend, the backend and the database.</p><p>There are several purposes that a backend serves:</p><ul><li><p><strong>Business logic</strong>. The backend converts higher level API calls into low-level SQL queries. It prepares data for presentation and writes it back when needed.</p></li><li><p><strong>Authorization</strong>. The backend acts as a security barrier, validating API calls. This is necessary because the frontend is running on the user's machine: the client is not trusted.</p></li><li><p><strong>Multiplexing</strong>. A database connection has a larger overhead than an HTTP connection. A backend can shunt hundreds of simultaneous clients over to a few database connections.</p></li></ul><section><h3 id="alternatives-to-crud-services">Alternatives to CRUD services</h3><p>One big issue with writing RESTful backends is that there's a lot of boilerplate. The programmer has to write very similar code to handle every action. They have to care of validation, typechecking and handling edge cases.</p><p>Libraries like <a href="https://postgrest.org/en/latest/" as="https://postgrest.org/en/latest/">PostgREST</a> and <a href="https://www.graphile.org/postgraphile/" as="https://www.graphile.org/postgraphile/">Postgraphile</a> have helped developers decrease iteration times. They introspect database schemas and generate REST and GraphQL APIs for them.</p><p>PostgREST and Postgraphile perform their authorization using database methods like <a href="https://postgrest.org/en/v7.0.0/auth.html" as="https://postgrest.org/en/v7.0.0/auth.html">row level security</a>. In essence, they decrease the size of the <a href="https://en.wikipedia.org/wiki/Trusted_computing_base" as="https://en.wikipedia.org/wiki/Trusted_computing_base">"trusted computing base"</a>.</p><p>Often, services that use these kinds of tools don't even have a separate backend. Client side code can call the automatically generated GraphQL/REST API directly.</p></section><section><h3 id="splitgraphs-architecture">Splitgraph's architecture</h3><p>The database can perform a lot of work that the backend does more quickly and more efficiently.</p><p>We use this idea in the API for the Splitgraph registry that allows you to push and pull <a href="https://www.splitgraph.com/docs/concepts/images">data images</a>. A <a href="https://www.splitgraph.com/docs/architecture/sgr-client">Splitgraph client</a> can access it over a normal PostgreSQL connection to <code>postgresql://data.splitgraph.com:5432/sgregistry</code>.</p><p>Our API implements all <strong>business logic</strong> as PostgreSQL functions. This has a few immediate advantages:</p><ul><li>Lets PostgreSQL precompile them</li><li>Avoids an extra hop from the backend, decreasing latency</li><li>Makes basic validation and type checking trivial. It's not possible to call a function with a wrong number of arguments or different types.</li></ul><p>For more complex logic, we wrote it in higher-level languages like <a href="https://www.postgresql.org/docs/current/plpython.html" as="https://www.postgresql.org/docs/current/plpython.html">PL/Python</a> or PL/Lua. PostgreSQL even supports languages like C or JavaScript.</p><p>We solved the problem of <strong>multiplexing and authorization</strong> by adding <a href="https://www.pgbouncer.org/" as="https://www.pgbouncer.org/">PgBouncer</a>, a connection pooler, in front of our database. Our fork of PgBouncer injects a signed cookie into every transaction as a local variable. Downstream procedures validate this cookie for authentication and authorization. This lets us decouple PostgreSQL users from application users. Multiple inbound sessions can use the same connection.</p><p>Our fork of PgBouncer even inspects queries on the fly and filters them. This makes sure that the client can only call Splitgraph SQL API functions.</p><p>For the web frontend at <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com/">www.splitgraph.com</a>, we use Postgraphile. Besides not having to write an extra API server, it lets us generate TypeScript client code.</p></section></section><section><h2 id="data-delivery-network">Data delivery network</h2><p>We can apply these ideas and concepts to the problem of building a <strong>"data delivery network"</strong>. Such a network would completely abstract away all the issues around making sure that data is available at the edge. It can also provide plenty of other useful services.</p><p>Here's a quick sketch of what a DDN's administration interface would look like:</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200713-data-delivery-network/admin-panel.png"></p><p>To use a DDN, a developer would create a read-only account on their database and give the DDN the credentials. It will then make a few services available:</p><p>The DDN will create an <strong>SQL endpoint</strong>. Any existing SQL client or application will be able to connect to it and run queries.</p><p>Besides SQL, the DDN will also be able to introspect the origin database and provide <strong>REST and GraphQL API endpoints</strong>. A client, running in the user's web browser, can use these endpoints instead of a backend server.</p><p>The DDN will be able to <strong>cache</strong> read-only SQL transactions with configurable policies. It will only forward the query to the origin database if there's a cache miss or expiry.</p><p>The client code doesn't need to be trusted. The DDN can intercept and <strong>firewall</strong> queries or <strong>rate limit</strong> them. To simplify migrations, the DDN can <strong>rewrite</strong> queries on the fly before forwarding them.</p><p>The DDN's work doesn't need to stop at handling queries. It can also manage <strong>data imports and exports</strong>. For example, it can make data from other services available to clients. Or, it can export data to Google Sheets or a data warehouse.</p><p>In the case of Splitgraph, we envision you being able to even run a <code>JOIN</code> across a public Splitgraph image and your private data.</p></section><section><h2 id="conclusion">Conclusion</h2><p>The database is the next frontier of serverless and edge computing. One of Splitgraph's goals is building a data delivery network to handle these problems.</p><p>If you're interested in learning more about Splitgraph, you can check our <a href="https://www.splitgraph.com/docs/getting-started/frequently-asked-questions">frequently asked questions</a> section, follow our <a href="https://www.splitgraph.com/docs/getting-started/five-minute-demo">quick start guide</a> or visit our <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">website</a>.</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/data-delivery-network</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819918</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Lisp GUI Toolkits]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819896">thread link</a>) | @ogogmad
<br/>
July 13, 2020 | https://lispcookbook.github.io/cl-cookbook/gui.html | <a href="https://web.archive.org/web/*/https://lispcookbook.github.io/cl-cookbook/gui.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" <p=""><p>Lisp has a long and rich history and so does the development of
Graphical User Interfaces in Lisp. In fact, the first GUI builder was
written in Lisp (and sold to Apple. It is now Interface Builder).</p>

<p>Lisp is also famous and unrivalled for its interactive development
capabilities, a feature even more worth having to develop GUI
applications. Can you imagine compiling one function and seeing your
GUI update instantly? We can do this with many GUI frameworks today,
even though the details differ from one to another.</p>

<p>Finally, a key part in building software is how to build it and ship
it to users. Here also, we can build self-contained binaries, for
the three main operating systems, that users can run with a double
click.</p>

<p>We aim here to give you the relevant information to help you choose
the right GUI framework and to put you on tracks. Don’t hesitate to
<a href="https://github.com/LispCookbook/cl-cookbook/issues/">contribute</a>, to
send more examples and to furnish the upstream documentations.</p>



<p>In this recipe, we’ll present the following GUI toolkits:</p>

<ul>
  <li><a href="https://www.tcl.tk/">Tk</a> with <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a></li>
  <li><a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a> with <a href="https://github.com/Shinmera/qtools">Qtools</a></li>
  <li><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> with <a href="https://github.com/lispnik/iup/">lispnik/iup</a></li>
  <li><a href="https://www.gtk.org/">Gtk3</a> with <a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a></li>
  <li><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> with <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a></li>
</ul>

<p>In addition, you might want to have a look to:</p>

<ul>
  <li>the <a href="http://www.lispworks.com/products/capi.html">CAPI</a> toolkit (Common Application Programming Interface),
which is proprietary and made by LispWorks. It is a complete and cross-platform
toolkit (Windows, Gtk+, Cocoa), very praised by its users. LispWorks
also has <a href="http://www.lispworks.com/products/lw4mr.html">iOS and Android
runtimes</a>. Example
software built with CAPI include <a href="https://scorecloud.com/">ScoreCloud</a>. It is possible to
try it with the LispWorks free demo.</li>
  <li><a href="https://franz.com/products/allegro-common-lisp/acl_ide.lhtml">Allegro CL’s IDE and Common Graphics windowing system</a> (proprietary): Allegro’s IDE is a general environment for developing applications. It works in concert with a windowing system called Common Graphics. The IDE is available for Allegro CL’s Microsoft Windows, on x86 Linux platforms, and on the Mac.</li>
  <li><a href="https://ccl.clozure.com/docs/ccl.html#the-objective-c-bridge">CCL’s built-in Cocoa
interface</a>,
used to build applications such as <a href="https://opusmodus.com/">Opusmodus</a>.</li>
  <li><a href="https://github.com/plkrueger/CocoaInterface/">CocoaInterface</a>, a
Cocoa interface for Clozure Common Lisp. Build Cocoa user interface
windows dynamically using Lisp code and bypass the typical Xcode
processes.</li>
  <li><a href="https://common-lisp.net/project/mcclim/">McCLIM</a> and <a href="https://github.com/earl-ducaine/cl-garnet">Garnet</a> are toolkit in 100% Common Lisp. McClim even has <a href="https://techfak.de/~jmoringe/mcclim-broadway-7.ogv">a prototype</a> running in the browser with the Broadway protocol and Garnet has an ongoing interface to Gtk.</li>
  <li><a href="https://github.com/Shirakumo/alloy">Alloy</a>, another very new toolkit in 100% Common Lisp, used for example in the <a href="https://github.com/shinmera/kandria">Kandria</a> game.</li>
  <li><a href="https://notabug.org/cage/nodgui">nodgui</a>, a fork of Ltk, with syntax sugar and additional widgets.</li>
  <li><a href="https://gitlab.com/eql">eql, eql5, eql5-android</a>, embedded Qt4 and Qt5 Lisp, embedded in ECL, embeddable in Qt. Port of EQL5 to the Android platform.</li>
  <li>this <a href="https://github.com/defunkydrummer/abcl-jazz">demo using Java Swing from ABCL</a></li>
  <li><a href="https://github.com/mifpasoti/Gtk-Demos">examples of using Gtk without C files with SBCL</a>, as well as GTK-server.</li>
  <li>and, last but not least, <a href="http://ceramic.github.io/">Ceramic</a>, to ship a cross-platform web app with Electron.</li>
</ul>

<p>as well as the other ones listed on <a href="https://github.com/CodyReichert/awesome-cl#Gui">awesome-cl#gui</a> and <a href="https://www.cliki.net/GUI">Cliki</a>.</p>

<h2 id="tk-ltk">Tk (Ltk)</h2>

<p><a href="https://www.tcl.tk/">Tk</a> (or Tcl/Tk, where Tcl is the programming language) has the
infamous reputation of having an outdated look. This is not (so) true
anymore since its version 8 of 1997 (!). It is probably better than
you think:</p>

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/gui/ltk-on-macos.png" alt=""></p>

<p>Tk doesn’t have a great choice of widgets, but it has a useful canvas,
and it has a couple of unique features: we can develop a graphical
interface <strong>fully interactively</strong> and we can run the GUI <strong>remotely</strong>
from the core app.</p>

<p>So, Tk isn’t fancy, but it is an used and proven GUI toolkit (and
programming language) still used in the industry. It can be a great
choice to quickly create simple GUIs, to leverage its ease of deployment, or
when stability is required.</p>

<p>The Lisp binding is <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a>.</p>

<ul>
  <li><strong>Written in</strong>: Tcl</li>
  <li>
    <p><strong>Portability</strong>: cross-platform (Windows, macOS, Linux).</p>
  </li>
  <li>
    <p><strong>Widgets</strong>: this is not the fort of Tk. It has a <strong>small set</strong> of
default widgets, and misses important ones, for example a calendar. We
can find some in extensions (such as in <strong>Nodgui</strong>), but they don’t
feel native, at all.</p>
  </li>
  <li>
    <p><strong>Interactive development</strong>: very much.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no</p>
  </li>
  <li><strong>Other features</strong>:
    <ul>
      <li><strong>remote execution</strong>: the connection between Lisp and Tcl/Tk is
done via a stream. It is thus possible to run the Lisp program on
one computer, and to display the GUI on another one. The only
thing required on the client computer is tcl/tk installed and the
remote.tcl script. See <a href="http://www.peter-herth.de/ltk/ltkdoc/node46.html">Ltk-remote</a>.</li>
    </ul>
  </li>
  <li><strong>Bindings documentation</strong>: short but complete. Nodgui too.</li>
  <li><strong>Bindings stability</strong>: very stable</li>
  <li><strong>Bindings activity</strong>: low to non-existent.</li>
  <li><strong>Licence</strong>: Tcl/Tk is BSD-style, Ltk is LGPL.</li>
  <li>Example applications:
    <ul>
      <li><a href="https://notabug.org/cage/fulci/">Fulci</a> - a program to organise your movie collections.</li>
      <li><a href="https://github.com/mijohnson99/ltk-small-games">Ltk small games</a> - snake and tic-tac-toe.</li>
      <li><a href="https://github.com/vindarel/cl-torrents">cl-torrents</a> - searching torrents on popular trackers. CLI, readline and a simple Tk GUI.</li>
    </ul>
  </li>
</ul>

<p><strong>List of widgets</strong></p>

<p>(please don’t suppose the list is exhaustive)</p>

<pre><code>Button Canvas Check-button Entry Frame Label Labelframe Listbox
Menu Menubutton Message
Paned-window
Radio-button Scale
Scrollbar Spinbox Text
Toplevel Widget Canvas

Ltk-megawidgets:
    progress
    history-entry
    menu-entry
</code></pre>

<p>Nodgui adds:</p>

<pre><code>treelist tooltip searchable-listbox date-picker calendar autocomplete-listbox
password-entry progress-bar-star notify-window
dot-plot bar-chart equalizer-bar
swap-list
</code></pre>



<p>Do we need to present Qt and <a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a>? Qt is huge and contains
everything and the kitchen sink. Qt not only provides UI widgets, but
numerous other layers (networking, D-BUS…).</p>

<p>Qt is free for open-source software, however you’ll want to check the
conditions to ship proprietary ones.</p>

<p>The <a href="https://github.com/Shinmera/qtools">Qtools</a> bindings target Qt4. The Qt5 Lisp bindings are
yet to be created.</p>

<p>A companion library for Qtools, that you’ll want to check out once you
made your first Qtool application, is
<a href="https://github.com/Shinmera/qtools-ui">Qtools-ui</a>, a collection of
useful widgets and pre-made components. It comes with short
<a href="https://www.youtube.com/playlist?list=PLkDl6Irujx9Mh3BWdBmt4JtIrwYgihTWp">demonstrations
videos</a>.</p>

<!-- possible future: gobject-introspection -->

<ul>
  <li><strong>Framework written in</strong>: C++</li>
  <li><strong>Framework Portability</strong>: multi-platform, Android, embedded systems, WASM.</li>
  <li>
    <p><strong>Bindings Portability</strong>: Qtools runs on x86 desktop platforms on Windows, macOS and GNU/Linux.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: Web browser, a lot more.</p>
  </li>
  <li><strong>Bindings documentation</strong>: lengthy explanations, a few examples. Prior Qt knowledge is required.</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: active</li>
  <li><strong>Qt Licence</strong>: both commercial and open source licences.</li>
  <li>Example applications:
    <ul>
      <li>https://github.com/Shinmera/qtools/tree/master/examples</li>
      <li>https://github.com/Shirakumo/lionchat</li>
      <li>https://github.com/shinmera/halftone - a simple image viewer</li>
    </ul>
  </li>
</ul>

<h2 id="gtk3-cl-cffi-gtk">Gtk+3 (cl-cffi-gtk)</h2>

<p><a href="https://www.gtk.org/">Gtk+3</a> is the primary library used to build <a href="https://www.gnome.org/">GNOME</a>
applications. Its (currently most advanced) lisp bindings is
<a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a>. While primarily created for GNU/Linux, Gtk
works fine under macOS and can now also be used on Windows.</p>

<ul>
  <li><strong>Framework written in</strong>: C</li>
  <li>
    <p><strong>Portability</strong>: GNU/Linux and macOS, also Windows.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li><strong>Graphical builder</strong>: yes: Glade.</li>
  <li>
    <p><strong>Other features</strong>: web browser (WebKitGTK)</p>
  </li>
  <li><strong>Bindings documentation</strong>: very good: http://www.crategus.com/books/cl-gtk/gtk-tutorial.html</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: low activity, active development.</li>
  <li><strong>Licence</strong>: LGPL</li>
  <li>Example applications:
    <ul>
      <li>an <a href="https://github.com/ralph-schleicher/atmosphere-calculator">Atmosphere Calculator</a>, built with Glade.</li>
    </ul>
  </li>
</ul>

<h2 id="iup-lispnikiup">IUP (lispnik/IUP)</h2>

<p><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> is a cross-platform GUI toolkit actively developed
at the PUC university of Rio de Janeiro, Brazil. It uses <strong>native
controls</strong>: the Windows API for Windows, Gtk3 for GNU/Linux. At the
time of writing, it has a Cocoa port in the works (as well as iOS,
Android and WASM ones). A particularity of IUP is its <strong>small API</strong>.</p>

<p>The Lisp bindings are <a href="https://github.com/lispnik/iup/">lispnik/iup</a>. They are nicely
done in that they are automatically generated from the C sources. They
can follow new IUP versions with a minimal work and the required steps
are documented. All this gives us good guarantee over the bus
factor.</p>

<p>IUP stands as a great solution in between Tk and Gtk or Qt.</p>

<ul>
  <li><strong>Framework written in</strong>: C (official API also in Lua and LED)</li>
  <li>
    <p><strong>Portability</strong>: Windows and Linux, work started for
Cocoa, iOS, Android, WASM.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: medium.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes: <a href="http://webserver2.tecgraf.puc-rio.br/iup/en/iupvisualled.html">IupVisualLED</a></p>
  </li>
  <li>
    <p><strong>Other features</strong>: OpenGL, Web browser (WebKitGTK on GNU/Linux), plotting, Scintilla text editor</p>
  </li>
  <li><strong>Bindings documentation</strong>: good examples and good readme, otherwise low.</li>
  <li><strong>Bindings stability</strong>: alpha (but fully generated and working nicely).</li>
  <li><strong>Bindings activity</strong>: low but steady, and reactive to new IUP versions.</li>
  <li><strong>Licence</strong>: IUP and the bindings are MIT licenced.</li>
</ul>

<p><strong>List of widgets</strong></p>

<pre><code>Radio, Tabs, FlatTabs, ScrollBox, DetachBox,
Button, FlatButton, DropButton, Calendar, Canvas, Colorbar, ColorBrowser, DatePick, Dial, Gauge, Label, FlatLabel,
FlatSeparator, Link, List, FlatList, ProgressBar, Spin, Text, Toggle, Tree, Val,
listDialog, Alarm, Color, Message, Font, Scintilla, file-dialog…
Cells, Matrix, MatrixEx, MatrixList,
GLCanvas, Plot, MglPlot, OleControl, WebBrowser (WebKit/Gtk+)…
drag-and-drop
</code></pre>

<!-- editor's note: found missing a list view with columns. -->

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/iup-demo.png" alt=""></p>

<h2 id="nuklear-bodge-nuklear">Nuklear (Bodge-Nuklear)</h2>

<p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a small <a href="https://en.wikipedia.org/wiki/Immediate_mode_GUI">immediate-mode</a> GUI toolkit:</p>

<blockquote>
  <p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a minimal-state, immediate-mode graphical user interface toolkit written in ANSI C and licensed under public domain. It was designed as a simple embeddable user interface for application and does not have any dependencies, a default render backend or OS window/input handling but instead provides a highly modular, library-based approach, with simple input state for input and draw commands describing primitive shapes as output. So instead of providing a layered library that tries to abstract over a number of platform and render backends, it focuses only on the actual UI.</p>
</blockquote>

<p>its Lisp binding is <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a>, and its higher level companions <a href="https://github.com/borodust/bodge-ui">bodge-ui</a> and <a href="https://github.com/borodust/bodge-ui-window">bodge-ui-window</a>.</p>

<p>Unlike traditional UI frameworks, Nuklear allows the developer to take
over the rendering loop or the input management. This might require
more setup, but it makes Nuklear particularly well suited for games,
or for applications where you want to create new controls.</p>

<ul>
  <li><strong>Framework written in</strong>: ANSI C, single-header library.</li>
  <li>
    <p><strong>Portability</strong>: where C runs. Nuklear doesn’t contain
platform-specific code. No direct OS or window handling is done in
Nuklear. Instead <em>all input state has to be provided by platform
specific code</em>.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: small.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lispcookbook.github.io/cl-cookbook/gui.html">https://lispcookbook.github.io/cl-cookbook/gui.html</a></em></p>]]>
            </description>
            <link>https://lispcookbook.github.io/cl-cookbook/gui.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819896</guid>
            <pubDate>Mon, 13 Jul 2020 12:13:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“johnyj12345” exposing self-hosted Gitlab's secrets to the public]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819885">thread link</a>) | @ferruck
<br/>
July 13, 2020 | https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/ | <a href="https://web.archive.org/web/*/https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <h2><a href="https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" rel="bookmark">Possible Gitlab Hack</a></h2>
                <p>Today I noticed a new and unknown user on our company's Gitlab
instance: "johnyj12345". We immediatly took down our instance as it
seems as if that Johny was able to extract our secrets. You should
probably do so, too.</p>
                <p><i>Published <time datetime="2020-07-13T12:05:42+02:00">Monday, 13 July 2020</time> by <a href="https://blog.philipp-trommler.me/author/philipp-trommler.html">Philipp Trommler</a>. This article has also been translated to: <a href="https://blog.philipp-trommler.me/de/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" hreflang="de">de</a>.</i></p>
                <p>Searching the web <a href="https://www.google.com/search?q=johnyj12345">for the
username</a> (attention: Google link!)
reveals that many self-hosted Gitlab instances are affected. The publicly
visible procedure is always the same: Johny creates one or more issues that are
linked with each other and at the end of the link cascade there's either an
attached file or a link to a file which holds Gitlab's <code>secrets.yml</code>.</p>
<p>From the web search it seems like the hack started on Saturday, though that may
be a false conclusion. In any case, you should probably take down your Gitlab
instance if you're affected since the <code>secrets.yaml</code> contains Gitlab's base key
and the database encryption key which should better be private AFAIK. This may
or may not be an immediate attack surface, but better safe than sorry,
especially since the files can be easily found via Google.</p>
<p>We're currently looking for a sane and safe way of rotating the keys within that
file. Any help would be appreciated.</p>
                <p><i>Filed under <a href="https://blog.philipp-trommler.me/category/security.html">Security</a>. Tags: <a href="https://blog.philipp-trommler.me/tag/git.html">git</a>, <a href="https://blog.philipp-trommler.me/tag/gitlab.html">gitlab</a>, <a href="https://blog.philipp-trommler.me/tag/hacking.html">hacking</a>, <a href="https://blog.philipp-trommler.me/tag/web.html">web</a>.</i></p>
                <p><i>Want to comment on this article? Write me at blog [at] philipp-trommler [dot] me!</i></p>
            </article></div>]]>
            </description>
            <link>https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819885</guid>
            <pubDate>Mon, 13 Jul 2020 12:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go Small]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819825">thread link</a>) | @webdva
<br/>
July 13, 2020 | https://rogerkirkness.com/go-small | <a href="https://web.archive.org/web/*/https://rogerkirkness.com/go-small">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<main>
			<b>Go Small</b>
<b>October 2018</b>
<hr>
<p>Maybe itâ€™s just the people I surround myself with, but I hear â€œmight as well go bigâ€� or some variation of it all the time. People say it about their personal life, and their business life. Iâ€™m not sure whether itâ€™s good specific advice, but itâ€™s generally terrible generic advice. My thinking on this is the opposite: go as small as you can. Risk is bad and you should try to make protect yourself from as many eventualities as you can.</p>

<p>The first example Iâ€™d offer is dating. Go big means marry the first person you think you can make it work with. Beyond the obvious failings of this approach, letâ€™s break down the math. The statistics shows you should probably date a certain number of people before you even start sampling whether someone is a good fit for the long haul. I read a study about how once you have dated 8 people, meeting a 9th person who is better than the first 8 is a strong indication you should marry them. Youâ€™d have to date over 100 more people to find a 10th who was stronger still. So at first, you are just gaining information, and eventually you make a choice. It requires an extremely incremental attitude to commitment, and lots of conviction.</p>

<p>Another example is business. Going big on the first idea you think is a good one is generally a terrible idea. One commonality among successful entrepreneurs is generally that they started many, many companies before they started the one that made them a success. Itâ€™s a safe assumption that most companies anyone starts will fail by conventional definitions. If you go small, you get more at bats in your life, which means you have a higher probability of success. The trade off is that if you give up too soon or donâ€™t go deep enough, you wonâ€™t know if it worked. There are many ways to validate an idea before pursuing it. The lean startup is falling out of favor because all the low hanging fruit is gone. That thesis is only half true, though. Easy ideas may be gone, but that doesnâ€™t mean you canâ€™t validate a hard/valuable idea in less time. Go small, figure out if there is traction, then expand incrementally. Behind every giant company, is a scientific approach to going small at first to figure out if the idea is worth the time.</p>

<p>There arenâ€™t many areas of your life where incremental learning is harmful. And there is nothing wrong with going small. Many more people regret going big and losing everything than regret going small in the early days of a risk based venture (marriage and business being but two examples). You can always scale your commitment up later, and do so with vastly higher confidence. Might as well go small.</p>

<hr>


		</main>
	</div></div>]]>
            </description>
            <link>https://rogerkirkness.com/go-small</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819825</guid>
            <pubDate>Mon, 13 Jul 2020 12:03:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semi-Supervised Learning in Computer Vision]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819812">thread link</a>) | @amitness
<br/>
July 13, 2020 | https://amitness.com/2020/07/semi-supervised-learning/ | <a href="https://web.archive.org/web/*/https://amitness.com/2020/07/semi-supervised-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>Semi-supervised learning methods for Computer Vision have been advancing quickly in the past few years. Current state-of-the-art methods are simplifying prior work in terms of architecture and loss function or introducing hybrid methods by blending different formulations.</p>
<p>In this post, I will illustrate the key ideas of these recent methods for semi-supervised learning through diagrams.</p>
<h2 id="1-self-training"><strong>1. Self-Training</strong></h2>
<p>In this semi-supervised formulation, a model is trained on labeled data and used to predict pseudo-labels for the unlabeled data. The model is then trained on both ground truth labels and pseudo-labels simultaneously.</p>
<p><img src="https://amitness.com/images/ssl-self-training.png" alt="Idea of Self-Training"></p>
<h3 id="a-pseudo-label">a. Pseudo-label</h3>
<p><a href="http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf" title="Pseudo-Label: The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks">Dong-Hyun Lee</a> proposed a very simple and efficient formulation called “Pseudo-label” in 2013.</p>
<p>The idea is to train a <span>model</span> simultaneously on a batch of both labeled and unlabeled images. The <span>model</span> is trained on labeled images in usual supervised manner with a cross-entropy loss. The same model is used to get predictions for a batch of unlabeled images and the <span>maximum confidence class</span> is used as the <span>pseudo-label</span>. Then, cross-entropy loss is calculated by comparing <span>model</span> predictions and the pseudo-label for the unlabeled images .</p>
<p><img src="https://amitness.com/images/ssl-pseudo-label.png" alt="Pseudo-Label for Semi-supervised Learning"></p>
<p>The total loss is a weighted sum of the labeled and unlabeled loss terms.</p>

<p>To make sure the model has learned enough from the labeled data, the  term is set to 0 during the initial 100 training steps. It is then gradually increased up to 600 training steps and then kept constant.
<img src="https://amitness.com/images/ssl-pseudolabel-alpha-increase.png" alt="Impact of alpha on semi-supervised loss"></p>
<h3 id="b-noisy-student">b. Noisy Student</h3>
<p><a href="https://arxiv.org/abs/1911.04252" title="Self-training with Noisy Student improves ImageNet classification">Xie et al.</a> proposed a semi-supervised method inspired by Knowledge Distillation called “Noisy Student” in 2019.</p>
<p>The key idea is to train two separate models called <span>“Teacher”</span> and <span>“Student”</span>. The <span>teacher model</span> is first trained on the labeled images and then it is used to infer the pseudo-labels for the unlabeled images. These pseudo-labels can either be soft-label or converted to hard-label by <span>taking the most confident class</span>. Then, the labeled and unlabeled images are combined together and a <span>student model</span> is trained on this combined data. The images are augmented using RandAugment as a form of input noise. Also, model noise such as Dropout and Stochastic Depth are incorporated in the student model architecture.</p>
<p><img src="https://amitness.com/images/ssl-noisy-student.png" alt="Noisy Student"></p>
<p>Once a <span>student model</span> is trained, it becomes the new <span>teacher</span> and this process is repeated for three iterations.</p>
<h2 id="2-consistency-regularization"><strong>2. Consistency Regularization</strong></h2>
<p>This paradigm uses the idea that <span>model</span> predictions on an unlabeled image should remain the same even after adding noise. We could use input noise such as Image Augmentation and Gaussian noise. Noise can also be incorporated in the architecture itself using Dropout.</p>
<p><img src="https://amitness.com/images/fixmatch-unlabeled-augment-concept.png" alt="Consistency Regularization Concept"></p>
<h3 id="a-π-model">a. π-model</h3>
<p>This model was proposed by <a href="https://arxiv.org/abs/1610.02242" title="Temporal Ensembling for Semi-Supervised Learning">Laine et al.</a> in a conference paper at ICLR 2017.</p>
<p>The key idea is to create two random augmentations of an image for both labeled and unlabeled data. Then, a <span>model with dropout</span> is used to predict the label of both these images. The <span>square difference</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The total loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-pi-model.png" alt="PI Model"></p>
<h3 id="b-temporal-ensembling">b. Temporal Ensembling</h3>
<p>This method was also proposed by <a href="https://arxiv.org/abs/1610.02242" title="Temporal Ensembling for Semi-Supervised Learning">Laine et al.</a> in the same paper as the pi-model. It modifies the π-model by leveraging the <span>Exponential Moving Average(EMA)</span> of predictions.</p>
<p>The key idea is to use the <span>exponential moving average</span> of past predictions as one view. To get another view, we augment the image as usual and a <span>model with dropout</span> is used to predict the label. The <span>square difference</span> of <span>current prediction</span> and <span>EMA prediction</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-temporal-ensembling.png" alt="Temporal Ensembling"></p>
<h3 id="c-mean-teacher">c. Mean Teacher</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/1703.01780" title="Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results">Tarvainen et al.</a>. The general approach is similar to Temporal Ensembling but it uses Exponential Moving Average(EMA) of the model parameters instead of predictions.</p>
<p>The key idea is to have two models called <span>“Student”</span> and <span>“Teacher”</span>. The <span>student</span> model is a regular model with dropout. And the <span>teacher</span> model has the same architecture as the <span>student</span> model but its weights are set using an <span>exponential moving average</span> of the weights of <span>student</span> model. For a labeled or unlabeled image, we create two random augmented versions of the image. Then, the <span>student</span> model is used to predict <span>label distribution</span> for first image. And, the <span>teacher</span> model is used to predict the <span>label distribution</span> for the second augmented image. The <span>square difference</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-mean-teacher.png" alt="Mean Teacher"></p>
<h3 id="d-virtual-adversarial-training">d. Virtual Adversarial Training</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/1704.03976" title="Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning">Miyato et al.</a>. It uses the concept of adversarial attack for consistency regularization.</p>
<p>The key idea is to generate an adversarial transformation of an image that will change the model prediction. To do so, first, an image is taken and an adversarial variant of it is created such that the KL-divergence between the model output for the original image and the adversarial image is maximized.</p>
<p>Then we proceed as previous methods. We take a labeled/unlabeled image as first view and take its adversarial example generated in previous step as the second view. Then, the same <span>model</span> is used to predict <span>label distributions</span> for both images. The <span>KL-divergence</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span></span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-virtual-adversarial-training.png" alt="Virtual Adversarial Training"></p>
<h3 id="e-unsupervised-data-augmentation">e. Unsupervised Data Augmentation</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/1904.12848" title="Unsupervised data augmentation for consistency training">Xie et al.</a> and works for both images and text. Here, we will understand the method in the context of images.</p>
<p>The key idea is to create an augmented version of a unlabeled image using AutoAugment. Then, a same <span>model</span> is used to predict the label of both these images. The <span>KL-divergence</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we only calculate the <span>cross-entropy loss</span> and don’t calculate any <span>consistency loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-unsupervised-data-augmentation.png" alt="Unsupervised Data Augmentation"></p>
<h2 id="3-hybrid-methods"><strong>3. Hybrid Methods</strong></h2>
<p>This paradigm combines ideas from previous work such as self-training and consistency regularization along with additional components for performance improvement.</p>
<h3 id="a-mixmatch">a. MixMatch</h3>
<p>This holistic method was proposed by <a href="https://arxiv.org/abs/1905.02249" title="Mixmatch: A holistic approach to semi-supervised learning">Berthelot et al.</a>.</p>
<p>To understand this method, let’s take a walk through each of the steps.</p>
<p>i. For the labeled image, we create an augmentation of it. For the unlabeled image, we create K augmentations and get the model <span>predictions</span> on all K-images. Then, the <span>predictions</span> are <span>averaged</span> and <span>temperature scaling</span> is applied to get a final pseudo-label. This pseudo-label will be used for all the K-augmentations.</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-1.png" alt="Preparing Pseudo-label in MixMatch"></p>
<p>ii. The batches of augmented labeled and unlabeled images are combined and the whole group is shuffled. Then, the first N images of this group are taken as , and the remaining M images are taken as .</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-2.png" alt="Shuffling labeled and unlabeled images"></p>
<p>iii. Now, Mixup is applied between the augmented labeled batch and group . Similarly, mixup is applied between the M augmented unlabeled group and the  group. Thus, we get the final labeled and unlabeled group.</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-3.png" alt="Applying Mixup trick in MixMatch"></p>
<p>iv. Now, for the labeled group, we take model predictions and compute <span>cross-entropy loss</span> with the ground truth mixup labels. Similarly, for the unlabeled group, we compute model predictions and compute <span>mean square error(MSE) loss</span> with the mixup pseudo labels. A weighted sum is taken of these two terms with  weighting the MSE loss.</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-4.png" alt="MixMatch overall pipeline"></p>

<h3 id="b-fixmatch">b. FixMatch</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/2001.07685" title="FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence">Sohn et al.</a> and combines pseudo-labeling and consistency regularization while vastly simplifying the overall method. It got state of the art results on a wide range of benchmarks.</p>
<p>As seen, we train a supervised model on our labeled images with cross-entropy loss. For each unlabeled image, <span>weak augmentation</span> and <span>strong augmentations</span> are applied to get two images. The <span>weakly augmented image</span> is passed to our model and we get prediction over classes. The probability for the most confident class is compared to a <span>threshold</span>. If it is above the <span>threshold</span>, then we take that class as the ground label i.e. <span>pseudo-label</span>. Then, the <span>strongly augmented</span> image is passed through our model to get a prediction over classes. This <span>prediction</span> is compared to ground truth <span>pseudo-label</span> using cross-entropy loss. Both the losses are combined and the model is optimized.</p>
<p><img src="https://amitness.com/images/fixmatch-pipeline.png" alt="Overall Architecture of FixMatch"></p>
<p>If you want to learn more about FixMatch, I have an <a href="https://amitness.com/2020/03/fixmatch-semi-supervised/">article</a> that goes over it in depth.</p>
<h2 id="comparison-of-methods">Comparison of Methods</h2>
<p>Here is a high-level summary of the differences between all the above-mentioned methods.</p>
<table>
<thead>
<tr>
<th>Method Name</th>
<th>Year</th>
<th>Unlabeled Loss</th>
<th>Augmentation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pseudo-label</td>
<td>2013</td>
<td>Cross-Entropy</td>
<td>Random</td>
</tr>
<tr>
<td>π-model</td>
<td>2016</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Temporal Ensembling</td>
<td>2016</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Mean Teacher</td>
<td>2017</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Virtual Adversarial Training(VAT)</td>
<td>2017</td>
<td>KL-divergence</td>
<td>Adversarial transformation</td>
</tr>
<tr>
<td>Unsupervised Data Augmentation(UDA)</td>
<td>2019</td>
<td>KL-divergence</td>
<td>AutoAugment</td>
</tr>
<tr>
<td>MixMatch</td>
<td>2019</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Noisy Student</td>
<td>2019</td>
<td>Cross-Entropy</td>
<td>RandAugment</td>
</tr>
<tr>
<td>FixMatch</td>
<td>2020</td>
<td>Cross-Entropy</td>
<td>CTAugment / RandAugment</td>
</tr>
</tbody>
</table>
<h2 id="common-evaluation-datasets">Common Evaluation Datasets</h2>
<p>To evaluate the performance of these semi-supervised methods, the following datasets are commonly used. The authors simulate a low-data regime by using only a small portion(e.g. 40/250/4000/10000 examples) of the whole dataset as labeled and treating the remaining as the unlabeled set.</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Classes</th>
<th>Image Size</th>
<th>Train</th>
<th>Validation</th>
<th>Unlabeled</th>
<th>Remarks</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
<td>10</td>
<td>32*32</td>
<td>50,000</td>
<td>10,000</td>
<td>-</td>
<td>Subset of tiny images dataset</td>
</tr>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-100</a></td>
<td>100</td>
<td>32*32</td>
<td>50,000</td>
<td>10,000</td>
<td>-</td>
<td>Subset of tiny images dataset</td>
</tr>
<tr>
<td><a href="http://ai.stanford.edu/~acoates/stl10/">STL-10</a></td>
<td>10</td>
<td>96*96</td>
<td>5000</td>
<td>8000</td>
<td>1,00,000</td>
<td>Subset of …</td></tr></tbody></table></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amitness.com/2020/07/semi-supervised-learning/">https://amitness.com/2020/07/semi-supervised-learning/</a></em></p>]]>
            </description>
            <link>https://amitness.com/2020/07/semi-supervised-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819812</guid>
            <pubDate>Mon, 13 Jul 2020 12:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foundations of Separation Logic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819707">thread link</a>) | @matt_d
<br/>
July 13, 2020 | https://chargueraud.org/teach/verif/ | <a href="https://web.archive.org/web/*/https://chargueraud.org/teach/verif/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="page-div"><table><tbody><tr><td id="page-col-menu"></td><td id="page-col-content"><div><h2>Foundations of Separation Logic</h2><p>The <i>Foundations of Separation Logic</i> course presents the foundations of Separation Logic for sequential programs and the construction of a practical program verification tool based on Separation Logic.</p><p>The course material is entirely developed in the Coq proof assistant, following the style of the <a href="https://softwarefoundations.cis.upenn.edu/">Software Foundations</a> volumes.</p><div><ul><li><a href="https://chargueraud.org/research/2020/seq_seplogic/seq_seplogic.pdf"><b>Dowload the summary paper</b></a> entitled <i>Separation Logic for Sequential Programs</i>. This paper, presented at ICFP'20, covers most of the material with the notable exception of the weakest precondition generator.</li><li><a href="https://chargueraud.org/teach/verif/slf/index.html"><b>Browse the course files</b></a>, in HTML format.</li><li><a href="https://chargueraud.org/teach/verif/slf.tar.gz"><b>Download the course material</b></a>, which includes Coq and HTML files.</li><li>The files have been tested for compilation with all versions from Coq v8.8 to coq v8.12.</li><li>Compilation issues warnings with versions 8.10 or above; these warnings may be safely ignored.</li><li>See the README file for instructions.</li></ul></div><p>Solutions are available on demand. Contributions to the material are welcome.</p><h2><br>Older material: Master course on Separation Logic</h2><p>I taught from 2013 until 2017 at the <a href="https://wikimpri.dptinfo.ens-cachan.fr/doku.php">MPRI</a> (Parisian Master of Research in Computer Sciences), the program verification course, together with Claude Marché. The course covered  the following chapters:</p><div><ul><li>Heap predicates, heap entailment, interpretation triples, derivation rules.</li><li>Representation predicates for list and trees, nested mutable data structures, ownership transfer.</li><li>Reasoning about loops, frame during loops, higher-order functions, iterators.</li><li>Arrays, records and objects, frame over individual cells, data structures with sharing.</li><li>Extensions of Separation Logic for read-only permissions, parallelism, concurrency, and amortized analysis.</li><li>Characteristic formulae for integrating Separation Logic in Coq.</li></ul></div><p>Here are the slides from Febuary 2017:</p></div></td></tr></tbody></table></div></div></div>]]>
            </description>
            <link>https://chargueraud.org/teach/verif/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819707</guid>
            <pubDate>Mon, 13 Jul 2020 11:47:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trade Wars Are Class Wars]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819673">thread link</a>) | @Ericson2314
<br/>
July 13, 2020 | https://phenomenalworld.org/reviews/trade-wars | <a href="https://web.archive.org/web/*/https://phenomenalworld.org/reviews/trade-wars">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <div>
          
          
<p><span>by Matthew C. Klein and Michael Pettis</span>
</p>
<p><span>Yale University Press, 2020</span>
</p>
<p>Good writing on international macroeconomics reads like a detective novel. There’s a suspicious event—hundreds of millions of dollars in <a href="https://www.bloomberg.com/news/audio/2019-10-25/the-great-whodunit-of-taiwanese-life-insurers-podcast">phantom FX swaps</a>, a container port’s worth of <a href="https://www.bis.org/speeches/sp190410.pdf">missing exports</a>—and an enormous cast of closely-linked characters. But instead of a preternatural ability to see the clear-cut means, motive, and opportunity of fictional characters in a pulp whodunit, the macroeconomic detective is armed with the knowledge that balance sheets always balance. This simple insight, that every transaction has two sides, means that there are certain aggregate relationships between transactions that must obtain for the world economy. Knowing this, it’s possible to chase actors across seemingly unrelated balance sheets to find where the system as a whole was forced to balance. From here, the skillful economist can identify the long-run tendencies that a given balance is likely to create. (Wynne Godley famously <a href="http://www.levyinstitute.org/pubs/sevenproc.pdf">predicted</a> the Global Financial Crisis in just this way, following US mortgage debt around the world and back.) This kind of detective work is difficult, and often unpopular. The balance sheet approach cuts through political and media platitudes to reveal who the winners and losers are in a given regime. By taking this approach to examining trade policy, Michael Pettis and Matthew Klein have, with <em><a href="https://yalebooks.yale.edu/book/9780300244175/trade-wars-are-class-wars">Trade Wars Are Class Wars</a></em>, written the ideal book for understanding the long-run trends that have shaped our dysfunctional present.</p>
<p>Pettis and Klein tell a broad story about the last fifty years of global economic development, which links the dynamics of global supply chains and tax evasion, and the historical shift from wage-led to profit-led growth. </p>
<p>The book argues that elites in all countries want to capture economic output while developing the capital stock of their economies. To do this, they invest massively, which mechanically creates savings. Rather than sharing those savings with the household sector in the form of wage increases, the elites hoard and move them offshore. This destroys local demand for the goods produced by their capital investments. At this point, they turn to the export market to make up for the missing local sales. The problem is that, to be competitive exporters, they have to produce tradeable goods at a lower unit cost than their competitors. Capitalists must then further suppress domestic wages to ensure those lower unit costs, and thus increase their dependency on export markets.</p>
<p>The problem is, not every country—or bloc, in the case of the Eurozone—can be a net exporter. This spells trouble, if every country’s capitalists are dependent on the export markets to validate their investments. Absent a country willing to import everyone else’s surplus, this kind of arrangement would set the capitalists of all countries against one another before falling apart. It’s at this point, however, that the US steps in to backstop the global order as a hegemonic debtor, allowing nearly every other country to be a net exporter. As many have <a href="https://phenomenalworld.org/analysis/the-class-politics-of-the-dollar-system">pointed out</a>, this is the natural role for the US to play, given nearly all transactions the world over are denominated in its currency. To update Robert Triffin, if the whole world uses your currency for trade, then the whole world economy needs you to issue dramatically more debt than your domestic economy requires. This extra debt, combined with massive offshoring of profits, means that annual US investment flows abroad—in dollar terms, not physical ones—vastly outstrip the rest of the world's annual investment in the US. This capital account surplus produces a matching current account deficit. The imports that make up this current account deficit are largely manufactured goods that the US used to produce domestically. Such an influx in turn hollows out domestic production in tradeable goods, and the industrial middle class of the US, brought into being by the second world war, falls apart into opiates, suicide, and nativism. By acting as debtor to the world, the <a href="https://twitter.com/quantian1/status/1260387202871287809">US benefits</a> from imported goods, while elites of all countries—the US included—win at the expense of all workers.</p>
<p>This story is a novel one because most economists and popularizers envision macroeconomics as the simple aggregation of microeconomic decisions: in a vacuum, all the actors come to their own conclusions about how to behave, and the sum of these decisions is expressed in macroeconomic figures. What those decisions add up to is ultimately a residual, only useful as a measurement of how well agents in general are making decisions, and how good some countries are at producing certain kinds of goods. In this view, for example, the Chinese simply <em>prefer</em> to save more, and Americans simply <em>prefer</em> to save less. Chinese workers will work for less money, and individual US consumers will decide that they prefer imports over American-made goods. In reality, individuals make decisions from the space of options dictated by macroeconomic conditions. To take this fact seriously, as Pettis and Klein do, means working from balance sheets—adhering to the accounting identities of the world economy and reconstructing the interrelated financial and real flows within it. </p>
<p>Without going through sets of T-accounts like a first-year accounting student, consider the following example. Someone buys a television. The buyer doesn’t have cash on hand and puts the \$500 purchase on a credit card. The consumer gains a television and a debt of \$500. The credit card company gives \$500 to the store and gains a debt of \$500 from the buyer. The store gains \$500 from the credit card company but loses a television. Simple enough. But say the store has to pay its international suppliers, and the credit card company chooses to sell the debt of the original purchaser. Now some chunk of the original $500 is going through foreign exchange (whose rate has been hedged, naturally) to a Chinese company that keeps some portion in a bank, which in turn keeps some portion in properly hedged US Treasuries. At the same time, the debt held by the credit card company is securitized and sold to a European bank looking for exposure to that particular kind of risk.</p>
<p>The simplest transaction can become very complex in a financial economy, if one maps every other transaction it touches. It can also fan out into accumulations of seemingly unrelated financial products, as participants hedge away unwanted risks and speculators demand exposure. But it is always possible to trace these relationships through to find their financing and final funding. Goods and money must come from somewhere, and every sale is also a purchase. Someone is always ultimately using credit, and someone else is ultimately providing credit. These kinds of transactions happen billions of times per day—hedged to one another, and contracted forwards and backwards in time—and are individually relatively unimportant. The promise of economics as a field of study is that, when aggregated together through a constellation of balance sheets, the functional relationships between different economic and financial quantities can be identified.</p>
<p>Some of these outcomes are set endogenously by parameters internal to the model, and some exogenously by the world at large. Although all financial variables are ultimately endogenous to nature and society, some can be treated as exogenous to—set externally and without reference to the calculations of—the model. In this approach, the trick is to find which incentives and patterns of behavior are sufficiently strong to be exogenously given in the model, such that the model closes by adjusting endogenous variables. Strong exogenous factors are often historical, political, or social events, and endogenous changes—whose movements condense into new trends—are often hard to see clearly or quickly.</p>
<p>When, for example, the rest of the world wants to accumulate assets denominated in US dollars, and the US government does not want to run a budget deficit, those assets have to come from somewhere. They could come just as easily from the rest-of-world banking sector in the form of Eurodollar loans as they could from dissaving in the US private sector. Postkeynesian economists associated with Stock-Flow Consistent modelling often take this approach to understanding the world of <a href="http://www.levyinstitute.org/pubs/wp_891.pdf">international finance</a>, which can uncover these endogenous changes. Wynne Godley, Hyman Minsky, and the sectoral balances framework for macroeconomics lurk behind the scenes for much of <em>Trade Wars Are Class Wars</em>, while Keynes himself is cited throughout.</p>
<p>Readers already invested in international macroeconomics will recognize many of the names and arguments in the book, which functions as a brilliant primer on the field. It’s almost like a reverse <em>Freakonomics</em>. Instead of claiming that a couple of economics papers provide the only valid method for answering every question, and that every human activity is simply a veil for econ 101-style supply and demand, Pettis and Klein pull in insights from a variety of nearby disciplines—corporate finance, tax accounting, supply chain management—to actually explain the economy. The arguments, citations, and allusions here—Brad Setser, Hyun Song Shin, <a href="https://press.princeton.edu/books/paperback/9780691170817/the-box">Marc Levinson</a>, a past-life <a href="https://econpapers.repec.org/article/eeeinecon/v_3a8_3ay_3a1978_3ai_3a3_3ap_3a445-456.htm">Paul Krugman</a>—provide a great starting point for a deep and flexible understanding of the global economy.</p>
<p>Common approaches to trade policy take an overly literal view of bilateral trade balances. The folk-Ricardian story—still dominant in American political discourse—is that countries that are not good at making things have to import lots of things. Importer countries become indebted to their trading partner, see their exchange rate devalued and their interest rates rise, until eventually a plague of locusts overtakes them for their inability to be sufficiently productive. In this shopworn story, the correct policy response is to apply tariffs on goods from the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://phenomenalworld.org/reviews/trade-wars">https://phenomenalworld.org/reviews/trade-wars</a></em></p>]]>
            </description>
            <link>https://phenomenalworld.org/reviews/trade-wars</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819673</guid>
            <pubDate>Mon, 13 Jul 2020 11:42:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Engineering != Coding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819607">thread link</a>) | @FailMore
<br/>
July 13, 2020 | https://taaalk.co/t/software-engineering-coding#upvote | <a href="https://web.archive.org/web/*/https://taaalk.co/t/software-engineering-coding#upvote">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <div id="tlk-section-read">
    



<div>

    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I'm a recently trained full stack developer who want's to understand the FULL stack. Right now I think of that as backend + frontend code, but I hear there is more to it than that...</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <div>
  <p>I am the founder of multiple bootstrapped companies. They include web, mobile and infrastructure development agency <a href="https://www.solidstategroup.com/">Solid State Group</a>, virtual office business <a href="https://www.hoxtonmix.com/">The Hoxton Mix</a> and, most recently, developer friendly feature flag tool <a href="https://bullet-train.io/">Bullet Train</a>. I've been involved with many more than that, watching some succeed and others fail.</p>
</div>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

</div>

  </div>







  <div>

      <div id="1">
        <div>
          
          <p>Joshua Summers</p>
          <p>15:58, 26 Jun 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Why did you ask for this?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="2">
        <div>
          
          <p>Ben Rometsch</p>
          <p>12:36, 03 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Right so yes I've spent over 25 years writing software for people in a professional capacity. As time has gone by, and I've learnt more about the process, I've slowly realised that actually writing code is actually quite a small part of the process. When I was a junior developer I probably spent 90% of my working day sat in front of an editor writing code. And I thought that was the job. Turns out it really isn't!Â&nbsp;</p></div><div><p>I think people both inside and outside of the industry fixate on coding for a number of reasons, and it's quite interesting to ruminate on those, but building software is so much more than writing code. Talking to users, agreeing on features, designing the interface, setting up the infrastructure, testing the platform for bugs, testing it for performance, providing support for it. These are all messy, imprecise things that have very human factors.Â&nbsp;</p></div><div><p>If you are a software engineer you can often seek solace in the code itself. Code is truth. You can't really argue with it. You can't argue with your compiler. It's really easy to fall into the trap of avoiding all work other than coding for these very reasons. But I would suggest that this makes you a really bad engineer! Engineering means getting your hands dirty, either literally in the case of Brunel, or from a human interaction point of view where software is concerned.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="3">
        <div>
          
          <p>Joshua Summers</p>
          <p>14:15, 10 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So you are sort of saying that an engineer solves problems, and problems are experienced (mostly) by people, so to solve problems effectively you a) have to deal with people and b) have to really know how to solve the problem (e.g. dealing with infrastructure, performance, etc.) instead of only the parts you are comfortable with. Is that correct?</p></div><div><p>How much of this comes down to the attitude of the engineer? And how much of this comes down to actively studying?Â&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="4">
        <div>
          
          <p>Ben Rometsch</p>
          <p>10:22, 13 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>In my experience, almost 100% of that learning comes from hard won experience.Â&nbsp;</p></div><div><p>When I studied at university, I was really surprised to discover that the "Computing" courses that I was interested in were labelled as "Software Engineering". I thought it was odd at the time; I never really had thought it about it before, and I was even a bit worried that I might have been signing up for the wrong course!Â&nbsp;</p></div><div><p>I don't think many universities at the time offered "Computer Science" as an undergrad course; it's a very different discipline.Â&nbsp;</p></div><div><p>It took me a LONG time to get my head around the fact that one of the words in the job was "engineering". And really the only way I realised that was after years of working building software. At some point the penny dropped that I was an engineer, and that writing code was only 1 aspect of that job.Â&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="5">
        <div>
          
          <p>Joshua Summers</p>
          <p>12:00, 15 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So based on your experience, where do you feel the greatest value lies in the spectrum of what it means to be an engineer? Or is it person dependent?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>

  </div>








  

  





    </div></div>]]>
            </description>
            <link>https://taaalk.co/t/software-engineering-coding#upvote</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819607</guid>
            <pubDate>Mon, 13 Jul 2020 11:34:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alpha Wolf Concept]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819529">thread link</a>) | @CaptainActuary
<br/>
July 13, 2020 | https://davemech.org/wolf-news-and-information/ | <a href="https://web.archive.org/web/*/https://davemech.org/wolf-news-and-information/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article class="page" itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><h2>News</h2>
<p>The most current, accurate, and objective wolf news can be found on the website of the International Wolf Center (<a href="http://www.wolf.org/">www.wolf.org</a>)</p>
<p><img src="http://davemech.org/wp-content/uploads/wolfreadsbook-300x228.jpg" alt="Wolf reading book." width="300" height="228" srcset="https://davemech.org/wp-content/uploads/wolfreadsbook-300x228.jpg 300w, https://davemech.org/wp-content/uploads/wolfreadsbook-768x584.jpg 768w, https://davemech.org/wp-content/uploads/wolfreadsbook.jpg 800w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h2><a href="http://davemech.org/wolf-news-and-information/books/">Mech books</a></h2>
<h2>Mech articles</h2>
<ul>
<li><a href="http://davemech.org/wp-content/uploads/technical-publications.pdf">Scientific publications</a> (.pdf)</li>
<li><a href="http://davemech.org/wp-content/uploads/popular-publications.pdf">Popular publications</a> (.pdf)</li>
<li><a href="http://www.wolf.org/wolf-info/basic-wolf-%C2%A0info/in-depth-resources/scientific-publications/">Downloadable articles</a></li>
</ul>
<h2><a href="http://davemech.org/wolf-news-and-information/schenkels-classic-wolf-behavior-study-available-in-english/">Schenkel’s 1948 Wolf Expression Studies</a></h2>
<h2>Alpha Wolf Concept</h2>
<p>The concept of the alpha wolf is well ingrained in the popular wolf literature, at least partly because of my book “The Wolf: Ecology and Behavior of an Endangered Species,” written in 1968, published in 1970, republished in paperback in 1981, and currently still in print, despite my numerous pleas to the publisher to stop publishing it. Although most of the book’s info is still accurate, much is outdated. We have learned more about wolves in the last 40 years then in all of previous history.</p>
<p>One of the outdated pieces of information is the concept of the alpha wolf. “Alpha” implies competing with others and becoming top dog by winning a contest or battle. However, most wolves who lead packs achieved their position simply by mating and producing pups, which then became their pack. In other words they are merely breeders, or parents, and that’s all we call them today, the “breeding male,” “breeding female,” or “male parent,” “female parent,” or the “adult male” or “adult female.” In the rare packs that include more than one breeding animal, the “dominant breeder” can be called that, and any breeding daughter can be called a “subordinate breeder.”<br>
For details, see <a href="http://www.wolf.org/wp-content/uploads/2013/09/267alphastatus_english.pdf" target="_blank" rel="noopener">www.wolf.org/wp-content/uploads/2013/09/267alphastatus_english.pdf</a> and <a href="http://www.wolf.org/wp-content/uploads/2013/08/247Leadership.pdf" target="_blank" rel="noopener">www.wolf.org/wp-content/uploads/2013/08/247Leadership.pdf</a></p>
<h2>Alpha Wolf videos</h2>
<p><a href="https://www.youtube.com/watch?v=tNtFgdwTsbU" data-rel="lightbox-video-0">Mech explains</a><br>
<iframe width="500" height="375" src="https://www.youtube.com/embed/tNtFgdwTsbU?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
<p><a href="https://www.youtube.com/watch?v=YTyQgwVvYyc" data-rel="lightbox-video-1">Cartoon explanation of Mech and the Alpha concept</a> (cartoon starts at minute 1)<br>
<iframe width="500" height="281" src="https://www.youtube.com/embed/YTyQgwVvYyc?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
</div></article></main></div></div></div>]]>
            </description>
            <link>https://davemech.org/wolf-news-and-information/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819529</guid>
            <pubDate>Mon, 13 Jul 2020 11:24:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS Big Sur is flatter than ever]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819485">thread link</a>) | @elorant
<br/>
July 13, 2020 | https://www.andrewdenty.com/blog/2020/07/10/why-macos-big-sur-is-flatter-than-ever.html | <a href="https://web.archive.org/web/*/https://www.andrewdenty.com/blog/2020/07/10/why-macos-big-sur-is-flatter-than-ever.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p><img src="https://www.andrewdenty.com/blog/assets/img/why-macos-big-sur-is-flatter-than-ever.png" alt="Catalina vs Big Sur"></p>
<p>Forget skeuomorphism, or even the newly coined neumorphism.</p>
<p>macOS Big Sur is flatter than ever.</p>
<p>In the last few weeks there have been a lot of suggestions that this is the start of a <a href="https://applypixels.com/blog/comeback" target="_blank">new “fun” era of visual design</a> and that Apple is returning to skeuomorphism, or even a new thing called <a href="https://www.inputmag.com/design/apple-macos-big-sur-the-rise-of-neumorphism" target="_blank">neumorphism</a>. Neumorphism is a design trend that focuses on creating an impression of a realistic 3D environment using shadow and lighting effects.</p>
<p>The times may well be changing, but in my view we are not returning to an age of textured writing paper and
stitched leather. This is why.</p>
<h3 id="icons-icons-icons">Icons, icons, icons</h3>
<p>Since the unveiling of macOS Big Sur a lot has been made of its new iOS shaped icon set. Everyone seems to either love or hate the new icons.</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-flat/macos-big-sur-icons.jpg"><img src="https://www.andrewdenty.com/blog/assets/img/macos-flat/macos-big-sur-icons.jpg" alt="macOS Big Sur icons"></a></p>
<p>Don’t be mislead by the icons - macOS icons have always been richer and more detailed than iOS icons. They have also used shadows and to create a sense of depth. In my view desktop interfaces are often more detailed as desktop users tend to use them for longer periods of undistracted time compared to mobile devices. Therefore adding more detail and richness is appropriate. In short, for as long as technology has allowed, macOS icons have been rich, detailed and realistic looking. Here are a selection of macOS Catalina’s icons to illustrate this:</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-flat/depth-in-macos-catalina.png"><img src="https://www.andrewdenty.com/blog/assets/img/macos-flat/depth-in-macos-catalina.png" alt="Detailed macOS Catalina icons"></a></p>
<p>The new icon set in Big Sur is simply a convergence of the existing highly detailed macOS icons with the consistent shape of iOS icons. During the WWDC 20 keynote, Alan Dye, Apples VP of Human Interface explained the rationale behind the new icons:</p>
<blockquote>
<p>“We wanted consistency throughout the ecosystem so users can move fluidly between their Apple devices, but we also love that Mac icons have a deep history and a distinct look and feel. So we retained many of the highly crafted details and th playful elements that make Mac icons unique”</p>
</blockquote>
<p>It’s also worth remembering that in many places the icons in macOS are simpler than before as Apple is porting its unified language of symbols from iOS. This means that in many places, existing detailed icons have become simple, monochrome 2D icons.</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-new-ui/apple-music-podcasts/5-podcasts-preferences-macos-catalina-big-sur-comparison.png"><img src="https://www.andrewdenty.com/blog/assets/img/macos-new-ui/apple-music-podcasts/5-podcasts-preferences-macos-catalina-big-sur-comparison.png" alt="Icons in Podcast app's preferences"></a></p>
<h3 id="big-sur-is-flatter-than-ever">Big Sur is flatter than ever</h3>
<p>This may surprise a few people, but if you look at the user interfaces in macOS Big Sur and compare it to the current release Catalina you won’t see richer shading and detailing. Also, while macOS Big Sur uses transparency, and shadows to create the impression of layers in the UI, this isn’t a new thing for macOS.</p>
<p>Actually, you’ll see a lot of the detail, texture and shadows have been removed. As a whole, macOS Big Sur’s interface is cleaner and more minimalist than ever. One of the aspects I’ve noticed most is there tends to be less contrast between UI elements. Apple has also completely dropped the aluminium inspired window chromes which can be traced back to Quicktime in the 1990s.</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-flat/finder-toolbar-comparison.png"><img src="https://www.andrewdenty.com/blog/assets/img/macos-flat/finder-toolbar-comparison.png" alt="Comparison of Finder toolbars between macOS Catalina and Big Sur"></a></p>
<p>Take for example the notes app. The faux-paper texture has finally been completely removed. The toolbar buttons no longer have containers and there is no background separator between the toolbar and writing area.</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-flat/notes-compared.png"><img src="https://www.andrewdenty.com/blog/assets/img/macos-flat/notes-compared.png" alt="Comparison of Notes app between macOS Catalina and Big Sur"></a></p>
<h3 id="if-anything-the-design-trend-is-convergence-with-ios">If anything the design trend is convergence with iOS</h3>
<p>This is not a new paradigm in visual design, but a shift towards unification between platforms. There is increasingly less separation between iOS and macOS. Both in hardware with Apple’s switch to an all ARM architecture and software where iPhones and iPads can now do many of the tasks once reserved for desktop computing.</p>
<p>In many ways the interface changes in macOS Big Sur reflect this transition. The iOS glyph icon set, the removal of distinct buttons and increasingly rounded corners. Apple has clearly been asking why interface elements on an iPad and a Mac should look different, and come to the conclusion there’s no longer a good reason for this.</p>
<p>On the topic of conversion, one interesting question will be how much further this transition goes. Can we expect to see touch enabled laptops? Dual booting iPads? iPhones with docking stations?</p>
<h3 id="but-what-about-fun-design---isnt-that-coming-back">But what about fun design - isn’t that coming back?</h3>
<p>As a designer I’ve often found the trend towards flat, minimalist design frustrating. I pretty much always have an urge to add little embellishments or extra layers to work. I then subsequently almost always end up removing them. Either due to what I’ve learned when testing the design with users, or just realising that these extra details often end up detracting from the bigger picture.</p>
<p>This doesn’t mean there’s no value in intricate detailing. If you are a designer and you can inject a fun details into your work in a way which delights and enriches your users lives then I implore you to do this. I just don’t think that macOS Big Sur is the signal we’ve all been waiting for to bring out those shadows, textures and bevels.</p>
</div>
</article></div>]]>
            </description>
            <link>https://www.andrewdenty.com/blog/2020/07/10/why-macos-big-sur-is-flatter-than-ever.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819485</guid>
            <pubDate>Mon, 13 Jul 2020 11:14:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding the Importance of Abstractions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819435">thread link</a>) | @dwltz
<br/>
July 13, 2020 | https://www.donnywals.com/understanding-the-importance-of-abstractions/ | <a href="https://web.archive.org/web/*/https://www.donnywals.com/understanding-the-importance-of-abstractions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As developers, we constantly deal with layers of abstractions that make our lives easier. We have abstractions over low level networking operations that allow us to make network calls with <code>URLSession</code>. Core Data provides an abstraction over data persistence that can be used to store information in an sqlite database. And there are many, many more abstractions that we all use every day.</p><p>Over the past few weeks I have seen many people ask about using Core Data in pure SwiftUI projects created in Xcode 12. These projects no longer require an App- and SceneDelegate, and the checkbox to add Core Data is disabled for these projects. Some folks immediately thought that this meant Core Data can't be used with these projects since Xcode's template always initialized Core Data in the <code>AppDelegate</code>, and since that no longer exists it seems to make sense that Core Data is incompatible with apps that don't have an <code>AppDelegate</code>. How else would you initialize Core Data?</p><p>Fortunately, this isn't true. It's still possible to use Core Data in projects, even if they don't have an <code>AppDelegate</code>. In fact, the only thing that <code>AppDelegate</code> has to do with Core Data is that Apple decided that they wanted to setup Core Data in the <code>AppDelegate</code>.</p><p>They didn't have to make that choice. Core Data can be initialized from anywhere in your app.</p><p>However, this got me thinking about abstractions. Folks who have built a layer of abstraction between their app and Core Data probably already know that you don't need Xcode to generate a Core Data stack for you. They probably also already know that you can initialize Core Data anywhere.</p><p>While thinking about this, I started thinking more about abstractions. Adding the right abstractions to your app at the right time can help you build a more modular, portable and flexible code base that can quickly adapt to changes and new paradigms.</p><p>That why in this week's post, I would like to talk about abstractions.</p><h2>Understanding what abstractions are</h2><p>Abstractions provide a seperation between the interface you program against and the underlying implementation that performs work. In essence you can think of most, if not all, frameworks you use every day on iOS as abstractions that make working with something complex easier.</p><p>In programming, we often work with abstractions on top of abstractions on top of more abstractions. And yet, there is value in adding more abstractions yourself. A good abstraction does not only hide complexity and implementation details. It should also be reusable. When your abstraction is reusable it can be used in multiple projects with similar needs.</p><p>I could try to make the explanation more wordy, fancy or impressive but that wouldn't help anybody. Abstractions wrap a complex interface and provide an (often simpler) inferface while hiding the wrapped, complex interface as an implementation detail. Good abstractions can be reused.</p><h2>Knowing when to write an abstraction</h2><p>Earlier I wrote that adding your own abstractions has value. That said, it's not always obvious to know when you should write an abstraction. Especially since there are no hard or clear rules.</p><p>A good starting point for me is to determine whether I will write a certain block of tedious code more than once. Or rather, whether I will write similar blocks of tedious code multiple times. If the answer is yes, it makes sense to try and create a lightweight abstraction to wrap the tedious code and make it less annoying to work with.</p><p>Another method I often use to determine whether I should write an abstraction is to ask myself how easily I want to be able to swap a certain mechanism in my app out for testing or to replace it entirely.</p><p>Usually the answer to this question is that I want to be able to swap things out as easily as possible. And more often than not this means that I should add an abstraction.</p><p>For instance, when I write code that uses Core Data I always wrap it in a small abstraction layer. I don't want my entire app to depend directly on Core Data. Instead, my app uses the abstraction to interface with a persistence layer. The code in my app doesn't know how the persistence layer works. It just knows that such a layer exists, and that it can fetch and save objects of certain types.</p><p>Creating an abstraction like this allows me to easily change the underlying storage mechanism in my persistence layer. I could switch to Realm, use sqlite directly, or even move from local persitence to persisting data on a server or in iCloud. The app shouldn't know, and the app shouldn't care. That's the beauty of abstractions.</p><h2>Designing an abstraction</h2><p>Once you've decided that you want to write an abstraction, you need to design it. The first thing I always do is make sure that I decide which properties and methods should be publicly available. I then define a protocol that captures this public API for my abstraction. For example:</p><pre><code>protocol TodoItemPersisting {
  func getAllTodoItems() -&gt; Future&lt;[TodoItem]&gt;
  func getTodoItem(withId id: UUID) -&gt; Future&lt;TodoItem?&gt;
  func updateItem(_ item: TodoItem)
  func newTodoItem() -&gt; Future&lt;TodoItem&gt;
}</code></pre><p>This is a very simple protocol that exposes nothing about the underlying persistence layer. In the rest of my code I will always refer to <code>TodoItemPersisting</code> when I want to use my persistence abstraction:</p><pre><code>struct TodoListViewModel {
  private let itemStore: TodoItemPersisting
}</code></pre><p>In this example I defined a <code>ViewModel</code> that has an <code>itemStore</code> property. This property conforms to <code>TodoItemPersisting</code> and the object that creates an instance of <code>TodoListViewModel</code> gets to decide which concrete implementation of <code>TodoItemPersisting</code> is injected. And since the protocol for <code>TodoItemPersisting</code> uses <a href="https://www.donnywals.com/using-promises-and-futures-in-combine/">Combine Futures</a>, we know that the persistence layer does work asynchronously. The <code>ViewModel</code> doesn't know whether the persistence layer goes to the network, file system, Core Data, Realm, Firebase, iCloud or anywhere else for persistence.</p><p>It just knows that items are fetched and created asynchronously.</p><p>At this point you're free to create objects that implement <code>TodoItemPersisting</code> as needed. Usually you'll have one or two. One for the app to use, and a second version to use while testing. But you might have more in your app. It depends on the abstraction and what it's used for.</p><p>For instance, if your app uses In-App Purchases to provide syncing data to a server you might have a local persistence abstraction, and a premium local + remote persistence abstraction that you can swap out depending on whether the user bought your premium IAP.</p><p>By desiginig abstractions as protocols you gain a lot of flexibility and power. So whenever possible I always recommend to design and define your abstractions as protocols.</p><h2>Things to watch out for when writing abstractions</h2><p>Once you get the hang of abstracting code, it's very tempting to go overboard. While abstractions provide a lot of power, they also add a layer of indirection. New members of your team might understand the things you've abstracted really well, but if you added to many layers your code will be really hard to understand and your abstractions will be in the way of understanding the code base.</p><p>It's also possible that you didn't design your abstractions properly. When this happens, you will find that your abstractions are holding you back rather than helping you write code that does exactly what you want it to do. When you find you're fighting your abstractions it's time to revise your design and make improvements where needed.</p><p>And the last word of warning I want to give you is that it's important to limit the levels of abstractions you add. No matter how good your abstractions are, there will come a point where it'll get harder and harder to understand and debug your app when something is wrong. There's no hard cutoff point but eventually you'll develop a sense for when you're going too far. For now it's good to know that you can abstract too much.</p><h2>In Summary</h2><p>In this week's post you learned about abstractions in programming. You learned what an abstraction is, what abstractions are used for and how you can determine whether you should write an abstraction of your own.</p><p>You learned that abstractions can be extremely useful when you want to write code that's testible, flexible, and maintainable. Good abstractions make difficult work easier, and allow you to hide all implementation details of the thing or process you've written your abstraction for. You also learned that protocols are a fantastic tool to help you define and design your abstraction. Lastly, I gave you some things to watch out for when writing abstractions to make sure you don't overcomplicate matters or abstract too much.</p><p>If you have any questions for me, or if you have feedback about this week's post make sure to reach out to me on <a href="https://twitter.com/donnywals">Twitter</a>.</p><div><hr><div><h4>Practical Combine</h4><p>Learn everything you need to know about Combine and how you can use it in your projects with my new book <a href="http://practicalcombine.com/" target="_blank">Practical Combine</a>. You'll get thirteen chapters, a Playground and a handful of sample projects to help you get up and running with Combine as soon as possible.</p><p>The book is available as a digital download for just <strong>$24.99</strong>!</p> <p><a href="https://practicalcombine.com/" target="_blank">Get Practical Combine</a></p></div><hr></div></div></div>]]>
            </description>
            <link>https://www.donnywals.com/understanding-the-importance-of-abstractions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819435</guid>
            <pubDate>Mon, 13 Jul 2020 11:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tangling Code from Hugo Content with Raku – Brian Wisti]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819371">thread link</a>) | @lizmat
<br/>
July 13, 2020 | https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/ | <a href="https://web.archive.org/web/*/https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

      <p>Let’s say I have a file.
The one you’re reading, perhaps.
Well, its original Markdown content.</p>
<p>It has a shortcode in it.</p>
<div><pre><code data-lang="go-html-template"><span>{{</span><span>&lt;</span><span> </span><span>code</span><span> </span><span>file</span><span>=</span><span>"hello.py"</span><span> </span><span>&gt;</span><span>}}</span>
print("Hello")
<span>{{</span><span>&lt;</span><span> </span><span>/</span><span>code</span><span> </span><span>&gt;</span><span>}}</span>
</code></pre></div><p>I based <code>{{&lt; code &gt;}}</code> here on a shortcode from the <a href="https://github.com/gohugoio/hugoDocs/blob/master/layouts/shortcodes/code.html">hugo docs</a>. It presents highlighted code with additional context.</p>






  









<p>Really handy when you’re writing about code.  Thing is, now I have two copies.  There’s one here in
the shortcode, and another in a <code>hello.py</code> file that I’m writing about.  I’d prefer there was only a
single copy.  That way they don’t get out of sync.</p>
<p>I <em>could</em> use Hugo’s <a href="https://gohugo.io/functions/readfile/"><code>readFile</code></a> function in a new shortcode, including the contents of
<code>hello.py</code> in this Markdown file. Something like this:</p>
<div><pre><code data-lang="go-html-template"><span>{{</span><span>&lt;</span><span> </span><span>include</span><span> </span><span>file</span><span>=</span><span>"hello.py"</span><span> </span><span>&gt;</span><span>}}</span>
</code></pre></div>
<p>But that still breaks up the writing flow a little bit. I’m writing the code over here, and
writing <em>about</em> it over there. It’s a tiny complaint, but working with <a href="https://randomgeekery.org/tags/org">Org mode</a> has spoiled me. I
get to write the code in the same document that I’m writing about it in. Everything stays in sync,
more or less.</p>
<p>What I want is to write about <code>hello.py</code> here, and with a command have <code>hello.py</code> appear on my
filesystem, containing the Python code I’ve been describing.</p>
<p>And I want to do it without disturbing Hugo. Let it turn Markdown into HTML.</p>
<h2 id="tangling">Tangling</h2>
<p>This process is called “tangling,” and it’s popular in the admittedly small world of <a href="http://literateprogramming.com/index.html">Literate
Programming</a>. The code is interleaved throughout some kind of document, and a tool like <a href="https://www.cs.tufts.edu/~nr/noweb/">noweb</a> or
<a href="https://orgmode.org/worg/org-contrib/babel/intro.html">Babel</a> parses the document to create code files. Could be any kind of file, really. The process can get
fancy.</p>
<p>But the start is not fancy: given a text file containing a <code>{{&lt; code file="(something)" &gt;}}</code>,
write the contents of that shortcode to the named file.</p>






  





<div id="tangle.raku"><p><a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/tangle.raku" title="Download tangle.raku" aria-label="Download">
          
        </a>tangle.raku
    </p>
    <pre><code data-lang="raku">sub MAIN() {
  my $filename = "index.md";
  my $opener = '{{&lt; ';
  my $closer = ' &gt;}}';
  my regex shortcode {
    $opener
      code \s
      'file="' $&lt;filename&gt; = .+? '"'  # Remember the filename
      .*?
    $closer
    \n                # Ignore leading newline
    $&lt;content&gt; = .+?  # Remember everything else in the block
    \n                # Ignore leading newline
    $opener '/code' $closer
  }

  my $markdown = slurp $filename;

  if $markdown.match(/ &lt;shortcode&gt; /) {
    my $tangle-file = $/&lt;shortcode&gt;&lt;filename&gt;;
    my $tangle-content = $/&lt;shortcode&gt;&lt;content&gt;;
    spurt $tangle-file, $tangle-content;
    say "Tangled to $tangle-file";
  }
}</code></pre>
  
  </div>



<p>I love Raku’s approach to <a href="https://docs.raku.org/language/regexes">regular expressions</a>.  For starters, the syntax looks a bit more like
describing a grammar.  I can break the funny regex characters up with spaces, and clarify them with
comments.  In fact, I could someday build this up to a real <a href="https://docs.raku.org/language/grammars">grammar</a>.</p>
<p>Secondly, it addresses the fact that most text we look at these days contains multiple lines.
I didn’t have to worry about any special multiline flags to get this working.</p>
<p>Finally, getting at the named captures was — I wouldn’t say “obvious,” but at least “coherent.”
I can treat the match variable <code>$/</code> as a nested <a href="https://docs.raku.org/language/hashmap">Hash</a>.
The important bits look something like this:</p>
<pre><code>shortcode =&gt;
  filename =&gt; ｢hello.py｣
  content =&gt; ｢print("Hello")｣
</code></pre><p>I can grab the named capture <code>filename</code> of my matched <code>shortcode</code> regex with
<code>$/&lt;shortcode&gt;&lt;filename&gt;</code> — or <code>~$&lt;shortcode&gt;&lt;filename&gt;</code>, depending on your preferred syntax.</p>
<p>This is all possible in languages like Perl with assorted flags, but I haven’t seen parsing treated
so well by default since maybe <a href="https://randomgeekery.org/tags/rebol">REBOL</a>.</p>
<p>Anyways, let’s run this thing.</p>



<div><pre><code>$ raku tangle.raku
Tangled to hello.py
$ bat hello.py
───────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────
       │ File: hello.py
───────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────
   1   │ print("Hello")
───────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────</code></pre>
</div>

<p>Sweet.</p>
<p>Except — this Markdown file I’m writing.
It has <em>two</em> file code blocks now.
I want to tangle both of them.</p>
<h2 id="multiple-output-files">Multiple output files</h2>
<p>This requires a couple changes, since I’m writing code about Hugo shortcodes in a Hugo post.</p>
<p>To show shortcode directives without Hugo evaluating them, they need to look like shortcode
comments. Their contents will get passed straight through as part of your post.
To show <code>{{&lt; shortcode &gt;}}</code> in a post, your Hugo content needs <code>{{&lt;/* shortcode */&gt;}}</code>.</p>
<p>So that’s lovely and all, but can be a headache of its own for this specific situation of extracting
code from a blog post.</p>
<p>I need to remember this commented shortcode syntax.</p>










<div id=""><p><em>Define commented shortcodes</em></p>
    <pre><code data-lang="raku">  my $commented-opener = '{{' ~ '&lt;/* ';
  my $commented-closer = ' */&gt;' ~ '}}';</code></pre>
  
  </div>




<p>That way I can replace those commented shortcode delimiters with their normal counterparts when I tangle later.</p>










<div id=""><p><em>Replace commented shortcodes</em></p>
    <pre><code data-lang="raku">      my $tangle-content = $block&lt;shortcode&gt;&lt;content&gt;
        .subst(:global, / $commented-opener /, $opener)
        .subst(:global, / $commented-closer /, $closer);</code></pre>
  
  </div>



<p>Now that I have that particular detail out of the way, tangle every block? Sure! Make a regular
expression match <code>:global</code> and it returns a list containing every match.</p>










<div id=""><p><em>Tangle every block</em></p>
    <pre><code data-lang="raku">  my $markdown  = slurp $filename;
  my @fragments = $markdown.match(/&lt;shortcode&gt;/, :global);

  for @fragments -&gt; $block {
    my $tangle-file = $block&lt;shortcode&gt;&lt;filename&gt;;
    «replace-commented-shortcodes»
    spurt $tangle-file, $tangle-content;
    say "Tangled to $tangle-file";
  }</code></pre>
  
  </div>



<p>I think that about covers it. The shortcode recognition logic can stay the same.</p>






  





<div id="tangle-multi.raku"><p><a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/tangle-multi.raku" title="Download tangle-multi.raku" aria-label="Download">
          
        </a>tangle-multi.raku
    </p>
    <pre><code data-lang="raku">sub MAIN() {
  my $filename = "index.md";
  my $opener = '{{&lt; ';
  my $closer = ' &gt;}}';

  my regex shortcode {
    $opener
      code \h
      'file="' $&lt;filename&gt; = .+? '"'  # Remember the filename
      .*?
    $closer
    \n                # Ignore leading newline
    $&lt;content&gt; = .+?  # Remember everything else in the block
    \n                # Ignore trailing newline
    $opener '/code' $closer
  }

  «define-commented-shortcodes»

  «tangle-every-block»
}</code></pre>
  
  </div>



<p>And it works!</p>
<pre><code>$ raku tangle-multi.raku
Tangled to hello.py
Tangled to tangle.raku
$ bat tangle.raku
───────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────
       │ File: tangle.raku
───────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────
   1   │ sub MAIN() {
   2   │   my $filename = "index.md";
   3   │   my $opener = '{{&lt; ';
   4   │   my $closer = ' &gt;}}';
   5   │   my regex shortcode {
   6   │     $opener
   7   │       code \s
   8   │       'file="' $&lt;filename&gt; = .+? '"'  # Remember the filename
   9   │       .*?
  10   │     $closer
  11   │     \n                # Ignore leading newline
  12   │     $&lt;content&gt; = .+?  # Remember everything else in the block
  13   │     \n                # Ignore leading newline
  14   │     $opener '/code' $closer
  15   │   }
  16   │
  17   │   my $markdown = slurp $filename;
  18   │
  19   │   if $markdown.match(/ &lt;shortcode&gt; /) {
  20   │     my $tangle-file = $/&lt;shortcode&gt;&lt;filename&gt;;
  21   │     my $tangle-content = $/&lt;shortcode&gt;&lt;content&gt;;
  22   │     spurt $tangle-file, $tangle-content;
  23   │     say "Tangled to $tangle-file";
  24   │   }
  25   │ }
───────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────
</code></pre><p>Unfortunately, I’m not quite done yet.</p>
<h2 id="multiple-fragments">Multiple fragments</h2>
<p>I’m not done yet because I don’t like to describe my code a full file at a time. I’d rather talk
about this bit here, explain that bit over there, then mash it all up in the end.</p>
<p>Consistency counts, so I need to pick a syntax. Well — you’ve been reading along. You can see that I
already made my choice.  I got used to <code>&lt;&lt;fragment-text&gt;&gt;</code> in Babel, where the attribute is called
<code>name</code>. Might as well keep doing that over here. Oh but hang on. I want it to stand out a bit. I’ll
use angle quotes <code>«‥»</code>.</p>
<div>
  <p>Note</p>

  <p>On a US keyboard using <a href="https://randomgeekery.org/tags/vim">Vim or Neovim</a>, <code>«</code> is a <a href="https://vimhelp.org/digraph.txt.html#digraph.txt">digraph</a> which can be entered via <code>Control-k</code> followed by <code>&lt;</code> <code>&lt;</code>.
Or if you’ve set up a <a href="https://en.wikipedia.org/wiki/Compose_key">Compose</a> key, it’s <code>Compose</code> followed by <code>&lt;</code> <code>&lt;</code> in any editor.</p>
<p><code>»</code> is the same, but <code>&gt;</code> <code>&gt;</code> instead.</p>
<p><em>Or</em> you can use <code>&lt;&lt;…&gt;&gt;</code> in your code and ignore my recent obsession with fancy characters.</p>
<p>Yes, I know I could practically write it <em>all</em> with fancy characters in Raku. One step at a time.</p>
</div>

<p>Let’s go back to the Python code because it’s still so small.</p>
<p>Say I want to demonstrate the delightful <a href="https://rich.readthedocs.io/en/latest/">Rich</a> terminal library for Python.</p>










<div id=""><p><em>Import libraries</em></p>
    <div><pre><code data-lang="python"><span>from</span> <span>rich</span> <span>import</span> <span>print</span>
<span>from</span> <span>rich.panel</span> <span>import</span> <span>Panel</span>
<span>from</span> <span>rich.markdown</span> <span>import</span> <span>Markdown</span></code></pre></div>
  
  </div>



<p>But before I really use it in my code, I spend 1,500 words singing its praises.</p>
<p>It’s nice. I like it.</p>
<p>Okay, done singing. Time to write the rest of the program.</p>






  





<div id="rich-hello.py"><p><a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/rich-hello.py" title="Download rich-hello.py" aria-label="Download">
          
        </a>rich-hello.py
    </p>
    <div><pre><code data-lang="py"><span>«</span><span>import</span><span>-</span><span>libraries</span><span>»</span>

<span>md</span> <span>=</span> <span>Markdown</span><span>(</span><span>"**Hello**, *World*."</span><span>)</span>
<span>print</span><span>(</span><span>Panel</span><span>(</span><span>md</span><span>))</span></code></pre></div>
  
  </div>



<p>I identify the fragment with a <code>name</code> attribute:</p>
<div><pre><code data-lang="go-html-template"><span>{{</span><span>&lt;</span><span> </span><span>code</span><span> </span><span>name</span><span>=</span><span>"import-libraries"</span><span> </span><span>lang</span><span>=</span><span>"python"</span><span> </span><span>&gt;</span><span>}}</span>
from rich import print
from rich.panel import Panel
from rich.markdown import Markdown
<span>{{</span><span>&lt;</span><span> </span><span>/</span><span>code</span><span> </span><span>&gt;</span><span>}}</span>
</code></pre></div><p>My <code>code</code> block references the <code>import-libraries</code> fragment by name when I’m ready for it.</p>
<div><pre><code data-lang="go-html-template"><span>{{</span><span>&lt;</span><span> </span><span>code</span><span> </span><span>file</span><span>=</span><span>"rich-hello.py"</span><span> </span><span>&gt;</span><span>}}</span>
«import-libraries»

md = Markdown("**Hello**, *World*.")
print(Panel(md))
<span>{{</span><span>&lt;</span><span> </span><span>/</span><span>code</span><span> </span><span>&gt;</span><span>}}</span>
</code></pre></div>
<h3 id="rounding-up-fragments-to-tangle">Rounding up fragments to tangle</h3>
<p>Recognizing an additional parameter doesn’t make my regular expression <em>that</em> much more
complicated, but I can see things getting more complex — or me finding a better pattern later — so
let’s give the params their own named regex for some encapsulation.</p>










<div id=""><p><em>Shortcode params regex</em></p>
    <pre><code data-lang="raku">  my regex params {
      'file="' $&lt;filename&gt; = .+? '"'
      ||
      'name="' $&lt;fragment&gt; = .+? '"'
  }</code></pre>
  
  </div>



<p>That way I can drop it in <code>shortcode</code> to say “oh and look for <code>params</code> …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/">https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/</a></em></p>]]>
            </description>
            <link>https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819371</guid>
            <pubDate>Mon, 13 Jul 2020 10:56:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Explained: A Weekly Newsletter for React Learners]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819302">thread link</a>) | @jwworth
<br/>
July 13, 2020 | https://www.getrevue.co/profile/react-explained/ | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/react-explained/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="profile">
<div>
<section id="profile-info">
<section id="profile-image">
<figure title="React Explained"><img alt="React Explained" src="https://s3.amazonaws.com/revue/profiles/images/000/061/011/thumb/Twitter_Profile.png?1593093658"></figure>
</section>
<section id="profile-signup">
<header>
<hgroup>

<address>By Jake Worth</address>
<h2 title="React Explained - Do you want to really (really!) learn React, while staying current on this exploding ecosystem? Subscribe to React Explained, a weekly newsletter of amazing, curated React news and resources, simply explained. It’s free! Subscribe now."><p>Do you want to really (really!) learn React, while staying current on this exploding ecosystem? Subscribe to React Explained, a weekly newsletter of amazing, curated React news and resources, simply explained. It’s free! Subscribe now.</p></h2>
</hgroup>
</header>
<section id="profile-stats">
<span>60 subscribers</span>
<span><a href="#archive">9 issues</a></span>
<span><span>
<a target="_blank" href="http://twitter.com/reactexplained"><span></span>
</a></span>
</span>
<section>
<form id="new_member" action="/profile/react-explained/add_subscriber" accept-charset="UTF-8" method="post">
<div id="profile-form">
<div id="profile-form-fields">
<p><label for="member_email">Subscribe to our newsletter</label></p><div>

</div>
<p><label for="confirm_q3S3EM">This thingy has to be empti pwieshh</label>

</p>

</div>
</div>
</form></section>



</section>
</section>
</section>
</div>
</article></div>]]>
            </description>
            <link>https://www.getrevue.co/profile/react-explained/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819302</guid>
            <pubDate>Mon, 13 Jul 2020 10:46:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Mock Interviews – learn about data and SQL by solving interview tasks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819221">thread link</a>) | @makaronich
<br/>
July 13, 2020 | https://www.sqlhabit.com/about-mock-interviews | <a href="https://web.archive.org/web/*/https://www.sqlhabit.com/about-mock-interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<div>
  <div>
    <section>
      
<div>
  

  <div><p>
    Mock Interviews will help you to get ready for an upcoming SQL interview. It's also a great way to learn and practice Data Analytics with SQL. The format is simple:
    </p>
  </div>

  <p><a href="https://www.sqlhabit.com/signup">
    Try Mock Interviews <br>for free
</a></p></div>

    </section>

    <section>
      <div>
        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews@2x-7a6e7ee7be9670546e04b57481518131981519804003b13c30b96beb72b70db9.jpg 2x">
    <img alt="Prepare for an interview" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg">
  </picture>

  <div>
    <h2>
      Prepare for an interview
</h2>
    <p>
      Mock Interviews are based on SQL challenges from Data Analysis, Product Management and Marketing interviews. Youâ€™ll have 45 minutes to solve 2 challenges varying in difficutly: easy, medium, hard and hardcore. <img title=":rocket:" alt="ðŸš€" src="https://twemoji.maxcdn.com/2/svg/1f680.svg">

    </p>
  </div>
</div>

        </div>

        

        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents@2x-b68c6ed4cd81b4a5d61ed804f4a8960e4ad180d40ff917f40e5e5deba66ba0fa.jpg 2x">
    <img alt="Master Data Analysis with SQL Habit course" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg">
  </picture>

  <div>
    <h2>
      Master Data Analysis with SQL Habit course
</h2>
    <p>
      Go beyond Mock Interviews and learn specifics of Data Analysis with SQL Habit course. Youâ€™ll not only master SQL, but learn how to apply it in different scenarios from Product Management and Marketing. All based on a story of a startup. <img title=":books:" alt="ðŸ“š" src="https://twemoji.maxcdn.com/2/svg/1f4da.svg">

    </p>
  </div>
</div>

        </div>
      </div>
    </section>

    <section>
      
<div id="pricing">
  <h2>
    Buy unlimited access to SQL Habit
  </h2>

  <div>
    <div>
      
<div>
  <p>
    FUNDAMENTALS
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>25 free</strong> lessons and exercises
          </p>
        </div>
        
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://www.sqlhabit.com/signup">Sign up</a></p><p>
        *no credit card required
      </p>

  </div>
</div>

    </div>
    <div>
      
<div>
  <p>
    COMPLETE PACKAGE
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>200+</strong> lessons and exercises
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to SQL Habit, forever
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to Mock Interviews
          </p>
        </div>
        <div>
          


          <p>
            Verified <strong>LinkedIn certificate</strong>
          </p>
        </div>
        <div>
          


          <p>
            A <strong>private Telegram group</strong> with the author and your fellow course participants
          </p>
        </div>
        <div>
          


          <div>
            <p><strong>Monthly live Q&amp;A sessions</strong>, next one is scheduled for August, 1 </p>

          </div>
        </div>
        <div>
          


          <p><strong>1 year of Datagrip</strong> for free
          </p>
        </div>
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://gum.co/kwYeT">Buy now</a></p>

  </div>
</div>

    </div>
  </div>
</div>

    </section>

    <section>
        <section>
          <div>
  <h2>
    Reviews
  </h2>

  

  <div>
      <div>
        <p><span>SQL habit is the best online course I have done! It is my number one recommendation when it comes to learn SQL, for a beginner or even an advanced user.</span>

Anatoli has a gift to teach through examples in a very fun and playful way. The course covers real life example of the data analysis function of a company, starting with accessible SQL (read no prior experience needed), to very advanced SQL (yes, I mean...
        </p>

          
      </div>
      <div>
        <p><span>I am so excited that I have finally learnt SQL and realised how much I can gain from it in my daily work! The course gave me a better understanding of Marketing and Product Analytics</span> â€” how data is tracked, stored and interpreted â€” on web and for mobile apps. I can't wait to put my new skills into practice! I have tested few SQL courses and I would highly recommend SQL Habit without a doubt! Thank you very...
        </p>

          <p>
            Artur, Marketing Analyst @ Babbel
          </p>
      </div>
      <div>
        <p>
          SQL was something I never touched before starting this course. But being a Product Designer, I often asked my colleagues about how many users saw a specific landing page, where did they come from, how many people signed up, etc. It made me want to learn more about the data behind those magic numbers I got from them all the time. <span>This course was an incredible help to understand exactly that and it made me way more...
        </span></p>

          <p>
            Franziska, Product Designer
          </p>
      </div>
  </div>
</div>

        </section>
    </section>

    <section>
      
<div>
  <h2>
    Frequently Asked Questions
  </h2>

  <div>

      <div>
    <p>Can I try the course for free?</p>

    <p>Absolutely. The first 33 lessons and exercises are free. Just <a href="https://www.sqlhabit.com/users/new">signup</a> with your email, no credit card info required.</p>
  </div>
  <div>
    <p>Do you accept PayPal purchases?</p>

    <p>SQL Habit uses Gumroad to accept payment and Gumroad supports PayPal.</p>
  </div>
  <div>
    <p>Can I get an invoice?</p>

    <p>Absolutely! Right after purchasing youâ€™ll get a receipt which includes a link to generate an invoice with any extra information you need to add for your own accounting purposes.</p>
  </div>
  <div>
    <p>Do you have monthly subscription?</p>

    <p>Nope, one time purchase allows you to access it <strong>forever</strong>. Honestly, I believe itâ€™ll take you 1-2 months to really develop this strong SQL Habit. <img draggable="false" title=":muscle:" alt="ðŸ’ª" src="https://twemoji.maxcdn.com/2/svg/1f4aa.svg"></p>
  </div>
  <div>
    <p>Can I purchase SQL Habit for my team/company?</p>

    
  </div>
  <div>
    <p>What if I realize itâ€™s not for me?</p>

    <p>No problem! Ping me at <a href="mailto:support@sqlhabit.com">support@sqlhabit.com</a> and youâ€™ll be refunded in full, no questions asked (except feedback).</p>
  </div>

  </div>
</div>

    </section>
  </div>
</div>

    </div></div>]]>
            </description>
            <link>https://www.sqlhabit.com/about-mock-interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819221</guid>
            <pubDate>Mon, 13 Jul 2020 10:32:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A $50.000/year streaming service]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819201">thread link</a>) | @gianlucahmd
<br/>
July 13, 2020 | https://blog.gianlucamauro.com/post/harvard-online-learning/ | <a href="https://web.archive.org/web/*/https://blog.gianlucamauro.com/post/harvard-online-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <section>
  
</section>










        

<section>

    <section id="articleHero">
    <div>
        <header>
            
            <div>
                <div>
                    


    
            
    



<p>
                    July 10, 2020
                     • 3 min read
                </p></div>
            </div>
        </header>
        
        
        
    </div>
</section>

    

    <article id="articleContent">
        <p>Harvard University announced that next academic year will be 100% online.</p>
<p>And the tuition won’t be a dime cheaper.</p>
<p><img src="https://blog.gianlucamauro.com/images/harvard.png" alt=""></p>
<p>Why does it matter?</p>
<p>I don’t want to question the worthiness of such an investment. Yet, I can’t help but wonder if you’ll loose some of your returns by switching from the Harvard University halls to your web browser.</p>
<p>When you give $50.000 to a University like Harvard, you’re paying for a bunch of stuff. Mainly:</p>
<ul>
<li>Prestige</li>
<li>The network (your network is your net worth, right?)</li>
<li>Learning, obviously</li>
</ul>
<p>How will the new experience impact these aspects?</p>
<p>The prestige will stay intact. You can show off your Harvard badge on LinkedIn without having to specify where you studied.</p>
<p>I don’t think that you’ll get exposure to the same network as with physical classes. Human connection is paramount to build strong social ties. Yes, you can talk to people trough Zoom and stuff. But let’s stop hiding: Zoom is a poor quality proxy for face to face interaction. Hopefully when Covid will be over students will catch up with the social interactions they missed.</p>
<p>Let’s talk about learning now.</p>
<p>For years, online learning has been seen as a “second choice” learning format. Yes, it’s more comfortable and democratic than “real” university learning, but at the cost of some quality. I have to admit, I was guilty myself of this bias a few years ago.</p>
<p><strong>By changing medium without touching its price tag, Harvard changed the game. Harvard stated loud and clear that online learning is still learning. And it’s worth as much.</strong></p>
<p>This is a huge win for people like me that work hard to create the best online educational content possible.</p>
<p>This legitimates online learning. It acknowledges that the medium does not devaluate the knowledge, passion and teaching skills of the teacher.</p>
<p>Among all the change that Covid has brought to our lives, some will stick forever. Once the stigma around online learning will be gone, we’ll be left with a more democratic way of learning.</p>
<p>Who has something to teach will be free of sharing his experience without fear. Who wants to improve herself will be free to do so without the entry barriers of the Harvard halls.</p>
<p>And my biggest wish of all: <strong>companies will treat people that built their education online with the same respect of who spent $200.000 to sit in Harvard’s classrooms.</strong></p>
<blockquote>
<p>Let the future tell the truth, and evaluate each one according to his work and accomplishments - Nikola Tesla</p>
</blockquote>

    </article>
    
    

<section id="subscriptionSection">
    <div>
        <div>
            <h3>
                Get my thoughts in your inbox
            </h3>
            <p>
                Join my subscribers to get curated emails with my posts. 
                No spam, no marketing bullshit. Opt-out at anytime. You have my word I won't not spam your inbox or share your email with any third parties.
            </p>


            

        </div>
    </div>
</section>











    
    
    
        
    




<section id="articleNext">
    
    
    
</section>


</section>







 

        
        
    

    </div></div>]]>
            </description>
            <link>https://blog.gianlucamauro.com/post/harvard-online-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819201</guid>
            <pubDate>Mon, 13 Jul 2020 10:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Meddling Middlemen of Academia]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23819130">thread link</a>) | @Topolomancer
<br/>
July 13, 2020 | https://bastian.rieck.me/blog/posts/2020/middlemen/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/middlemen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>One of the strangest phenomena in academia is the reliance on publishing
companies. In this article, I want to outline some of the issues that
arise when working with publishers. I shall also endeavour to provide
some solutions to improve this collaboration.</p>
<p>Before we start, a brief <strong>disclaimer</strong>: this article will use an
amalgamation of different incidents that involved either myself, my
colleagues, or my friends.  Names&nbsp;(of the publishing companies)
have been withheld because I do not think it fair to use my ‘soapbox’
without giving the <em>other</em> side a chance to respond. Moreover,
everything I write here pertains to publishing your research in
a journal. Conference publishing—at least in machine learning—is
a joy<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. Plus, there <em>are</em> good examples of journals for machine
learning papers, foremost of them the <a href="http://www.jmlr.org/">Journal of Machine Learning
Research</a>. The ‘adversaries’ in this article are
rather the ‘big’ publishing companies and their practices. With that out
of the way, let us take a look at the state of the art!</p>

<p>If you are new to science, at some point, you will probably have to deal
with an established publishing company to get your article published.
The deal usually works like this:</p>
<ol>
<li>
<p>You look for a journal you want to publish in and submit your article
to the journal. This already often involves jumping through some
hoops. Without knowing the eventual fate of your article, you often
already have to abide by certain arbitrary formatting guidelines or
completely ‘butcher’ your article for the submission<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> by shifting
content around. However, this can be all accepted and endured because
of course, you want something from <em>them</em>, i.e. a published,
citable publication!</p>
</li>
<li>
<p>The journal then receives your submission—often through a web
interface that was developed with all the UX/UI knowledge of the
1980s<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> and has <em>never</em> been updated since—and this is where it gets
slightly <em>murky</em>. Another person—typically the editor of the
journal—now decides whether to accept the paper for reviewing, or
whether to provide you with a desk reject. A desk reject usually cannot
be appealed. It just shows you the door and leaves you to try again
with another journal&nbsp;(more murkiness here). For early-career
researchers like Ph.D. students submitting their first paper,
this can be highly discouraging. I see the reason for reducing the
workload on reviewers, of course, but I also heard of academic feuds
that were carried out on the backs of Ph.D. students and their
publications.</p>
</li>
<li>
<p>Assuming your paper ‘survived’ the desk reject, it will now be sent
to reviewers or referees. Their job is to review your paper
thoroughly, provide feedback, and in general give this whole business
a formal veneer. Setting aside problems in the reviewing
process—which I discussed <a href="http://bastian.rieck.me/blog/posts/2019/reviewing/">in another blog post</a>—this again opens up a portal into
a strange dimension: working as a reviewer for a journal is usually
a job that is provided for free&nbsp;(same goes for editorial
duties). Notice that this is <em>despite</em> the fact that those journals
are charging money to readers and universities. ETH Zurich, my
current employer, describes their experiences of the <a href="https://www.library.ethz.ch/en/Services/Using-ordering-resources/National-negotiations-with-publishers-Read-publish-reorganised">negotiations
with
publishers</a>
and mentions an expenditure of 6.4 million EUR&nbsp;(roughly 7.25
million USD) per year for being allowed to access journal articles.
That is a lot of money.</p>
<p>Setting aside the actual numbers here, let me just point out how
strange it is that companies are relying on <em>unpaid labour</em>, and this
reliance is <em>crucial</em> to their business model. They often do not
employ people that are qualified to judge the content that they want
to publish! But of course, reviewers and editors get the benefit of
<em>exposure</em>—that wonderful currency that is supposed to help your
career along! Even stranger: journals often charge hefty sums for
accessing your own research articles. To me, it is super weird that
research that is often <em>funded</em> by the taxpayer cannot be <em>accessed</em>
by the taxpayer.</p>
</li>
<li>
<p>Supposing your article got sufficiently good reviews to be published,
the next stage of the process starts. This is where the <em>meddling</em>
begins in earnest. After a little back and forth, you article will be
changed according to some arbitrary rules: the last period of every
sentence in an image caption will be removed, footnotes will be put
into the text—because for some reason, footnotes are permitted in
virtually every template and publishing medium, but deemed somewhat
uncouth by certain publishers—and you might have to redo certain
parts of your paper because of subtle font changes or what have you.</p>
<p>Again, lest you think of me as a particularly cranky person prone to
grumbling and finding faults, you are getting the wrong idea here.
I do not object to these changes, but I <em>do</em> object to the fact that
these meddlesome changes often decrease the quality of your paper.
Here are some irksome changes:</p>
<ul>
<li>
<p>Footnotes will be inserted willy-nilly into the text, regardless of
whether they make sense or not. That might break the flow of your
paper, but that is <em>your</em> problem.</p>
</li>
<li>
<p>Some ‘publisher house rules’ conflict with proper nomenclature in
a field. For example, the journal might have the ‘rule’ that all
fields in a table have to be capitalised. If this clashes with
nomenclature in your field, it is—you guessed it—<em>your</em> problem.</p>
</li>
<li>
<p>Your equations will typically be typeset yet
another time for you<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, which might introduce subtle changes: symbols
will change and you have to be go through your own paper once again
line-by-line to see whether anything untoward happened. Again, I am
primarily objecting to the substandard quality of this meddling:
the work that you put into writing your equations is completely
ignored, and now you have to chase—often very subtle—changes in
your own text. For mathematical typesetting, precision is crucial,
and it is unbecoming when people who do not <em>care</em> about this
precision create more work for you.</p>
</li>
<li>
<p>As a last example, your figures might be meddled with: you might be
forced to convert them into obsolete file formats&nbsp;(because
apparently, EPS is still the best format available), or, more
appallingly, vector graphics might be converted to raster
images&nbsp;(judging from the experiences of my friends and myself,
this is unfortunately relatively common!). This might sound like a tiny
problem again, but it decreases readability and accessibility for
some readers, and, more to the point of this post, it is somewhat
unnecessary meddling.</p>
</li>
</ul>
<p>Let me re-iterate my main point: I do not object to changing my
paper, I merely object to meddlesome changes that are just generating
useless work. For example, there is no need whatsoever to typeset
your equations again—this is quite literally the definition of
negative work.</p>
</li>
<li>
<p>If you survived this ordeal intact, you now must <em>pay</em>. To be fair,
not all journals charge you for normal articles, but <em>most</em> of them
charge you for open access publishing. In other words: if I want my
research, which is generously funded<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> by the Swiss taxpayers, to
be available to those selfsame taxpayers, I have to pay. The amounts
vary a little bit, of course, but we are talking upwards of a few
hundred USD at least. Luckily, this is <em>not</em> a problem for my
research group; my postdoctoral adviser, <a href="https://bsse.ethz.ch/mlcb/karsten.html">Prof. Karsten
Borgwardt</a> ensures that
sufficient funds for open access publications are available.</p>
<p>Interestingly, sometimes the cost is fielded by a conference; this
happens when the conference has a contract that ensures that its
publications will be available as special issue of some journal.
This might seem nice because it <em>shifts</em> the costs away from authors,
but it is also somewhat non-transparent; conference costs being high
already, I find it strange that some of the money goes into the
pockets of another party.</p>
<p>After all this negativity, it is time for a <em>positive example</em>:
NeurIPS, one of the flagship machine learning conferences, is
partnered with a publisher and makes <em>all</em> papers available for free
online. I <em>gladly</em> pay the conference fee for this!</p>
</li>
</ol>

<p>How can this process be improved? I have a few suggestions:</p>
<ol>
<li>
<p><strong>Transparency</strong>: publishers should make it clear <em>where</em> the funds are
going. Are we increasing shareholder value by working for free? How
are profits split and used?</p>
</li>
<li>
<p><strong>Giving back</strong>: it is generally understood that everyone needs to eat
and no one should have to work for free. Why is then that this
completely different in publishing? Almost all the profits are
essentially generated because editors and reviewers work for free.
I know that being remunerated for your reviewing work might raise
some questions about impartiality etc., so I think <em>paying</em> people to
write reviews might be somewhat problematic.</p>
<p>However, closely related to my point about transparency, publishers
could be more upfront about how they user their funds and <em>give back</em>
to the community. For example, publishers could sponsor students so
that they can visit a conference for free, or publishers could
sponsor the conferences themselves.</p>
<p>If you, as a publisher, engage the community and give back a little,
the community will be all the more happy to work with you. We need
you, but you also need us. Without the scientists, you cannot be
a scientific publisher.</p>
</li>
<li>
<p><strong>Commitment to excellence</strong>: publishers should commit to the highest
quality and the highest standards. Employ people that are capable of
working <em>with</em> the scientists, not <em>for</em> the scientists. Train your
employees to be experts in typography, typesetting, and pair them
with domain experts so that they do not create more work for the
authors by inadvertently destroying equations, figures, and so on.</p>
<p>This goal is not necessarily orthogonal to maximising your profits,
by the way: if you lower your standards, your reputation as
a publisher will suffer, meaning that scientists in the long
run&nbsp;(!) might not be willing to publish with you any more. If
you commit to excellence, by contrast, we will flock to you.</p>
<p>I know that working with a publisher that <em>cares</em> about the end
product as much as I do is a heavenly match! So we should endeavour
to make such …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bastian.rieck.me/blog/posts/2020/middlemen/">https://bastian.rieck.me/blog/posts/2020/middlemen/</a></em></p>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/middlemen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819130</guid>
            <pubDate>Mon, 13 Jul 2020 10:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real World Programming in SWI-Prolog]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23818901">thread link</a>) | @luu
<br/>
July 13, 2020 | http://www.pathwayslms.com/swipltuts/ | <a href="https://web.archive.org/web/*/http://www.pathwayslms.com/swipltuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>This is a hopefully ever expanding collection of tutorials on aspects of the SWI-Prolog environment.
Our emphasis is on learning to write <b>real world</b> applications in SWI-Prolog.</p>

<ol>
<li><a href="http://www.pathwayslms.com/swipltuts/dcg/index.html">Definite Clause Grammars</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/html/index.html">Web Applications</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/clpfd/clpfd.html">Constraint Logic Programming over Finite Domains</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/message/index.html">Printing Messages in SWI-Prolog</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/chr/index.html">Constraint Handling Rules</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
</ol>

<h2>Stuff that's in the general vein of the <i>Real World</i> tutorials, but are by others</h2>
<ul>
<li>There is a <a href="http://swish.swi-prolog.org/example/dict.swinb">SWISH tutorial on the dict structure</a> that was introduced with revision 7.0</li>
<li>There is a <a href="http://swish.swi-prolog.org/example/tabling.swinb">SWISH tutorial on tabling</a> that was introduced with 7.2.3</li>
<li>Michael Richter maintains a tutorial on using modules with SWI-Prolog <a href="http://chiselapp.com/user/ttmrichter/repository/gng/doc/trunk/output/tutorials/swiplmodtut.html">Using Modules with SWI-Prolog</a></li>
<li>Michael Hendricks has a tutorial for his vastly nifty pack "Julian" for reasoning about dates and times <a href="http://mndrix.github.io/julian/index.html">Julian tutorial</a></li>
<li>The Amzi Corporation maintains a useful introduction to expert systems <a href="http://www.amzi.com/ExpertSystemsInProlog/">Expert Systems in Prolog</a></li>
</ul>

<h2>Other stuff by me (Anne Ogborn) about Prolog</h2>
<li><a href="http://www.pathwayslms.com/swipltuts/student/index.html">FAQ For The ##Prolog Channel</a> by Anne Ogborn and Michael Richter</li>
<li>A little story about <a href="http://www.pathwayslms.com/swipltuts/teacher/index.html">teaching Programming Languages courses that include Prolog</a></li>
<li><a href="https://www.youtube.com/watch?v=JmOHV5IlPyU">Youtube video (35 mins) of my tutorial on Pengines at Strange Loop 2014</a></li>
<li><a href="https://www.youtube.com/watch?v=G_eYTctGZw8">Youtube video (40 mins)</a> of Michael Hendricks' talk on Production Prolog, with great hints on practical Prolog</li>
<li>I gave a workshop on SWI-Prolog web development at <a href="https://thestrangeloop.com/">Strangeloop 2013</a> The workshop materials were basically the set of html tutorials collected into a single program. <a href="https://github.com/Anniepoo/strangeloop">You can get them here</a>.</li>

<h2>Selected other folks' tutorials and info about prolog</h2>
<ul>
<li>Roman Bartok maintains a great <a href="http://kti.ms.mff.cuni.cz/~bartak/prolog/index.html">tutorial introduction to Prolog</a></li>
<li>The introductory book <a href="http://lpn.swi-prolog.org/lpnpage.php?pageid=online">Learn Prolog Now</a> is online, and has embedded SWISH so you can run the examples right in the text</li>
<li>Help, my brain is melting <a href="http://www.pathwayslms.com/swipltuts/())).pl">())).pl</a></li>
</ul>

<h2>Contribute!</h2>
<p>We'd love to have more contributors of tutorials. Areas we'd love to see covered: Pldoc, The IDE, CLP, Expert Systems, aggregator library, and whatever else excites you.</p>



</div>]]>
            </description>
            <link>http://www.pathwayslms.com/swipltuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818901</guid>
            <pubDate>Mon, 13 Jul 2020 09:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark Web Price Index 2020]]>
            </title>
            <description>
<![CDATA[
Score 296 | Comments 205 (<a href="https://news.ycombinator.com/item?id=23818727">thread link</a>) | @known
<br/>
July 13, 2020 | https://www.privacyaffairs.com/dark-web-price-index-2020/ | <a href="https://web.archive.org/web/*/https://www.privacyaffairs.com/dark-web-price-index-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><b>The dark web has a longstanding reputation as a haven for the worst kinds of criminal activity. This reputation is not wholly unjustified, as there are indeed terrible things happening around the world that can be bought and sold on the dark web. </b></p><p><span>The privacy offered by software such as TOR creates an environment where criminals can sell their wares on the dark web without the worry of law enforcement.</span></p><p><span>What’s more, many will have heard the horror stories of people’s bank accounts being cleaned out, or their identity stolen and turning up in custody in Mexico. Again, not unjustified horror.</span></p><p><span>You might be asking yourself, just how easy is it to obtain someone else’s personal information, documents, account details?&nbsp;</span></p><p><span>We certainly were.</span></p><p><span>To see just how prevalent such items of personal data are being listed, and at what price, we sent our researchers on a data-gathering mission into the dark web.</span></p><table><tbody><tr><td>Category</td><td>Product</td><td>Avg. dark web Price (USD)</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#2">Credit Card Data</a></td><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td></td><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td></td><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td></td><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td></td><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td></td><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td></td><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td></td><td>Walmart account with credit card attached</td><td>$10</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#3">Payment processing services</a></td><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td></td><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td></td><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td></td><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#4">Forged documents</a></td><td>US driving license, average quality</td><td>$70</td></tr><tr><td></td><td>US driving license, high quality</td><td>$550</td></tr><tr><td></td><td>Auto insurance card</td><td>$70</td></tr><tr><td></td><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td></td><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td></td><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td></td><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td></td><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td></td><td>Europe national ID card</td><td>$550</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#5">Social Media</a></td><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td></td><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td></td><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td></td><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td></td><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td></td><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td></td><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td></td><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td></td><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td></td><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td></td><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td></td><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td></td><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td></td><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td></td><td>Instagram likes x 1000</td><td>$6</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#6">Malware</a></td><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td></td><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td></td><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td></td><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td></td><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td></td><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td></td><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td></td><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td></td><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td></td><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td></td><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td></td><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td></td><td>Android x 1000</td><td>$600</td></tr><tr><td></td><td>Premium x 1000</td><td>$6000</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#7">DDoS Attack</a></td><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td></td><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table></section><div><section id="1"><h2>What We Found</h2><p>Whilst there are many marketplaces on the dark web, there are even more forum posts warning of scammers. This makes verified prices difficult to obtain without ordering the items to find out, which of course we didn’t.</p><p>Our methodology was to scan dark web marketplaces, forums, and websites, to create an index of the average prices for a range of specific products.</p><p>We were only interested in products and services relating to personal data, counterfeit documents, and social media.</p><p>This is what we found.</p></section><section id="2"><h2>Cloned credit cards and associated data</h2><table><tbody><tr><td>Product</td><td>Average dark web Price (USD)</td></tr><tr><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td>Walmart account with credit card attached</td><td>$10</td></tr></tbody></table><p>Credit card details usually come in the format CC|MM|YY|CVV|HOLDER_NAME|ZIP|CITY|ADDRESS|EMAIL|PHONE with the first 4 sections being the details on the card and the rest the details of the account holder. This will definitely cause a major inconvenience, but the prospect of someone using your online banking logins to gain full access to your account is far more daunting.</p><p><a href="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png"><img src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" data-src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" alt="Dark web credit card price" width="840" height="447"></a></p><p>Vendors tend to offer a guarantee of 80%. Meaning that two of every ten cards either won’t work or will have less than the advertised balance. We didn’t order any so can’t verify whether this is true, but the prevalence of these claims alongside the well documented increase in identity fraud cases suggests that there is a high turnover of such data.</p></section><section id="3"><h2>Payment processing services</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr></tbody></table><p>PayPal account details were easily the most common items listed, and extremely cheap. More expensive was actual transfers from a hacked account.</p><p>Another very common item for sale was guides on how to “cash out” – actually get the money in a way that doesn’t alert the authorities. These guides go for a few cents, but whether or not they actually work is not what we were looking for.</p></section><section id="4"><h2>Forged documents</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>US driving license, average quality</td><td>$70</td></tr><tr><td>US driving license, high quality</td><td>$550</td></tr><tr><td>Auto insurance card</td><td>$70</td></tr><tr><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td>Europe national ID card</td><td>$550</td></tr></tbody></table><p>These documents came with a range of guarantees and are available with any details the buyer chooses. With just a few pieces of real information about someone, a criminal could create a whole file of official documents to be used for all sorts of fraudulent activities. This one way in which an identity is stolen.</p><h3>Counterfeit money</h3><p>Counterfeit banknotes are extremely common, mainly in 20 or 50 denominations.</p><p>We came across USD, EUR, GBP, CAD, AUD most often. Some come with a UV pen test guarantee. The “quality” ones tend to cost around 30% of the banknote value.</p></section><section id="5"><h2>Social media</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td>Instagram likes x 1000</td><td>$6</td></tr></tbody></table><p>Offers to hack accounts or sell them were relatively scarce, but not non-existent. Perhaps due to a lack of demand for the product coupled with increased security practices. Hackers trying to get the social media credentials from their victims mostly have to resort to using <a href="https://www.getsafeonline.org/blog/what-is-pii-and-how-do-you-keep-it-private/">social engineering techniques</a>, which have a very high effort input for relatively low success ratio.</p><p>The extremely low cost for social engagement should seriously make you question an account’s validity before blindly trusting their wealth of social currency.</p></section><section id="6"><h2>Malware</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td>Android x 1000</td><td>$600</td></tr><tr><td>Premium x 1000</td><td>$6000</td></tr></tbody></table><p>Malicious tools are installed on comprised systems (Windows, Android and others) which gives attackers access to the system. Initial installation is via fake online casino, FB/social networks, warez websites etc.</p><p>Some forms of malware may simply use your computer’s resources for activities such as cryptocurrency mining. Others may be used to steal credentials as you enter them on a website. For each 1000 installs, hackers can often steal tens of thousands of dollars.</p></section><section id="7"><h2>DDoS attack</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table><p>A distributed denial of service (DDoS) attack aims to take a website offline by sending thousands of requests per second in order to overload the website’s server, causing it to crash.</p></section><section id="8"><h2>Why This Data Is Important</h2><p>For the average person, underground market data isn’t necessarily going to provide much use as they most likely aren’t shopping around for stolen card data or PayPal accounts. Though this is true, the prices at which these items sell provide a powerful perspective.</p><p>If someone gets their hands on your financial details or social media credentials, the prices mentioned above is basically what it’s worth to them. There’s a good chance that you value these things much more than they do, as to them you’re just another mark for a quick buck.</p><p>For far less than the amount your data would sell for on the black market, you can protect it from ever having to reach their hands with a couple of simple rules and habits. With this knowledge, there’s no excuse not to do what you can to protect your data.</p><p>Nothing is foolproof however, and …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.privacyaffairs.com/dark-web-price-index-2020/">https://www.privacyaffairs.com/dark-web-price-index-2020/</a></em></p>]]>
            </description>
            <link>https://www.privacyaffairs.com/dark-web-price-index-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818727</guid>
            <pubDate>Mon, 13 Jul 2020 09:08:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial sites treating FreeBSD like a Linux distro]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 82 (<a href="https://news.ycombinator.com/item?id=23818702">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>On the Gold Coast in January, Deb Goodkin from the FreeBSD Foundation began her Linux.conf.au talk with an intentionally-provocative slide: <em>FreeBSD, that’s just another Linux distro, right?</em> It was said in jest to highlight what a common misconception it is.</p>
<p>One way this manifests is through introductory FreeBSD guides online, usually on blogs with the words sysadmin, cookbook, or tutorial in their names; you know the ones I’m talking about. Invariably they advise updating the base system and pkgng, then immediately installing bash, nano, htop, lsof, coreutils, proc, and more. Some go as far as aliasing these over the built-in tools, and even setting bash as the root shell. From then on, you barely have to touch the FreeBSD userland.</p>
<p>Like a poorly-maintained cheese utensil, this used to grate. If you’re installing an entire GNU toolchain, why not use a Linux distribution, or Debian/kFreeBSD, or a Nexenta-like OS that’s built specifically for those tools? You’re not learning about FreeBSD’s features, nor are you taking advantage of any of its benefits beyond the kernel and base. It’s wasted opportunity, and could render future project contributions more difficult because of misunderstood assumptions about how the system works.</p>
<p><img src="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg" srcset="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg 1x, https://rubenerd.com/files/2020/usebsd-pillow@2x.jpg 2x" alt="A photo of a pillow saying: Use BSD"></p>
<p>I’ve since changed my tune somewhat, with a caveat. I also want to take this opportunity— not a sponsor—to spruik Jay Patel’s <a href="https://www.redbubble.com/people/jaypatelani/shop">RedBubble store</a> for your BSD laptop and loungeroom. I’ve already added some to next sticker batch.</p>
<p>What was I talking about?</p>
<p>We should be encouraging Linux people to try FreeBSD, and if giving them their familiar tooling gets their foot in the door, it’s worth it. I personally learn things the quickest by jumping in the deep end, but I know others want to take things a step at a time.</p>
<p>What also gets lost in the fray is FreeBSD, even with all those Linux-focused tools, is still a compelling and useful operating system. It’s a feature not a bug to be able to have all these tools available, and at times run them faster than Linux could on the same hardware. It may even integrate better into shops that otherwise entirely run Linux, given the motivation to write portable, POSIX-compliant code and applications is no longer a priority for most people (sadface).</p>
<p>So rather than saying those guides aren’t useful or even misrepresent FreeBSD, we need to reframe them. Instead of <em>introductions to FreeBSD</em>, say they’re <em>FreeBSD for Linux people</em>. This shouldn’t be constued as criticism; the latter kinds of post would be <em>hugely</em> useful. It’s also then easier to introduce BSD-specific tools and ideas, either inline after each Linuxism you introduce, or in a follow-up post where you compare and contrast.</p>
<p>We need more bridge-building and outreach between the two communities, and anything to make FreeBSD relatable to people coming from Linux, or any other operating system, is useful.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818702</guid>
            <pubDate>Mon, 13 Jul 2020 09:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Erasmus University Rotterdam builds first virtual campus in the Netherlands]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23818681">thread link</a>) | @vinrob92
<br/>
July 13, 2020 | https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands | <a href="https://web.archive.org/web/*/https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-history-node-id="61036"><p><span><p><time datetime="2020-07-09T12:13:58Z">Thursday, 9 Jul 2020</time></p> </span><span><p>Press release</p> </span></p> <figure> </figure><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Erasmus University Rotterdam (EUR) has re-created their Woudestein campus in the Minecraft platform to provide students and staff a sense of purpose and community during the Covid-19 crisis, a first for the Netherlands. The first blocks of the campus were laid by a small team of enthusiastic students and the project has since then mushroomed to include all buildings on campus, a secret underground labyrinth which players need to find, a treasure hunt for the 17 SDGs (de UN Sustainable Development Goals) and much more. </span></span></span></span></span></span></span></p><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Expansion plans are in the works for the Erasmus Medical Centre and the Erasmus University College. Through this project, EUR aims to fight the Covid-19 setback to the start of the academic year 2020-2021, by giving a platform to the Erasmus community to engage with each other.</span></span></span></span></span></span></span></p><div> <article data-video-provider="YouTube" data-video-id="cQ_Ke1z_Cjo"><div> <picture> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=7Ncx-0nR 1x" media="(min-width: 992px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_desktop/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=pjuiFzAV 1x" media="(min-width: 768px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_tablet/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=SqdQGgEy 1x" media="(min-width: 480px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ 1x" type="image/png"> <img src="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ" alt="Introducing The Virtual Campus - Erasmus University Rotterdam"> </picture></div><div> <h2>Introducing The Virtual Campus - Erasmus University Rotterdam</h2></div></article></div><div><h2>Campus recreated brick by brick</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>It started off as a project to provide students an opportunity for social engagement outside of the Zoom-filled lectures after the Covid-19 pandemic brought universities to a physical shutdown. After a research the Erasmus University Rotterdam (EUR) conducted into the effects of the Corona Crisis on the well-being of its students and staff members, the results strongly pointed towards the need for something to keep the Erasmus community together. People started to feel lonely and missed the ability to socially interact with each other, exactly that what a physical campus is able to provide a podium for. In an attempt to tackle this issue, ErasmusX – a disruptive innovative unit of the university – launched a creative project whereby students and staff could recreate their beloved Woudestein campus in the virtual gaming platform Minecraft. The very first building blocks were laid by members of the student-led Erasmus E-sports Community, and thereafter a professional Minecraft building team helped polish up the final product.</span></span></span></span></span></span></span></p></div><div><h2>"What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale"</h2></div><div><div><h2>Woudestein: a place to meet friends</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>To the EUR community, the campus is not just a place you go to in order to study and work. It is a place where you meet your friends (that perhaps have become like family), where you develop yourself as a human being, where you hang out and where you dream about the opportunities life has in store for you. It almost feels like a small village. “This feeling was so apparent when we saw the many emotional reactions from students and colleagues when they first see the virtual campus – they tell us that navigating the campus makes them feel like they are there again”, states Alexander Whitcomb, a project team member. “What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale. So walking from one end of the campus to the other with your avatar in Minecraft takes exactly the same amount of time as it would do in real life.“</span></span></span></span></span></span></span></p></div></div><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>The Minecraft campus has two main purposes. First it will be used for various planned activities such as onboarding all new incoming students during the famous EurekaWeek 2020, virtual tours for prospective students and the ErasmusX team is also exploring the game platform for educational and research purposes. Secondly, the campus is designed as a creative space, a way for students and staff to design their own interactions and discover new, innovative ways of engaging with one another through the virtual campus. The platform will be moderated by the Erasmus E-sports Community and all ideas are welcomed.</span></span></span></span></span></span></span></p><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Ultimately, the campus in Minecraft is there to strengthen the community of Erasmians, in an academic year where physical interactions are limited by Covid-19, and a ‘normal’ university experience remains unavailable until further notice.</span></span></span></span></span></span></span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818681</guid>
            <pubDate>Mon, 13 Jul 2020 08:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Remote Control Keypad Silicone Oil Problem (2008)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818632">thread link</a>) | @edgartaor
<br/>
July 13, 2020 | http://www.michaelshell.org/gadgetsandfixes/keypadsiliconeoil.html | <a href="https://web.archive.org/web/*/http://www.michaelshell.org/gadgetsandfixes/keypadsiliconeoil.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content">
<p><img src="http://www.michaelshell.org/img/dish_remote_80x250.png" width="80" height="250" alt="Echostar 3000 remote control"></p>
<p id="first_paragraph">
The symptoms are all too familiar - the buttons of a remote control
require very hard presses to be recognized, and the problem only
gets worse with time. Many, many, millions of remotes are replaced
and/or discarded because of this problem. Upon investigating the cause,
I found the presence of an oily substance between the rubber keypad
and the printed circuit board (PCB) it makes contact with. At first, I thought
it was the result of a spill or perhaps even a buildup of hand oil
(and there are technicians who can never be convinced otherwise).
However, the oil did not seem to be petroleum-based as it was highly
resistant to detergent. It reminded me a lot of DOT 5 silicone brake fluid.
And in fact, that is exactly what it turned out to be - silicone oil.
Here is a quote from section 7.0 of the
<span>Silicone Rubber Components Manual</span>
of the Danish company J.D. Friderichsen A/S (which does not exist any more as it was
purchased by the Danish company
<a href="http://www.fst.dk/">Fritz Schur Teknik</a>
in 1999, and the manual is now available only as an
<a href="http://web.archive.org/web/20020225183655/http://www.jdf.dk/esilman/esilman6.htm">internet archive</a>),
which among other things, manufactured silicone rubber keypads:
</p>

<div>
<p>
<strong>7.0 Quality</strong>
</p>
<p>
It is a matter of confidence to buy silicone rubber components, because the
purchaser has to has be certain that the silicone oil is baked out of the
keypad, in order to ensure that quarts don't form on the circuit board and
thereby disrupt the connection. Most of us have probably had this experience
with a remote control at home. (However an incident such as this can also
happen in situations where the OEM are using conductive ink instead of contact
pillars in order to reduce the cost). The only way to control if the silicone
is baked out properly is to check if the keypad has lost some weight after it
has been baked. The current problem is that many far east manufacturers are
used to manufacturing components for cheap products such as one dollar
calculators, and are having difficulties recognizing the requirements set by
western manufacturers. They might not "forget" it for the first few supplies,
but maybe later. The result will surface a few years down the line, so you are
required to know your supplier well. It is equally important that the printed
symbols is baked into the keys, to ensure they don't wear off. A large variety
of qualities are available to the buyer on the market, and you will probably
experience that our price is DKK 0,25 higher than our competition. You are
however welcome to test our quality with an eraser.
</p>
</div>

<p>
I posted about this issue on December 8, 2000 in the thread
<a href="http://groups.google.com/group/sci.electronics.repair/browse_thread/thread/c14d8e962b605e97/ff097119b1b968b1">"Do remote keypads sweat silcone oil?"</a>
(dang it, I misspelled "silicone" in the title) to the Usenet group sci.electronics.repair
and have received email about that post years thereafter. The solution is easy enough - to clean
and degrease the internals of the remote. And this will have to be repeated every
few years, although the interval will become longer as the amount
of oil trapped in the rubber keypad decreases. The remote for my old
Dish Network 3000 satellite receiver (shown at the upper right) was a major offender
and required cleaning every year. My more recent Dish Network 3900 remote, requires
cleaning every 3-5 years. Based on my experience, most remotes with silicone
rubber keypads cannot go a decade without needing to be cleaned. The pressure
generated by pressing a button rather than time itself appears to be the trigger
by which oil is released. So, all things being equal, a remote that is used more often
releases more oil. In theory, it should be possible to bake the oil out yourself
as silicone rubber can take high temperatures (spark plug boots are made out of it).
However, I don't know what temperature is needed or how well the conductive rubber
contacts can withstand this heat without an oxygen-free environment.
</p>

<p>
Now, it is true that silicone oil contamination is not the only cause of
unreliable remotes. Other common problems include bad solder connections
(especially at the LED and battery terminals), worn contacts on the
keypad or PCB, or microbreaks of the PCB traces. While you have the remote apart,
be on the lookout for these other problems. If spotted, bad solder connections
are easy enough to fix by reflowing the solder with a soldering iron. Broken PCB
traces can be really tough to find, but fortunately this normally does
not happen unless the remote has been abused. Worn keypad contacts
are tough to fix. There are conductive rubber repair kits for this
purpose, but they can involve careful cutting and gluing. Sometimes
fine (1000 grit) sandpaper can be used to clean oxides off of the contact
surfaces, but it is all too easy to destroy the conductive rubber contacts
and does not seem to be necessary, so I don't recommend this. You could
try it on stubborn keys if you've tried everything else and have nothing
to loose if it ruins the remote.
</p>


<!-- Amazon Electronics General Bestsellers Ad -->
<!--[if !IE]> <-->

<!----> <!--[endif]---->
<!--[if IE]>
<div class="amazon_ad_ie">
<iframe src="http://rcm-na.amazon-adsystem.com/e/cm?t=micshesweb-20&amp;o=1&amp;p=15&amp;l=bn1&amp;mode=electronics&amp;browse=172282&amp;fc1=000000&amp;lt1=&amp;lc1=3366FF&amp;bg1=FFFFFF&amp;f=ifr" style="border:none;" marginwidth="0" marginheight="0" width="468" height="240" border="0" frameborder="0" scrolling="no">
</iframe>
</div>
<![endif]-->



<h2>Opening and Cleaning the Remote</h2><p>
It isn't the easiest thing in the world to open a remote. First, open the battery
compartment, remove the batteries and unscrew any case screws that are visible.
Using a flat-bladed screwdriver, press fairly hard (take care that you don't stab
yourself should it slip) into the seam between the two halves to
disengage the plastic catches and then twist to snap them apart. Some areas of the
remote are easier to do than others. So, if one place is tough, move to another
position. Once you've got one area unsnapped, work your way all around the remote
until both halves are separated. No matter how careful you are, the screwdriver may
leave raised areas that will make the remote feel terrible in the hand. Shave these
"pips" off with a razor blade knife until they cannot be felt. If you break too many
plastic catches (often caused by not pressing inward to help disengage them before
twisting the screwdriver), you'll have to use something such as silicone sealer (which
will allow the case to be reopened without further damage, but does require a day
to cure) to hold the two halves together when you reassemble it. My open Dish Network
3000 remote and its rubber keypad is shown in figure 1:
</p><div>
<p><img src="http://www.michaelshell.org/img/dish_remote_open_oil_600x392.jpeg" width="600" height="392" alt="An open Dish Network remote control"></p><p>Figure 1: An open Dish Network remote showing silicone oil.</p>
</div><p>
Note the oil just running down the keypad. A closeup is shown in figure 2:
</p><div>
<p><img src="http://www.michaelshell.org/img/dish_remote_oil_closeup_600x300.jpeg" width="600" height="300" alt="closeup of the oil"></p><p>Figure 2: A closeup view of the oil.</p>
</div><p>
This is not the result of a spill, but comes from inside the rubber. Clean and degrease
the entire remote (both case halves inside and outside, both sides of the rubber keypad,
and both sides of the PCB) using a strong detergent (such as 409, dish detergent or
Simple Green) and a toothbrush. Thoroughly scrub the parts with the toothbrush and flush
them with a strong stream of warm water to help push the oil off. You may have to repeat
this as the oil can be stubborn to remove. Thoroughly dry the parts. Blowing them off
with compressed air and letting them dry overnight is perhaps the best approach. Lay the
keypad and filter window in their proper positions and resnap the case together. Reinstall
any screws and the batteries. If your work was successful, you'll be amazed at how
sensitive the keys are compared to the way they were before and you can congratulate
yourself for saving some money. Good luck.



</p></div></div>]]>
            </description>
            <link>http://www.michaelshell.org/gadgetsandfixes/keypadsiliconeoil.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818632</guid>
            <pubDate>Mon, 13 Jul 2020 08:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Exploratory Data Analysis (EDA)? An Introduction with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818607">thread link</a>) | @fabdrnd
<br/>
July 13, 2020 | https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/ | <a href="https://web.archive.org/web/*/https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.deepflow.ai/content/images/size/w300/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 300w,
                            https://www.deepflow.ai/content/images/size/w600/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 600w,
                            https://www.deepflow.ai/content/images/size/w1000/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 1000w,
                            https://www.deepflow.ai/content/images/size/w2000/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.deepflow.ai/content/images/size/w2000/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg" alt="What is Exploratory Data Analysis? Yes, another post on EDA">
            </figure>

            <section>
                <div>
                    <p><em>Christophe Pere is a senior NLP researcher and a Deepflow advisor. His post was originally published on <a href="https://towardsdatascience.com/what-is-eda-yes-another-post-on-eda-d8b5c06269a9">Medium</a>. Cover picture: <a href="https://unsplash.com/@markusspiske">Markus Spiske</a> — <a href="https://unsplash.com/s/photos/math">Unsplash</a></em></p><blockquote>A notebook containing all the relevant code is available on <a href="https://github.com/Christophe-pere/EDA" rel="noopener nofollow">GitHub</a>.</blockquote><p>Yes, this is a new post among many that address the subject of EDA. This step is the most important of a Data Science project. Why? Because it allows you to acquire knowledge about your data, ideas, and intuitions to be able to model it later.</p><p>EDA is the art of making your data speak. Being able to control their quality (missing data, wrong types, wrong content …). To be able to determine the correlation between the data. To be able to know the cardinality.</p><p>But not only, EDA is not just about exploring data. When you have a target, a column containing label (supervised learning) you also have feature selection and Feature Importance. Without, you have Feature Extraction (unsupervised learning).</p><p>For years, the best way was to tirelessly code the same functions to calculate correlations, plot variables, manually explore the columns to calculate interesting variables, etc…</p><p>But now there are simpler, faster, and more efficient ways to do all of this:</p><h2 id="ia-pandas-profiling">Ia. Pandas-profiling</h2><p>The first, <a href="https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/introduction.html" rel="noopener nofollow">pandas-profiling</a>, can create reports in HTML format with a very nice interface of the content of a <em>dataframe</em>. Based on pandas, it allows with exceptional performance (up to a million lines, recommendation to be taken into account) to make a complete exploration of the data. This report can be integrated via a widget in <em>jupyter lab </em>or <em>notebook</em>. Or, it can also be presented as a frame.</p><p>As the authors indicate, you’ll the relative information:</p><blockquote><strong>Type inference</strong>: detect the types of columns in a dataframe.</blockquote><blockquote><strong>Essentials</strong>: type, unique values, missing values</blockquote><blockquote><strong>Quantile statistics</strong> like minimum value, Q1, median, Q3, maximum, range, interquartile range</blockquote><blockquote><strong>Descriptive statistics</strong> like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness</blockquote><blockquote><strong>Most frequent values</strong></blockquote><blockquote><strong>Histograms</strong></blockquote><blockquote><strong>Correlations</strong> highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices</blockquote><blockquote><strong>Missing values</strong> matrix, count, heatmap, and dendrogram of missing values</blockquote><blockquote><strong>Duplicate rows</strong> List the most occurring duplicate rows</blockquote><blockquote><strong>Text analysis</strong> learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data</blockquote><blockquote>source: <a href="https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/introduction.html" rel="noopener nofollow">pandas-profiling</a></blockquote><p>You can find examples on the <strong><em>GitHub </em></strong>page of the library like:</p><ul><li><a href="https://pandas-profiling.github.io/pandas-profiling/examples/master/meteorites/meteorites_report.html" rel="noopener nofollow">NASA Meteorites landing</a> this report is the output of the function profil_report() and it shows how powerful is this library.</li></ul><p>How to use it? In a few line of code, let me show you:</p><p>It takes a few seconds to compute compare to something hardcoded to get an impressive result.</p><p>The result when you show the report in a widget:</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png 1005w" sizes="(min-width: 720px) 720px"><figcaption>Pandas-profiling profile report in widget (rendering)</figcaption></figure><p>The result when you show the report in a frame inside the notebook:</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png 1004w" sizes="(min-width: 720px) 720px"><figcaption>Pandas-profiling HTML in a frame (rendering)</figcaption></figure><h2 id="ib-dataprep-eda">Ib. Dataprep.eda</h2><p>Another great library is <strong><em>dataprep</em></strong> with module <strong><em>eda</em></strong>. What is doing?</p><p>You have three main functions:</p><ul><li><strong>plot</strong></li></ul><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png 1044w" sizes="(min-width: 720px) 720px"><figcaption>plot function of the dataprep.eda package on the Boston House Prices data set</figcaption></figure><p>This function will show you a histogram for each feature. Each plot is interactive based on the <strong>bokeh </strong>library. You have different parameters that allow you to show information on the data you want.</p><ul><li><strong>plot_correlation</strong></li></ul><p>The function allows you to compute three sorts of the correlation matrix (Pearson, Spearman, and KendallTau). The advantage is that the plot is also interactive and you can see the values just putting the cursor on it.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-ZqLi8cHnCYnPf0XtgDsyHg.png" alt=""><figcaption>plot_correlation on Boston House Prices data set</figcaption></figure><ul><li><strong>plot_missing</strong></li></ul><p>This last function is very interesting like the picture below shows you. It allows you to visualize where the missing data are in the column and the percentage of them.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-6qEJdtUj4v_ITqSEHlW05Q.png" alt=""><figcaption>plot_missing function</figcaption></figure><h2 id="ic-sweetviz">Ic. Sweetviz</h2><p>The last interesting library is <a href="https://github.com/fbdesignpro/sweetviz" rel="noopener nofollow">sweetviz</a>. Based on pandas-profiling the library permits to compare different columns or the train and test part of your data to determine if the test set is representative of the train. Like pandas-profiling, you have tons of information per columns. The picture below shows the dashboard of the HTML report generated by the library.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png 1592w" sizes="(min-width: 720px) 720px"><figcaption>Comparison between train and test with Sweetviz</figcaption></figure><p>EDA is not just a focus on what is inside the data. You can also go deeper into the analysis with the following parts. The feature selection is a manner to reduce the number of features present in your dataset.</p><p>Here, I just present three ways to do it. The <a href="https://scikit-learn.org/" rel="noopener nofollow">sklearn </a>library has powerful modules to do what you want in terms of selecting or extracting data.</p><h2 id="iia-removing-feature-with-low-variance">IIa. Removing Feature with low variance</h2><p>This technique simply makes it possible to select the features which have a threshold lower than that fixed. It removes all features whose variance doesn’t meet some threshold. By default, it removes all zero-variance features, i.e. features that have the same value in all samples. In the code below, the columns with more than 80% missing data are automatically deleted. This method doesn’t look to the prediction variable y so it can be used in an unsupervised way.</p><pre><code>from sklearn.feature_selection import VarianceThresholdthreshold = 0.8 # 80% of low variance

fe_low_variance = VarianceThreshold(threshold=(threshold * (1 - threshold)))
X_variance = fe_low_variance.fit_transform(X)</code></pre><h2 id="iib-univariate-selection">IIb. Univariate Selection</h2><p>In supervised learning, you have a target feature (commonly named <strong><em>y</em></strong>). The goal of the univariate selection is simple, to take one feature to make a variation on it, and see how it affects the estimated target. In the end, the univariate select will select the best feature based on the univariate statistical test.</p><p>With sklearn, you have 4 methods to do it.</p><ul><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest" rel="noopener nofollow"><strong>SelectKBest</strong></a>: This will select the best <strong><em>k</em></strong> (manually chooses by the user) features of your dataset and removes the others. This function needs a scorer, a metric function to apply the selection. The commonly used scorer function is <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2" rel="noopener nofollow"><strong><em>chi2</em></strong></a>.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile" rel="noopener nofollow"><strong>SelectPercentile</strong></a>: Same as <em>SelectKBest </em>you need to pass a scorer, but instead of a <strong><em>k</em></strong> number of features, you pass a percentile value.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFpr.html#sklearn.feature_selection.SelectFpr" rel="noopener nofollow"><strong>SelectFpr</strong></a><strong>/</strong><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFdr.html#sklearn.feature_selection.SelectFdr" rel="noopener nofollow"><strong>SelectFdr</strong></a><strong>/</strong><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFwe.html#sklearn.feature_selection.SelectFwe" rel="noopener nofollow"><strong>SelectFwe</strong></a>: selection by the <strong><em>pvalues</em></strong> based on the false positive rate, the false discovery rate, and the family-wise error.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html#sklearn.feature_selection.GenericUnivariateSelect" rel="noopener nofollow"><strong>GenericUnivariateSelect</strong></a>: Here you can customize your estimator with configurable strategy.</li></ul><p>In the code below I use <strong><em>SelecKBest </em></strong>with <strong><em>chi2 </em></strong>scorer:</p><pre><code>from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

#apply SelectKBest class to extract top 10 best features
select_best_features = SelectKBest(score_func=chi2, k=10) # where k is the number of features you want
fit = select_best_features.fit(X,y)
df_scores = pd.DataFrame(fit.scores_)
df_columns = pd.DataFrame(X.columns) # where X is your data
#concat two dataframes for better visualization
feature_scores = pd.concat([df_columns,df_scores],axis=1)
feature_scores.columns = ['Specs','Score']  #naming the dataframe columns
print(feature_scores.nlargest(10,'Score'))  #print 10 best features</code></pre><h2 id="iic-recursive-feature-elimination">IIc. Recursive Feature Elimination</h2><p>As the picture below shows, the principle of the RFE is simple. The estimator fit the data and compute the feature importance, it’s the weight of the data on the target. At each iteration, the model will remove the feature with lower importance until reach the number of <strong><em>k</em></strong> features needed.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-AWnrEWagQiol5hUeqe52kw.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-AWnrEWagQiol5hUeqe52kw.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-AWnrEWagQiol5hUeqe52kw.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-AWnrEWagQiol5hUeqe52kw.png 1074w" sizes="(min-width: 720px) 720px"><figcaption>Schema of the RFE</figcaption></figure><p>How could we code this? I show here an implementation for <strong><em>SVM </em></strong>and <strong><em>Logistic Regression</em></strong>.</p><p><strong>SVM:</strong></p><pre><code>from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_selection import RFECV

# SVM implementation
svc = SVC(kernel="linear")
# The "accuracy" scoring is proportional to the number of correct

rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(5),            scoring='accuracy')rfecv.fit(X, y)

print("Optimal number of features : %d" % rfecv.n_features_)</code></pre><p><strong>Logistic Regression:</strong></p><pre><code># Feature Extraction with RFE
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(solver='lbfgs', max_iter=5000)
rfe = RFE(model, 3)
fit = rfe.fit(X, Y)
print("Num Features: %d" % fit.n_features_)
print("Selected Features: %s" % fit.support_)
print("Feature Ranking: %s" % fit.ranking_)</code></pre><h2 id="iid-selectfrommodel">IId. SelectFromModel</h2><p>This last method is a generalization of the previous because <strong><em>SelectFromModel </em></strong>takes an <strong><em>estimator </em></strong>and returns a new matrice containing the reduced dimension.</p><p>The code below shows how to implement it:</p><pre><code>from sklearn.svm import LinearSVC
from sklearn.feature_selection import SelectFromModel

lsvc = LinearSVC(C=0.01, penalty="l1", dual=False) # estimatorlsvc.fit(X, y)
model = SelectFromModel(lsvc, prefit=True)
X_new = model.transform(X)
print(f"The new number of feature is {X_new.shape[1]}")</code></pre><h2 id="iiia-principal-component-analysis-pca-">IIIa. Principal Component Analysis (PCA)</h2><p>The Principal Component Analysis is a method used to reduce the dimension of a dataset. The principle is simple, the PCA will fit a line or a plane to the points to create another representation of the data.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-lh5TKadyKILDVlaazuE1UA.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-lh5TKadyKILDVlaazuE1UA.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-lh5TKadyKILDVlaazuE1UA.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-lh5TKadyKILDVlaazuE1UA.png 1227w" sizes="(min-width: 720px) 720px"><figcaption>PCA projection</figcaption></figure><p>The code is simple to use. You just have to specify the N_var parameter which represents the number of dimensions you want.</p><pre><code>from sklearn.decomposition import PCA
N_var = 2
pca = PCA(n_components=N_var)
X_pca = pca.fit_transform(X)
df_pca = pd.DataFrame(data = X_pca, columns = ['PC1', 'PC2'])</code></pre><h2 id="iiib-independent-component-analysis-ica-">IIIb. Independent Component Analysis (ICA)</h2><p>ICA is a powerful technique to separate multivariable independent signals linearly mixed. This technique can permit us to separate different signals in signal processing.</p><p>The code below shows an implementation of a <strong><em>FastICA</em></strong>:</p><pre><code>from sklearn.decomposition import FastICA
N_var = 2
ica = FastICA(n_components=N_var)
X_ica = ica.fit_transform(X)</code></pre><h2 id="iiic-linear-discriminant-analysis-lda-">IIIc. Linear Discriminant Analysis (LDA)</h2><p>I share here the abstract of the original paper explaining LDA.</p><blockquote>We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/">https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/</a></em></p>]]>
            </description>
            <link>https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818607</guid>
            <pubDate>Mon, 13 Jul 2020 08:49:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM64 Popcount in Golang and Assembler]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23818574">thread link</a>) | @fanf2
<br/>
July 13, 2020 | https://barakmich.dev/posts/popcnt-arm64-go-asm/ | <a href="https://web.archive.org/web/*/https://barakmich.dev/posts/popcnt-arm64-go-asm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Apropos of Apple’s ARM announcment, I thought I might write up a post on a recent bit of code I wrote that specifically looks at ARM64, and its benchmarks on various hardware.</p><p>I’ve been implementing some compact data structures for a project. One of the CPU hotspots for the implementation is the need to run a quick population count across a potentially large bit of memory.</p><p>If you’ve never seen population count before, it’s the count of the number of set 1 bits in a byte (or list of bytes) – for example:</p><div><pre><code data-lang="text">0xF3 == 0b11110011
popCount(0xF3) == 6
</code></pre></div><p>Now, every reasonable x86_64/amd64<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> CPU in the past decade or so has a built-in instruction for this: <a href="https://en.wikipedia.org/wiki/SSE4#POPCNT_and_LZCNT"><code>POPCNT</code></a>. It works like this (in Go Assembler):</p><div><pre><code data-lang="text">MOV    $0xF3, R10  // Store a constant
POPCNT   R10, AX   // AX now equals 6
</code></pre></div><p>Go uses the built-in instruction for this in the <code>math/bits</code> via SSA compiler rewrites (which it added in 1.9), but only up to a uint64 at a time; using assembly to loop over a <code>[]byte</code> is considerably more efficient</p><p><a href="https://github.com/tmthrgd"><code>@tmthrgd</code></a> created a really nice little x86_64-assembly-optimized package at <a href="https://github.com/tmthrgd/go-popcount">github.com/tmthrgd/go-popcount</a>. It works great, works around a weird little Intel bug (see the helpful comments) and is still faster than looping and using the Go standard library, which it helpfully benchmarks as well.</p><p>Recently, I picked up one of the new 8GB Raspberry Pi 4s. Loaded it up with the nice new <a href="https://manjaro.org/">Manjaro 20.06</a> and set up my usual environment. As a test, I wanted to try my latest WIP data structure code.
Of course, the bottleneck was right where I expected it to be: in the population count.</p><h3 id="implementing-it">Implementing it</h3><p>I discovered that ARM64 has a <code>POPCNT</code>-like instruction, logically enough called <code>CNT</code>. I thought, since I’ve been playing with Go assembly for memmove, why not try my hand at the new architecture?</p><p>Go already has the SSA-rewrite for OnesCount on ARM (added in 1.11), but again, only a uint64 at a time. There might be some performance on the table.</p><p><a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">Official architecture guide</a> at the ready, I got to work. And there was a lot to learn. Some notes:</p><h4 id="1-its-part-of-the-vector-suite-neon">1. It’s part of the vector suite, NEON</h4><p>NEON is the name for the addition of vector instructions to the ARM architecture, so I’d be working with both an unfamiliar architecture <em>and</em> its vector instructions.</p><p>In x86-land, <code>POPCNT</code> and vectorization are two separate concepts. <code>POPCNT</code>, as an instruction, deals with everyday, 64-bit integer registers, and not the vector registers (even though it appeared approximately the same time as the addition to vector instructions, SSE4)<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p><p>ARM/NEON did <code>CNT</code> differently. Since you can load an array of items (say, 16 bytes, in the ARM64 vector registers), <code>CNT</code> will count them individually. In fact, you can <em>only</em> do it in vectors of single bytes.</p><p>So this means that the following signatures are approximately the way to think about it:</p><div><pre><code data-lang="go"><span>func</span> <span>popCountx86</span><span>(</span><span>in</span> <span>uint64</span><span>)</span> <span>uint64</span> <span>// register-at-a-time, 64-bit (8 bytes)
</span><span></span>
<span>func</span> <span>popCountNeon</span><span>(</span><span>in</span> <span>[</span><span>16</span><span>]</span><span>byte</span><span>)</span> <span>[</span><span>16</span><span>]</span><span>uint8</span> <span>// 16 bytes all counted in parallel.
</span></code></pre></div><p>This ends up being really effective, as it turns out (below).</p><h4 id="2-gos-assembler-documentation-is-barebones">2. Go’s assembler documentation is barebones</h4><p>Writing instructions so that Go’s assembler is happy with the instructions you’re giving it is a bit frustrating.</p><p>There’s a good gloss at <a href="https://golang.org/pkg/cmd/internal/obj/arm64/">golang.org/pkg/cmd/internal/obj/arm64</a> which gives an overview of many of the differences.
For example, all vector instructions start with <code>V</code>, different than what ARM64 switched to (they used to commonly start with V on 32-bit ARM) – so while I understand the desire for continuity (and even subtly like it, knowing it’s a vector op) it’s just makes another little difference to remember vs. the original documentation.</p><p>But more frustrating is, even if your instruction is supported (and most of them are) knowing how to <em>use</em> the instruction in Go assembler boils down to “assume data goes left-to-right and hope there’s an example <a href="https://github.com/golang/go/blob/master/src/cmd/asm/internal/asm/testdata/arm64enc.s">in the test suite</a>”</p><p>I’m a big Go fan, yet Go’s history into Plan 9 and accompanying assembler (and, relatedly, odd calling conventions) is one of my gripes about Go, even more than lack of generics (which is a topic for another day).
Sure, there were some good ideas in Plan 9 that influenced the design of Go – from a design level, it’s great! – but on the implementation level, this is one place where I kinda wish it had followed precident.
Take whichever side you want in the Intel vs GNU syntax debate, <a href="https://xkcd.com/927/">creating a third option</a> means relearning all the quirks from scratch, and ignoring any documentation that already exists.</p><h3 id="putting-it-all-together">Putting it all together</h3><p>The end result is my friendly fork of <code>go-popcount</code>: <a href="https://github.com/barakmich/go-popcount">github.com/barakmich/go-popcount</a></p><p>Really, it’s more of an extension than a fork – it provides the same API, just with handwritten assembly for ARM64 chips.</p><h4 id="how-it-works">How it works</h4><p>The vectorization works really well. The process is:</p><ul><li>Load a set of vector registers, 16 bytes each</li><li>popCount them</li><li>Vector sum their partial results (up to 32 individual vectors, to fit the 8-bit counts), trying to avoid a data dependency</li><li>Finally, sum (“widening”, in vector terms) the final vector</li><li>Add it to the final output</li></ul><p>The other thing to balance was how much to load from memory vs. how much work to do to optimize throughput. That ended up being about 8 vectors (128 bytes) at a time.
That may vary as a function of CPU, but it’s a good place to start.</p><h4 id="arm64-feels-nice">ARM64 feels nice</h4><p>This is purely subjective, but there were a number of moments where I felt “hey, that’s handy” in writing ARM64 assembly.
Of course modern x86_64 chips account for all of these differences and makes them performant – through deeper instruction pipelines or having <a href="http://sunnyeves.blogspot.com/2009/07/intel-x86-processors-cisc-or-risc-or.html">micro-op instruction queues</a> that ultimately pull the same tricks.
But at the same time, when you’re dropping down to work at the instruction level, it’s kind of a breath of fresh air.</p><h5 id="pre-and-post-increment">Pre-and-post increment</h5><p>A lot of the time when you’re working with an array of whatever you’re pulling a chunk of memory into registers, doing some transform, and putting it back.</p><div><pre><code data-lang="asm"><span>VLD1.P</span> <span>64</span><span>(</span><span>R1</span><span>),</span> <span>[</span><span>V16.B16</span><span>,</span> <span>V17.B16</span><span>,</span> <span>V18.B16</span><span>,</span> <span>V19.B16</span><span>]</span>
</code></pre></div><p>Reads as load 1-byte*size structures into the following vector registers – so far so good, this is similar to the <a href="https://www.felixcloutier.com/x86/movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64"><code>VMOVDQU</code></a> instruction family (though the size-structure variants on that instruction are a recent addition) on x86. It has a similar ability to load many registers in multiple back-to-back instructions through address/offset/size calculation, but ARM has a nice one-liner that way.</p><p>But I really like the auto-increment of <code>R1</code> by the read size (64) after loading – hence post-increment. Many loads from memory have a similar flag. It’s very descriptive and means things like “increment the offset register and decrement the size register and test” things live with their appropriate parts of the code, instead of having to increment later (and finding the optimal time)</p><h5 id="consistency-of-style">Consistency of style</h5><p>This is a holdover from history, but the consistency of having fixed-size instructions is a nice thing when trying to hand-assemble an instruction. I had to do some hand-assembly when <a href="https://github.com/golang/go/issues/39445">I discovered and reported a bug in Go</a>. It was silently writing the wrong version of the instruction while accepting the correct one as input. Kudos to the Go community – it was fixed by an expert within a day or two, so I’m looking forward to the next version that contains the fix!</p><p>Still, this meant with a <a href="https://xkcd.com/378/">steady hand</a> and a copy of <a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">the architecture guide</a> I could feasibly implement any instructions that were missing.</p><p>Also in consistency-land, most binary operations take <code>input1_reg, input2_reg, output_reg</code> with few exceptions. Omitting the output_reg is Go’s assembler syntactic sugar to set output to input2. x86, again for historical reasons (trying to keep instructions small), often has the store-to-the-second-register as the primary or only version of an operation, which can lead to more operations overall (and cognitive overhead IMO).</p><h3 id="benchmarking-on-arm">Benchmarking on ARM</h3><p>So let’s take a look at some benchmarks.
The most interesting thing about looking at population count is that this little routine does something useful and shows tradeoffs between CPU bounds and memory bandwith between the CPU, the on-chip caches, and main memory.
At array sizes small enough to fit into CPU cache (but big enough to run the compute loop a few times), the CPU is the limiting factor – how many bits it can count.
For larger data sizes, the memory bandwidth becomes the bound; the CPU is waiting on getting enough data to crunch through.</p><p>To this end, the benchmark curves in the repository max out in throughput at about 16K (most work possible, while still being in cache) and then trail down into a steady state as memory becomes the bound. So I’ll truncate the full benchmarks to compare peak throughput and long tail.</p><p>Some findings and commentary:</p><h4 id="raspberry-pi-4">Raspberry Pi 4</h4><div><pre><code data-lang="text">Unoptimized (Go implementation):
BenchmarkCountBytesGo/16K              297778          8056 ns/op     2033.78 MB/s
BenchmarkCountBytesGo/512M                  8     279380432 ns/op     1921.65 MB/s

Optimized (My hand-rolled assember):
BenchmarkCountBytes/16K                520807          2303 ns/op     7113.24 MB/s
BenchmarkCountBytes/512M                    8     131214574 ns/op     4091.55 MB/s
</code></pre></div><p>This was my finished product on my local Pi. I may be able to do better, but varying the block sizes between grabbing from memory and doing the vector addition for popcount topped out about here, so I’m fairly satisfied.</p><p>Interestingly, the ~4.1GB/s memory bandwidth follows exactly with <a href="https://hackaday.com/2019/07/10/raspberry-pi-4-benchmarks-processor-and-network-performance-makes-it-a-real-desktop-contender/">initial read benchmarks of the Pi 4</a> suggesting it’s close to saturation, which is good news.</p><h4 id="ampere-emag">Ampere eMag</h4><p>So my next thought was to spin up an ARM64 server with my old friends at <a href="https://packet.net/">Packet</a>. They have a <a href="https://www.packet.com/cloud/servers/c2-large-arm/">c2.large.arm</a> and it’s gonna be great!</p><div><pre><code data-lang="text">Unoptimized:
BenchmarkCountBytesGo/16K      	   69939	     17208 ns/op	 952.09 MB/s
BenchmarkCountBytesGo/512M     	       2	 582293709 ns/op	 921.99 MB/s

Optimized:
BenchmarkCountBytes/16K        	  458394	      2614 ns/op	6267.80 MB/s
BenchmarkCountBytes/512M       	      12	  93371433 ns/op	5749.84 MB/s
</code></pre></div><p>…but I was rather underwhelmed.</p><p>This isn’t necessarily Packet’s fault – they were early onto having ARM hardware available and it’s …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://barakmich.dev/posts/popcnt-arm64-go-asm/">https://barakmich.dev/posts/popcnt-arm64-go-asm/</a></em></p>]]>
            </description>
            <link>https://barakmich.dev/posts/popcnt-arm64-go-asm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818574</guid>
            <pubDate>Mon, 13 Jul 2020 08:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Consolidation of the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817946">thread link</a>) | @Fizzadar
<br/>
July 13, 2020 | https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/ | <a href="https://web.archive.org/web/*/https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
 
<div>

        <h2>
            On the Consolidation of the Web
            <span>Wed 29 July 2020</span>
        </h2>

        <p>In recent years, the web has been consolidating. From the servers to the apps, a growing majority of the web is controlled by a small pool of companies. When AWS was founded in 2006 I was just starting out with my first VPS, running this blog on WordPress (the good ol' days!). For the last 10 years I have part-run a small VPS (“cloud server”) host called <a href="https://afterburst.com/">Afterburst</a>. Throughout these years I have watched this consolidation, and these are my observations.</p>

<h3>The Pre-Cloud Days</h3>

<p>Way back in 2009 blogs were booming. The market for personal servers was growing rapidly. People often used forums (remember those?) to find providers. Providers would compete to attract the most eyeballs to their sale posts.</p>

<p>The quality and cost of hosting varied wildly. During summer there would be a huge influx of budget “summer hosts” during school holidays. The majority of these would then fold only two months later. Thinking back, it was The While West. Of course there were big players; but the smaller hosts had the cheapest offers and captured the market for personal servers.</p>

<p>I believe that this was a great market for all. Buyers had a wealth of choice of companies tiny to massive. Providers were kept in check by thriving forum communities, leading to better services. The smaller providers would offer a personal touch, often partaking in forums alongside their customers. To me, this was an amazing environment in which I learnt a huge amount about servers but also customer service.</p>

<h3>The Clouds Ascend</h3>

<p>The VPS market was exploding when we started Afterburst in 2010. Shared hosting/PHP was stagnating and the prices had bottomed out. Shared hosting was consolidating fast, hosts were folding daily. Dedicated server and VPS markets remained strong and WebHostingTalk (our “home” forum) was buzzing with activity. The competition for the best VPS was in full swing.</p>

<p>And then came DigitalOcean.</p>

<p>When DO arrived in 2011 everything changed. They managed to make the much hyped “cloud” accessible to everyone where AWS had so far struggled. You could click a button and have a cloud server available within minutes. The all-SSD package, “cloud” marketing and a wave of free launch coupons caused them to explode onto the scene.</p>

<p>It was fascinating to watch the “cloud” hype train. “Cloud servers” were, almost overnight, seen as superior to “VPS”. This is despite most “cloud server” providers offering nothing different to VPS. Now I totally get that The Cloud goes way beyond servers. The offerings today include a staggering number of services. But an individual looking for a server to host their blog? They don’t need any of that, just the server space.</p>

<p>In the years since DO arrived they, AWS and later Azure/GCloud boomed. Cloud was/is the future - we must move everything “to the cloud” many a huge tech company would say. As much as it was marketing hype, the individual started to follow. The cloud was only a little more expensive and came with fancy UI and excellent developer tooling. It was cool to be using the cloud. The small/traditional VPS provider market began to slow, and later reduce. The golden days were over.</p>

<p>Whilst this was very frustrating at the time it also forced us to review and improve our marketing and customer experience. We started marketing cloud servers and optimised the checkout and customer sign-up flow. The competition led to an improved service for existing and new customers.</p>

<h3>So - where are we now?</h3>

<p>10 years later, we’re still here! The consolidation of providers has slowed and many continue to survive. Forums like WHT struggle on but are shadows of their former selves. There’s still a market for individual servers - people have a natural desire to tinker in ways that specific services cannot provide.</p>

<p>I think there will remain a cohort of individual bloggers and websites. But I also believe the web is dividing. On one side a small number of platforms the vast majority of “normal” people consume from and share to. And elsewhere a separate “old style” web of fragmented loosely connected websites/forums/blogs formed by those who tinker. Perhaps something will merge the two together in the future.</p>

<p>It’s like supermarkets consuming ‘Mom and Pop shops’, a trend that goes back decades now. Yet small greengrocers and butchers still live on. There are signs of people returning to these shops in growing numbers. Perhaps this is the start of a reverse trend, could the web follow suit? I’d like to think so.</p>
</div>
    
    </section></div>]]>
            </description>
            <link>https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817946</guid>
            <pubDate>Mon, 13 Jul 2020 07:18:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Profile READMEs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23817930">thread link</a>) | @patelpankaj
<br/>
July 13, 2020 | https://time2hack.com/create-activate-github-profile-readme/ | <a href="https://web.archive.org/web/*/https://time2hack.com/create-activate-github-profile-readme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>The <strong>Github Profile README</strong> design was being in twitter conversation for a while. I discovered it with one of the profiles with README in theirs.</p><p>I went ahead and <a href="https://github.com/pankajpatel">added on mine</a> and it looks super awesome 😎 now:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/profile-readme.png" alt=""><figcaption>My <a href="https://github.com/pankajpatel">profile <strong>README</strong></a></figcaption></figure><p>You can also <strong>activate profile README</strong> on yours by simply <a href="https://github.com/new">creating a new repository</a> with same name as your Github profile handle. So for me, it is <code>pankajpatel</code> as the repository name; similar to my Github username.</p><p>You can also see it in the above picture, the <code><strong>README.md</strong></code> is from <code>pankajpatel/README.md</code></p><p>When you will go ahead and <strong>create a repository with same name as your profile handle</strong>; you will see the following message:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/new-repo.png" alt=""></figure><hr><p>Just initialize your repository with a <strong>README</strong> file by checking the checkbox below. Other files in the initialization don't matter for this repository</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/initialize-with-README.png" alt=""></figure><hr><p>Once you hit <code><strong>Create Repository</strong></code> button, you will see the repository with list of files as follows:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/fresh-README-repo.png" alt=""></figure><p>Important thing to note here is the green box on right side:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/readme-repo-edit-readme.png" alt=""></figure><hr><p>Click on <code><strong>Edit README</strong></code> and start editing the Welcome message of your profile. By default, you will see the following contents on your <strong>README</strong> as a hint to get started:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/start-editing-profile-README.png" alt=""></figure><hr><p>You can add content as Markdown or HTML and preview it in the next tab. Once you are done, you can commit the file and your profile will show this <strong>README</strong> above the top/pinned repositories of your profile.</p><p>If you are new to Markdown, you can follow this <a href="https://guides.github.com/features/mastering-markdown/">guide to get started with Markdown</a>.</p><hr><h2 id="for-organizations">For Organizations?</h2><p>Unfortunately, the Organizations are not having this feature but I hope this feature will come there. I tried for time2hack's org on github and it still looks the same:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/org-time2hack-readme.png" alt=""></figure><hr><h2 id="conclusions">Conclusions</h2><p><em>Github Profile README</em> is a good way to introduce yourself to your profile visitors.</p><p>This way others can know more about you other than your top repositories and how much you code every day.</p><p><strong>Github Profile README is a nice flavour to Social Coding.</strong></p><p><strong><em>Have you created yours? And How does it look like?</em></strong></p><p>Let me know through comments 💬 or on Twitter at &nbsp;<a href="https://twitter.com/patel_pankaj_">@patel_pankaj_</a> &nbsp;and/or &nbsp;<a href="https://twitter.com/time2hack">@time2hack</a></p><p>If you find this article helpful, please share it with others 🗣</p><p>Subscribe to the blog to receive new posts right to your inbox.</p><hr><h4 id="credits">Credits</h4><p>Icon from <a href="https://icons8.com/icon/52539/github">https://icons8.com/icon/52539/github</a></p><p>Photo by <a href="https://unsplash.com/@yancymin?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Yancy Min</a> on <a href="https://unsplash.com/s/photos/github?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>

<ins data-ad-client="ca-pub-1830015441649630" data-ad-slot="3501574357" data-ad-format="auto" data-full-width-responsive="true"></ins>

</section></div>]]>
            </description>
            <link>https://time2hack.com/create-activate-github-profile-readme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817930</guid>
            <pubDate>Mon, 13 Jul 2020 07:16:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Sourcing Company Culture]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817799">thread link</a>) | @soorajchandran
<br/>
July 12, 2020 | https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/ | <a href="https://web.archive.org/web/*/https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-318">

	

	
	<div>
		
<figure><img data-attachment-id="353" data-permalink="https://blog.oysterhr.com/adobestock_32068789/" data-orig-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png" data-orig-size="1491,1008" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="adobestock_32068789" data-image-description="" data-medium-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300" data-large-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=750" src="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024" alt="" srcset="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024 1024w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=150 150w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300 300w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=768 768w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png 1491w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>TL;DR: <em>Companies that have recently gone fully-remote can draw inspiration from open source. Doing so provides helpful ways to think about attracting talent and building culture.&nbsp;</em></p>



<p><strong>Fully-Distributed is Taking Off</strong></p>



<p>Though the headlines have focused on the <a rel="noreferrer noopener" href="https://www.cnn.com/2020/05/22/tech/work-from-home-companies/index.html" target="_blank">big name companies</a> and their announcements about going remote, events of the last four months have undoubtedly created a lot of new fully-distributed companies you’ve <a rel="noreferrer noopener" href="https://www3.nhk.or.jp/nhkworld/en/news/videos/20200622091038913/" target="_blank">never heard of</a>. This includes organizations that may have been partially or even fully-colocated (office-based) before Coronavirus. And this is happening in part because remote working has worked out so well for so many of them, and in part because it has proven difficult for many companies to scale down to a “reduced” real estate footprint — to serve a subset of their employees. Hybrid is <a rel="noreferrer noopener" href="https://www.linkedin.com/pulse/remote-work-having-moment-future-isnt-hybrid-sid-sijbrandij/" target="_blank">harder</a> than fully-distributed, we keep hearing. And the truth is that returning to the office is still an open discussion (fraught with overwhelming <a rel="noreferrer noopener" href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank">emergent</a><a href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank" rel="noreferrer noopener"> logistical considerations</a>) even for companies that really want to.</p>



<p>We have also no doubt seen in the last four months an acceleration in the rate of creation of new fully-distributed startups that reject offices altogether, and that do not expect their people to meet physically to get work done. This was already a trend, and any founders who may have been hesitant before Coronavirus because they were worried about investor bias or their own inexperience with remote leadership, now have <a href="https://techcrunch.com/sponsor/oyster/the-dawn-of-the-distributed-age/" target="_blank" rel="noreferrer noopener">enormous encouragement</a> to kick the office to the curb.</p>



<p>This means, however, that now many, many more companies, not just the ones that were already on the fully-distributed bandwagon before COVID-19, are going to face the challenges unique to fully-distributed organizations.</p>



<p><strong>Next-Level Guidance is Needed</strong></p>



<p>There’s been a great outpouring of new content from the community on the basic how-to’s of remote working. We have also seen that the “bibles of remote working” (that have been around for years from the pioneering remote working companies like <a rel="noreferrer noopener" href="https://distributed.blog/" target="_blank">Automattic</a>, <a href="https://about.gitlab.com/company/culture/all-remote/guide/">Gitlab</a>, and <a href="https://basecamp.com/remote-resources">Basecamp</a>, etc) are getting the reference attention they deserve. These basics (like asynchronous communication) are of course essential principles that have to be properly installed for a fully-distributed team to walk and run. But there are other challenges that come with being a fully-remote organization for which there’s less explicit guidance.</p>



<p>Two such challenges we keep hearing about are:</p>



<ul><li>How do you attract and recruit great talent from around the world (<em>whom you may never meet in person</em>)?, and</li><li>How do you create and sustain great culture (<em>when everything is virtual</em>)?</li></ul>



<p><strong>Open Source, a Model of Distributed Success</strong></p>



<p>To these important challenges of fully-distributed organizations, the <a href="https://www.redhat.com/en/topics/open-source/what-is-open-source" target="_blank" rel="noreferrer noopener">principles and history of Open Source</a> would seem to offer a lot.&nbsp;</p>



<p>We often hear that software “eats” things. An aspect of that is that the ways of software development continue to penetrate into the ways other types of work are done. That open source should provide ways of thinking and working that are helpful to fully-distributed organizations may be yet another example of something that started in software development spreading more generally into business. Like <a rel="noreferrer noopener" href="https://agilemanifesto.org/principles.html" target="_blank">Agile</a> and <a rel="noreferrer noopener" href="https://www.agilealliance.org/glossary/kanban/" target="_blank">Kanban</a> have. This keeps happening because these “frameworks from another domain” offer avenues to better ways of working, even when what you’re doing is some other type of knowledge work.&nbsp;</p>



<blockquote><p>Whether or not they are a software company, fully-distributed organizations are going to have to become more like software companies in their ways of working.</p><a href="http://twitter.com/share?&amp;text=Whether%20or%20not%20they%20are%20a%20software%20company%2C%20fully-distributed%20organizations%20are%20going%20to%20have%20to%20become%20more%20like%20software%20companies%20in%20their%20ways%20of%20working.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=HeyOyster" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>This shift will be necessary for non-software development knowledge work to be done well in a fully-distributed organization. Naturally, that has deep implications for how technology will support knowledge work in the future. For that reason, we’re also going to see a pattern where new tools are going to be created that allow non-software developer knowledge workers to work more like developers do. This was also probably a trend well in evidence before Coronavirus, now greatly accelerated.</p>



<p>Once your organization is thinking and working a bit more like a fully-distributed software company (especially if you ARE a software company), it shouldn’t be too difficult to aspire to some of the attributes of an open source project.&nbsp;&nbsp;</p>



<p>Open source is worthy to provide guidance and inspiration to any fully-distributed company because it demonstrates a model through which great talent is not only attracted but also uniquely enabled and remotely synchronized to produce semi-miraculous results.&nbsp;</p>



<p>There is no better example of this than Linux.</p>



<blockquote><p>“Linux was the first project for which a conscious and successful effort to use the entire world as its talent pool was made.”</p><cite><em>Eric Steven Raymond, <a rel="noreferrer noopener" href="http://www.catb.org/~esr/writings/cathedral-bazaar/cathedral-bazaar/ar01s11.html" target="_blank">The Social Context of Open-Source Software</a></em></cite></blockquote>



<p>Successful open source projects like Linux should inspire fully-distributed companies because they demonstrate the extraordinary productivity potential of organized knowledge work performed by a team of people who didn’t ever have to meet in person to accomplish it.</p>



<p><strong>Becoming a Beacon for Global Talent</strong></p>



<p>Organizations who’ve let go of their offices and have recently made the transition to fully-distributed are probably still focused on getting things back on track, and on fostering the healthy continuity of the pre-existing team. Though hiring may not be the present priority, they must surely be thinking about how recruitment will work as a fully-remote company. Whether they are fully-distributed or just have newly-created remote roles, as organizations shift their recruiting perspective from thinking locally to thinking globally, this is going to radically transform the recruiting process as we have known it.&nbsp;</p>



<p>Even for companies that decide they will only hire in a subset of timezones (to facilitate synchronous work, like <a href="https://www.quora.com/q/quora/Remote-First-at-Quora" target="_blank" rel="noreferrer noopener">Quora</a>), the size of the available talent pool would still overwhelm the traditional recruitment approaches of “publishing” their open roles and waiting for “applicants” to express an interest in them. The new pervasiveness of remote working and highly-distributed companies is going to create unprecedented liquidity in the global talent marketplace. This is great for all parties, but it also means that everyone’s game has to change.&nbsp;</p>



<p>Thinking and acting like an open source project may be a good way for fully-distributed companies to evolve their talent acquisition game. Reflect on the Linux example in a post-Coronavirus talent market. When the most talented individuals can work for any company in the world, how will your company compete? How can your company distinguish itself amongst a much larger number of prospective employers?</p>



<blockquote><p>The downside for employers gaining access to the global talent pool is that they are also suddenly competing with every company in the world for talent.</p><a href="http://twitter.com/share?&amp;text=The%20downside%20for%20employers%20gaining%20access%20to%20the%20global%20talent%20pool%20is%20that%20they%20are%20also%20suddenly%20competing%20with%20every%20company%20in%20the%20world%20for%20talent.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=2hp" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>One approach is to become like an open source project, whose first organizing principle is attracting people who care deeply about the same thing. This of course requires knowing what that special thing (of singular and obsessive focus) is for your organization. I think most companies can find their unique <a href="https://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action" target="_blank" rel="noreferrer noopener">Why</a>, if they try. And I think it’s a good thing that prospective global employers should feel they have to produce a thoughtful and compelling expression of their purpose to compete for global talent.</p>



<p><strong>Creating Culture on Purpose</strong></p>



<p>Perhaps your company is bootstrapping its culture for the first time as a brand new fully-distributed startup. Or perhaps you’re an established organization now transitioning from an office-based culture. Either way, you may as a leader be wondering how to develop and nurture culture when everything is virtual and everyone’s remote.</p>



<p>Attracting people who share a common passion is potentially more than just a way to acquire talent. It can also be a terrific way to instantiate culture. But attracting talent like an open source project, however, is not just about having a clear and compelling purpose. It’s also about calling those talented people to come work on that purpose together in a <strong>particular</strong> way.</p>



<blockquote><p>“Culture is a pattern of basic assumptions — invented, discovered, or developed by a given group as it learns to cope with its problems of external adaptation and internal integration — that has worked well enough to be considered valid and, therefore, to be taught to new members as the correct way to perceive, think, and feel in relation to those problems.”</p><cite><em>Edgar Schein, <a rel="noreferrer noopener" href="https://agustinazubair.files.wordpress.com/2013/04/13-organizational_culture_and_leadership_3rd_edition-p-4581.pdf" target="_blank">Organizational Culture and Leadership</a></em></cite></blockquote>



<p>In other words, culture is inherently linked to a particular problem space, and isn’t directly about people or their attributes. Organizational culture is about how people decide to work together on a specific set of problems.</p>



<p>For many office-based companies, the “Our values” plaque that hangs on the wall is just a list of nice ideas. And though that list of values is intended to be the codification of their culture, those values may not relate in any useful way to the work to be done, and therefore probably don’t drive much useful behavior. The experience and the effects of culture, therefore, are organic, accidental, and overly-dependent on physical proximity.</p>



<blockquote><p>“Running a remote work environment effectively, requires amongst other things a deliberate approach to culture development. </p><p>Transitioning from an office to remote is not going to be easy for a lot of companies. The reason for this is leaders took the human proximity, camaraderie, informal comms &amp; ‘water cooler moments’ for granted. </p><p>The majority of CEOs who ran office-based businesses before the pandemic and didn’t invest in their culture unknowingly relied on their office space environment to hold their unwritten culture together.”</p><cite><em>Bretton Putter (via <a rel="noreferrer noopener" href="https://twitter.com/BrettonPutter/status/1263829426258817025" target="_blank">Twitter</a>)</em></cite></blockquote>



<p>As human beings we abhor vacuums, particularly social ones. This is the reason why, in the face of non-deliberate culture, we are able to “fill in” …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</a></em></p>]]>
            </description>
            <link>https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817799</guid>
            <pubDate>Mon, 13 Jul 2020 06:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting with RF Using RTL-SDR]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817738">thread link</a>) | @ngutman
<br/>
July 12, 2020 | https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/ | <a href="https://web.archive.org/web/*/https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><h2 id="introduction">Introduction</h2>
<p>I was always interested in the RF world, the fact that we are surrounded by an infinite amount of invisible waves that carry information is intriguing. A lot has changed over the years, the technology advanced and today you can easily dive into the electromagnetic realm without fiddling with mountains of equipment and burning your pocket.</p>
<p>In this post we’ll explore using RTL-SDR to read live temperature and humidity stats from cheap 433.92Mhz modules, feeding them to InfluxDB using rtl_433, MQTT and Telegraf on a Raspberry Pi (but any Linux based device can work)</p>
<h2 id="hardware">Hardware</h2>
<p><strong><a href="https://www.amazon.com/gp/product/B011HVUEME/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B011HVUEME&amp;linkCode=as2&amp;tag=rsv0f-20&amp;linkId=b3bd3c48a6a7e921144609cb59359f0e" target="_blank" rel="noopener noreffer">RTL-SDR</a></strong></p>
<p>The definition of SDR is “Software Defined Radio”, it’s a radio-communication system where instead of using components that were traditionally implemented in hardware - software is used, allowing greater flexibility and reducing costs.</p>
<p>RTL-SDR is a high quality USB dongle (but relatively cheap at ~$25) that can be used to scan and receive radio signals from 500Khz (24Mhz for the device I used) up to 1.75Ghz. It was designed and built by the awesome dudes over at <a href="https://www.rtl-sdr.com/about-rtl-sdr/" target="_blank" rel="noopener noreffer">RTL-SDR.com</a> based on DVB-T TV tuner dongles. I ordered <a href="https://www.amazon.com/gp/product/B011HVUEME/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B011HVUEME&amp;linkCode=as2&amp;tag=rsv0f-20&amp;linkId=b3bd3c48a6a7e921144609cb59359f0e" target="_blank" rel="noopener noreffer">this</a> kit which included two modular dipole antennas.</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1_huc616545b0e7314066a2472f01ef5c4d9_1120817_200x0_resize_q75_box.jpeg" title="images/rtl-sdr/1.jpeg" data-sub-html="<h2>images/rtl-sdr/1.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1_huc616545b0e7314066a2472f01ef5c4d9_1120817_200x0_resize_q75_box.jpeg" alt="images/rtl-sdr/1.jpeg">
        </a>
    
        
        <a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2_hu4415df00103010adacdf168ad8b6a4c9_1598270_200x0_resize_q75_box.jpeg" title="images/rtl-sdr/2.jpeg" data-sub-html="<h2>images/rtl-sdr/2.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2_hu4415df00103010adacdf168ad8b6a4c9_1598270_200x0_resize_q75_box.jpeg" alt="images/rtl-sdr/2.jpeg">
        </a>
    
        
        <a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3_hu11fcd6c9e34e3b5d10fc09ac9d03a1d1_1389802_200x0_resize_q75_box.jpeg" title="images/rtl-sdr/3.jpeg" data-sub-html="<h2>images/rtl-sdr/3.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3_hu11fcd6c9e34e3b5d10fc09ac9d03a1d1_1389802_200x0_resize_q75_box.jpeg" alt="images/rtl-sdr/3.jpeg">
        </a>
    
</p>

<p><strong><a href="https://www.aliexpress.com/item/33006820989.html?spm=a2g0s.9042311.0.0.1b754c4dDEUyyf" target="_blank" rel="noopener noreffer">RF Wireless Hygrometer + Thermometer</a></strong></p>
<p>Almost any RF based wireless thermometer / humidity sensor is probably readable by <code>rtl_433</code>. Since we’re talking about cheap hardware you can’t really get any assurances, checking the RF frequency is probably enough - if it says 433.92Mhz, you are 99% good. I’ve used <a href="https://www.aliexpress.com/item/33006820989.html?spm=a2g0s.9042311.0.0.1b754c4dDEUyyf" target="_blank" rel="noopener noreffer">this</a> as my indoor sensor and <a href="https://www.aliexpress.com/item/4000872896502.html?spm=a2g0s.9042311.0.0.419a4c4duApRRx" target="_blank" rel="noopener noreffer">this</a> as my outdoor, for monitoring my garden soil humidity level and outdoor temperature</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria_huc9d833e79d7dd2a83277d6401be6cf3b_1248250_200x0_resize_q75_box.jpeg" title="images/sensors/oria.jpeg" data-sub-html="<h2>images/sensors/oria.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria_huc9d833e79d7dd2a83277d6401be6cf3b_1248250_200x0_resize_q75_box.jpeg" alt="images/sensors/oria.jpeg">
        </a>
    
        
        <a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor_huc3d583f5dfc3f1b32518ba7724faca9b_1100341_200x0_resize_q75_box.jpeg" title="images/sensors/outdoor.jpeg" data-sub-html="<h2>images/sensors/outdoor.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor_huc3d583f5dfc3f1b32518ba7724faca9b_1100341_200x0_resize_q75_box.jpeg" alt="images/sensors/outdoor.jpeg">
        </a>
    
</p>

<p><strong><a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/" target="_blank" rel="noopener noreffer">Raspberry Pi</a></strong></p>
<p>I’ve used a RPi4 that I had lying around loaded with Raspbian Buster.</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi_hu779a99be76e550e5ba32d164eed4fdcf_1769197_400x0_resize_q75_box.jpeg" title="images/rpi.jpeg" data-sub-html="<h2>images/rpi.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi_hu779a99be76e550e5ba32d164eed4fdcf_1769197_400x0_resize_q75_box.jpeg" alt="images/rpi.jpeg">
        </a>
    
</p>

<h2 id="software">Software</h2>
<p><strong><a href="https://cubicsdr.com/" target="_blank" rel="noopener noreffer">CubicSDR for MacOS</a></strong></p>
<p>This is an awesome free open-source software for SDR. It wasn’t easy finding one for MacOS, most of the commonly-used projects are made for Linux and Windows. It’s not really required for decoding 433.92Mhz signals, but I wanted to get my hands dirty and look on live RF, it’s pretty neat (and of course to test the device is actually working!)</p>
<p><strong><a href="https://github.com/merbanan/rtl_433" target="_blank" rel="noopener noreffer">rtl_433</a></strong></p>
<p>An amazing project that can be used to decode a variety of RF-based devices on various frequencies (433.92 MHz, 868 MHz, 315 MHz, 345 MHz, and 915 MHz ISM bands). This is the software that does the heavy lifting.</p>
<p><strong><a href="https://github.com/eclipse/mosquitto" target="_blank" rel="noopener noreffer">Mosquitto</a></strong></p>
<p>Very simple MQTT server and client implementation, we’ll be using that as the output of rtl_433 and input of Telegraf to stream the metrics to a remote InfluxDB instance.</p>
<p><strong><a href="https://github.com/influxdata/telegraf" target="_blank" rel="noopener noreffer">Telegraf</a></strong></p>
<p>Agent for collecting and writing metrics. It will subscribe to our MQTT queue, parse and transmit the metrics to InfluxDB.</p>
<h2 id="getting-a-signal">Getting a signal</h2>
<h3 id="connecting-the-antennas">Connecting the antennas</h3>
<p>Let’s start by quickly testing our shiny RTL-SDR receiver, I’ve used the two short 5cm dipole telescopic antennas for this test, you should definitely read <a href="https://www.rtl-sdr.com/using-our-new-dipole-antenna-kit/" target="_blank" rel="noopener noreffer">this great guide</a> that the awesome dudes over at rtl-sdr.com wrote on using the provided antennas. The antenna used is critical for getting high-quality signal in some cases. For our radio FM test any antenna will probably suffice, but if you want to receive <a href="http://happysat.nl/Setup_Meteor/Setup.html" target="_blank" rel="noopener noreffer">weather satellite signal running on 137Mhz</a>, you’ll have to be more specific.</p>
<p>Hopefully you’ve ended up with something like this:</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna_hud9eea2dece6bfac112cbc216cd3fea82_1405534_400x0_resize_q75_box.jpeg" title="images/antenna.jpeg" data-sub-html="<h2>images/antenna.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna_hud9eea2dece6bfac112cbc216cd3fea82_1405534_400x0_resize_q75_box.jpeg" alt="images/antenna.jpeg">
        </a>
    
</p>

<h3 id="listening-to-radio">Listening to radio</h3>
<p>Now you can connect the dongle to your usb port, launch CubicSDR, choose “Generic RTL2832U OEM” and hit “Start”, you can ignore the extra settings you see on the right for now. You should see a pretty moving signal heatmap, you can change the center frequency by hovering over it and tapping space (the key), I chose a local FM radio station that is broadcasting on 88Mhz (FM).</p>
<p>Now your bandwidth setting should be set to 200Khz, you should get a nice signal and when you hover your mouse over it the band will “encapsulate” the signal, click and you should start hearing radio!</p>
<h3 id="checking-frequency-43392mhz">Checking Frequency 433.92Mhz</h3>
<p>Let’s get ready to use <code>rtl_433</code> by looking at the frequency and making sure there are devices there. Usually they will transmit information in 30 second bursts, you can change the center frequency to 433.92Mhz and check that you see data. Near the end of the video above you can see the signal bursts when I switch to 433.92Mhz</p>

<p>
  <iframe src="https://www.youtube.com/embed/fnKBjiwZoSw" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h2 id="decoding-on-the-rpi">Decoding on the RPi</h2>
<h3 id="installing-and-running-rtl_433-on-our-rpi">Installing and running rtl_433 on our RPi</h3>
<p>I’m assuming you have a working Raspberry Pi with SSH access running Raspbian. We’ll need to compile <a href="https://osmocom.org/projects/rtl-sdr/wiki/Rtl-sdr" target="_blank" rel="noopener noreffer">rtl-sdr</a> and <a href="https://github.com/merbanan/rtl_433" target="_blank" rel="noopener noreffer">rtl_433</a>:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="shell"><span># Install RTL-SDR</span>
mkdir ~/sdr
<span>cd</span> ~/sdr
sudo apt-get update
sudo apt-get install git git-core cmake libusb-1.0-0-dev build-essential
git clone git://git.osmocom.org/rtl-sdr.git
<span>cd</span> rtl-sdr/ <span>&amp;&amp;</span> mkdir build <span>&amp;&amp;</span> <span>cd</span> build/
cmake ../ -DINSTALL_UDEV_RULES<span>=</span>ON -DDETACH_KERNEL_DRIVER<span>=</span>ON
make
sudo make install
sudo ldconfig
</code></pre></td></tr></tbody></table>
</div>
</div><div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="shell"><span># Install rtl_433</span>
<span>cd</span> ~/sdr
git clone https://github.com/merbanan/rtl_433.git
<span>cd</span> rtl_433
mkdir build
<span>cd</span> build <span>&amp;&amp;</span> cmake ../
make
sudo make install
</code></pre></td></tr></tbody></table>
</div>
</div><p>You can now connect the RTL-SDR dongle to the Raspberry Pi and see if you can get some temperature and humidity data! (If you haven’t tested your sensors, now is the time to do it). Run <code>rtl_433</code> and you should get some data like in the video below</p>

<p>
  <iframe src="https://www.youtube.com/embed/2MiUqlUVpNk" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="installing-mosquitto-and-telegraf">Installing Mosquitto and Telegraf</h3>
<h4 id="mosquitto">Mosquitto</h4>
<p>So we’re getting live sensor data, that’s pretty awesome, let’s stream everything to InfluxDB. You can open a free <a href="https://cloud2.influxdata.com/signup" target="_blank" rel="noopener noreffer">Influx Cloud</a> account and we’ll configure Telegraf to stream information to it, after you open the account generate an API key for your bucket.</p>
<p>We’ll use Eclipse Mosquitto as the MQTT server, it’s a very lightweight implementation of MQTT server, providing simple pub/sub service which we’ll use.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="shell">sudo apt-get install mosquitto mosquitto-clients

<span># Enable Mosquitto service and check that it's running</span>
sudo systemctl <span>enable</span> mosquitto
sudo systemctl status mosquitto
</code></pre></td></tr></tbody></table>
</div>
</div><p>The logs are accessible over at <code>/var/log/mosquitto/mosquitto.log</code></p>
<h4 id="telegraf">Telegraf</h4>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="shell">curl -sL https://repos.influxdata.com/influxdb.key <span>|</span> sudo apt-key add -
<span>DISTRIB_ID</span><span>=</span><span>$(</span>lsb_release -c -s<span>)</span>
<span>echo</span> <span>"deb https://repos.influxdata.com/debian </span><span>${</span><span>DISTRIB_ID</span><span>}</span><span> stable"</span> <span>|</span> tee /etc/apt/sources.list.d/influxdb.list

sudo apt-get update
sudo apt-get install telegraf
</code></pre></td></tr></tbody></table>
</div>
</div><p>Before running Telegraf service let’s configure it, you can backup the existing config and paste the contents of my <code>/etc/telegraf/telegraf.conf</code> like this:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span></code></pre></td>
<td>
<pre><code data-lang="shell">sudo mv /etc/telegraf/telegraf.conf /etc/telegraf/telegraf.conf.bak
sudo bash -c <span>'cat &lt;&lt; EOF &gt; /etc/telegraf/telegraf.conf
</span><span>[agent]
</span><span>  interval = "10s"
</span><span>  round_interval = true
</span><span>  metric_batch_size = 1000
</span><span>  metric_buffer_limit = 10000
</span><span>  collection_jitter = "0s"
</span><span>  flush_interval = "10s"
</span><span>  flush_jitter = "0s"
</span><span>  precision = ""
</span><span>  debug = false
</span><span>  quiet = false
</span><span>  logfile = ""
</span><span>  hostname = ""
</span><span>  omit_hostname = false
</span><span>[[outputs.influxdb_v2]]	
</span><span>  urls = ["CHANGE THIS"]
</span><span>  token = "CHANGE THIS"
</span><span>  organization = "CHANGE THIS"
</span><span>  bucket = "CHANGE THIS"
</span><span>[[inputs.mqtt_consumer]]
</span><span>  servers = ["tcp://127.0.0.1:1883"]
</span><span>  qos = 0
</span><span>  connection_timeout = "30s"
</span><span>  topics = [ "rtl_433/#" ]
</span><span>  client_id = "telegraf"
</span><span>  persistent_session = false
</span><span>  data_format = "json"
</span><span>EOF'</span>

<span># You can now run telegraf manually to make sure the configuration is okay</span>
telegraf --config /etc/telegraf/telegraf.conf

<span># If all went well go ahead and restart the already running service</span>
sudo systemctl restart telegraf
</code></pre></td></tr></tbody></table>
</div>
</div><p>You’ll need to get your InfluxDB endpoint url, token, organization name and bucket from Influx cloud. The MQTT consumer settings specifies connecting to our MQTT server and listening to rtl_433/# topic, which basically says any topic with the prefix rtl_433/ will be sent to InfluxDB.</p>
<p>The expected data should be json (as specified by the <code>data_format</code> option)</p>
<h3 id="running-rtl_433">Running rtl_433</h3>
<p>Now for the last part, just run rtl_433 with mqtt output!, to make sure everything works you can first run a mosquitto subscription client and listen to incoming events by running <code>mosquitto_sub -t "rtl_433/#"</code>, afterwards launch it (I like using screen for that, see the next video):</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td>
<td>
<pre><code data-lang="shell">rtl_433 -C si -F <span>"mqtt://localhost:1883,events=rtl_433[/model][/id]"</span>
<span># You will not get any data in the shell so if you think</span> 
<span># something is not working launch mosquitto_sub and make sure you are getting events</span>
</code></pre></td></tr></tbody></table>
</div>
</div>
<p>
  <iframe src="https://www.youtube.com/embed/lR6ynCU9QYs" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>If all went well data should be flowing to InfluxDB! hurrah!</p>
<h2 id="viewing-your-data">Viewing your data</h2>
<p>Using InfluxDB is outside the scope of this post but you should be able to get funky graphs like this one:</p>
<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" title="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" data-src="images/influx_dashboard.png" data-srcset="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png, images/influx_dashboard.png 1.5x, /posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png 2x" data-sizes="auto" alt="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" srcset="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png, https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png 1.5x, https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png 2x">
    </a></p><h2 id="final-words">Final words</h2>
<p>Using RTL-SDR for decoding RF data is only the tip of the iceberg of what you can do with it, I highly suggest going to <a href="https://www.rtl-sdr.com/" target="_blank" rel="noopener noreffer">rtl-sdr.com</a> and checking some of their amazing tutorials - You can receive live weather satellite data, decode trunked radio systems and see the universe!</p>
</div></div>]]>
            </description>
            <link>https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817738</guid>
            <pubDate>Mon, 13 Jul 2020 06:46:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scheduling Your Life Like a Computer Engineer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817690">thread link</a>) | @mycpuorg
<br/>
July 12, 2020 | http://www.mycpu.org/scheduling/ | <a href="https://web.archive.org/web/*/http://www.mycpu.org/scheduling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>No matter which stage of career you are in, managing time and tasks become a
matter of utmost priority. Paul Graham’s essay on <a href="http://www.paulgraham.com/makersschedule.html">Maker’s
Schedule</a> explains a good way
to think about typical programmers vs typical managers schedule.</p>

<p>Beyond this, there is a more specific problem that most programmers battle with
intra-project prioritization. You break down a large project into sub tasks and
how would you schedule them? Especially if the project is for a client (assuming
it doesn’t entail a monolithic purpose to it, since this is extremely rare). For
example: it rarely is “Make me a new text editor”</p>

<p>With that said, if you looked into how Operating Systems handle this sort of a
thing we can see the various scheduling policies available. In Linux Kernel,
there are a ton of such policies:</p>
<ul>
  <li>Completely Fair Scheduler (CFS)</li>
  <li>FIFO or FCFS (First In First Out)</li>
  <li>Earliest Deadline First or Deadline Scheduling (EDF)</li>
</ul>

<h2 id="earliest-deadline-first-edf">Earliest Deadline First (EDF)</h2>
<p>EDF has produces an optimal scheme for minimizing the maximum lateness.</p>

<p><img src="http://www.mycpu.org/images/EDD.png" alt="">
<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>If your goal is to simply minimize the amount of lateness only, then this is
it. It is the optimal scheme. However, this has the downside of producing a lot
of tasks can be late albeit by a smaller margin. What if you want to optimize
for minimizing the number of tasks that are late?</p>

<h2 id="moores-algorithm">Moore’s Algorithm</h2>
<p>Moore’s Algorithm optimizes for the number of tasks that are late. It does so by
first ordering the tasks as per EDF scheme then trying to spot a largest job that
results in delaying a later task in the pipeline. It then moves this large job
to the end of the queue.</p>

<p><img src="http://www.mycpu.org/images/MooresAlgo.png" alt="">
<sup id="fnref:1:1"><a href="#fn:1">1</a></sup></p>

<p>You can break down a big problem into smaller tasks, by simply using the better
of these two schemes recursively you have solved your schedule. You have even
mathematically optimized your scheduling scheme. Another important, yet
underrated benefit is that you have drastically reduced your cognitive load on
the planning/scheduling aspect. Instead you get to look deeper into the design
and other technical parts of the project.</p>



      <hr>
      
    </div></div>]]>
            </description>
            <link>http://www.mycpu.org/scheduling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817690</guid>
            <pubDate>Mon, 13 Jul 2020 06:35:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817638">thread link</a>) | @apsec112
<br/>
July 12, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817638</guid>
            <pubDate>Mon, 13 Jul 2020 06:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Evolutionary Psychology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817470">thread link</a>) | @ghosthamlet
<br/>
July 12, 2020 | https://www.deepideas.net/introduction-to-evolutionary-psychology/ | <a href="https://web.archive.org/web/*/https://www.deepideas.net/introduction-to-evolutionary-psychology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				<div>
					


<div> <!-- start fusion sticky header wrapper -->
	<div>
		<div>
							<div data-margin-top="31px" data-margin-bottom="0px" data-margin-left="0px" data-margin-right="0px">
			<a href="https://www.deepideas.net/">

						<!-- standard logo -->
			<img src="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png" srcset="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png 1x" width="332" height="102" alt="deepideas.net Logo" data-retina_logo_url="">

			
					</a>
		
<div>
			<h3>
			a blog on cognitive science and artificial intelligence, dedicated to the deep thinkers of this world		</h3>
	</div>
</div>
								
			
					</div>
	</div>
	
</div> <!-- end fusion sticky header wrapper -->
				</div>
				
			</header>
						
			
		
				
			
			

						<main id="main">
				<div>

<section id="content">
			
	
					<article id="post-648">
						
														
						
																									<div>
				<p>Evolutionary psychology is an approach to understand human behavior that combines insights gained from evolutionary biology, the computational sciences and the study of ancestral living conditions. It has been put forward as an opposing view to what Tooby and Cosmides (1992) call the <em>Standard Social Science Model</em> (SSSM), which has dominated the social and behavioral sciences throughout most of the 20th century. According to the SSSM, the mental organization of adult human beings is not caused by human nature. Rather, humans acquire their mental organization almost entirely from their sociocultural and physical environment. Human beings, on this view, only have a minimal amount of innate impoverished drives (like hunger, thirst, sexual motivation, etc.) and, independently of these, a capacity to be socialized through learning.</p>
<p>A prominent argument given in favor of the SSSM is the fact that genetically determined behavior might be maladaptive due to changing environmental conditions, and therefore the mind evolved towards general-purpose and domain-general learning systems. On this view, the phenotype’s behavior is plastic and tailored toward maximizing individual fitness under changing environmental circumstances. The selective pressures of ancestral environments gave rise to this plasticity, but the concrete adaptive problems that have been faced in these environments play only a minor role in explaining the behavior of modern humans. This is the reason why many social scientists study human behavior in modern conditions more or less independently from their evolutionary history.</p>
<p>Evolutionary psychology, in contrast, holds that psychological mechanisms are evolved adaptations to ancestral adaptive problems. An analogy is drawn here between organs in the body and “cognitive programs” or “mental organs”: Analogous to how organs in the body evolved to solve a particular adaptive problem, e.g. digesting food, cognitive programs evolved to solve a particular adaptive information processing problem, e.g. predator/prey distinction, kin detection, language, etc.</p>
<p>In the following, we will break down the individual tenets of evolutionary psychology and review the arguments that are given in support of these tenets. Since not all tenets are shared by all evolutionary psychologists, we will focus here on the formulation given by Cosmides and Tooby (1987) and Tooby and Cosmides (2005). The tenets are not listed explicitly, but can be reconstructed implicitly from these texts. I will go through each tenet in turn and present a reconstruction of the arguments that motivate these tenets.</p>
<h3>Tenet 1: The brain evolved to be a computer that solves information processing problems.</h3>
<p>This tenet is motivated as follows: Environments pose adaptive information processing problems to organisms. Hence, the genes of organisms that successfully solve these information processing problems spread in the gene pool and such organisms are, by definition, computers.</p>
<p>This tenet, Tooby and Cosmides (2005, p. 31) argue, is shared by proponents of the SSSM. Even a domain-general learning mechanism would be an innate information processing mechanism that evolved at some point to solve adaptive problems. For example, operant conditioning presupposes an innate mechanism to alter the probability of behaviors based on their intrinsically reinforcing consequences (like food or pain). Similarly, classical conditioning presupposes innate unconditioned stimuli and a method to calculate contingencies. Consequently, Tooby and Cosmides (2005, p. 32) conclude that “learning is not an alternative explanation to the claim that natural selection shaped the behavior” and that “a behavior can be, at one and the same time, cultural, learned, and evolved”. This means that the commonly perceived controversy between innateness/evolvedness on the one hand and learnedness on the other is based on a false dichotomy. Rather, it is proposed, evolution created programs as learning mechanisms, and these mechanisms are a prerequisite for learning to be able to occur. The disagreement between the SSSM and evolutionary psychology, therefore, only regards the structure of the evolved learning mechanisms, not the question whether such learning mechanisms evolved at all.</p>
<p>When we accept the theory of evolution through natural selection, it arguably becomes theoretically impossible to deny that the brain evolved to be a computer that solves adaptive information processing problems – unless we claim that (A) evolution hasn’t found this path yet, (B) evolution cannot find this path in principle since it would lead through a fitness valley or (C) adaptive problems aren’t information processing problems and therefore a computer would not be the ideal solution. Discussing these possibilities would be beyond the scope of this introduction, so I am going to suppose (A), (B) and (C) to be false for the rest of this discussion. This leads us to accept this tenet.</p>
<h3>Tenet 2: The brain is not a “blank slate” domain-general fitness-maximizing machine.</h3>
<p>Cosmides and Tooby (1987, p. 47) and Tooby and Cosmides (2005, pp. 294- 299) argue that there is no domain-general success criterion that is correlated with fitness and, therefore, a domain-general mechanism would not be successful at actually maximizing fitness and could therefore not have evolved. This argument can be summarized as follows: If no domain-specific innate knowledge is present in the organism, then it can only acquire knowledge that can be inferred from perceptual inputs, without relying on innate perceptual heuristics. Similarly, it can learn behaviors only through trial and error learning, which would amount to generating random sequences of actions, observing the fitness outcome (e.g. the number of produced offspring) and then reinforcing or mitigating behaviors based on this outcome. Proposing instead that the mechanism could rely on perceptual cues like smell or taste as a proxy for expected fitness, they argue, amounts to “admitting domain-specific innate knowledge”.</p>
<p>However, when observing a certain positive or negative fitness outcome (like an increase or decrease in the produced offspring), it is virtually impossible to trace it back to the precise actions or sequences of actions that caused it, since virtually any action taken before in the organism’s life could have caused it. Furthermore, whether a sequence of action promotes fitness is highly context-sensitive. Thus, due to the resulting combinatorial explosion, behaviors cannot reliably be reinforced or mitigated and behavior stays more or less random. Therefore, an organism with adequate innate domain-specific knowledge, perceptual heuristics and perception-action patterns would have a fitness advantage over an organism that only has a domain-general fitness-maximizing mechanism, consequently triggering selection for organisms with these traits.</p>
<h3>Tenet 3:&nbsp;The brain executes innate, domain-specific, functionally isolable cognitive programs that generate particular behaviors in response to particular external or internal informational inputs. Most or even all of these programs evolved as a response to a particular adaptive information processing problem.</h3>
<p>It should be noted that it is not claimed that all cognitive programs generate behavior deterministically based on the current perceptual input. Rather, some of these programs exhibit what is commonly called <em>experience-dependent plasticity</em>: They are able to learn based on the input they receive throughout the organism’s development (Cosmides and Tooby, 1987, p. 284). For example, the language program learns to acquire the language of a person’s surrounding community. The programs, therefore, did not evolve to produce a certain kind of behavior, but they evolved to produce a mapping from current inputs and the sequence of inputs they received throughout development to behaviors. Different programs have different degrees of experience-dependent plasticity, depending on the fitness advantage that plasticity would provide over genetic determinism in the program’s adaptive domain.</p>
<p>In a similar fashion, programs are <em>experience-expectant</em>: They evolved to be able to develop only if they receive certain informational inputs at critical periods throughout development (Tooby and Cosmides, 2005, p. 34-35). This entails that a program’s innateness does not mean that it is present at birth – much like teeth are innate but not present at birth. Rather, a cognitive program can develop at any point in an organism’s life, depending on whether it is relevant at that point in life and whether the developmentally relevant informational inputs have been received. Tooby and Cosmides (2005, p. 35) stress that this developmentally relevant information consists not only of contingencies in physical laws and the behavior of other organisms, but also of the physical and cultural environment. The latter comprise a second inheritance system that co-evolves with the genes, and changes in these environments can lead to significant alterations in the operation of the cognitive programs, or even a failure of certain cognitive programs to develop.</p>
<p>It should also be noted that it is not claimed that the cognitive programs can&nbsp;only generate behavior according to their original adaptive function. For example, the language program, which arose as an adaptation for spoken language, can learn to acquire reading and writing (Tooby and Cosmides, 2005, p. 26). The ability to learn reading and writing is not an adaptation but a by-product of the adaptation for spoken language.</p>
<p>However, it is claimed that the …</p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepideas.net/introduction-to-evolutionary-psychology/">https://www.deepideas.net/introduction-to-evolutionary-psychology/</a></em></p>]]>
            </description>
            <link>https://www.deepideas.net/introduction-to-evolutionary-psychology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817470</guid>
            <pubDate>Mon, 13 Jul 2020 05:32:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Is Surprisingly Good as a Server Language]]>
            </title>
            <description>
<![CDATA[
Score 307 | Comments 339 (<a href="https://news.ycombinator.com/item?id=23817464">thread link</a>) | @signa11
<br/>
July 12, 2020 | https://stu2b50.dev/posts/rust-is-surpris76171 | <a href="https://web.archive.org/web/*/https://stu2b50.dev/posts/rust-is-surpris76171">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
      <div id="main">
        

    

    <div>
        
<p>At some point, I got tired of my old static site generator setup for my blogs and other pages. It was annoying to ssh every time I wanted to make a modification, it was annoying to sftp or sshfs all my images, and so forth. And god forbid, if you ever wanted someone else to write something or make an edit, let me tell you, most people are not particularly happy when you tell him "hey, I'll make you a user on my server, give me your public key so you can ssh in".</p>
<p>I wanted something with a <em>little</em> more dynamism. </p>
<p>So that was the project: a small scope blog, where a few, already <em>trusted</em> users can make, edit, and post new pages in markdown (with a nice markdown editor courtesy of <a href="https://simplemde.com/">SimpleMDE</a>). Additionally, I want a built in jank verison of imgur so I can satisfy my need to be self sufficient without going crazy.</p>
<p>So while I could whip something up in an afternoon with Django, I could also experiment with other languages. The project is simple enough that I can't imagine being too limited by any language's ecosystem. And I've been itching to write something substansive in Rust...</p>
<h3>Which framework?</h3>
<p>The biggest framework is probably <code>actix-web</code>. But</p>
<ol>
<li>When I was scoping out my options months ago, actix-web's maintainer quit with a bunch of drama</li>
<li>At least from what I could tell reading the docs, it seems more suited to APIs rather than servers serving templated HTML</li>
<li>With the above, I wanted this to be a weekend project, not a weekly project, so the more batteries included the better</li>
<li>I really don't want to figure out which async library is considered better. And note that with each async library, comes its own ecosystem of libraries, which only work with that async library, so it's a pretty hard decision to reverse after you made it.</li>
</ol>
<p>So Rocket it is. </p>

<p>Something I didn't realize until I started scoping out this project is that on servers... the memory model is actually pretty simple! </p>
<p>Much of your state is just handled by your database. I <em>never</em> actually fought with the borrow checker. I never had to. For the most part, everything had exactly one owner, and exactly one lifetime: the function that's handling the request. </p>
<p>Rocket, too, has a surprising amount of "magic":</p>
<pre><code>#[get("/posts/&lt;slug&gt;/"]
pub fn post_view(slug: String) -&gt; Option&lt;Template&gt; {
    ...
		
    Some(Template::render("/posts/post", hashmap! { "post" =&gt; post}))
}
</code></pre>
<p>As opposed to Flask's</p>
<pre><code>@app.route("/posts/&lt;string:slug&gt;")
def post_view(slug):
    ...
		
    return render_template("posts/post.html", post=post)
</code></pre>
<p>Rust's macro system has really impressed me so far. Not only is there a shocking amount of "just works", but it's all statically typed and compiled.</p>
<p>The closest analogue to Rocket is flask + all the flask adjacent libraries (SQLAlchemy-flask, etc). Rocket, through the power of 3rd party integrations, comes with two template engines (handlebars, and Tera, which is basically Jinja2), database pooling support for quite a few ORMs/DB drivers, and more.</p>
<p>It's still at the point where you have to roll your own auth, though.</p>
<p>While I've heard comparisons to Django/Rails, it doesn't really seem like they're going that direction. Django/Rails purposefully put you, the developer, on the metaphorical rails, dictating best practices from everything from where the files go, to how you update your models and views. Rocket doesn't do that, and I'm not sure it should ever.</p>
<p>I also had, for the most part, the experience that "if it compiles, it works". Most of my runtime errors were in the templates, which incidentally is the only thing that's not statically typed. </p>
<p>I guess that's really what surprised me. For a lot of it, "it just works"! There's not a lot of boilerplate syntax, type inference keeps your functions clean, and I didn't write a <em>single</em> lifetime annotation at any point. My rust server really didn't look that different from my flask server, or my Django server, and honestly it looks cleaner than my Java server. All with no garbage collector or runtime.</p>

<p>Next, I'll talk about Diesel, which as far as I can see, is the most mature ORM available. While I do have my gripes, it's not really anything "objectively" bad. I suppose it's more on tradeoffs, and Diesel chooses to go light on the magic. </p>
<p>For one, it's annoying to make two structs for each table. You need one to represent the table, and one to insert with (with any autogenerated columns like the primary key removed). For instance, I have</p>
<pre><code>#[derive(Identifiable, Queryable, Associations, PartialEq, Debug, Serialize)]
#[belongs_to(BlogPosts, foreign_key="post_id")]
#[table_name = "tags"]
pub struct Tag {
    id: i32,
    tag_name: String,
    post_id: i32,
}

#[derive(Insertable)]
#[table_name = "tags"]
pub struct InsertTag {
    tag_name: String,
    post_id: i32
}
</code></pre>
<p>Additionally, while in some ORMs you write your table models, and the ORM generates your SQL migrations, in Diesel, you write your SQL migrations by hand, and the ORM generates a <code>schema.rs</code> file that contains the mappings. I actually don't mind that one too much.</p>
<p>Diesel also only supports parent-child relationships, and you have to be quite explicit. There's no magic field on your parent, that magically gives you a list of its children. No, you just have to write the query and call it. In some sense it's more like using a slightly fancier query builder.</p>
<p>Dipping down from that level of magic, it's not really a <em>bad</em> thing per se. By being explicit, you prevent users from believing too much in that magic, and shooting themselves in the foot, like N+1 selects. </p>
<p>But I'm not going to say it didn't slow me down quite a bit, either. And to be honest, writing joins was a humongous pain in the ass. Maybe that's how it should be, but maybe that also caused a generation of NoSQL databases. 🤷</p>

<p>Here's how you upload an image in flask</p>
<pre><code>@app.route('/images/upload')
def upload_file():
	files = request.files['file']
	if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
</code></pre>
<p>Here's the "simpler" example, while using a <em>third party library in addition</em> from abonader</p>
<p><a href="https://github.com/abonander/multipart/blob/master/examples/rocket.rs"><strong>See the whole thing here</strong></a></p>
<pre><code>#[post("/upload", data = "&lt;data&gt;")]
// signature requires the request to have a `Content-Type`
fn multipart_upload(cont_type: &amp;ContentType, data: Data) -&gt; Result&lt;Stream&lt;Cursor&lt;Vec&lt;u8&gt;&gt;&gt;, Custom&lt;String&gt;&gt; {
    // this and the next check can be implemented as a request guard but it seems like just
    // more boilerplate than necessary
    if !cont_type.is_form_data() {
        return Err(Custom(
            Status::BadRequest,
            "Content-Type not multipart/form-data".into()
        ));
    }

    let (_, boundary) = cont_type.params().find(|&amp;(k, _)| k == "boundary").ok_or_else(
            || Custom(
                Status::BadRequest,
                "`Content-Type: multipart/form-data` boundary param not provided".into()
            )
        )?;

    match process_upload(boundary, data) {
        Ok(resp) =&gt; Ok(Stream::from(Cursor::new(resp))),
        Err(err) =&gt; Err(Custom(Status::InternalServerError, err.to_string()))
    }
}

fn process_upload(boundary: &amp;str, data: Data) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {
    let mut out = Vec::new();

    // saves all fields, any field longer than 10kB goes to a temporary directory
    // Entries could implement FromData though that would give zero control over
    // how the files are saved; Multipart would be a good impl candidate though
    match Multipart::with_body(data.open(), boundary).save().temp() {
        Full(entries) =&gt; process_entries(entries, &amp;mut out)?,
        Partial(partial, reason) =&gt; {
            writeln!(out, "Request partially processed: {:?}", reason)?;
            if let Some(field) = partial.partial {
                writeln!(out, "Stopped on field: {:?}", field.source.headers)?;
            }

            process_entries(partial.entries, &amp;mut out)?
        },
        Error(e) =&gt; return Err(e),
    }

    Ok(out)
}
</code></pre>
<p>Now, to be fair, Rocket is in version 0.4.5. From <a href="https://github.com/SergioBenitez/Rocket/issues/106"><strong>this github issue</strong></a>, multipart form support is coming in 0.5.0. But it doesn't change the fact that right now, the current libraries are somewhat immature still. They lack some of the edge features, especially for more traditional web servers that serve templated HTML, as opposed to pure API servers, or an SPA. </p>
<hr>
<p>Rust's errors are quite good, usually. But that's before you get into, well, libraries that try to do a bit more. I ran into some... interesting error messages, mostly from macros in Rocket and Diesel. Take a look at this one, for instance.</p>
<pre><code>the trait bound `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32): diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not satisfied

the trait `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not implemented for `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32)`

help: the following implementations were found:
        &lt;(A, B, C, D, E, F, G, H, I) as diesel::Queryable&lt;(SA, SB, SC, SD, SE, SF, SG, SH, SI), __DB&gt;&gt;
note: required because of the requirements on the impl of `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stu2b50.dev/posts/rust-is-surpris76171">https://stu2b50.dev/posts/rust-is-surpris76171</a></em></p>]]>
            </description>
            <link>https://stu2b50.dev/posts/rust-is-surpris76171</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817464</guid>
            <pubDate>Mon, 13 Jul 2020 05:31:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gödel’s Incompleteness Theorem and Its Implications for Artificial Intelligence]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817462">thread link</a>) | @ghosthamlet
<br/>
July 12, 2020 | https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/ | <a href="https://web.archive.org/web/*/https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				<div>
					


<div> <!-- start fusion sticky header wrapper -->
	<div>
		<div>
							<div data-margin-top="31px" data-margin-bottom="0px" data-margin-left="0px" data-margin-right="0px">
			<a href="https://www.deepideas.net/">

						<!-- standard logo -->
			<img src="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png" srcset="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png 1x" width="332" height="102" alt="deepideas.net Logo" data-retina_logo_url="">

			
					</a>
		
<div>
			<h3>
			a blog on cognitive science and artificial intelligence, dedicated to the deep thinkers of this world		</h3>
	</div>
</div>
								
			
					</div>
	</div>
	
</div> <!-- end fusion sticky header wrapper -->
				</div>
				
			</header>
						
			
		
				
			
			

						<main id="main">
				<div>

<section id="content">
			
	
					<article id="post-71">
						
														
						
																									<div>
				<h2>Introduction</h2>
<p>This text gives an overview of Gödel’s Incompleteness Theorem and its implications for artificial intelligence. Specifically, we deal with the question whether Gödel’s Incompleteness Theorem shows that human intelligence could not be recreated by a traditional computer.</p>
<div class="page" title="Page 1">
<div>
<div>
<p>Sections 2 and 3 feature an introduction to axiomatic systems, including a brief description of their historical development and thus the background of Gödel’s Theorem. These sections provide the basic knowledge required to fully understand Gödel’s Theorem and its significance for the history of mathematics – a necessary condition for understanding the arguments to follow. Section 4 features a thorough description of Gödel’s Theorem and outlines the basic idea of its proof. Sections 5 and 6 deal with arguments advocating the view that intelligence has a non-algorithmic component on the grounds of Gödel’s Theorem. In addition to a detailed account of the arguments, these sections also feature a selection of prominent objections to these arguments raised by other authors. The last section comprises a discussion of the arguments and my own objections.</p>
<h2>The Formalization of Mathematics</h2>
<div class="page" title="Page 1">
<div>
<div>
<p>At the beginning of the 20th century, the mathematical community suffered from a crisis regarding the very foundations of mathematics, triggered by the discovery of various paradoxes that called into question the reliability of mathematical intuition and the notion of proof. At that time, some fields of mathematics were grounded on a rigorous formal basis, called an <strong>axiomatic system</strong> (or interchangeably formal system), whereas other fields relied on a certain degree of intuitive insight.</p>
<div class="page" title="Page 2">
<div>
<div>
<p>In a formal way, an axiomatic system is a set of propositions, expressed in a formal language, called axioms. These axioms represent statements that are assumed to be true without proof. The set of axioms is equipped with a set of inference rules which can be used to derive other propositions, called theorems, by applying them to the axioms. Applying the rules of inference boils down to replacing expressions by certain other expressions according to precise syntactical rules. The axioms and the set of inference rules are ideally chosen in such a way that they are intuitively evident. This way, the truth of a complex, non-obvious statement can be accepted by accepting the truth of the axioms and sequentially applying the inference rules until the complex statement in question is deduced.</p>
<div class="page" title="Page 2">
<div>
<div>
<p>An early, prominent example of such an axiomatic system is the Euclidean geometry described by the ancient Greek philosopher Euclid in c. 300 BC (an English translation can be found in [Euc02]). It consists of 5 axioms making trivial statements about points, lines and circles (e.g. that any two points could be connected by a line). From these axioms, Euclid derived 48 non-trivial geometric propositions solely by means of logical inference and without making use of informal geometric intuition or perception.</p>
<div class="page" title="Page 2">
<div>
<div>
<p>Up until modern times, geometry was the only branch of mathematics that was predicated on such a sound axiomatic basis, whereas research and applications in other branches were carried out without a rigid formal notion about which types of inference were allowed and which statements were assumed to be intuitively evident. This was due to the fact that, for most practical purposes, mathematicians saw no need for doing so. However, this changed with the discovery of various paradoxes around the turn of the 20th century. In 1901, the British mathematician Bertrand Russell put forward what later came to be known as <strong>Russell’s paradox</strong> (cf. [Gri04]). This paradox showed an inherent flaw in the informal set theory proposed by German mathematician Georg Cantor, according to which every definable collection of distinct elements is a set. Russell defined the set R of all sets that do not contain themselves, symbolically:</p>
<p>$$\{x \; \mid \; x \not\in x\}$$</p>
<div class="page" title="Page 2">
<div>
<div>
<p>According to Cantor, R is a valid set. The paradox arises when one asks the question whether R contains itself. If R contains itself, then by definition it does not contain itself. If, on the other hand, it does not contain itself then it contains itself by definition. Symbolically:</p>
<p>$$R \in R \; \iff R \not\in R$$</p>
<div class="page" title="Page 3">
<div>
<div>
<p>Therefore, the question whether R contains itself has no well-defined answer. This example shows that the notion of a set defined by Cantor is flawed, even though it seems to be intuitively reasonable. Examples like this lead many mathematicians to recognize that intuition is not a safe guide and that there was a need to supply all branches of mathematics with an axiomatic system that would be sufficient to formally derive all true propositions, a standpoint later termed <strong>formalism</strong> (cf. [NN01] p. 3). Over time, more and more branches, both new and old, were equipped with sets of axioms (e.g. the Zermelo-Fraenkel set theory, cf. [Fra25]).</p>
<div class="page" title="Page 3">
<div>
<div>
<p>It is worth noting that axiomatic systems and formal proofs do not require an intuitive understanding of the entities described or the nature of the proven statements. Consider the following example:</p>
<div class="page" title="Page 3">
<div>
<div>
<blockquote><p><strong>Axiomatic system 1.<br>
</strong>1. Every member of P is contained in exactly two members of L.<br>
2. Every member of L contains exactly two members of P.<br>
3. Every two members of L share exactly one member of P.</p></blockquote>
<div class="page" title="Page 3">
<div>
<div>
<p>This axiomatic system makes statements about some abstract sets L and P , and even though we can understand the axioms per se, we do not associate any meaning with the symbols and we do not have any intuition about the overall structure of L and P. Still, we can deduce theorems from these axioms. For example, it can be shown that every three members of L contain exactly three members of P. Even though the axioms were given informally, they can be translated into second-order logic and the proof for the theorem can be carried out using rules that just replace certain sequences of symbols with other symbols. This way, the proof could be carried out by a computer simply by iteratively applying symbol replacement rules on meaningless sequences of symbols until the theorem is obtained. It is then clear that the theorem follows from the axioms without any intuition as to what the theorem or the axioms actually represent.</p>
<h2>Hilbert’s Program</h2>
<div class="page" title="Page 3">
<div>
<div>
<p>A prominent representative of the formalist standpoint was David Hilbert, who initiated what was later termed <strong>Hilbert’s Program</strong> (cf. [Zac15]). Hilbert advocated the view that all fields of mathematics should be grounded on an axiomatic basis. Furthermore he demanded that every such system should be proven to be consistent, which means that it is impossible to deduce two contradictory theorems from the axioms.</p>
<div class="page" title="Page 3">
<div>
<div>
<p>Proving the inconsistency of an axiomatic system can be done by deducing a contradiction. The question that Hilbert wanted to address, however, was how to prove the consistency, i.e. how to prove the impossibility to deduce a contradiction. One way to do so is to find an interpretation of the axioms, such that they form true statements about some part of reality or some abstract concept of our intuition. A possible model for the axiomatic system 1 is given in the following image:</p>
<p><img data-attachment-id="102" data-permalink="https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/triangle/" data-orig-file="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=1270%2C930&amp;ssl=1" data-orig-size="1270,930" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="triangle" data-image-description="" data-medium-file="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=300%2C220&amp;ssl=1" data-large-file="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=1024%2C750&amp;ssl=1" src="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle-300x220.png?resize=300%2C220" alt="" width="300" height="220" srcset="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=200%2C146&amp;ssl=1 200w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=300%2C220&amp;ssl=1 300w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=400%2C293&amp;ssl=1 400w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=600%2C439&amp;ssl=1 600w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=768%2C562&amp;ssl=1 768w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=800%2C586&amp;ssl=1 800w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=1024%2C750&amp;ssl=1 1024w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=1200%2C879&amp;ssl=1 1200w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=1270%2C930&amp;ssl=1 1270w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></p>
<p>When we interpret the set P as the corners of a triangle and the set L as its edges, then the axioms are invested with meaning and we can verify beyond doubt that all axioms represent true statements about the model by verifying them for each individual element. This can be done easily since there are only finitely many elements. This proves the consistency of the system, because no contradiction can be deduced from true premises.</p>
<div class="page" title="Page 4">
<div>
<div>
<p>However, there are axiomatic systems for which the model-based approach to proving their consistency is open to dispute. If, for example, the axioms require the model to contain an infinite number of elements, then it is impossible to verify the truth of the axioms beyond doubt, since the truth can no longer be verified for each individual element. Moreover, the model-based approach actually only reduces the consistency of one system to the consistency of another system. As regards the triangle example, we established the consistency of the axioms by verifying them for the triangle, but in doing so we implicitly assumed the consistency of geometry. Therefore, we have only shown that if geometry is consistent, then our axiomatic system is also consistent; we have given what is called a <strong>relative proof of consistency</strong>.</p>
<div class="page" title="Page 4">
<div>
<div>
<p>Hilbert urged to find <strong>absolute proofs of consistency</strong>, i.e. proofs that establish the consistency of an axiomatic system without presupposing the consistency of another axiomatic system. Absolute proofs of consistency use structural properties of the axioms and inference rules in order to show that no contradictions can be derived; they are not proofs within the formal axiomatic system itself, but rather proofs about the system. They are, so to speak, proofs in some meta-system. To better understand the concept of a meta-system, consider the statement ”’$p \vee p \rightarrow p$’ is a tautology”. This is not a statement within propositional logic, but a statement in some meta-system <em>about</em> propositional logic, and it can be proved within that meta-system.</p>
<div class="page" title="Page 5">
<div>
<div>
<p>Absolute proofs of consistency have successfully been established for some axiomatic systems, e.g. propositional logic (cf. [NN01] p. 45). This lead Hilbert to believe that such a proof could be found for any consistent axiomatic system, which is where Gödel’s Incompleteness Theorem comes into play: amongst other things, it shows that this is impossible for most of the axiomatic systems.</p>
<h2>Gödel’s Incompleteness …</h2></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/">https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/</a></em></p>]]>
            </description>
            <link>https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817462</guid>
            <pubDate>Mon, 13 Jul 2020 05:31:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The three levels of Hindu philosophy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817439">thread link</a>) | @paraschopra
<br/>
July 12, 2020 | https://invertedpassion.com/three-levels-of-hindu-philosophy/ | <a href="https://web.archive.org/web/*/https://invertedpassion.com/three-levels-of-hindu-philosophy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-511">
		<!-- .entry-header -->
	<div>
		
		
<p><strong>1/</strong> The first level related to the metaphysical and spiritual domain.</p>



<p>It says that Brahman is all that exists and our material world (Maya) comes from ignorance.</p>



<p>The Brahman is not a God. It is beyond any quality – it isn’t intelligent, good or bad. It just is.</p>



<p><strong>2/</strong> It also suggests that if we strip away all ignorance, we will discover that the self – the atman – is one and the same thing as the Brahman.</p>



<p>At its core, this level denies the duality of subject and object and says they both are the same.</p>



<p><strong>3/</strong> The second level has more religious connotations because, like all religions, its purpose is the stabilization of society.</p>



<p>The concept of Karma and Dharma ensures that society has net positive interactions. And the rituals and idol worship ensures everyone knows who is in the camp.</p>



<p><strong>4/</strong> This level ensures an ethical code exists and that it’s clear who all share that same ethical code.</p>



<p>The symbols – the idols, the chants, the rituals – take a spiritual dimension on their own, but these are subservient to the belief in one Brahman – the essence of the world.</p>



<p><strong>5/</strong> The third level is psychological – to give guidance to an individual on how to live his/her life.</p>



<p>The suggestion in <a href="https://invertedpassion.com/what-gita-teaches-us-and-what-it-doesnt/">Gita</a> that one must do work without an expectation of reward is towards minimizing psychological anguish.</p>



<p><strong>6/</strong> To reiterate, the three levels of Hindu philosophy are:</p>



<ul><li>METAPHYSICAL: <a href="https://en.wikipedia.org/wiki/Mah%C4%81v%C4%81kyas">Tat tvam asi.</a> You’re it [it = Brahman]</li><li>SOCIETAL: Rebirth, Karma, Dharma, and Rituals</li><li>PSYCHOLOGICAL: Expect no reward</li></ul>



<p><strong>7/</strong> Of course, everyone has their interpretation. Unlike Judeo-Christian religions, there are no definitive books on Hindusim.</p>



<p>Rather than a bug, I think it’s a feature.</p>



<p>It ceases to be a philosophy if you can’t interpret it on your own.</p>



<p><strong>8/</strong> There are some beautiful ideas in Hinduism, though I’m not sure I agree with all of them.</p>



<p>If you have your favorite ideas, let me know. I love diving deep into Indian philosophy.</p>



<p><em>This essay is a lightly-edited version of a <a href="https://twitter.com/paraschopra/status/1104658952061681665">Twitter thread I posted</a>.</em></p>



<p>Someone made an image out of the three levels:</p>



<figure><img src="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg" alt="" srcset="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg 756w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-221x300.jpg 221w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-768x1041.jpg 768w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-1134x1536.jpg 1134w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq.jpg 1338w" sizes="(max-width: 756px) 100vw, 756px"><figcaption>Made by <a href="https://twitter.com/nisacharan">@nishacharan</a></figcaption></figure>



<p><span><strong>Have an opinion on this essay?</strong></span> You can send your feedback on <a href="https://invertedpassion.com/cdn-cgi/l/email-protection#5828392a392b6961606f7331283e3d3d3c3a393b33183f35393134763b3735">email</a> to me.


</p>



			</div><!-- .entry-content -->
						<!-- .entry-footer -->
		</article></div>]]>
            </description>
            <link>https://invertedpassion.com/three-levels-of-hindu-philosophy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817439</guid>
            <pubDate>Mon, 13 Jul 2020 05:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Butt Pomodoro – A butt triggered pomodoro timer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817401">thread link</a>) | @Abishek_Muthian
<br/>
July 12, 2020 | https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/ | <a href="https://web.archive.org/web/*/https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A need gap of <a href="https://needgap.com/problems/130-remind-me-to-take-break-when-working-from-home-wfh-activity" target="_blank">Remind me to take break when working from home</a> was recently posted. Forgetting to take regular breaks when immersed with work in front of a computer is a common problem, especially when working from home.</p><p>On the flip side, <a href="https://needgap.com/problems/30-getting-things-done-at-individual-level-productivity-taskmanagement" target="_blank">getting distracted from completing a task</a> is also a common problem.</p><h3 id="why-pomodoro">Why pomodoro?</h3><p><a href="https://en.wikipedia.org/wiki/Pomodoro_Technique" target="_blank">Pomodoro technique</a> is to work in 25 minutes intervals called pomodoro, taking 5 minutes break every pomodoro and taking a 30 minutes break after 4 pomodoros.</p><p>This helps in mitigating <a href="https://needgap.com/problems/93-focus-drift-cognitivescience-neuroscience" target="_blank">focus drift</a>, burn outs and enables us to complete our tasks.</p><h3 id="why-butt-triggered">Why butt triggered?</h3><p>There are no dearth of pomodoro timer based apps in the market, but they require manual trigger of the timer each time we are about to start a task, this is a huge overhead as stated by in the first problem statement.</p><p>I personally feel that the activity of constantly interacting with the pomodoro timer is counter-intuitive for productivity and so to address that it needs to be triggered seamlessly without any user action.</p><p>Most of us work with the computer while seated on a chair, I figured that triggering the pomodoro timer with a sensor under the seat would fulfil my goals.</p><h3 id="design-goals">Design goals</h3><h4 id="simple">Simple</h4><p>The solution should be simple enough to be easily reproducible by many, even by those without the technical know-how of the solution.</p><h4 id="portable">Portable</h4><p>Setup should be easily transportable to any chair, be it at home or office. Hence, facial recognition with machine learning based solution is not being considered.</p><h4 id="inexpensive">Inexpensive</h4><p>Components should be easily available and inexpensive.</p><h3 id="design-choices">Design choices</h3><h4 id="sensor">Sensor</h4><p>Sensor is needed to trigger the timer when I sit on the chair, basically to serve as a switch.</p><p>I started with a pressure sensor made with Velostat fabric, since its light weight and could seamlessly fit between the seat cushion and the chair. But the resistance varied too much in my test to serve as a reliable switch and I didn’t like the possibility conductive threads setting my ass on fire if they get shorted.</p><p><amp-accordion id="velostat-accordian" disable-session-states=""><section><h5>Click to see Velostat with Conductive Threads</h5><amp-img alt="Velostat with conductive thread" src="/images/Velostat_Conductive_Thread.jpg" width="3915" height="3813" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="trigger">Trigger</h4><p>Then I experimented with a standard 12mm momentary button switch on a 170 holes mini breadboard and it served the purpose well. Depending upon your chair, seat cushion and your weight; you might have to choose a button which works well for you.</p><p><amp-accordion id="button-accordian" disable-session-states=""><section><h5>Click to see Momentary Button</h5><amp-img alt="Button" src="/images/Momentary_Button.jpg" width="2863" height="3451" layout="responsive"></amp-img></section><section><h5>Click to see Mini Breadboard</h5><amp-img alt="Button" src="/images/Mini_Breadboard.jpg" width="1670" height="1365" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="microcontroller">Microcontroller</h4><p>Microcontroller is needed process the input signal from the button, compute the timers and send message to the notifications.</p><p>ESP8266 based NodeMCU is being used the microcontroller for this as it has WiFi for communication.</p><p><amp-accordion id="nodemcu-accordian" disable-session-states=""><section><h5>Click to see NodeMCU</h5><amp-img alt="NodeMCU" src="/images/ESP8266_NodeMCU.jpg" width="962" height="1451" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="power">Power</h4><p>I’m supplying 5V power over microUSB with 18650 power-bank to the NodeMCU.</p><p><amp-accordion id="powerbank-accordian" disable-session-states=""><section><h5>Click to see 18650 Power-Bank</h5><amp-img alt="18650 Power-Bank" src="/images/18650_Power-Bank.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><p><em>Note: The reliability of this power-bank is questionable as I’ve had failures, so I would suggest using a simple battery holder instead.</em></p><p><amp-accordion id="battery_holder-accordian" disable-session-states=""><section><h5>Click to see the setup with battery holder, terminals secured with solder, hot glue and tape</h5><amp-img alt="Butt Pomodoro with Battery Holder" src="/images/Butt_Pomodoro_Battery_Holder.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="computation">Computation</h4><p>My initial plan was to use the NodeMCU itself for computation as that’s what microcontrollers are used for, but stopping the timers at will was bit of a hassle with Arduino code on NodeMCU and decided to leverage the comfort of Go with <a href="https://gobot.io/documentation/platforms/esp8266/" target="_blank">Gobot</a> using Firmata firmware.</p><p>Gobot allows client-server architecture on IoT devices, so NodeMCU can be controlled remotely from a client. The main advantage of using Gobot is that it allows me to modify the code and test it without having to flash it on the NodeMCU each time. I’m running Gobot client on a Raspberry Pi 2 after flashing firmata server on NodeMCU.</p><p><em>Update: Starting and stopping timers with Gobot on NodeMCU within different Goroutines resulted in unnecessary race conditions, deadlocks hence I resorted to calculating elapsed time manually and simple flags to start the timers. I guess, this method could have been easily implemented directly on the NodeMCU with Arduino code, but due to other advantages of using Gobot I’m continuing with it.</em></p><h4 id="communication">Communication</h4><p>I’m using <a href="http://mqtt.org/" target="_blank">MQTT protocol</a> for communication between the devices. <a href="https://appcodelabs.com/introduction-to-iot-build-an-mqtt-server-using-raspberry-pi" target="_blank">A MQTT broker(server) runs on the Raspberry Pi</a> along with the Gobot client which acts as the MQTT publisher.</p><p><a href="https://play.google.com/store/apps/details?id=in.dc297.mqttclpro" target="_blank">MQTT Client android app</a> is the MQTT subscriber. <a href="https://play.google.com/store/apps/details?id=net.dinglisch.android.taskerm" target="_blank">Tasker android app</a> creates a notification when MQTT client receives the message, displays the notification via <a href="https://play.google.com/store/apps/details?id=com.joaomgcd.autonotification" target="_blank">Auto Notification Tasker plugin</a>(paid) and <a href="https://play.google.com/store/apps/details?id=com.rageconsulting.android.lightflow" target="_blank">Light Flow android app</a>(paid) reads out the notification message and creates custom LED light.</p><p>The notification is further received at my desktop smart clock, which is an old android wear smartwatch modified to receive latest Google Play services updates.</p><p><amp-accordion id="communication-accordian" disable-session-states=""><section><h5>Click to see MQTT Client</h5><amp-img alt="MQTT Client" src="/images/MQTT_Client.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Tasker profile</h5><amp-img alt="Tasker Profile" src="/images/Tasker-profile.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Notification Configuration</h5><amp-img alt="Auto Notification Configuration" src="/images/AutoNotification.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Light Flow Configuration</h5><amp-img alt="Light Flow Configuration" src="/images/LightFlow_configuration.jpg" width="1080" height="1920" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="circuit">Circuit</h4><p><amp-accordion id="circuit-accordian" disable-session-states=""><section><h5>Click to see the circuit diagram</h5><amp-img alt="Butt pomodoro circuit diagram" src="/images/Circuit.png" width="614" height="587" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="setup">Setup</h4><p>Here is the overview of the complete architecture and the setup.</p><p><amp-accordion id="architecture-accordian" disable-session-states=""><section><h5>Click to see the architecture diagram</h5><amp-img alt="Butt pomodoro architecture" src="/images/Butt_pomodoro_architecture.png" width="686" height="660" layout="responsive"></amp-img></section><section><h5>Click to see the Butt pomodoro setup</h5><amp-img alt="Butt pomodoro setup" src="/images/Butt_pomodoro_setup.jpg" width="6000" height="4000" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="code">Code</h4><p>Source code for the Gobot client is available over the <a href="https://github.com/heavyinfo/buttpomodoro" target="_blank">GitHub</a>.</p><h4 id="demo">Demo</h4><h5 id="demo-video-enable-audio">Demo Video (enable audio)</h5><p><amp-accordion id="demo_video-accordian" disable-session-states=""><section><h5>Click to see video from Twitter (Fast loading, requires loading of twitter script)</h5><amp-twitter width="375" height="472" layout="responsive" data-tweetid="1281998220118249472"></amp-twitter></section></amp-accordion></p><p><a href="https://abishekmuthian.com/videos/Butt-Pomodoro-Demo.mp4" target="_blank">Click to see video from local .mp4 source, Slow loading, Requires HTML5 video support</a></p><p><a href="https://abishekmuthian.com/videos/Butt_Pomodoro.webm" target="_blank">Click to see video from local .webm source, Slow loading, Requires HTML5 video support</a></p><h3 id="enhancements">Enhancements</h3><p>Further enhancements which could improve the usability of the Butt Pomodoro -</p><pre><code>* Using a PIR (Passive Infrared) sensor as a trigger for contact less butt detection.

* Using a Bluetooth LE based microcontoller to communicate directly with the smartphone for cutting down the separate compute module.

* Custom app record the data on completed pomodoros, incomplete pomodoros, breaks and displaying it with cool visualisations. Of course, for notifications as well.
</code></pre><p>Tweet to me <a href="https://twitter.com/heavyinfo" target="_blank">@heavyinfo</a>.</p><h3 id="business-plan">Business Plan</h3><p>Do you think Butt Pomodoro is something people want?</p><p>Would you like to build Butt Pomodoro as a commercial product? I have <a href="https://hitstartup.com/business-plans/" target="_blank">business plan at hitstartup</a> to help you get started.</p></div></div>]]>
            </description>
            <link>https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817401</guid>
            <pubDate>Mon, 13 Jul 2020 05:17:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting audio code from C to rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817392">thread link</a>) | @est31
<br/>
July 12, 2020 | https://jneem.github.io/nnnoiseless/ | <a href="https://web.archive.org/web/*/https://jneem.github.io/nnnoiseless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    <time datetime="2020-07-12T00:00:00+00:00">July 12, 2020</time>
  </header>
<p>I ported a C library to rust last week, and it went pretty smoothly. This is
the story, and <a href="https://github.com/jneem/nnnoiseless">here</a> is the repo.</p>

<p>The library in question is <a href="https://github.com/xiph/rnnoise">RNNoise</a>, a
library for removing noise from audio. It works well, it runs fast, and best of
all it has no knobs that you need to tune. There’s even a <a href="https://github.com/RustAudio/rnnoise-c">rust
binding</a>.</p>

<p>So why bother porting it?
Well, I need to patch it so that it would compile with MSVC, but my PR went
unnoticed for a month. I thought about maintaining my own fork, but it’s been
more than 10 years since I last wrote anything in C or C++.
And that’s how I ended up porting RNNoise to rust. It probably wasn’t the most
efficient use of my time, but I had fun and learned something.</p>

<p>There’s a lot of information out there about porting C to rust, but the most
useful resource for me was the fantastic
<a href="https://github.com/carols10cents/rust-out-your-c-talk">talk</a> by Carol (Nichols
|| Goulding). It lays out a simple process for porting one function
at a time: first, you set up the cargo to compile as a static library and you
set up the C build system to link that static library into the C library
(see the slides for the relevant Makefile and Cargo.toml snippets).
Then you can port one function at time: the C code goes like this:</p>

<div><div><pre><code><span>+</span><span>extern</span> <span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>);</span>
<span>+</span><span>void</span> <span>__celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>-</span><span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>{</span>
    <span>/* C body of _celt_lpc */</span>
<span>}</span>
</code></pre></div></div>

<p>and the rust code goes like this:</p>

<div><div><pre><code><span>+</span><span>#[no_mangle]</span>
<span>+</span><span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>_</span><span>celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span> <span>ac</span><span>:</span> <span>*</span><span>const</span> <span>f32</span><span>,</span> <span>p</span><span>:</span> <span>c_int</span><span>)</span> <span>{</span>
<span>+</span>    <span>unsafe</span> <span>{</span>
<span>+</span>        <span>let</span> <span>lpc_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts_mut</span><span>(</span><span>lpc</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span><span>);</span>
<span>+</span>        <span>let</span> <span>ac_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>ac</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span> <span>+</span> <span>1</span><span>);</span>
<span>+</span>        <span>rs_celt_lpc</span><span>(</span><span>lpc_slice</span><span>,</span> <span>ac_slice</span><span>);</span>
<span>+</span>    <span>}</span>
<span>+</span><span>}</span>
<span>+</span>
<span>+</span><span>fn</span> <span>rs_celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>],</span> <span>ac</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>])</span> <span>{</span>
<span>+</span><span>// rust body of celt_lpc</span>
<span>+</span><span>}</span>
</code></pre></div></div>

<p>If you’ve watched the talk (which you should), you might notice that this is a
tiny bit different from what they recommend: I’ve renamed the original C
function instead of deleting it. I found that this helped me narrow down porting
mistakes, because it made it easy to switch back and forth between the C and
rust implementations.</p>



<p>Most of the porting process was mechanical and easy. One of the less fun parts was
porting code involving C structs. RNNoise has structs that (when ported to
rust) look like this:</p>

<div><div><pre><code><span>#[repr(C)]</span>
<span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>*</span><span>const</span> <span>RnnModel</span><span>,</span>
    <span>// Various buffers, whose sizes are determined by some subfields of `model`.</span>
    <span>vad_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>An idomatic rust version might look something like</p>
<div><div><pre><code><span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>&amp;</span><span>'static</span> <span>RnnModel</span><span>,</span>
    <span>vad_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>
<p>but this isn’t layout-compatible with the original C version, and so I need to
stick with the original struct for as long as <code>RnnState</code> is being accessed by
both C and rust code. This increases the amount of <code>unsafe</code> sprinkled around
the rust code, and it was also the source of an annoying bug of the sort that I
thought I had left behind by moving to rust.</p>



<p>At some point during the porting process, my tests started failing in release mode,
but not in debug mode. Most likely some undefined behavior triggered by my amateurish
attempts at unsafe code, but I couldn’t quickly spot the problem and the prospect of
a more careful round of debugging didn’t spark a whole lot of joy. So I did something
that I never would have dared to do in my C/C++ days: I ignored the problem and kept
porting; after all, the tests were still working in debug mode. And sure enough,
a few more ported functions later and <code>rustc</code> found the problem for me: in a function
taking a <code>&amp;RnnState</code> parameter, I was modifying data in the <code>vad_gru_state</code> buffer.
Since I was using unsafe code, <code>rustc</code> didn’t complain at first. But once I ported
the <code>RnnState</code> struct to safe and idiomatic rust, the compiler flagged the problem
immediately.</p>



<p>After getting everything to 100% safe (if not particulary idiomatic) rust, it was time
to check whether performance had suffered.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark.svg" alt="initial benchmark"></p>

<p>Yes, apparently, by about 50%. The most obvious culprit was bounds checking: there was
a lot of indexing in the C code, and some of it wasn’t trivial to convert to a more
rust-friendly, iterator-based version. First priority was the neural network evaluation:</p>

<div><div><pre><code><span>let</span> <span>m</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 114.</span>
<span>let</span> <span>n</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 96.</span>

<span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span><span>;</span>
    <span>for</span> <span>j</span> <span>in</span> <span>0</span><span>..</span><span>m</span> <span>{</span>
        <span>output</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>layer</span><span>.input_weights</span><span>[</span><span>j</span> <span>*</span> <span>n</span> <span>+</span> <span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>*</span> <span>input</span><span>[</span><span>j</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>I can already see you shaking your head. I’m doing naive matrix-vector multiplication
with a 100x100ish matrix in
<a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">column-major format</a>?
Not only is this costing me bounds checks, it’s terrible for memory locality.
Swapping the weights storage from column- to row-major order only made things
about 1.5% faster, but more importantly it made the whole thing iterator-friendly.
Converting to zips and sums bought another 15%, leaving me only about 25-30% slower
than the C code.</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span>
        <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>+</span> 
        <span>layer</span><span>.input_weights</span><span>[(</span><span>i</span> <span>*</span> <span>m</span><span>)</span><span>..</span><span>((</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>*</span> <span>m</span><span>)]</span>
            <span>.iter</span><span>()</span>
            <span>.zip</span><span>(</span><span>input</span><span>)</span>
            <span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span>
            <span>.sum</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>For my next optimization opportunity, I moved on to the function
that
computes <a href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlations</a>.
The un-optimized version of this function looks like</p>

<div><div><pre><code><span>fn</span> <span>pitch_xcorr</span><span>(</span><span>xs</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>ys</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>xcorr</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>])</span> <span>{</span>
    <span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>()</span> <span>{</span>
        <span>xcorr</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>&amp;</span><span>ys</span><span>[</span><span>i</span><span>..</span><span>])</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>();</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>but the C code contained a massive, manually-unrolled version. I’d skipped
it while porting, but maybe I’d gain something from porting it over. Here’s
an abbreviated version of the optimized function, assuming that all
lengths are a multiple of 4 (the real code also handles the case that they aren’t).</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>(</span><span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>())</span><span>.step_by</span><span>(</span><span>4</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>c0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>let</span> <span>mut</span> <span>y0</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>0</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y1</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y2</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>2</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y3</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>3</span><span>];</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>[(</span><span>i</span> <span>+</span> <span>4</span><span>)</span><span>..</span><span>]</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>

        <span>y0</span> <span>=</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>

        <span>y1</span> <span>=</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>

        <span>y2</span> <span>=</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>

        <span>y3</span> <span>=</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Basically, both inner and outer loops have been unrolled four times, and I’ve
exploited the inner loop’s unrolling to optimize the memory access pattern.
Thanks to the amazing <a href="https://github.com/gnzlbg/cargo-asm"><code>cargo asm</code></a>, I
can happily report that there’s no bounds-checking in the inner loop and that
all the arithmetic has been <a href="https://en.wikipedia.org/wiki/Automatic_vectorization">auto-vectorized</a>
to work four <code>f32</code>s at a time. (Maybe it would get even faster if I unrolled 8 times and
compiled with AVX enabled; I haven’t tried that yet.)</p>

<p>This change more than doubled the speed of <code>pitch_xcorr</code>, and gained me about 10% overall.
More importantly, it showed me how to coerce the compiler into auto-vectorizing something
that it hadn’t auto-vectorized before. I went back to the neural network code and
replaced things like</p>

<div><div><pre><code><span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>ys</span><span>)</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>()</span>
</code></pre></div></div>

<p>with things like</p>

<div><div><pre><code><span>{</span>
    <span>let</span> <span>mut</span> <span>sum0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>sum0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>sum1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>sum2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>sum3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
    <span>sum0</span> <span>+</span> <span>sum1</span> <span>+</span> <span>sum2</span> <span>+</span> <span>sum3</span>
<span>}</span>
</code></pre></div></div>

<p>for another 20% improvement.</p>

<p>Current score: the rust version (still 100% safe) is about 15% faster, and there’s probably plenty more
still on the table.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark_after.svg" alt="final benchmark"></p>

<p>The performance lesson I learned from this is that bounds checking can be expensive in numerical code
and iterator-style code can help a bit, but if you really want faster numerical code then you need
to write in a style that the auto-vectorizer likes. (Or you could use the <a href="https://doc.rust-lang.org/core/arch/index.html">SIMD intrinsics</a>
directly, but that’s another story.)</p>



<p>Like I wrote above, it’s been a while since I did any C/C++, and because of that I’ve started to take tools
like cargo for granted. This little porting project brought back some memories, mostly because about half of the
code in RNNoise was actually “vendored” from <a href="https://gitlab.xiph.org/xiph/opus">opus</a>. I put “vendored”
in quotes because I usually think of vendoring as involving a subdirectory (maybe even a git submodule if
I’m lucky) with its own build artifacts. That’s not what’s going on here, though; I’m just talking about files
that were copied from the source directory of one project to the source directory of another, complete with
never-used functions and never-def’ed ifdefs. The thing is, though, that I understand exactly why they did it:
it’s by far the easiest way to share code between C projects. So I just want to finish by saying a big “thank you”
to <code>cargo</code> and <code>crates.io</code> for making me not have to deal with C dependency management any more.</p>


  
  
</article></div>]]>
            </description>
            <link>https://jneem.github.io/nnnoiseless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817392</guid>
            <pubDate>Mon, 13 Jul 2020 05:14:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Artificial Neural Networks Closer to Animal Brains]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23817347">thread link</a>) | @hardmaru
<br/>
July 12, 2020 | https://maraoz.com/2020/07/12/brains-vs-anns/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/12/brains-vs-anns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p><img src="https://maraoz.com/img/brains-vs-anns/cover.jpg"></p>

<p>Lately, I’ve been thinking and reading a lot about consciousness and how the human mind works. A question that emerges all the time is whether machines can <a href="https://en.wikipedia.org/wiki/Turing_test">emulate human thought</a>. An even more interesting one is whether consciousness (a subjective experience) can arise from a machine, but I’ll leave that discussion for a future post (I’ll need ~20 more years to think about that before I can write about it).</p>

<p>So, how far are we from _behaviorally _imitating a human? Truth is, we achieved a lot in the past 5 years (see <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a>, <a href="https://openai.com/blog/better-language-models/">OpenGPT-2</a>, <a href="https://openai.com/blog/jukebox/">OpenAI Jukebox</a>, <a href="https://en.wikipedia.org/wiki/Tesla_Autopilot">Tesla Autopilot</a>, <a href="https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning">Alphastar</a>, <a href="https://openai.com/blog/openai-five-defeats-dota-2-world-champions/">OpenAI Dota2 Team</a>, <a href="https://openai.com/blog/openai-api/">OpenAI API</a>), but we’re still quite not there. My hunch is that we still can learn a lot from biology’s state of the art. I’ve done some research on differences in how human brains work and how we emulate them using deep neural networks, and what follows is a summary of what I’ve found (and some new ideas).</p>

<figure>
  <img src="https://maraoz.com/img/brains-vs-anns/image1.png">
  <figcaption>
    I find it encouraging that John Carmack is studying human brains for his AI research. <a href="https://twitter.com/ID_AA_Carmack/status/1280693213549002752">Source</a>.
  </figcaption>
</figure>

<h2 id="morphology">Morphology</h2>

<p>The most surprising difference between artificial and human brains is how <em>sequential</em> our artificial neural networks (ANN) are, compared to the richly interconnected biological counterparts.</p>

<p>I’m always amazed by the sheer amount of layers that are stacked on top of each other <a href="https://jalammar.github.io/illustrated-gpt2/">in the latest deep learning models</a>. The largest GPT-3 model (with 175B parameters) uses 96 attention layers, each with 96x 128-dimension heads. <a href="https://arxiv.org/pdf/2005.14165.pdf">Their paper</a> shows that language model performance scales as a power-law with model size.</p>

<p>However, this assumes the size of the network can only increase by adding more layers, making it “deeper”. Using layers enables for great performance in training via <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">backpropagation/ADAM</a>, but I think the current mostly-sequential approach to scaling ANNs is limiting. Some ideas:</p>

<h3 id="wide-vs-deep-neural-networks">Wide (vs. Deep) Neural Networks</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image8.png">
<img src="https://maraoz.com/img/brains-vs-anns/image3.png"></p>

<p>A promising approach is exploring other kinds of architectures, where the concept of “layer” is forgotten, and networks are built more freely (with connections being modelled at the neuron level, and allowing for loops and more complex topologies). This <a href="https://en.wikipedia.org/wiki/Boltzmann_machine">has been somewhat explored in the past</a>, but I haven’t seen recent studies where today’s computing power is thrown at such architectures. Additionally, <a href="https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies">Ken Stanley’s NEAT (2002)</a> and derivatives are a very promising way of finding new topologies via evolution.</p>

<h3 id="neural-grids">Neural Grids</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image6.png"></p>

<p>Another idea worth exploring: grid-like structures where each cell communicates only with its neighbors. In this neural net model, potential is not only passed forward, but also “upward” and “downward”, or even diagonally. This would emulate more closely, I think, a real brain’s connectivity. A related approach is <a href="https://www.mitpressjournals.org/doi/abs/10.1162/artl.2009.15.2.15202">Hypercube-based NEAT (2009)</a>, which allows exploiting the task’s geometry by mapping its regularities onto the topology of the network.</p>

<h3 id="artificial-cortical-columns">Artificial Cortical Columns</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image9.png">
<img src="https://maraoz.com/img/brains-vs-anns/image5.png"></p>

<p>Human’s brain neocortex seems to have a surprisingly self-repeating pattern, called <a href="https://youtu.be/x2mYTaJPVnc?t=98">cortical columns</a>. Each column can be thought of as a reusable ~110 neuron module that appears (with variations) across neocortex areas associated with such different functions as vision, motor control, auditory perception, decision-making, planning, etc. <a href="https://numenta.com/neuroscience-research/cortical-columns/">Studying these structures</a> and applying similar concepts/topologies to ANNs seems like a promising approach. Cortical columns provide amazingly generic hierarchical information processing capabilities, feedback mechanisms, and layered communication with other parts of the brain.</p>

<h3 id="generative-architectures-arising-from-growth">Generative architectures arising from growth</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image10.png"></p>

<p>What if neural net architecture is determined by a generative / procedural algorithm on runtime, instead of being defined by researchers? The seed could be random or evolved through genetic algorithms too. I think that somehow mimicking <a href="https://www.youtube.com/watch?v=BtLyik7oAxc&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=4">neurulation of human embryos</a> via simple models could lead to finding better-performing architectures. Human brains grow into existence, and maybe that matters for high-level intelligence.</p>

<h2 id="function">Function</h2>

<h3 id="evolve-first-learn-later">Evolve first, Learn later.</h3>

<p>Some techniques use <a href="https://www.nature.com/articles/s42256-018-0006-z">neuroevolution used to automate network design</a> or <a href="https://blog.otoro.net/2017/11/12/evolving-stable-strategies/">evolutionary strategies finding network weights instead of gradient descent</a>. It’d be interesting to see hybrid approaches where network structure is evolved and <em>later</em> allowed to learn in an environment (like humans!). Additionally, as I learnt from <a href="https://www.nature.com/articles/s41467-019-11786-6">this fascinating paper by Tony Zador</a> (2019), “A large component of an animal’s behavioral repertoire is not the result of supervised or unsupervised learning, but rather of behavior programs already present at birth”. Learning is actually one of such behaviors, so… shouldn’t researchers be focusing more on optimizing the lower-level mechanism of evolution instead of polishing our “hand-crafted” learning algorithms and architectures?</p>

<p>On a similar ‘meta-learning’ vein, the comically named <a href="http://papers.nips.cc/paper/6461-learning-to-learn-by-gradient-descent-by-gradient-descent.pdf">Learning to learn by gradient descent by gradient descent</a> (2016) paper shows that you can train a network to optimize other networks, and they perform better than hand-crafted learning algorithms like <a href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c">ADAM</a> and <a href="https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a">RMSProp</a>.</p>

<h3 id="continuous-vs-discrete-neuron-firing">Continuous (vs. discrete) neuron firing</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image4.png"></p>

<p>Instead of processing inputs in discrete events, our networks could ‘stare’ at inputs for a couple iterations, and neurons can ‘store-up’ potential until they fire. This aims to mimic how we humans can look at something we don’t understand, but after a couple of seconds we “get it”. This could also enable the emergence of “memories” in the form of stored potential, too, analogous to the hidden state vector of LSTMs. Check out <a href="https://www.youtube.com/watch?v=lddzHEtu934">Gabriel Kreiman’s related work (2018)</a> on improving object detection in occluded or distorted conditions. Regardless of the specific implementations mentioned above, biological brains clearly have a temporal dimension (for example, <a href="https://www.youtube.com/watch?v=aFrG7KdjUOs&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=32">neurons in the visual motion MT area respond to direction of motion</a>), which we need to understand better to inform construction of artificial ones. Another interesting time-related property of biological brains is <a href="https://youtu.be/fki7AmLma_I?t=450">the difference between tonic vs bursting modes of neuron firing</a>.</p>

<h3 id="connecting-functional-building-blocks">Connecting functional building blocks</h3>

<p>Animal brains are surprisingly pre-wired and connected since birth, and it’s still not clear in general which behaviors are learned through experience and which are innate. Moreover, a big field of study in neuroscience is understanding how the human brain is wired, mostly via <a href="https://en.wikipedia.org/wiki/Tractography">diffusion tractography</a>, and in some cases <a href="https://youtu.be/KFfaBoDANNI?t=134">it’s been shown that connectivity can predict function</a>. However, the fascinating <a href="https://www.youtube.com/watch?v=8Bvblav-BQk&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=65">‘rewired ferrets’ experiments</a> showed that training input also conditions function strongly (newborn ferrets with auditory cortex rewired to receive visual input still learn to see). This implies that animal brains have a very optimized initial configuration, but also the flexibility to adapt to structural damages or drastical environmental condition changes.</p>

<p>Many well-performing techniques simply stack two architectures that work for two separate domains (eg: CNN visual embedder and LSTM language model) and re-train them for a new combined task (eg: image captioning).</p>

<p><img src="https://maraoz.com/img/brains-vs-anns/image7.png">
<img src="https://maraoz.com/img/brains-vs-anns/image2.png"></p>

<p>I suggest trying to mimic what we know today of how the human brain is wired (from <a href="http://www.humanconnectomeproject.org/">the Human Connectome Project</a>, for example), and plugging in some state-of-the-art modules for vision, language, and audio-processing.</p>

<h3 id="slow-and-data-light-learning">Slow and Data-Light Learning</h3>

<p>Humans seem to learn slowly (in real time, it takes a human ~2 years to learn a language at a basic level, and ~18 years to learn advanced level language usage or complex language tasks like translation) but with few examples. Machines, on the other hand, learn very fast (in the order of weeks to achieve state of the art in some tasks) but are very data-hungry. Some techniques require less training data but might take longer to train, like <a href="https://medium.com/@SmartLabAI/a-brief-overview-of-imitation-learning-8a8a75c44a9c">Imitation Learning</a>, <a href="https://openai.com/blog/competitive-self-play/">Competitive Self-Play</a>, and <a href="https://arxiv.org/abs/2005.11212">Symbolic Pregressions (2020)</a> and could be key to getting closer to human intelligence.</p>

<h3 id="intermixing-learning-techniques">Intermixing Learning Techniques</h3>

<p>A combination of learning strategies could be necessary for human-level intelligence, as Yann LeCun suggests with his cake analogy: “If intelligence is a cake, the bulk of the cake is <a href="https://ai.stackexchange.com/a/10624">self-supervised learning</a>, the icing on the cake is <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, and the cherry on the cake is <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>.”</p>

<p>Humans train by learning from others (supervised learning) <em>and</em> experimenting on our own (unsupervised/self-supervised learning). For example, a chess student first talks to a teacher, then plays some games. They wouldn’t go to a chess tournament after just talking to a teacher or playing games alone. Can we combine/emulate these kinds of training efficiently in ML too?</p>

<h2 id="final-words--further-studying">Final words &amp; further studying</h2>

<p>What do you think of these approaches? Have you actually seen any of these used in the wild (with success or otherwise)? Which do you think may have merits? Let me know if you do some experiments to try them out.</p>

<p>If you’ve been intrigued by the potential of imitating biological brains, here are some up-to-date resources to dig deeper, in order of relevance:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=i1pdQjdAndc&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0">Nancy Kanwisher’s The Human Brain course on YouTube</a> (2018)</li>
  <li><a href="https://www.youtube.com/watch?v=8-KF0rnhKTU&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=2">Ninja Nerd Lectures on Embryology</a> (2019)</li>
  <li><a href="https://www.nature.com/articles/s41467-019-11786-6">A critique of pure learning and what artificial neural networks can learn from animal brains by Anthony M. Zador</a> (2019)</li>
  <li><a href="https://www.youtube.com/watch?v=pkJkHB_c3nA">AI for physics &amp; physics for AI by Max Tegmark</a> (2020)</li>
  <li><a href="https://www.youtube.com/watch?v=x2mYTaJPVnc">Brains Explained video on cortical columns</a> (2017)</li>
  <li><a href="https://www.youtube.com/watch?v=h0InlY2WKc0">Deciphering Brain Codes to Build Smarter AI by Gabriel Kreiman</a> (2020)</li>
</ul>

<p><em>Thanks to Javi Silveira, <a href="https://twitter.com/hardmaru">David Ha (@hardmaru)</a>, <a href="https://twitter.com/alcuadrado">Pato Palladino (@alcuadrado)</a> and <a href="https://twitter.com/itsladywhite">Lady White (@itsladywhite)</a> for providing feedback and pointers.</em></p>

<p><em>Image by <a href="https://unsplash.com/@davidclode?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">David Clode on Unsplash</a>.</em></p>


  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/12/brains-vs-anns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817347</guid>
            <pubDate>Mon, 13 Jul 2020 05:05:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Silicon Valley Translated in the Wizard of Oz]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817205">thread link</a>) | @billybjork
<br/>
July 12, 2020 | https://www.home.vujade.world/dream | <a href="https://web.archive.org/web/*/https://www.home.vujade.world/dream">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="SITE_ROOT" aria-hidden="false"><div id="masterPage" data-mesh-layout="grid"><main tabindex="-1" data-is-mobile="false" data-is-mesh="true" data-site-width="980" data-state="" id="PAGES_CONTAINER"><div id="PAGES_CONTAINERcenteredContent"><div id="PAGES_CONTAINERinlineContent"><div><div data-ismobile="false" data-is-mesh-layout="true" id="fhyds"><div id="fhydsinlineContent"><div id="fhydsinlineContent-gridWrapper" data-mesh-internal="true"><div id="fhydsinlineContent-gridContainer" data-mesh-internal="true"><p data-packed="false" data-vertical-text="false" data-min-height="64" data-hidden="true" id="comp-kcku3nqo"><h3><span><span><span><span>&nbsp;DATA RULES EVERYTHING AROUND ME&nbsp;</span></span></span></span></h3></p><div data-packed="true" data-vertical-text="false" data-hidden="true" id="comp-kbfvr8s7"><p><span><span>We’re not in Kansas anymore.</span></span></p>



<p><span><span>Swept along by the cyclone of innovation, we’ve stumbled into the "information superhighway." At first it appeared we’d found a beautiful land, somewhere over the rainbow. But it's becoming clear our Emerald City isn’t all it was cracked up to be. In this remix film based on The Wizard of Oz, we journey alongside Dorothy down the Yellow Brick Algorithm, decoding the myths surrounding digital culture. DREAM speaks about the media, through the media – finding clarity in a digital space that’s never been so noisy.</span></span></p></div><div data-packed="false" data-vertical-text="false" data-min-height="61" data-hidden="true" id="comp-k9lpk92t"><h5><span><span>FEATURING</span></span></h5>

<p><span><span>The Wizard of Oz</span></span></p>

<p><span><span>Duckwrth&nbsp; &nbsp;The Talking Heads&nbsp; &nbsp;Lou Reed</span></span></p>

<p><span><span>Rod Serling&nbsp; &nbsp;Marshall McLuhan&nbsp; &nbsp;Neil Postman&nbsp; &nbsp;John Perry Barlow</span></span></p>

<p><span><span>Jaron Lanier&nbsp; &nbsp;Douglas Rushkoff&nbsp; &nbsp;Astra Taylor&nbsp; &nbsp;Yosemitebear62&nbsp; &nbsp;Beeple</span></span></p>

<p><span><span>Gary Vee&nbsp; &nbsp;Donald Trump&nbsp; &nbsp;Mark Zuckerberg&nbsp; &nbsp;Bill Gates&nbsp; &nbsp;Alex Jones</span></span></p>

<p><span>PewDiePie&nbsp; &nbsp;Casey Neistat&nbsp; &nbsp;Pepe the Frog&nbsp; &nbsp;Oliver Tree&nbsp; &nbsp;Joe Hollier</span></p>

<p><span><span>And many more</span></span></p></div><p data-packed="false" data-vertical-text="false" data-min-height="61" data-hidden="true" id="comp-ka8xwtkq"><h5><span><span>PROCESS REEL</span></span></h5></p><p data-packed="false" data-vertical-text="false" data-min-height="61" data-hidden="true" id="comp-ka8xy3f6"><h5><span><span>TRAILER</span></span></h5></p><p data-packed="false" data-vertical-text="false" data-min-height="61" data-hidden="true" id="comp-ka8xzfwq"><h5><span><span>SOURCES</span></span></h5></p></div></div></div></div></div></div></div></main></div></div></div>]]>
            </description>
            <link>https://www.home.vujade.world/dream</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817205</guid>
            <pubDate>Mon, 13 Jul 2020 04:34:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$15 HDMI Capture Card Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817119">thread link</a>) | @rubatuga
<br/>
July 12, 2020 | https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><br>
<video src="https://www.naut.ca/videos/smash60fps.mp4" poster="https://www.naut.ca/videos/smash60fps.jpg" preload="none" controls="" playsinline=""></video>

<p>Above is a sample of 60fps Super Smash Bros Ultimate gameplay (I'm a Jigglypuff main) recorded with the $15 HDMI Capture Card and OBS. This card has been making the rounds last month on <a href="https://twitter.com/Ascii211/status/1268631069051453448">Twitter</a>, as well as on <a href="https://www.youtube.com/watch?v=daS5RHVAl2U">YouTube</a>, mainly due to its low, low price of $15 USD. I've decided to get one myself and take a look. The chipset contained in the card is the MacroSilicon MS2109. Here is the review, as well as a discussion of the potential use-cases.</p>
<h3 id="operatingsystem">Operating System</h3>
<p>This card, surprisingly enough, works on Windows, macOS and Linux! This is because it implements the UVC standard, a USB device that is OS agnostic. Getting it working on Linux is a bit of a hassle, but you can find out how <a href="https://bigl.es/friday-fun-10-hdmi-to-usb-capture/">here</a>.</p>
<p>I noticed that using the capture card on Linux or macOS resulted in significantly more framedrops and synchronization issues, when compared to Windows (although the macOS issues might be due to weak CPU). If you are okay with slightly choppy or stuttery recordings, then feel free to use the card on macOS or Linux. The Windows UVC driver captures more frames, and has the most options of the three. Most of the guide will be focusing on the Windows driver. The controls that are listed in OBS for each operating system are shown below.<br>
<img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-7.13.22-PM.jpg" alt="Screen-Shot-2020-07-09-at-7.13.22-PM"></p>
<h3 id="yuy2vsmjpeg">YUY2 vs MJPEG</h3>
<p>Windows and Linux both support the YUY2 and MJPEG video format, while macOS only supports MJPEG. YUY2 in this context refers to an almost uncompressed form of data (except for colour information), while MJPEG uses lossy JPEG compression on every frame. This means that YUY2 provides a cleaner image with no compression artifacts, while MJPEG has a noisier and blockier image. Compare the two capture formats below:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.33.23-AM.png" alt="Screen-Shot-2020-07-09-at-12.33.23-AM"></p>
<p>As you can see MJPEG has degraded the image data, which is necessary to compress each frame to a small size. Only MJPEG can achieve high framerates with this card because the interface it uses, USB 2.0, caps out around 50 MB/s. For reference, a YUY2 1280x720 60fps signal would exceed 100 MB/s. If you want a card that supports a 60fps YUY2 signal, you can expect to pay in the range of hundreds of dollars.</p>
<p>Both the YUY2 and MJPEG video formats from this card use something called <a href="https://en.wikipedia.org/wiki/Chroma_subsampling">chroma subsampling</a>, a data saving trick that takes advantage of the human eye's decreased colour resolution. It essentially deletes colour data, while keeping brightness data intact. I tested both formats, and they are outputting a 4:2:2 signal (50% of the colour data is deleted). You can see that the horizontal axis changes colour at 2 pixel boundaries, while the vertical axis changes at 1 pixel boundaries.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.32.56-AM.png" alt="Screen-Shot-2020-07-09-at-12.32.56-AM"></p>
<h3 id="resolutionandframerate">Resolution and Framerate</h3>
<p>A wide variety of resolutions and framerates are supported on the input side of the device. It even supports input at 4K 60fps! From the NVIDIA Control Panel, here is an abridged list of the resolutions and framerates supported on the <strong>input side</strong>:</p>
<pre><code>4K    60,59,50,30,29,25,24,23Hz
1080p 60,59,50Hz
720p  60,59,50Hz
576p  50Hz
480p  60,59Hz
PC    60Hz
</code></pre>
<p>To clarify, just because this card can accept or capture a 4K signal, does not mean that it can send the full signal to your computer. This card contains a scaler, which scales the image down (or up, depending on the input) in resolution before it is sent. With reference to the OBS properties window, here is an abridged list of the resolutions and max framerates as seen by my Windows PC:</p>
<pre><code>1920x1080 MJPEG:30fps, YUY2:5fps
1600x1200 MJPEG:30fps, YUY2:5fps
1360x768  MJPEG:30fps, YUY2:?
1280x960  MJPEG:50fps, YUY2:?
1280x720  MJPEG:60fps, YUY2:10fps
1024x768  MJPEG:60fps, YUY2:10fps
800x600   MJPEG:60fps, YUY2:20fps
720x480   MJPEG:60fps, YUY2:30fps
</code></pre>
<p>Each resolution dictates a maximum framerate for the device, limited by the bandwidth of the USB interface. To summarize, this card supports an output of 1920x1080 30fps and 1280x720 60fps with the MJPEG format.</p>
<h3 id="resolutionandframeratecaveats">Resolution and Framerate Caveats</h3>
<p>First I'll talk about framerate. I noticed that recording or streaming from the card at 60fps tends to repeat or skip a frame every few seconds, even with buffering on. Make sure to keep buffering on, otherwise you will lose frames at 30fps as well. I have confirmed this by recording videos in OBS and analyzing them frame by frame.</p>
<p>If you want virtually perfect frame capture at both 720p and 1080p, you should use 30fps with buffering!</p>
<p>Also, you may notice that there are 29.97fps and 59.94fps options in OBS. Only use these if you are absolutely sure that your device needs these values. You will likely run into desynchronization issues if you accidentally use these framerates.</p>
<p>Next, when I tested the 1920x1080 capture, I was shocked by how blurry it was. It turns out that this card doesn't actually do true 1080p! Here's a screenshot of Wikipedia, compared to what was captured at 1920x1080.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-2.48.49-AM.png" alt="Screen-Shot-2020-07-09-at-2.48.49-AM"></p>
<p>It looks like the card is capturing the vertical resolution fine, but the horizontal resolution is a soft mess. I tried out 1280x720, and everything looked crisp and fine, leading me to suspect that the card was capturing internally at a resolution of 1280 columns. I ended up using display calibration images from <a href="http://www.lagom.nl/lcd-test/sharpness.php">Lagom LCD</a> to see how the pixels in the capture were behaving. Right click the following image and choose Open/View Image for a better view.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-3.05.56-AM.png" alt="Screen-Shot-2020-07-09-at-3.05.56-AM"></p>
<p>Using the reference on the left, we can see that 1280x720 has correct vertical and horizontal resolution. 1360x768 and 1920x1080 also have correct vertical resolution, but the columns are turning grey. This is because adjacent white and black pixels from the high input resolution are merged into a lower resolution, i.e. from 1920 columns into 1280 columns. If you also noticed that pixel columns are brighter than the rows, I will be talking about that in the next section.</p>
<p>As a quick aside, everything above was for progressive video input. Interestingly, this card also supports an input of 1080i/interlaced video, which I tested with macOS and my Canon 600D camera. Using 1080i was absolutely horrible for desktop recording, since the card uses a brainless deinterlacing algorithm that halves the vertical resolution to 540. Yes, it actually looks that bad. As for my camera, it was decent, but the edges were kind of funny.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.01.51-AM.png" alt="Screen-Shot-2020-07-09-at-5.01.51-AM"></p>
<h3 id="imageaccuracycaveats">Image Accuracy Caveats</h3>
<p>This card needs "Color Range" set to "Full" in the OBS Capture Card Properties. Any devices that are connected to the card input need to have their HDMI "Range" set to "Limited". This is the only correct combination, otherwise highlights and shadows in the video are clipped. The following shows the effects of the device range options.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.53.19-PM.png" alt="Screen-Shot-2020-07-09-at-5.53.19-PM"></p>
<p>As you might have noticed from the previous section, the 1280x720 capture is brightening the columns. This indicates that the card is performing image sharpening only in the horizontal direction. You can find evidence of this type of sharpening wherever there are sharp edges:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.21.58-AM.png" alt="Screen-Shot-2020-07-09-at-5.21.58-AM"></p>
<p>This is a bad feature, as all image sharpening should be done after the capture. Fortunately, there is a way to get around this for 1280x720 content. Simply set your device to 1280x720, and then capture at 1920x1080. The image loses some clarity in brightness changes, due to the unnecessary resize, but all the sharpening has disappeared! Furthermore, since we are receiving 1920x1080 data, we now have better colour resolution as well, close to 4:3:3 chroma subsampling.</p>
<p>The 1920x1080 MJPEG capture also has significantly less compression artifacts than the 1280x720 MJPEG capture, which is probably due to different framerate support. From the image below, you can see that the 1080p capture is the winner all around (sharpening was applied post-capture for comparison with 720p).</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.25.44-PM.png" alt="Screen-Shot-2020-07-09-at-5.25.44-PM"></p>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>
<p>If you are capturing slower gameplay, i.e. only 30fps, set your device to 1920x1080 and then capture at 1920x1080. This provides the most brightness and colour resolution at 30fps.</p>
</li>
<li>
<p>If you have 1280x720 content, capture at 1920x1080. This will result in the least amount of sharpening and MJPEG artifacts.</p>
</li>
<li>
<p>If you are capturing a desktop screen or anything with thin lines and pixels, then set your device to 1280x720 and then capture at 1280x720.</p>
</li>
<li>
<p>If you need 60fps content, i.e. for gaming, then set your device to 1920x1080 and then capture at 1280x720. This disables sharpening. The sample at the beginning of the article was encoded with "x264" at the "veryfast" setting.</p>
</li>
</ul>
<p>Warning: if you see a listing for a $20 USD capture card that claims to support USB 3.0 and 1080p 60fps, it's a scam. I've already bought two of them from Amazon and eBay, and had to return both because they turned out to be a repackaging of the product I just reviewed!</p>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817119</guid>
            <pubDate>Mon, 13 Jul 2020 04:18:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 in schoolchildren – A comparison between Finland and Sweden [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 95 (<a href="https://news.ycombinator.com/item?id=23816709">thread link</a>) | @mrfusion
<br/>
July 12, 2020 | https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf | <a href="https://web.archive.org/web/*/https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816709</guid>
            <pubDate>Mon, 13 Jul 2020 02:50:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Features are a better abstraction than issues]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816682">thread link</a>) | @gauthamshankar
<br/>
July 12, 2020 | https://zepel.io/blog/how-issue-tracking-hurts-development/ | <a href="https://web.archive.org/web/*/https://zepel.io/blog/how-issue-tracking-hurts-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>The short answer is yes. Let me explain.</p><p>I’ve been working with developers and designers my entire life. </p><p>I’ve built a couple of products, worked at a young startup, and I’m now at Zepel helping development teams build better software.</p><p>I’ve spoken to 1000+ development teams while at Zepel alone. <strong>And it's evident that the way we build products is broken.</strong></p><p>There’s so much disconnect between how you and I talk about building products and how our teams actually build them.</p><p>For all the talk of scrum and agile and getting feedback quickly, there’s so much that’s broken in how we act on the feedback and build the feature.</p><p>Teams spend so much time and effort getting a deeper understanding of customers’ needs. And yet distil everything down to a simple two-line ticket and a couple of lines of markdown description.</p><p>This is hurting your developers. And it’s hurting your business.</p><blockquote>Nothing is more frustrating than having to understand what an entire feature should or shouldn’t do from a two-line ticket filled with ten bullet points of acceptance criteria.</blockquote><p><em>*Here are five prioritized tickets for the upcoming sprint. We have to ship them on time!*</em></p><p>On the other hand, you have teams who are able to build top quality software. They’re the ones who can concentrate on the fine implementation details without losing focus on the broader purpose of the feature as a whole.</p><p>Everyone wants to get to that level. But instead, teams do the exact opposite.</p><p><strong>Teams think in issues and tickets, instead of the feature as a system.</strong></p><hr><h2 id="development-teams-are-not-ticket-movers-">Development teams are not ticket movers!</h2><p>Today, everything is about moving a ticket from “Todo” to “Done” as quick as possible. And watching <a href="https://zepel.io/agile/reports/burndown/">burndown charts</a>. And customizing the tool to the extent that the developer only views a single ticket.</p><p><em>*“What’s the velocity of our team?” is simply another way of asking how quickly can my team move an issue from “Todo” to “Done”.*</em></p><p>Pieces of that stuff are important for productivity and shipping on time.</p><p>But seriously, how is your team supposed to ship anything of value if you narrow their focus down to the smallest unit of work without any context of why it’s needed or how it connects to the whole feature?!</p><p>Overall, we’ve lost our way. Product development today has become more about checking items off a list as quickly as possible. </p><p><strong>It isn’t enough to write multiple user stories and share a Figma link if you want to ship quality software.</strong></p><hr><h2 id="how-software-product-teams-really-build-software-together">How software product teams really build software together</h2><p>Development teams build better software together when they have the complete context of what and why something is being built.</p><p>To achieve this, the foundational elements need to change.</p><p>And it starts with getting the right abstractions and naming conventions.</p><p><strong>The names you choose determine the perception and the quality of conversations you have. </strong>It’s why top developers spend time obsessing over names for classes, functions, and variables.</p><p>When you open up a VS Code and see a function called <code>send_signup_email</code>, you have a certain sense of what’s going to be inside and why that’s there.</p><p>The right abstractions can drive the team towards asking the right questions. And this is critical.</p><p><strong>Because when you’re tracking issues and tickets in isolation you have no choice but to measure only outputs.</strong></p><p>And teams today don’t want to measure only the outputs. They want to measure <em>outcomes</em>.</p><hr><h2 id="what-s-the-right-abstraction">What’s the right abstraction?</h2><p>The right abstraction is the one that prioritizes people over processes and tools. It's the one you and I use every day — it's Features.</p><p>When a squad creates a Feature and opens it, they’ll get to look at the entire feature as a unit. A <a href="https://zepel.io/agile/user-stories/">user story</a> inside it might describe a specific functionality. But the difference is, now each developer and designer know how it connects to the larger scheme of things for the entire feature.</p><blockquote>A feature forces inept managers to stop focussing on output-oriented questions like “how can we work faster”. <p>And shifts the focus on outcome-oriented questions like “why should we prioritize this feature” and “how does this feature tie to the OKR”.</p></blockquote><p>Miscellaneous tasks and incoming bugs can be tracked on a separate “List”, so high-priority bugs don't get missed out. And of course, when it comes to tracking them, they can all be tracked on a Sprint or on a Kanban Board.</p><p><strong>Feature as an abstraction is the right middle ground that lets you focus on the output as well as the outcome.</strong> It lets you zoom in and track what's happening today. It also allows you to zoom out and track a feature's progress across multiple disciplines. And it enables you to see how a feature moves from a feature request all the way to prioritization and development.</p><p>Simple issue trackers and project management tools have shoehorned teams into ticket-movers and have made them think in outputs. Metrics get feigned to show productivity. Thinking in outcomes has become ridiculously hard. And it's hurting businesses.</p><p>It's time for tools to reflect the reality of product development. It's time to remove the disconnect between development teams and what your customers really want. </p><p>It's time to stop thinking in isolated tickets and start thinking in features as a system!</p><hr><p>If you liked what you read, I think you’ll love what we have in store for you. Go ahead and <a href="https://zepel.io/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=product-development-is-broken">try Zepel for free</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://zepel.io/blog/how-issue-tracking-hurts-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816682</guid>
            <pubDate>Mon, 13 Jul 2020 02:42:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Website allows you to experience what it is like to live with dyslexia (2016)]]>
            </title>
            <description>
<![CDATA[
Score 426 | Comments 178 (<a href="https://news.ycombinator.com/item?id=23816678">thread link</a>) | @colinprince
<br/>
July 12, 2020 | http://geon.github.io/programming/2016/03/03/dsxyliea | <a href="https://web.archive.org/web/*/http://geon.github.io/programming/2016/03/03/dsxyliea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        


<div>
  <div>
    
<p>A friend who has dyslexia described to me how she experiences reading. She <em>can</em> read, but it takes a lot of concentration, and the letters seems to “jump around”.</p>

<p>I remembered reading about <a href="https://en.wikipedia.org/wiki/Typoglycemia">typoglycemia</a>. Wouldn’t it be possible to do it interactively on a website with Javascript? Sure it would.</p>

<p>Feel like making a bookmarklet of this or something? <a href="https://github.com/geon/geon.github.com/blob/master/_posts/2016-03-03-dsxyliea.md">Fork it</a> on github.</p>

<blockquote>
  <p>Dyslexia is characterized by difficulty with learning to read fluently and with accurate comprehension despite normal intelligence. This includes difficulty with phonological awareness, phonological decoding, processing speed, orthographic coding, auditory short-term memory, language skills/verbal comprehension, and/or rapid naming.</p>
</blockquote>

<blockquote>
  <p>Developmental reading disorder (DRD) is the most common learning disability. Dyslexia is the most recognized of reading disorders, however not all reading disorders are linked to dyslexia.</p>
</blockquote>

<blockquote>
  <p>Some see dyslexia as distinct from reading difficulties resulting from other causes, such as a non-neurological deficiency with vision or hearing, or poor or inadequate reading instruction. There are three proposed cognitive subtypes of dyslexia (auditory, visual and attentional), although individual cases of dyslexia are better explained by specific underlying neuropsychological deficits and co-occurring learning disabilities (e.g. attention-deficit/hyperactivity disorder, math disability, etc.). Although it is considered to be a receptive language-based learning disability in the research literature, dyslexia also affects one’s expressive language skills. Researchers at MIT found that people with dyslexia exhibited impaired voice-recognition abilities.</p>
</blockquote>

<p><em>Source: <a href="http://en.wikipedia.org/wiki/Dyslexia">Wikipedia</a></em></p>






    <hr>
    
    <hr>
    


  


<p><a href="http://disqus.com/">blog comments powered by </a>




  </p></div>
  
  
</div>


      </div></div>]]>
            </description>
            <link>http://geon.github.io/programming/2016/03/03/dsxyliea</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816678</guid>
            <pubDate>Mon, 13 Jul 2020 02:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning done right can be your biggest investment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816474">thread link</a>) | @xueyongg
<br/>
July 12, 2020 | https://blog.phuaxueyong.com/post/2020-07-13-learning-the-right-way/ | <a href="https://web.archive.org/web/*/https://blog.phuaxueyong.com/post/2020-07-13-learning-the-right-way/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><span><p>In the midst of chaotic schedules and piles of work, it is often easy to just take the easy way out of the pile of work: auto pilot. You just switch out the curiosity mode, and just churn out work one after another. “There isn’t time to just sit and ponder. I’ve got 10 other todos to clear out today”. As we continue down this train of thought, we will find ourselves at the brink of a burnout soon and very soon. How then do the smartest people actually learn such complex knowledge? For example, learning calculus in colleague, does one know what does dy/dx actually means?</p>

<p>I came across an article talking about how the smartest people are <a ref="nofollow" target="_blank" href="https://nabeelqu.co/understanding">learning the right way</a>. Now this right does not mean morally right or wrong. But rather learning as a reflection of one’s virtue of honesty and integrity. We will get to this.</p>

<p>Below are four lessons I’ve gotten away from the article:</p>
<br>
<h2>1. More than one solution to the same problem; don’t stop at 1.</h2>

<p>Once a problem was solved, some of the smartest people I’ve known will go back and continue thinking about the problem and try to figure out different solutions to the same problem. Afterwards, he’d come back with 3-4 alternative solutions to the same problem + explanations of why each solutions are somehow connected.</p>
<br>
<blockquote>
<p>It’s also so easy to think that you understand something, when you actually don’t. So even figuring out&nbsp;whether&nbsp;you understand something or not requires you to attack the thing from multiple angles and test your own understanding.</p>
</blockquote>

<p><img src="https://pbs.twimg.com/media/EcvWI2NXYAgD5UT?format=jpg&amp;name=large" alt=""> <em>source from visualizingvalue</em></p>

<p>A problem is often times bigger and more complex beyond our current perspective. The ability to sit and ponder for alternative solutions to the same problem forces you to consider the possibility of not knowing something in this problem at hand. It allows you to force out the cracks in the pottery by placing the knowledge under fire.</p>
<br>
<h2>2. Be honest with yourself; do you really know? Ask yourself.</h2>

<p>To admit that you do not understand a concept is related to honesty or integrity. It is uniquely easy to lie to yourself that you know and move on because there is no external force keeping you honest. You and only you can run that constant loop of asking “do i really understand this?”. Do not just skirt past the problem just to move on to the next task, you’re not a factory that just just churning out work day in day out. You’re an individual that is part of your own journey to learn, grow, and develop.</p>

<p>Also, writing has a part to play. Firstly, it helps you to be honest with yourself; it forces you to articulate your understanding. And if the writing comes out confusing and disjointed, it is a reality check for knowledge gaps.</p>
<br>
<blockquote>
<p>It’s okay to admit that you don’t know</p>
</blockquote>
<br>
<h2>3. Go beyond the abstraction, tell me what you really know. Give examples.</h2>

<p>The tangible experiments of your learning with concrete examples is important to illustrate understanding. You do not just stop at simple verbal “word based” understanding. It can only bring you this far. But visuals creates a context in which your understanding can take place in.</p>
<br>
<blockquote>
<p>Visualizing something, in three dimensions, can help you with a concrete “hook” that your brain can grasp onto and use as a model;</p>
</blockquote>

<p>If you’re not coming up with visuals and your understanding of things remains on the level of abstractions or abstract concepts, you probably do not understand the concept deeply and should dig further. Below is basically the concept of AI conversational classifiers done up with the illustration of a coin filter.</p>

<p><img src="https://pbs.twimg.com/media/Ebxl9eFWoAAJuFT?format=png&amp;name=small" alt=""> <em>source from nwilliams030’s twitter</em></p>
<br>
<ol start="4">
<li>Have the courage to ask; Ask if you don’t know.</li>
</ol>
<p>Have the courage to be unafraid to look stupid. Have the courage to admit and seek for clarity and understanding. Don’t just pretend you understand just to pass the time. This is your journey of learning and getting better than the you yesterday. Do not let other people dictate how you should invest in yourself. Shower yourself with love and respect for your own growth.</p>

<p><img src="https://images.unsplash.com/flagged/photo-1558979217-e7f2c4511e8b?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1650&amp;q=80" alt="kid watering flower"></p>
<br>
<hr>
<br>
<h2>TLDR;</h2>

<p>At the end of the day, if you want to understand something, go slow. Explore every step of the way in your adventure to learn and unveil. Read slowly, think slowly, really spend time pondering the thing. A week or a month of continuous pondering about a question will get you surprisingly far. In the space of technology, you will face a ton of technology that are more abstracted and technical beyond human mind (haha kidding, but it feels like so). There’s what you got to be honest with yourself to admit that you don’t know then can the learning begin (:</p>

<p>Before you end off, do watch this video! It is really good. It’s a video talking about the 5 hours rule deliberate learning. Let’s learn together! (:</p>

<p>
<iframe src="https://www.youtube.com/embed/IaODRYKFbrc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></span></p> </div></div>]]>
            </description>
            <link>https://blog.phuaxueyong.com/post/2020-07-13-learning-the-right-way/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816474</guid>
            <pubDate>Mon, 13 Jul 2020 02:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Host a Wiki or Knowledge Base for Your Team]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 70 (<a href="https://news.ycombinator.com/item?id=23816462">thread link</a>) | @chsasank
<br/>
July 12, 2020 | http://chsasank.github.io/outline-self-hosted-wiki.html | <a href="https://web.archive.org/web/*/http://chsasank.github.io/outline-self-hosted-wiki.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>How is your startup sharing knowledge with the rest of your team?
We’ve been using slack’s <code>#general</code> or <code>#random</code> channels to make announcements.
We regularly post documents and PPTs slack channels so that they can be used by other people. We have a channel called <code>#setup</code> to post all IT related information like how to login to VPN etc.</p>

<p>But after a few weeks, these docs/notes become super hard to find. As good slack’s search is, you have to precisely know what you’re looking for. What we needed was a centralized knowledge base website - something like <a href="https://www.atlassian.com/software/confluence">Confluence</a></p>

<p>But Confluence is clunky and slow, and not cheap ($5/user). We experimented with <a href="https://tiddlywiki.com/">TiddlyWiki</a>. It calls itself ‘a non-linear personal web notebook’. It’s an opensource software which you can host on your servers or AWS. But its non linear organization makes it super unintuitive and confusing.</p>

<h2 id="why-outline">Why Outline?</h2>

<p>Then, I found <a href="https://www.getoutline.com/">outline</a>! Outline is similar to TiddlyWiki in that it’s opensource and free to self-host. Its UI is a great balance between simplicity of plain text notes and feature creep of Confluence. Login to outline is through your slack - so one less password to remember (or save). You can create private notebooks for a team or just for yourself. You can create a public link of a note so that you can share it with people outside your team - say via email.</p>

<p><span>
    Outline has great UI
</span>
<img src="https://www.getoutline.com/images/screenshot.png"></p>

<p>Best part of all of this is that <em>data doesn’t leave your servers</em> if you self-host it!
We already have a server lying around on AWS to host our own <a href="https://en.wikipedia.org/wiki/Python_Package_Index">python package server, pypi</a>. Since neither hosting pypi nor hosting outline are particularly intensive, we’ve hosted outline on this machine as <code>wiki.qure.ai</code>.</p>

<h2 id="install-outline">Install Outline</h2>

<p>Unfortunately, documentation for self-hosting outline is limited. There’s no robust docker-compose avaialable that you can use to directly create your server. In the rest of this post, I’ll show you how to host in your laptop or server. Before starting, make sure to install <a href="https://docs.docker.com/get-docker/">docker</a> and <a href="https://docs.docker.com/compose/install/">docker-compose</a>.</p>

<div><div><pre><code>git clone https://github.com/chsasank/outline-wiki-docker-compose.git
cd outline-wiki-docker-compose
make install
</code></pre></div></div>
<p><span>
    make install
</span>
<img src="http://chsasank.github.io/assets/images/outline/make_install.png"></p>

<p>Follow the instructions. You’ll have to create a slack app.
<span>
   Slack app
</span>
<img src="http://chsasank.github.io/assets/images/outline/slack_app.png"></p>

<p>If you want to install HTTPS:</p>



<p>Run the server:</p>



  </section></div>]]>
            </description>
            <link>http://chsasank.github.io/outline-self-hosted-wiki.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816462</guid>
            <pubDate>Mon, 13 Jul 2020 02:00:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Biotech]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23816390">thread link</a>) | @apsec112
<br/>
July 12, 2020 | https://www.celinehh.com/how-to-build-a-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/how-to-build-a-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

      

        

        <div data-content-field="main-content">
          <div data-type="page" data-updated-on="1594684464227" id="page-5e0541ebe2b52a3155df2dcb"><div><div><div data-block-type="2" id="block-3ee5a93fdab84f05b621"><p><h3>The Summer of 2019, I gave a series of lectures to Longevity Fund’s Venture Fellows on the basics of building a biotechnology company. This is the write up of those lectures, with some additions by Laura Deming &amp; myself. </h3></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1577404962916_9483"><div><h2>First Steps</h2><p>You’re intrigued by biotech and want to explore ideas in the area. Where do you start? </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1577402821118_87823"><div><h2>Raising Money</h2><p>Science is expensive! One way to fund your work is to get venture capital (VC) investment. It’s a very different process from applying for an academic research grant. </p><p>There are a lot of excellent resources out there on raising capital.* Because of this I’ve focused here on “SF style” biotech investing, and the areas where the advice for a bio company differs from that of a tech company. </p><h3><a href="https://www.celinehh.com/vc101">VC for Bio 101</a> </h3><h3><a href="https://www.celinehh.com/investment-memo">Biotech investment memos</a></h3><p><a href="https://pmarchive.com/guide_to_startups_part1.html">*Marc Andreessen’s guide to startups</a>, the <a href="http://paulgraham.com/articles.html">PG essays</a>, and <a href="https://www.amazon.com/Venture-Deals-Smarter-Lawyer-Capitalist/dp/1118443616">Venture Deals</a> are three classics</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1577402821118_96448"><div><h2>Building in Bio</h2><p>A bit of a deeper dive into the predominant types of drugs and the considerations around each of them. The type of drug you select impacts the safety, dosing strategy, potential efficacy, downstream price &amp; profit margin, and competitiveness of your drug. </p></div></div></div></div></div>
        </div>
      
    </div></div>]]>
            </description>
            <link>https://www.celinehh.com/how-to-build-a-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816390</guid>
            <pubDate>Mon, 13 Jul 2020 01:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From English Major to Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816355">thread link</a>) | @shsachdev
<br/>
July 12, 2020 | https://www.careerfair.io/reviews/software-engineer-interview-at-scratch-finance | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/software-engineer-interview-at-scratch-finance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            


<p>
My name is Chris Dang and I work at <a href="https://www.scratch.fi/">Scratch</a> which is a Series A fintech startup that has reimagined loan servicing to help borrowers understand, manage, and pay back their loans. It’s a company filled with determined, smart, and mission driven individuals. 
</p>
<p>
We were recently mentioned in this <a href="https://www.nytimes.com/2020/06/23/business/paycheck-protection-program-cross-river-bank.html">New York Times article</a>.
</p>
<center>
    <img src="https://www.careerfair.io/assets_cdang/final_homepage.png" alt="">
</center>
<p>
I’m a software engineer who primarily focuses on Identity and Access Management. This means I focus on authentication, authorization, and user management problems. I also occasionally work outside my domain in areas such as frontend, security, and infrastructure. This happens a lot at startups which require folks to wear many hats. 
</p>



<p>
I don’t really understand why but I just enjoyed writing essays and discussing texts so I became an English major. It was one of those moments where I felt like I just had to go with my gut and I’m glad I did because becoming an English major made me a more creative person. This creativity allowed me to come up with a few startup ideas that I’ve attempted and have planned for the future. 
</p>
<p>
The reason I taught myself how to code is that I wanted to build my ideas. I’d like to note that I did take a few intro computer science courses before I became an upperclassman, so when I began attempting some of my startup ideas I already knew OOP, runtime analysis, data structures and algorithms. 
</p>
<p>
In my day-to-day, being an English major helps me with communication, which is very key as an engineer, and, this is a little random, but it makes me more relatable to non-engineering folks since a lot of them probably took similar courses to me.
</p>
<center>
  <img src="https://www.careerfair.io/assets_cdang/new_venn_diagram.png" alt="">
</center>



<p>
It was definitely a problem in the beginning since I had no experience and a lot of companies wouldn’t even give me an interview. I wasn’t too worried about this though because I had a passion project I was working on and if I wasn’t able to get a job, I was determined to go all on the project and turn it into a startup. I actually was able to launch it to the app store and had a customer acquisition strategy. Luckily, a few companies, including WeWork, liked the grit I showed in my startup and gave me a chance.
</p>
<p>
The lack of a CS major did leave a gap in my knowledge when it came to interviews and performing the day to day job. I did a few things to mitigate this gap which included going through lecture slides for upper division courses I found interesting (e.g. Operating Systems and Computer Security), spending copious amounts of time reading articles about engineering, and spending time on my passion project which gave me a lot of real world experience. Also, Stack Overflow was my best friend. 
</p>



<p>
My time at WeWork made me realize that I was very interested in the Identity, Infrastructure, and Security domains with Identity being my primary interest. So when I began my job search, I made sure to focus on jobs in those domains but I did apply to some generalist positions. The reason for this is that I’m pretty young and it’s good for me to have breadth in other areas. I also wanted to make sure that my next job had really challenging problems and smart engineers. The things I cared about least were job stability (e.g. whether or not my company would exist in a year), my total compensation, and the company brand. 
</p>
<p>
I optimize for growth over learning by focusing on opportunities that I’m passionate about over opportunities that would make me more money. Money and brand names bring you a limited amount of satisfaction. However, doing something you are passionate about will always be more exciting because as you grow in that area, the horizons expand and more exciting ideas/projects will come to you.
</p>
<center>
    <img src="https://www.careerfair.io/assets_cdang/cash.png" alt="">
</center>



<p>
The nice thing about working at startups is you are guaranteed to have a large role. Everyday I learn something new and I always feel like my work is rewarding. But there is a trade off here.  I do feel like I’m a lot busier since my role is more significant than if I were at a large company. 
</p>
<p>
One thing I wish I realized earlier though was that even at a big company, you can have a really exciting role. It really depends on the team and your manager. If you are hungry for a challenge but would like the comfort of a large company, I would recommend interviewing with some of the newer projects.
</p>



<p>
I actually went to the office before the shelter in place was ordered so I didn’t have any issues with setting up my laptop or developer environment. But even if this wasn’t the case, I don’t see remote onboarding being a problem due to strong video technologies such as Zoom. 
</p>
<p>
My first day of work actually began a few weeks after the quarantine began so I haven’t had more than a few days to see my coworkers in person. It’s a little weird because I spend so much time with these people but our interactions are exclusively through a computer screen. One thing I’ve realized is I’m lukewarm to remote work culture since it’s hard to have spontaneous interactions with coworkers and happy hours aren’t as fun. 
</p>
<p>
That being said, I’m really amazed by how our team has adapted to these conditions. Despite the pandemic, the conditions of working remote, and other obstacles, we’ve managed to persevere and launch our PPP product.
</p>

<center>
  <img src="https://www.careerfair.io/assets_cdang/spontaneous.png" alt="">
</center>




<p>
I’ve worked with teams in business operations and design at least once a week. It’s cool to collaborate with folks from other departments because you can pick their brains and see another perspective to a problem you are working on. A really big aspect of these interactions is your ability to communicate technical topics since a lot of times non-technical individuals will rely on you to explain what’s going on under the hood with the software. 
</p>



<p>
My average day consists of reviewing pull requests and working on my own pull requests. Occasionally, I’ll have meetings to sync on the state of my team or the company or run interviews for candidates.
</p>
<p>
My experience with my side project gave me a pretty good idea of the technical challenges I would face in my day-to-day. I would say one thing that surprised me was how open people were to my questions. This made it easier for me to grow as an engineer since I was surrounded by people who wanted to help me learn. A piece of advice I’d give to new engineers is to try to solve a problem or understand a concept on your own first before asking the questions. 
</p>
          </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/software-engineer-interview-at-scratch-finance</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816355</guid>
            <pubDate>Mon, 13 Jul 2020 01:39:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bringing GPU Acceleration to Inkscape, Week 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816235">thread link</a>) | @shahreel
<br/>
July 12, 2020 | https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/ | <a href="https://web.archive.org/web/*/https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
      
<h2>
  Bringing GPU Acceleration to Inkscape, Week 2
</h2>
<p>Published the <time datetime="2020-06-12T20:02:31+02:00">2020-06-12</time></p>
<p>Hello everyone!</p>
<p>For the past two weeks since the beginning of this <a href="https://summerofcode.withgoogle.com/organizations/6070010742571008/#5859756641615872">GSoC
2020</a>
I have attempted to integrate <a href="https://github.com/servo/pathfinder">Pathfinder</a>
into Inkscape, in order to draw (and refresh!) the canvas much faster by using
your GPU.</p>
<p>After some early attempts, where I created a C++ Inkscape extension opening
Pathfinder’s demo on the current SVG, and another extension which was basically
a copy of <a href="https://github.com/servo/pathfinder/blob/master/examples/c_canvas_glfw_minimal/c_canvas_glfw_minimal.c">Pathfinder’s C canvas
example</a>,
I’ve started to properly integrate it into Inkscape’s widgets.</p>
<p>That’s where the fun began, here is a small tour of the fun bugs I encountered:</p>
<h3 id="using-apitrace-on-wayland-can-be-interesting">Using <code>apitrace</code> On Wayland Can Be Interesting</h3>
<p><a href="https://apitrace.github.io/"><code>apitrace</code></a> is a very handy tool for debugging
OpenGL applications, it avoids having to understand the code’s structure, and
allows me to focus on the actual behaviour from the driver’s point of view.</p>
<pre><code><span>glXGetCurrentContext() not found: /usr/bin/../lib/apitrace/wrappers/egltrace.so: undefined symbol: glXGetCurrentContext
apitrace: warning: caught signal 6
</span></code></pre>
<p>I was a bit sad to see that a bug I found at the intersection of
<a href="https://github.com/apitrace/apitrace/issues/380">apitrace</a> and
<a href="https://github.com/anholt/libepoxy/issues/68">libepoxy</a> back in 2015
reappeared now, this time caused by GDK doing the same.  In the end I rebuilt
both libepoxy and GTK+ with only their Wayland backend so they wouldn’t be
tempted to call GLX symbols.  This breaks Firefox and probably some other
software which link against their X11 symbols, but on my build/testing machine
it’s fine.</p>
<p>Speaking of running a (soon-to-be) OpenGL program on a remote machine,
<a href="https://gitlab.freedesktop.org/mstoeckl/waypipe">waypipe</a> from last year’s
GSoC is extremely useful, it feels almost instantaneous on my 900&nbsp;KiB/s down
80&nbsp;KiB/s up ADSL connection.  For comparison, I also tried X11 forwarding over
ssh which only shows Inkscape’s window after 1:05, and also mounting the build
directory over sshfs where it takes 1:20 to do the same, and 6:40 (!) to
generate a stack trace in case of a panic.  I probably should have figured that
out during the community bonding period, but I didn’t think of it.</p>
<h3 id="pathfinder-doesn-t-like-to-draw-into-gtk-glarea-very-much">Pathfinder Doesn’t Like To Draw Into <code>Gtk::GLArea</code> Very Much</h3>
<p>I spent quite a few days trying to get Pathfinder to draw into a GTK+ widget,
first inside of Inkscape, then in a <a href="https://linkmauve.fr/files/pathfinder-glarea.tar.xz">testcase
application</a>.  The
<code>Gtk::GLArea</code> widget lets an application draw using OpenGL.  I want it to
eventually replace Inkscape’s <code>SPCanvas</code>, once I’m done and <a href="https://wiki.inkscape.org/wiki/index.php?title=Inkscape_Canvas">Tavmjong as
well</a>, but in
the meantime I’ll keep them both side-by-side in order to compare their
rendering more easily.</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/empty-glarea.png" alt=""></p>
<p>Despite the rendering being done, according to <code>apitrace</code>’s step-by-step
debugging, the <code>Gtk::GLArea</code> stayed hopelessly black.  Even though I could
render a simple solid colour using <code>glClearColor()</code> and
<code>glClear(GL_COLOR_BUFFER_BIT)</code>, as soon as I tried to render using Pathfinder
it went back to a solid black.</p>
<p>Experimenting with the OpenGL contexts, I could make Pathfinder render its
iconic tiny house everywhere but where I wanted it:</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/almost-but-not-quite.png" alt=""></p>
<p>Here is a particularly trippy rendering I got, when <code>Gtk::GLArea</code> is reading
from a framebuffer Pathfinder hasn’t written into:</p>

<p>It was only with the help of <a href="https://github.com/s3bk">sebk</a> that I finally
figured out that I wasn’t passing the correct
<a href="https://www.khronos.org/opengl/wiki/Framebuffer_Object">fbo</a> to Pathfinder.  I
was passing <code>0</code> which means the default (display’s) framebuffer instead of the
one created for me by GTK+.  With this fixed, everything rendered fine, even on
resize:</p>

<p>After that it was a simple matter of <a href="https://github.com/servo/pathfinder/pull/357">adding some API to Pathfinder’s C
bindings</a> and I can render the
same SVG as Inkscape!</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/same-svg.png" alt="">
On the left hand side we can see <a href="https://poez.io/">poezio</a>’s logo rendered by
Inkscape with cairo; on the right hand side the same logo being serialised and
passed to Pathfinder to be rendered on the GPU.</p>
<p>And this concludes my first progress report of this GSoC, a big thanks to
ebassi, halfline and Neville[m] from
<a href="xmpp:%23gtk%irc.freenode.net@irc.jabberfr.org?join">#gtk</a>, and especially sebk
from <a href="xmpp:%23pathfinder%23mozilla.org@matrix.org?join">#pathfinder</a>, who
helped me a lot in that process!</p>


    </div>
  </section></div>]]>
            </description>
            <link>https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816235</guid>
            <pubDate>Mon, 13 Jul 2020 01:23:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuzz Week 2020 – Come Learn the Basics to Advanced of Fuzzing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816110">thread link</a>) | @gamozolabs
<br/>
July 12, 2020 | https://gamozolabs.github.io/2020/07/12/fuzz_week_2020.html | <a href="https://web.archive.org/web/*/https://gamozolabs.github.io/2020/07/12/fuzz_week_2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>Welcome to fuzz week 2020! This week (July 13th - July 17th) I’ll be streaming
every day going through some of the very basics of fuzzing all the way to
cutting edge research. I want to use this time to talk about some things
related to fuzzing, particularly when it comes to benchmarking and comparing
fuzzers with each other.</p>



<p>Ha. There’s really no schedule, there is no script, there is no plan, but
here’s a rough outline of what I want to cover.</p>

<p>I will be streaming on my <a href="https://twitch.tv/gamozo">Twitch channel</a> at approximately
<a href="https://www.timeanddate.com/worldclock/fixedtime.html?msg=Fuzz+Week+Approx+Stream+Start&amp;iso=20200713T14&amp;p1=234">14:00 PST</a>. But things aren’t really going to be on a strict schedule.</p>

<p>My <a href="https://twitter.com/gamozolabs">Twitter</a> is probably the best source of information for when
things are about to start.</p>

<p>Everything will be recorded and uploaded to my <a href="https://www.youtube.com/user/gamozolabs">YouTube</a>.</p>

<h4 id="july-13th">July 13th</h4>

<p>The very basics of fuzzing. We’ll write our own fuzzer and tweak it to improve
it. We’ll probably start by writing it in Python, and eventually talk about the
performance ramifications and the basics of scaling fuzzers by using threads or
multiple processes. We’ll also compare our newly written fuzzer against AFL and
see where AFL outperforms it, and also where AFL has some blind spots.</p>

<h4 id="july-14th">July 14th</h4>

<p>Here we’ll cover code coverage. We might get to this sooner, who knows. But
we’re going to write our own tooling to gather code coverage information such
that we can see not only how easy it is to set up, but how flexible coverage
information can be while still proving quite useful!</p>

<h4 id="july-15th-17th">July 15th-17th</h4>

<p>Here we’ll focus mainly on the advanced aspects of fuzzing. While this sounds
complex, fuzzing really hasn’t become that complex yet, so follow along! We’ll
go through some of the more deep performance properties of fuzzing, mainly
focused around snapshot fuzzing.</p>

<p>Once we’ve discussed some basics of performance and snapshot fuzzing, we’ll
start talking about the meaningfulness of comparing fuzzers. Namely, the
difficulties in comparing fuzzers when they may involve different concepts of
what a crash, coverage, or input are. We’ll look at some existing examples of
papers which compare fuzzers, and see how well they actually prove their point.</p>



<p>I think it’s important when doing something like this, to make it clear what my
existing biases are. I’ve got a few.</p>

<ul>
  <li>I think existing fuzzers have some major performance problems and struggle to
scale. I consider this to be a high priority as general performance
improvements to fuzzing harnesses makes both generic fuzzers (eg. AFL,
context-unaware fuzzers) and hand-crafted (targeted) fuzzers better.</li>
  <li>I don’t think outperforming AFL is impressive. AFL is impressive because it’s
got an easy-to-use workflow, which makes it accessible to many different
users, broadening the amount of targets it has been used against.</li>
  <li>I don’t really thinking comparing fuzzers is reasonable.</li>
  <li>I think it is very easy to over-fit a fuzzer to small programs, or add
unrealistic amounts of information extraction from a target under test, in a
way that the concepts are not generally applicable to many targets that
exceed basic parsers. I think this is where a lot of current research falls.</li>
</ul>

<p>But… that’s mainly the point of this week. To either find out my biases are
wildly incorrect, or to maybe demonstrate why I have some of the biases. So,
how will I address some of these (in order of prior bullets)?</p>

<ul>
  <li>I’ll compare some of my fuzzers against AFL. We’ll see if we can outperform
AFL in terms of raw fuzz cases performed, as well as the results (coverage
and crashes).</li>
  <li>I’ll try to demonstrate that a basic fuzzer with 1/100th the amount of code
of AFL is capable of getting much better results, and that it’s really not
that hard to write.</li>
  <li>I’ll propose some techniques that can be used to compare fuzzers, and go
through my own personal process of evaluating fuzzers. I’m not trying to get
papers, or funding, or anything. I don’t really have an interest in making
things look comparatively better. If they perform differently, but have
different use cases, I’d rather understand those cases and apply them
specifically rather than have a one-shoe-fits-all solution.</li>
  <li>I’ll go through some instrumentation that I’ve historically added to my
fuzzers which give them massive result and coverage boosts, but consume so
much information that they cannot meaningfully scale past tiny pieces of
code. I’ll go through when these things may actually be useful, as sometimes
isolating components is viable. I’ll also go through some existing papers and
see what sorts of results are being claimed, and if they actually have
general applicability.</li>
</ul>



<p>It’s important to note, nothing here is scheduled. Things may go much faster,
slower, or just never happen. That’s the beauty of research. I may be very
wrong with some of my biases, and we’ll hopefully correct those. I love being
wrong.</p>

<p>I’ve maybe thought of having some fuzzing figureheads pop on the stream for
random discussions/conversations/interviews. If this is something that sounds
interesting to you, reach out and we can maybe organize it!</p>



<p>See you there :)</p>

<hr>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://gamozolabs.github.io/2020/07/12/fuzz_week_2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816110</guid>
            <pubDate>Mon, 13 Jul 2020 01:01:46 GMT</pubDate>
        </item>
    </channel>
</rss>
