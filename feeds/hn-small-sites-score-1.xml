<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 03 Oct 2020 01:04:44 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 03 Oct 2020 01:04:44 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[PowerShell Universal v1.4]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649270">thread link</a>) | @l33t_d0nut
<br/>
October 1, 2020 | https://blog.ironmansoftware.com/powershell-universal-1-4/ | <a href="https://web.archive.org/web/*/https://blog.ironmansoftware.com/powershell-universal-1-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main"><div><h2>PowerShell Universal v1.4</h2><h4>September 30, 2020</h4><p>I’m pleased to announce another feature-packed <a href="https://ironmansoftware.com/powershell-universal">PowerShell Universal</a> release! Today, we’re releasing version 1.4 of the ultimate platform for building web-based IT tools. This release contains an extensive list of features as well as bug fixes. This blog post will go over them but I encourage you to <a href="https://ironmansoftware.com/downloads">download or upgrade</a> to take full advantage of everything that has been added.</p><h2 id="release-notes">Release Notes</h2><p>Full release notes can be found <a href="https://docs.ironmansoftware.com/changelog">here</a>.</p><h2 id="downloads">Downloads</h2><ul><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/PowerShellUniversal.1.4.0.msi">Windows MSI</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.win-x64.1.4.0.zip">Windows ZIP</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.linux-x64.1.4.0.zip">Linux ZIP</a></li><li><a href="https://hub.docker.com/r/ironmansoftware/universal">Docker</a></li></ul><h2 id="platform">Platform</h2><h3 id="environments">Environments</h3><p>We’ve extended the concept of PowerShell Versions and replaced it with Environments. Environments allow you to specify the executable, arguments, modules and variables that are defined whenever you execute an API request, run a job or host a dashboard. The execution environment will automatically create a runspace pool with the assets you define so there is no need to import them every time.</p><p>We’ve standardized environments across all features and now you can select which environment is used in each place.</p><p><a href="https://docs.ironmansoftware.com/config/environments">Learn more about Environments</a></p><p><img src="https://blog.ironmansoftware.com/images/environments.png" alt=""></p><h3 id="windows-authentication-with-iis">Windows Authentication with IIS</h3><p>You can now configure Windows Authentication without IIS. IIS can complicate deployments and if it’s not something you need, you can now avoid it by simply installing Universal as a service and configuring Windows authentication.</p><p><a href="https://docs.ironmansoftware.com/config/security#windows-authentication-outside-of-iis">Learn more about Windows Authentication without IIS</a></p><h2 id="apis">APIs</h2><h3 id="rate-limiting">Rate Limiting</h3><p>We’ve added the ability to configure rate limiting for APIs. This is an important feature for anyone that may be exposing their API publicly or may call a sensitive resource that you do not want to overload. You can configure rate limits based on HTTP method, endpoint (or pattern), and the number of requests over a period of time.</p><p><a href="https://docs.ironmansoftware.com/api/rate-limiting">Learn more about Rate Limiting</a></p><p><img src="https://blog.ironmansoftware.com/images/ratelimit.png" alt=""></p><h3 id="connection-information">Connection Information</h3><p>You’ll have access to more connection information in your endpoints. Variables are now defined for Local IP Address, Remote IP Address, Local Port and Remote Port.</p><h3 id="updated-endpoint-page">Updated Endpoint Page</h3><p>We’ve enhanced the API page to provide a neat in-browser experience for developing your API. This includes the ability to test your APIs directly in the browser.</p><p><img src="https://blog.ironmansoftware.com/images/apis.png" alt=""></p><h2 id="automation">Automation</h2><h3 id="continuous-schedules">Continuous Schedules</h3><p>You can now define continuous schedules that will run a job over and over again with a configurable delay. It won’t start another job until the previous one has finished.</p><p><a href="https://docs.ironmansoftware.com/automation/schedules#continuous">Learn more about Scheduling</a></p><p><img src="https://blog.ironmansoftware.com/images/continuous-schedule.png" alt=""></p><h3 id="variables">Variables</h3><p>Variables are now global for the entire Universal platform. By default, your existing Environments will import all variables but you can define specific variables or patterns to use in an environment. This change shouldn’t affect your jobs but be aware that variables are no longer present only present in jobs but present in any one of the features using an Environment.</p><p><a href="https://docs.ironmansoftware.com/automation/variables">Learn more about Variables</a></p><h2 id="dashboard">Dashboard</h2><h3 id="role-based-access">Role-based Access</h3><p>We’ve added the ability to assign roles to dashboards and pages in the v3 framework. If you assign a role to a dashboard, only users of that role will have access to the entire dashboard. When you assign roles to a page in a dashboard, any authenticated user will be able to access the dashboard but only users in the specified role will have access to the pages.</p><p><a href="https://docs.ironmansoftware.com/dashboard/role-based-access">Learn more about Role-Based Access in Dashboards</a></p><h3 id="chartjs">ChartJS</h3><p>We’ve brought back ChartJS support. This was the primary chart library in UDv2. Many users preferred this library over our Nivo charts integration so we have decided to include it. We’ve also simplified the API to make it even easier to build charts.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/data-visualization/charts#chartjs">Learn more about ChartJS integration</a></p><p><img src="https://blog.ironmansoftware.com/images/chartjs.png" alt=""></p><h3 id="improved-navigation">Improved Navigation</h3><p>We’ve simplified and extended the built in navigation. You can now more easily define your navigation items for a page. We also support a persistent layout that does not require a click of a hamburger menu to open the navigation.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/pages#navigation">Learn more about Navigation</a></p><p><img src="https://blog.ironmansoftware.com/images/permanent-drawer.png" alt=""></p><h3 id="redesigned-dashboard-page">Redesigned Dashboard Page</h3><p>The dashboard page has been redesigned to make it easier to see an overview of the dashboards running in your environment.</p><p><img src="https://blog.ironmansoftware.com/images/new-dashboards.png" alt=""></p><h2 id="get-started-now">Get Started Now</h2><p>PowerShell Universal is free to try. <a href="https://ironmansoftware.com/downloads">Download now</a> and start building tools with your existing PowerShell scripts. Please feel free to join our <a href="https://forums.universaldashboard.io/">growing community</a>.</p></div></div></div>]]>
            </description>
            <link>https://blog.ironmansoftware.com/powershell-universal-1-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649270</guid>
            <pubDate>Thu, 01 Oct 2020 10:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can drive more traffic and engagement with content amplification]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649266">thread link</a>) | @JamesConverge
<br/>
October 1, 2020 | https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification | <a href="https://web.archive.org/web/*/https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><strong>Content amplification is one of the most underused&nbsp;pieces of the&nbsp;content marketing puzzle.</strong></p>
<p><strong>Hands down.</strong></p>
<p><span>So many businesses create great content, but then they only publish that content on their own website, and maybe share it once or twice on social media.</span></p>
<p><span>Sorry to break it to you, but with millions of other businesses doing the same thing, that isn't going to help you cut through the noise.&nbsp;</span></p>
<p><span>At all.&nbsp;</span></p>
<p><span>And hoping that someone will just stumble across your content isn’t a good strategy, either.&nbsp;</span></p>
<p><span>In reality, you need to <strong>AMPLIFY YOUR CONTENT</strong></span><span>.</span></p>
<p><span>Without content amplification, your hard work and effort will remain essentially “on the shelf collecting dust".</span></p>
<p><span>Creating content is less than half the battle. If you don't have a distribution, or amplification strategy for your content, then you're missing out on more traffic, more awareness, more backlinks, better SEO and a more engaged audience.</span></p>
<p><span>And, of course, all of the above <em>usually</em> lead to additional commercial benefits such as more customers and more sales.</span></p>
<p><span>In this article, we’re going to break down content amplification, tell you what it is, how it works, and how you can get the most out of it so your content can start to work harder and more effectively for you.&nbsp;</span></p>
<p><span>We’re going to answer the most common questions we get that relate to content amplification, such as:</span></p>
<ul>
<li><span>What is content amplification?</span></li>
<li><span>Why is content amplification so important?</span></li>
<li><span>How can I build a content amplification strategy?</span></li>
</ul>
<p><span>But enough with the preamble. Let’s jump in and get right into the good stuff.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Mark%20Masters.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"The reason we shy away from content distribution or amplification is that it feels far better to be creative and produce, than it is to encourage people to watch/listen/read, as this side takes far more effort. Then again, the reason we are creating is to motivate people and get them to subscribe, enquire, interact and buy.</em></p>
<p><em>What is really important is to have something to say that can be amplified. Distribution channels work really well, once you have something to distribute. So, make sure that your message links to your values and that can strike a chord with others. This is how you find your allies, make sure your work is seen and people want to feel a part of it and prepared to stand with you."&nbsp;</em></p>
<p><strong><em>Mark Masters - <a href="https://www.wearethemedia.co.uk/">We Are The Media</a></em></strong></p>
<p>What is content amplification, and why is it so important?</p>
<p><span>Content amplification is the act of promoting and distributing your content across multiple channels (paid, owned and earned) so you can increase the reach and impact of both your content and your brand.</span></p>
<p><span>However, amplifying your content does more than simply provide your brand with additional exposure. It also allows you to position yourself as a thought leader, and build valuable backlinks, as well as build relationships, and increase both engagement and conversion rates with your target audience.&nbsp;</span></p>
<p><span>There are many different ways to amplify content. Paying to promote your content on Facebook or Twitter, leveraging influencers to promote your content, publishing your content on </span><a href="https://promos.converge.today/join-converge"><span>other platforms with an already captivated audience</span></a><span> - they’re all different ways to amplify your content, and we’ll get into them in a bit more detail later on.</span></p>
<p><span>Without amplification, it’ll be much more difficult for you to get the results you want from your content.&nbsp;</span></p>
<p><span>Every single day, there are</span><a href="https://www.worldometers.info/blogs/"><span> millions of new blogs published</span></a><span>. Yes, not all of them will be competing with what you’ve created, but that’s a lot of potential noise getting in the way of your message. And organic reach is getting lower and lower all the time.</span></p>
<p><span>Because organic reach across the board is down, way down, when it comes to creating content - and you may be producing the best stuff out there - the likelihood is that without amplifying your content, it’s not going to perform well.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Cathy%20McPhillips.jpg" alt="" width="1600" height="150"></span></p>
<p><em>“You’ve written an amazing article – and now what? You can’t expect the results to happen without some distribution work on your end. This includes content amplification – a multi-channel approach to increase your brand’s reach. It’s taking your owned media, and combining it with paid and earned media. It’s really knowing the right places – and people – to help amplify your message to your audience.</em></p>
<p><em>Through content amplification, you’re able to extend your reach into new areas you couldn’t achieve on your own through organic methods. It’s getting out of your echo chamber of your current customers and brand loyalists and finding new and relevant customers who wouldn’t have necessarily heard of you otherwise. Amplification done right brings customers to you who didn’t yet know how much they needed you.</em></p>
<p><strong><em>Cathy McPhillips - <a href="http://contentmarketinginstitute.com/">Content Marketing Institute</a></em></strong></p>
<p>The problem with organic traffic</p>
<p><span>OK, that’s a little misleading. There is no problem with organic traffic.</span></p>
<p><span>The problem lies with the expectations people have when it comes to organic traffic. And, frankly, the delusion that generating it is both a) easily achievable and, b) that it is the only traffic source worth aiming for.&nbsp;</span></p>
<p><span>Nope.</span></p>
<p><span>Listen, organic traffic is great. It’s wonderful. If you’re getting huge organic traffic and your website and blogs are appearing right at the top of search results for your most relevant and valuable keywords and phrases, then brilliant! You’ve smashed it already.&nbsp;</span></p>
<p><span>Chances are, though, that’s not the case. Because, 1) only a handful of businesses across the entire planet can claim to have achieved the above. And it’s a constant battle for them to remain at the top. And, 2) organic reach is in decline </span><a href="https://blog.hootsuite.com/organic-reach-declining/"><span>across the board</span></a><span>.</span></p>
<p><span>We’re not saying achieving a first page ranking on Google for your content is impossible, but it may take both time and resources that you currently don’t have to get there. So, before you become a high-ranking Google superstar, you must find another way to get eyeballs on your content.</span></p>
<p><span>You need to amplify content so you can generate the consistent traffic and backlinks you need to get it the awareness and engagement it deserves, and to get it started on the long, arduous climb towards the first page of search results.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Abby%20Sorensen.jpg" alt="" width="1600" height="150"></span></p>
<p><em>“Imagine this scenario at the most important trade show in your industry - Your sales team picks up their badges and heads for the show floor, eager to make connections and meet potential buyers. Your product/service is the exact right fit for these prospects, and your message has been carefully crafted to resonate with them. But your booth is set up at the empty convention center across town. Maybe you were trying to stretch your budget. Or maybe you thought your product/service was so exciting that buyers would go out of their way to find you. Your sales team heads back to the office empty-handed, a complete waste of time and energy spent setting up your booth where your buyers were not.</em></p>
<p><em>This is exactly what happens when you create content with no plan to distribute it.<strong> Only a select few companies can afford to buy their way to the top of Google’s search rankings.</strong> The only way to get the most out of your content is to distribute it where your buyers are likely to be. And while your website might be the most strategized, optimized, digitized, mobilized website in your market, your buyers simply are not likely to spend a great deal of time there (especially if you hit them with gates and form-fills).”</em></p>
<p><strong><em>Abby Sorensen - <a href="https://www.followyourbuyer.com/">Follow Your Buyer</a></em></strong></p>
<p>Creating content is less than half the battle</p>
<p><span>That’s right. All that time you spent researching, planning, creating and publishing content is less than half of what’s required to give your content the best chance of generating the return on investment you want from it.&nbsp;</span></p>
<p><span>Depending on who you talk to and the articles you read, you may have heard people saying content creation is anywhere from 20-40% of the job.</span></p>
<p><span>The rest of it? You guessed it; amplification/distribution/promotion - whatever you call it. Whatever it takes to get your content in front of everyone you want to read it.</span></p>
<p><span>But let’s not get bogged down in specific percentages. The only thing you need to know is that you need to spend more time promoting your hard work than you do creating it. Because the competition for attention is fierce, and you need to cut through the noise and make sure people are actually engaging with your content. Otherwise why spend the time creating it in the first place?&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Alexandra%20Cote.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"Beyond simply creating a really good post, you'll also need really great content amplification methods in place. In fact, everything that happens AFTER you publish a piece of content is much more important than the post itself. This is because sharing content across appropriate channels and talking about your findings and products gets your brand in front of more people.</em></p>
<p><em>This being said, content amplification is the core driver behind reaching your business goals and hitting your KPIs. Whether you want to improve your brand awareness, get more qualified leads, gain new partnerships, or just position yourself as a thought leader in the industry, content amplification can help you hit those targets. Do remember to stay away from vanity metrics though. Just because a lot of people like a post of yours on LinkedIn doesn't mean they read your article and it's a far cry from them actually making a purchase.</em></p>
<p><em>The best advice I have to ensure you're seeing real results from your content amplification techniques is to choose the right networks and websites to promote your content. You'll first need a clear image of your buyer persona. By analyzing potential customers and their behavior, you'll see where they spend most of their time and, above all, what determines them to make a purchase decision. Then, all you have to do is craft the right messaging revolving around the benefits they're looking to get and stay consistent on a couple of networks of choice. Feel free to include the same terms and pain points they use and remember to be responsive so the conversation is bidirectional."</em></p>
<p><strong><em><a href="https://mktodyssey.wordpress.com/">Alexandra Cote</a>, B2B and SaaS Content Writer and SEO Strategist</em></strong></p>
<p>Building a content amplification strategy</p>
<p><span>Of course, it’s easy …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</a></em></p>]]>
            </description>
            <link>https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649266</guid>
            <pubDate>Thu, 01 Oct 2020 10:10:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Proposed Standard to ensure secure time on the Internet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649121">thread link</a>) | @fogihujy
<br/>
October 1, 2020 | https://www.netnod.se/time-and-frequency/new-proposed-standard-to-ensure-secure-time-on-the-internet | <a href="https://web.archive.org/web/*/https://www.netnod.se/time-and-frequency/new-proposed-standard-to-ensure-secure-time-on-the-internet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                  
                
            <p>Stockholm, Sweden - 1 October 2020 - The Proposed Standard for Network Time Security (NTS) has today been published by the IETF as RFC8915. This comes at the end of a five year development process. As one of the leading figures in NTS, Netnod has worked on all stages of NTS development from the IETF standard to software and hardware implementations at client and server levels. The publication of the NTS Proposed Standard as an RFC marks an important milestone in the development of secure time on the Internet.&nbsp;</p>
      
        
            <div><p><span><span><span><span><span><span><span>The current standard for receiving time information over the internet, the Network Time Protocol (NTP), was created in 1985</span></span></span></span></span></span></span><span><span><span><span><span><span>. Over the last 35 years, a number of issues as well as some high-profile attacks have shown that NTP needs an increased level of security. The new Network Time Security (NTS) standard has been designed to fix that.</span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>NTS uses modern cryptography to add an essential layer of security to NTP. It prevents a range of security vulnerabilities including amplification attacks, packet manipulation, and replay attacks. The protection against packet manipulation and replay attacks secures NTP against Man-in-the-Middle (MITM) attacks. MITM attacks are used by malicious actors to sit between the client and the NTP server, forge messages and lie about time. Since many processes are dependent on accurate time, the consequences here are very serious. </span></span></span></span></span></span><span><span><span><span><span><span><span>Everything from establishing encrypted sessions and using DNSSEC to time-stamping financial transactions and preventing online fraud depends on accurate and secure time.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>In March 2015, the first Internet-Draft of the NTS standard was published by the NTP working group in the IETF. Over the next 5 years, the draft went through 28 further iterations until </span></span></span></span></span></span><a href="https://datatracker.ietf.org/doc/draft-ietf-ntp-using-nts-for-ntp/" target="_blank"><span><span><span><span><span><span><span><span>the Internet Draft ‘Network Time Security for the Network Time Protocol’ </span></span></span></span></span></span></span></span></a><span><span><span><span><span><span>was approved as a Proposed Standard in March 2020. Following some time in the RFC editor queue and final approval from the authors, </span></span></span></span></span></span><a href="https://www.rfc-editor.org/info/rfc8915" target="_blank"><span><span><span><span><span><span><span><span>the RFC proper </span></span></span></span></span></span></span></span></a><span><span><span><span><span><span>has today been published.</span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>“The publication of </span></span></span></span></span></span><span><span><span><span><span><span><span>RFC8915 is an important moment both for the development of NTS</span></span></span></span></span></span></span><span><span><span><span><span><span> and for security on the Internet in general,” said Lars Michael Jogbäck, Netnod CEO. “Netnod is proud to have been at the forefront of developing the NTS standard and implementations. We will continue to focus on services such as NTS to make the Internet as secure and robust as possible for everyone.”</span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>Netnod provides NTP, NTS and Precision Time Protocol (PTP) services offering a robust, reliable and highly accurate source for time and frequency traceable to official Swedish time UTC(SP). Netnod’s time service, funded by the Swedish Post and Telecom Authority (PTS), uses a distributed timescale on multiple, autonomous sites throughout Sweden to provide a time service available over IPv4 and IPv6. Each site has full redundancy: multiple servers, caesium clocks, and FPGA boards provide an extremely fast hardware implementation of NTP. The service is available to the general public worldwide for free on ntp.se, which resolves to anycast IPv4 and IPv6 addresses. The NTS-enabled service is available at: nts.ntp.se. More information about Netnod’s NTS service is available </span></span></span></span></span></span><a href="https://www.netnod.se/time-and-frequency/network-time-security"><span><span><span><span><span><span><span><span>here</span></span></span></span></span></span></span></span></a><span><span><span><span><span><span>. </span></span></span></span></span></span><span><span><span><span><span><span><span>&nbsp;</span></span></span></span></span></span></span></p>
<p><span><span><span><strong><span><span>About Netnod</span></span></strong></span></span></span></p>
<p><span><span><span><span><span><span>Netnod provides critical infrastructure support ranging from interconnection services and Internet Exchanges to DNS services, root server operations, and time and frequency services. With a worldwide reputation for its services and the expertise of its staff, Netnod ensures a stable and secure Internet for the Nordics and beyond.Established in 1996 as a neutral and independent Internet infrastructure organisation, Netnod is fully owned by the non-profit foundation TU-stiftelsen (Stiftelsen för Telematikens utveckling). More information is available at:</span></span></span></span></span></span><a href="http://www.netnod.se/"><span><span><span><span><span><span><span><span> www.netnod.se</span></span></span></span></span></span></span></span></a></p>
</div>
      
        

      </div></div>]]>
            </description>
            <link>https://www.netnod.se/time-and-frequency/new-proposed-standard-to-ensure-secure-time-on-the-internet</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649121</guid>
            <pubDate>Thu, 01 Oct 2020 09:43:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are secrets in Git such a threat?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649034">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secret-sprawl | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secret-sprawl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What are secrets in the software development world?</p><div><p>In the common language, a secret can be any sensitive data that we want to keep private. When discussing secrets in the context of software development, secrets generally refer to digital authentication credentials that grant access to systems or data. These are most commonly API keys, usernames and passwords, or security certificates.</p><p>Secrets exist in the context of applications that are no longer standalone monoliths. Applications nowadays rely on thousands of independent building blocks: cloud infrastructure, databases, SaaS components such as Stripe, Slack, HubSpot…&nbsp;</p><p>Secrets are what tie together these different building blocks of a single application by creating a secure connection between each component.</p></div><p>What is secret sprawl?</p><div><p>Secret sprawl is the unwanted distribution of secrets like API keys and credentials through multiple systems.&nbsp;</p><p>In modern software development, secrets are regularly used by developers and applications. As a result they often get shared through different services like Slack or email and can be stored in multiple locations including different machines, git repositories or inside company wikis. This is a phenomenon we call secret sprawl.</p></div><p>What are some of the best practices to securely manage secrets like API keys?</p><div><p>Storing and managing secrets like API keys and other credentials can be challenging. Even the most careful policies can sometimes be circumvented in exchange for convenience. We have put together a helpful <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">cheat sheet</a> and article explaining the <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">best practices for managing secrets</a>.</p><p>As a minimum here are some points you should consider:</p></div><div><p>Never store unencrypted secrets in git repositories</p></div><div><p>Avoid git add * commands on git</p></div><div><p>Add sensitive files in .gitignore</p></div><div><p>Don’t rely on code reviews to discover secrets</p></div><div><p>Use automated secrets scanning on repositories</p></div><div><p>Don’t share your secrets unencrypted in messaging systems like Slack</p></div><div><p>Store secrets safely (method to be used depends on every use case)</p></div><div><p>Default to minimal permission scope for APIs</p></div><div><p>Whitelist IP addresses where appropriate</p></div><p>What are the threats associated with secret sprawl?</p><div><p>When secrets are sprawled through multiple systems it increases what is referred to as the ‘attack surface’. This is the amount of points where an unauthorized user could gain access to your systems or data. In the case of secret sprawl, each time a secret enters another system it is another point where an attacker could gain access to your secrets.</p><p>Most internal systems are not an appropriate place to store sensitive information, even if those systems are private. No company wants credit card numbers in plaintext in databases, PII in application logs, bank account credentials in a Google Doc. Secrets benefit from the same kind of protective measures.</p><p>As a general security principle, where feasible, data should remain safe even if it leaves the devices, systems, infrastructure or networks that are under organizations’ control, or if they are compromised. This helps prevent credential stealing, which is a well-known adversary technique described in the MITRE ATT&amp;CK framework:</p></div><p>“ Adversaries may search local file systems and remote file shares for files containing passwords. These can be files created by users to store their own credentials, shared credential stores for a group of individuals, configuration files containing passwords for a system or service, or source code/ binary files containing embedded passwords. ”<br></p><p>Secrets accessed by malicious threat actors can lead to information leakage and allow lateral movement or privilege escalation, as secrets very often lead to other secrets. Furthermore, once an attacker has the credentials to operate like a valid user, it is extremely difficult to detect the abuse and the threat can become persistent.<br></p><p>What are some of the biggest challenges associated with secret sprawl?</p><div><p>Because secrets tie together each component of an application, developers and ops need access to these secrets to build, connect, test and deploy applications. The result is that secrets need to be both tightly wrapped and also widely distributed. </p><p>Enforcing good security practices at the organization level is hard. Developers today can have large turnovers inside companies, be spread through many different teams and geographies. They have a growing number of technologies they must master and are under hard pressure due to shortened release cycles. This makes secret management very complicated and an ever changing challenge. </p><p>This is further complicated when VCS like git are introduced because secrets can be buried deep inside the history. The actual version of source code might look clean, while the history might present credentials that were added than later removed. Any secret reaching the Version Control System must be considered compromised and the presence of valid secrets in the git history presents a threat!</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secret-sprawl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649034</guid>
            <pubDate>Thu, 01 Oct 2020 09:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is it hard to detect API keys in source code?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24649026">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Why is it hard to detect secrets like API keys and other credentials?</p><div><p>Secrets detection is probabilistic—that is to say that it is not always possible to determine what is a true secret (or true positive). Because secrets share very few common, distinctive factors, decisions must be taken by aggregating weak signals to make strong predictions. </p><p>One of the most common factors is that almost all secrets are strings that look random. We call these strings high entropy strings. The issue is that this common factor is not very distinctive: 99% of strings that look random in source code aren’t secrets. They are for example database IDs or other types of false positives. </p><p>Of course, some secrets have fixed patterns: AWS keys often start with AKIA for example. But most secrets do not. The portions of code surrounding them are also very different, depending on what the secrets are used for and how they are used by the developers in the context of specific applications. Usernames and passwords can be used to authenticate in many different ways, and it is really hard to distinguish between real and fake credentials used as placeholders for example. </p><p>All this makes it extremely challenging to accurately capture all true secrets without also capturing false positives. At some point, a line in the sand needs to be drawn that considers the cost of a secret going undetected (a false negative) and compares it to the outcome that too many false positives would create. Different organizations with different people, cultures and workflows will draw different lines!</p></div><p>Why do code reviews fail at finding secrets in source code?</p><p>Code reviews are great overall for detecting logic flaws or maintaining certain good coding practices. But they are not adequate protection for detecting secrets, mostly for two reasons:<br></p><div><p>Reviews generally only consider the net difference between the current and proposed states. Not the entire history of changes. If a commit adds a secret and another one later deletes it, this has a zero net effect that is not of any interest to reviewers. But the vulnerability is there.</p></div><div><p>Reviewers prefer to focus on errors that cannot be automatically detected, like design flaws. As a general principle, security automation should be implemented wherever it can be, so that humans focus on where they bring the most value.</p></div><p>What is a "good" secrets detection algorithm?</p><div><p>Detecting secrets in source code is like finding needles in a haystack: there are a lot more sticks than there are needles, and you don’t know how many needles might be in the haystack. In the case of secrets detection, you don’t even know what all the needles look like!</p><p>Ideally, you want your detection system to achieve at the same time:</p></div><div><p>A low number of false alerts raised. We call this high precision. Precision answers the question: «What is the percentage of the secrets that you detect that are actual secrets?». This question is perfectly legitimate, especially in the context of security teams being overwhelmed with too many alerts.</p></div><div><p>A low number of secrets missed. This is what we call high recall. Considering that a single undetected credential can have a big impact for an organization, some organizations prefer to triage more false alerts but make sure they don’t miss a secret.</p></div><p>Balancing the equation to ensure that the algorithm captures as many secrets as possible without flagging too many false results is an intricate and extremely difficult challenge. Read more on evaluating <a href="https://blog.gitguardian.com/secrets-detection-accuracy-precision-recall-explained/" target="_blank">secrets detection algorithms</a>.<br></p><p>What is a false positive in secrets detection?</p><div><p>A false positive in secrets detection refers to when a secret candidate is wrongly marked as a true secret when it is in fact a non-sensitive string. </p><p>Typical examples of strings that can be mistaken for true secrets are:</p></div><div><p>UUIDs (Universally Unique Identifiers) that are used for example by databases as unique keys.</p></div><div><p>High entropy URLs or file paths. They often contain random strings that look like keys.</p></div><p>Examples of server-side hooks:<br></p><div><p>Test keys. Service Providers sometimes provide developers with a set of test credentials with a very restricted scope so developers can exercise parts of the API without charging their account</p></div><div><p>Public keys. As surprising as it is, a very small number of keys are really meant to be public (like Firebase keys, see this Stack Overflow <a href="https://stackoverflow.com/questions/37482366/is-it-safe-to-expose-firebase-apikey-to-the-public" target="_blank">conversation</a>).</p></div><p>Are secrets detection algorithms language-dependent?</p><p>Secrets detection is, for the most part, not language specific. Of course, there are some subtleties to take into account, like the way variables are assigned in any programming language. But there is no need to support all the different syntaxes in their greatest details. This means that the same algorithms can be applied to any project, in any programming language, without using things like Abstract Syntax Trees.<br></p></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649026</guid>
            <pubDate>Thu, 01 Oct 2020 09:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why automate secrets scanning throughout your SDLC?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649022">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secrets-detection-application-security | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secrets-detection-application-security">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My source code is private, so why is hardcoding credentials in git considered a bad practice?</p><div><p>While private repositories offer some level of protection for your code they still do not have adequate protection to store information as sensitive as secrets. </p><p>Imagine if there was a plain text file with all your credit card numbers within it, you hopefully wouldn’t put this into the companies git repository. Secrets are just as sensitive.</p><p>A few things to consider when storing secrets in private repositories:</p></div><div><p>Source code is made to be duplicated and distributed, therefore lives in multiple places. Source code is a leaky asset and you never know where it is going to end up. It can be cloned to a compromised workstation or server, intentionally or accidentally published in whole or in part, uploaded to your website, released to a customer, pasted in Slack, or end up in your package manager or mobile application...</p></div><div><p>It would just take one compromised developer account to compromise all the secrets they have access to.</p></div><div><p>Hardcoded credentials make it impossible to know what secrets a developer accessed, and very difficult to rotate keys.</p></div><p>Why automate secrets scanning throughout the Software Development Life Cycle (SLDC)?</p><p>While DevOps, Continuous Integration and Continuous Delivery speed up software development, they can also significantly increase security risks.<br></p><p>“DevOps is rapid and requires lots of small, iterative changes. But this increases complexity and opens up a new set of security problems. With DevOps, existing security vulnerabilities can be magnified and manifest themselves in new ways. The speed of software creation can mean new vulnerabilities are created unseen by developers. The solution is to build security monitoring into the DevOps process from the start.”<br></p><p>Greg Day, RSA Conference Organizer (<a href="https://www.securityroundtable.org/the-biggest-cybersecurity-risks-in-2020/" target="_blank">source</a>)<br></p><p>Security now needs to be part of the SDLC from the start, and part of every incremental change. This concept is called Shifting Left, a development principle which states that security should move from the right (or end) of the SDLC to the left (the beginning). A great deal of automation is needed in order to be able to cope with running security checks at each incremental change. &nbsp;Automation helps streamline the detection, alerting and remediation processes and workflows.<br></p><p>How does secrets detection compare with Static Application Security Testing (SAST)?</p><div><p>Secrets detection is often confused with SAST because both scan through static source code. </p><p>SAST is mostly testing control structure, input validation, error handling, etc. Such vulnerabilities like SQL injection vulnerabilities only express themselves the moment the code is deployed. Exposed secrets are unlike these vulnerabilities, because any secret reaching version control system must be considered compromised and requires immediate attention. This is true even if the code is never deployed. </p><p>Implementing secrets detection is not only about scanning the most actual version of your master branch before deployment. It is also about scanning through every single commit of your git history, covering every branch, even development or test ones.</p><p>To conclude, SAST is concerned only with the current version of a project, the version that is going to be deployed, whereas secrets detection is concerned with the entire history of the project.</p></div><p>What are git hooks?</p><div><p>Git hooks are scripts that are triggered by certain actions in the software development process, like committing or pushing. By automatically pointing out issues in code, they allow reviewers not to waste time on mistakes that can be easily diagnosed by a machine. </p><p>There are client-side hooks, that execute locally on the developers’ workstation, and server-side hooks, that execute on the centralized version control system.</p><p>Examples of client-side hooks:</p></div><p>Examples of server-side hooks:<br></p><p>What is a pre-commit hook?</p><div><p>"The pre-commit hook is run first when committing, before you even type in a commit message. It’s used to inspect the snapshot that’s about to be committed, to see if you’ve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. </p><p>Exiting non-zero from this hook aborts the commit, although you can bypass it with <span>git commit --no-verify</span>. You can do things like check for code style (run lint or something equivalent), check for trailing whitespace, or check for appropriate documentation on new methods."</p></div><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>What is a pre-receive hook?</p><div><p>A pre-receive hook is a script that runs on the server. It performs checks on the content of the push; if it exits non-zero, the push is rejected. You can use this hook to do things like prevent a PR author from merging their own changes, or require commit messages to follow some specific guidelines. </p><p>Be careful when using pre-receive hooks as they are blocking: if the checks don’t pass, the server is not updated.</p></div><p>What is a post-receive hook?</p><p>"The post-receive hook runs after the entire process of pushing code to the server is completed and can be used to update other services or notify users. Examples include emailing a list, notifying a continuous integration server, or updating a ticket-tracking system – you can even parse the commit messages to see if any tickets need to be opened, modified, or closed. This script can’t stop the push process, but the client doesn’t disconnect until it has completed, so be careful if you try to do anything that may take a long time."<br></p><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>Unlike the pre-receive hook, post-receive is non-blocking.<br></p><p>Where in the DevOps pipeline to implement automated secrets scanning? Client-side or server-side?</p><div><p>The earlier a security vulnerability is uncovered, the less costly it is to correct. Hardcoded secrets are no exceptions. If the secret is uncovered after the secret reaches centralized version control server-side, it must be considered compromised, which requires rotating (revoking and redistributing) the exposed credential. This operation can be complex and typically involves multiple stakeholders.</p><p>Client-side secrets detection early in the software development process is a nice-to-have as it will prevent secrets entering the VCS earlier. </p><p>Server-side secrets detection is a must have:</p></div><div><p>&nbsp;Server-side is where the ultimate threat lies. From the server, the code can uncontrollably spread in a lot of different places, with the hardcoded secrets in it.</p></div><div><p>Implementing client-side hooks on an organization level is hard. This is something we have heard many application security professionals claim they are not confident to do, due to the difficulty to deploy and update this on every developer’s workstation.</p></div><div><p>Client-side hooks can and must be easy to bypass (remember secret detection is probabilistic). Usage of client side hooks largely comes down to the individual developers’ responsibility. Hence the need to have visibility over the later stages.</p></div><p>Should secrets detection be blocking or non-blocking in the SDLC?</p><div><p>From our experience, when trying to impose rules that are too constraining, people will bend them, often in an effort to collaborate better and do their job. Security must not be a blocker. It should allow flexibility and enable information to flow, yet enable visibility and control. </p><p>On one hand, security measures will be bypassed, sometimes for the worst. But on the other hand, it is also good sometimes that the developer can take the responsibility to bypass them. </p><p>Because even the best algorithms can fail and need human judgement. Secrets detection is probabilistic: algorithms achieve a tradeoff between not raising false alerts and not missing keys.</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secrets-detection-application-security</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649022</guid>
            <pubDate>Thu, 01 Oct 2020 09:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paralyzed Dutch man can temporarily move and talk again thanks to sleeping pill]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24648831">thread link</a>) | @jacquesm
<br/>
October 1, 2020 | https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/ | <a href="https://web.archive.org/web/*/https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A Dutch man who has been unable to move and speak for eight years due to brain damage, can temporarily do so after taking the sleeping drug Zolpidem.  Brain scans show that the sleeping pill removes an obstacle to these actions, scientists from Radboudumc and Amsterdam UMC report Thursday.</p>
<p>In men, the brain activity for moving and talking is drowned out by the brain activity for the transfer of information.</p>
<p>“You could compare the brain, as it were, to a large string orchestra”, explains fellow researcher Hisse Arnts.  “With Richard (the man, ed.) The first violins play so loud that they drown out the other members of the string orchestra and people can no longer hear each other. Zolpidem ensures that these first violins play more ‘pianissimo’, so that everyone back within time. “</p>
<p>The fact that the man does not go to sleep because of Zolpidem is probably due to the way his brain has become confused, Arnts thinks.  The problem, however, is that the man gets used to the sleeping aid, so that the effect becomes shorter and shorter.  Yet he still receives it regularly and the discovery is a promising starting point for further research.</p>
<p>The man is not the first to return to a normal situation briefly with such a means;  there are similar reports from Italy and South Africa.  But how that is possible has now been determined for the first time on the basis of scans, according to the medical centers.</p>

<p>The man, in his late twenties at the time, suffered a severe lack of oxygen eight years ago due to choking.  He ended up in a nursing home with the very rare diagnosis of akinetic mutism.  Because Richard’s situation seemed hopeless, it was decided to give him the remedy.</p>

</div><p>    .</p></div>]]>
            </description>
            <link>https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648831</guid>
            <pubDate>Thu, 01 Oct 2020 08:48:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648639">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648639</guid>
            <pubDate>Thu, 01 Oct 2020 08:15:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian opposition leader Alexei Navalny describes his poisoning with Novichok]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24648502">thread link</a>) | @FrojoS
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;83eb2320-0da2-4c9c-971a-560530cea088&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;1b58feba-2271-4627-b7a7-d3cd67af0bd7&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg" srcset="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w520_r1.77_fpx28.11_fpy49.98.jpg 520w, https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg 948w" width="948" height="536" sizes="948px" title="Alexei Nawalny" alt="Alexei Nawalny">
</span>
</span>
</span>

</p>
<figcaption>
<p>Alexei Nawalny</p>
<span>
Foto: Peter Rigaud&nbsp;/ DER SPIEGEL
</span>
</figcaption>
</figure>
</div><div>
<p>In his first media interview following his poisoning, Russian opposition leader Alexei Navalny expresses his "tremendous gratitude to all Germans" in an interview with the newsmagazine DER SPIEGEL. In the interview, he says that although he never had close ties to Germany, it was German politicians and Chancellor Angela Merkel who saved his life. He says the doctors at Berlin's Charité University Hospital saved his life for a second time and nursed him back to health. "I know it sounds a bit over the top, but Germany has become a special country for me," Navalny says. Describing the personal visit paid to him by Merkel last week, he says: "I was impressed by the detail she knows about <a href="https://www.spiegel.de/thema/russia_en/" data-link-flag="english">Russia</a> and my case."</p>



<section data-area="contentbox">

</section>
<p>Navalny says he is doing "much better than three weeks ago, and things are getting better each day." The doctors say he could get back to 90 percent of his former self, perhaps even 100 percent, although no one knows for sure. "Basically, I’m a bit of a guinea pig," he says. "There aren’t many people you can observe who are still alive after being poisoned with a nerve agent." Describing the moment in the airplane when the poison started to take effect, Navalny says: "You feel no pain, but you know you’re dying. And I mean, right now. Even though nothing hurts you." You just think: This is the end. "Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you," he told DER SPIEGEL.</p>

<div>
<p>"I assert that <a href="https://www.spiegel.de/thema/vladimir_putin_en/" data-link-flag="english">Putin</a> was behind the crime, and I have no other explanation for what happened." Despite the attempt on his life, he says he wants to return to Russia. "And my job now is to remain the guy who isn’t afraid. And I’m not afraid! When my hands shake, it’s not from fear – it’s from this stuff. I would not give Putin the gift of not returning to Russia."</p><p>When asked whether he thinks Germany should stop the completion of the Nord Stream 2 Russian gas pipeline project, Navalny didn’t want to answer. "That’s Germany’s business. Decide for yourself!" Any strategy toward Russia must "take into account the level of insanity that Putin has reached."</p>
</div>

<div>
<p><em>The full interview with Navalny will be posted in English later today.</em></p>
<p><span><svg aria-labelledby="title-3bd6ad3a-9ef1-43f3-a948-e2e8657f3575" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-3bd6ad3a-9ef1-43f3-a948-e2e8657f3575">Icon: Der Spiegel</title><g id="l-s-flag-3bd6ad3a-9ef1-43f3-a948-e2e8657f3575"><path id="vector-3bd6ad3a-9ef1-43f3-a948-e2e8657f3575" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648502</guid>
            <pubDate>Thu, 01 Oct 2020 07:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Checking Out Quest DB]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648455">thread link</a>) | @asafg6
<br/>
October 1, 2020 | https://www.turtle-techies.com/checking-out-quest-db/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/checking-out-quest-db/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
        
        <h4>We decided to check out Quest DB, an open-source Time Series database</h4>
                <h6>
                    By Suresh Regmi, Published 2020-08-31
                </h6>
    </p><div itemprop="articleBody"><h2 id="what-is-quest-db">What is Quest DB?</h2>
<p>QuestDB is an open-source Time Series database that uses a column-oriented storage approach and vectored execution for simple and extremely quick query execution.<br>
It was developed by QuestDB Limited in 2014.<br>
It is written in Java and supports Linux, macOS and Windows as the server operating system.<br>
The query language utilized for QuestDB is SQL (Structured Query Language) alongside its expansion for time series-analysis.<br>
QuestDB depends on the relational data model, normally found in some of the popular relational databases like PostgreSQL, MySQL, SQL Server, Oracle, and so forth which means that each time-series estimation is recorded in its row, with a time field followed by other fields.</p>
<h2 id="features">Features</h2>
<p>Some of the best features of QuestDB are as follows.</p>
<ul>
<li>Time series database with a relational data model.</li>
<li>SIMD optimized analytics</li>
<li>Uses column-oriented storage technologies with each column stored continuously in sequential blocks</li>
<li>It allows columns to be chosen as a designated timestamp to utilize it’s high-performance time series functions</li>
<li>Comes with a built-in SQL optimizer</li>
<li>InfluxDB line and Postgres wire protocol support</li>
<li>Supports time series and relational joins</li>
<li>It supports horizontal partitioning (by timestamps)</li>
<li>Supports ACID</li>
</ul>
<p>The setting up of QuestDB can be done easily by following the <a href="https://questdb.io/docs/introduction/" target="_blank">QuestDB documentation</a><a>.<br>
It runs on port 9000 (by default) and provides a web console to interact with the database. The web console has a schema/table browser, query tool and visualization window where the query results can be shown either in tabular form or using graphs.</a></p><a>
<p>Here is how the web console looks like:</p>
</a><p><a></a><a href="https://www.turtle-techies.com/checking-out-quest-db/image1.png" target="_blank"><img src="https://www.turtle-techies.com/checking-out-quest-db/image1.png" alt="QuestDB web console"></a></p>
<h2 id="how-to-setup-questdb">How to setup QuestDB</h2>
<p>If like me, you want to setup QuestDB for learning or for a development environment, I would recommend using Docker.
Here are the instructions I used:
<a href="https://questdb.io/docs/packages/docker/" target="_blank"> </a><a href="https://questdb.io/docs/packages/docker/">https://questdb.io/docs/packages/docker/</a> </p>
<p>Your other options are:</p>
<ol>
<li>
<p>Using binaries:
For setting up QuestDB using binaries, you can refer to QuestDB's documentation <a href="https://questdb.io/docs/packages/binaries/" target="_blank"> </a><a href="https://questdb.io/docs/packages/binaries/">https://questdb.io/docs/packages/binaries/</a> .</p>
</li>
<li>
<p>Homebrew:
For macOS users, QuestDB is available via Homebrew <a href="https://questdb.io/docs/packages/homebrew/"> </a><a href="https://questdb.io/docs/packages/homebrew/">https://questdb.io/docs/packages/homebrew/</a> .</p>
</li>
</ol>
<h2 id="why-should-you-choose-questdb">Why should you choose QuestDB?</h2>
<p>The one thing I like most about QuestDB is that despite the fact that its engineering is planned from the ground up to be close to the hardware.
It offers advanced execution and is additionally centered around making it simpler for designers to integrate and query.</p>
<p>Following are the reasons you should choose QuestDB</p>
<h3 id="easy-to-set-up-and-use">Easy to set up and use</h3>
<p>QuestDB is a lightweight open-source database and is anything but difficult to set up without any conditions.
It will take just a couple of minutes to download and you can begin playing with it.
Its official website provides detailed technical documentation which makes installation, configuration and running the database very simple.
Its web console enables us to perform real-time analytics with easy visualization using different types of charts like bar, line area etc.</p>
<h3 id="supports-sql">Supports SQL</h3>
<p>One reason for utilizing QuestDB is its SQL-like query language.
On the off chance that you know about SQL, utilizing QuestDB would be simpler as it depends on SQL with its very time-series alterations.</p>
<h3 id="performance">Performance</h3>
<p>Execution is one of the fundamental rules that ought to be thought of while picking the database.
QuestDB offers better execution while managing time-series data like data from IoT gadgets, stock value information and DevOps measurements.
For a database that is new in the TSDB field, it gives seemingly preferable execution over other entrenched time-series databases.</p>
<h2 id="why-questdb-is-not-a-good-choice">Why QuestDB is not a good choice?</h2>
<h3 id="new-to-the-tsdb-ecosystem">New to the TSDB ecosystem</h3>
<p>QuestDB is a less mature product than other time-series databases like TimescaleDB and InfluxDB, which implies that there are a ton of integrations and features that are yet to be worked from the developers’ side.
So if you are searching for a well established time-series database with an extraordinary help network and discussion, QuestDB isn't there yet.</p>
<h3 id="oltp-support">OLTP Support</h3>
<p>OLTP databases require frequent inserts, updates, and deletes with user-defined constraints to be kept up.
If you are intending to utilize a database that likewise supports Online Transaction Processing, QuestDB is not a solid match.</p>
<h2 id="how-does-it-compare-with-other-databases">How does it compare with other databases?</h2>
<h3 id="questdb-vs-sql-databases">QuestDB vs SQL Databases</h3>
<p>QuestDB is like a SQL database (MySQL, Oracle, PostgreSQL) however unique from multiple points of view.<br>
Other relational databases can also handle time-series data but they tend to offer worse performance while dealing with common time-series operations like real-time aggregations of data.</p>
<p>On the other hand, QuestDB is purpose-built for fast storage and processing of time series data.
The data model followed by QuestDB is a relational data model which means that data is stored in a table and each row in a table represents a collection of related values.
It also follows the ACID property and supports joins like relational databases but does not allow user-defined constraints and triggers.</p>
<h3 id="alternatives-to-questdb">Alternatives to QuestDB</h3>
<p>Some of the best alternatives to QuestDB are as follows</p>
<h4 id="influxdb">InfluxDB</h4>
<p>InfluxDB is an open-source time-series database designed for high-availability storage and retrieval of data.<br>
It is a part of the TICK (Telegraf, InfluxDB, Chronograf, Kapacitor) stack and has a non-relational, NoSQL data model. It has SQL-like query language to handle interactions with the data</p>
<h4 id="timescaledb">TimescaleDB</h4>
<p>Built on the top of the Postgres database, TImescaleDB is optimized for fast ingest and complex queries with full SQL support like traditional relational databases.</p>
<h5 id="kdb">KDB+</h5>
<p>KDB+ is also a high performance column-store relational time-series database with in-memory abilities.<br>
It is commonly used to store, analyze and process high-frequency financial time series data.</p>
<p>I hope you enjoyed, and of course as always, feel free to comment or share.<br>
Thank you for reading.</p>
</div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/checking-out-quest-db/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648455</guid>
            <pubDate>Thu, 01 Oct 2020 07:47:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bare-metal programming the tinyAVR 0 microcontrollers]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24648397">thread link</a>) | @unwind
<br/>
October 1, 2020 | https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers | <a href="https://web.archive.org/web/*/https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><h4>All you need is a text editor, a makefile and a USB-serial cable.</h4></div></section><section><div><p><img src="https://www.omzlo.com/uploads/std_attiny-406-macro.jpg" alt=""></p>

<h2 id="introduction">Introduction</h2>

<p>Are you an 8-bit or a 32-bit programmer? </p>

<p>At OMZLO, we have been mainly focussing our development efforts on newer 32-bit Arm-Cortex chips (STM32 and SAMD), which typically offer more RAM, more speed, more peripherals, at a similar or lower price-point than older 8-bit MCUs. But 8-bit MCUs are far from dead. Microchip has notably released a new series of chips, collectively branded as the "tinyAVR 0-series", which offer more modern peripherals than the older AVR chips at a very competitive price point. They seem like the perfect candidate for simple products that don't need all the features and fine-tuning capabilities of the newer 32-bit MCUs. 8-bit MCUs are also substantially simpler to program, which translates into faster development time. </p>

<p>Thanks to the success of the Arduino UNO, there are tons of tutorials online that explain how to program 8-bit Atmega328 microcontrollers and their cousins like the Attiny85 using direct register access, without the Arduino language or any vendor IDE such as Atmel Studio. Just google "atmega328 blinky". All you need is an AVR C-compiler, a text editor, <a href="https://www.nongnu.org/avrdude/">avrdude</a>, and an AVR programmer. Some <a href="https://www.instructables.com/id/Getting-Started-With-the-ATMega328P/">resources</a> even show how to also build the electronics needed to get a basic atmega328 running on a breadboard. However, it's hard to find the same information for these newer "tinyAVR 0" chips.</p>

<p>Of course, Microchip offers all the tools necessary to program these newer "TinyAVR" MCUs with their windows-only IDE. There are also "Arduino cores" for some of these newer "TinyAVR" MCUs that let you program them with the Arduino IDE. But again, if you like to write code for MCUs in "baremetal" style, with your favorite text editor, a makefile, and a c-compiler, there are few resources available online. </p>

<p>In this blog post, we will describe how to program a <a href="https://www.ladyada.net/learn/proj1/blinky.html">blinky</a> firmware on an <strong>Attiny406</strong>, from the ground up, using the simplest tools. Most of the things described here can be easily transposed to other TinyAVR MCUs. Our approach is generally guided toward macOS or Linux users, but should also be applicable in an MS-Windows environment with a few minor changes.</p>

<h2 id="hardware">Hardware</h2>

<p>We decided to play with the <a href="https://www.microchip.com/wwwproducts/en/ATTINY406">Attiny406</a>, with a view of using it in the future to replace the Attiny45 we currently use on the <a href="https://www.omzlo.com/articles/the-piwatcher">PiWatcher</a>, our Raspberry-Pi watchdog. The Attiny406 has 4K of flash space, 256 bytes of RAM, and can run at 20Mhz without an external clock source.</p>

<p>One of the most important differences between the new TinyAVR MCUs and the older classic AVR MCU like the Attiny85 is that the newer chips use a different programming protocol called UPDI, which requires only 3 pins, as opposed to the 6-pin ISP on the classic AVRs.</p>

<p>A little research shows that programming TinyAVRs with UPDI can be achieved with a simple USB-to-serial cable and a resistor, thanks to a python tool called <a href="https://github.com/mraardvark/pyupdi">pyupdi</a>, which suggests the following connection diagram for firmware upload:</p>
<pre>                        Vcc                     Vcc
                        +-+                     +-+
                         |                       |
 +---------------------+ |                       | +--------------------+
 | Serial port         +-+                       +-+  AVR device        |
 |                     |      +----------+         |                    |
 |                  TX +------+   4k7    +---------+ UPDI               |
 |                     |      +----------+    |    |                    |
 |                     |                      |    |                    |
 |                  RX +----------------------+    |                    |
 |                     |                           |                    |
 |                     +--+                     +--+                    |
 +---------------------+  |                     |  +--------------------+
                         +-+                   +-+
                         GND                   GND
</pre>
<h3 id="shematic">shematic</h3>

<p>We created a minimalistic breakout board for the Attiny406. The board can be powered by 5V through USB or a lower 3.3V through dedicated VCC/GND pins. An LED and a button were also fitted on the board. For testing purposes, we decided to embed the 4.7K resistor needed for the UPDI programming directly in the hardware (i.e. resistor <em>R2</em>). 
This gives us the following schematic:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-schematic.png" alt="schematic"></p>

<h3 id="board">Board</h3>

<p>The resulting breakout board is tiny and fits conveniently on a small breadboard. The design files are <a href="https://aisler.net/p/SIEGFIYL">shared on aisler.net</a>.</p>

<p><img src="https://www.omzlo.com/uploads/std_attiny-406-breadboard.jpg" alt=""></p>

<p>Programming the Attiny406 on the board with a USB-serial cable is done by connecting the headers on the board edge:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-prog.png" alt=""></p>

<h2 id="software">Software</h2>

<h3 id="pyudpi">pyudpi</h3>

<p>We installed <strong>pyupdi</strong> following the instructions provided on <a href="https://github.com/mraardvark/pyupdi">their webpage</a>. </p>

<p>We connected our USB-Serial cable to the board with the 4 dedicated UPDI pins available on the board. Our USB-Serial converter shows up as the file <code>/dev/tty.usbserial-FTF5HUAV</code> on a MacOS system.</p>

<p>To test that the programmer recognizes the Attiny406, you can issue a command similar to the following, adapting the path for the USB-serial converter to your setup:</p>
<pre>pyupdi -d tiny406 -c /dev/tty.usbserial-FTF5HUAV -i
</pre>
<p>This should result in the following output if all goes well:</p>
<pre>Device info: {'family': 'tinyAVR', 'nvm': 'P:0', 'ocd': 'D:0', 'osc': '3', 'device_id': '1E9225', 'device_rev': '0.1'}
</pre>
<h3 id="the-c-compiler">The C compiler</h3>

<p>The typical <strong>avr-gcc</strong> available on macOS with <a href="https://brew.sh/">homebrew</a> did not seem to recognize the Attiny406 as a compiler target, so we went off to install the avr-gcc compiler provided by Microchip, which is available <a href="https://www.microchip.com/mplab/avr-support/avr-and-arm-toolchains-c-compilers">here</a>. Downloading the compiler requires you to create an account on the Microchip website, which is a bit annoying. </p>

<p><img src="https://www.omzlo.com/uploads/avr-toolchain.png" alt="AVR toolchain link"></p>

<p>Once downloaded, we extracted the provided archive in a dedicated directory. The <code>bin</code> directory in the archive should be added to the <code>PATH</code> variable to make your life easier. Assuming the downloaded compiler is stored in the directory <code>$HOME/Src/avr8-gnu-toolchain-darwin_x86_64</code>, the PATH can be altered by adding the following line to your <code>.bash_profile</code> file:</p>
<pre>export PATH=$PATH:$HOME/Src/avr8-gnu-toolchain-darwin_x86_64/bin/
</pre>
<p>Newer Attiny MCUs are not supported out of the box by the Microchip <strong>avc-gcc</strong> compiler. You need to download a dedicated <em>Attiny Device Pack</em> from <a href="http://packs.download.atmel.com/">their website</a>, as shown below:</p>

<p><img src="https://www.omzlo.com/uploads/microchip-pack-repository.png" alt="AVR toolchain link"></p>

<p>The resulting downloaded <em>Device Pack</em> is named <code>Atmel.ATtiny_DFP.1.6.326.atpack</code> (or similar depending on versioning). Though the extension is <code>.atpack</code>, the file is actually a zip archive. We changed the extension to <code>.zip</code> and extracted the package in the directory <code>$HOME/Src/Atmel.ATtiny_DFP.1.6.326</code> next to the compiler files. </p>

<h3 id="c-program">C program</h3>

<p>We created the following program that blinks the LED on pin PB5 of our Attiny board at a frequency of 1Hz.</p>
<pre><span>#include &lt;avr/io.h&gt;
#include &lt;util/delay.h&gt;
</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
    <span>_PROTECTED_WRITE</span><span>(</span><span>CLKCTRL</span><span>.</span><span>MCLKCTRLB</span><span>,</span> <span>0</span><span>);</span> <span>// set to 20Mhz (assuming fuse 0x02 is set to 2)</span>

    <span>PORTB</span><span>.</span><span>DIRSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
    <span>for</span> <span>(;;)</span> <span>{</span>
        <span>PORTB</span><span>.</span><span>OUTSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
        <span>PORTB</span><span>.</span><span>OUTCLR</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
    <span>}</span>
<span>}</span>
</pre>
<p>The code looks very similar to what you would see on a classic AVR "blinky" program. One visible change is the use of structures to access various registers of the MCU: e.g instead of setting bits in <code>PORTB</code>, you access <code>PORTB.DIRSET</code>.</p>

<p>The other visible change is the clock setup code <code>_PROTECTED_WRITE(CLKCTRL.MCLKCTRLB, 0)</code>. Out of the box, at reset, the Attiny406 runs at 3.33Mhz, which corresponds to a base frequency of 20Mhz with a 6x clock divider applied. To enable the full 20Mhz speed, the register <code>CLKCTRL.MCLKCTRLB</code> is cleared. Because this register needs to be protected against accidental changes, the Attiny406 requires a specific programming sequence to modify it. Fortunately, this is natively offered by the macro <code>_PROTECTED_WRITE</code>. More details are available in the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/ATtiny406-DataSheet-DS40001976B.pdf">Attiny406 datasheet</a>.</p>

<p>In comparison with an STM32 or a SAMD21, the code is blissfully simple. </p>

<h3 id="makefile">Makefile</h3>

<p>We assume the following directory structure where:</p>

<ul>
<li><code>Src/Atmel.ATtiny_DFP.1.6.326/</code> is the location of the Microchip <em>Device Pack</em></li>
<li><code>Src/attiny406-test/</code> is the directory where the code above is stored in a file called <code>main.c</code></li>
</ul>

<p>Compiling the code can be done by issuing the following command within <code>attiny406-test/</code> directory,:</p>
<pre>avr-gcc -mmcu=attiny406 -B ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ -O3 -I ../Atmel.ATtiny_DFP.1.6.326/include/ -DF_CPU=20000000L -o attiny406-test.elf main.c
</pre>
<p>An <code>-O</code> optimization flag is required to make the <code>_delay_ms()</code> function calls work successfully, as well as defining the variable F_CPU to reflect the expected chip clock speed. The rest of the parameters provide the location of the Attiny406 device-specific files we previously extracted from the <em>Device Pack</em>.</p>

<p>Uploading the firmware to the MCU requires a conversion to the intel HEX format and a call to the <strong>pyupdi</strong> tool. To address all these steps, we created a simple Makefile.</p>
<pre><span>OBJS</span><span>=</span>main.o
<span>ELF</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.elf  
<span>HEX</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.hex
<span>F_CPU</span><span>=</span>20000000L


<span>CFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ <span>-O3</span>
CFLAGS+<span>=</span><span>-I</span> ../Atmel.ATtiny_DFP.1.6.326/include/ <span>-DF_CPU</span><span>=</span><span>$(</span>F_CPU<span>)</span>
<span>LDFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/
<span>CC</span><span>=</span>avr-gcc
<span>LD</span><span>=</span>avr-gcc

all:    <span>$(</span>HEX<span>)</span>  

<span>$(</span>ELF<span>)</span>: <span>$(</span>OBJS<span>)</span>
                <span>$(</span>LD<span>)</span> <span>$(</span>LDFLAGS<span>)</span> <span>-o</span> <span>$@</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>LDLIBS<span>)</span>

<span>$(</span>HEX<span>)</span>: <span>$(</span>ELF<span>)</span>
                avr-objcopy <span>-O</span> ihex <span>-R</span> .eeprom <span>$&lt;</span> <span>$@</span>

flash:  <span>$(</span>HEX<span>)</span>
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-f</span> attiny406-test.hex

read-fuses:
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-fr</span>

clean:
                <span>rm</span> <span>-rf</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>ELF<span>)</span> <span>$(</span>HEX<span>)</span>
</pre>
<p>To compile the code, we simply type <code>make</code>. Uploading is done with <code>make flash</code>. This Makefile can be further enhanced as needed.</p>

<h2 id="conclusion">Conclusion</h2>

<p>With the right tools, baremetal programming on the new TinyAVR MCUs is as simple as on its older AVR cousins. </p>

<p>If you have programming tips for the AVRTiny, please share them with us on <a href="https://twitter.com/OmzloElec">on Twitter</a> or in the comments below.</p>
</div></section><section><div><h4>Comments</h4><div><div><p>Hi, </p>

<p>It's great that …</p></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</a></em></p>]]>
            </description>
            <link>https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648397</guid>
            <pubDate>Thu, 01 Oct 2020 07:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start your open-source venture with AsyncAPI at Hacktoberfest]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648373">thread link</a>) | @derberg
<br/>
October 1, 2020 | https://www.asyncapi.com/blog/hacktoberfest-2020 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/hacktoberfest-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/hacktoberfest.webp" alt="Post cover image"><h2 id="what-is-asyncapi">What is AsyncAPI</h2><p>AsyncAPI is a specification for describing your <a href="https://www.asyncapi.com/docs/getting-started/event-driven-architectures/">event-driven architecture</a>. You are probably using already <a href="https://www.asyncapi.com/docs/getting-started/coming-from-openapi/">OpenAPI/Swagger specification</a> for describing your synchronous RESTful APIs. AsyncAPI is something that supplements OpenAPI. As an example, you should use AsyncAPI when your services do not talk to each other directly but through a message broker.</p><p>In contrast to the OpenAPI Initiative, AsyncAPI Initiative is focused not only on creating and evolving the AsyncAPI specification but also on its tooling. It is a vendor-neutral space for the community to work together on the spec and its tools. We work on tools like specification parsers or docs and code generators.</p><p><iframe src="https://www.youtube.com/embed/pU71J-F7pfI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="what-is-hacktoberfest-and-why-asyncapi-initiative-joins-it">What Is Hacktoberfest And Why AsyncAPI Initiative Joins It</h2><p><a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> is a well-known event that promotes open source contributions. In short, you have the entire October to submit four pull requests to any project you want, and in exchange, you get a super cool t-shirt. Is that it? Is it just for a t-shirt? Nah, the t-shirt is nice but what you also get is easy access to open source world. Maintainers of many projects open up for contributions, and it is a great chance to make your first step to joining this fantastic world.</p><p>AsyncAPI Initiative joins the Hacktoberfest for two main reasons:</p><ul><li>Promote AsyncAPI Initiative as a place where we don't work on the specification only but also build a lot of great tools</li><li>Make it much easier for the community to make the first contribution to one of the AsyncAPI repositories</li></ul><p>In the past, we were also there where you are now, shy and uncertain if we can impact open source community. We want to give you an easy path to take the first baby steps in the world of open source in a welcoming and friendly environment.</p><blockquote><p>Don't forget to <a href="https://hacktoberfest.digitalocean.com/login">sign up</a> to the Hacktoberfest</p></blockquote><p><iframe src="https://www.youtube.com/embed/_1WRr3Ml9t4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="how-can-you-help">How Can You Help</h2><p>There is always a lot of work waiting out there. For the sake of this special event, we prepared around 75 GitHub issues that you can pick up. They represent different areas (for example, JavaScript or HTML), different difficulty (for example, 50 issues are easy), and different repositories. No matter if they are trivial or demanding, all of them are important for us. Even with trivial ones where you, for example, need to remove a semicolon, we will still be super happy because this will improve the quality of the project (SonarCloud reports). In other words, every single issue from <a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">this</a> list is important.</p><h3 id="1-pick-the-right-issue">1. Pick The Right Issue</h3><p><a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">Here</a> you can find a list of all the issues that you can work on. Most of the issues are about code contribution, but not all of them. There are also issues about documentation or CI/CD configuration (we use GitHub Actions). Just pick the issues you want to work on, one at a time, and let us know in the comments section that you want to work on it.</p><p><iframe src="https://www.youtube.com/embed/Iqs_2BiNEEo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h3 id="2-setup-your-environment-and-create-a-first-pull-request">2. Setup Your Environment And Create A First Pull Request</h3><p>Once you <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">install Git</a> on your machine and get a <a href="https://github.com/join">GitHub account</a>, you need first to decide if you are here just for Hacktoberfest or longer, and make sure if your issue is easy and maybe you can complete it in the GitHub UI. </p><p>In case you are here just for the Hacktoberfest, and you picked easy issues that involve changes only to a single file, there is no need to install Git and complicate your life. GitHub UI enables you to <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-files-in-a-repository/editing-files-in-your-repository">make changes to a single file online</a>.</p><p>In case you:</p><ul><li>want to stay with us longer,</li><li>you picked up an issue where you need to make changes to more than just one file,</li><li>you also need to run the project locally to check if it works</li></ul><p>Then follow <a href="https://github.com/asyncapi/.github/blob/master/git-workflow.md">this</a> short instruction on how to fork the repository and set it up locally.</p><p>Once you are ready with your changes, submit a pull request. Be nice and follow our <a href="https://github.com/asyncapi/.github/blob/master/CODE_OF_CONDUCT.md">code of conduct</a> and make sure your pull request is <a href="https://github.com/asyncapi/.github/blob/master/CONTRIBUTING.md#conventional-commits">described properly</a>.</p><p><iframe src="https://www.youtube.com/embed/BsC5tu4M1rw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="office-hours">Office Hours</h2><p>Do you feel overwhelmed? No need. You can do it. Just take this blog post seriously. </p><p>Trust me when I write that every pull request is crucial for us.
Trust me when I write that we are a welcoming community.
Don't be afraid that you will waste our time. If we would think about it this way, we would not even join the Hacktoberfest.</p><p>Still not sure if you can make it? Don't worry. We want to host office hours throughout the event, 2x a week, 1h long, and different time zones. You can join whenever you want and ask us anything, or do pair programming with us. We start with the first meeting on <a href="https://calendar.google.com/calendar/u/0?cid=dGJyYmZxNGRlNWJjbmd0OG9rdmV2NGxzdGtAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">Tuesday 6th, 8AM UTC</a> and then on the following days:</p><ul><li>Tuesday 6th, 8AM UTC</li><li>Thursday 8th, 4PM UTC</li><li>Tuesday 13th, 8AM UTC</li><li>Thursday 15th, 4PM UTC</li><li>Tuesday 20th, 8AM UTC</li><li>Thursday 22nd, 4PM UTC</li><li>Tuesday 27th, 8AM UTC</li><li>Thursday 29th, 4PM UTC</li></ul><p>You can also join us in a more asynchronous discussion on <a href="https://www.asyncapi.com/slack-invite/">Slack</a>. For updates and latest news, the best is to follow our <a href="https://twitter.com/AsyncAPISpec">Twitter account</a>. </p><h2 id="blooper-reel">Blooper Reel</h2><p>Before you jump to your first contribution, have a look at the making of the videos. It was quite fun.</p><p><iframe src="https://www.youtube.com/embed/anjcF2l0lGs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><p>Enjoy the Hacktoberfest!</p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/hacktoberfest-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648373</guid>
            <pubDate>Thu, 01 Oct 2020 07:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Worst Decision of My Career]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24648256">thread link</a>) | @fribmendes
<br/>
October 1, 2020 | https://subvisual.com/blog/posts/the-worst-decision-of-my-career/ | <a href="https://web.archive.org/web/*/https://subvisual.com/blog/posts/the-worst-decision-of-my-career/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><section><div><div><div><div><div><div>
<p>This is a reflection on software development and complexity. Let's start with
some quotes to make me look smart:</p>
<blockquote>
<p>A complex system that works is invariably found to have evolved from a simple
system that worked. A complex system designed from scratch never works and
cannot be patched up to make it work. You have to start over with a working
simple system -- <em>Gall's law</em></p>
</blockquote>
<p>I only came across this quote recently, but I think that it summarizes what
I've learned these past seven years. Another idea that I've found in a few books
is that programming in isolation is problem-solving, but software engineering
is all about managing complexity. This distinction between programming and
software engineering makes sense to me, probably because of my mental models.
I'm sure we can all disagree on this, but that's not the topic of today.
Complexity is.</p>
<h2>Complexity</h2>
<p>Almost everyone I know in the software industry wants to build products that
solve real and challenging problems. Change the world! The last thing you want
is to build another CRUD application. They are fine, but it gets boring after
a while.</p>
<p>Most of us will get bored without novelty. That's why the software industry has
a recycling mechanism to keep things fresh and interesting for us: every once
in a while a new, or different, language/framework will rise and light the path
for a brighter future, overthrowing the existing standard, demanding that we
learn it to be on top of the game.</p>
<p>We change our tools, but we keep building the same things over and over. I've
been doing this long enough to see that we are just going in circles. Let's be
honest, most of us aren't building life-changing products that wouldn't have
been possible ten years ago, so let's not jump straight into another shiny
technology that just came out and is going to solve all of our problems.</p>
<h2>Solutions, solutions, solutions</h2>
<blockquote>
<p>For a while, the solution to every problem I encountered was a Rails app. --
<em>this one is mine</em></p>
</blockquote>
<p>Over the years, I've seen companies rewrite their products to change languages,
frameworks, or architectures because they were told that the change would make
their product better, run faster, and scale. By the way, you're only a true
Ruby developer after you've heard the question "but does it scale?" at least
one hundred times (kidding, but it'll happen).</p>
<p>Think about it, how many times were you sold a new programming language,
technology, or a concept like microservices, serverless, event sourcing, clean
architecture, micro frontends. There are many preachers in the software world.</p>
<p>At Subvisual, we started using Elixir a lot these past years, so I've learned
a bit about the history of Erlang. If you don't know, Erlang uses the Actor
Model, and the interesting part is that the designers of Erlang only learned
about the Actor Model after having designed Erlang. This is important because
the designers of Erlang didn't start with the intent of applying the Actor
Model; it came as a solution to fault-tolerant distributed programming.</p>
<blockquote>
<p>If all you have is a hammer, everything looks like a nail <em>Abraham Maslow</em></p>
</blockquote>
<p>The designers of Erlang picked the right tool for the job and most of us want
to do the same. Unfortunately, there's usually more than one "tool" that would
be "right," but to know which ones, you need to know what "job" you're solving.
All of us <strong>should</strong> know this, but I keep learning about teams that fail to do
it. There are so many companies, with a handful of experienced developers, that
don't know what they are building, don't have a clear business yet, but their
product is already built on complex architectures and technologies such as
microservices, Kubernetes or event-sourcing.</p>
<h2>Improving</h2>
<p>Every project we start from scratch is an opportunity to do it right. We'll
think to ourselves: <em>This time I won't fall into the same traps! I have learned
my lessons, I've studied the books, and I even met some of my gurus that wrote
them! This time I'll follow "industry standards"!</em></p>
<p><em>I am the "architect"; I will design the perfect system! Without me, none of
this will be possible. Those mindless programmers have no idea what they are
doing. I, and only I, am the true heir of Martin Fowler!</em></p>
<p>This was a bit dramatic, but I needed a break from all of that whining. I know
it's easy to fall into these traps. It's even easier when your company raised
money, and everyone is expecting you to deliver the absolute best product ever
because they are paying you for it! This is why your starting team is so
important; they have to withstand the pressure. They must know that to build
the grand vision, they have to go one step at a time.</p>
<h2>The decision</h2>
<p>I've made many bad decisions, and I've been fortunate enough to suffer the
consequences of those decisions. A lot of developers don't get to experience
consequences, so they never learn.</p>
<p>So what was the worst decision of my career? I don't know. But the title of
this blog post is inspired by something an old colleague said. At the time, we
were working for a product company that reached for event-driven architecture
and event-sourcing too soon. They knew little about their market, and the
choices the software team made were crippling their ability to change. Business
rules were almost set in stone. Migrating data was a pain and the source of
many bugs. And unfortunately, because the team didn't have experience with
event-sourcing, the event store, which kept the state of all services, was also
being used as an event-bus to communicate between services. Because of that, it
was possible to couple one service to the internal state of another, which
happened a lot. This almost invisible coupling made everything worse.</p>
<p>What did we do against such an unpredictable system? We took it apart: merging
services that were too coupled; defining clear boundaries between services;
moving some services away from the event-store into a traditional database;
making some communication channels synchronous; writing integration and
end-to-end tests.</p>
<p>When we were finished it was still an unnecessarily complex system, but it was
one that we could change with some confidence. After that, we defined
a long-term plan for the product's architecture and technology, but we didn't
implement it. We waited for the right moment when something was starting to
slow us down to make a small step in that direction. When the business goals
changed, we changed our long-term plan, and once again made small steps in that
direction when we felt the need for it.</p>
<p>Eventually, complexity found its way again into the codebase, but it was fine
because the codebase was evolving slowing, adding and removing complexity when
necessary.</p>
<h2>Making the right call</h2>
<p>Was that the worst decision of his career? I don't think so. The issue with him
going for event-sourcing and event-driven architecture was that it wasn't the
right moment, but my colleague didn't know that. He thought the goals for the
next years were well defined, but unfortunately, they never are.</p>
<p>Should you use microservices or event-sourcing? Maybe, it depends on the
context and the client. The decisions I make are the best that I can with the
information that I have. For instance, when I'm part of the team that's
starting a product, the technology we pick will depend on how we'll hire: if
you want to build an office in Portugal, we have to make sure we have
developers for that technology available. We have to think things through, and
some things you only learn from experience. This applies to the systems we
design as well. I've seen enough people design around what they believe the
product will become in two years to know that those designs always fail to
accommodate the changes that will come. So we design systems for small,
incremental changes. Do the smallest thing that will get us started and
doesn't compromise our ability to change once we know what the business needs.</p></div></div></div></div></div></div></section></article></div></div></div>]]>
            </description>
            <link>https://subvisual.com/blog/posts/the-worst-decision-of-my-career/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648256</guid>
            <pubDate>Thu, 01 Oct 2020 07:18:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before You Start Coding]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24647918">thread link</a>) | @dinomad
<br/>
September 30, 2020 | https://scorpil.com/post/before-you-start-coding/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/before-you-start-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>Full disclosure: things discussed in this post are, to be frank, quite obvious. My intent is not so much to teach a reader something new, as to remind him what might have been forgotten. After all, anyone who does a single kind of work daily for years inevitably develops habits and mental-shortcuts that are <em>usually</em> useful but can misfire from time to time. After all, software development is too complex and too technical to be guided by subconscious intuition.</p><p>Pilots use pre-flight checks to combat this kind of problem, so why not developers? Here’s a check-list of things I find important to consider <strong>before</strong> writing the first line of code.</p><h3 id="set-your-target-straight">Set your target straight</h3><p>Imagine yourself solving these tasks:</p><ul><li>generating a single-use report for an established company</li><li>writing a feature in proof-of-concept MVP for a startup</li><li>extending at enterprise product that has 20 years of codebase support guarantee in its SLAs</li></ul><p>Clearly, it wouldn’t be smart to blindly apply the same set of software development best-practices for all three cases. You probably don’t need a perfectly polished code for a single-use report. A startup that operates in the “rush to market before we run out of money" mode is much more worried about the feature working than about its performance. Long-support code needs to be first and foremost maintainable. Also, if you’re working on a pet-project for fun, you might gasp skip writing tests (unless you enjoy writing tests, in which case I envy you a little bit). Some developers take so much pride in their craft that they lose sight of the forest behind the trees. Following all best practices and writing state-of-the-art code <em>feels</em> right, but logically it’s not the only option. Sometimes you should consciously generate technical debt. Reality constraints are not something that can be ignored.</p><p>As self-evident as this advice is, we’ve all heard stories where things went wrong because of misaligned goals. “Premature optimization” is a common special case. Refactoring an old codebase that rarely changes, just so it’s pretty, is another one. And to not leave you with the thought that goal misalignment is always linked to perfectionism: writing an unsupportable code to meet a <em>fictional</em> deadline, either self-imposed or forced on to developers by impatient management, is the same kind of error.</p><p>You need to know where to go before you can start thinking about how to get there. Think of the most important criteria your solution needs to fulfill and align your decision-making with those.</p><h3 id="consider-alternatives">Consider alternatives</h3><p>You’ve got the task in front of you, requirements are pretty clear, and you vaguely remember how you did something similar a few years before. Or maybe you don’t know how to solve it at first, but after some googling, you get a general idea. Start coding?</p><p>There are always multiple ways to solve a problem. The first viable solution is unlikely to be an optimal one. By focusing on the first approach discovered you rob yourself of choice. Do a thorough research first, and after you have options in front of you, carefully consider the pros and cons of each. There is no magical number of solutions you need. I often set the minimum bound to three for myself.</p><p>Selecting the right tool for a job is an obvious example of a decision that benefits from upfront research, and even then, in a real-world scenario, a tool that’s familiar often gets selected over the tool that fits. Don’t think this advice only applies to „macro“ decisions, it can be applied just as well for your everyday code design choices.</p><h3 id="consult-the-docs-yes-upfront">Consult the docs. Yes, upfront</h3><p>It’s impossible to keep up with the pace modern tech is moving. Doesn’t matter how many years of experience you have under your belt, when you pick up the project on a modern stack there will be tools and libraries, released recently, that have slipped under your radar. So most developers are in a constant in-flight-learning mode: picking up knowledge as they search answers on immediate questions. It’s an efficient way to learn, but it creates a risk of missing an easy solution because of the inability to form the right question.</p><p>Skimming the docs upfront, without digging deep into any particular topic, doesn’t take much time, but it helps create mental anchors, which your brain will fetch when you encounter the problem. You will have a better starting point for finding the right answer quickly.</p><h3 id="design-your-apis">Design your APIs</h3><p>The hardest part of writing code is to imagine in the minutest details how to handle each workflow, each exceptional situation, and each edge case. Many developers first solve a problem, then write a „wrapper“ to expose their work to the outside world through some kind of API (i don’t mean just REST API, function signatures and interfaces are APIs as well). Often this bottom-up design leads to an API that’s too „technical“, i.e. leaking it’s abstractions to the consumer. It’s hard to make your brain switch from one level of abstraction to another.</p><p>Before starting the work on implementation, put yourself in the shoes of the API user first (even if that user is you). What would be the user’s most common usage pattern? What’s the absolute minimal required set of parameters the API needs to have? Which terminology makes sense for the user? What input format would be most convenient? What defaults to set? It’s up to you how thorough you want this process to be.</p><h3 id="split-up-the-work">Split up the work</h3><p>Each entity in a system exponentially increases the number of possible interactions. Code that’s easy to reason about forms a pyramid of abstraction layers, each one hiding its inner workings from the layer above. Each layer can be reasoned about independently, limiting the amount of „moving parts“ you need to keep track of in your brain. If you succeed in splitting the task into multiple loosely coupled entities upfront, you will simplify your code and work process.</p><p>If the task at hand is large enough, it might make sense to form a tree-like task structure, starting from the highest level of abstraction and moving down the layers until the tasks are small enough. The „small enough“ parameter depends on your particular codebase, mindset, and type of work you do, but after a bit of practice, you’ll find what granularity suits you the best.</p><p>Each task should be fairly self-sufficient and ideally shouldn’t stay in “kinda-finished” state for long (“finished but not deployed”, “finished but not reviewed”, “finished but not tested” or “finished but waiting for authorization from XYZ department”). Finished is when you don’t think about it anymore and it doesn’t drain your mental resources.</p><p><img src="https://scorpil.com/img/tree.png" alt="Example of a task tree"></p><p>Do you have your own tips and tricks for organizing developer’s work? Please share!</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/before-you-start-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647918</guid>
            <pubDate>Thu, 01 Oct 2020 06:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Allowed to Write Slow Rust Code]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24647910">thread link</a>) | @ingve
<br/>
September 30, 2020 | https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/ | <a href="https://web.archive.org/web/*/https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post">
    
    
    <article>
        <p>There's a thing that comes up from time to time in the Rust community: people wanting to optimize their code. Make the code run faster. Make it allocate less memory. These are worthy goals, but maybe not necessary for all projects. Just because your program is written in Rust, it doesn't have to be optimized to the moon and back to do it's job. In a lot of cases, you'll be fine using <code>.clone()</code>.</p>
<p>There's a fantastic quote from a discussion on the <a href="https://users.rust-lang.org/">Rust user forums</a> which I always think of when these discussions emerge:</p>
<blockquote>
<p>Just because Rust allows you to write super cool non-allocating zero-copy algorithms safely, doesn't mean every algorithm you write should be super cool, zero-copy and non-allocating.<br>
-- <a href="https://users.rust-lang.org/t/feeling-rust-is-so-difficult/29962/15">trentj on The Rust Programming Language Forum</a></p>
</blockquote>
<p>Of course there's a time and place for <em>super cool no-allocating zero-copy algorithms</em>, but very often it's not the time, nor the place. You can write fantastically effective code with Rust, but <strong>you don't have to</strong>! A lot of the time it's entirely fine to just write code that works with minimal effort. You don't have to spend 4 days trying to figure out how lifetimes work just to avoid calling <code>.clone()</code> a few times.</p>
<p>Don't spend time trying to make micro optimizations now. Take the easy route. You'll probably come back to that piece of code in a few months time, smile, and change that <code>.clone()</code> to something more efficient.</p>
<p>Happy coding!</p>
<p><small>NB: Watch this <a href="https://youtu.be/rAl-9HwD858">video by Jon Gjengset</a> if you want a good, pragmatic walk through of lifetimes in Rust.</small></p>

    </article>
</div></div>]]>
            </description>
            <link>https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647910</guid>
            <pubDate>Thu, 01 Oct 2020 06:19:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designed IOS14 Icons to to fight the screen time, clutter and visual fatigue]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24647737">thread link</a>) | @hren
<br/>
September 30, 2020 | https://hren.io/products/iso14-home-screen-icons-set/ | <a href="https://web.archive.org/web/*/https://hren.io/products/iso14-home-screen-icons-set/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As IOS14 allows the customization of the home screen with the Shortcuts app, this icon set tries to fight the screen time, clutter and fatigue by minimizing visuals.</p><p>The goal is to also lover the Screen Time by only limited to one screen.</p><p>More icons will be added. For icon requests DM on<!-- --> <a href="https://twitter.com/@darjanhren" target="_blank">Twitter</a>.</p><p><a href="https://gum.co/wIROw" target="_blank">Get Calm Icon Set</a></p></div></div></div>]]>
            </description>
            <link>https://hren.io/products/iso14-home-screen-icons-set/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647737</guid>
            <pubDate>Thu, 01 Oct 2020 05:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running GitHub Actions for Certain Commit Messages]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24647722">thread link</a>) | @kiyanwang
<br/>
September 30, 2020 | https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages | <a href="https://web.archive.org/web/*/https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
                <section>
        
        <p>A quick look at how you can configure your GitHub Actions workflows to only run when a certain phrase is present in the commit message.</p>
                    <small>Published 3 days ago</small>
                            <span>|</span>
                <small>Updated 3 days ago</small>
                                                <p><span>
    Tooling
</span>
 
                                     <span>
    GitHub Actions
</span>
 
                            </p>
                        <article>
            <p>I'm going to be honest with you all for a second. I write a lot of <code>wip</code> commits. These commits are normally small changes that I want to push up to GitHub so that:</p>
<ol>
<li>I don't lose things if anything goes wrong and my backup hasn't picked it up.</li>
<li>If I can't describe the change I have just made.</li>
<li>If I'm demonstrating something to somebody on a pull-request.</li>
</ol>
<p>The problem is, my actions are setup to run on <code>push</code>, so every single <code>wip</code> commit gets run through the CI process, whether it be running tests, linting or formatting.</p>
<p>After doing some research, I found a way of preventing these from running on every single commit.</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"! contains(github.event.head_commit.message, 'wip')"</span>
</code></pre>
<p>Now, whenever I push a <code>wip</code> commit or any commit that contains the word <code>wip</code>, it will be marked as skipped inside of GitHub actions.</p>
<p>You could also flip the logic and perhaps do something like:</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"contains(github.event.head_commit.message, '[build]')"</span>
</code></pre>
<p>Any commit that contains <code>[build]</code> will now trigger these jobs, everything else will be skipped.</p>
<p>You can thank me later! 😉</p>

        </article>
    </section>
        </div>
    </div></div>]]>
            </description>
            <link>https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647722</guid>
            <pubDate>Thu, 01 Oct 2020 05:41:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Literal String Matching in Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24647210">thread link</a>) | @boyter
<br/>
September 30, 2020 | https://boyter.org/posts/faster-literal-string-matching-in-go/ | <a href="https://web.archive.org/web/*/https://boyter.org/posts/faster-literal-string-matching-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>TL/DR:</strong> I wrote a fast literal string matching library in Go get it here <a href="https://github.com/boyter/go-string/">https://github.com/boyter/go-string/</a></p>
<p>Recently I rebuilt <a href="https://searchcode.com/">searchcode</a> in Go, as <a href="https://boyter.org/posts/searchcode-rebuilt-with-go/">mentioned</a>.</p>
<p>While there was a variety of reasons for this one was that performance in the previous Python version was not great. Please note this was mostly due to my own shortcomings and not the language itself. However I have always used searchcode as a test bed for interesting problems, since it gets enough traffic to verify things at scale, and I wanted to get better at Go.</p>
<p>One of the main performance hotspots in searchcode has always been finding lines to display based on the search query and then highlighting them. While most search index tools can do this for you, I have always done this myself, because I want to control whats displayed as I find it an interesting problem to solve.</p>
<p>It sounds simple, for some search terms “sally sea shell” find all the locations of inside a string “Sally sells sea shells by the sea shore” and then wrap them in a tag. This seems to be a trivial, since all you need a <code>indexOf</code> in a loop and some string splitting and insertion.</p>
<p>I had previously written about some of the issues with the above when writing about <a href="https://boyter.org/posts/unicode-support-what-does-that-actually-mean/">unicode support</a> with the relevant portion below,</p>
<blockquote>
<p>At which point you go, fine i’ll just search for all case variants of Java and use that to work things out, and then realise adding case folding is a small addition to what you just wrote and working with just bytes to save time was a red-herring.</p>
</blockquote>
<p>The generally always correct answer to case insensitive matching is to use Regular Expressions. However there can be issues with it. Firstly the regular expression engine in Go is slower than you think, and for matching string literals its a very large hammer for a smallish nail.</p>
<p>So I wrote my own implementation which does the same thing but without touching the regular expression engine <a href="https://github.com/boyter/go-string/">https://github.com/boyter/go-string/</a> thus making it much faster than using FindAllIndex for the majority of cases.</p>
<p>Talk is cheap… show me the benchmarks. Included below is the output from a small application I wrote. A small program which you supply a search string and a filename. I have tested it against a 550MB file. First it runs case insensitive search using FindAllIndex in the regex package, then against IndexAllIgnoreCase my own implementation. The number on the end of each line is the number of matches found.</p>
<pre><code>$ ./csperf ſecret 550MB
File length 576683100

FindAllIndex (regex ignore case)
Scan took 25.403231773s 16680
Scan took 25.39742299s 16680
Scan took 25.227218738s 16680

IndexAllIgnoreCase (custom)
Scan took 2.04013314s 16680
Scan took 2.019360935s 16680
Scan took 1.996732171s 16680
</code></pre><p>Note using the long s, <code>ſ</code> in the search term so both solutions are unicode aware!</p>
<p>The results speak for themselves. The case insensitive search is considerably faster. For pure literal case insensitive searches based on wall clock time it can be 10 times faster. I also added an implementation of <code>IndexAll</code> for case sensitive matches saving you from having to do your own logic there or again falling back to regular expressions, although its speedup will depend on your needle and haystack.</p>
<p>If you are curious about I did this read on. Otherwise feel free to just suck down the library and use it. It’s published under either MIT or The Unlicense so be as liberated as I can make it. There is also some other useful functions in there such as the highlight function which I am not going to discuss here.</p>
<p><strong>So how does it work?</strong></p>
<p>The code itself is reasonably <a href="https://github.com/boyter/go-string/blob/master/index.go#L98">well commented</a> so you may want to just read the code.</p>
<p>In short it copies some techniques from tools like ripgrep.</p>
<p>When looking at string matching algorithms, you run into algorithms such as Boyer-Moore, Aho-Corasick and Rabin-Carp. It may then surprise you to learn that Go’s implementation of strings.Index does not use them, well at least not till the needle is over 64 characters when 64 bit compiled where it starts to use Rabin-Carp, presumably as a CPU cache line optimisation.</p>
<p>What strings.Index actually does a simple loop through each byte checking for a match, and then when one is found starts checking against the needle. This means it does not do any byte skipping which Boyer-Moore does! Naturally, I was appalled by this and looked for a Boyer-Moore implementation to swap it out for. Turns out there is one inside the Go codebase which made me very curious. Why was it not used? Well after trying a few implementations each turned out to be much slower than the simple one Go uses. As it turns out, that implementation compiles down to fancy vector instructions on modern CPU’s. It’s pretty hard to beat silicon with algorithms, unless you algorithm happens to be massively more efficient so there was no trivial gains to be made there with a fancy algorithm.</p>
<p>So what actually happens in the code is that it takes the needle, and uses the first 3 characters (if over 3 characters long) to create a string of every possible case. So <code>foo</code> would return the following strings <code>foo Foo fOo FOo foO FoO fOO FOO</code>. It then searches using each one of those cases and collecting all the resulting matching locations. For strings over 3 characters (note characters, not bytes so it is unicode aware for simple case fold rules), as mentioned the first 3 characters are used, and then when a possible match is found the rest of the characters are checked to see if there is actually a match before recording the location.</p>
<p>In theory Aho-Corasick would be faster than the above as you could use maybe the first 4 characters and use that for matching each byte, however I was not going for extreme performance, but something much faster than regular expressions. Also its reasonably simple to follow, while leveraging the Go SDK which is a massive win in my opinion.</p>
<p>The result is currently running in searchcode. This replaces what was the slowest portion of the code in the old version of searchcode and is much faster reducing the load on the servers considerably. Every string runs through the implementation and as such its fairly battle tested. It might not be perfect, but there has been no crashes to date with the v1.0.0 tag release so it should be reasonably safe to use, but of course there is no warranty. As mentioned a few times the code is open and on github, so feel free to bash against it <a href="https://github.com/boyter/go-string">https://github.com/boyter/go-string</a> and report bugs! If you do run into an interesting case where you use it let me know and ill add it to the README.</p>

</div></div>]]>
            </description>
            <link>https://boyter.org/posts/faster-literal-string-matching-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647210</guid>
            <pubDate>Thu, 01 Oct 2020 03:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prime and battery usage on Linux laptops: sometimes it's not what it seems to be]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646504">thread link</a>) | @todsacerdoti
<br/>
September 30, 2020 | https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/ | <a href="https://web.archive.org/web/*/https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://wiki.archlinux.org/index.php/PRIME">PRIME</a> is a technology used to manage hybrid graphics. It was meant to be a resource saver since you can configure it to use only the Integrated GPU, and render offload to the dedicated GPU whenever is needed. But that is not what happened in my real life situation.</p>

<p>I was not happy with the fact that my laptop was draining a lot of battery. Not only while using render offload by running software with <code>prime-run</code> and delegating gpu stuff to my dGPU(Nvidia MX150), but using the iGPU(i915 Intel) to daily stuff(terminal, browser) was also draining a lot of battery. Overheating was also a problem and then, i started to investigate.</p>
<p>Using <code>powertop -t 3</code> shown that Firefox was draining as much as <code>800 mW</code> per process(tab) on the <code>Power Est.</code> column. Meanwhile, <code>i915</code> module was using about <code>150 mW</code> alone. That got me thinking if, using the dedicated GPU to render stuff would get it better, but it didn’t. Launching Firefox with <code>prime-run</code> reduced a little the power usage per tab (opening the same websites), but the Intel module was still draining almost the same amount of power(<code>145 mW</code>) while the <code>nvidia</code> module was using <code>35mW</code>.</p>
<p>Other thing that bugged me was that my system always started with a lot of RAM already compromissed(<code>900MB</code>) on a simple <code>i3</code> setup. Could be the case where my iGPU was already allocating a lot of that resource to itself?</p>
<p>After that, i’ve decided to try some 3D, and <a href="https://veloren.net/">Veloren</a> was the game i’ve chosen. Those were the metrics captured with my status bar and <code>powertop</code>:</p>
<ul>
<li>
<p>Using <code>i915</code> driver:</p>
<ul>
<li>Driver drain reached <code>400mW</code>.</li>
<li><code>1,9 GB</code> Ram used</li>
<li>Battery expected duration after full charge was <code>1:28</code>.</li>
</ul>
</li>
<li>
<p>Using <code>nvidia</code> driver with <code>prime-run</code>.</p>
<ul>
<li><code>i915</code> driver was still draining <code>200 mW</code> approximately, spiking to <code>400</code> sometimes.</li>
<li><code>nvidia</code> driver was using about <code>50mW</code>, spiking to <code>80</code> once in a while.</li>
<li><code>1,7 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>Battery expected duration after full charge was <code>1:12</code>.</li>
<li>nvidia temperature reached <code>73ºC</code>.</li>
</ul>
</li>
</ul>
<p>I know that this doesn’t seems to be a fair test, comparing a dGPU with an iGPU while executing a game. The point I was trying to prove was: Using the render offload didn’t really help on reducing resource consumption at all. On the oposite, it seems that it somehow helped me to have resources wasted by doubling energy consumption due to this binding created between modules with the <a href="https://wiki.archlinux.org/index.php/PRIME#PRIME_render_offload">render offload</a> feature.</p>

<p>I was decided to try a new approach and use <a href="https://wiki.archlinux.org/index.php/NVIDIA_Optimus#Use_NVIDIA_graphics_only">Nvidia graphics only</a>. Setup was pretty straightforward and after rebooting, I’ve launched Firefox with the same sites and <code>Power Est.</code> was about <code>570mW</code> per process. Good news, lets try Veloren again:</p>
<ul>
<li>Using <code>nvidia</code> driver only
<ul>
<li><code>nvidia</code> driver was using about <code>120mW</code>.</li>
<li>Battery expected duration after full charge was <code>1:47</code>.</li>
<li><code>1,3 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>nvidia temperature reached <code>67ºC</code>.</li>
</ul>
</li>
</ul>
<p>That’s a lot better. I also noticed that my system was using only <code>500MB</code> RAM after a fresh start(a <code>400MB</code> difference).</p>
<p><strong>Lesson learned.</strong> Try things by yourself when it comes to power management.</p>

<p>Other things changed on my system after spending the weekend optimizing energy stuff:</p>
<ul>
<li>Not using <a href="https://github.com/tobi-wan-kenobi/bumblebee-status"><code>bumblebee-status</code></a> anymore. It’s a great bar, full of useful modules, but it was creating some weird spikes on power usage. Migrated to <a href="https://github.com/greshake/i3status-rust/"><code>i3status-rust</code></a> and now my bar isn’t even listed on the top 20 power usage agressors.
<ul>
<li>All previous tests were done using the same bar.</li>
</ul>
</li>
<li><code>telegram-desktop</code> is a mess on power and cpu usage and i’m seriously thinking on ditching this software and using it’s web version only. Firefox is a software I already use so, there’s nothing to lose.</li>
<li>Try to get used with some lightweight browser like <a href="https://qutebrowser.org/">qutebrowser</a> while on battery, and stop using my bookmark sync of choice. Have to test since not having video acceleration could be a caveat.</li>
<li>Find out why while using specific softwares <code>pulseaudio</code> gets crazy and it spikes with <code>4W</code> of Power Estimated usage.</li>
</ul>
  </div></div>]]>
            </description>
            <link>https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646504</guid>
            <pubDate>Thu, 01 Oct 2020 02:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mouth Dreams]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646471">thread link</a>) | @bangonkeyboard
<br/>
September 30, 2020 | http://www.neilcic.com/mouthdreams/ | <a href="https://web.archive.org/web/*/http://www.neilcic.com/mouthdreams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.neilcic.com/mouthdreams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646471</guid>
            <pubDate>Thu, 01 Oct 2020 02:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Voice Assistant Spoke to Google Duplex. Here’s What Happened]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646421">thread link</a>) | @xingyzt
<br/>
September 30, 2020 | https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/ | <a href="https://web.archive.org/web/*/https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				
													<p><img src="https://www.polyai.com/wp-content/uploads/2019/08/nikola-1-500x500.jpg"></p><div>
							<h6>Nikola Mrkšić</h6>
							<p><span>
								23 Sep 2020								- 5 minutes read							</span>
						</p></div>
						
										
				</div>
			</div><div>
									<p>This summer, Google has been deploying its AI voice assistant called Duplex to call bars and restaurants in order to update their opening hours on Google Maps listings.<br>
Here’s a call their system had with our virtual assistant for restaurants.</p>
<p><iframe src="https://player.vimeo.com/video/460586741" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span></iframe></p>
<p>As far as we’re aware, this is the <strong>first naturally-occurring conversation between AI voice assistants in the wild</strong>. I have never seen anything like this before, and I’m incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.</p>
<p>After listening to the call, we’d say that it went pretty well! Google could have handled the two-part opening hours a bit better, but overall, the interaction was smooth. I want to share a few thoughts on what this means for the future of conversational technologies.</p>
<h3>Human language is a Universal API</h3>
<p>This interaction did not need to be a conversation in the way that we as humans think of it. The caller’s request was transactional and to the point. An API call or an HTTPS request between two web services would have done the job in 150ms, instead of two minutes of synthesized voice going back and forth across the telephone line. However, such APIs are not always available, or standardised. For instance, there are dozens of reservation APIs for restaurants used in the UK alone, and voice assistants will never integrate with every single one.</p>
<p>This kind of machine-to-machine conversational communication will become more commonplace as AI deployment accelerates. And while it may seem like an overkill from a technical standpoint, there are good reasons for these kinds of interactions to be conversational, rather than API calls.</p>
<p>Imagine you ask your virtual assistant — Siri or Alexa, for example — to book a hotel room. It can phone multiple hotels to check availability and book without having to integrate into each hotel’s individual booking API. And logs of the conversation can inform the user of alternative venues for their next trip.</p>
<h3>Welcome to the Uncanny Valley</h3>
<p>Google introduced <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex in May 2018</a> as an ‘AI system for accomplishing real-world tasks over the phone’. You may have seen this video of <a href="https://www.youtube.com/watch?v=D5VN56jQMWM">Sundar Pichai at Google I/O</a> using Duplex to make a restaurant reservation.</p>
<p>I’ll be the first to point out how incredible Google’s TTS (text-to-speech) is in the Duplex/PolyAI call. It sounds like a human, much more so than our assistant does.</p>
<p>According to the <a href="https://en.wikipedia.org/wiki/Uncanny_valley">Uncanny Valley theory</a>, the more human-like a robot is, the more likely people are to feel positive towards it. However, at a certain point of human-likeness, the robot becomes a bit creepy, and people are repulsed by it.</p>
<p><img src="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png" alt="" width="588" height="387" srcset="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png 588w, https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley-300x197.png 300w" sizes="(max-width: 588px) 100vw, 588px"></p>
<p>In the Google/PolyAI call, Duplex really does sound like a human – it does mention that it’s an automated service, but this is not enough. Why? Because crossing the Uncanny Valley means that a person on the call will treat the bot as though they are human.</p>
<p>Around the 1 minute mark, you’ll hear our voice assistant ask the caller when they’d like to come in, and Duplex speaks over it. In reality, these are machines – no-one’s getting offended. But when you listen to the call, the Duplex bot comes across as pretty rude. Because it sounds so human, it’s practically impossible to not attribute human qualities to the bot. And no one wants a rude voice assistant representing their company.</p>
<p><strong>Making customers think that your voice assistant is a real human is a sure-fire way to deliver frustrating customer experiences. At PolyAI, we work hard to make sure our voice assistants sit at the peak right before the Uncanny Valley – but without crossing it. Warm and friendly enough to put callers at ease, but not real enough to cause cognitive dissonance.</strong></p>
<h3>The Future of Voice</h3>
<p>Companies are wising up to the benefits of conversational AI in customer communications, and we’ll see a growing number of instances of machines communicating in human language. While this type of transactional communication may seem better suited to quick API calls, voice assistants can get the job done even when such APIs are not available.</p>
<p>We are super excited about the future of voice assistants. Two highly sophisticated voice assistants have now met in the wild, in a rerun of the legendary “Dr Livingstone, I presume” moment (though neither assistant realised they were speaking to one of their own). This is a sign of great things to come. Stay tuned – and get in touch with us if you want to build a great voice assistant for your brand.</p>
<p><strong>What do you think of the PolyAI vs Google Duplex call? Let us know on Twitter, <a href="https://twitter.com/poly_ai">@poly_ai</a>.</strong></p>
							</div></div>]]>
            </description>
            <link>https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646421</guid>
            <pubDate>Thu, 01 Oct 2020 01:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Grand Design by Stephen Hawking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646120">thread link</a>) | @got-any-grapes
<br/>
September 30, 2020 | https://blas.com/the-grand-design/ | <a href="https://web.archive.org/web/*/https://blas.com/the-grand-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<!-- #masthead -->

	<div id="main">

	<div id="primary">
		<div id="content" role="main">

			
				
	<article id="post-5144">
				<!-- .entry-header -->

				<div>
			
<p>Summary</p>



<ol><li>Traditionally these are questions for philosophy, but philosophy is dead. Philosophy has not kept up with modern developments in science, particularly physics. Scientists have become the bearers of the torch of discovery in our quest for knowledge. The purpose of this book is to give the answers that are suggested by recent discoveries and theoretical advances. They lead us to a new picture of the universe and our place in it that is very different from the traditional one, and different even from the picture we might have painted just a decade or two ago.</li></ol>



<p>Key Takeaways</p>



<ol><li>According to the traditional conception of the universe, objects move on well-defined paths and have definite histories. We can specify their precise position at each moment in time. Although that account is successful enough for everyday purposes, it was found in the 1920s that this “classical” picture could not account for the seemingly bizarre behavior observed on the atomic and subatomic scales of existence. Instead it was necessary to adopt a different framework, called quantum physics. Quantum theories have turned out to be remarkably accurate at predicting events on those scales, while also reproducing the predictions of the old classical theories when applied to the macroscopic world of daily life. But quantum and classical physics are based on very different conceptions of physical reality.</li><li><strong>We will explain Feynman’s approach in detail, and employ it to explore the idea that the universe itself has no single history, nor even an independent existence. That seems like a radical idea, even to many physicists. Indeed, like many notions in today’s science, it appears to violate common sense. But common sense is based upon everyday experience, not upon the universe as it is revealed through the marvels of technologies such as those that allow us to gaze deep into the atom or back to the early universe.</strong></li><li><strong>To deal with such paradoxes we shall adopt an approach that we call model-dependent realism. It is based on the idea that our brains interpret the input from our sensory organs by making a model of the world. When such a model is successful at explaining events, we tend to attribute to it, and to the elements and concepts that constitute it, the quality of reality or absolute truth. But there may be different ways in which one could model the same physical situation, with each employing different fundamental elements and concepts. If two such physical theories or models accurately predict the same events, one cannot be said to be more real than the other; rather, we are free to use whichever model is most convenient.</strong><ol><li><em>Model-dependent realism, mental models</em></li></ol></li><li><strong>M-theory is not a theory in the usual sense. It is a whole family of different theories, each of which is a good description of observations only in some range of physical situations. It is a bit like a map. As is well known, one cannot show the whole of the earth’s surface on a single map. The usual Mercator projection used for maps of the world makes areas appear larger and larger in the far north and south and doesn’t cover the North and South Poles. To faithfully map the entire earth, one has to use a collection of maps, each of which covers a limited region. The maps overlap each other, and where they do, they show the same landscape. M-theory is similar. The different theories in the M-theory family may look very different, but they can all be regarded as aspects of the same underlying theory. They are versions of the theory that are applicable only in limited ranges—for example, when certain quantities such as energy are small. Like the overlapping maps in a Mercator projection, where the ranges of different versions overlap, they predict the same phenomena. But just as there is no flat map that is a good representation of the earth’s entire surface, there is no single theory that is a good representation of observations in all situations.</strong><ol><li><em>The Mp is Not the Terrain</em></li></ol></li><li>Today most scientists would say a law of nature is a rule that is based upon an observed regularity and provides predictions that go beyond the immediate situations upon which it is based.<ol><li><em>General and broadly applicable</em></li></ol></li><li>Because it is so impractical to use the underlying physical laws to predict human behavior, we adopt what is called an effective theory. In physics, an effective theory is a framework created to model certain observed phenomena without describing in detail all of the underlying processes.</li><li>There is no picture- or theory-independent concept of reality. Instead we will adopt a view that we will call model-dependent realism: the idea that a physical theory or world picture is a model (generally of a mathematical nature) and a set of rules that connect the elements of the model to observations. This provides a framework with which to interpret modern science.</li><li><strong>We make models in science, but we also make them in everyday life. Model-dependent realism applies not only to scientific models but also to the conscious and subconscious mental models we all create in order to interpret and understand the everyday world. There is no way to remove the observer—us—from our perception of the world, which is created through our sensory processing and through the way we think and reason. Our perception—and hence the observations upon which our theories are based—is not direct, but rather is shaped by a kind of lens, the interpretive structure of our human brains.</strong><ol><li><em>Mental Models, Galilean Relativity</em></li></ol></li><li><strong>A model is a good model if it: Is elegant, Contains few arbitrary or adjustable elements, Agrees with and explains all existing observations, Makes detailed predictions about future observations that can disprove or falsify the model if they are not borne out.</strong></li><li>Another of the main tenets of quantum physics is the uncertainty principle, formulated by Werner Heisenberg in 1926. The uncertainty principle tells us that there are limits to our ability to simultaneously measure certain data, such as the position and velocity of a particle. According to the uncertainty principle, for example, if you multiply the uncertainty in the position of a particle by the uncertainty in its momentum (its mass times its velocity) the result can never be smaller than a certain fixed quantity, called Planck’s constant. That’s a tongue-twister, but its gist can be stated simply: The more precisely you measure speed, the less precisely you can measure position, and vice versa.</li><li><strong>In other words, nature does not dictate the outcome of any process or experiment, even in the simplest of situations. Rather, it allows a number of different eventualities, each with a certain likelihood of being realized.</strong></li><li>Given the state of a system at some time, the laws of nature determine the probabilities of various futures and pasts rather than determining the future and past with certainty.</li><li><strong>Quantum physics tells us that no matter how thorough our observation of the present, the (unobserved) past, like the future, is indefinite and exists only as a spectrum of possibilities. The universe, according to quantum physics, has no single past, or history. The fact that the past takes no definite form means that observations you make on a system in the present affect its past.</strong></li><li>Electric and magnetic forces are far stronger than gravity, but we don’t usually notice them in everyday life because a macroscopic body contains almost equal numbers of positive and negative electrical charges. This means that the electric and magnetic forces between two macroscopic bodies nearly cancel each other out, unlike the gravitational forces, which all add up.</li><li>Maxwell’s equations dictate that electromagnetic waves travel at a speed of about 300,000 kilometers a second, or about 670 million miles per hour. But to quote a speed means nothing unless you specify a frame of reference relative to which the speed is measured. That’s not something you usually need to think about in everyday life. When a speed limit sign reads 60 miles per hour, it is understood that your speed is measured relative to the road and not the black hole at the center of the Milky Way. But even in everyday life there are occasions in which you have to take into account reference frames. For example, if you carry a cup of tea up the aisle of a jet plane in flight, you might say your speed is 2 miles per hour. Someone on the ground, however, might say you were moving at 572 miles per hour. Lest you think that one or the other of those observers has a better claim to the truth, keep in mind that because the earth orbits the sun, someone watching you from the surface of that heavenly body would disagree with both and say you are moving at about 18 miles per second, not to mention envying your air-conditioning.<ol><li><em>Galilean Relativity</em></li></ol></li><li>Electromagnetic forces are responsible for all of chemistry and biology.</li><li>The histories that contribute to the Feynman sum don’t have an independent existence, but depend on what is being measured. We create history by our observation, rather than history creating us. The idea that the universe does not have a unique observer-independent history might seem to conflict with certain facts we know. There might be one history in which the moon is made of Roquefort cheese. But we have observed that the moon is not made of cheese, which is bad news for mice. Hence histories in which the moon is made of cheese do not contribute to the present state of our universe, though they might contribute to others. That might sound like science fiction, but it isn’t.</li><li>What makes this universe interesting is that although the fundamental “physics” of this universe is simple, the “chemistry” can be complicated. That is, composite objects exist on different scales. At the smallest scale, the fundamental physics tells us that there are just live and dead squares. On a larger scale, there are gliders, blinkers, and still-life blocks. At a still larger scale there are even more complex objects, such as …</li></ol></div></article></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blas.com/the-grand-design/">https://blas.com/the-grand-design/</a></em></p>]]>
            </description>
            <link>https://blas.com/the-grand-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646120</guid>
            <pubDate>Thu, 01 Oct 2020 01:08:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Computer Dungeon Slash Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646063">thread link</a>) | @panic
<br/>
September 30, 2020 | https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem | <a href="https://web.archive.org/web/*/https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-article_id="496">


    

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image2.png"></p>


        

    


<p>I consider <a href="https://museumofzzt.com/file/c/CDZ20MOZ.ZIP" target="_blank"><i>Computer Dungeon Slash: ZZT 2.0</i></a> my personal best for ZZT games. I've now released two versions, one in September of 2019 and then another with some updates and optimizations in May of 2020. Aside from a couple of smaller errors and special-thanks additions, there's not much more to fix, so this will probably be the final version with any major changes.</p>

<p>Like some of my previous ZZT games, it relies heavily on procedural generation, with apparently such complexity that Dr. Dos called it "basically sorcery" during their <a href="https://museumofzzt.com/article/479/livestream-computer-dungeon-slash-zzt-20">playthrough on Twitch</a>, which I took as a great compliment. He also mentioned that this game, its generators in particular, could use a write-up. So I wrote one!</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image24.png"></p>

<p>In case you're reading this and unfamiliar with this game, it concerns a player finding themselves in the town of Habeas Corpus, where almost everyone and everything has been swallowed by the dungeon.</p>

<p>The player's task is to brave the randomly-generated dungeon, rescuing the town and townspeople from its clutches.</p>

<p>There's not much more plot or lore than the above, since I focused mainly on characterization in my worldbuilding and most of the actual plot isn't revealed until the end.</p>

<p>So what about the workings of this game?</p>

<p>I'll start with "sorcery"--there's something to that, for sure. When I work with procedural generation it feels a bit like alchemy. Scientific, but also a little bit mysterious and magical. I hope this article helps you better understand the scientific side of that coin.</p>

<p>For readers not intimately familiar with ZZT, one reason a veteran ZZTer would call my level generation "sorcery"  is its limitations. ZZT is a 1991 DOS game-creation-system, after all, simple enough for 8-year-old me to use. So if you don't know anything about ZZT coming in, I hope this write-up helps you better understand the absurdity and appeal of working in it and pushing its limits.</p>

<p>Further, if you came into this wanting to know how this stuff works so that you can experiment with it or even improve on it, I want you to be empowered to do so.</p>

<h2>Goals</h2>

<p>With <i>Computer Dungeon Slash: ZZT</i> (called <i>CDZ</i> here for short) I had three goals for generation. I wanted levels to be interesting to look at, fun to play, and fair. What does fair mean?</p>

<p>Most previous ZZT releases with procedural generation would probably not soft-lock players (block them off from finishing the game). In the early 2000s when this fad hit, most ZZTers involved were in high school and "probably not" was enough. But that small chance of soft-locking players with my generators annoyed me even then.</p>

<p>With <i>CDZ</i>, I wanted some certainty that my algorithms absolutely would not soft-lock players.</p>

<p>With these goals in mind, let's look at the tools I had to accomplish them.</p>

<h2>Building Blocks for Procedural Level Generation in ZZT</h2>

<p>ZZT is tile-based, so making it create its own levels is kind of like generating dungeons for classic ASCII roguelikes, except with much more restrictive tools and limits than, for example, C++ or Python. There's no way to easily store level layout data outside of "in the level", and ZZT boasts precious few variables and only ten true-or-false flags. In addition, the entire game is made up of "boards" of only 60x25 tiles! Despite being such a limited system, ZZT lets us do a fair amount.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image4.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image7.gif"></p>

<p>Almost any element (terrain or other object) that takes up a space on a board is helpful, but a few basic ones are laid out in a reference image on the left. Fake walls prove pretty invaluable because they don't block objects but help the engine easily keep track of where another terrain type <i>will</i> later appear.</p>

<p>While <i>CDZ</i> uses sliders and boulders to some extent, the classic examples of ZZT level generators using sliders and boulders are probably WiL's <i>Run-On</i> and Benco's <i>Lost</i>.</p>

<p>And of course, one of the elements of play is actually <i>called</i> an object, and can run little scripts in ZZT-OOP, the engine's default "language." ZZT-OOP has a number of helpful commands for procedural generation.</p>

<p>The <code>#change</code> command can change almost any ZZT gameplay element into almost any other, which is invaluable both for structuring and theming levels. <code>#put THING DIRECTION</code> and <code>#become THING</code> allow for level builder objects to modify environments directly, and they have a more complex use we'll go into later.</p>

<p>Procedural level generation in <i>CDZ</i> is random. Appropriately, ZZT-OOP's random directions proved immensely useful in making it happen. A number of situations call for a "four-sided" dice-roll, and ZZT does have an <i>rnd</i> direction (randomly north, south, east, or west), but as the reader may know, <i>rnd</i> is twice as likely to give an east-west result as a north-south. So what to do?</p>

<p>Well, there are also <i>rndne</i> (north or east) and <i>rndp DIRECTION</i> (one of two directions perpendicular to <i>DIRECTION</i>). Because <i>rndne</i> is a valid direction in itself, you can use <i>rndp rndne</i> to get a random cardinal direction with equal probability of each. (I'm ashamed that I didn't realize that one until reading Anna Anthropy's <i>ZZT</i> a few years back.)</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image14.gif"></p>

<p>In ZZT, <code>#if blocked DIRECTION</code> tells an object whether it is blocked in a given direction. And <code>#send OBJECTNAME:LABEL</code> tells another object, <i>OBJECTNAME</i>, to immediately begin executing code starting with <i>:LABEL</i>.</p>

<p>Slime enemies move erratically and leave breakable walls behind, so you can change their color frequently to fill empty spaces with different colors of breakable walls.</p>

<p>One last limitation and one last "coding" trick deserves mention. ZZT has a limit of about 20 kilobytes per board (including code) before the board misbehaves or gets corrupted at runtime. Objects can use the command <code>#bind OBJECTNAME</code> to work from the same exact instance of the same code as the other object <i>OBJECTNAME</i>, saving valuable code space.</p>

<p>Nowadays, one can "pre-bind" objects with external editors, causing them to share identical labels and behaviors but eliminating the need for the 5+ bytes of space that a <code>#bind</code> command needs.</p>

<h2>Two Big Insights</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image18.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image20.png"></p>

<p>In addition to the more concrete "tools" above, two big conceptual insights greatly impacted this project. The first is about level connectedness, and it hit me after reading Rabbitboots's musings on house generation in <a href="https://museumofzzt.com/file/d/dood2018.zip" target="_blank"><i>Doodads 2018</i></a>.</p>

<p>Say I have a house with four rooms, and I block off only one doorway in the house, as on the left. Any room in the house can still visit any other.</p>

<p>Rabbitboots goes on to note that if we make a larger house out of smaller ones, the large house remains fully connected.</p>

<p>If House A connects to House B and B connects to House C, then A connects to C.</p>

<p>This was huge for me. It gave me hope that I could avoid soft-locks while also making more interesting, varied levels.</p>

<p>Shortly after the 2019 release, while looking at TriphEd's maze generation in <a href="https://museumofzzt.com/file/b/BACKTRAX.zip" target="_blank"><i>Backtrax</i></a>, I had another "Aha!" moment.</p>


<p>The algorithm is best explained step-by-step, and you can follow along with the following roughly equivalent method if you have a pencil and paper.</p>

<p>(1) Start with a grid of dots. Any size 3 x 3 or up will do.</p>

<p>(2) Connect all the outer dots along the edge so that they make a rectangle.</p>

<p>(3) For each "middle dot" within the square, draw <i>exactly one line</i> from that dot to any dot directly above, below, left, or right of it. Edge dots can receive lines.</p>

<p>If you used a 3 x 3 grid of dots, the end result will resemble the 2 x 2 house above.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/backtrax-levels.gif"></p>

<p>Any edge tile can access any other edge tile in this algorithm. It can leave some squares inaccessible from the edges, but this is acceptable if nothing essential to player progress is placed in those tiles.</p>

<p>In ZZT, you can accomplish this by having objects use <code>#put rndp rndne ELEMENT</code> on a grid, and that's exactly what <i>Backtrax</i> is doing.</p>

<p>A <i>very</i> small set of soft-lock possibilities does exist in <i>Backtrax</i>. Because there's a blocking linewall diagonally southeast of the lower-right-hand wall generator object, the wrong combinations of walls <i>could</i> block the player, but it is <i>incredibly</i> unlikely and easily remedied.</p>

<p>This is the most elegant level generator in ZZT to date--and also, in case it wasn't already elegant enough, it weighs in at only 10.9 kilobytes and re-uses its "grid" after you reach the exit, using a separate trick (that I won't discuss in detail here) to teleport the player back to the start for a new level.</p>

<p>Recognize TriphEd's genius.</p>

<p>After the initial <i>CDZ</i> release, I experimented a lot with this algorithm. Several generators in version 2.0 benefited from its use. We can now move slowly but surely into the actual inner workings of this game.</p>

<h2>Primary Generators</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image6.png"></p>

<p><i>Computer Dungeon Slash</i> level generators have a "primary generator" object that handles a lot of needed dice-rolls and uses <code>#send</code> to communicate its randomization to different groups of objects. It's usually set up as on the left, or similar.</p>

<p>This particular setup involves fake walls placed north, south, east, and west of the primary generator and water (a blocking terrain) in the four corners. To make a four-direction roll, it uses <code>#put rndp rndne gem</code> and then iterates over some variation of:</p>

<code>#if blocked n #send object:option1
#if blocked e #send object:option2
#if blocked s #send object:option3
#if blocked w #send object:option4</code>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image16.png"></p>

<p>The objects referred to in the <code>#send object:option</code> commands  are pre-bound objects with exactly the same code, and positioned so that only one of them will place a wall, generate an important key, etc. at the time they're called. In this example, the pre-bound group of objects has this code:</p><p>

<code>@object
#cycle 1
#end
:option1
#if blocked n become solid
#die
:option2
#if blocked e become solid
#die
:option3
#if blocked s become solid
#die
:option4
#if blocked w become solid
#die</code></p><p>There is a fake wall in the middle of the house, so that only one object becomes a wall, and the rest die. Then the primary generator turns the fake into a solid wall.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image23.gif"></p>

<p>This method also extends to larger houses similar to those in the <i>Doodads 2018</i> example, and can …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</a></em></p>]]>
            </description>
            <link>https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646063</guid>
            <pubDate>Thu, 01 Oct 2020 00:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario doctors sign letter to Premier advising against sweeping lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 148 (<a href="https://news.ycombinator.com/item?id=24645821">thread link</a>) | @mrfusion
<br/>
September 30, 2020 | https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html | <a href="https://web.archive.org/web/*/https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>



<div>
    
        <p>Published Sept. 30, 2020 9:40 a.m. ET</p>
        <p>Updated  Sept. 30, 2020 7:26 p.m. ET</p>
    
</div>



  


    
        
        
    
    
    <amp-iframe resizable="" width="16" height="17" layout="responsive" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation" allowfullscreen="" frameborder="0" src="https://ampvideo.ctvnews.ca/content/ctvnews/en/local/ottawa/2020/9/30/1_5126193.vidi.root-responsivegrid-vidicomponent.html?preventDefault=true">
        
        <p>Click to Expand</p>
    </amp-iframe>





    <p>OTTAWA -- 	Twenty-one Ontario doctors have signed a joint letter to Premier Doug Ford, urging him not to issue a new lockdown this fall because of rising COVID-19 case numbers.</p><p>	Daily numbers of new cases have risen dramatically in recent days, with Ontario recording <a href="https://toronto.ctvnews.ca/new-covid-19-cases-in-ontario-reach-highest-mark-ever-1.5122863" target="_blank">700 new cases of COVID-19 on Monday</a> – the highest number of new cases recorded in a single day.</p><p>	However, the 21 doctors who signed the letter to the premier say another provincewide lockdown—similar to what was in place in the spring—would not be helpful.</p><ul>	<li>		<a href="#Full letter"><i>Read the full letter below</i></a></li></ul><p>	"We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario," the letter says.&nbsp;</p><p>	"Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions."</p><p>	Speaking on Newstalk 580 CFRA's "The Morning Rush with Bill Carroll" in Ottawa, CTV's infectious disease specialist Dr. Neil Rau—a signatory of the letter—pointed to two data points to consider when looking at the spread of COVID-19.</p><p>	"We're reacting to increased aggregate case numbers, but the percentage positive is not really as bad as it used to be," he said. "We're testing more people, so we're finding more cases […] We're driving our numbers up, it's worse than it was in the summer, but it's not what it was last winter and life has to go on."</p><ul>	<li>		<a href="https://www.iheartradio.ca/580-cfra/podcasts/the-morning-rush-dr-neil-rau-interview-why-we-don-t-want-another-lockdown-1.13612912?mode=Article" target="_blank"><strong>LISTEN NOW: "The Morning Rush": Dr. Neil Rau - Why we don't want another lockdown</strong></a></li></ul><p>	Monday's 700 cases in Ontario came from 41,111 total tests, for a positive percentage rate of 1.7 per cent. On April 24, <a href="https://toronto.ctvnews.ca/highest-number-of-new-covid-19-cases-in-a-single-day-reported-by-ontario-health-officials-1.4910216" target="_blank">the previous watermark of 640 new cases in a single day</a>, the result came from 12,295 tests, for a positive percentage rate of 5.2 per cent.</p><p>	Testing capacity was lower in the spring than it is now, and testing criteria has changed over time; however, Dr. Rau and the other signatories of the letter said the increasing case numbers are not leading to unmanageable levels of hospitalizations.</p><p>	"In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions," the letter says.</p><p>	The letter also points to other health impacts linked to the lockdown.</p><p>	"Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined," the letter states.</p><p>	"Economic harms are health harms," Dr. Rau told CFRA. "It sounds horrible to say, but it's true. Health is wealth. We all know this."</p><h2>	<strong>LETTER POINTS TO DISAGREEMENT AMONG HEALTH PROFESSIONALS</strong></h2><p>	Other Ontario health professionals have been arguing for increased restrictions as cases rise.</p><p>	Last week, the Ontario Hospital Association released a letter signed by 38 health professionals which <a href="https://ottawa.ctvnews.ca/ontario-hospital-association-calls-for-return-to-restrictions-on-non-essential-businesses-1.5119832" target="_blank">called for immediate restrictions to be re-imposed on non-essential businesses</a>, such as gyms, dine-in restaurants and bars, nightclubs, and theatres. It also calls on restrictions on other places where people can gather, such as places of worship.</p><p>	The letter from the OHA said regions where the speed of transmission was underestimated are “now facing the consequence of increased hospitalization rates, including a rise in intensive care unit (ICU) admissions and more deaths.”</p><p>	Hospitalizations in Ontario have been increasing, but have not yet reached the same level that was seen in the spring.</p><p>	According to <a href="https://covid-19.ontario.ca/data" target="_blank">data from the Ontario government</a>, there were 128 people in hospital in Ontario with COVID-19 complications on Monday—the day 700 new cases were recorded—up from 65 a week before; however, on April 24—when 640 new cases were recorded—government data shows that there were 910 people in hospital. The peak for hospitalizations in Ontario came in May, when there were days when more than 1,000 people were hospitalized. That number steadily decreased from May through the summer before it began going up again in September.</p><p>	Speaking on CTV Morning Live Ottawa, infectious disease specialist Dr. Abdu Sharkawy suggested t<a href="https://ottawa.ctvnews.ca/video?clipId=2045684" target="_blank">emporary restrictions on gathering would help curb the spread of COVID-19</a>.&nbsp;</p><p>	"We don't want to see our hospitals overwhelmed," he said. "We're still waiting for flu season and a whole bunch of other respiratory viruses to hit us and our capacity to be challenged. We don't want that to happen. We need everybody to try and simplify their lives and minimize anything that's non-essential."</p><p>	Dr. Sharkawy said regions where cases are rapidly rising may need to impose new restrictions to get the spread of the virus under control.</p><p>	"I think it's abundantly clear that, particularly in hot spots like Ottawa, Toronto and Peel region, the situation is not well controlled," he said. "Sometimes you need blunt instruments, even if they're temporary in nature, to make sure that you curtail the spread of this virus because it gets away from us a lot more quickly than many of us can anticipate sometimes."</p><p>	Dr. Sharkawy suggested hot spots follow the lead of Quebec, which imposed <a href="https://montreal.ctvnews.ca/life-in-the-red-zone-here-s-what-you-can-and-can-t-do-1.5125093" target="_blank">harsh restrictions on three areas in the province</a>, including Montreal and Quebec City, banning private gatherings and closing bars and restaurant dining rooms.</p><p>	"I think we should do it now," Dr. Sharkawy said of Ontario. "I think we all need to adopt an attitude and an approach that recognizes that we have to do what's absolutely necessary to keep everybody safe."</p><h2>	<strong>FULL LETTER FROM ONTARIO DOCTORS TO THE PREMIER</strong></h2><p>	Dear Premier Ford,</p><p>	We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario. Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions.</p><p>	In Ontario the increase in cases at this time are in people under 60 years of age who are unlikely to become very ill. At the peak of the pandemic in Ontario in mid-April, 56% of cases were in ≥60 year olds, now in Sept only 14% of cases are in ≥60 year olds. In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions. This is not a result of a lag in reporting of severe and fatal cases. While we understand the concerns that these cases could spill into vulnerable communities, we also need to balance the actual risk. As the virus circulates at manageable levels within the community, we need to continue the gains we have made in the protection of the vulnerable in long-term care and retirement institutions, and continue to educate other people about their individual risk, so that they can observe appropriate protective measures.</p><p>	Lockdowns have costs that have, to this point, not been included in the consideration of further measures. A full accounting of the implications on health and well-being must be included in the models, and be brought forward for public debate. Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined. A huge concern is the implication of closure of schools, and the ongoing reluctance we have seen in the large urban centers of sending children back to the classroom due to safety concerns. Global data clearly now show that children have an extremely low risk of serious illness, but they are disproportionately harmed by precautions. Children’s rights to societal care, mental health support and education must be protected. This cannot be achieved with ongoing or rotating lockdown.</p><p>	The invitation and involvement of other health experts to advise the government’s response beside individuals in Public Health and Infectious Diseases in addition to leaders in the business, securities and arts communities is essential. We also call for increased open debate, in the public forum, that hears voices from outside the medical and public health communities, in order to consider all points of view from society. This is a fundamental principle upon which democratic societies are built. All stakeholders should have an equal right to participation in public discourse when it comes to setting such fundamental and sweeping societal interventions.</p><p>	All have the right to feel their voices have been heard, and moreover to ensure factual credible data is openly debated, in contrast to the personal and political slants that have had apparent significant impacts on the management of the virus to date. Our society has borne enormous pain over the past 6 months. It’s time to do something different.</p><p>	Sincerely,</p><p>	Jane Batt MD, PhD, FRCPC. Respirologist, Associate Professor, Department of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</a></em></p>]]>
            </description>
            <link>https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645821</guid>
            <pubDate>Thu, 01 Oct 2020 00:23:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A housing industry of endless one-offs is holding our society back]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24645525">thread link</a>) | @jseliger
<br/>
September 30, 2020 | https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/ | <a href="https://web.archive.org/web/*/https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><strong>By Aaron Holm and Nelson Del Rio,<br>Co-CEOs, Blokable Inc.</strong></h2><h2>The following post breaks down the high cost of building housing as part of a series exploring the root causes of the U.S. housing crisis and how private and public sector collaboration can chart a different course.&nbsp;</h2><figure><img width="1200" height="800" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjA0OCAxMzY0IiB3aWR0aD0iMjA0OCIgaGVpZ2h0PSIxMzY0IiBkYXRhLXU9IiUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjA5JTJGQmxvZy0yLWltYWdlLTIwNDh4MTM2NC5qcGciIGRhdGEtdz0iMjA0OCIgZGF0YS1oPSIxMzY0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-spai="1" alt="" sizes="(max-width: 1200px) 100vw, 1200px"></figure><p>In mid-2018 we met with Washington State Governor Jay Inslee to discuss the insatiable need for affordable housing in the Pacific Northwest. We gave him a tour of Blokable’s prototype factory in Vancouver, Wash., and shared our R&amp;D work to reimagine how housing is built. Afterward, we drove up to Seattle in a rented Nissan Maxima, wondering aloud what it would cost to build our rental car from scratch in a driveway — exactly how nearly all housing is built today.&nbsp;&nbsp;&nbsp;</p><p>We would have to design, engineer, and fabricate all of the car’s systems and components, specify and source the materials, identify the regulatory requirements and work with different agencies to test our systems and sign off on safety and environmental requirements, create a working set of engineering drawings to track the build, order the equipment necessary to complete the assembly, and hire at least a small team of people to put the car together. A car that retails for just under $35,000 would cost tens of millions of dollars to build, and there would be no guarantees of quality and reliability.&nbsp;</p><p>Every time a new residential real estate project appears on the landscape, it’s a bespoke process that can directly involve hundreds of people, including a developer and a general contractor, various architects and engineers, and the investors who are funding the project. For each participant in the process, the singular goal is to extract a profit from that specific patch of dirt, and their profits are circumscribed by the value of the land, the applicable building regulations, and the prevailing labor and capital costs.&nbsp;</p><p>The result of this one-off approach is soaring project costs that make housing simply unaffordable to most people in many parts of the U.S.. Conventional housing development is like building a snowflake every time. And if the glut of empty luxury condo towers in downtown San Francisco is any indication, many of these snowflake projects are indeed melting as soon as they touch the ground.&nbsp;</p><p>How did this one-off approach to development take shape? Everything from ovens to stereos were all once clunky prototypes built as one-offs in the same location as their eventual use. Over time with innovation, standardization, and market demand, they evolved into products. In the early days of the automobile and aviation industries, prototypes and projects were built at high cost and yielded low quality results that resembled the current market products in their most basic functionality: they could drive and fly. Early automobile and airplane prototypes were unsafe and expensive. But through investment in product design, engineering, prototyping, and manufacturing, these prototypes eventually evolved into products. Increasingly stable designs and specifications enabled greater standardization, repeatability, and mass production resulting in lower costs, higher quality, and broader distribution.&nbsp;</p><p>Coupled with clear market demand, this standardization led to the formation of entire industries to build roads and airports, manufacture tires, test safety under federal guidelines, and so on. If you visit the automotive and aviation manufacturing hubs around Detroit and Seattle you’ll find vibrant supply chains competing for business and investing in innovation to provide better products and services. Continuously improving engines, seats, windshields, and bathrooms. All of this activity creates ever-improving products and fierce competition for performance, quality, and price.&nbsp;&nbsp;</p><p>If we compare product manufacturing in the automotive and aviation industries to how we build housing — whether it is an Accessory Dwelling Unit (ADU), single family home, multi-family apartment building, or a high rise — the steps in the process are largely the same. To simplify the housing development process, let’s assume the land is entitled, there are no environmental mitigation issues, financing is secured, and development will not be opposed by regulatory agencies or local city council. What does it take to build a snowflake?</p><figure><img width="1200" height="800" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjA0OCAxMzY0IiB3aWR0aD0iMjA0OCIgaGVpZ2h0PSIxMzY0IiBkYXRhLXU9IiUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjA5JTJGQmxvZy0yLWJvZHktaW1hZ2UtMjA0OHgxMzY0LmpwZyIgZGF0YS13PSIyMDQ4IiBkYXRhLWg9IjEzNjQiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-spai="1" alt="Housing creation is an endless series of one-offs" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><em>Conventional housing development is like building a snowflake every time.</em></figcaption></figure><p>Let’s look at the absolute bare minimum of steps in the process from the perspective of the developer. Broadly speaking, the developer identifies and ties up the site, conducts preliminary site review and discussions with impacted parties, manages entitlements, financing, and the project approval process for the site, oversees all building and owns the project along with any equity investors they have brought in to finance the deal. With respect to the building process itself, the developer will partner with an architect to work up a site massing and design that will satisfy the intended program — the mix of units, floorplans, common spaces, revenue generating and non-revenue generating space — as well as the code requirements for the building and the site. Once the basic architecture is in place, the project heads over to engineers, which are typically separate firms with separate contracts, costs, regulatory oversight, and liability, to specify structural engineering, MEP (mechanical, electrical, plumbing), and site and offsite engineering.&nbsp;</p><p>With the initial design and engineering complete, the developer sends a construction set of drawings to a general contractor (GC) for final pricing. The GC will take the specifications and build out a schedule and budget to determine how much work they intend to do themselves (self-perform) vs. how much work they will contract out to sub-contractors (subs). The GC will oversee all of the work necessary to build this custom-designed and engineered project on-site, including civil, foundation, pulling utilities, framing, rough-in and waterproofing, siding and cladding, roofing, windows and doors, MEP, paint and trim, fixtures and finishes, and ultimately certificate of occupancy.&nbsp; It is important to note that at this stage the GC’s quote is just an estimate. We haven’t built anything yet.</p><p>With approved drawings, financing, budget, and schedule in hand, the developer can start the snowflake build. Every step listed in the paragraph above must be completed by the corresponding specialists, and getting the work done on schedule is much more of an art than a science. Each contractor and subcontractor has their own contractual obligations, risks, and liability. Getting to the certificate of occupancy means the developer has navigated the process and can now bring in buyers or renters to start paying off the decades of debt that were secured to finance the build.&nbsp; When the developer moves on to the next project, all of the steps must be performed again, without exception. The finished project may be beautiful, energy efficient, or last 100 years, but it will still be a one-off.&nbsp;&nbsp;</p><p>All of this work is done for every project every time, regardless of size. A home or apartment is not more complicated than a car or plane, and while the unique attributes of individual sites and real estate do add challenges to repeatability, it is possible to decouple the building from the dirt.</p><p>We can’t be surprised that building costs for new housing continue to escalate. We can’t be surprised that it’s even more expensive to create affordable housing. Yet we continue to shrug our shoulders and say, “That’s just how it is.” We dig around the edges of the problem, foraging for scraps by looking for cost savings in commodities, underpaying labor, cutting corners on quality and performance, and building on cheaper land further and further from work and community.&nbsp;</p><p>Housing development is antiquated and the only group benefitting is the real estate development and building industry, who in fact have every incentive to restrict the supply. We’re making Version 1 of the oven, stereo, car, and plane over and over again, in a housing market that is chronically under-served. The failure to build adequate housing has generational effects on health, education, and opportunity.&nbsp;</p><p>There has to be a better way. We have to re-imagine the housing market and build better. More on that to come in our next post.</p></div></div></div>]]>
            </description>
            <link>https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645525</guid>
            <pubDate>Wed, 30 Sep 2020 23:48:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: CSS-to-Tailwind – Transform plain CSS into TailwindCSS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24645087">thread link</a>) | @miklosme
<br/>
September 30, 2020 | https://transform.tools/css-to-tailwind | <a href="https://web.archive.org/web/*/https://transform.tools/css-to-tailwind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://transform.tools/css-to-tailwind</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645087</guid>
            <pubDate>Wed, 30 Sep 2020 23:01:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bay Area approve plan requiring employees to work from home 3 days a week]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24645083">thread link</a>) | @henryw
<br/>
September 30, 2020 | https://usatodaysun.com/bay-area-says-employees-will-be-required-to-work-from-home-three-days-a-week-after-the-pandemic-to-reduce-greenhouse-gas-emissions/ | <a href="https://web.archive.org/web/*/https://usatodaysun.com/bay-area-says-employees-will-be-required-to-work-from-home-three-days-a-week-after-the-pandemic-to-reduce-greenhouse-gas-emissions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<li><strong>The&nbsp;Metropolitan Transportation Commission approved a plan that would require Bay Area residents to work from home three days a week&nbsp;</strong></li>
<li><strong>The proposal, which was voted on Wednesday, would ensure that sizable, office-based companies keep 60 per cent of their workers home</strong></li>
<li><strong>&nbsp;Transportation officials hope it will reduce greenhouse gas emissions and curb climate change in the area</strong></li>
<li><strong>Some residents and workers opposed the plan by noting that working remotely is not ideal for many people</strong></li>
<li><b>Big Tech companies in Bay Area have already transitioned much of their operations online and some have made remote work a permanent feature&nbsp;</b></li>
<li>
<p>A new proposal could require Californians to work remotely three days a week – even after the COVID-19 pandemic – to reduce greenhouse gas emissions to aid in environmental efforts.</p>
<p>A number of Bay Area residents, including employees at large tech firms, were concerned over a new proposal approved by the Metropolitan Transportation Commission on Wednesday.</p>
 <!-- A generated by theme --> 



 <!-- end A --> 


<p>The controversial proposal would effectively ensure that sizable, office-based companies kept 60 per cent of their workers at home on any given workday to curb</p>
</li>
<li>
<p>‘Given the changes in travel patterns during the&nbsp;<a id="mol-ecbfd540-000a-11eb-af1a-6fc9d77b8f42" href="https://www.dailymail.co.uk/news/coronavirus/index.html">coronavirus</a>&nbsp;pandemic, there was strong support for bolder policies on this front in the Final Blueprint, including a mandate for office-based employers,’ the proposal read.</p>
<p>‘To ensure this strategy achieves equity goals, a complementary strategy to expand internet access in underserved communities was added to the Economy Element as well.’</p>
</li>
<li>
<p>This latest proposal underscores a larger shift towards remote work that became commonplace after the COVID-19 pandemic hit the United States in January.</p>
<p>By March, entire office buildings shuttered and industries stumbled as employers struggled to transfer in-person operations to out of the workplace.</p>
<p>But now, six months later, city officials and some employers viewed the forced transition as a unrealized benefit that could reshape office culture and transportation.</p>
<p>‘There is an opportunity to do things that could not have been done in the past,’ said&nbsp;Oakland Mayor Libby Schaaf, a commission member and proposal supporter,</p>
</li>
<li><img loading="lazy" src="https://usatodaysun.com/wp-content/uploads/2020/09/b-300x200.jpg" alt="" width="524" height="349" srcset="https://usatodaysun.com/wp-content/uploads/2020/09/b-300x200.jpg 300w, https://usatodaysun.com/wp-content/uploads/2020/09/b.jpg 634w" sizes="(max-width: 524px) 100vw, 524px"></li>
<li>
<p>A May 2020 study from the&nbsp;Nature Climate Change Journal&nbsp;noted that daily carbon dioxide emissions plunged by 17 per cent in the United States during April.</p>
<p>‘The estimated decrease in daily fossil CO2&nbsp;emissions from the severe and forced confinement of world populations of –17% (–11 to –25%) at its peak are extreme and probably unseen before,’ the study said.</p>
<p>The commission’s proposal was found inside a larger policy package titled ‘Plan Bay Area 2050 Final Blueprint,’ in which officials theorized what the Bay Area could look like in 30 years and what could be done about reducing greenhouse gas emissions.</p>
<p>Members voted 11-1 to approve the overall policy package, including the mandate.</p>
<p>Bay Area is home to Silicon Valley, the central hub of Big Tech firms that have taken different approaches to working from home.</p>
<p>Facebook quickly embraced remote working as a longterm plan&nbsp;and advised its 50,000 staffers to work from home to avoid spreading the coronavirus.</p>
<p>CEO Mark Zuckerberg later announced that the company had extended its work-from-home plan until 2021, allowing employees to avoid the Menlo Park office for the next several months.</p>
<p>Similarly, Twitter, which reported 5,100 employees in its most recent earnings report, ordered employees to work from home .</p>
</li>
<li>
<p>It was later revealed by CEO Jack Dorsey that the company will allow most of its employees to work from home permanently.</p>
<p>‘Opening offices will be our decision. When and if our employees come back, will be theirs,’ a spokesperson for the company said.</p>
<p>But companies like Apple, that have invested loads of money on its campuses and facilities, have been less eager to fully welcome remote work.</p>
<p>Tim Cook revealed in a recent interview at The Atlantic Festival that he hoped employees would be back in the office by next year and pointed out that remote work doesn’t allow for certain employee interactions.</p>
<p>When word of the plan reached Bay Area residents, many were concerned and logged onto the virtual commission meeting on Wednesday to object.</p>
<p>‘We do not want to continue this as a lifestyle,’ said&nbsp;Steven Buss, a Google software engineer who lives in San Francisco, according to NBC News.</p>
<p>‘We are all sacrificing now to reduce the spread of the virus, but no one is enjoying working from home.</p>
<p>‘It’s probably fine if you own a big house out in the suburbs and you’re nearing retirement, but for young workers like me who live in crowded conditions, working from home is terrible.’</p>
</li>
<li>
<p>Some residents noted that the strategy enforces workplace inequality since some jobs cannot be performed at home, while others worried about the effects it would have on other industries as a result.</p>
<p>Stacey Randecker called into the meeting on Wednesday and questioned why the proposal included all commute alternatives if the main focus was on car emissions.</p>
<p>‘Yes, yes, yes, we want to reduce greenhouse gases, but why aren’t you considering transit? Walking? Biking?’ she said.</p>
<p>Duston Moskovitz, co-founder of Facebook, shared the sentiments on Twitter.</p>
<p>‘We tried nothing, and we’re all out of ideas,’ he wrote on Tuesday.</p>
</li>
<li>
<p>Commission member Nick Josefowitz said the work-from-home proposal was a late addition into the policy package.</p>
<p>NBC News reports that&nbsp;Josefowitz attempted to amend the proposal to allow transit and walking from home as alternatives, but critics worried that a delay could result in the commission missing emission reduction targets and an important funding deadline.</p>
<p>‘If we start amending this plan at this late hour, do you have any rabbits in your hat that’s going to get us to the finish line,’ asked commission member&nbsp;Jim Spering.</p>
<p>The proposal added that the work-from-home strategy ‘was not included in the Draft Blueprint and was added based upon public feedback this summer.’</p>
<p>MTC executive director Therese McMillan said there would be opportunities to later go over the strategy’s details and include alternative transportation.</p>
<p>The commission will meet against before the end of the year and then it would need to be implemented over time.</p>
</li>
</div></div>]]>
            </description>
            <link>https://usatodaysun.com/bay-area-says-employees-will-be-required-to-work-from-home-three-days-a-week-after-the-pandemic-to-reduce-greenhouse-gas-emissions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645083</guid>
            <pubDate>Wed, 30 Sep 2020 23:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Boost Debt Collection Using Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644984">thread link</a>) | @umermirzapk
<br/>
September 30, 2020 | https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p4/ | <a href="https://web.archive.org/web/*/https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://thinkml.ai/content/images/size/w300/2020/09/ModelingDT.JPG 300w,
                            https://thinkml.ai/content/images/size/w600/2020/09/ModelingDT.JPG 600w,
                            https://thinkml.ai/content/images/size/w1000/2020/09/ModelingDT.JPG 1000w,
                            https://thinkml.ai/content/images/size/w2000/2020/09/ModelingDT.JPG 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://thinkml.ai/content/images/size/w2000/2020/09/ModelingDT.JPG" alt="Boost Debt Collection and Recovery using Machine Learning [part 4/5]">
            </figure>

            <section>
                <div>
                    <p>This is part-4 of the case study on Boost Debt Collections and Recoveries using Machine Learning (MLBR). A machine learning predictive model to enhance the current recovery system by creating focus groups for business to boost debt collection.</p><blockquote><em><em><em><em><u>Disclaimer:</u> This case study is solely an educational exercise and information contained in this case study is to be used only as a case study example for teaching purposes. This hypothetical case study is provided for illustrative purposes only and do not represent an actual client or an actual client’s experience. All of the data, contents and information presented here have been altered and edited to protect the confidentiality and privacy of the company.</em></em></em></em></blockquote><p>In <a href="https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p1/">Part-1</a>, we looked at the background and the understanding of the debt collection and recovery process in credit lending companies. We looked at the entities/players involved in the traditional debt recovery process. We also defined the objective of our use case and highlights of the proposed machine learning solution.</p><p>In <a href="https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p2/">Part-2</a>, we looked at the data elements and high level design. We also discussed the data collection process and design of the data pipeline. We also discussed the complex data variables created as result of feature engineering. We also discussed the importance of expert opinion in this complex case study. The value of expert opinion and how collection score turned out to be a significant key attribute in Modeling phase.</p><p>In <a href="https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p3/">Part-3</a>, we discussed the modeling phase. We also explained the learning phase and the various data sets. How Training data set, Test data set and cross validation data set are prepared.</p><p>In this part, we will look at the comparison of various models results and the selection of the best model.</p><h3 id="4-6-1-3-selection-of-the-best-model-for-classification"><strong>4.6.1.3 &nbsp;</strong>Selection of the best model for Classification</h3><p>We trained three classification models, </p><ul><li>Support Vector Machine (SVM) </li><li>Decision Tree (DT) </li><li>Naïve Bayes (NB) </li></ul><p>“Training dataset” is used to train all three machine learning models. Once training is complete, we compared the statistics of all three models. </p><p><em>Recap on the data sets used:</em> </p><p>Multiple snapshots of LHD were created,</p><ol><li><strong><strong>Snapshot-0: </strong></strong>This is the historical snapshot of the database as of <strong><strong>31-Mar-2018</strong></strong>. It is further split into two datasetsa) &nbsp;<strong><strong>Training dataset:</strong></strong> 70% of the data from snapshot-0 is taken into training dataset at random. Purpose of this dataset is to train different models for prediction.b) &nbsp;<strong><strong>Testing dataset:</strong></strong> 30% of the data from snapshot-0 is taken into testing dataset at random. Purpose of this dataset is to test and compare all three models. This dataset is also used for first Cross Validation.</li><li><strong><strong>Snapshot-1:</strong></strong> This is the historical snapshot of the database as of <strong><strong>31-Mar-2019</strong></strong> (one year later).</li><li><strong><strong>Snapshot-2:</strong></strong> This is the historical snapshot of the database as of <strong><strong>31-Oct-2019</strong></strong> (almost one and half year later than snapshot-0).</li></ol><p>The data cutoff date for all snapshots are depicted below:</p><figure><img src="https://thinkml.ai/content/images/2020/09/image-11.png"><figcaption>Data cutoff for Training, Testing and Cross Validation Data sets</figcaption></figure><figure><img src="https://thinkml.ai/content/images/2020/09/image-9.png"><figcaption>Overall performance of all three models (after training)</figcaption></figure><figure><img src="https://thinkml.ai/content/images/2020/09/image-10.png"><figcaption>Performance Matrix for all three models (after training)</figcaption></figure><p>Decision tree model appears to have better overall accuracy on training dataset but Naïve Bayes turned out to be a better option on testing dataset. So, we choose Naïve Bayes for Cross Validation.</p><p>In next <a href="https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p5/">part</a>, we will look at Cross Validation Result and Implementation.</p><p>Cheers :)</p>
                </div>
            </section>

            <section>
                <h3>Subscribe to ThinkML</h3>
                <p>Get the latest posts delivered right to your inbox</p>
                


            </section>

            

            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644984</guid>
            <pubDate>Wed, 30 Sep 2020 22:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My First Year as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644935">thread link</a>) | @josejorgexl
<br/>
September 30, 2020 | https://jj.hashnode.dev/my-first-year-as-a-developer | <a href="https://web.archive.org/web/*/https://jj.hashnode.dev/my-first-year-as-a-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>It has been a year since I started to make money from building software. I don't call myself a developer, maybe one year making a living from programming is very similar to your definition of what a developer is, but I don't see the things in that way. However this could be the subject of another post. Here I will write about some of my first year experiences.</p>
<blockquote>
<p>I'll include some side notes like this one. I'll use these notes to briefly introduce some concepts and tools for those who are starting their programming journey right now.</p>
</blockquote>
<h2 id="rigidness-is-not-that-bad">Rigidness is not that bad</h2>
<p>When it comes to choosing a framework or a library there is often a lot of discussion. At some point in my evolution as a programmer I thought that flexibility is always good. After a bunch of lines of code I learned that rigidness is not that bad.</p>
<p>Frameworks, libraries, and tools in general are here because we are bad programmers by nature (among other causes). I really appreciate when a tool forces me to make things in a unique specific and very good way, so I can acomplish my goals by following that way.</p>
<p>In a smooth scenario, when definitions and requirements don't change abruptly during a week I always choose rigidness. I always choose the straight path.</p>
<h2 id="when-premises-dont-hold">When premises don't hold</h2>
<p>Then here I am, a guy that prefers the straight path in the middle of this jungle with no path at all. Definitions and requirements are changing every day in the most abrupt possible way and every week I am doing a very different project. I had to learn to embrace flexibility, in the hard way.</p>
<p>Now I am going to ilustrate that hard way through examples.</p>
<p>They decided to build a website using React. I learned React while doing the project so I started to consume a lot of tutorials. I decided to use <code>create-react-app</code> (CRA) to scafold the project since it is used in every single tutorial. So far, so good. I had a good workplace and was able to make the production build with a single command and so on.</p>
<blockquote>
<p>I highly recommend you to learn something while doing a project and, if possible, while getting paid for it. I think it is the best way to learn, at least when it comes to frameworks and tools in general.</p>
<p>CRA is a very useful way to get started with your React project. With just typing <code>npx create-react-app &lt;project-name&gt;</code> you get the whole project scafolding. I think every React developer can take advantage from this tool no matter if you are novice or senior. I won't complain about CRA, but I think some tutorials should warn us about the possible drawbacks resulting from using it.</p>
</blockquote>
<p>Then the boss learned what a Progressive Web App (PWA) is, and after a couple of weeks we were required to make the site progressive. This is not a big deal since CRA provides us with a service worker.</p>
<blockquote>
<p>PWA is a mechanism to make websites working offline and to behave like native apps in mobile devices, among other benefits. This is achieved with the colaboration of several components like the browser, a special script called service worker, a manifest file, and some code to install the service worker in the browser. As I said, CRA provides us with the required components in order we can make our React site progressive.</p>
</blockquote>
<p>Once you have a service worker in your site, you are able to receive push notifications from a server, and of course, after two weeks we were required to implement this too. But to make that possible you need to make some adjustments in the service worker and guess what, the CRA service worker is not customizable at all!</p>
<blockquote>
<p>Maybe you have encountered some sites that ask you whether you'd like to receive notifications. If you answer yes, they can send you the so called push notifications with the content they like. This notifications pop up in your device no matter that you have the browser closed. This is possible because the browser keeps the service worker script running in the background.</p>
</blockquote>
<p>Then I had to build a new service worker from scratch and the code to install it. That is not a big deal because I had have to do it no matter I had used CRA or not. So let's move to other issues.</p>
<p>After building the whole payment process, they decided that we needed to use some service that verifies your identity from some images of your face and of an identity document. So we needed to change a lot of things in the already built payment process. I made possible that the user could take a selfie, and take the picture of his ID document. But after that, we were required to use a specific SDK provided by the service in order to make the images to fulfill some features required for a reliable evaluation.</p>
<p>The SDK was a vanilla Javascript file that needed to be imported via HTML script tag. It is intended to be integrated in applications that use vanilla javascript. You know, the non-NodeJS one. So I needed to make the impossible to get everything working without making <code>eject</code>. After knowing about webpack, I'd like to go back in time and start my project from scratch, without using CRA or anything and taking care of my own webpack configuration. Belive me, this is just a single example because I don't want to make the story so long, I just want to make my point.</p>
<blockquote>
<p>Webpack is a tool that allows us to translate our NodeJS code into a vanilla javascript bundle that can be used in our production site. It's hard to master and that's why tools like CRA manage all the webpack related issues for you. But I haven't found a smooth enough way to make changes in the CRA webpack configurations, so I think that if you are facing the sort of complexities I am telling you about, you should consider using some more flexible tool (and then tell me what tool is that) or doing your own webpack configurations. CRA allows you to run <code>npm eject</code> and after that, you are by your own with webpack and everything, but I am not brave enough yet.</p>
</blockquote>
<p>My first task in this company, before the React website I have written about above, was to build a responsive website. After a lot of effort and passing through all sort of dificulties, the site have never been used. Yes, I got paid, but this post is not about making money, this post is about what I think is wrong.</p>
<h2 id="what-i-would-do">What I would do</h2>
<p>The problem here is not the changing. There are always unstable scenarios, businesses that are unstable by nature, or at least that become unstable due to new events. The problem is the rush in the decision making, the lack of connection between developers and the business men and the misconception by some of those business men that the cost of developing is negligible.</p>
<p>I think you just learn about good programming practices when you find yourself repeating the same code everywhere and fixing the same bug in diferent places. Well, with this experience I have learned the necessity of planning and writing. You need to define your problem and to write down that definition. You need to keep a record of your requirements, and even keep a record of the infrastructure you need in order to fulfill those requirements.  I don't like to overthink, but it's just a lack of common sense thinking that you can get something by just hitting the keys when the project is complex enough.</p>
<p>The problem is not the need to make big changes in the project per se. But if you can include those changes in the initial plan then they are not changes but initial requirements, and the developing process is faster, cleaner and no one do fruitless job. The sooner the change is predicted, the smaller and the easier the refactoring.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Those have been some of my experiences in this firs year as a developer. I'll certainly write about some others, don't think everything have been that painful.</p>
<p>I hope you or your boss don't be suffering the WIPCA syndrome (Why Isn't Paul Coding Anything?!). So always try to write your problem definition, the requirements and everything you think is necessary, like the infrastructure. No matter if you are using Scrum, Waterfall or whatever. Just write a little bit and try to make changes, which will always be needed, less painful. Of course this only applies to complex enough projects, but don't underestimate projects, actually a way to assert whether a project is complex enough is defining the problem and the requirements.</p>
<p>If you liked this post hit the like button. Feel free to comment whatever you want. You can also follow me on Twitter for debates about Computer Science.</p>
</div></div>]]>
            </description>
            <link>https://jj.hashnode.dev/my-first-year-as-a-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644935</guid>
            <pubDate>Wed, 30 Sep 2020 22:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A wearable sensor for people with inflammatory bowel disease]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644672">thread link</a>) | @finphil
<br/>
September 30, 2020 | https://nuadox.com/post/630721968777396224/wearable-sensor-ibd | <a href="https://web.archive.org/web/*/https://nuadox.com/post/630721968777396224/wearable-sensor-ibd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="630721968777396224">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/630721968777396224/wearable-sensor-ibd"><h2>A wearable sensor for people with inflammatory bowel disease</h2></a>
                                <figure data-orig-height="1080" data-orig-width="1440"><img src="https://64.media.tumblr.com/8437b22213729d2768464edb697ca740/317dd0b354885cc7-93/s1280x1920/ae1679bff7d4419d3646dd55cd062ce8c187ed01.jpg" data-orig-height="1080" data-orig-width="1440" width="1280" height="960" alt="image"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2Fnews%2Fmedia-contact%2Fkim-horner%2F&amp;t=ZGExNDVjNjhhZWVhMTU5Y2NiNmNlZTUzNzQ4ZWY2OGI2OGJmY2YwZCwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">Kim Horner</a> ,&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2F&amp;t=NmNlMmEzNDdhMzdlOTIzZTdhNzJjYjQ4MTJiNTA4MzE1ZGNkZTNlNSwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">University of Texas at Dallas</a> -</b></p><p>University of Texas at Dallas researchers have designed a wearable device that monitors sweat for biomarkers that could signal flare-ups of inflammatory bowel disease (IBD).</p><p>A team of bioengineers demonstrated the wristwatch-like device in a proof-of-concept study funded by the Crohn’s &amp; Colitis Foundation and published online July 28 and in the October print edition of the foundation’s journal, <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Facademic.oup.com%2Fibdjournal%2Fadvance-article-abstract%2Fdoi%2F10.1093%2Fibd%2Fizaa191%2F5877396&amp;t=MjMzMDA2ZjY1ZmQ4ODM5YTg4OGY2NTM1NmM3YTA2NDA1NWUxM2UxYSwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091"><i>Inflammatory Bowel Diseases</i></a>.</p><p>A sensor in the device detects and quantifies the presence of two key biomarkers associated with inflammatory bowel disease: interleukin-1β and C-reactive protein (CRP). The study is the first to establish that CRP is present in human sweat and the first to show that the two biomarkers can be detected in sweat.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Futdallas.edu%2Fchairs%2Fprofiles%2Fdr-shalini-prasad%2F&amp;t=Y2I0OTY5YzhlYTM1YjEzMzY4OGUxYmI1ODE3ZmE4N2U4MzRjZGQ5YiwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">Dr. Shalini Prasad</a>, department head and professor of <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fbe.utdallas.edu%2F&amp;t=Yzc5OTVlN2RlNmE0Yzk2Mzg1MWU5NDdjMzljNmJjMzVlZWQzMzc0NiwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">bioengineering</a> in the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fengineering.utdallas.edu%2F&amp;t=MTMwNjQ4NWFiZjVkMzkyMjQzNzk2OTg2YTNkODM3YThlNTk0ZmNjZSwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">Erik Jonsson School of Engineering and Computer Science</a> and the study’s principal investigator, said the technology could provide a warning but not a diagnosis of inflammatory bowel disease. The ultimate goal of the work is to develop a device to help patients gain more control over IBD, which can be unpredictable.</p><p>“It’s like the check-engine light in a car,” said Prasad, the Cecil H. and Ida Green Professor in Systems Biology Science. “The warning signal doesn’t mean a patient is having a flare-up, but it could give the person the chance to intervene earlier, when the symptoms may be more responsive to treatment. The device also could help doctors understand sooner whether a treatment is working.”</p><p>The researchers monitored the levels of the two biomarkers in 20 healthy volunteers to show that the biomarkers could be tracked and to establish the levels of biomarkers in people without IBD.</p><p>The researchers used what is called passive sweat, which means that the wearer did not need to engage in physical activity or have their sweat glands expressed to generate a sample. The sweat is collected on a removable strip incorporated into the wrist device that must be changed daily. That the device collects passive sweat is important because people with IBD may be unable to exercise at levels needed to generate active sweat, Prasad said.</p><p>The prototype will be tested on patient volunteers in a second phase of the research, also funded by the foundation, and must undergo further testing before it can become available to patients.</p><p>The device has the potential to track other diseases and conditions marked by an inflammatory response. Prasad’s team is investigating whether it could alert people to increases in cytokines, which are proteins released by the immune system at the early stages of a viral infection, such as COVID-19.</p><p>Prasad’s team previously developed a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2Fnews%2Fscience-technology%2Fbioengineers-improve-diabetes-monitors-versatility%2F&amp;t=MWY3MWRiZjVhZmFjMDMwMWQ4ODc3YWQ1NzQ2YzhjNDhjZmY1ZjY4MiwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">biosensor</a> that analyzes sweat to detect levels of certain chemicals, such as glucose and cortisol, that could indicate diabetes. In 2014 she co-founded a company called <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fenlisense.com%2F&amp;t=MTgwYzQ3ZjU1Nzc3NmMwN2JkMmRiMGIwOThmMTNhZWQ3ZTdhZWFjNCwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">EnLiSense</a> in Allen, Texas, to develop lifestyle-based sensors and devices. Based on Prasad’s successful work on the glucose tracker, the Crohn’s &amp; Colitis Foundation partnered with her to apply the concept to develop a noninvasive monitor for IBD, said Dr. Gerard Honig, associate director of research innovation for the foundation.</p><p>“We’ve seen extraordinary revolutions in a number of fields, such as bioengineering, and dramatic events relating to medical devices, and we have not necessarily seen those ideas applied to IBD,” Honig said.</p><p>IBD, which affects millions of people in the U.S., is characterized by chronic or recurring immune response wherein the cells lining the intestines are attacked when the body mistakes food, bacteria and other materials for foreign substances, causing inflammation. Symptoms include fatigue and abdominal pain, with diarrhea in patients with Crohn’s disease and stool urgency in those with ulcerative colitis.</p><p>Currently, doctors measure intestinal inflammation through endoscopy, which involves the insertion of a long, thin tube into the body to view internal organs or tissue. The procedure is too invasive to be feasible for frequent monitoring of the disease, which creates challenges in recruiting patients for clinical drug trials, Honig said.</p><p>“A wearable microsensor device would have the potential to empower patients to be actively engaged in monitoring their disease and managing it,” Honig said. “It would greatly facilitate clinical research and potentially could be used in the long term to facilitate proactive management, where you have a target biomarker level you’re trying to achieve over a certain period of time and you optimize care to get there.”</p><p>–</p><p><i>Header image:&nbsp;UT Dallas researchers designed a prototype of a wristwatch-like device that detects two key biomarkers associated with inflammatory bowel disease. Credit:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2Fnews%2Fscience-technology%2Fwearable-sensor-ibd-2020%2F&amp;t=OTg5YTgzYzM4YmIwOTE2ZTQxM2YxOWNmN2QyZDY1YjU3MWE3YzA2MiwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">University of Texas at Dallas</a>.</i></p><p><b>Source:&nbsp;

<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2Fnews%2Fscience-technology%2Fwearable-sensor-ibd-2020%2F&amp;t=OTg5YTgzYzM4YmIwOTE2ZTQxM2YxOWNmN2QyZDY1YjU3MWE3YzA2MiwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">University of Texas at Dallas</a></b></p><p><b>Full study:</b>&nbsp;“A Sweat-based Wearable Enabling Technology for Real-time Monitoring of IL-1β and CRP as Potential Markers for Inflammatory Bowel Disease”,&nbsp;<i>Inflammatory Bowel Diseases</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1093%2Fibd%2Fizaa191&amp;t=NDRkNjVkNzE2ODNjYmEwZjg0ZGQwYTU3OGM3NGNlZTNmMmVmZjgxNiwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601687091">https://doi.org/10.1093/ibd/izaa191</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/178125297442/new-wearable-ultrasound-patch-ucsd">New wearable ultrasound patch non-invasively monitors blood pressure in arteries</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/smart-wristband">smart wristband</a>
                                    
                                        <a href="https://nuadox.com/tagged/inflammatory-bowel-disease">inflammatory bowel disease</a>
                                    
                                        <a href="https://nuadox.com/tagged/ibd">ibd</a>
                                    
                                        <a href="https://nuadox.com/tagged/wearables">wearables</a>
                                    
                                        <a href="https://nuadox.com/tagged/healthcare">healthcare</a>
                                    
                                        <a href="https://nuadox.com/tagged/health-tech">health tech</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/iot">iot</a>
                                    
                                        <a href="https://nuadox.com/tagged/internet-of-things">internet of things</a>
                                    
                                        <a href="https://nuadox.com/tagged/biosensor">biosensor</a>
                                    
                                        <a href="https://nuadox.com/tagged/biotech">biotech</a>
                                    
                                        <a href="https://nuadox.com/tagged/biotechnology">biotechnology</a>
                                    
                                        <a href="https://nuadox.com/tagged/gastroenterology">gastroenterology</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/630721968777396224/wearable-sensor-ibd</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644672</guid>
            <pubDate>Wed, 30 Sep 2020 22:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secrets detection learning center: complete handbook for dev, SEC, ops]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644392">thread link</a>) | @mackenzie-gg
<br/>
September 30, 2020 | https://www.gitguardian.com/secrets-detection | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644392</guid>
            <pubDate>Wed, 30 Sep 2020 21:49:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting Lemire’s nearly divisionless random]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24644370">thread link</a>) | @bbgm
<br/>
September 30, 2020 | https://veryseriousblog.com/posts/dissecting-lemire | <a href="https://web.archive.org/web/*/https://veryseriousblog.com/posts/dissecting-lemire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-74174200445ef6e30546"><div><p>This blog post is very late. It’s well over a year since<a href="https://twitter.com/colmmacc/status/1153727018896244736"> I posted a coding challenge on twitter</a>. The idea was simple, I’ve always felt that code readability is undervalued so I figured I’d put cold hard cash up. I announced a $1,000 pot, divided into $500, $300, and $200 prizes for the most readable implementations of <a href="https://lemire.me/blog/2019/06/06/nearly-divisionless-random-integer-generation-on-various-systems/">Daniel Lemire’s nearly divisionless algorithm for selecting a random number from an interval.</a> I now have winners to announce and congratulate, and they’re in this blog post, but there’s more to this story.</p><p>I didn’t know it at the time but I’d end up reviewing the entries with colleagues to see if they could follow what was happening (spoiler: they couldn’t). When people got stuck, we’d whiteboard&nbsp;our way through so that we could better understand why and where people were getting stuck. Oh, to be able to whiteboard in person again!  </p><p>I learned a lot about how people think through problems, and that process led to me writing a seperate implementation of Lemire’s Algorithm, with a twenty-to-one comment to code ratio (that’s a lot of comments), and finding a sort-of security issue with the algorithm in the process. I say “sort of” because you really have a ridiculously enormous struggle to find a case where it’s going to be practical to exploit. But it still surprised me, and you probably can’t use Lemire’s algorithm in Vegas.</p><h4>Why Lemire’s Algorithm?</h4><p>I chose Lemire’s algorithm because it is brilliant. When I read Lemire’s code I get that kind of brain-tingling and gawk at the sheer “How on earth did someone think of this” of it all. Lemire has a mastery of code and how code is executed, and then pairs that with transcendent creativity and concision.  Lemire also writes well, and the papers that accompany his code and algorithms are easily some of the most cogent and approachable you’ll find in academia. They are short and clear and avoid the jargon and obtuseness that plagues the field, while containing just enough formalism to be rigorous.</p><p>Lemire’s algorithm is a solution to the problem “Give me a random number between 0 and N, not including N itself”. For simulating a dice, N would be 6 and you’d get back either 0, 1, 2, 3, 4, or 5 with equal probability. Computers like to start at zero. We can always add one to the result to get the familiar results you’d get on a real dice. I’ve worked on random number generators and written quite a few. In 20 years of doing that, I’d never come across a solution as cool as Lemire’s.</p><p>Before Lemire, the best-known solutions to this problem required one or two divisions per number generated. You probably learned long division when you were quite young. You may remember that it can be get pretty tedious and cumbersome. It’s the same for computers. Division is actually one of the slowest things we can ask a computer to do. Lemire avoids division by translating numbers into a much larger number “space” and using binary-friendly powers-of-two operations instead. His technique almost always avoids needing a division.</p><p>The second reason I chose Lemire’s algorithm is that it is impenetrable upon first reading. There are lucky few people who are so practiced and conversant in number manipulation that they can see inside of algorithms like Neo in the matrix, but I don’t mean them. To the average reader, myself included, it’s not clear what’s going on and why.</p><p>Lemire’s reference code is fourteen lines long, like a sonnet. Twelve of the lines are simple, and any proficient programmer could tell <em>what</em> they are doing. Two specific lines of the code are pretty hard to decipher.. But the real difficulty is how hard it is to understand <em>why</em> all 14 lines are doing what they are doing, and <em>why</em> it results in a fair and correct algorithm for choosing a random number.</p><div><p>As a case in point, if you read the comments to Lemire’s blog, you’ll find several misunderstandings of the code. That’s within an audience of primed Lemire fans and critics who are familiar with the field. <a href="https://arxiv.org/abs/1805.10941">Lemire’s accompanying paper</a> is great and very readable, but it still takes effort and concentration to follow everything. I work on cryptography and write cryptographic code for a living and I’m not ashamed to tell you it took me about 3 readings to really get it. The algorithm is based on an interaction between two modular spaces, one of which is sized 2 to power of 64, and the other is “N” sized, and if I just totally lost you there, I beg forgiveness and if you bear with me I promise there’s a link to my detailed dissection of how and why everything works. </p><p>All of this makes Lemire’s algorithm a really good challenge for creating a more readable version. Ideally something that an average coder can read in one pass, understand, and agree that it’s correct. </p></div><h4>Why does readability matter?</h4><p>Code readability is the most important pillar of code correctness and maintainability. When code is unreadable, it is harder to spot errors. That’s true when you’re doing a code review and it’s even more true when you’re adding more code to an existing code base. Great testing can compensate for some of the correctness challenges, but it doesn’t do as much for maintainability. </p><p>In s2n, one of our <a href="https://github.com/awslabs/s2n/blob/main/docs/DEVELOPMENT-GUIDE.md">development principles</a> is to write clear readable code with a light cognitive load. We’re serious about it, and I wasn’t going to try and use Lemire’s algorithm in s2n without a very readable implementation.</p><p>Working in software development I’ve heard the opinion more than once about how programmers and coders should be more familiar with the fundamental mathematics of logic and number theory that underpin their field, and that academic style papers and explanations should be sufficient. I happen to work with teams that are made up of both expert coders and expert mathematicians, and even there I don’t think this is a good idea.</p><p>Software engineering is engineering, which means translating science into solutions that work in the real world.  To wildly generalize, there are better dividends to be found in focusing on deepening ones understanding of the “real world” part of that, the users, the customers, the business models, usability, ergonomics, and so on, than on the “science” part of that. Some science is needed, but there’s a shallow limit. Just as a civil engineer doesn’t need too detailed an understanding of the chemistry of concrete. PHs and setting times, but not quantum numbers.</p><p>Code should be self-documenting. The average programmer, including someone straight out of college, should be able to understand and work on a well put-together codebase. This greatly improves the odds of finding problems, and that’s what matters. </p><h4>The contest</h4><p>One of the reasons I’ve been so tardy about this blog post is that the contest didn’t go as I’d expected. </p><p>Let’s start with the great thing that happened. I got several submissions, more than enough to pick winners from. Many of these submissions are good and do improve upon Lemire’s code. The most common improvement was to use more descriptive names for the variables. Lemire uses variable names such as “s”, “t”, “l” which seemingly don’t correspond to much. In such a short piece of code, this actually isn’t too big an offense. I kept these terms in my own implementation, because I want to be consistent with the paper, but it’s absolutely a valid improvement. Another great improvement is to write and include tests, which is really an essential part of software development. </p><p>The first place <a href="https://github.com/ziglang/zig/blob/98183e47436699f6e5eab200061c46eec342806e/std/rand.zig#L74-L118">winner</a> did both of these, and also cleared up some of the confusing lines of code by making an implicit truncation explicit. According to GitHub the winner had 5 contributors, but twitter user <a href="https://twitter.com/komu_wairagu/status/1161643573223317504">komu_wairagu</a> submitted it, so that’s who I’ll be contacting to Venmo $500.</p><p>The second place <a href="https://github.com/nimia/Lemire_RNG">winner</a> comes from <a href="https://twitter.com/NimrodAviram">Nimrod Aviram</a>, who I know professionally as the discoverer of the DROWN vulnerability and fun person to hang out with at RealWorldCrypto. Nimrod’s implementation includes some great testing too.</p><p>The third place winner wants to stay anonymous, and cheated their way to some bonus points by writing a great implementation in LISP. How can you not love that? If they change their minds about anonymity I’ll update this post with a link. The sha256 checksum of their implementation is ae008644b2f0b10eddbbce3a0508b103b19925e4e0c9354c569ff0816acb760c. </p><p>Now on to the not as great, and one of the reasons I’ve taken this long to write. It doesn’t feel right to criticize any of these efforts, made in spare time and as part of a fun challenge I put out there, but none of them actually explained Lemire’s algorithm or broke down how and why it worked. I asked several colleagues to look through these implementations and tell me if they understood what was going on, and the response was a uniform zero. Noone could fully understand even one of the implementations, or Lemire’s original.  When I asked people to also read the paper, things got a bit better, but everyone still seemed to trip on some issues.  These are smart people who absolutely know what they are doing. I’m sure given more time they could fully understand everything, but that wasn’t the goal. The goal was to have understanding after one or two, or at most just a few, readings.</p><h4>What did people find hard to follow?</h4><p>Talking through things with people I found some common problems. Some directly in the code, and others in the paper. The first line of code that threw people was:</p><pre><code>uint64_t l = ( uint64_t ) m;</code></pre><p>This line of code does an unusual operation called truncation. It takes a 128-bit value “m” and truncates that to its least significant 64-bits. All of this is implicit in the code, rather than explicit. Reading the code, you have to recall that m is 128-bits. Then there’s also the question of why are we doing this truncation? I’ll leave that for a minute. </p><p>The next problematic line of code was:</p><pre><code>uint64_t t = -s % s;</code></pre><p>This line of code is using an unusual combination of unary negation, on an unsigned int, and the modulus operator.  Nobody remembers what unary negation does to an unsigned int - and why should they …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://veryseriousblog.com/posts/dissecting-lemire">https://veryseriousblog.com/posts/dissecting-lemire</a></em></p>]]>
            </description>
            <link>https://veryseriousblog.com/posts/dissecting-lemire</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644370</guid>
            <pubDate>Wed, 30 Sep 2020 21:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netflix 4K UHD Streaming requires Apple's T2 chip]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644228">thread link</a>) | @aunali1
<br/>
September 30, 2020 | https://www.iphoneincanada.ca/news/how-to-stream-netflix-in-4k-on-mac/ | <a href="https://web.archive.org/web/*/https://www.iphoneincanada.ca/news/how-to-stream-netflix-in-4k-on-mac/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<!-- .entry-social-links -->
<div>
	
	
	
		
		
	
<!-- .entry-social-links -->	
		
		
	<div>
	<p>Netflix has finally made its 4K Ultra HD content available to stream on Mac, albeit not everyone will be able to benefit from that. As mentioned on the&nbsp;<a href="https://help.netflix.com/fr-ca/node/55764">Netflix Ultra HD support page</a>, 4K streaming only works on&nbsp;select 2018 or later Mac computers with an Apple T2 Security chip (via <em><a href="https://www.macg.co/mac/2020/09/netflix-en-4k-sur-mac-uniquement-pour-les-machines-avec-puce-t2-116775">MacGeneration</a></em>).</p>
<p><img title="netflix log.png" src="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/netflix-log.png" alt="Netflix log" width="640" height="272"></p>	
	
	
	
<p>In addition to a T2 chip Mac, you also need the latest version of Safari running on macOS Big Sur, a screen capable of displaying a 4K 60Hz image (compliant with the HDCP 2.2 standard in the case of an external screen), and a subscription plan that supports Ultra HD streaming.</p>
<p>Here’s an interesting take on the T2 chip requirement from a <a href="https://www.reddit.com/r/apple/comments/j2cik9/youll_need_a_mac_with_a_t2_chip_to_be_able_to/">Reddit</a> user:</p>
<blockquote>
<p><em>“This makes zero sense to me. The only Macs, that could really benefit from 4k streaming, without an external monitor, are the 4k and 5k iMacs yet only 2 models (the Pro and the new 2020 27″) will be able to stream it. Windows machines don’t have any kind of T2 alternative and are still able to stream 4k via Edge or via the native app, their only requirement is a 7th gen intel cpu or a dedicated graphics card.”</em></p>
</blockquote>
<p>Below is the&nbsp;list of Macs compatible with 4K Netflix streaming:</p>
<ul>
<li>iMac Pro (late 2017)</li>
<li>Mac mini (late 2018)</li>
<li>MacBook Air ( 2018 and up)</li>
<li>MacBook Pro (2018 and up)</li>
<li>Mac Pro (2019)</li>
<li>iMac (2020)</li>
</ul>
<p>What do you guys think of the T2 chip requirement for streaming Netflix in Ultra HD?</p>

	</div>

</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://www.iphoneincanada.ca/news/how-to-stream-netflix-in-4k-on-mac/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644228</guid>
            <pubDate>Wed, 30 Sep 2020 21:36:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Good Retention]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24643994">thread link</a>) | @cwaffles
<br/>
September 30, 2020 | https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29 | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Hello, and welcome to the&nbsp;<strong>free monthly edition&nbsp;</strong>of my weekly newsletter. I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>, and each week I tackle reader questions about product, growth, working with humans, and anything else that’s stressing you out at the office.</em></p><p><em><strong>If you’re not a paid subscriber, here’s what you missed this month:</strong></em></p><ol><li><p><em><a href="https://www.lennyrachitsky.com/p/interviewing-users-for-product-market">How to find out if you have product-market fit</a></em></p></li><li><p><em><a href="https://www.lennyrachitsky.com/p/taking-responsibility-for-a-failed">How to communicate bad news to your boss</a></em></p></li><li><p><em><a href="https://www.lennyrachitsky.com/p/prioritizing-across-conversion-opportunities">Tips for prioritizing amongst conversion opportunities</a></em></p></li></ol><p>I’m very excited about this week’s post, so let’s get to it.</p><blockquote><p><em>"Great retention is THE scalable way to grow a product. It's the best indicator of product-market fit, it is the most important factor in a user’s lifetime value, and high retention drives all of the best acquisition strategies. It's growth's equivalent of the triple-word-score."</em></p><p>— <a href="https://twitter.com/onecaseman">Casey Winters</a></p></blockquote><p><strong>Although retention is widely considered to be the most important metric to get right when building (and investing in) a business, it’s also one of the least understood.</strong> Why? Because unless you’re a growth expert or an experienced investor, you’re often relying on anecdotes, dated blog posts, and misguided benchmarks. I ran into this problem myself many times when working with startups.</p><p>So when <a href="https://www.linkedin.com/in/caseywinters">Casey Winters</a> (former head of growth at Pinterest, GrubHub, and now CPO at Eventbrite) brought up this question in a conversation we were having, we decided to take the opportunity to do some new research. Together, we reached out to twenty of the most experienced growth practitioners we knew and asked them two simple questions:</p><ol><li><p><strong>What do you consider GOOD and GREAT user retention (at 6 months)</strong>?</p></li><li><p><strong>What do you consider GOOD and GREAT net revenue retention (at 12 months)</strong>?</p></li></ol><p>Taking these insights and combining them with available public data, <strong>we’ve come up with a set of concrete recommendations for GOOD and GREAT retention across most types of businesses</strong>. Below you’ll find a visual summary of these conclusions, along with detailed recommendations from each of the experts, and public comps from many of today’s biggest companies.</p><p>As a companion to this post, <a href="https://caseyaccidental.com/what-is-good-retention">Casey also published an essay</a> delving into ways to increase retention, amongst other topics, which you should definitely check out.</p><p>Without further ado, let’s dive in.</p><h2><strong>What is GOOD and GREAT retention?</strong></h2><h4><strong>GOOD and GREAT User Retention</strong></h4><ul><li><p><strong>Consumer Social:</strong> ~25% is GOOD, ~45% is GREAT</p></li><li><p><strong>Consumer Transactional</strong>:  ~30% is GOOD, ~50% is GREAT</p></li><li><p><strong>Consumer SaaS:</strong> ~40% is GOOD, ~70% is GREAT</p></li><li><p><strong>SMB / Mid-Market SaaS:</strong> ~60% is GOOD, ~80% is GREAT</p></li><li><p><strong>Enterprise SaaS:</strong> ~70% is GOOD, ~90% is GREAT</p></li></ul><h4><strong>GOOD and GREAT Net Revenue Retention</strong></h4><ul><li><p><strong>Consumer SaaS:</strong> ~55% is GOOD, ~80% is GREAT</p></li><li><p><strong>Bottom-Up SaaS:</strong> ~100% is GOOD, ~120% is GREAT</p></li><li><p><strong>Land and Expand VSB SaaS:</strong> ~80% is GOOD, ~100% is GREAT</p></li><li><p><strong>Land and Expand SMB / Mid-Market SaaS:</strong> ~90% is GOOD, ~110% is GREAT</p></li><li><p><strong>Enterprise SaaS:</strong> ~110% is GOOD, ~130% is GREAT</p></li></ul><p>Here’s a handy visual guide, which links to a high-res PDF:</p><p><a target="_blank" href="https://www.dropbox.com/s/h6p02vvmyxxonzy/What%20is%20good%20retention%20.pdf?dl=0"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F56c42120-3472-426c-bc68-6498d214944a_2550x2944.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/56c42120-3472-426c-bc68-6498d214944a_2550x2944.png&quot;,&quot;height&quot;:1681,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:617828,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:&quot;https://www.dropbox.com/s/h6p02vvmyxxonzy/What%20is%20good%20retention%20.pdf?dl=0&quot;}" alt=""></a></p><h2><strong>Big thank you to the experts</strong></h2><p><strong><a href="https://www.linkedin.com/in/adamjfishman/">Adam Fishman</a></strong> (Patreon, Imperfect Foods), <strong><a href="https://twitter.com/andrewchen">Andrew Chen</a></strong> (Uber, a16z), <strong><a href="https://www.linkedin.com/in/andrewjohns/">Andy Johns</a></strong> (Twitter, Facebook, Wealthfront), <strong><a href="https://brianbalfour.com/">Brian Balfour</a></strong> (Reforge), <strong><a href="https://brianrothenberg.com/)">Brian Rothenberg</a></strong> (Eventbrite, TaskRabbit), <strong><a href="https://www.linkedin.com/in/chenliw/">ChenLi Wang</a></strong> (Dropbox), <strong><a href="https://twitter.com/danhockenmaier">Dan Hockenmaier</a></strong> (Thumbtack), <strong><a href="https://www.linkedin.com/in/elenaverna/">Elena Verna</a></strong> (SurveyMonkey, Miro), <strong><a href="https://www.linkedin.com/in/fareed/">Fareed Mosavat</a></strong> (Slack), <strong><a href="https://twitter.com/jamiequint?lang=en">Jamie Quint</a></strong> (Notion, Reddit), <strong><a href="https://www.linkedin.com/in/jeff-chang-82467459/">Jeff Chang</a></strong> (Pinterest), <strong><a href="https://www.linkedin.com/in/julieyizhou/">Julie Zhou</a></strong> (Hipmunk, Yik Yak, AdRoll), <strong><a href="https://www.linkedin.com/in/kevinakwok/">Kevin Kwok</a></strong> (Greylock), <strong><a href="https://twitter.com/ljin18">Li Jin</a></strong> (a16z), <strong><a href="https://www.linkedin.com/in/merci/">Merci Grace</a></strong> (Slack), <strong><a href="https://twitter.com/mduboe">Mike Duboe</a></strong> (Stitch Fix, Greylock), <strong><a href="https://www.linkedin.com/in/naomipilosofionita/">Naomi Ionita</a></strong> (Evernote, Menlo Ventures), <strong><a href="https://www.linkedin.com/in/nicksoman/">Nick Soman</a></strong> (Gusto, Decent), <strong><a href="https://twitter.com/saranormous">Sarah Guo</a></strong> (Greylock), <strong><a href="https://www.linkedin.com/in/shaun-clowes-80795014">Shaun Clowes</a></strong> (Atlassian, MuleSoft), and <strong><a href="https://www.linkedin.com/in/yuriytimen/">Yuriy Timen</a></strong> (Grammarly). And of course, my incredible partner on this research, <strong><a href="https://www.linkedin.com/in/caseywinters">Casey Winters</a></strong>.</p><h3><strong>Disclaimer: Why it may be OK for your retention to be low</strong></h3><p>To some, these retention benchmarks will seem high. This is because the bar to build a massively successful business is high. Frankly, it’s why most startups fail. However, although<strong> retention is an important metric to get right, it doesn’t live in vacuum</strong>. There are cases where a lower retention rate is OK:</p><ol><li><p><strong>You’re just starting out:</strong> Don’t despair if you don’t see this level of retention immediately. Use these benchmarks a guide to prioritize between retention vs. acquisition, and <a href="https://caseyaccidental.com/what-is-good-retention">read Casey’s post</a> for three ways to approach increasing retention. But just know, startups rarely increase retention significantly.</p></li><li><p><strong>You have low CAC and marginal costs: </strong>Growth is a balancing act between CAC, retention, and unit economics. If you can acquire new users cheaply (e.g. SEO, WOM, or virality), you can afford to lose more users. <a href="https://twitter.com/danhockenmaier/status/1270376412642373633">This thread by Dan Hockenmaier</a> explains why low retention for businesses like Shopify and Twitter is OK. </p></li><li><p><strong>You’re not building a venture-scale business:</strong> These benchmarks are coming from people who helped build iconic, massively scalable, businesses. This level of retention is <em>not</em> required for product/market fit, or to build a sustainable business. Though the upside will be limited, a flat retention curve that drives a scalable acquisition strategy is enough to keep your business alive.</p></li></ol><blockquote><p><strong>Ultimately,  what matters is that your retention supports sustained growth. </strong></p><p>— <a href="https://www.linkedin.com/in/fareed/">Fareed Mosavat</a></p></blockquote><p>Now, let’s get into the details.</p><p>Let’s define <em>user retention</em> as the % of users who signed up and are still active (i.e. using the product, making a purchase, posting a photo) six months later.</p><h3>Consumer<strong> Social: ~25% is GOOD, ~45% is GREAT</strong></h3><p>This includes companies such as <strong>Snapchat, Twitter, and Instagram</strong> that are free to use and are generally supported by advertising. The denominator in this category are registered users.</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Jeff Chang</strong>: Over 25% is GOOD, over 40% is GREAT</p></li><li><p><strong>Casey Winters</strong>: Over 25% is GOOD, over 45% is GREAT</p></li><li><p><strong>Brian Rothenberg</strong>: Over 25% is GOOD, over 50% is GREAT</p></li><li><p><strong>Jamie Quint: </strong>Over 30% is GOOD, over 40% is GREAT</p></li><li><p><strong>ChenLi Wang</strong>: Over 30% is GOOD, over 50% is GREAT</p></li><li><p><strong>Julie Zhou</strong>: Over 30% is GOOD, over 60% is GREAT</p></li><li><p><strong>Kevin Kwok</strong>: Over 30% is GOOD, over 60% is GREAT</p></li><li><p><strong>Andrew Chen</strong>: Over 50% is GOOD, over 75% is GREAT</p></li></ul><p><strong>Public comps</strong></p><ul><li><p><strong>Facebook</strong>: 60 - 70% 6-month user retention</p></li><li><p><strong>Instagram</strong>: 50 - 60% 6-month user retention</p></li><li><p><strong>Snapchat</strong>: 33% 3-month user retention, 30% 24-month (<a href="https://www.theinformation.com/articles/which-apps-retail-their-users-and-which-ones-dont">source</a>, <a href="https://www.statista.com/statistics/523845/highest-retention-social-android-apps/">source</a>)</p></li><li><p><strong>Twitter</strong>: 31% 3-month user retention, 22% 24-month (<a href="https://www.theinformation.com/articles/which-apps-retail-their-users-and-which-ones-dont">source</a>, <a href="https://www.statista.com/statistics/523845/highest-retention-social-android-apps/">source</a>)</p></li></ul><h3>Consumer<strong> Transactional: ~30% is GOOD, ~50% is GREAT</strong></h3><p>This includes companies such as <strong>Airbnb, Lyft, and TurboTax </strong>that are generally supported by one-off purchases. The denominator in this category are users who have made at least one transaction.</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Casey Winters</strong>: Over 15% is GOOD, over 35% is GREAT</p></li><li><p><strong>Kevin Kwok</strong>: Over 30% is GOOD, over 50% is GREAT</p></li><li><p><strong>Dan Hockenmaier</strong>: Over 30% is GOOD, over 50% is GREAT</p></li><li><p><strong>Li Jin:</strong> Over 30% is GOOD, over 50% is GREAT</p></li><li><p><strong>Brian Rothenberg</strong>: Over 30% is GOOD, over 60% is GREAT</p></li><li><p><strong>ChenLi Wang</strong>: Over 30% is GOOD, over 70% is GREAT</p></li></ul><p><strong>Public comps</strong></p><ul><li><p><strong>TurboTax</strong>: 77% 12-month customer retention (<a href="https://www.hbs.edu/openforum/openforum.hbs.org/goto/challenge/understand-digital-transformation-of-business/intuit-s-turbotax-price-discrimination-is-effective.1.html">source</a>)</p></li><li><p><strong>Lyft</strong>: 22% 12-month customer retention (<a href="https://www.thetaequity.com/lyft-ipo">source</a>)</p></li></ul><h3>Consumer SaaS:<strong> ~40% is GOOD, ~70% is GREAT</strong></h3><p>This includes companies such as <strong>Netflix, Spotify, and Hulu</strong> that sell a monthly/yearly subscription to consumers. The denominator in this category are users who have started a paid subscription.</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Dan Hockenmaier: </strong>Over 40% is GOOD, over 60% is GREAT</p></li><li><p><strong>Adam Fishman: </strong>Over 40% is GOOD, over 70% is GREAT</p></li><li><p><strong>Jeff Chang: </strong>Over 50% is GOOD, over 70% is GREAT</p></li><li><p><strong>Mike Duboe: </strong>Over 50% is GOOD, over 70% is GREAT</p></li><li><p><strong>Elena Verna</strong>: Over 70% is GOOD, over 80% is GREAT</p></li></ul><p><strong>Public comps</strong></p><ul><li><p><strong>Amazon Prime</strong>: 93% 12-month customer retention (<a href="https://www.twice.com/retailing/amazon-prime-subscribers-2019">source</a>)</p></li><li><p><strong>Dropbox:</strong> ~80% 12-month customer retention</p></li><li><p><strong>Spotify</strong>: 72% 6-month customer retention (<a href="https://blog.measurable.ai/2019/11/04/exceptional-purchase-retention-of-spotify-and-its-new-podcast-strategy/">source</a>, <a href="https://www.statista.com/statistics/241424/dau-and-mau-of-spotifys-facebook-app/">source</a>)</p></li><li><p><strong>Netflix</strong>: 66% 12-month customer retention (<a href="https://secondmeasure.com/datapoints/netflix-disney-plus-apple-customer-retention/">source</a>)</p></li><li><p><strong>Hulu</strong>: 53% 12-month customer retention (<a href="https://secondmeasure.com/datapoints/netflix-disney-plus-apple-customer-retention/">source</a>)</p></li></ul><h3><strong>SMB / Mid-Market SaaS: ~60% is GOOD, ~80% is GREAT</strong></h3><p>This includes companies such as <strong>Asana, Slack, and Atlassian</strong> that primarily sell a subscription product to companies roughly 100-1000 employees. The denominator in this category are companies who have started a paid subscription.</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Yuriy Timen</strong>: Over 60% is GOOD, over 80% is GREAT</p></li><li><p><strong>Mike Duboe</strong>: Over 60% is GOOD, 80% is GREAT</p></li><li><p><strong>Sarah Guo</strong>: Over 70% is GOOD, over 80% is GREAT</p></li><li><p><strong>Fareed Mosavat: </strong>Over 70% is GOOD, over 85% is GREAT</p></li><li><p><strong>ChenLi Wang</strong>: Over 70% is GOOD, over 85% is GREAT</p></li><li><p><strong>Andy Johns</strong>: Over 70% is GOOD, 90% is GREAT</p></li><li><p><strong>Dan Hockenmaier</strong>: Over 70% is GOOD, over 90% is GREAT</p></li><li><p><strong>Merci Grace</strong>: Over 80% is GOOD, 90% is GREAT</p></li></ul><p><strong>Public companies</strong></p><ul><li><p><strong>Atlassian</strong>: 98% 12-month customer retention (<a href="https://seekingalpha.com/article/4289582-atlassian-is-repositioning-for-future">source</a>)</p></li><li><p><strong>Slack:</strong> 90-95% 12-month customer retention (<a href="https://www.rocketblocks.me/blog/slack-metrics.php">source</a>, <a href="https://www.thetaequity.com/slack-ipo">source</a>)</p></li><li><p><strong>QuickBooks</strong>: 79% 12-month customer retention (<a href="http://analysisreport.morningstar.com/stock/research/c-report?&amp;t=XNAS:INTU&amp;region=usa&amp;culture=zh-CN&amp;productcode=QS&amp;cur=&amp;urlCookie=8056723522&amp;e=eyJhbGciOiJSU0EtT0FFUCIsImVuYyI6IkExMjhHQ00ifQ.jRbbMI400Bb9ZooVDzRwlWTjZLVQK8Wuoe4MTNuK_HRhEGWQC7iTj6RNX_QkUhRaIakTpCwLhioYtggMawqPo_MQQU9oqP5dJxQh_4aQBR9MdISHGljBgRaItM-6xRSIfSxa5GgnDmcwLALZe1tkPz0YI5rXlvXPDOflJOXHEuY.yO-n-CczhDqdbPMI.MPLk1bS9rMP369DrL5Q-RcyIIBeMhHp5svZmp0VIsOjaG0J9Sjk53Uq9PrFqk883utblUw2UqRXSn0ORFuXLSfQcS7fD1y1Y9a7VlubYNWqVfoBlbRZNxjaGidgk62ToWSvSkVztsyLfwQMbaBp1_G3ITrQ-Ud0GTNbK7oCzTZ7IMHwcvonZRt5gnVFRcSpe1EFT7Z3oZt3GtfwoNrI-mq8faPGpqForBnxtrDo.1-3ri8thKyjDFOjF2CIn2Q">source</a>)</p></li></ul><h3><strong>Enterprise SaaS: ~75% is GOOD, ~90% is GREAT</strong></h3><p>This includes companies such as <strong>Salesforce, Workday, and ADP</strong> that primarily sell a subscription product to large enterprise companies (i.e. over 1000 employees).</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Andy Johns</strong>: Over 70% is GOOD, over 90% is GREAT&nbsp;</p></li><li><p><strong>Brian Rothenberg</strong>: Over 75% is GOOD, over 90% is GREAT</p></li><li><p><strong>Jeff Chang</strong>: Over 80% is GOOD, over 90% is GREAT</p></li><li><p><strong>Sarah Guo</strong>: Over 85% is GOOD, over 95% is GREAT</p></li><li><p><strong>Nick Soman</strong>: Over 85% is GOOD, over 95% is GREAT</p></li><li><p><strong>Shaun Clowes:</strong> Over 85% is GOOD, over 95% is GREAT</p></li></ul><p><strong>Public comps</strong></p><ul><li><p><strong>Workday: </strong>95% 12-month customer retention (<a href="https://www.workday.com/content/dam/web/en-us/documents/investor/workday-financial-analyst-day-2018.pdf">source</a>)</p></li><li><p><strong>Salesforce: </strong>90% 12-month customer retention (<a href="https://seekingalpha.com/article/4308906-salesforce-buy">source</a>)</p></li><li><p><strong>ADP: </strong>90%+ 12-month customer retention (<a href="https://www.forbes.com/sites/greatspeculations/2019/02/01/key-takeaways-from-adps-q2/#549ea1ac4877">source</a>)</p></li></ul><p>Let’s define <em>Net Revenue Retention</em> as a company’s monthly recurring revenue (MRR) one year ago divided into the current month’s MRR <em>from that same group of customers</em>. Essentially, how much revenue are you driving from one cohort of customers over time?</p><p>You’ll notice this section has slightly different categories from previous section. This is because of the way the customers a business sells to impacts revenue retention (unlike user retention). For example, the network effects in Bottom-Up SaaS often drive up retention, while involuntary churn of Very Small business (VSB) is common because many go out of business, and Land and Expand models increases revenue&nbsp;per user in ways that can make up for high user churn.</p><p>Now, let’s look at what good and great net revenue retention looks like for each type of business.</p><h3><strong>Consumer SaaS: ~55% is GOOD, ~80% is GREAT</strong></h3><p>This includes companies such as <strong>Netflix, Spotify, and Hulu </strong> that sell a monthly/yearly …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29">https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643994</guid>
            <pubDate>Wed, 30 Sep 2020 21:18:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ent by Facebook: Entity Framework for Go Now Supports GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24643910">thread link</a>) | @ajeetdsouza
<br/>
September 30, 2020 | https://entgo.io/docs/graphql/ | <a href="https://web.archive.org/web/*/https://entgo.io/docs/graphql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><span><p>The <code>ent</code> framework provides an integration with GraphQL through the <a href="https://github.com/99designs/gqlgen">99designs/gqlgen</a>
library using the <a href="https://entgo.io/docs/templates">external templates</a> option (i.e. it can be extended to support other libraries).</p>
<h2>Quick Introduction</h2>
<p>In order to enable the <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql"><code>entgql</code></a> extension to your
project, you need to use the <code>entc</code> (ent codegen) package as described <a href="https://entgo.io/docs/code-gen#use-entc-as-a-package">here</a>.
Follow these 3 steps to enable it to your project:</p>
<p>1. Create a new Go file named <code>ent/entc.go</code>, and paste the following content:</p>
<pre><code>

<span>package</span> main

<span>import</span> (
    <span>"log"</span>

    <span>"github.com/facebook/ent/entc"</span>
    <span>"github.com/facebook/ent/entc/gen"</span>
    <span>"github.com/facebookincubator/ent-contrib/entgql"</span>
)

<span><span>func</span> <span>main</span><span>()</span></span> {
    err := entc.Generate(<span>"./schema"</span>, &amp;gen.Config{
        Templates: entgql.AllTemplates,
    })
    <span>if</span> err != <span>nil</span> {
        log.Fatalf(<span>"running ent codegen: %v"</span>, err)
    }
}
</code></pre>
<p>2. Edit the <code>ent/generate.go</code> file to execute the <code>ent/entc.go</code> file:</p>
<pre><code><span>package</span> ent


</code></pre>
<p>Note that <code>ent/entc.go</code> is ignored using a build tag, and it's executed by the <code>go generate</code> command
through the <code>generate.go</code> file. The full example can be found in the <a href="https://github.com/facebookincubator/ent-contrib/blob/master/entgql/internal/todo">ent-contrib repository</a>.</p>
<p>3. Run codegen for your ent project:</p>
<pre><code>go generate ./...
</code></pre>
<p>After running codegen, the following add-ons will be added to your project.</p>
<h2>Node API</h2>
<p>A new file named <code>ent/node.go</code> was created that implements the <a href="https://relay.dev/docs/en/graphql-server-specification.html#object-identification">Relay Node interface</a>.</p>
<p>In order to use the new generated <code>ent.Noder</code> interface in the <a href="https://gqlgen.com/reference/resolvers/">GraphQL resolver</a>,
add the <code>Node</code> method to the query resolver, and see the <a href="#gql-configuration">configuration</a> section to understand
how to use it.</p>
<pre><code><span><span>func</span> <span>(r *queryResolver)</span> <span>Node</span><span>(ctx context.Context, id <span>int</span>)</span> <span>(ent.Noder, error)</span></span> {
    <span>return</span> r.client.Noder(ctx, id)
}
</code></pre>
<p>Note that schema migration must be configured with the <a href="https://entgo.io/docs/migrate#universal-ids">Universal IDs</a> option if you want
ent to resolve the "type from id" for you.</p>
<h2>GQL Configuration</h2>
<p>Here's a configuration example for a todo app as exists in <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql/internal/todo">ent-contrib/entgql/todo</a>.</p>
<pre><code><span>schema:</span>
  <span>-</span> <span>todo.graphql</span>

<span>resolver:</span>
  
  <span>layout:</span> <span>follow-schema</span>
  <span>dir:</span> <span>.</span>



<span>autobind:</span>
  <span>-</span> <span>github.com/facebookincubator/ent-contrib/entgql/internal/todo/ent</span>

<span>models:</span>
  <span>ID:</span>
    <span>model:</span>
      <span>-</span> <span>github.com/99designs/gqlgen/graphql.IntID</span>
  <span>Node:</span>
    <span>model:</span>
      
      <span>-</span> <span>github.com/facebookincubator/ent-contrib/entgql/internal/todo/ent.Noder</span>
</code></pre>
<h2>Pagination</h2>
<p>The pagination template adds a pagination support according to the <em>Relay Cursor Connections Spec</em>. More info
about the Relay Spec can be found in its <a href="https://relay.dev/graphql/connections.htm">website</a>.</p>
<h2>Connection Ordering</h2>
<p>The ordering option allows us to apply an ordering on the edges returned from a connection.</p>
<h3>Usage Notes</h3>
<ul>
<li>The generated types will be <code>autobind</code>ed to GraphQL types if a naming convention is preserved (see example below).</li>
<li>Ordering can only be defined on ent fields (no edges).</li>
<li>Ordering fields should normally be <a href="https://entgo.io/docs/schema-indexes">indexed</a> to avoid full table DB scan.</li>
<li>Pagination queries can be sorted by a single field (no order by ... then by ... semantics).</li>
</ul>
<h3>Example</h3>
<p>Let's go over the steps needed in order to add ordering to an existing GraphQL type.
The code example is based on a todo-app that can be found in <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql/internal/todo">ent-contrib/entql/todo</a>.</p>
<h3>Defining order fields in ent/schema</h3>
<p>Ordering can be defined on any comparable field of ent by annotating it with <code>entgql.Annotation</code>.
Note that the given <code>OrderField</code> name must match its enum value in graphql schema.</p>
<pre><code><span><span>func</span> <span>(Todo)</span> <span>Fields</span><span>()</span> []<span>ent</span>.<span>Field</span></span> {
    <span>return</span> []ent.Field{
        field.Time(<span>"created_at"</span>).
            Default(time.Now).
            Immutable().
            Annotations(
                entgql.OrderField(<span>"CREATED_AT"</span>),
            ),
        field.Enum(<span>"status"</span>).
            NamedValues(
                <span>"InProgress"</span>, <span>"IN_PROGRESS"</span>,
                <span>"Completed"</span>, <span>"COMPLETED"</span>,
            ).
            Annotations(
                entgql.OrderField(<span>"STATUS"</span>),
            ),
        field.Int(<span>"priority"</span>).
            Default(<span>0</span>).
            Annotations(
                entgql.OrderField(<span>"PRIORITY"</span>),
            ),
        field.Text(<span>"text"</span>).
            NotEmpty().
            Annotations(
                entgql.OrderField(<span>"TEXT"</span>),
            ),
    }
}
</code></pre>
<p>That's all the schema changes required, make sure to run <code>go generate</code> to apply them.</p>
<h3>Define ordering types in GraphQL schema</h3>
<p>Next we need to define the ordering types in graphql schema:</p>
<pre><code><span><span>enum</span> <span>OrderDirection</span> {</span>
  ASC
  DESC
}

<span><span>enum</span> <span>TodoOrderField</span> {</span>
  CREATED_AT
  PRIORITY
  STATUS
  TEXT
}

input TodoOrder {
  <span>direction:</span> OrderDirection!
  <span>field:</span> TodoOrderField
}
</code></pre>
<p>Note that the naming must take the form of <code>&lt;T&gt;OrderField</code> / <code>&lt;T&gt;Order</code> for <code>autobind</code>ing to the generated ent types.
Alternatively <a href="https://gqlgen.com/config/#inline-config-with-directives">@goModel</a> directive can be used for manual type binding.</p>
<h3>Adding orderBy argument to the pagination query</h3>
<pre><code><span>type</span> <span>Query</span> {
  todos(
    after: <span>Cursor</span>
    first: <span>Int</span>
    before: <span>Cursor</span>
    last: <span>Int</span>
    orderBy: <span>TodoOrder</span>
  ): <span>TodoConnection</span>
}
</code></pre>
<p>That's all for the GraphQL schema changes, let's run <code>gqlgen</code> code generation.</p>
<h3>Update the underlying resolver</h3>
<p>Head over to the Todo resolver and update it to pass <code>orderBy</code> argument to <code>.Paginate()</code> call:</p>
<pre><code><span><span>func</span> <span>(r *queryResolver)</span> <span>Todos</span><span>(ctx context.Context, after *ent.Cursor, first *<span>int</span>, before *ent.Cursor, last *<span>int</span>, orderBy *ent.TodoOrder)</span> <span>(*ent.TodoConnection, error)</span></span> {
    <span>return</span> r.client.Todo.Query().
        Paginate(ctx, after, first, before, last,
            ent.WithTodoOrder(orderBy),
        )
}
</code></pre>
<h3>Use in GraphQL</h3>
<pre><code>query {
    todos(first: 3, orderBy: {direction: DESC, field: NAME}) {
        edges {
            node {
                name
            }
        }
    }
}
</code></pre>
<h2>Fields Collection</h2>
<p>The collection template adds support for automatic fields collection from GraphQL requests using eager-loading
the ent-edges. In order to configure this option to specific edges, use the <code>entgql.Annotation</code> as follows:</p>
<pre><code><span><span>func</span> <span>(Todo)</span> <span>Edges</span><span>()</span> []<span>ent</span>.<span>Edge</span></span> {
    <span>return</span> []ent.Edge{
        edge.To(<span>"children"</span>, Todo.Type).
            Annotations(entgql.Bind()).
            From(<span>"parent"</span>).
            
            
            Annotations(entgql.Bind()).
            Unique(),
        edge.From(<span>"owner"</span>, User.Type).
            Ref(<span>"tasks"</span>).
            
            Annotations(entgql.MapsTo(<span>"taskOwner"</span>)),
    }
}
</code></pre>
<p>Then, in the resolver, use it as follows:</p>
<pre><code><span><span>func</span> <span>(r *todoResolver)</span> <span>Parent</span><span>(ctx context.Context, t *ent.Todo)</span> <span>(*ent.Todo, error)</span></span> {
    parent, err := t.Edges.ParentOrErr()
    <span>return</span> parent, ent.MaskNotFound(err)
}

<span><span>func</span> <span>(r *todoResolver)</span> <span>Children</span><span>(ctx context.Context, obj *ent.Todo)</span> <span>([]*ent.Todo, error)</span></span> {
    <span>return</span> obj.Edges.ChildrenOrErr()
}
</code></pre>
<p>More info about fields-collection can be found in <a href="https://spec.graphql.org/June2018/#sec-Field-Collection">Relay website</a>.</p>
<h2>Enum Implementation</h2>
<p>The enum template implements the MarshalGQL/UnmarshalGQL methods for enums generated by ent.</p>
<h2>Transactional Mutations</h2>
<p>The <code>entgql.Transactioner</code> handler executes each GraphQL mutation in a transaction. The injected client for the resolver
is a <a href="https://entgo.io/docs/transactions#transactional-client">transactional <code>ent.Client</code></a>.
Hence, code that uses <code>ent.Client</code> won't need to be changed. In order to use it, follow these steps:</p>
<p>1. In the GraphQL server initialization, use the <code>entgql.Transactioner</code> handler as follows:</p>
<pre><code>srv := handler.NewDefaultServer(todo.NewSchema(client))
srv.Use(entgql.Transactioner{TxOpener: client})
</code></pre>
<p>2. And then, in the GraphQL mutations, use the client from context as follows:</p>
<pre><code><span><span>func</span> <span>(mutationResolver)</span> <span>CreateTodo</span><span>(ctx context.Context, todo TodoInput)</span> <span>(*ent.Todo, error)</span></span> {
    client := ent.FromContext(ctx)
    <span>return</span> client.Todo.
        Create().
        SetStatus(todo.Status).
        SetNillablePriority(todo.Priority).
        SetText(todo.Text).
        SetNillableParentID(todo.Parent).
        Save(ctx)
}
</code></pre>
<hr>
<p>Please note that this documentation is under development. All code parts reside in <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql">ent-contrib/entgql</a>,
and an example of a todo-app can be found in <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql/internal/todo">ent-contrib/entql/todo</a>.</p>
</span></p></article></div></div>]]>
            </description>
            <link>https://entgo.io/docs/graphql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643910</guid>
            <pubDate>Wed, 30 Sep 2020 21:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DigitalOcean's Hacktoberfest Is Hurting Open Source]]>
            </title>
            <description>
<![CDATA[
Score 671 | Comments 308 (<a href="https://news.ycombinator.com/item?id=24643894">thread link</a>) | @domenicd
<br/>
September 30, 2020 | https://blog.domenic.me/hacktoberfest/ | <a href="https://web.archive.org/web/*/https://blog.domenic.me/hacktoberfest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For the last couple of years, <a href="https://www.digitalocean.com/">DigitalOcean</a> has run
<a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a>, which purports to “support open source” by giving free
t-shirts to people who send pull requests to open source repositories.</p>

<p>In reality, <strong>Hacktoberfest is a corporate-sponsored distributed denial of service attack against the open source
maintainer community</strong>.</p>

<p>So far today, on <a href="https://github.com/whatwg/html/pulls?q=is%3Apr+is%3Aclosed+label%3Aspam">a single repository</a>, myself
and fellow maintainers have closed 11 spam pull requests. Each of these generates notifications, often email, to the 485
watchers of the repository. And each of them requires maintainer time to visit the pull request page, evaluate its
spamminess, close it, tag it as spam, lock the thread to prevent further spam comments, and then report the spammer to
GitHub in the hopes of stopping their time-wasting rampage.</p>

<p>The rate of spam pull requests is, at this time, around four per hour. <em>And it’s not even October yet in my timezone.</em></p>

<p><img src="https://blog.domenic.me/images/hacktoberfest-spam-listing.png" alt="A screenshot showing a spam query for the whatwg/html repository, which is at this time up to 14 spam PRs"></p>

<p>Myself and other maintainers of the whatwg/html repository are not alone in suffering this deluge.
<a href="https://twitter.com/gravitystorm/status/1311386082982924289">My tweet</a> got commiseration from
<a href="https://mobile.twitter.com/gravitystorm/status/1311386082982924289">OpenStreetMap, phpMyAdmin</a>,
<a href="https://mobile.twitter.com/ulmerleben/status/1311378655231332355">PubCSS</a>,
<a href="https://mobile.twitter.com/JakeDChampion/status/1311389420638138370">GitHub, the Financial Times</a>,
<a href="https://twitter.com/slicknet/status/1311377444188770312">ESLint</a>, a
<a href="https://mobile.twitter.com/zekjur/status/1311411780162326531">computer club website</a>, and
<a href="https://mobile.twitter.com/juliusvolz/status/1311412919196844038">a conference website</a>, just within the first couple
of hours. Since then a dedicated account “<a href="https://twitter.com/shitoberfest">@shitoberfest</a>” has arisen to document the
barrage. Some <a href="https://github.com/search?q=is%3Apr+%22improve+docs%22+created%3A%3E2020-09-29&amp;type=Issues">cursory</a>
<a href="https://github.com/search?q=is%3Apr+label%3Ainvalid+created%3A%3E2020-09-29&amp;type=Issues">searches</a> show thousands of
spam pull requests, and rising.</p>

<p>DigitalOcean seems to be aware that they have a spam problem. Their solution, per their
<a href="https://hacktoberfest.digitalocean.com/faq">FAQ</a>, is to put the burden solely on the shoulders of maintainers. If we go
out of our way to tag a contribution as spam, then… we slightly decrease the chance of the spammer getting their free
t-shirt. In reality, the spammer will just keep going, submitting more pull requests to more repositories, until they
finally find a repository where the maintainer doesn’t bother to tag the PR as spam, or where the maintainer isn’t
available during the seven-day window DigitalOcean uses for spam-tracking.</p>

<p>To be clear, myself and my fellow maintainers did not ask for this. This is not an opt-in situation. If your open source
project is public on GitHub, DigitalOcean will incentivize people to spam you. There is no consent involved. Either we
contribute to DigitalOcean’s marketing project, or,
<a href="https://twitter.com/SudoFox/status/1311431141702819840">they suggest, we should quit open source</a>.</p>

<p>Hacktoberfest does not support open source. Instead, it drives open source maintainers even closer to
<a href="https://www.google.com/search?q=open+source+burnout">burnout</a>.</p>

<p><img src="https://blog.domenic.me/images/hacktoberfest-spam-pr.png" alt="A screenshot of a spam PR which adds the heading &quot;Great Work&quot; to the HTML Standard README"></p>

<h2 id="what-can-we-do">What can we do?</h2>

<p>My most fervent hope is that DigitalOcean will see the harm they are doing to the open source community, and put an end
to Hacktoberfest. I hope they can do it as soon as possible, before October becomes another lowpoint in the hell-year
that is 2020. In 2021, they could consider relaunching it as an opt-in project, where maintainers consent on a
per-repository basis to deal with such t-shirt–incentivized contributors.</p>

<p>To protect ourselves, maintainers have a few options. First, you can take the feeble step of ensuring that any spam
against your repositories doesn’t contribute to the spammer’s “t-shirt points”, by tagging pull requests with a “spam”
label, and <a href="https://twitter.com/MattIPv4/status/1311390498888781824">emailing hacktoberfest@digitalocean.com</a>.
DigitalOcean themselves, however, admit that
<a href="https://twitter.com/MattIPv4/status/1311390054334554113">this won’t stop the problem they’ve unleashed on us</a>. But
maybe it will contribute to the <a href="https://github.com/MattIPv4/hacktoberfest-data">metrics</a> they collect, which last year
showed that “only” 3,712 pull requests were labeled as spam by project maintainers.</p>

<p>If you’re comfortable cutting off genuine contributions from new users, you can try enabling GitHub’s
<a href="https://docs.github.com/en/free-pro-team@latest/github/building-a-strong-community/limiting-interactions-in-your-repository">interaction limits</a>.
However, <del>you have to do this every 24 hours, and</del> it has the drawback of also disabling issue creation and
comments. <ins>Update: GitHub has made the limit configurable, and has
<a href="https://twitter.com/github/status/1311772722234560517">a nice cheeky announcement tweet</a> zooming in on the “1 month”
option.</ins></p>

<p>Another promising route would be if GitHub would cut off DigitalOcean’s API access, as
<a href="https://twitter.com/__agwa/status/1311399074814472194">Andrew Ayer has suggested</a>. It’s not clear whether DigitalOcean
is committing a terms of service violation that would support such measures. But they’re certainly making GitHub a
less-pleasant place to be, and I hope GitHub can think seriously about how to discourage such corporate-sponsored
attacks on the open source community.</p>

<p>Finally, and most importantly, we can remember that this is how DigitalOcean treats the open source maintainer
community, and stay away from their products going forward. Although we’ve enjoyed using them for hosting the
<a href="https://whatwg.org/">WHATWG</a> standards organization, this kind of behavior is not something we want to support, so
we’re starting to investigate alternatives.</p>

  </div>

</article></div>]]>
            </description>
            <link>https://blog.domenic.me/hacktoberfest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643894</guid>
            <pubDate>Wed, 30 Sep 2020 21:10:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create and watch any 100m race with AI based Fantasy100m]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24643622">thread link</a>) | @SeanWingad
<br/>
September 30, 2020 | https://www.joinfudge.com/fantasy100m | <a href="https://web.archive.org/web/*/https://www.joinfudge.com/fantasy100m">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.joinfudge.com/fantasy100m</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643622</guid>
            <pubDate>Wed, 30 Sep 2020 20:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creative Destruction: The Risks of Not Innovating]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24643617">thread link</a>) | @nicotesla
<br/>
September 30, 2020 | https://blog.codelitt.com/not-innovating/ | <a href="https://web.archive.org/web/*/https://blog.codelitt.com/not-innovating/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="Post__Main-Content">
        <div>
          <p>What makes an idea or product innovative? It depends on who you ask, but most answers can be boiled down to the process of <strong>creating purpose-driven value. </strong></p><p>For an organization, this process could be focusing on creating a new product for its customers or streamlining internal workflows to enable greater productivity. They could be <em>exciting</em>, like a tool for visualizing data in augmented reality, or just simply <em>necessary</em>, such as bringing a 100-year-old company’s internal systems up to modern-day standards. These two very different examples give insight into the spectrum of projects that Codelitt has been brought on as a partner to help solve. </p><p>A big point to be made here is that innovation is not just for startups. “Out with the old and in with the new” doesn’t mean that the established companies need to step aside! </p><p>Instead, it’s a call to action that they need to stay agile in the face of a rapidly changing world and take part in what Joseph Schumpeter referred to as “creative destruction” - incessantly destroying the old and creating the new <em>from</em> <em>within</em>. </p><p>Enter the infamous business consideration: risk! Risk is what keeps organizations and the leaders within them complacent in participating in this evolution. <a href="https://archive.fortune.com/magazines/fortune/fortune500_archive/full/1955/">With nearly 90% of the companies in the Fortune 500 in the 1950s</a><a href="https://fortune.com/fortune500/walmart/"> gone by the 2010s</a>, complacency has serious implications. </p><p>Furthermore, the <strong>longer you wait to act in these fast-moving times the higher the cost.</strong> 50 years ago the life expectancy for a company within the Fortune 500 was 75 years. Today, the average is 15 years.<br></p><figure><img src="https://res-3.cloudinary.com/hepw4b4yn/image/upload/q_auto/v1/ghost-blog-images/Creative-Destruction-Graph.png"></figure><p>There are two ways that we’ve found companies are taking on this risk: empowering employees to become intrapreneurs and <strong>outsourcing the burden of innovation to experienced partners. </strong></p><p>Codelitt believes that any employee can be innovative regardless of their position within an organization. <a href="https://www.codelitt.com/intrapreneur.html">We have written extensively about how employees can become “intrapreneurs”</a> - essentially internal entrepreneurs! </p><p>Some companies just encourage their employees to think outside of the box while others take a more active role through the creation of internal Innovation Centers of Excellence made up of people whose sole purpose is to ideate and innovate. </p><p>Regardless of where your particular company stands on this, it cannot be argued that <strong>establishing a structured process</strong> for how to approach innovation from within can help save you time and money.<br></p><figure><img src="https://res-5.cloudinary.com/hepw4b4yn/image/upload/q_auto/v1/ghost-blog-images/creative-2.jpg"></figure><p>When an organization can’t do it internally or feels it would benefit from an outside perspective, the decision is made to outsource to a 3rd party Innovation Partner. </p><p>Why? Simple! The leaders we speak with know they need to prioritize innovation, but the risks/costs of keeping it internal are too high.</p><p><strong>What are these risks?</strong></p><ul><li>Ideating in a vacuum can cause biases to form which makes refining or reframing of the innovative solutions challenging</li><li>Staying on time and within budget is difficult</li><li>Diverting resources to work on innovation is inefficient</li><li>The required specialized skills might not exist within the org. Having to find, hire, onboard, train, and pay salary/benefits is expensive</li></ul><p>Along with having these specialized skills, outsourced partners have processes in place for working with a wide variety of teams to help them quickly validate ideas. </p><p>For the decision makers we work with, Codelitt is extremely valuable as we shoulder the weight of having to deliver projects on time and within the established budget. Where internal Innovation Centers of Excellence exist, leaders have found value in collaborating with Codelitt to ensure they are being <strong>strategic with their innovation backlog.</strong> </p><p>We become the “expert pair of eyes” to ensure that they are thinking about their problems the right way and delivering results when the skills needed are beyond internal capabilities.<br></p><p><strong>How will you take on creative destruction within your own organization in 2020?</strong></p><p><a href="https://www.codelitt.com/contact.html">Get in touch with us!</a></p>
        </div>
      </section></div>]]>
            </description>
            <link>https://blog.codelitt.com/not-innovating/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643617</guid>
            <pubDate>Wed, 30 Sep 2020 20:46:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ClickHouse, Redshift and 2.5B Rows of Time Series Data – Brandonharris.io]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24643541">thread link</a>) | @daniel_levine
<br/>
September 30, 2020 | http://brandonharris.io/redshift-clickhouse-time-series/ | <a href="https://web.archive.org/web/*/http://brandonharris.io/redshift-clickhouse-time-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p><img src="http://brandonharris.io/images/stochastic.jpg" alt=""></p>

<h3 id="overview">Overview</h3>
<blockquote>

  <p>Finding true time series data at billion row level scale is hard. It’s usually either generated from standard RNG’s which leave out the very important temporal dependencies through their use of Gaussian or Uniform distributions, or it’s too large to easily move around for testing purposes. In this post I show you how to synthesize billions of rows of true time series data with an autoregressive component, and then explore it with ClickHouse, a big data scale OLAP RDBMS, all on AWS. If you’re on a deadline, feel free to skip my thoughts and <a href="https://github.com/namebrandon/time-series-gen">get the code here</a>.</p>
</blockquote>

<h3 id="background-discussion">Background Discussion</h3>

<p>One of the areas that I continue to be impressed with is how quickly “standard SQL” solutions rebounded to start to handle very large datasets. These multi-billion row datasets were the domain of a few limited “Big Data” solutions only a few years ago. If you were working in this field in the early 2010’s, you’ll remember some crazy things when it came to manipulating very large data sets (raise your hand if you spent time googling how to create a bag in pig…).</p>

<p>Of course there have always been SQL or SQL-like offerings for big data work (and I won’t even talk about some of the crazy big data OLAP cube solutions) but in those early days if you wanted serious performance, you probably were going to be doing a lot more than just writing SQL. Even Spark SQL (which was a great option at the time, and still is for some use cases) required knowing a bit about RDD’s and lazy evaluation and even though you may have had some serious SQL chops, unless you knew Python or a bit of Scala, you were in for a tough ride.   </p>

<p><a href="https://prestodb.io/">Presto</a> went pretty far to solve this pain point, and in fact it was one of my early favorites in this space, as you can see from a post of mine <a href="http://brandonharris.io/redshift-clickhouse-time-series/(http://brandonharris.io/evaluating-big-data-performance-of-prestodb-and-parquet-on-s3-storage/)">way back in 2016</a>. Presto is still doing well (Amazon Athena anyone?) and has great support (check out the cool things <a href="https://www.starburstdata.com/">Starburst</a> is doing with enterprise Presto). <a href="https://spark.apache.org/sql/">SparkSQL</a> definitely has its place, and of course the proprietary solutions like Vertica, Aster and Greenplum are in use at alot of enterprises, but there are also some great offerings out there that are still not mainstream for some reason.</p>

<p>Back when I wrote that old <a href="http://brandonharris.io/evaluating-big-data-performance-of-prestodb-and-parquet-on-s3-storage/">Presto post</a>, <a href="https://tech.marksblogg.com/benchmarks.html">Mark</a> had jumped in and left some comments and I’d been following his Taxi Ride Adventures ever since. I started off this research really wanting to test out a GPU database and settled on <a href="https://www.brytlyt.com/">brytlytDB</a>, but something is up with them and they’ve pulled their AMI from AWS. I went looking elsewhere for something interesting to evaluate and I decided to give <a href="https://clickhouse.tech/">ClickHouse</a> a shot. Released in 2016 from the minds at Yandex (you should be familiar with them, but if not, think Google in Russia), <a href="https://clickhouse.tech/">ClickHouse</a>  is a columnar RDBMS implemented in C++ that offers distributed capabilities and has a syntax very close to ANSI SQL. </p>

<h3 id="about-clickhouse">About ClickHouse</h3>

<p>One of the areas that impressed me the most about ClickHouse was the numerous analytics related functions that are available right out to the box. These are just a few that I’m looking forward to playing with.</p>

<ul>
  <li>
    <p><a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/parametric-functions/#windowfunnel">windowFunnel()</a> – Searches for event chains in a sliding time window and calculates the maximum number of events that occurred from the chain.     </p>
  </li>
  <li>
    <p><a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/parametric-functions/#retention">retention()</a> - The function takes as arguments a set of conditions from 1 to 32 arguments of type UInt8 that indicate whether a certain condition was met for the event. Any condition can be specified as an argument (as in WHERE).    </p>
  </li>
  <li>
    <p><a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/parametric-functions/#function-sequencecount">sequenceCount()</a> - Counts the number of event chains that matched the pattern. The function searches event chains that don’t overlap. It starts to search for the next chain after the current chain is matched.</p>
  </li>
  <li>
    <p>Aggregate function combinations like <a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/combinators/#agg-functions-combinator-resample">resample()</a> - Lets you divide data into groups, and then separately aggregates the data in those groups. Groups are created by splitting the values from one column into intervals.</p>
  </li>
  <li>
    <p><a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/reference/grouparraymovingavg/">groupArrayMovingAvg </a>- Calculates the moving average of input values.</p>
  </li>
</ul>

<p>There is even an implementation for <a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/reference/stochasticlinearregression/">stochastic Linear and Logistic regression</a> with an option to use a variety of algorithms for updating weights (SGD of course, but also Adam, Nesterov and Momentum)! Not only is that just plain cool, but think of the overhead you can save not moving your data out of the database! </p>

<p>The analytics functions lead me to the next item.. I had been impressed with the work Mark and others had done to benchmark ClickHouse, but I wanted to focus a bit more on time series data rather than your traditional Taxi ride set many have used. I started looking for some large datasets and didn’t find what I wanted, so in a similar approach to the <a href="https://github.com/namebrandon/Sparkov_Data_Generation">Sparkov</a> project, I decided to generate my own. </p>

<p>I found a big boost from the team behind the Python <a href="https://github.com/TimeSynth/TimeSynth">TimeSynth</a> package, as with their help I was able to address the largest fault I’ve found with most synthetic “time series” data. Most synthetic data sets that purport to be time series are usually just generated with a random number generator based on a uniform or gaussian distribution, which means the data is independent. This is the case even with the wonderful <a href="https://github.com/timescale/tsbs">Time Series Benchmark Suites (TSBS)</a>. Part of the magic of time series data is the temporal dependency inherent in the values. With the availability of the TimeSynth package it became trivial to implement a solution that could generate billions of records that had an autoregressive component, as well as to add noise based in a Gaussian process (meaning the noise generated was i.i.d). </p>

<p>OK, enough exposition, let’s walk through creating an environment to generate 2.5 billion rows of true time series data, and then using ClickHouse to demonstrate some very impressive performance. While ClickHouse has a distributed capability, I was impressed enough with the SMP-style performance to run this on a single instance for now. Even though I used a hefty instance (r5ad.24xlarge, 96 cores, 200GB memory), this is still some fantastic performance. You’re not going to see these numbers on MySQL, even with equivalent hardware, I promise. In fact, I’ve included some RedShift comparisons at the end if you’re interested in the measurements.</p>

<h2 id="hands-on">Hands-On</h2>

<p>Here’s the high-level approach.     </p>

<p>•	Using a Python 3 environment with boto3 we’ll create an ec2 instance   <br>
•	Configure two NVME disks in RAID 0 to use for data generation as well as our ClickHouse storage. <br>
•	Clone <a href="https://github.com/namebrandon/time-series-gen">my repo</a> and use the parallelized Python code there to generate our data. <br>
•	Create the destination table in ClickHouse that’s well suited to our use case of time series data (column-oriented and using the MergeTree engine). <br>
•	Load the data into ClickHouse. <br>
•	Run some queries that demonstrate how we can perform aggregations and windowing functions across billions of rows very quickly.   </p>

<p>At this point I will assume you have an environment running Python 3 and that has the boto3 library installed. There is some more detail on this on my <a href="https://github.com/namebrandon/time-series-gen/blob/master/readme.md">GitHub readme</a> but Google will be your friend here to get to this state if you’re not already there.    </p>

<h3 id="data-generation">Data Generation</h3>

<p>The first thing we’ll need to do is the clone the repo from GitHub.</p>

<div><pre><code data-lang="bash">git clone https://github.com/namebrandon/time-series-gen.git</code></pre></div>

<p>You’ll end up more or less with a structure like this.</p>

<div><pre><code data-lang="text">---\
----\ create-db.sql - SQL DDL to create ClickHouse database and table
----\ gen.py - Python 3 script that is configurable. Data size and details are set here.
----\ launch-ec2.py - Python 3 script that uses AWS SDK to instantiate data generation and query environment
----\ load-data.sh - bash script to load data to ClickHouse
----\ requirements.txt - pip requirements
----\ secrets.txt - you create this. Two lines, account key on first, secret on second line.
----\ time-series.conf - ClickHouse conf.d override for storage - points to nvme raid 0 array</code></pre></div>

<p><code>launch-ec2.py</code> is the python script we’ll be using to create the infrastructure, and as mentioned, requires boto3. There is a requirements.txt for pip usage but that’s for the data generation component. Using it here will take care of the boto3 requirement, but it’s also overkill and you may want avoid those packages being installed in your current environment.</p>

<p>Assuming there are no issues with boto, you need to make sure you create a file called <code>secrets.txt</code> in the root of the directory where you cloned the repo. This should have your AWS IAM secret and key in the file and that’s how the <code>launch-ec2.py</code> obtains credentials for creating AWS resources. If you’ve got them in your environment variables you can re-write the code to use those, I believe <code>os.getenv</code> should help, but if you’re using virtualenv that may make things a bit more complicated.</p>

<p><strong>Please note that you should never store secrets or credentials in version control. My .gitignore will prevent the secrets.txt file from being shared but you should be cautious here and double-check before committing.</strong></p>

<div><pre><code data-lang="bash">touch secrets.txt
<span>echo </span>AADK1134123213 &gt;&gt; secrets.txt
<span>echo </span>asd090jkj12l3kj2l109a-0s9klk3aqa14 &gt;&gt;secrets.txt</code></pre></div>

<p>The final step before we execute the script is to modify any account or region specific items in the code so that they work for you. There is a section in the <code>launch-ec2.py</code> file labeled “Configure your relevant information here”. I’ll let you guess what that section might be for!</p>

<p><strong>One import item:</strong> Part of generating this data as well as optimizing most any database performance is ensuring our I/O subsystem is performing well. As a result, I’ve chosen either the r5ad or c5ad ec2 instance family. These come with a pair of NVME disks that we can put into RAID 0 for very fast I/O throughput. The userdata script that is part of the <code>launch-ec2.py</code> creates this array, and expects certain underlying storage devices. Unless you are comfortable picking up where this code will fail and creating your own array and manually following from this point, <strong>please stick with an r5ad or c5ad instance type (I suggest at minimum a 4xlarge).</strong></p>

<p>Once you’re comfortable with your changes to the <code>launch-ec2.py</code> file, let’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://brandonharris.io/redshift-clickhouse-time-series/">http://brandonharris.io/redshift-clickhouse-time-series/</a></em></p>]]>
            </description>
            <link>http://brandonharris.io/redshift-clickhouse-time-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643541</guid>
            <pubDate>Wed, 30 Sep 2020 20:39:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Definition of News Has Been Legally Changed]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24643481">thread link</a>) | @recroad
<br/>
September 30, 2020 | https://zararsiddiqi.com/definition-of-news-legally-changed/ | <a href="https://web.archive.org/web/*/https://zararsiddiqi.com/definition-of-news-legally-changed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A tipping point has been reached in what is legally considered news. Critiquing a news source by  questioning the facts presented, the manner in which they were communicated, the source's validity, the broadcaster's motivations or any inherent biases that may exist, is no longer a fruitful activity.</p>
<p>That line of critique has been swept aside by legally muddying what news is. The presenter is no longer required to convey any truths and the onus of verification has entirely shifted from the news source to the audience.</p>
<p>There are two ways on how this has been achieved.</p>
<p><em>Burden of Verification</em>: A "reasonable" viewer is expected to "arrive with an appropriate amount of skepticism" based on the material presented by the news outlet. Any lies that the news broadcast may convey are not actionable because the viewer is expected to filter out lies from the truth. Even if the news source is spewing lies they're given a pass because the viewer should have known better to believe it in the first place to believe it. That is, any "reasonable" viewer. Adding this word into any court's ruling opens up the door to say anything.</p>
<p><em>False Presupposition</em>: The presenter can state an assumption which is very likely to be false (or known to be false) and then base future arguments on the suspect assumption. As long as what follows traces back to the false assumption, all is good and anything can be said. For example if a host says "We’re going to start by stipulating that everything Michael Cohen has told the feds is absolutely true", then the presenter has wide latitude on what conclusions they can draw, without ever worrying about whether Cohen was lying.</p>
<p>There are two compounding factors which make this especially harmful.</p>
<p><em>Inability for Skepticism</em>:  The constant bombarding of rhetoric in news shows overwhelms its audience and amplifies the echo in the chamber that the viewer already lives in. There is no pause (or desire to pause) to reflect on whether the information presented should be met with skepticism. The expectation that the consumer has the ability to be skeptical is wrong. The medium has become powerful enough that it overrides a human being's ability to be skeptical, especially one who <em>wants to believe</em> in the lie.</p>
<p><em>Repackaging</em>: Having talk shows disguise as news programs is a laughably easy way of repackaging lies without risking the penalty of being called out. Twenty-four hour news channels can have talk shows with millions of viewers who tune in to get some semblance of valid information. I provide the "some semblance" qualifier only because the audience have been conditioned enough and are polarized enough that they no longer can think on their own, and only tune in to reinforce whatever they already believe. As there is no material differentiation between talk shows and news programs for the audience, the convenient repackaging gives the broadcaster an out to say anything and hide behind the argument, "it's not news, it's a talk show".</p>
<p><img src="https://zararsiddiqi.com/images/news-court-ruling.png" alt="&quot;US District Court, Southern District of New York: Case 1:19-cv-11161-MKV   Document 39   Filed 09/24/20   Page 12 of 19&quot;">
US District Court, Southern District of New York: Case 1:19-cv-11161-MKV   Document 39   Filed 09/24/20  Page 12 of 19</p>
<p>--</p>
<ul>
<li><a href="https://law.justia.com/cases/federal/district-courts/new-york/nysdce/1:2019cv11161/527808/39/">https://law.justia.com/cases/federal/district-courts/new-york/nysdce/1:2019cv11161/527808/39/</a></li>
</ul></div></div>]]>
            </description>
            <link>https://zararsiddiqi.com/definition-of-news-legally-changed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643481</guid>
            <pubDate>Wed, 30 Sep 2020 20:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CloudBee's CodeShip Critical Security Notification]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24643253">thread link</a>) | @seneca
<br/>
September 30, 2020 | https://www.codeshipstatus.com/incidents/91bvlfw9xlm9 | <a href="https://web.archive.org/web/*/https://www.codeshipstatus.com/incidents/91bvlfw9xlm9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
              Dear CodeShip users,</p><p>We are reaching out to inform you of additional information we have uncovered as a result of our continuing investigation of the recent GitHub breach. To provide maximum transparency, we are reporting on the results of our investigation, the impact on users, actions you must take to protect yourself/your organization, and actions we will take to strengthen our security processes going forward.</p><p>On Wednesday, September 16, 2020, CloudBees was notified by GitHub of suspicious activities targeting CodeShip business accounts connected to GitHub via the CodeShip GitHub app and now deprecated CodeShip OAuth tokens. CloudBees immediately initiated an investigation conducted by our security and engineering teams, and on September 27, we identified additional evidence of malicious activity against a failover CodeShip database. On September 29, we uncovered evidence to indicate that a malicious actor had access to this failover instance during the period of June 2019 to June 2020. At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. </p><p>*What type of data was affected?*</p><p>The impacted accounts are those of CodeShip users. No other products or accounts were affected and CodeShip is in no way integrated with other CloudBees products or systems.</p><p>*For all CodeShip users:*</p><p>CodeShip users hashed account passwords, one-time password (OTP) recovery codes, and the OTP secret keys used to seed two-factor authentication all may have been exposed.</p><p>Business contact information for invoicing purposes such as company contact name, company name, VAT number, postal address, phone number also may have been exposed. No payment information, such as bank account numbers or credit card numbers, was exposed. No other CloudBees product other than CodeShip was impacted. Also, the logging system was not accessed for any customers.</p><p>*For CodeShip Basic users:*</p><p>Any information contained in CodeShip users’ pipelines may have been exposed. This includes scripts, environment variables, access tokens and other similar data.</p><p>*For CodeShip Pro users:*</p><p>AES encryption keys may have been exposed.</p><p>*Steps you should take*</p><p>Although at this time we have no evidence that the data potentially exfiltrated has been used, all CodeShip users may have been affected (including free, Basic and Pro accounts) and should take the following steps:</p><p>- Immediately rotate any keys or other secrets for cloud providers, third-party tools, or anything else that you used in your CodeShip pipelines.</p><p>- If using CodeShip Pro, rotate your AES key and re-encrypt your secrets.</p><p>- Immediately identify any other sensitive information that is stored in your pipelines and replace them within your pipelines and on any external systems.</p><p>- Determine whether any of your systems accessible from CodeShip have experienced unauthorized access, by contacting your provider or carefully review your access records.</p><p>- Verify that the source code held in repositories that are linked to your CodeShip account have retained their full integrity.</p><p>- Reset your CodeShip 2FA: <a target="_blank" href="https://documentation.codeship.com/general/about/2fa/">https://documentation.codeship.com/general/about/2fa/</a></p><p>At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. We are continuing to monitor the situation.</p><p>*Steps we are taking*</p><p>As soon as we were notified by GitHub on September 16, we proceeded to rotate all our applications' internal secrets and rebuilt all our AWS AMIs. We are continuing to scrutinize our AWS security logs to monitor for suspicious activity, such as outbound connections to known malicious IPs. To date, we have not found any such activity.</p><p>We want you to be assured that we are taking steps to increase the security strength of the CodeShip product, including but not limited to:</p><p>- Validation that our product threat modeling and large-scope security reviews are systematically implemented.</p><p>- Validation that the application of production security standards to all operational processes and artifacts is systematically implemented.</p><p>- Enhancement of strict restrictions on access to production data and strict segregation of sensitive data.</p><p>- Improvement of existing SIRT processes to ensure faster and better forensic investigation.</p><p>*Who to contact *</p><p> We will update here with any new developments. </p><p>If you still have questions, please contact <a target="_blank" href="mailto:security@codeship.com">security@codeship.com</a>.</p><p>Last but not least, I’d like to apologize for the impact this is having on you. In the decade that CloudBees has been operating SaaS applications, we have always taken full responsibility for our products and we do so today. Please be assured that we will do everything we can to prevent this from happening again. </p><p>- Sacha Labourey, CEO, CloudBees
            </p></div></div>]]>
            </description>
            <link>https://www.codeshipstatus.com/incidents/91bvlfw9xlm9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643253</guid>
            <pubDate>Wed, 30 Sep 2020 20:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defer Reference Implementation for C]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24643034">thread link</a>) | @cyber1
<br/>
September 30, 2020 | https://gustedt.gitlabpages.inria.fr/defer/ | <a href="https://web.archive.org/web/*/https://gustedt.gitlabpages.inria.fr/defer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-1-1">
<p>
In the following code snippet we
have one <i>guarded block</i> and three <i>deferred statements</i>.
</p>

<div>
<pre>guard {
  <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
  <span>if</span> (<span>!</span>p) <span>break</span>;
  <span>defer</span> <span>free</span>(p);

  <span>void</span> * <span>const</span> <span>q</span> = malloc(25);
  <span>if</span> (<span>!</span>q) <span>break</span>;
  <span>defer</span> <span>free</span>(q);

  <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>break</span>;
  <span>defer</span> <span>mtx_unlock</span>(&amp;mut);

  <span>// </span><span>all resources acquired</span>
}

</pre>
</div>

<p>
The idea is that we indicate with a <b><code>defer</code></b> keyword that the
statement, e.g a call to <b><code>free</code></b>, is only to be executed at the end of
the guarded block, and, that we want this action to happen
unconditionally in which way ever the guarded block is left.  For the
three deferred statements together it says that they should be
executed in the inverse order than they were encountered. So the
control flow for this code example can be visualized as follows:
</p>



<p><img src="https://gustedt.gitlabpages.inria.fr/defer/defer-image.png" alt="defer-image.png">
</p>

<p>
Here, the dashed lines represent circumstancial control flow that
might arise when some resources are not available or when the
execution is interrupted by a signal.
</p>

<p>
This new technique has at least two advantages to commonly used <code>C</code> or
<code>C++</code> techniques:
</p>

<dl>
<dt>proximity</dt><dd>The cleanup code (<code>free</code> or <code>mtx_unlock</code>) is coded
close to the place where its need arises.</dd>

<dt>visibility</dt><dd>The cleanup code is not hidden in some previously
defined function (such as for <code>atexit</code> handlers) or
constructor/destructor pairs (<code>C++</code>)</dd>
</dl>


<p>
For normal control flow (without intermediate <b><code>return</code></b>, <code>exit</code>, …)
code with similar properties can be coded with existing tools. The
above is equivalent to something like the following
</p>

<div>
<pre>{
   <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
   <span>if</span> (<span>!</span>p) <span>goto</span> <span>DEFER0</span>;
   <span>if</span> (<span>false</span>) {
     <span>DEFER1</span>:
       free(p);
       <span>goto</span> <span>DEFER0</span>;
   }

   <span>void</span> * <span>const</span> <span>q</span> = malloc(25);
   <span>if</span> (<span>!</span>q) <span>goto</span> <span>DEFER1</span>;

   <span>if</span> (<span>false</span>) {
     <span>DEFER2</span>:
       free(q);
       <span>goto</span> <span>DEFER1</span>;
   }

   <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>goto</span> <span>DEFER2</span>;

   <span>if</span> (<span>false</span>) {
     <span>DEFER3</span>:
       mtx_unlock(&amp;mut);
       <span>goto</span> <span>DEFER2</span>;
   }

   <span>// </span><span>all resources acquired</span>

   <span>goto</span> <span>DEFER3</span>;
   <span>DEFER0</span>:;
}

</pre>
</div>

<p>
Here, the <b><code>if(false)</code></b> clauses guarantee that the deferred statements
are jumped over when they are first met, and the labels and <b><code>goto</code></b>
statements implement the hops from back to front to execute the
deferred statements eventually.
</p>

<p>
Obviously, most <code>C</code> programmers would not code like this but they
would prefer to write down a <i>linearization</i> of the above, which is a
quite common idiom for cleanup handling in <code>C</code>:
</p>

<div>
<pre>{
   <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
   <span>if</span> (<span>!</span>p) <span>goto</span> <span>DEFER0</span>;

   <span>void</span>*<span>const</span> <span>q</span> = malloc(25);
   <span>if</span> (<span>!</span>q) <span>goto</span> <span>DEFER1</span>;

   <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>goto</span> <span>DEFER2</span>;

   <span>// </span><span>all resources acquired</span>

   mtx_unlock(&amp;mut);

 <span>DEFER2</span>:
   free(q);
 <span>DEFER1</span>:
   free(p);
 <span>DEFER0</span>:;
}

</pre>
</div>

<p>
This has the advantage of only making the circumstantial control flow
explicit (with three *=goto=) but it does that for the price of
proximity; the cleanup code is far from the place where its need
arises.
</p>

<p>
Nevertheless, even this linearization needs some form of naming
convention for the labels. For more complicated code the maintenance
of these jumps can be tricky and prone to errors.  This shows another
advantage of the <a href="#org63e5a5c"><code>defer</code></a> approach:
</p>

<dl>
<dt>maintainability</dt><dd>The cleanup specification is not dependent on
arbitrary naming such as labels (<code>C</code>) or RAII classes
(<code>C++</code>) and does not change when <a href="#org63e5a5c"><code>defer</code></a> or <b><code>break</code></b>
statements are added or removed.</dd>
</dl>

<p>
Another important property that is much more difficult to implement in
<code>C</code> (and that needs <b><code>try/catch</code></b> blocks in <code>C++</code>) is that <b>all</b> exits
from the guarded block are detected and acted upon: <b><code>break</code></b>, <b><code>return</code></b>,
<a href="#org18b8cc4"><code>thrd_exit</code></a>, <a href="#org9db677d"><code>exit</code></a>, <a href="#org7f6c106"><code>panic</code></a>, or
an interruption by a signal. That is, unless there are nasal deamons
flying around, we have a forth important property
</p>


<dl>
<dt>robustness</dt><dd>Any deferred statement is guaranteed to be executed
eventually.</dd>
</dl>

<p>
This is different from <code>C++</code>'s handling of destructors, which are only
guaranteed to be executed if there is a <b><code>try/catch</code></b> block underneath.
</p>

<p>
This principle of deferred execution extends to nested
guarded blocks in a natural way, even if they are stacked in
different function calls.
</p>
</div></div>]]>
            </description>
            <link>https://gustedt.gitlabpages.inria.fr/defer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643034</guid>
            <pubDate>Wed, 30 Sep 2020 19:55:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Qiskit release comprehensive textbook for all to learn basic quantum computing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24643006">thread link</a>) | @mindcrime
<br/>
September 30, 2020 | https://quantumzeitgeist.com/qiskit-releases-comprehensive-textbook-for-all-to-learn-basic-quantum-computing | <a href="https://web.archive.org/web/*/https://quantumzeitgeist.com/qiskit-releases-comprehensive-textbook-for-all-to-learn-basic-quantum-computing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
<p>Qiskit hosted a course this past summer, which saw over 4000 students from more than 100 countries registering to attend the same quantum computing courses taught to IBM Quantum interns. Now, Qiskit is planning to offer the same course to anyone who wants to get their feet wet in the world of quantum computing and quantum hardware.</p>



<p>One of the core beliefs the Qiskit team holds to is that anyone trained right can program a quantum computer. Because of this belief, the team wrote an open-source textbook that teaches readers how to use Qiskit in quantum computing. The training is both effective and thorough. A survey revealed that 92 percent of QGSS participants felt that the Qiskit Global Summer School exceeded or was equivalent to other quantum computing courses available.</p>



<figure><img loading="lazy" width="1024" height="668" src="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;ssl=1" alt="" srcset="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;ssl=1 1024w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=300%2C196&amp;ssl=1 300w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=768%2C501&amp;ssl=1 768w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=750%2C490&amp;ssl=1 750w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?w=1050&amp;ssl=1 1050w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;ssl=1 1024w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=300%2C196&amp;ssl=1 300w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=768%2C501&amp;ssl=1 768w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=750%2C490&amp;ssl=1 750w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?w=1050&amp;ssl=1 1050w" data-lazy-src="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The various lectures that will be available for all</figcaption></figure>



<p>The team will be releasing 27 lectures with notes and labs, around a semester’s load of content. The lectures will teach students the basics of programming a quantum computer, introduce famous algorithms such as Shor’s and Grover’s algorithm, and give an overview of how they built quantum bits and use them to represent data. There will even be an introduction to quantum chemistry included. Two prerequisites are a basic understanding of the Python language and linear algebra.</p>



<p>Qiskit believes that quantum computing should be accessible by all, and access to this knowledge should not be limited. They hope that students can teach themselves how to code with quantum computers as well as help and teach others. By doing so, the largest and easiest quantum community will come to fruition.</p>



<p><strong>About<a href="https://qiskit.org/" data-wpel-link="external" rel="external noopener noreferrer"> Qiskit</a></strong></p>



<p>Qiskit is an open-source software development kit that is used to program quantum computers, work with quantum experiments, and write quantum applications. It can be installed by anyone with a working computer and is easily available. The Qiskit community is very tight-knit and often very helpful in sharing information and teaching.</p>
															</div></div>]]>
            </description>
            <link>https://quantumzeitgeist.com/qiskit-releases-comprehensive-textbook-for-all-to-learn-basic-quantum-computing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643006</guid>
            <pubDate>Wed, 30 Sep 2020 19:53:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signals and Threads: Compiler Optimization, with Greta Yorsh]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642987">thread link</a>) | @yminsky
<br/>
September 30, 2020 | https://signalsandthreads.com/compiler-optimization/ | <a href="https://web.archive.org/web/*/https://signalsandthreads.com/compiler-optimization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<!--
## 0:00
# Name
Text with [link](url).  <br><br>New paragraph.
-->

<h2 id="000004">00:00:04</h2>

<p>Welcome to Signals &amp; Threads, in-depth conversations about every layer of the tech stack from Jane Street. I’m Ron Minsky. So, it’s my pleasure today to have a conversation with Greta Yorsh. Greta is a compiler engineer in our compilers team in the London office, and she also has a rich and interesting background in compilers and programming languages and program analysis and verification, and we’re going to talk about all that. She’s also had a lot of experience in both industry and academia, and since 2018, Great has worked with us working on the OCaml compiler. So, Greta, to start with, can you talk about how you got interested in compiler optimization?</p>

<h2 id="000044">00:00:44</h2>

<div><p>I studied in Israel. I did my undergraduate studies in computer science and economics. I found that I don’t cope well with uncertainty, so the interesting mathematical bits of economics were not the right choice for me. So, I decided to do a PhD in computer science in the area of software verification where a lot of the concerns are about ensuring things, so that fits well with my approach to certain things. And after my PhD, I worked for a few years at IBM Watson Research Center in New York working on program analysis and verification problems.
</p><p> After that, I moved to Cambridge in England, and I joined an amazing company, ARM, that makes processors, and I worked there in the compilers team working on the GCC compiler backend for ARM, and after that, I worked at Queen Mary University of London as an assistant professor, or lecturer it’s called in England, where I did research in teaching in the area of compilers, and then recently, a year and a half ago, I joined Jane Street. At Jane Street, I work on the compilers team on the OCaml compiler.</p></div>

<h2 id="000209">00:02:09</h2>

<p>Tell us a little bit more about how that fits into the arc of your research.</p>

<h2 id="000214">00:02:14</h2>

<div><p>I started my research working on the problem of software verification or certain aspects of this problem, proving that software satisfies certain good properties, correctness properties that users expect from it, and that research involved a lot of reasoning about the source code of the program rather than executing it and then using certain formal methods and logical reasoning techniques, decision procedures, in order to prove properties of the program.
</p><p> I worked on that for a while, and there’s this ultimate goal of proving that the software behaves just the way it should be so that real-world executions of their program don’t cause terrible failures, and I was very excited about it for a while, but it is an undecidable problem, a problem that is very hard to solve in general, and that becomes a bit frustrating after a while, and I was interested in what is it that real programmers and users of software want to prove about their programs, and how I can help them using the techniques that I know and the logic that I know.
</p><p> So I worked on that, and in the process of that, I’ve discovered that it’s really fun to work with real users and have people who care about certain things. I don’t know what they care about, but if I talk to them, maybe I’ll find out, and maybe one of the tools I have in my toolbox will help me to give users a tool, and I found it very exciting. I think the first time it happened, it was at IBM, and I was really excited about it, but what I also realized is that not everyone really cares about correctness, that sometimes it’s okay to have bugs in their programs.
</p><p> There are other important aspects of software, like performance. That made a big change to my understanding, because I could now put these very formal techniques together with something practical and try to combine the two. And then when I had the chance to work at ARM on the GCC compiler backend for ARM, I’ve discovered how important it is, the performance and how exciting it is to work on this micro-optimization, CPU-specific, machine-specific optimization, how much difference they make to the behavior of the program, to the performance behavior from these characteristics of the program, and at the same time, working on the compiler, you just can’t have bugs. An important property of the compiler is that so much else in our system is built on top of it. That was a tool that combines correctness and performance. It’s an optimization function that is very clear and measurable, as opposed to what properties do users want to have for their programs, and that’s how I came to work in compilers.</p></div>

<h2 id="000458">00:04:58</h2>

<div><p>Yeah, it’s interesting, you’re starting off by focusing on verification, because I think verification is this very shiny and attractive goal, because there’s this basic fact about programming, which is that we’re all terrible at it. Humans are bad at writing programs. Program languages are things that, at their best, do, infuriatingly, only the very specific things you ask them to do and not what you intended, and so trying to close that gap between the thing you tried to do and the terrible thing that you actually wrote down is an attractive goal.
</p><p> You were talking about one of the problems of verification, and just to be clear, by verification, formal methods (lots of terms here), we basically mean coming up with the moral equivalent of a proof that a program matches some specification. So you write in some precise, higher-level way what the program is supposed to do, and then there’s the actual program that you’ve written, and some kind of proof of the program does what it’s intended to do. You mentioned undecidability – an undecidable problem is one where you can show that there is no general technique that solves it all the time, and you mention that as a sign of how difficult the problem is. But, it’s a funny thing, in some sense almost everything that we do is undecidable, right? You can’t answer almost any interesting question about a program in full generality, the classic result being the halting program: You can’t even tell whether a given problem is going to ever finish executing in a general way. But that normally doesn’t stop us. The way we deal with this is we tend to provide people not with fully automated systems that solve all of their problems, but instead, tools that they can use while they write programs. They can maybe do some extra work along the side to help ensure the correctness of those programs, and those tools might be in the form of testing systems, and they might be in the forms of something that looks more like formal methods, things that, essentially, along with the program, develop some aspect of the proof of correctness of the program. So, I’m curious what you think about the kind of practicality and ergonomics of formal methods as a thing that can be layered into the programming process to make it easier for people to write programs that do the right thing.</p></div>

<h2 id="000702">00:07:02</h2>

<div><p>The kind of verification, proving properties of programs, that I think of when I say software verification (traditional methods) involve writing a program in one language and then providing specification of its behavior, telling what properties should hold about the program in a different language, in logic of some kind that describes it, and then proving that the specification and the implementation are conformed. That is very different from the type system approach that OCaml takes where the types are the specification of the program, and that is something I’m learning as I become better at programming in OCaml. But the kind of verification I’m talking about, the idea of specifying these properties on the side somewhere or even in the program, but in a different syntax, I think is a big problem for adopting this kind of technology. It’s possible to specify something about the library, but keeping it up to date as the code evolves is very hard. Same problem with documentation, but as you try to reason about it, and you have a tool that runs together with the specification and the code and checks them against each other as you do the development, there is some hope to keep the code and the spec aligned, but still, the programmer needs to write both of them. So, there is opportunity for automation to save some work for the programmer and keep the two aligned.
</p><p> I also wanted to mention, when you were talking about verification, so different people think of verification as different things. To me, it is what you said. It’s the more formal proof about the source code of the program and its properties, but for most of the development process, it is testing. It’s running the program on some inputs and checking that the outputs behave as we expect. So, after working a bit and trying to find the right logics that are expressive enough to describe the properties we want and at the same time, allow us to prove automatically that the program conforms to these properties, you find, “oh, this is very restrictive.” Then you look, but testing is so much better. “I’ve been working on this for two years, but I could’ve found this bug with a simple test.” So how do we find tests that are good tests, or do we have good tests? So, this problem has been worked on by many people, and what I find exciting is that taking the testing approach, finding test cases, and the formal proof approach, and combining them helps us build better tools. So, there are many ways in which each side can help the other, and I worked on exploring some of these ways, and I found it very interesting. And I think this shows up in the verification, but there are also similar combinations of static and dynamic information or execution time and compile time information that are useful for compilers during compilations.</p></div>

<h2 id="000949">00:09:49</h2>

<p>It’s interesting for you to say this thing about the way in which tests and formal proofs mix together. I feel like this is a thing that I’ve noticed informally on my own in programming, which is the OCaml type system, and in general type systems, are a kind of lightweight formal method. Types only capture some fairly limited properties of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://signalsandthreads.com/compiler-optimization/">https://signalsandthreads.com/compiler-optimization/</a></em></p>]]>
            </description>
            <link>https://signalsandthreads.com/compiler-optimization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642987</guid>
            <pubDate>Wed, 30 Sep 2020 19:51:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you should care about Robot Framework – Part I]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642945">thread link</a>) | @kim_schiller
<br/>
September 30, 2020 | https://testautomation.dev/why-you-should-care-about-robot-framework-part-i/ | <a href="https://web.archive.org/web/*/https://testautomation.dev/why-you-should-care-about-robot-framework-part-i/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Have you ever heard of Robot Framework? If not, then this article will show you why you should care about Robot Framework and how it can be useful to you in your test automation work.</p>



<h2>What is Robot Framework?</h2>



<p>Robot Framework is a generic test automation framework. You use it primarily for functional acceptance testing and it is well suited for acceptence test driven development (ATDD) or similar approaches, but has also been extended to be used for robotic process automation (RPA). It is open source and implemented in Python.</p>



<p>While it is frequently used for testing web applications, it extends far beyond that. It can be used for testing REST API’s, databases, Java desktop applications, mobile applications and really it can be used on most types of systems. More on that later.</p>



<h2>Keyword-Driven</h2>



<p>One of the benefits of using Robot Framework is that you have an easy way to define and execute test cases, without the need to know technical details. This makes it a very useful for collaboration between test engineers, domain experts and developers. And using <strong>keywords</strong> makes this happen. </p>



<p>If you are not familiar with keyword-driven testing, here are the most important things you need to know.</p>



<ul><li>Keywords provide a layer of abstraction that hide implementation details away from the user.</li><li>Any action or step you define in your test case is considered a keyword.<ul><li>example: <code>Open login page</code></li></ul></li><li>You can add arguments to keywords<ul><li>example: <code>Open login page   user    password<mark id="annotation-text-8dd14e67-57d7-4a0d-b96c-ca4a857b4150"></mark></code></li></ul></li><li>You can reuse an already defined keyword in multiple test cases.</li><li>Keywords are well suited for automation</li></ul>



<h2>Architecture</h2>



<div><figure><img src="https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture-241x300.png" alt="Robot Framework architecture diagram" width="300" srcset="https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture-241x300.png 241w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture-823x1024.png 823w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture-768x955.png 768w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture.png 1010w" sizes="(max-width: 241px) 100vw, 241px"><figcaption>Figure 1: Robot Framework Architecture</figcaption></figure></div>



<p>Don’t skip this section! The modular architecture of Robot Framework is one of the main attractions, since this is what provides you with the great versatility this framework offers.</p>



<p>You pass test data into the framework, which in turn communicates with the system under test through the use of libraries, as you will see more of in the next chapter. </p>



<p>The libraries can use tools internally to provide functionality or contain the whole implementation themselves.</p>



<p>An example of using tools, is the AppiumLibrary for mobile testing, which internally uses the <a href="http://appium.io/">Appium Framework</a> to do all the heavy lifting. In this instance, the Robot Framework library acts as a wrapper of Appium functionality in keywords, ready to use.</p>



<p>By having this layered model, with the Library API at the core, Robot Framework makes it easy for you to:</p>



<ul><li>Test practically any type of system regardless of technology stack. (This is something most Record-Playback tools promise as well, but with Robot Framework, you don’t have to sell your soul to get it. 😉 )</li><li> Maintain stable test cases, even if the technology in the system under test changes.</li><li>Have full control over how test tests call the system under test, by adding your own library.</li></ul>







<h2>Libraries</h2>



<p>As mentioned earlier, Robot Framework can be used to test a wide range of systems. This is due to its well thought out architecture that you just saw, that allows external libraries to be plugged in to the framework.</p>



<p>External? Yes, well there are a number of libraries already included in the framework as <strong>standard libraries</strong>, for you to use. And you will use many of them for basic operations on files, strings, working with dates and lists and so on. </p>



<p>As for the <strong>external libraries</strong>, there are many external libraries developed by others, like:</p>



<ul><li><a href="https://github.com/jollychang/robotframework-appiumlibrary">AppiumLibrary</a></li><li><a href="http://franz-see.github.com/Robotframework-Database-Library/">Database Library</a></li><li><a href="https://github.com/kowalpy/Robot-Framework-FTP-Library">FTP Library</a></li><li><a href="https://github.com/eficode/JavaFXLibrary">JavaFXLibrary</a></li><li><a href="https://github.com/asyrjasalo/RESTinstance/">RESTinstance</a></li><li><a href="http://github.com/robotframework/SeleniumLibrary/">SeleniumLibrary</a></li></ul>



<div><figure><img loading="lazy" src="https://testautomation.dev/wp-content/uploads/2020/07/python-logo.png" alt="Python logo" width="292" height="99" srcset="https://testautomation.dev/wp-content/uploads/2020/07/python-logo.png 601w, https://testautomation.dev/wp-content/uploads/2020/07/python-logo-300x101.png 300w" sizes="(max-width: 292px) 100vw, 292px"></figure></div>



<p>You can also create your own library. The easiest option is to create it using Python. Robot Framework natively understands Python. </p>



<p>But if you run Robot Framework on the Java implementation Jython, you can write libraries in Java, and for .NET you can run IronPython and write libraries in supported .NET-languages.</p>



<p>In addition you can use the remote library feature, which opens up even more options. A remote library launches a remote server as a gateway to your library. There are remote servers available for Java, Ruby, .NET, Clojure, Perl, node.js and PHP. Check out the project: <a href="https://github.com/robotframework/RemoteInterface">https://github.com/robotframework/RemoteInterface</a></p>



<h2>Reporting</h2>



<p>Reporting is a very important feature in a test framework. Some frameworks come with only basic reporting functionality, that you normally can expand on yourself. But with Robot Framework you get a very comprehensive report and log out-of-the-box.</p>



<p>A test run produces three report artifacts. A <strong>report.html</strong> with an overview of the complete test execution. A <strong>log.html</strong> that contains details for each test, including output from each keyword executed. And finally an <strong>output.xml</strong> containing the raw data in XML format. Anyone interested in the test result, can read the HTML files, which are formatted to be human readable. External tools can use and process the XML file, eg. a test management system or continuous integration system.</p>



<p>The report looks like this:</p>



<div><figure><img loading="lazy" width="1024" height="690" src="https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-1024x690.png" alt="Robot Framework Test Report" srcset="https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-1024x690.png 1024w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-300x202.png 300w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-768x518.png 768w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-1536x1035.png 1536w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report.png 1730w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Figure 2: Robot Framework Test Report</figcaption></figure></div>



<p>In case you are wondering, the background color is not always <span>green</span>. When one of your tests fail, it changes to <span>red</span>. This is a small feature, but it can actually be very valuable. <strong>Failed tests should make noise!</strong></p>



<h2>Community</h2>



<p>You are going to get stuck! And you will have questions. When this happens, you can join the Robot Framework online communities and get help. </p>



<div><figure><img loading="lazy" width="226" height="230" src="https://testautomation.dev/wp-content/uploads/2020/07/slack.png" alt="Slack logo"></figure></div>



<p>The most active place is probably Slack, where you will find several channels for specific topics.</p>



<p>Also you should visit the new <a href="https://forum.robotframework.org/">Robot Framework forum</a> and the still active mailing list on Google Groups.</p>



<p>The community is friendly and very helpful, both helping you solve problems you might run in to and in general discussing the use of the framework and the surrounding ecosystem.</p>



<h2>Development and maintenance</h2>



<p>Robot Framework was originally developed by <a href="https://twitter.com/pekkaklarck">Pekka Klärck</a> as his masters theses in 2005, and was further developed during his time at Nokia Networks and finally open sourced in 2008. Pekka is still active as lead developer on the framework.</p>



<p>Since then, the Robot Framework Foundation has been established as a non-profit organisation with the objective to sponsor the development of the framework and the ecosystem. They are also helping in organising local meetup groups as well as the annual <a href="https://robocon.io/">RoboCon</a> conference.</p>



<p>As of today there are more than 40 members of the foundation. This provides a strong backing for the framework.</p>



<h2>Conclusion</h2>



<p>Robot Framework is a keyword-driven generic test automation framework written in Python. It is a versatile framework that can be used to test most systems regardless of technology. </p>



<p>At the core of its architecture is a library API, that allows external libraries to be used to communicate with the system under test. Apart from the standard libraries being included, there is a growing number of libraires developed for both common and not so common technologies. A comprehensive test status report and log is built in, that has both an HTML version and XML version. </p>



<p>There is a very active community around Robot Framework, with a lot of discussions, which mostly takes place on Slack. And the creator of the framework, Pekka Klärck, is very active in the community and is lead developer on the framework. However, the development has been adopted by the Robot Framework Foundation, where over 40 members now sponsor the framework development.</p>



<p>Go check out <a href="https://robotframework.org/">Robot Framework</a> now. Or wait, because soon you can read the next part in this two-part series, <em>Why you should care about Robot Framework – Part II,</em> where you will be introduced to writing and executing test cases in Robot Framework. Coming soon…</p>



<hr>
<div heateor-sss-data-href="https://testautomation.dev/why-you-should-care-about-robot-framework-part-i/"><p>Share this post with your friends and followers:</p><ul></ul></div>	</div></div>]]>
            </description>
            <link>https://testautomation.dev/why-you-should-care-about-robot-framework-part-i/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642945</guid>
            <pubDate>Wed, 30 Sep 2020 19:46:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can Artificial Intelligence help with the Coronavirus vaccine search?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642851">thread link</a>) | @Sanksshep
<br/>
September 30, 2020 | https://www.aiplusinfo.com/blog/aiandcovid19 | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/aiandcovid19">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f6660711674913350fd1601"><div><div><div data-block-type="2" id="block-5638530cbcac306ba30c"><p><h2>Artificial Intelligence can help accelerate the search for Coronavirus (COVID-19) vaccine. My thoughts, research, and approach to benefit &amp; accelerate the search for Coronavirus vaccine using artificial intelligence.</h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1600544883185_4355"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1601252346673-38UEV8LFISCPL031AC0N/ke17ZwdGBToddI8pDm48kKC_hTD-rFzHwTnJxMBwHBZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UTNiI2uMwdQQKY2MK1cexINQOr1bn4yoydgWGauILAZDG6v6ULRah83RgHXAWD5lbQ/coronavirus-5590560_1920.png" data-image="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1601252346673-38UEV8LFISCPL031AC0N/ke17ZwdGBToddI8pDm48kKC_hTD-rFzHwTnJxMBwHBZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UTNiI2uMwdQQKY2MK1cexINQOr1bn4yoydgWGauILAZDG6v6ULRah83RgHXAWD5lbQ/coronavirus-5590560_1920.png" data-image-dimensions="1920x1358" data-image-focal-point="0.5,0.5" alt="source:&amp;nbsp; Alexandra_Koch , via&amp;nbsp; pixabay &amp;nbsp;(CC0)" data-load="false" data-image-id="5f712bfa4278c74ee0ed73b2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1601252346673-38UEV8LFISCPL031AC0N/ke17ZwdGBToddI8pDm48kKC_hTD-rFzHwTnJxMBwHBZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UTNiI2uMwdQQKY2MK1cexINQOr1bn4yoydgWGauILAZDG6v6ULRah83RgHXAWD5lbQ/coronavirus-5590560_1920.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1600544883185_6098"><div><blockquote>
<p>Before I start I would like to take this opportunity to thank all the COVID warriors who are on the frontline. This is hard, folks on the frontlines are real heroes! We cannot thank them enough. Scientific research is not easy, there are a million edge cases that these scientists need to think of and apply, our body is very complex and different due to diversity and habits. They are not making 2-minute noodles. So please be patient and help them by staying home, wearing a mask and maintaining social distancing. Help them flatten the curve till we find a solution. 🙏</p>
</blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600544883185_4645"><div><h2>Preface</h2><p>Artificial intelligence has had its share of debates where we have questioned how can it be used for good and bad. There is a lot of fear and hope as a result of these discussions and debates. What we need right now is a ray of hope in these dark times when we are fighting a pandemic. It is time that AI lives up to its hype and helps the scientific community in the search of a vaccine. I write this piece with a lot of responsibility and would like to share my research and thoughts on this topic through this article.</p><p>I am very fortunate to have an interest in AI and the opportunity to work with AI. I think AI is playing three strategic roles in this quest of helping scientist fight Coronavirus —</p><ul data-rte-list="default"><li><p><em>Running complex algorithms by parsing diverse datasets and identifying components of a vaccine by understanding the viral protein structure of COVID -19.</em></p></li><li><p><em>By helping medical researchers parse through tons of relevant research papers at an unprecedented pace.</em></p></li><li><p><em>Identifying compounds using AI and cloud computing to prevent the Spike protein from binding to the ACE2 receptor on human cells.</em></p></li></ul><p>A lot of companies/institutes have&nbsp;created&nbsp;AI tools, shared data sets, and research results, and shared them freely with the global scientific community.</p><p>According to the National Institute of Allergy and Infectious Diseases, There are three types of vaccines —</p><ul data-rte-list="default"><li><p>Whole-Pathogen Vaccines</p></li><li><p>Subunit Vaccines</p></li><li><p>Nucleic Acid Vaccines</p></li></ul><p>The types of vaccines the scientific community is interested in, are the subunit vaccine and nucleic acid vaccine type.&nbsp;These types of vaccines inject genetic material of the pathogen into human cells to stimulate an immune response.&nbsp;The latter is the type of vaccine targeting the virus, that began trials this week in the United States. AI is useful in accelerating the development of subunit and nucleic acid vaccines.</p><p>Proteins are an essential part of viruses and are made up of a sequence of amino acids that determine their unique 3D structure.&nbsp;Once we understand the structure of the protein, scientists can develop response based drugs that work with the protein’s unique structure.&nbsp;However, it would be impossible to examine all possible shapes of a protein before finding its unique 3D structure. AI can expedite this process by a million fold and helps us identify compounds that can vector in the unique protein structure.</p><p>There has been extensive work done on this using AI by a lot of organizations and institutions.&nbsp;In January, Google DeepMind introduced&nbsp;<a href="https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery">AlphaFold</a>, a cutting-edge system that predicts the 3D structure of a protein-based on its genetic sequence.&nbsp;In early March, the system was put to the test on&nbsp;<a href="https://deepmind.com/research/open-source/computational-predictions-of-protein-structures-associated-with-COVID-19">COVID-19</a>. DeepMind released protein structure predictions of several under-studied proteins associated with SARS-CoV-2, the virus that causes COVID-19, to help the research community better understand the virus.</p><p>The University of Texas at Austin and the National Institutes of Health used a popular biology technique to create the&nbsp;<a href="https://news.utexas.edu/2020/02/19/breakthrough-in-coronavirus-research-results-in-new-map-to-support-vaccine-design/">first 3D atomic-scale map</a>&nbsp;of the part of the virus that attaches to and infects human cells — the spike protein.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1600544883185_6812"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1600545451047-JQYFQNL6P8BFX5J2IT50/ke17ZwdGBToddI8pDm48kFX2KuRl8d90069-zQ5z-Q1Zw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7UAwRg-drVjy0tH40Gqh4FNmfMO9L-gD9pMjeJ2_fJe7yhtyYWkC_zq_QBMOQI-dPg/Protien_Structure.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1600545451047-JQYFQNL6P8BFX5J2IT50/ke17ZwdGBToddI8pDm48kFX2KuRl8d90069-zQ5z-Q1Zw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7UAwRg-drVjy0tH40Gqh4FNmfMO9L-gD9pMjeJ2_fJe7yhtyYWkC_zq_QBMOQI-dPg/Protien_Structure.jpg" data-image-dimensions="214x300" data-image-focal-point="0.5,0.5" alt="Protien_Structure.jpg" data-load="false" data-image-id="5f6662aa179c39639df86337" data-type="image" src="https://www.aiplusinfo.com/blog/Protien_Structure.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600544883185_7101"><div><pre><code>This is a 3D atomic-scale map, or molecular structure, of the 2019-nCoV spike protein. The protein takes on two different shapes, called conformations — one before it infects a host cell, and another during infection. This structure represents the protein before it infects a cell, called the prefusion conformation. Credit: Jason McLellan/<a href="https://news.utexas.edu/2020/02/19/breakthrough-in-coronavirus-research-results-in-new-map-to-support-vaccine-design/">Univ. of Texas at Austin</a></code></pre><p><a href="https://www.ipd.uw.edu/">University of Washington’s Institute for Protein Design</a>&nbsp;also used computer models to develop&nbsp;<a href="https://www.ipd.uw.edu/2020/02/rosettas-role-in-fighting-coronavirus/">3D atomic-scale models of the SARS-CoV-2 spike</a>&nbsp;protein that closely match those discovered in the UT Austin lab.</p><p>It is crucial to be on top of the scientific research on COVID-19 but it requires a lot of effort to keep up with the results and collate them at one common platform. This can really help the scientific community by sharing critical pieces of information that will save them a lot of time and effort. Labs report their work via published articles and increasingly via preprint services like&nbsp;<a href="https://www.biorxiv.org/">bioRxiv</a>&nbsp;(<a href="https://connect.biorxiv.org/relate/content/181">COVID-19 Work</a>) and&nbsp;<a href="https://www.medrxiv.org/">medRxiv</a>&nbsp;(<a href="https://connect.medrxiv.org/relate/content/181">COVID-19 Work</a>).</p><p>As new research keeps getting published on a daily, sometimes hourly basis in this critical time. it becomes increasingly difficult for the scientists to be on top of the research, connect the dots, and uncover insights.</p><p>In this pursuit,&nbsp;<a href="https://allenai.org/">Allen Institute for AI</a>&nbsp;has partnered with several research organizations to produce the&nbsp;<a href="https://pages.semanticscholar.org/coronavirus-research">COVID-19 Open Research Dataset (CORD-19)</a>, a unique resource of over forty thousand plus scholarly articles about COVID-19, SARS-CoV-2, and related coronaviruses. It is updated daily as new research is published. This freely available data set is machine-readable, so researchers can create and apply natural-language processing algorithms, and hopefully accelerate the discovery of a vaccine.</p><p>AI has played a vital role in the COVID-19 outbreak apart from just research.</p><ol data-rte-list="default"><li><p><em> AI startup&nbsp;</em><a href="https://www.cnbc.com/2020/03/03/bluedot-used-artificial-intelligence-to-predict-coronavirus-spread.html"><em>Bluedot</em></a><em>&nbsp;detected a cluster of unusual pneumonia cases in Wuhan in late December and accurately predicted where the virus might spread.<br></em></p></li><li><p><em>&nbsp;</em><a href="https://www.cnbc.com/2020/03/18/how-china-is-using-robots-and-telemedicine-to-combat-the-coronavirus.html"><em>Robots</em></a><em>&nbsp;have been reducing human interaction by disinfecting hospital rooms, moving food and supplies, and delivering telehealth consultations. AI is being used to&nbsp;</em><a href="https://www.wsj.com/articles/online-map-tracks-coronavirus-outbreak-in-real-time-11583354911"><em>track and map the spread of infection</em></a><em>&nbsp;in real-time,&nbsp;</em><a href="https://www.radiologybusiness.com/topics/artificial-intelligence/artificial-intelligence-ct-images-coronavirus-diagnosis"><em>diagnose infections</em></a><em>,&nbsp;</em><a href="https://www.medrxiv.org/content/10.1101/2020.02.27.20028027v2"><em>predict mortality risk</em></a><em>, and more.<br></em></p></li><li><p><em>AI and FLIR enabled helmets have been used to monitor the temperature in large scale and regulate, isolate, and transfer patients who have shown symptoms of COVID-19.<br></em></p></li><li><p><em>AI enabled&nbsp;models that predict the rate of spread of this infection and help us flatten the curve with better targeting.<br></em></p></li><li><p><em>AI enabled models that predict the mutations of the virus that can help our scientists work with the vaccine to counter the mutations.<br></em></p></li><li><p><em>Robots that help healthcare workers with limiting the exposure to the patients.<br></em></p></li><li><p><em>Doctors using AI to triage COVID-19 patients (More info&nbsp;</em><a href="https://www.technologyreview.com/2020/04/23/1000410/ai-triage-covid-19-patients-health-care/"><em>here</em></a><em>).<br></em></p></li><li><p><em>AI is being used to fight misinformation about COVID-19.</em></p></li></ol><p>There is a slight problem though, modern AI methods require large amounts of labeled data to be effective, and that data isn’t currently available. Even when data is available, human judgment is essential to carefully analyze AI’s pattern recognition. This is something we need to keep in mind while using AI as a tool on such large scale unvetted data.</p><h2>My Approach</h2><p>Here is my humble attempt to accelerate the search for the COVID-19 vaccine using AI.</p><p>While we have some issues with the way we are collating data with regards to what is happening in real-time, we have some solid input based on the 3d structure of the protein that forms the outer layer of this virus. My approach to identifying a series of compounds used in drugs that are already available in the market.</p><p>My approach towards the problem from a technical standpoint encompasses the following steps.</p><ol data-rte-list="default"><li><p>Identify possibilities of the virus outer structure.</p></li><li><p>Identify vector possibilities from the diverse set of structures of the lipid spike protein.</p></li><li><p>Go through the list of available vaccines/medicines, parse them to identify chemical compounds.</p></li><li><p>Identify compounds that prevent the spike protein to bind with the ACE2 receptors of the human cells.</p></li></ol><h2>Algorithms</h2><p>The following algorithms have been used during the various stages of the research.</p><ul data-rte-list="default"><li><p>Cluster analysis</p></li><li><p>K-means clustering</p></li><li><p>Decision tree/forest</p></li><li><p>K-NN</p></li><li><p>Statistical classification</p></li></ul><p>My approach was to identify and use the rules of deduction so we can focus on the compounds that are probable. This would mean the positives will be limited and we can focus on them. The first step in this process was to do some cluster analysis on the compounds and identify positives. The next step was to build a strong decision tree / decision forest. Once the criteria was established, I ran the compounds through the decision forest. I was able to tweak the decision forest based on results which helped in streamlining compounds further. Once the positives were identified, I wanted to identify the nearest compounds to the positive compounds. This approach helped me identify&nbsp;34 compounds using AI that&nbsp;<strong><em>may</em></strong>&nbsp;prevent the spike protein from binding to the AEC2 receptors in the human&nbsp;body. Using these compounds&nbsp;<strong><em>may</em></strong>&nbsp;help stop the replication of the COVID-19 virus within the&nbsp;human body.</p><h2>Cluster Analysis</h2></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1600544883185_9444"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1600545774238-FGXXS3D2SUBX1ZSO5A8P/ke17ZwdGBToddI8pDm48kO3V6q6KF4Q0x4UdZodyGVNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEUyZMBYoKljUDZzBUjLz9HCyU9QRw0ahXsdyZm4nwj3jFvbuqF0GUInBxxtVhBOn4/ClusterAnalysis.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1600545774238-FGXXS3D2SUBX1ZSO5A8P/ke17ZwdGBToddI8pDm48kO3V6q6KF4Q0x4UdZodyGVNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEUyZMBYoKljUDZzBUjLz9HCyU9QRw0ahXsdyZm4nwj3jFvbuqF0GUInBxxtVhBOn4/ClusterAnalysis.gif" data-image-dimensions="405x386" data-image-focal-point="0.5,0.5" alt="Data modeling of data compiled. GIF created via&amp;nbsp; imgflip" data-load="false" data-image-id="5f6663ee6909a42b50203e8f" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Data modeling of data compiled. GIF created via&nbsp;<a href="http://imgflip.com/">imgflip</a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600544883185_9733"><div><p>The objective of cluster analysis is to assign observations to groups “clusters” so that observations within each group are similar to one another with respect to variables or attributes of …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aiplusinfo.com/blog/aiandcovid19">https://www.aiplusinfo.com/blog/aiandcovid19</a></em></p>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/aiandcovid19</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642851</guid>
            <pubDate>Wed, 30 Sep 2020 19:39:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using redo to manage data analysis workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642732">thread link</a>) | @kkoncevicius
<br/>
September 30, 2020 | http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/ | <a href="https://web.archive.org/web/*/http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p>Real world data analysis projects are often quite complicated.
They can involve multi-gigabyte input files, complex data cleaning procedures, week-long computations, and elaborate reports.
Making changes and then tracking down the parts that need to be recomputed becomes close to impossible.
In this article I describe my approach for dealing with this problem, which is based on a lesser known build automation tool - redo<a href="#fn:1" id="fnref:1" title="see footnote"><sup>◦</sup></a>.</p>

<h2 id="redo">Redo</h2>

<p>Data science projects typically have complex pipelines involving input files, code, results, and reports.
Analyses can be computationally intensive and take hours if not days or weeks to complete.
Hence data science practitioners need to be able to make changes without restarting the whole pipeline from scratch.
Workflow management becomes essential and many projects turn to build automation tools like Make<a href="#fn:2" id="fnref:2" title="see footnote"><sup>◦</sup></a>.
However Make has its warts, in particular when applied to data analysis, and so people end up designing their own variants, such as SCons<a href="#fn:3" id="fnref:3" title="see footnote"><sup>◦</sup></a>, Snakemake<a href="#fn:4" id="fnref:4" title="see footnote"><sup>◦</sup></a>, and Drake<a href="#fn:5" id="fnref:5" title="see footnote"><sup>◦</sup></a>, among others.</p>

<p>One lesser known alternative to the above mentioned tools goes by the name of “redo”.
Redo is a recursive build automation system that promises to be simpler and more powerful than Make.
Unlike Make or its derivatives redo is tiny, recursive, and has no special syntax of its own.
It allows us to declare target dependencies straight from within the code being executed, which enables writing scripts that “know” they will need to rerun themselves whenever their input data changes all without maintaining a separate dependency configuration file.
In this demonstration we will be using the redo version by “apenwarr”<a href="#fn:6" id="fnref:6" title="see footnote"><sup>◦</sup></a> who rediscovered, documented, and popularized the idea and is the author and current maintainer of its most comprehensive implementation<a href="#fn:7" id="fnref:7" title="see footnote"><sup>◦</sup></a>.</p>

<h2 id="setup">Setup</h2>

<p>A typical data analysis workflow has four parts: 1) obtaining the data; 2) cleaning the data; 3) estimating a model; 4) producing a report.
Similarly our dummy project will consist of four steps:</p>

<ol>
<li>Obtain a dataset of chicken weights and their feed supplements.</li>
<li>Subset the data by only selecting one type of feed supplement.</li>
<li>Produce a “model” for the selected supplement using empirical density estimation.</li>
<li>Summarise the obtained results in a report.</li>
</ol>

<p>Each step will produce an output and save the results to a separate file.
To keep things simple all the scripts for the steps above will be written in R.
The overall goal is to construct a pipeline that can detect changes in our stored data files or our code and automatically reproduce the final report with all its dependencies.
This demonstration will start simple and add complexity along the way.</p>

<h2 id="doingandredoing">Doing and redoing</h2>

<p>Let’s start with the most basic redo command.
In the first step we have to obtain a dataset of chicken weights plus the type of supplements they were fed and store it in a file.
The dataset is already freely available from within R so all we have to do is save it.
We enter the commands to do the task in a file named <code>'rawdata.rds.do'</code>:</p>

<pre><code>1.  #!/usr/bin/env Rscript
2.
3.  outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.
5.  saveRDS(chickwts, file = outfile)
</code></pre>

<p>Then to obtain the data file we go to a command line and call redo:</p>

<pre><code>$ redo rawdata.rds

redo:  rawdata.rds
</code></pre>

<p>Which creates the <code>'rds'</code> file named <code>'rawdata.rds'</code> containing the data and informs us about the result.</p>

<p>Some explanation is necessary.
The redo command simply takes an argument and tries to produce a file of the same name.
In this case the argument was <code>'rawdata.rds'</code> and, given the command, redo starts looking for instructions about how to produce it.
The rule for storing instructions is quite simple - they are stored in a separate file with a name constructed by adding a <code>'.do'</code> suffix to the original argument.
In other words - redo looks for instructions about producing <code>'rawdata.rds'</code> file in a file named <code>'rawdata.rds.do'</code>.</p>

<p>The file itself is treated as a shell script.
This is why it is started with a hash-bang<a href="#fn:8" id="fnref:8" title="see footnote"><sup>◦</sup></a> sequence followed by a path to a program that will be used to interpret the instructions.
We want to write our script in R so we specify Rscript.</p>

<p>Finally, when redo calls our script with <code>'redo rawdata.rds.do'</code> it passes three arguments to it:
1) The target name itself - <code>'rawdata.rds'</code>, 2) The basename of the target file - <code>'rawdata'</code>, 3) The temporary file to save the data in - <code>'rawdata.rds.redo.tmp'</code>.
After the execution finishes the file stored in the temp file (3rd argument) will be moved to the target (1st argument).
This mechanism makes sure that in the case of failed computation the existing target will not be corrupted.
And that is why we do not specify the output filename within the script ourselves but rather use the 3rd variable provided by redo.</p>

<p>The dataset is obtained and stored and so the first step of this project is now complete.</p>

<h2 id="dependencies">Dependencies</h2>

<p>What happens if we execute the previous redo command again? - nothing spectacular:</p>

<pre><code>$ redo rawdata.rds

redo  rawdata.rds
</code></pre>

<p>Redo executed the instruction file again and reproduced the output.
But there exists another command called <code>redo-ifchange</code> that behaves a bit differently:</p>

<pre><code>$ redo-ifchange rawdata.rds
</code></pre>

<p>After calling this command - nothing happens.
<code>redo-ifchange</code> differs from redo in an important way: it checks if any dependencies needed to reproduce the specified output have changed.
In our case redo knows only a single dependency for our <code>'rawdata.rds'</code> file - the ‘do’ instruction file itself.
It hasn’t changed so <code>redo-ifchange</code> halts and does not reproduce the target.</p>

<p>So let’s move on to the second step of the project and select a feed type.
To achieve this we produce a separate R file called <code>'subdata.rds.do'</code>:</p>

<pre><code>1.   #!/usr/bin/env Rscript
2.
3.   outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.
5.   system("redo-ifchange rawdata.rds")
6.   rawdata &lt;- readRDS("rawdata.rds")
7.
8.   subdata &lt;- rawdata[rawdata$feed == "soybean", ]
9.
10.  saveRDS(subdata, file = outfile)
</code></pre>

<p>Take a closer look at the 5th line in the file above.
Here, before loading the data, we call the <code>redo-ifchange</code> command on it.
At this step the script temporarily halts and checks if our requested data file, <code>rawdata.rds</code>, needs to be recomputed.
If the target file is missing or some of its dependencies have changed it will be regenerated by calling the <code>'rawdata.rds.do'</code> script.
And if nothing changed the 5th line passes without redoing anything and the already existing data file is used.</p>

<p>Now, to obtain the output for the second step, we request the file with redo, just like before:</p>

<pre><code>$ redo subdata.rds

redo subdata.rds
</code></pre>

<p>All done, the result is stored in <code>'subdata.rds'</code>.
Currently we have the following files in our project:</p>

<pre><code>$ tree
.
├── rawdata.rds
├── rawdata.rds.do
├── subdata.rds
└── subdata.rds.do
</code></pre>

<p>Let’s remove all the <code>'rds'</code> data files and try reproducing the <code>'subdata.rds'</code> again:</p>

<pre><code>$ rm *.rds
$ redo subdata.rds

redo  subdata.rds
redo    rawdata.rds
</code></pre>

<p>Here we asked for <code>'subdata.rds'</code> but redo was smart enough to reproduce both of the data files.
What we did, in essence, is declared a dependency between two R scripts from within the script itself.</p>

<h2 id="defaultinstructions">Default instructions</h2>

<p>Before moving on we have to spend some time on a few redo implementation details.
By convention when we call <code>'redo a.b.rds'</code> command redo starts looking for an <code>'a.b.rds.do'</code> script.
But if the file doesn’t exist redo will search for a different file named <code>'default.b.rds.do'</code> which should store general instructions for producing any <code>'*.b.rds'</code> file.
As an example we rename our previous <code>'subdata.rds.do'</code> file to <code>'default.subdata.rds.do'</code>.
Now this do script will get executed whenever we use redo to request a file that ends with <code>'subdata.rds.do'</code>:</p>

<pre><code>$ mv subdata.rds.do default.subdata.rds.do
$ redo a.subdata.rds b.subdata.rds

redo a.subdata.rds
redo b.subdata.rds
</code></pre>

<p>Since both files generated above were produced by the same script <code>'default.subdata.rds.do'</code> they are identical - they both hold the data for soybean feed.
Those files will no longer be needed for our demonstration so we can get rid of them:</p>

<pre><code>$ rm *subdata.rds
$ tree
.
├── default.subdata.rds.do
├── rawdata.rds
└── rawdata.rds.do
</code></pre>

<h2 id="parameters">Parameters</h2>

<p>The default instructions introduced above can be exploited to implement parameters in our do scripts.
In the current stage we have a script - <code>'default.subdata.rds.do'</code> that is executed whenever we request an ‘rds’ file that ends with <code>'subdata.rds'</code>.
It always produces the data for the soybean feed but we can make it return different outputs based on the prefix of the target file.</p>

<p>Currently the feed types we are selecting are hard-coded in the code itself.
It would be nicer if we can specify them as parameters passed to the R script.
We rewrite <code>'default.subdata.rds.do'</code> file:</p>

<pre><code>1.   #!/usr/bin/env Rscript
2.
3.   outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.   feed    &lt;- strsplit(outfile, "\\.")[[1]][1]
5.
6.   system("redo-ifchange rawdata.rds")
7.   rawdata &lt;- readRDS("rawdata.rds")
8.
9.   subdata &lt;- rawdata[rawdata$feed == feed, ]
10.
11.  saveRDS(subdata, file = outfile)
</code></pre>

<p>Two changes were made:
1) the 4th line uses the prefix of the output file in order to decide which feed type should be returned;
2) the 9th line then uses the selected feed type in order to subset the data.
This allows us to request various types of feed data:</p>

<pre><code>$ redo soybean.subdata.rds

redo soybean.subdata.rds

$ redo casein.subdata.rds

redo casein.subdata.rds
</code></pre>

<p>And now we have separate types in separate files.</p>

<h2 id="redoingwithparameters">Redoing with parameters</h2>

<p>In the third step we need a do script that, given subsetted feed data, estimates the density function and stores the result to a separate file.
Like the previous script, we want it to be general and produce the results for any selected feed type.
For this to work we have to know which input file to load based on the given output file.
If the script will be called by <code>'redo soybeen.density.rds'</code> command our target will be <code>'soybean.density.rds'</code>.
And from this we can deduce that the input file needed to obtain its density is <code>'soybean.subdata.rds'</code>.</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/">http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/</a></em></p>]]>
            </description>
            <link>http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642732</guid>
            <pubDate>Wed, 30 Sep 2020 19:30:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial Intelligence in Health Care]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642719">thread link</a>) | @Sanksshep
<br/>
September 30, 2020 | https://www.aiplusinfo.com/blog/ai-in-healthcare | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/ai-in-healthcare">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-3857ad1892c7d8adea01"><p><h2>Artificial intelligence has the potential to transform many aspects of patient care and administrative processes in healthcare. I think the role of artificial intelligence will be an asset to all healthcare professionals. The following article contains examples of artificial intelligence in healthcare and companies doing a great job at it.</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1600557578492_4166"><div><h3>Introduction</h3><p>Artificial intelligence (AI), Machine learning, NLP, Robotics, and Automation are increasingly prevalent in all aspects and are being applied to healthcare as well. These technologies have the potential to transform all aspects of health care from patient care to the development and production of new experimental drugs that can have a faster roll-out date than traditional methods.&nbsp;</p><p>There are numerous research studies suggesting that AI can outperform humans at key healthcare tasks, such as diagnosing ailments. Here is a great example, <a href="https://www.bbc.com/news/health-50857759#:~:text=Artificial%20intelligence%20is%20more%20accurate,images%20from%20nearly%2029%2C000%20women." target="_blank">AI ‘outperforms’ doctors diagnosing breast cancer¹.</a></p><p>Artificial intelligence is a collection of technologies that come together form artificial intelligence. AI’s diverse range of technologies impacts a wide spectrum of healthcare.&nbsp;</p><p>Tech firms and startups are also working assiduously on the same issues. Google, for example, is collaborating with health delivery networks to build prediction models from big data to warn clinicians of high-risk conditions, such as sepsis and heart failure. Google, Enlitic, and a variety of other startups are developing AI-derived image interpretation algorithms. Jvion offers a ‘clinical success machine’ that identifies the patients most at risk as well as those most likely to respond to treatment protocols. Each of these could provide decision support to clinicians seeking to find the best diagnosis and treatment for patients.</p><p>You will find below some technologies that improve a specific area in healthcare with examples sourced from the internet with citations.&nbsp;</p><h3>Machine learning</h3><p>Machine learning is an application of artificial intelligence (AI)<em> </em>that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves².</p><p>There are majorly three types of Machine learning — </p><ul data-rte-list="default"><li><p>Supervised Learning</p></li><li><p>Unsupervised Learning</p></li><li><p>Reinforcement Learning&nbsp;</p></li></ul><p>In healthcare, the most common application of machine learning is predictive medicine  —  predicting what treatment alternatives are likely to work best on a patient based on various patient traits, history, the treatment situation, and protocols. The supervised learning model for predictive medicine applications requires a training dataset, like all supervised learning models. the difference here is that there may be a lot of variables.&nbsp;</p><p>Using neural networks it is now possible to also predict whether a patient will acquire a particular ailment or not based on a set of variables and conditions that can be fed into algorithms in the form of data.</p><p>One common application of deep learning and neural networks is the ability to detect ailments/issues in the radiology images. I think deep learning should be increasingly applied wherever clinically possible. This will allow doctors and radiologists to just supervise results and focus on other important aspects of their job. This combination promises better accuracy of finding ailments with limited human intervention or supervision.&nbsp;</p><p>Here are some organizations that are doing groundbreaking work in this area.</p><blockquote><p><strong>Organization:</strong> <a href="https://www.pathai.com/">PathAI</a><br><strong>Location: </strong>Cambridge, Massachusetts<br><strong>How it’s using AI in healthcare:</strong> PathAI is developing machine learning technology to assist pathologists in making more accurate diagnoses. The company’s current goals include reducing errors in cancer diagnosis and developing methods for individualized medical treatment³.</p><p><strong>Organization:</strong> <a href="https://www.enlitic.com/">Enlitic</a><span><br></span><strong>Location: </strong>San Francisco, California<br><strong>How it’s using AI in healthcare: </strong>Enlitic develops deep learning medical tools to streamline radiology diagnoses. The company’s deep learning platform analyzes unstructured medical data (radiology images, blood tests, EKGs, genomics, patient medical history) to give doctors better insight into a patient’s real-time needs³.</p></blockquote><h3>Natural language processing</h3><p>In healthcare, most applications of NLP involve the creation, understanding, parsing, and classification of clinical documentation and published research. NLP can also be used to analyze clinical notes, prescriptions, help prepare reports, and possibly conversational AI. Few good examples of how NLP is currently being used.&nbsp;</p><ul data-rte-list="default"><li><p>Parsing data realtime from coronavirus research that is being published globally. You can find more information about this in my article <a href="https://medium.com/@sanksshep/how-can-ai-help-with-the-covid-19-vaccine-search-a68d40fc0cb0" target="_blank">here</a>.&nbsp;</p></li><li><p>Project Meena by Google. More information can be found <a href="https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html" target="_blank">here</a>.</p></li></ul><h3>Decision Tree&nbsp;</h3><p>Decision trees require doctors and engineers to come up with an if-then-else decision flow chart that can help train machines to make decisions by building complex algorithms based on the finalized decision tree. This is critical and processes heavy software design, this enables the machines to take accurate decisions with human intervention. This will help save a ton of time for doctors and patients alike. This will enhance the capabilities of doctors to predict, analyze, and come up with a treatment plan for patient care.&nbsp;</p><p>This can also be used extensively in vaccine and treatment research provided the known variable is the ailment we are making the vaccine for and its pre-set conditions and protocols. This is an effective mechanism for pre-morbidity patients as well.&nbsp;</p><h3>Robotics</h3><p>Robots are becoming more intelligent, as other AI capabilities are being embedded in their OS. Other areas of improvements in AI have exponentially improved the capabilities of the robots and their ability to perform complex operations.</p><p>One such area of operation is robotic surgery. This enables surgeons to perform complex procedures with much greater precision and create precise, minimized, invasive incisions, and stitches. This is a game-changer in performing surgery, as long as human supervision exists. &nbsp;</p><p>Here are some examples of organizations using AI and Robotics&nbsp;</p><blockquote><p><strong>Organization: </strong><a href="https://www.vicarioussurgical.com/" target="_blank">Vicarious Surgical</a><br><strong>Location: </strong>Charlestown, Massachusetts<br><strong>How it’s using AI in healthcare: </strong>Vicarious Surgical combines virtual reality with AI-enabled robots so surgeons can perform minimally invasive operations. Using the company’s technology, surgeons can virtually shrink and explore the inside of a patient’s body in much more detail³.</p><p><strong>Organization:</strong> <a href="https://www.aurishealth.com/" target="_blank">Auris Health</a><br><strong>Location: </strong>Redwood City, California<br><strong>How it’s using AI in healthcare: </strong>Auris Health develops a variety of robots designed to improve endoscopies by employing the latest in micro-instrumentation, endoscope design, data science and AI. Consequently, doctors get a clearer view of a patient’s illness from both physical and data perspective³.</p><p><strong>Organization:</strong>  <a href="https://www.accuray.com/" target="_blank">Accuray</a>  <br><strong>Location: </strong>Sunnyvale, California<br><strong>How it’s using AI in healthcare: </strong>The Accuray CyberKnife System uses robotic arms to precisely treat cancerous tumors all over the body. Using the robot’s real-time tumor tracking capabilities, doctors and surgeons are able to treat only affected areas rather than the whole body. The Accuray CyberKnife robot uses 6D motion-sensing technology to aggressively track and attack cancerous tumors while saving healthy tissue³.</p><p><strong>Organization:</strong> <a href="https://www.intuitive.com/" target="_blank">Intuitive</a><br><strong>Location:</strong> San Francisco, California<br><strong>How it’s using AI in healthcare:</strong> Intuitive’s da Vinci platforms have pioneered the robotic surgery industry. Being the first robotic surgery assistant approved by the FDA over 18 years ago, the surgical machines feature cameras, robotic arms, and surgical tools to aide in minimally invasive procedures.<br>The da Vinci platform is constantly taking in information and providing analytics to surgeons to improve future surgeries. So far, da Vinci has assisted in over five million operations³.</p><p><strong>University: </strong><a href="https://www.cmu.edu/" target="_blank">Carnegie Mellon University</a> <br><strong>Location:</strong> Pittsburgh, Pennsylvania<br><strong>How it’s using AI in healthcare:</strong> The robotics department at Carnegie Mellon University developed Heartlander, a miniature mobile robot designed to facilitate therapy on the heart. Under a physician’s control, the tiny robot enters the chest through a small incision, navigates to certain locations of the heart by itself, adheres to the surface of the heart, and administers therapy³.</p><p><strong>Organization:</strong> <a href="http://microsure.nl/" target="_blank">MicroSure</a><br><strong>Location:</strong> Eindhoven, The Netherlands<br><strong>How it’s using AI in healthcare:</strong> MicroSure robots help surgeons overcome their human physical limitations. The company’s motion stabilizer system reportedly improves performance and precision during surgical procedures. Currently, eight of MicroSure’s micro-surgical operations are approved for lymphatic system procedures³.</p><p><strong>Organization:</strong> <a href="https://www.mazorrobotics.com/index.php/en-us/" target="_blank">Mazor Robotics</a><br><strong>Location:</strong> Caesarea, Israel<br><strong>How it’s using AI in healthcare:</strong> Surgeons use the Mazor Robotics’ 3D tools to visualize their surgical plans, read images with AI that recognizes anatomical features and perform a more stable and precise spinal operation³.</p></blockquote><h3>Robotic process automation</h3><p>Robotic process automation performs structured digital tasks for administrative purposes, ie those involving information systems, as if they were a human user following a script or rules. It relies on a combination of workflow, business rules, and ‘presentation layer’ integration with information systems to act like a semi-intelligent user of the systems. In healthcare, they are used for repetitive tasks like prior authorization, updating patient records, or billing. When combined with other technologies like image recognition, they can be used to extract data from, for example, faxed images in order to input it into transactional systems.</p><h3>Mass personalization</h3><p>Artificial Intelligence can help in mass personalization of patient care, treatments, procedures, vaccine research, and production. This along with human interaction can reduce costs and improve coverage across the board for healthcare.&nbsp;</p><p>AI can help with various aspects of patient care, like, charting the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aiplusinfo.com/blog/ai-in-healthcare">https://www.aiplusinfo.com/blog/ai-in-healthcare</a></em></p>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/ai-in-healthcare</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642719</guid>
            <pubDate>Wed, 30 Sep 2020 19:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systems Thinking: A Technical Overview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642695">thread link</a>) | @genghizkhan
<br/>
September 30, 2020 | https://hawkradius.com/systems-thinking-a-technical-overview/ | <a href="https://web.archive.org/web/*/https://hawkradius.com/systems-thinking-a-technical-overview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://hawkradius.com/content/images/size/w300/2020/09/systems-thinking-header.jpg 300w,
                            https://hawkradius.com/content/images/size/w600/2020/09/systems-thinking-header.jpg 600w,
                            https://hawkradius.com/content/images/size/w1000/2020/09/systems-thinking-header.jpg 1000w,
                            https://hawkradius.com/content/images/size/w2000/2020/09/systems-thinking-header.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://hawkradius.com/content/images/size/w2000/2020/09/systems-thinking-header.jpg" alt="Systems Thinking: a Technical Overview">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>I've had to to a bunch of reading about systems thinking with respect to healthcare recently, sparking an intense interest in the topic. You tend to find <a href="https://thesystemsthinker.com/systems-thinking-what-why-when-where-and-how/">a lot</a> <a href="https://learningforsustainability.net/systems-thinking">of literature</a> <a href="https://medium.com/disruptive-design/tools-for-systems-thinkers-the-6-fundamental-concepts-of-systems-thinking-379cdac3dc6a">online</a> talking about it. Systems thinking is described as an approach to problem solving in which one thinks about the whole system as being comprised of constituent parts and concentrates on parts and relationships both.</p>
<p>However, that doesn't really tell us much about what it is and how one goes about using this paradigm. If one wants to really get into what systems thinking is about, a more academic source might be handier. For the purposes of this article, I refer to a paper called "A Definition of Systems Thinking: A Systems Approach" by Arnold and Wade from 2015<sup><a href="#fn1" id="fnref1">[1]</a></sup> which goes about the process of definition in a very interesting way.</p>
<h2 id="sowhatreallyissystemsthinking">So what really is systems thinking?</h2>
<p>We can start by saying that systems thinking is, really, nothing more than a <em>system of thinking about systems</em>. If that sounds like a circular concept, buckle up. Systems tend to be the easiest to define using their function or their purpose; but that is, often, the hardest part of a system to tease out. In this case, fortunately, it is easy. The function of systems thinking is to think about systems!</p>
<p>To go deeper, we need to define what a system <em>is</em>. The Oxford Dictionary tells us that a system is "a set of things working together as parts of a mechanism or an interconnecting network; a complex whole." In other words, it is a set of things (let's call them elements) which are connected to each other, signifying relationships. So systems thinking is a framework which gives us the tools to understand how a system functions.</p>
<h3 id="whyisthisneeded">Why is this needed?</h3>
<p>Understanding systems turns out to be fundamental to nearly every task we manage because systems surround us. Nothing in this world is completely independent. Society, the government, electricity transmission, the shipping industry, the ecosystem of a pond, the climate are all examples of systems. Understanding each of them is an art in of itself: understanding their effects on each other and the surrounding world might be beyond the world's fastest supercomputer!</p>
<p>Hold on, you might say at this point. Don't we already understand these things? Aren't we already fluent in our understanding of electricity transmission systems? Didn't we <em>design</em> the government? Isn't the shipping industry the bedrock of all modern consumerism?</p>
<p>The answer is kind of, to all of those. Or rather, it depends on how we define these systems. Sure, we understand electricity transmission systems. But a huge element of these systems is the group of consumers who sit pretty at the other end, the ones who actually consume the electricity being generated and transmitted. Another big part happens to be the workers who maintain these lines. Another element of this system might be politicians (depending on your country) who may have a vested interest in making sure that the constituents of their choice get the generated electricity. Claiming that we understand all these actors and the relationships between them is more than can be said by most people. Similarly, it would be the height of folly for any man or woman to claim that they understand the inner workings of the government or the economic eddies that govern shipping.</p>
<p>The classical approach to problems such as this is called reductionism. Most wielders of the scientific method are intimately familiar with this school of thought. Break a complex problem into its constituent parts, understand each part, and lo behold! The complex, intractable problem is now reduced to several manageable issues.</p>
<p>This tends to be one part of systems thinking. Knowing how to define the elements of a system requires one to be educated in reductionism, but understanding their relationships tends to be a problem of exponentially increasing complexity as the number of elements of a system increase.</p>
<p>So let's start with the easier part of systems thinking. Reducing it to its elements.</p>
<h3 id="elementsofsystemsthinking">Elements of systems thinking</h3>
<p>Stave and Hopper (2007) give us a set of elements with which we may start understanding systems thinking<sup><a href="#fn2" id="fnref2">[2]</a></sup>:</p>
<ol>
<li>Recognizing Interconnections</li>
<li>Identifying Feedback</li>
<li>Understanding Dynamic Behavior</li>
<li>Differentiating types of flows and variables</li>
<li>Using Conceptual Models</li>
<li>Creating Simulation Models</li>
<li>Testing Policies</li>
</ol>
<p>Arnold and Wade (2015) add to and subtract from these elements to give us the following:</p>
<ol>
<li><strong>Recognizing Interconnections:</strong> This tends to be the most basic systems thinking still. One needs to be able to identify the key parts of a system and figure out the key relationships between them</li>
<li><strong>Identifying and Understanding Feedback:</strong> A bunch of these relationships form feedback loops, where two elements may feed into each other. These need to be understood and evaluated separately from the others</li>
<li><strong>Understanding System Structure:</strong> This is a step above the other two elements, in which one takes these key relationships and understands how the parts of a system fit together so as to describe the system as a whole</li>
<li><strong>Differentiating Types of Stocks, Flows, Variables:</strong> A stock is a pool of a given resource in a system. A flow would be the inflow or outflow of that resource. A variable would be something like flow-rate or the maximum quantity of a stock. Once the system structure is understood, stocks, flows and variables need to be quantified and described separately</li>
<li><strong>Identifying and Understanding Non-Linear Relationships:</strong> This has been separated out from the previous element by Arnold and Wade. In particular, this element is also about measuring stocks and flows, but it measures those which do not have linear relationships with each other</li>
<li><strong>Understanding Dynamic Behavior:</strong> All the elements and relationships which have been understood interact with each other and may behave unpredictably. Such behaviour is called dynamic behaviour. Understanding this is one of the core functions of systems thinking</li>
<li><strong>Reducing Complexity by Modeling Systems Conceptually:</strong> While complexity is part and parcel of most systems, understanding them often requires stripping away that complexity and observation from different angles. In other words, one needs to know how to model a system so as to be able to explain it well</li>
<li><strong>Understanding Systems at Different Scales:</strong> And finally, this skill is the ability to understand systems at different scales. Each element of a system may be a system itself, and the system being viewed is probably an element in a more complex system. Being aware of these details can lead to better insights</li>
</ol>
<h3 id="relationships">Relationships</h3>
<p>Now that we know all the elements, we can see what the relationships between them are like. The easiest way to understand it is to map it out (adapted from Arnold and Wade, 2015).</p>
<p><img src="https://hawkradius.com/content/images/2020/09/systems-thinking-relationships-5.png" alt="Relationships between the elements of systems thinking"></p>
<p>This is a slightly complicated map. In short, the thick arrows with solid borders represent strong relationships, and the thin arrows with dotted borders represent weak relationships. The strong relationships are as follows:</p>
<ol>
<li>Understanding system structure strongly enhances understanding of dynamic system behaviour</li>
<li>Understanding a system's structure leads to developing conceptual models properly</li>
<li>A conceptual understanding of the system may lead to insights about the system's role in as an element in bigger systems as well as the complexity of its constituent elements</li>
</ol>
<p>The weak relationships come out thus:</p>
<ol>
<li>Understanding dynamic behaviour of a system may prompt one to go back and take a second look at the elements and relationships already identified</li>
<li>It is often worth going back and re-identifying elements and relationships when making conceptual systems</li>
<li>Understanding a system conceptually makes it easier to identify and seek out dynamic behaviour</li>
<li>Once a person is able to start understanding systems at different scales, it can reveal additional elements and relationships one might not have picked up at the start of the exercise</li>
<li>Understanding dynamic behaviour can allow the incorporation of dynamic models when creating a conceptual system</li>
<li>Knowledge of the different scales at which a system operates can help in enhancing the accuracy of any conceptual models one might like to use</li>
</ol>
<p>All the four major elements in the diagramme strongly improve one's ability to identify systems, predict their behaviours, and devise modifications if and when needed.</p>
<h2 id="definitionofsystemsthinking">Definition of systems thinking</h2>
<p>So now that we <em>have</em> come this far, we can understand the definition of systems thinking:</p>
<blockquote>
<p>Systems thinking is a set of synergistic analytic skills used to improve the capability of identifying and understanding systems, predicting their behaviors, and devising modifications to them in order to produce desired effects. These skills work together as a system. - Arnold and Wade (2015)</p>
</blockquote>
<p>These analytical skills and their interconnections are easy enough to understand, and they make complete sense when seen from the lens of systems thinking itself.</p>
<p>In the next post in this series, we shall look at some systems thinking frameworks used in healthcare followed by an intervention strategy informed by the same.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Arnold, R.D. and Wade, J.P., 2015. A definition of systems thinking: A systems approach. Procedia computer science, 44(2015), pp.669-678. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>Stave, K. and Hopper, M., 2007, July. What constitutes systems thinking? A proposed taxonomy. In 25th International Conference of the System Dynamics Society. <a href="#fnref2">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://hawkradius.com/systems-thinking-a-technical-overview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642695</guid>
            <pubDate>Wed, 30 Sep 2020 19:27:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buy vs. Building Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642596">thread link</a>) | @neinasaservice
<br/>
September 30, 2020 | https://21-lessons.com/2020/09/30/buy-vs-build/ | <a href="https://web.archive.org/web/*/https://21-lessons.com/2020/09/30/buy-vs-build/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><div id="content">
		<div>

		

<header id="masthead" role="banner">
	<div>

		<p><a href="https://21-lessons.com/" rel="home" itemprop="url"><img width="400" height="400" src="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-size="patch-site-logo" itemprop="logo" data-attachment-id="694" data-permalink="https://21-lessons.com/original-scaled/" data-orig-file="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Original – Scaled" data-image-description="" data-medium-file="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1" data-lazy-src="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p><div>
		<p><a href="https://21-lessons.com/" rel="home">
			21 Lessons		</a>

		</p></div>
			<p><span>Learn 21st Century Skills</span>
			</p>

		
	</div><!-- .site-branding -->

	<nav id="site-navigation" role="navigation">

		<ul id="menu-main-menu"><li id="menu-item-343"><a href="https://21lessonscom.wordpress.com/">Home</a></li>
<li id="menu-item-1094"><a title="About Jan" href="https://work-with-jan.com/">About</a></li>
</ul>
	</nav><!-- #site-navigation -->

</header><!-- #masthead -->


	<div id="primary">
		<main id="main" role="main">

			
<article id="post-1145">

    <div>

        
        <header>
            <div>

                <p><span><a href="https://21-lessons.com/category/business/" rel="category tag">Business</a>, <a href="https://21-lessons.com/category/programming/" rel="category tag">programming</a></span></p><div>

                    <p><span> by <span><a href="https://21-lessons.com/author/jan21lessonscom/">Jan</a></span></span><span><a href="https://21-lessons.com/2020/09/30/buy-vs-build/" rel="bookmark"><time datetime="2020-09-30T14:54:00-04:00">September 30, 2020<span>2:54 pm</span></time></a></span>
                </p></div>

            </div><!-- .entry-meta -->

            
        </header><!-- .entry-header -->

        
    </div>

	<div>

		
<figure><img data-attachment-id="1146" data-permalink="https://21-lessons.com/2020/09/30/buy-vs-build/buy_vs_build/" data-orig-file="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?fit=2048%2C2048&amp;ssl=1" data-orig-size="2048,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Buy_Vs_Build" data-image-description="" data-medium-file="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?fit=980%2C980&amp;ssl=1" loading="lazy" width="980" height="980" src="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=980%2C980&amp;ssl=1" alt="Buy vs Build Sketchnote, explaining the cost of not using a paid tool for CI/CD" srcset="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=2048&amp;ssl=1 2048w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=800%2C800&amp;ssl=1 800w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=400%2C400&amp;ssl=1 400w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=200%2C200&amp;ssl=1 200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=640%2C640&amp;ssl=1 640w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=500%2C500&amp;ssl=1 500w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=928%2C928&amp;ssl=1 928w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=600%2C600&amp;ssl=1 600w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=100%2C100&amp;ssl=1 100w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=1960&amp;ssl=1 1960w" sizes="(max-width: 980px) 100vw, 980px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=2048&amp;ssl=1 2048w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=800%2C800&amp;ssl=1 800w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=400%2C400&amp;ssl=1 400w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=200%2C200&amp;ssl=1 200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=640%2C640&amp;ssl=1 640w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=500%2C500&amp;ssl=1 500w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=928%2C928&amp;ssl=1 928w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=600%2C600&amp;ssl=1 600w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=100%2C100&amp;ssl=1 100w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=1960&amp;ssl=1 1960w" data-lazy-src="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=980%2C980&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>

<p id="jp-relatedposts">
	<h3><em>Also checkout these posts</em></h3>
</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->



		</main><!-- #main -->
	</div><!-- #primary -->


<div id="secondary" role="complementary">

	
</div><!-- #secondary -->		</div><!-- .container -->
	</div><!-- #content -->

	<!-- #colophon -->
	<div>
		<div>
			<form role="search" method="get" action="https://21-lessons.com/">
				<label>
					<span>Search for:</span>
					
				</label>
				
			</form>			<p>Begin typing your search above and press return to search. Press Esc to cancel.</p>
		</div>
		</div>
</div></div>]]>
            </description>
            <link>https://21-lessons.com/2020/09/30/buy-vs-build/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642596</guid>
            <pubDate>Wed, 30 Sep 2020 19:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Progress in Biology Is Slow – Here's How We Can Speed It Up]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24642489">thread link</a>) | @ashwal
<br/>
September 30, 2020 | https://adamashwal.com/irreducible | <a href="https://web.archive.org/web/*/https://adamashwal.com/irreducible">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			<p>Living is great and I'd prefer to do more of it. Unfortunately, progress towards immortality has been rather slow — for all of our technological progress in the last century we've only picked up a few extra years of life. An incorrect framing of the problem has led to slow progress, but with a little bit of mind shift we can choose much better strategies for learning about and manipulating biology.</p>
<h3 id="what-s-the-status-quo-">What's the status quo?</h3>
<p>There's been a subset of humans over the last 100 years who also would like to live longer and healthier lives and have invested considerable time and energy into this problem. They've mostly failed as is evidence by the fact if you make it out of childhood, keep a good BMI, stop smoking, and exercise, you'll make it, at best, <a href="https://ourworldindata.org/life-expectancy">a decade longer than someone in the 1700s</a> (provided you escaped the trough of death that was childhood). In that same 100 years we took our first flight on Earth and then landed on the moon. In that same 100 years we went from 0 transistors per chip to 50,000,000,000. In that same 100 years we invented the Cool Ranch Dorito. So why did we succeed in so many other places but have failed in the most important? Why don't we live extremely long, healthy, and happy lives?</p>
<h3 id="why-has-this-approach-worked-in-other-areas-">Why has this approach worked in other areas?</h3>
<p>Some problems are, in retrospect, clearly easier than others. But if you had surveyed the leading minds in 1900 which would be easier: splitting the atom, sending a probe outside the solar system, or living to 90, it's hard to imagine it would be the last option they would have chosen. Yet here we are.</p>
<p>There are problems that on the face of it seem of similar difficulty to an outsider but are magnitudes (and magnitudes and magnitudes) harder to solve. What leads to this difference can be summarized as <em>computational reducibility</em>. As way of example, take the planet. Think of every atom on Earth- the rocks, the trees, that one ex who still drifts in and out of memory. If I want to know where this sphere will be in the universe tomorrow or 1,000 years from now and I don't have a notion of basic physics I may think this intractable. There's so much going on! How could one possibly think to describe how all these atoms would move through space and time? But it turns out to be fairly trivial - all those atoms can be reduced to a single point, a center of mass, and then calculations of momentum can be easily computed and trajectory projected forward. There are many systems that allow for these "shortcuts" where the dimensionality can be collapsed and the useful information is still present. A bridge builder doesn't need to think of each atom in a brick, or even really the brick; it's enough to think of the collection of bricks and how they are arranged.</p>
<h3 id="engineering-takes-place-in-reducible-places">Engineering takes place in reducible places</h3>
<p>Engineering, generally, is the practice of working on problems that are tractable. Given constraints on energy and time, only hard problems that have been sufficiently reduced are tractable and as such are the ones that are worked on. Oftentimes science leads us to new ways of reducing the complexity of problems (think Newton and his equations in the previous example). This isn't a law, just a result of how resources are allocated. </p>
<h3 id="is-biology-reducible-">Is Biology Reducible?</h3>
<p>We haven't seen progress in biology because it is stubborn to attempts to reduce it. Darwin was one of the last great reducers - able to collapse the high dimensional problem of evolution into a few axioms. But even with natural selection in hand, the resolution of claims is not particularly specific. Hypotheses are hard to prove or disprove given the near impossibility of running a counterfactual and it mostly serves as a post-hoc description (large proboscis <a href="https://en.wikipedia.org/wiki/Xanthopan">moths</a> notwithstanding). Perhaps if we were luckier we could  have lived in a universe that allowed us to use natural selection to know the structure of cells and animals without having to go look (this is a little true - something I'll explore in a future post), similar to knowing the position of the planets a millennia in advance.</p>
<p>What is it about biology that makes it irreducible but splitting the atom was something we accomplished 80 years ago? Spitting in the face of entropy is hard and the number of problems that need to be solved by a biological system are vast. The components of that system are not elegant fundamental laws of the universe but artisanal components created by random search through a loosely constrained fitness space. Even highly conserved pathways still exist in a unique context of the whole organism. </p>
<h3 id="biology-s-drunken-walk">Biology's Drunken Walk</h3>
<p>Biology is constantly transitioning from current state to a future state where some future branch of the evolutionary tree has higher fitness but the potential branch space is massive and the "choice" of which branch is picked is a random process. For example, in a scenario where the environment is slowly acidifying, any given bacteria has many solutions to survive. While aesthetically they could be vastly different (off the top of my head: changes to cell membranes, additional transmembrane proton pumps, neutralizing organelles, heat shock proteins, etc), which one ends up being dominant for a given bacteria is a random mutation. Given enough bacteria "searching" the solution space, you'll likely see many solutions.</p>
<p>Crucially, because in any scenario there is a one-to-many relationship between a problem and solutions, you can't extrapolate which solutions an organism possesses based on reasoning. You can’t postdict, you have to go look.</p>
<h3 id="so-what-do-we-do-">So, what do we do?</h3>
<p>So biology suffers from low reducibility - we aren’t able to summarize systems allowing us to make inferences cheaply. In the instance of disease this prevents both easy understanding of the disease state, i.e. what is going wrong, and prevents easy drug design, i.e. which node in the system do I push on in order to reverse the disease state. Right now, drug discovery is a lot of serendipity and a lot of pretending we know enough to pick targets. Unsurprisingly, this mostly fails.</p>
<p>There is another way. Currently, we brute force biology via Grad student search and it’s remarkably slow. A small number of underpowered, poorly done experiments makes up the bulk of what is produced. A model organism is chosen, an intervention is proposed, a measurement is done, and a paper is written: repeat ad nauseam. </p>
<p>But if an infinite number of monkeys can write Shakespeare, an infinite number of mice can allow us a way forward.</p>
<p>If we care about blood pressure, for example, why have we not given every drug, at every dosage, every regiment, and in every combination to a mouse and actually seen what happens?
We <em>do</em> have high throughput screening, mostly in individual cells or enzymes, but this is mostly garbage owing to the information decay from cell to whole organism (something I will expound on in a future post). Is my proposed solution expensive? Yes! Combinatorial explosions are the opposite of computational reducibility. But my point is that we can't just hope to have cheaper solutions in the future – that is the ostrich approach to progress. And we spent $288,100,000,000 to get to the moon.</p>
<p>The problem is also not as intractable as it may first seem. How do we test a large number of drugs on a large number of mice? Drive the cost down on any marginal mouse. Recent advances in machine learning allow automation of those pesky variable costs. Image recognition and classification are now good enough to track a mouse and its movements automatically - there is no need to babysit mice and manually classify behavior. With the state of every mouse known, simple robotics, e.g. food/medication administration and outcome measurements, become possible. The simplest experiments are possible today, and with a concerted effort, the realm of possible can grow. </p>
<p>There will always be innovations in new measurement techniques, new ways of peering into the system. Biologists generally fail in scaling these new techniques at a detriment to our ability to control biology. By adding scalability as an important aspect of innovation we can unlock so much more with what we already have today. </p>
<p>Importantly, this isn't just limited to a causal inference between a drug and a disease. We're getting very good at measuring the state of systems, just pick your favorite "–ome". It's not hard to squint and see that large numbers of interventions, on large numbers of model organisms, with large readouts of state will approach full 4D models of organic systems.  </p>
<p>There are not going to be any shortcuts with biology. The sooner we recognize this, the sooner we can start building systems that operate at the scale needed to bring useful inference, drug discovery, and network topology into the 21st century. </p>
<p>Thank you to Aubree for her feedback on commas, words, and ideas.</p>


			
			
		

			
			




		</div></div>]]>
            </description>
            <link>https://adamashwal.com/irreducible</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642489</guid>
            <pubDate>Wed, 30 Sep 2020 19:10:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trillium: Cancer Drug Bet Pays Off for Biotech CEO with 3,600% Stock Surge]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642462">thread link</a>) | @finphil
<br/>
September 30, 2020 | https://www.bnnbloomberg.ca/cancer-drug-bet-pays-off-for-biotech-ceo-with-3-600-stock-surge-1.1501665 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/cancer-drug-bet-pays-off-for-biotech-ceo-with-3-600-stock-surge-1.1501665">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>(Bloomberg) -- When Jan Skvarka joined biotechnology firm Trillium Therapeutics Inc. as chief executive officer, he made a big bet to reshape the company and went all-in on a cancer treatment platform. Now, heâ€™s reaping the rewards.</p><p>It was the gamble of a lifetime for the 53-year-old CEO, who decided to shutter the drug developerâ€™s lead program on treating tumors directly and instead focus on cancer-fighting technology for patients with different blood cancers. Investors cheered, rewarding him with a 3,600% stock-surge since he joined the company a year ago.</p><p>Trillium is the No. 1 stock on Canadaâ€™s S&amp;P/TSX Composite Index this year, skyrocketing past tech behemoth Shopify Inc. by almost 10-fold. Itâ€™s U.S.-listed shares are the fourth best-performing company on the Nasdaq Composite Index.</p><p>Despite its epic stock-market rally, every analyst covering the company rates it a buy, signaling that further gains are on the horizon for investors that missed out on Trilliumâ€™s initial boom. Wall Street has an average 12-month share price target of $17.58, implying gains of about 30% over the coming year, data compiled by Bloomberg show. Trilliumâ€™s shares closed trading at $13.55 on Tuesday.</p><p>â€œWe need to walk before we run, but if you ask me what our ultimate aspirations are, itâ€™s to challenge chemotherapy,â€� Skvarka, a former partner of Bain &amp; Co. and Harvard Business School graduate, said by phone.</p><p>The rebirth of Cambridge, Massachusetts-based Trillium attracted a whoâ€™s who of health-focused hedge funds and snagged a $25 million investment from industry giant Pfizer Inc. For Skvarka, who celebrated the anniversary of his first year last weekend, the decision to restructure the company and focus on a newer cancer technology has transformed the drugmaker into a firm with a market cap of about $1.3 billion. Last Halloween, it had a value of a mere $7 million.</p><p>Some of the hedge funds that have invested in the company, like Millennium Management LLC and Avoro Capital Advisors, have cashed in on part of the yearâ€™s gains, while others including Ghost Tree Capital LLC have piled onto their positions.</p><p>Trillium, like many drug-developing peers that are focused on cancer therapies, is looking to improve on current treatment options and help patients live longer lives.</p><p>â€œItâ€™s a very exciting time,â€� Skvarka said. â€œWe are squarely out of the realm of preclinical data and in the realm of clinical data.â€�</p><p>M&amp;A Target?</p><p>Those aspirations are where the companyâ€™s cancer medicines, TTI-621 and TTI-622, come in. The pair of programs, which have shown promising results in early stage studies, are in an emerging class of cancer-fighting technologies that triggered Gilead Sciences Inc.â€™s $4.9 billion takeout of peer Forty Seven Inc. earlier this year. That deal has sparked speculation that Trillium could be among the next group of companies snatched up by bigger players amid the industryâ€™s rush of deals.</p><p>While Skvarka wouldnâ€™t comment on whether the company has been approached about a sale, he said that Trilliumâ€™s goal is to keep its options open for the time being.</p><p>â€œThe way we struck the Pfizer deal was very important for us as it kept our optionality openâ€� for the future, he said. â€œI am a big believer of optionality and having as many options as possible. The options for us are to continue alone or strike a global partnership potentially a way down the road.â€�</p><p>Â©2020 Bloomberg L.P.</p></div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/cancer-drug-bet-pays-off-for-biotech-ceo-with-3-600-stock-surge-1.1501665</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642462</guid>
            <pubDate>Wed, 30 Sep 2020 19:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Advisors]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642383">thread link</a>) | @dmonn
<br/>
September 30, 2020 | https://mentorcruise.com/blog/startup-advisors-what-they-do-where-meet-them-and-/ | <a href="https://web.archive.org/web/*/https://mentorcruise.com/blog/startup-advisors-what-they-do-where-meet-them-and-/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Advisors are the bloodline of many modern startups. Not only do they often add fancy names to your team page, but they can <a href="https://mentorcruise.com/blog/how-get-business-mentor/">help your business</a> with their connections and network, help you work through issues, bring in their inputs and open doors with partners and investors that would usually be closed.</p>
<p>That doesn’t come from nothing, of course. Companies must prove their worth, show progress every week and the traction an advisor expects for them to stay on board. That often also means that the advisor is compensated or has a stake in the company.</p>
<h2 id="what-does-a-startup-advisor-do">What does a startup advisor do?</h2>
<p>Startup advisors are chosen and utilized on a varying range of topics. The most common startup advisors are professors, founders and serial founders themselves, with deep expertise of the niche that a company acts in.</p>
<p>Apart from that, they may be growth advisors, with deep expertise in marketing, sales and growing products from nothing to millions of users. Growth is often the number one priority at startups and bringing on independent and new ideas can work wonders.</p>
<p>There are also technical advisors, commonly seen in industries where deep technical expertise is needed or where founders need extra support to push through the challenges.</p>
<p>No matter the nature of the advisors, an advisory board is usually a formal group and often the first place that startup founders can go to talk through issues.</p>
<h2 id="how-do-i-compensate-a-startup-advisor">How do I compensate a startup advisor?</h2>
<p>Startup advisors don’t work for free. For the value they provide, they are looking for a return.</p>
<p>Most commonly, advisors have an equity stake in the company and are paid $1,000 upwards, plus expenses, for each meeting to reimburse their time.</p>
<p>Other advisors will not take a meeting fee and rely on a more generous equity package instead, while a monetary meeting and retainer fee may be preferred by others.</p>
<p>The compensation and service plan is usually tightly set in an advisory agreement, like this one by the <a href="https://fi.co/insight/the-founder-institute-s-standard-advisor-agreement-for-startups-fast">Founder Institute</a>.</p>
<h2 id="where-can-i-find-a-startup-advisor">Where can I find a startup advisor?</h2>
<p>So, you’re sold on the idea of getting an <a href="https://mentorcruise.com/blog/how-can-startup-mentor-can-help-your-business-succ/">advisor for your startup</a>, where can you get one? Good advisors aren’t sold on the street, so you need to go to the right places to find one.</p>
<h3 id="1-startup-networking-events">1. Startup networking events</h3>
<p>Be it meetups, demo days or startup groups. If you want to make the right connections, startup network events are usually where investors and advisors are looking to hear your ideas.</p>
<p>If you work in a specific industry and visit those events, you will also get the added benefit of finding people experienced and well-connected in those industries.</p>
<p>When it comes to signing up an advisor to your team, it’s always good to show others what you can do. Participate in presentations and demo days or directly pick out who you want to talk with and give it your best. </p>
<h3 id="2-partners">2. Partners</h3>
<p>It wouldn’t be the first time that someone signed a business partner, customer or supplier to come on board as an advisor or even an investor.</p>
<p>Exploring the business partners you are close with is a great way to get an introduction to advisors in your industry. Even better, there’s no need to make things formal right away. You can start by asking a few questions, meeting once in a while to get some advice, before moving on to the next stage.</p>
<p>This is an approach we value and exercise at <a href="https://mentorcruise.com/">MentorCruise</a> religiously. Just yesterday, I’ve signed up for another session with a <a href="https://mentorcruise.com/expert/marketing/">marketer</a>, right here on the platform. In the past, I’ve booked sessions to push through scalability issues and gain new ideas in marketing. Talk about scratching our itch!</p>
<h3 id="3-cold-emailing-startup-advisors">3. Cold emailing startup advisors</h3>
<p>A good cold email can open a ton of doors! <a href="https://woodpecker.co/blog/how-to-write-a-cold-email-that-actually-works-six-step-tutorial/">Writing a good cold email</a> is an art in itself, but if you master it, there’s no limit to what you can achieve and who you can reach.</p>
<p>The great thing about this is that you can pick <strong>anyone</strong> on the world and see whether they can help you. The not-so-great thing is that great advisors get a ton of cold emails and most of them land in spam right away. As someone receiving a fair share of cold emails myself, not many are getting the response you’d like.</p>
<p>Therefore, a few short tips to make your cold email feel a lot less cold.</p>
<ul>
<li>
<p>Do not, never, automate your cold emails. Keep things personal and human.</p>
</li>
<li>
<p>Don’t ask them to become an advisor or whether you will be able to send them a question – lead with your question and be direct</p>
</li>
<li>
<p>Offer something in return. Support a project or cause that they are passionate about or feedback to something they’ve written/built/talked about.</p>
</li>
</ul>
<p>In short: be human and natural, don’t ask for commitment or even a reply, just pay it forward and see whether it can lead to a relationship.</p>
<h3 id="4-online-communities">4. Online Communities</h3>
<p>Especially nowadays, startup events and networking increasingly happen online. There are online communities out there, where super-smart engineering students share the same space with 8-figure business owners. The possibilities are endless.</p>
<p>Even better – people in the right communities <strong>love</strong> to interact with others. Whereas with cold emailing your biggest challenge is to even get a reply, in communities you will find a lot of people with the same mindset as you.</p>
<p>In many cases, what you will find in these places is peer-to-peer advisors: Folks in the trenches together, trying to help each other out. That’s not something bad though! In many cases, you will find long-lasting and valuable contacts in communities like this.</p>
<p>Our top picks for this are <a href="https://indiehackers.com/">IndieHackers</a>, <a href="https://megamaker.co/">MegaMaker</a> and <a href="https://www.startupschool.org/">Startup School</a>, but there are many others!</p>
<h3 id="5-mentorship-platforms">5. Mentorship Platforms</h3>
<p>Mentorship platforms are popping up left and right and indeed, they are one of the easiest ways to connect with an expert for advice.</p>
<p>Besides ourselves offering sessions and longterm mentorships with experts all around the tech industry, there are plenty of <a href="https://mentorcruise.com/blog/best-mentor-programs-tech/">other players in the market</a> that can help you.</p>
<p>On one side, you have apps like <a href="https://growthmentor.com/">GrowthMentor</a>, helping you to connect casually to growth and marketing experts that can help you get unstuck in a few sessions you can book through the platform.</p>
<p><img alt="GrowthMentor" src="https://cdn.mentorcruise.com/pinax-images/image-set-122/50229a0f-14a9-43dd-8b09-bd4ce583660d.png"></p>
<p>Then, you have programs like <a href="https://mentorpass.co/">Mentorpass</a> that allow you to get access to a range of great advisors for as long as you need them, to push through issues and problems in a few calls as well.</p>
<p>While not the cheapest option, it’s probably the most comfortable and accessible way to get access to real experts in their topic and your industry.</p>
<h3 id="6-incubators-and-accelerators">6. Incubators and accelerators</h3>
<p>Finally, if you want to go the full way, you can get very close 1-to-1 mentorships and advisors if you join a renowned incubator program. For example, the well-known <a href="https://www.ycombinator.com/">YCombinator</a> and <a href="https://www.techstars.com/">Techstars</a> programs each give you a personal advisor when you join their program.</p>
<p>Of course, incubators and accelerators also come with the most baggage out of all of them. It’s not uncommon for these programs to have rigid investing rules, long presence programs and is usually bound to them taking a free equity stake, so make sure you know what you are getting into!</p>
</div></div>]]>
            </description>
            <link>https://mentorcruise.com/blog/startup-advisors-what-they-do-where-meet-them-and-/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642383</guid>
            <pubDate>Wed, 30 Sep 2020 19:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revisiting Apple Notes (5): Encrypted Notes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642368">thread link</a>) | @ra7
<br/>
September 30, 2020 | https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: Apple Notes allows users to encrypt note contents at rest and the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser">Apple Cloud Notes Parser</a> now supports parsing of encrypted content.</p> <!--more--> <h2 id="background">Background</h2> <p>Apple Notes has allowed users to encrypt their note’s contents at rest in the NoteStore database since <a href="https://support.apple.com/en-us/HT208010#93">iOS 9.3</a>. While some commercial forensics tools can unlock notes, I am unaware of free, open source tools in the community which do so and adding this functionality was a challenge posed to me by <a href="https://smarterforensics.com/">Heather Mahalik</a> a few years ago during a <a href="https://www.sans.org/course/advanced-smartphone-mobile-device-forensics">SANS FOR585</a>. The foundations which Apple uses to carry out the encryption are well documented standards, but initial attempts at putting them together when the parser was written in Perl failed. The struggles with debugging are what led to completely rewriting the parser into an object-oriented language in late 2019 and early 2020. With the parser rewritten, each of the foundational blocks could be implemented discretely and built into the overall program, leading to decryption of encrypted notes in July of 2020.</p> <p>This article is a detailed look at what is encrypted, how it is encrypted, and how to decrypt it. If you are just looking at Apple notes for the first time, I would recommend starting with the other entries in the <a href="https://ciofecaforensics.com/categories/#Apple%20Notes">Apple Notes</a> category to understand how it works under normal circumstances before tackling encrypted notes. Throughout this article, I will mainly refer to the <code>ZICCLOUDSYNCINGOBJECT</code> table when I reference the NoteStore.sqlite database and hence will not be writing that table name every time. I will intentionally include a table name when referencing other tables, such as <code>ZICNOTEDATA.ZDATA</code>.</p> <p><img src="https://ciofecaforensics.com/assets/img/posts/2020/07/lockednote_sm.jpg" alt="Locked note"></p> <h2 id="password-recovery">Password Recovery</h2> <p>It must be said from the outset that the Apple Cloud Notes Parser is not intended to be a password cracker for Apple Notes. This software is to be used to backup or recover notes which you legally have the password to. With that said, Apple’s documentation says that “if you forgot your password, Apple can’t help you regain access to your locked notes.” While true, if you do not have the password for the encrypted note, but do still have the database, you could use a program like <a href="https://github.com/hashcat/hashcat">HashCat</a> or <a href="https://github.com/magnumripper/JohnTheRipper">John the Ripper</a> to potentially recover it. Both of those programs support password recovery on Apple Notes and Apple File System (APFS) encryption. The rest of this article assumes you either created the note and know the password for the note or have a legal reason for reading the note and have the password.</p> <p>Face ID and Touch ID can also be used to unlock notes, but these do not change the underlying password. All they do is unlock the password you set up in Settings-&gt;Notes-&gt;Password and enter it automatically, so the password is still able to be recovered from the database. .</p> <h2 id="decrypting-with-apple-cloud-notes-parser">Decrypting with Apple Cloud Notes Parser</h2> <p>While I hope the detailed explanations below allow many others to implement note decryption, Apple Cloud Notes Parser aims to make it easy. To tell the parser which passwords to try, a new argument has been added which expects a file path pointing to a file with one password on each line.</p> <div><div><pre><code>-w, --password-file FILE         File with plaintext passwords, one per line.
</code></pre></div></div> <p>For example:</p> <figure><pre><code data-lang="raw">notta@cuppa ~/apple_cloud_notes_parser $ cat passwords.txt
root
Summer!2018
password
password1

notta@cuppa ~/apple_cloud_notes_parser $ ruby notes_cloud_ripper.rb --itunes-dir ~/phone_rips/iphone/notes_2019_12_05/device_id --password-file passwords.txt

Starting Apple Notes Parser at Wed Jul 29 19:48:43 2020
Storing the results in ./output/2020_07_29-19_48_43

Created a new AppleBackup from iTunes backup: /home/notta/phone_rips/iphone/notes_2019_12_05/device_id/
Guessed Notes Version: 13
Guessed Notes Version: 8
Added 4 passwords to the AppleDecrypter from /home/notta/apple_could_notes_parser/passwords.txt
Updated AppleNoteStore object with 70 AppleNotes in 11 folders belonging to 2 accounts.
Updated AppleNoteStore object with 0 AppleNotes in 1 folders belonging to 1 accounts.
Adding the ZICNOTEDATA.ZPLAINTEXT and ZICNOTEDATA.ZDECOMPRESSEDDATA columns, this takes a few seconds

Successfully finished at Wed Jul 29 19:48:48 2020</code></pre></figure> <h2 id="what-is-encrypted">What is Encrypted?</h2> <p>When I say that users can encrypt their note’s contents, I need to be careful to be precise. For the most part, what is encrypted is what is found in the <code>ZICNOTEDATA.ZDATA</code> column in the NoteStore.sqlite database. This leaves most of the note metadata unencrypted, and even some of the content (specifically the <code>ZTITLE1</code> column) unencrypted. Aside from the <code>ZICNOTEDATA.ZDATA</code> column, contents of attached files end up encrypted and some of the metadata about objects ends up encypted in the <code>ZENCRYPTEDVALUESJSON</code> column, such as filenames and URLs. Notice in the below screenshot how, even though the notes are all locked, you can see the day they were created and the title.</p> <p><img src="https://ciofecaforensics.com/assets/img/posts/2020/07/all_locked_notes_sm.jpg" alt="Locked note"></p> <p>According to Apple<sup id="fnref:secure-notes-features" role="doc-noteref"><a href="#fn:secure-notes-features">1</a></sup>, users can encrypt notes containing “images, sketches, tables, maps, and websites.” Each of those functions slightly differently in how they encrypt, but the general rules I’ve seen are:</p> <ol> <li>If the normal version of the attachment writes to disk, such as an image or a thumbnail of a webpage, that file will contain encrypted data</li> <li>If the normal version of the attachment has a user-generated filename, such as an image, that filename will be encrypted and stored in the <code>ZENCRYPTEDVALUESJSON</code> column but the file will use the <code>ZIDENTIFER</code> column as its filename</li> <li>If the normal version of the attachment has a Notes-generated filename, such as a sketch, that filename will remain the same</li> <li>If the normal version of the attachment uses the <code>ZMERGEABLEDATA1</code> column, such as a table, that blob will be encrypted and stored in the <code>ZENCRYPTEDVALUESJSON</code> column</li> <li>Files are encrypted on disk using the <code>ZASSETCRYPTOTAG</code> and <code>ZASSETCRYPTOINITIALIZATIONVECTOR</code> columns</li> <li>Fallback images, such as for sketches, are encrypted on disk using the <code>ZFALLBACKIMAGECRYPTOTAG</code> and <code>ZFALLBACKIMAGECRYPTOINITIALIZATIONVECTOR</code> columns</li> </ol> <h2 id="how-is-it-encrypted">How is it Encrypted?</h2> <p>Like much of Apple’s products, specific details on the inner workings of Apple Notes are hard to come by and they use functionality that is not part of the larger libraries Apple makes available to most developers<sup id="fnref:aes-added" role="doc-noteref"><a href="#fn:aes-added">2</a></sup>. The bulk of what is officially known comes from a brief blurb that has been copied over a few different Apple pages over the years<sup id="fnref:secure-notes-features:1" role="doc-noteref"><a href="#fn:secure-notes-features">1</a></sup>. The blurb describes the underlying foundation of their encryption, but doesn’t get quite far enough for someone unfamiliar with the implementation of these foundations to implement it on their own. That is possibly why this feature shows up in commercial tools and not homegrown ones. Here is the most relevant section of the blurb:</p> <blockquote> <p>When a user secures a note, a 16-byte key is derived from the user’s passphrase using PBKDF2 and SHA256. The note and all of its attachments are encrypted using AES-GCM. New records are created in Core Data and CloudKit to store the encrypted note, attachments, tag, and initialization vector. After the new records are created, the original unencrypted data is deleted. Attachments that support encryption include images, sketches, tables, maps, and websites. Notes containing other types of attachments can’t be encrypted, and unsupported attachments can’t be added to secure notes.</p> </blockquote> <blockquote> <p>…</p> </blockquote> <blockquote> <p>To change the passphrase on a secure note, the user must enter the current passphrase, as Touch ID and Face ID aren’t available when changing the passphrase. After choosing a new passphrase, the Notes app rewraps the keys of all existing notes in the same account that are encrypted by the previous passphrase.</p> </blockquote> <h2 id="what-changes-during-encryption">What Changes During Encryption?</h2> <p>During testing of how to decrypt, we wanted to see what exactly happened when a user encrypted a note. I used a MacOS computer to create a note, copied the NoteStore.sqlite database off, then encrypted the note and copied it off again. This is the output of sqldiff’ing the files:</p> <figure><pre><code data-lang="sql"><span>notta</span><span>@</span><span>cuppa</span> <span>~/</span><span>notestores</span> <span>$</span> <span>sqldiff</span> <span>MacNoteStore_preencryption</span><span>.</span><span>sqlite</span> <span>MacNoteStore_postencryption</span><span>.</span><span>sqlite</span> <span>|</span> <span>grep</span> <span>-</span><span>e</span> <span>"ZICCLOUDSYNCINGOBJECT</span><span>\|</span><span>ZICNOTEDATA"</span>
<span>UPDATE</span> <span>ZICCLOUDSYNCINGOBJECT</span> <span>SET</span> <span>Z_OPT</span><span>=</span><span>8</span><span>,</span> <span>ZMARKEDFORDELETION</span><span>=</span><span>1</span><span>,</span> <span>ZSNIPPET</span><span>=</span><span>NULL</span><span>,</span> <span>ZTITLE1</span><span>=</span><span>NULL</span> <span>WHERE</span> <span>Z_PK</span><span>=</span><span>121</span><span>;</span>
<span>UPDATE</span> <span>ZICCLOUDSYNCINGOBJECT</span> <span>SET</span> <span>Z_OPT</span><span>=</span><span>4</span> <span>WHERE</span> <span>Z_PK</span><span>=</span><span>123</span><span>;</span>
<span>INSERT</span> <span>INTO</span> <span>ZICCLOUDSYNCINGOBJECT</span><span>(</span><span>Z_PK</span><span>,</span><span>Z_ENT</span><span>,</span><span>Z_OPT</span><span>,</span><span>ZCRYPTOITERATIONCOUNT</span><span>,</span><span>ZISPASSWORDPROTECTED</span><span>,</span><span>ZMARKEDFORDELETION</span><span>,</span><span>ZMINIMUMSUPPORTEDNOTESVERSION</span><span>,</span><span>ZNEEDSINITIALFETCHFROMCLOUD</span><span>,</span><span>ZNEEDSTOBEFETCHEDFROMCLOUD</span><span>,</span><span>ZNEEDSTOSAVEUSERSPECIFICRECORD</span><span>,</span><span>ZCLOUDSTATE</span><span>,</span><span>ZACCOUNT</span><span>,</span><span>ZCHECKEDFORLOCATION</span><span>,</span><span>ZFILESIZE</span><span>,</span><span>ZHANDWRITINGSUMMARYVERSION</span><span>,</span><span>ZHASMARKUPDATA</span><span>,</span><span>ZIMAGECLASSIFICATIONSUMMARYVERSION</span><span>,</span><span>ZIMAGEFILTERTYPE</span><span>,</span><span>ZOCRSUMMARYVERSION</span><span>,</span><span>ZORIENTATION</span><span>,</span><span>ZSECTION</span><span>,</span><span>ZLOCATION</span><span>,</span><span>ZMEDIA</span><span>,</span><span>ZNOTE</span><span>,</span><span>ZNOTEUSINGTITLEFORNOTETITLE</span><span>,</span><span>ZPARENTATTACHMENT</span><span>,</span><span>ZAPPEARANCETYPE</span><span>,</span><span>ZSCALEWHENDRAWING</span><span>,</span><span>ZVERSION</span><span>,</span><span>ZVERSIONOUTOFDATE</span><span>,</span><span>ZATTACHMENT</span><span>,</span><span>ZSTATE</span><span>,</span><span>ZACCOUNT1</span><span>,</span><span>ZTYPE</span><span>,</span><span>ZACCOUNT2</span><span>,</span><span>ZATTACHMENT1</span><span>,</span><span>ZATTACHMENTVIEWTYPE</span><span>,</span><span>ZISPINNED</span><span>,</span><span>ZLEGACYNOTEWASPLAINTEXT</span><span>,</span><span>ZNOTEHASCHANGES</span><span>,</span><span>ZPAPERSTYLETYPE</span><span>,</span><span>ZPREFERREDBACKGROUNDTYPE</span><span>,</span><span>ZACCOUNT3</span><span>,</span><span>ZFOLDER</span><span>,</span><span>ZNOTEDATA</span><span>,</span><span>ZTITLESOURCEATTACHMENT</span><span>,</span><span>ZISHIDDENNOTECONTAINER</span><span>,</span><span>ZSORTORDER</span><span>,</span><span>ZOWNER</span><span>,</span><span>ZACCOUNTTYPE</span><span>,</span><span>ZDIDCHOOSETOMIGRATE</span><span>,</span><span>ZDIDFINISHMIGRATION</span><span>,</span><span>ZDIDMIGRATEONMAC</span><span>,</span><span>ZSTOREDATASEPARATELY</span><span>,</span><span>ZACCOUNTDATA</span><span>,</span><span>ZCUSTOMNOTESORTTYPEVALUE</span><span>,</span><span>ZFOLDERTYPE</span><span>,</span><span>ZIMPORTEDFROMLEGACY</span><span>,</span><span>ZACCOUNT4</span><span>,</span><span>ZPARENT</span><span>,</span><span>ZCREATIONDATE</span><span>,</span><span>ZCROPPINGQUADBOTTOMLEFTX</span><span>,</span><span>ZCROPPINGQUADBOTTOMLEFTY</span><span>,</span><span>ZCROPPINGQUADBOTTOMRIGHTX</span><span>,</span><span>ZCROPPINGQUADBOTTOMRIGHTY</span><span>,</span><span>ZCROPPINGQUADTOPLEFTX</span><span>,</span><span>ZCROPPINGQUADTOPLEFTY</span><span>,</span><span>ZCROPPINGQUADTOPRIGHTX</span><span>,</span><span>ZCROPPINGQUADTOPRIGHTY</span><span>,</span><span>ZDURATION</span><span>,</span><span>ZMODIFICATIONDATE</span><span>,</span><span>ZORIGINX</span><span>,</span><span>ZORIGINY</span><span>,</span><span>ZPREVIEWUPDATEDATE</span><span>,</span><span>ZSIZEHEIGHT</span><span>,</span><span>ZSIZEWIDTH</span><span>,</span><span>ZHEIGHT</span><span>,</span><span>ZMODIFIEDDATE</span><span>,</span><span>ZSCALE</span><span>,</span><span>ZWIDTH</span><span>,</span><span>ZSTATEMODIFICATIONDATE</span><span>,</span><span>ZMODIFICATIONDATEATIMPORT</span><span>,</span><span>ZCREATIONDATE1</span><span>,</span><span>ZFOLDERMODIFICATIONDATE</span><span>,</span><span>ZLASTNOTIFIEDDATE</span><span>,</span><span>ZLASTVIEWEDMODIFICATIONDATE</span><span>,</span><span>ZLEGACYMODIFICATIONDATEATIMPORT</span><span>,</span><span>ZMODIFICATIONDATE1</span><span>,</span><span>ZCUSTOMNOTESORTTYPEMODIFICATIONDATE</span><span>,</span><span>ZDATEFORLASTTITLEMODIFICATION</span><span>,</span><span>ZPARENTMODIFICATIONDATE</span><span>,</span><span>ZIDENTIFIER</span><span>,</span><span>ZPASSWORDHINT</span><span>,</span><span>ZZONEOWNERNAME</span><span>,</span><span>ZADDITIONALINDEXABLETEXT</span><span>,</span><span>ZFALLBACKSUBTITLEIOS</span><span>,</span><span>ZFALLBACKSUBTITLEMAC</span><span>,</span><span>ZFALLBACKTITLE</span><span>,</span><span>ZHANDWRITINGSUMMARY</span><span>,</span><span>ZIMAGECLASSIFICATIONSUMMARY</span><span>,</span><span>ZOCRSUMMARY</span><span>,</span><span>ZREMOTEFILEURLSTRING</span><span>,</span><span>ZSUMMARY</span><span>,</span><span>ZTITLE</span><span>,</span><span>ZTYPEUTI</span><span>,</span><span>ZURLSTRING</span><span>,</span><span>ZUSERTITLE</span><span>,</span><span>ZDEVICEIDENTIFIER</span><span>,</span><span>ZCONTENTHASHATIMPORT</span>…</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/">https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642368</guid>
            <pubDate>Wed, 30 Sep 2020 19:01:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The story on how I discovered, fell in love and abandoned Event Sourcing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642262">thread link</a>) | @zeLaur
<br/>
September 30, 2020 | https://laurentiu.codes/2020/09/04/the-story-on-how-i-discovered-and-fell-in-love-with-event-sourcing/ | <a href="https://web.archive.org/web/*/https://laurentiu.codes/2020/09/04/the-story-on-how-i-discovered-and-fell-in-love-with-event-sourcing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-77">

    

	<div>

		
<p>Well, yeah … quite the title here, for quite the story. To be honest, I discovered and used Event sourcing way before it was called event sourcing, and way before it was cool, or at least at that time, I had no idea that this will become such a hot topic.</p>



<p>It all happened about 7 years ago, I was a quite happy camper, achieving my “mid software engineer” title and was a awaiting this awesome new project were, for the first time will have a say in the software design (green field and stuff). Everything was looking just fine and dandy, the client was a top client, the software stack was up to us to pick, so yeah I was super hyped, that is, until I got the requirements… </p>



<blockquote><p> I was super hyped, that is, until I got the requirements…</p></blockquote>



<p>Apart from the usual stuff, there was one thing that, thus far, I haven’t ever done on a web based application nor ever seen being implemented, this thing was the ability to <strong>audit everything</strong> (including data access) and <strong>undo </strong>any changes done on the domain objects.</p>



<p>At this point, I kind of understood why other people with more seniority didn’t want to work on this, this was looking to be quite a big undertaking to implement, keep in mind this was something about 2010 – 2012, nosql was a kind of an idea more than an actual product, and cloud wasn’t yet in the picture and we were still using .net 3.5 and 4 at that time and phones back than were upgrading from Android 1.6 to 2.1. </p>



<p>But I digress, back to the story. Now that we build a better temporal  awareness and a bit more context, let go into the more depth. As I said, I was a seen as a “promising” young engineer back than, and this was the first project with this new client a lot of eye were on me, and a lot of pressure, as you may or may not know, if you are working in a consulting / services context, the first project usually makes or brakes a partnership. So yeah, the stakes were high. </p>



<p>So how did we managed to pull this of ? Well, after endless discussion with my Team Lead / PM and a few other people around, who mostly had their experience in embedded C and low level UNIX development, and doing some research on how desktop applications do this (mostly playing around in excel trying to figure it out), I came with this crazy idea of writing our software stack. </p>



<p>We will be using MVC instead of WebForms ( first revolutionary thing, back than ), and instead of the regular way of storing data ( CRUD based ) we will be storing ALL of the interactions with the back-end that touch the Domain objects in Journal tables. In order to give the users the ability to read the data in a “normal view” we would hydrate the journal entries for that specific id by selecting them and applying all the changes one after the other, this way we would be able to know exactly who made what change, and also have versioned “domain objects” and we would be able to undo changes. </p>



<p>People seemed to like the idea, and gave me the green light, I was the only developer working on this full time with two other seniors who I could ask help from on very specific issues. </p>



<p>So off to the races, I started implement this to the best of my abilities back than, everything was going great until I realized than my great design had this small performance issue, on a very small and not very frequently used page, the List View … I’m not going to lie, this was baaaaddd… after letting the others know about this, they gave me a few days to fix this, or they would take the project away from me, and rebuild it with a different team using “industry standard” patterns. </p>



<blockquote><p>I’m not going to lie, this was baaaaddd…</p><cite>Me</cite></blockquote>



<p>As you could imagine, this scared the life out of me, but instead of despair I started thinking on how I could figure the perfect solution to this problem, because, I really liked the idea of this journaling the changes… So, as you might think right know this is obvious, back than, not so much, I wasn’t aware of Greg Young and his push of ES, so yeah, back to the story, so I came with this crazy <strong>“database memoization”</strong> idea. </p>



<p>How did this work ? Glad you asked. Well basically the way this worked was the following, on each “change” a user would make to a domain object, after we would save the “change” in the journal, we would call this memoization component ( I think we called it “[DomainType]MemoizationManager”, in those days most classes were managers :D) to run, this component would go through each of the events of a specific ID, and build the state for it, as before, but this time, instead of returning it it would save it in a “classic” database table, also, this entity also had two columns to keep track of the version and id of the last processed event so it would require to go through all of them on each change. Than, we set up MVC to display the list and detail view based on this table. Also, in order to minimize the chance that a user would see old data after a “change was made”, after the edit view was submitted, we would redirect them to a page that said that the “change was successful” and provided links to the detail view and list view ( I know, but UX wasn’t a thing back than).</p>



<p>Yep, this worked like a charm, the day was saved! (and I continued to work there for about 5 more years). But this was not all, this “db memorization” basically was like a gateway drug, and one of the best things since sliced bread, because it opened the way to building backing tables for highly specific reports that otherwise would take tons of ram and cpu to process.</p>



<p>Now, if you are even remotely familiar with “modern” event sourcing you will basically recognize that was I used was, CQRS ( acknowledging the changes via commands, having a different read model, although used the same DB), Event sourcing with Stream per type, since DBs don’t usually like to have dynamic tables, and projections ( DBMemoization ). Just for the record, we also used event snapshots after about 200 events ( at the end as an optimization), and cross domain object memoizations for the reports and the dashboard. </p>



<blockquote><p>Nobody in their right mind would build such a complex abomination.</p><cite>Enterprise Developers</cite></blockquote>



<p>The sad thing about this whole project was that, although it turned out to be success, both commercial and technically, the client was very impressed by the performance and machine requirements, every one I talked about this solution at that time and quite a lot after said that, this was crazy, nobody in their right mind would build such a complex abomination, and could have been build with nHibernate and some services and a lot of polymorphism. It didn’t matter that this solution was better in terms of performance and memory usage, it wasn’t the way .NET was developed. After hearing this a lot more times than I’d  like to admit, I kind of buried the idea more or less like a highly specific one time thing, and haven’t discussed about it again.</p>



<p>To be honest, I still used some things I learned from that project, for example building “report tables” with data updates triggered on domain events. But most of the time I had to be quite sneaky when presenting others the concept.</p>



<p>That was until, a couple of years ago a discovered ,by mistake, on YouTube, a talk from a guy called Greg Young who, for years was pushing this cool new idea, <strong>Event Sourcing</strong>. I remember watching the whole talk without event flinching, and at the very end I got this very nice and fuzzy feeling of knowing that I’m not crazy, or at least not as crazy as other people thought, or there were others that noticed this cool way of doing things. Now I had somewhere where I could send people if they thought I wasn’t making a lot of sense, and more importantly someone with more notoriety, so yeah thanks Greg.</p>



<h2>The takeaway</h2>



<p>Well, I think, if there is a takeaway from this story, that would be, if you are presented an idea by someone, even with far less seniority than you, give it thought, and remember that especially in software development there are endless ways of achieving something. And more important, if you are going to disagree or give feedback, give constructive feedback / criticism don’t just shut them down.</p>









	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://laurentiu.codes/2020/09/04/the-story-on-how-i-discovered-and-fell-in-love-with-event-sourcing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642262</guid>
            <pubDate>Wed, 30 Sep 2020 18:53:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Beeminder?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642136">thread link</a>) | @maxwelljoslyn
<br/>
September 30, 2020 | https://www.maxwelljoslyn.com/beeminder | <a href="https://web.archive.org/web/*/https://www.maxwelljoslyn.com/beeminder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-body">
        <p><strong>I vigorously encourage you</strong> to <a href="https://beeminder.com/">use Beeminder</a> for tracking, maintaining, and modifying habits.</p>
<p>Several people have recently asked me to explain why I like this service so much. This page is my evolving answer.</p>
<p>So, <strong>why Beeminder?</strong></p>
<h2 id="design">Design</h2>
<p>The core feature of Beeminder is the “bee sting.” The service charges you money if you fail to meet a certain rate of progress toward a goal.</p>
<p>For instance, if I declare to Beeminder that I will meditate 5 minutes per day, and I fail to perform meditation at that rate, Beeminder will “derail” me, charge me a small amount of money, and – after a weeklong grace period – rearm the sting.</p>
<p><strong>Why Beeminder?</strong> It assigns meaningful consequences for not living up to your stated goals.</p>
<p>The good news about the bee sting is that Beeminder is totally self-driven. You<a href="#fn1" id="fnref1"><sup>1</sup></a> do the data reporting, you set the starting and maximum penalties for the bee sting, and you choose how fast you want to make progress on each goal. You are even responsible for confirming with the Beeminder team whether or not a derailment was legitimate.</p>
<p><strong>Why Beeminder?</strong> It trains you to build honesty with yourself (and the support team!) when you succeed or fail. This calibrates a better understanding of your strengths and weaknesses, while giving you the information you need to ramp up or ease off on a goal.</p>
<h2 id="philosophy">Philosophy</h2>
<p>A Beeminder user must break down his or her goals into atomic, numerically-measurable steps toward a large goal. Goals like “chinups performed,” being both numeric and precise, are a perfect fit for Beeminder. To perform 100 chinups, set your target rate to 1 chinup per hour/day/week; set your target number to 100; and do chinups whenever you can. That’s it: as long as you keep your average rate above 1 chinup per chosen time unit, Beeminder will never charge you, and you’ll be making steady progress.</p>
<p><strong>Why Beeminder?</strong> It trains you to reframe your life goals, especially ones that seem monumental, as nothing more than piles of little goals, steadily achieved.</p>
<p>While goals that are easily quantified are the best fit for Beeminder, even nebulous goals can be tracked and nudged in the system. One of my goals is called “selfserve”, and its target number is 100 – where “100” means “has ported 100% of this website to self-administered web servers and infrastructure.”</p>
<p>Few methods of calculating exact progress on this goal would be worth the time they took to administer. However, since I know the scope of the task and its subtasks, after completing each subtask I can add a few percent here and a few percent there into Beeminder’s tracker.</p>
<p><strong>Why Beeminder?</strong> Whether your goal is concrete or abstract, Beeminder puts you on a schedule which will achieve it.</p>
<p>What’s more, merely declaring “I will be 100% done with this hairy task by such-and-such date” was enough to spur me into action. My original target date was 100% completion by mid-December, but as of today, before even reaching October, my “selfserve” goal sits at 60%! I’m months ahead of my original pessimistic estimate, and <em>it never once felt difficult</em> to get there – but if I hadn’t <em>promised myself</em>, via Beeminder, that I would do so, I’d probably still be sitting around griping about my crappy old website infrastructure.</p>
<p><strong>Why Beeminder?</strong> It builds the self-confidence and self-trust that can only come from diligently working toward success.</p>
<p>Finally, I realized recently that Beeminder has <em>instilled in me a new and creative instinct</em>: the impulse to judge any new opportunity by determining how I might realize its potential in steps of Beemindable size.</p>
<p>It is one thing for the latest self-help book or productivity guru to tell you that anything is achievable in small steps. It is quite another for that mantra to develop into a deep-seated instinct which influences your worldview. Thus Beeminder is empowering in the truest sense of the word: it grants new abilities.</p>
<p><strong>Why Beeminder?</strong> Extended use installs the powerful meta-habit of noticing opportunities to achieve goals by “mere” effort – and as a Beeminder user, you’ll be ready to exploit such opportunities <em>because you’ve practiced doing so.</em></p>
<h2 id="proof-by-existence">Proof by Existence</h2>
<p>The Beeminder founders, Danny and Bethany, use Beeminder to supercharge the development of Beeminder itself. <a href="https://www.beeminder.com/meta">They’ve set up the Beeminder user “meta”</a> to publicly display business metrics, which they’ve committed to Beeminding just as you or I might Beemind pushups or calories.</p>
<p>The “meta” goals include typical metrics like revenue and monthly active users. That Beeminder openly publishes these figures makes them is noble, but I want to draw attention to a non-financial indicator: <a href="https://www.beeminder.com/meta/uvi">a very, very important number called “UVIs.”</a></p>
<p>UVI stands for “User-Visible Improvement,” and they are the gold-standard, AAA, totally-unfakeable indicator that Beeminder works. One point on the UVI goal means the Beeminder team has directly improved your experience using Beeminder, and at time of writing, the Beeminder team has added <em>one new UVI every day for ten years</em>.</p>
<p><strong>Why Beeminder?</strong> <em>Its own existence is a massive proof</em> of its ability to motivate you to fantastic heights – like, say, creating a program which has helped tens of thousands of people achieve their goals.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I’ve said my piece, so don’t delay: <a href="https://beeminder.com/">go try Beeminder for yourself</a>. <strong>Set your goals set to the minimum charge until you figure out what works for you</strong>, and if you want help getting started, email the ever-helpful support team, or check out the forums.</p>
<p>I’m just a happy customer with a blog, and Beeminder didn’t ask me to write this post. That said, Danny and other staff members encouraged me to write on this topic after I mentioned it over email.</p>
<p>If you liked this, leave a response! In a future post, I’ll investigate my own Beeminder successes and failures as case studies for others to learn from. Thanks for reading, and never ever hesitate to .</p>


        





        
    </div></div>]]>
            </description>
            <link>https://www.maxwelljoslyn.com/beeminder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642136</guid>
            <pubDate>Wed, 30 Sep 2020 18:43:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Energy Efficiency across Programming Languages [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 141 (<a href="https://news.ycombinator.com/item?id=24642134">thread link</a>) | @Malfunction92
<br/>
September 30, 2020 | https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf | <a href="https://web.archive.org/web/*/https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642134</guid>
            <pubDate>Wed, 30 Sep 2020 18:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My path away from spinning hard drives on my home desktop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641719">thread link</a>) | @pcr910303
<br/>
September 30, 2020 | https://utcc.utoronto.ca/~cks/space/blog/tech/HomePCAllSolidStatePath | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/HomePCAllSolidStatePath">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>My likely path away from spinning hard drives on my home desktop</h2>

	<p><small>September 28, 2020</small></p>
</div><div><p>One of my goals for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my home desktop</a>
is to move entirely to solid state storage. Well, it's a goal for
both my home and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">work machine</a>, and I
originally expected to get there first at home, but then work had
spare money and suddenly my work machine has been all solid state
for some time (which is great except for the bit where I'm not at
work to enjoy it).</p>

<p>Moving to all solid state at work was relatively straightforward
because all of my old storage on my work machine was relatively
small; I had a mirrored pair of 250 GB SSDs, a mirrored pair of 1
TB HDs, and a third 500 GB HD for less important things, and none
of them were all too full. This was easily all replaced with a pair
of reasonable sized NVMe drives and a pair of 2 TB SSDs, which
weren't that expensive even in late 2019. Unfortunately my home
machine is better configured; I currently have a mirrored pair of
750 GB SSDs and a mirrored pair of '3 TB' HDs (one of them is a 4
TB HD, but since it's mirrored the extra TB is wasted). The HDs are
used for a <a href="https://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)">LVM volume</a> that
has only about 1.4 TiB allocated, so in theory I could get away
with a pair of 2 TB SSDs as the replacement for these HDs. However,
that would leave me relatively short of extra space for things like
digital photography (those <a href="https://en.wikipedia.org/wiki/Raw_image_format">RAW</a> files add up fast).</p>

<p>The obvious replacement and supplement for my current 750 GB SSDs is
a pair of decent 1 TB NVMe drives, which seem to be not too expensive
these days. Unfortunately there is not as good a replacement for my
pair of 3 TB HDs. While 4 TB SSDs are available, they cost noticeably
more per GB than 2 TB SSDs do (as I write this, one large Canadian
online retailer lists WD Blue 2 TB SSDs for $304 and the 4 TB version
for $709). One option would be to shrug and pay the premium for future
proofing things; another would be to buy a pair of 2 TB SSDs and rely
on a combination of the extra space on the NVMe drives, reusing my
current 750 GB SSDs, and rationalizing space usage when I migrate
from my old LVM setup to ZFS on the new SSDs.</p>

<p>A complication is that now is not necessarily the right time to buy
new NVMe drives, especially relatively expensive ones. The NVMe
world is just starting to move from PCIe 3.0 to PCIe 4.0, which
offers various improvements once everything is working. My current
home motherboard has no PCIe 4.0 support, of course, but based on
past experience I'll be keeping any NVMe drives that I buy now for
at least half a decade, which means that they'll likely wind up in
a PCIe 4.0 capable system within their lifetime.</p>

<p>(On the one hand, PCIe 4.0 will probably not make a particularly
visible performance difference on my home machine on typical or
even somewhat atypical tasks, like compiling Firefox from source.
On the other hand, I don't like leaving potential performance on
the table.)</p>

<p>So despite all of what I've written, I'm probably going to do my
usual thing and sit on my hands for a while. Perhaps various end
of the year sale prices will get me to finally move forward.</p>

<p>(This is one of the entries that I write partly to try to motivate
myself.)</p>

<p>PS: I have a mixed pair of 3TB and 4TB HDs for the usual reason,
which is that I used to have a pair of 3 TB HDs and then one of
them died and I needed to replace it. My LVM array has migrated
up from smaller sizes of HDs over time this way.</p>

<p>(Waiting for a warranty replacement is never an option, because I
want my redundancy back much sooner than a replacement would get
to me.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/HomePCAllSolidStatePath</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641719</guid>
            <pubDate>Wed, 30 Sep 2020 18:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards an Infinite Laptop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641674">thread link</a>) | @thedataexchange
<br/>
September 30, 2020 | https://gradientflow.com/towards-an-infinite-laptop/ | <a href="https://web.archive.org/web/*/https://gradientflow.com/towards-an-infinite-laptop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-7518">

	

	
	<div>
		<h3>The new Anyscale platform offers the ease of development on a laptop combined with the power of the cloud.</h3>
<p><span>During a series of short keynotes at the </span><a href="https://events.linuxfoundation.org/ray-summit/?utm_source=gradientflow&amp;utm_medium=postanyscalelaunch&amp;utm_campaign=raysummit#featuredspeakers"><span>Ray Summit</span></a><span> this morning, Anyscale</span><sup>1</sup><span>, the company formed by the creators of Ray, publicly shared their initial product offering. <a href="https://anyscale.com/?utm_source=gradientflow&amp;utm_medium=post&amp;utm_campaign=anyscale"><img data-attachment-id="7525" data-permalink="https://gradientflow.com/towards-an-infinite-laptop/attachment/anyscale-logo/" data-orig-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?fit=484%2C134&amp;ssl=1" data-orig-size="484,134" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="anyscale-logo" data-image-description="" data-medium-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?fit=300%2C83&amp;ssl=1" data-large-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?fit=484%2C134&amp;ssl=1" loading="lazy" src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?resize=217%2C60&amp;ssl=1" alt="" width="217" height="60" srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?resize=300%2C83&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?w=484&amp;ssl=1 484w" sizes="(max-width: 217px) 100vw, 217px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?resize=300%2C83&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?w=484&amp;ssl=1 484w" data-lazy-src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?resize=217%2C60&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a>Dubbed the “infinite laptop”,&nbsp; Anyscale’s platform allows developers to treat their laptop as an “infinite cluster”. Developers can use their preferred development tools (e.g., IDE, notebook, text editor, etc.) on Anyscale’s platform, and seamlessly burst into a cloud platform when needed.&nbsp;</span></p>
<p><span>The demo at the conference walked the audience through the process of a building an end-to-end application: training and deploying models for a recommendation engine. Consider a developer in the process of building and training a model for a machine learning application. The challenge with machine learning is that the model building phase requires multiple runs. You usually need to explore different models and model parameters before settling on a model. If model training takes too long, it limits the amount of ideas a developer can try. On the other hand, developers invest time setting up their laptops and they feel productive when their favorite IDE, libraries and software are in place.&nbsp;Ideally one can explore ideas on a laptop (say a simpler model, or a model that uses less training data) and burst out to a compute cluster when computations begin to overwhelm your laptop. The Anyscale platform delivers this exact solution!</span></p>
<p><span>The Anyscale platform gives developers the “development experience on their laptop combined with the power of the cloud”. This means that Anyscale syncs code on your laptop to the cloud. You can continue to edit your program using the development tools on your laptop and Anyscale will optionally execute your code on the cloud. Machine learning developers can use specialized processors (including TPUs or fast GPUs) and scale out to a cluster if they need to parallelize certain computations.&nbsp; It is cloud native and you can even use multiple clouds at the same time. You really have the best of both worlds: the tools and libraries that you feel most comfortable with, backed with the compute resources you need to be productive and effective. My immediate reaction after watching the demo was <em>“That’s exactly how I want to work and the platform I need!”</em></span></p>
<p><a href="https://anyscale.com/blog/?utm_source=gradientflow&amp;utm_medium=post&amp;utm_campaign=anyscale"><img data-attachment-id="7523" data-permalink="https://gradientflow.com/towards-an-infinite-laptop/attachment/anyscale-demo/" data-orig-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?fit=1946%2C1006&amp;ssl=1" data-orig-size="1946,1006" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="anyscale-demo" data-image-description="" data-medium-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?fit=300%2C155&amp;ssl=1" data-large-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?fit=750%2C387&amp;ssl=1" loading="lazy" src="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=750%2C387&amp;ssl=1" alt="" width="750" height="387" srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1024%2C529&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=300%2C155&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=768%2C397&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1536%2C794&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1200%2C620&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1568%2C811&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?w=1946&amp;ssl=1 1946w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1024%2C529&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=300%2C155&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=768%2C397&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1536%2C794&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1200%2C620&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1568%2C811&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?w=1946&amp;ssl=1 1946w" data-lazy-src="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=750%2C387&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p><center><small>Image: Edward Oakes, Anyscale Product Demo at the Ray Summit</small></center>
<p><span>Building efficient and performant distributed applications – the sort needed in modern AI – is challenging for most developers. A developer needs to be able to deal with failures (which are inevitable), control where computations take place, and efficiently handle multiple processes that handle data and communicate with each other. Fortunately, developers need not start from scratch. As Anyscale co-founder Robert Nishihara highlighted in his keynote, the open source project </span><a href="https://ray.io/"><span>Ray</span></a><span> is becoming the </span><a href="https://docs.ray.io/en/master/ray-libraries.html"><span>software platform for building distributed applications</span></a><span>.</span></p>
<p><img data-attachment-id="7646" data-permalink="https://gradientflow.com/towards-an-infinite-laptop/attachment/ray-library-ecosystem/" data-orig-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?fit=2504%2C1310&amp;ssl=1" data-orig-size="2504,1310" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ray-library-ecosystem" data-image-description="" data-medium-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?fit=300%2C157&amp;ssl=1" data-large-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?fit=750%2C393&amp;ssl=1" loading="lazy" src="https://i1.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem-1024x536.jpg?resize=750%2C393&amp;ssl=1" alt="" width="750" height="393" srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1024%2C536&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=300%2C157&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=768%2C402&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1536%2C804&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=2048%2C1071&amp;ssl=1 2048w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1200%2C628&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1568%2C820&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?w=2250&amp;ssl=1 2250w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1024%2C536&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=300%2C157&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=768%2C402&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1536%2C804&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=2048%2C1071&amp;ssl=1 2048w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1200%2C628&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1568%2C820&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?w=2250&amp;ssl=1 2250w" data-lazy-src="https://i1.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem-1024x536.jpg?resize=750%2C393&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><center><small>Image: Robert Nishihara at the Ray Summit (“The Future of Ray”)</small></center>
<p><span>Anyscale provides what co-founder Ion Stoica described as a “serverless experience without serverless limitations”. It abstracts away servers and DevOps so developers can focus on writing their applications.&nbsp; And since Anyscale uses Ray, the Actor model allows it to support stateful applications that are as fast as those built from scratch by experts in distributed programming.</span></p>
<p><img data-attachment-id="7640" data-permalink="https://gradientflow.com/towards-an-infinite-laptop/attachment/ray-serverless/" data-orig-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?fit=2316%2C1354&amp;ssl=1" data-orig-size="2316,1354" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ray-serverless" data-image-description="" data-medium-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?fit=300%2C175&amp;ssl=1" data-large-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?fit=750%2C439&amp;ssl=1" loading="lazy" src="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=750%2C439&amp;ssl=1" alt="" width="750" height="439" srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1024%2C599&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=300%2C175&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=768%2C449&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1536%2C898&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=2048%2C1197&amp;ssl=1 2048w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1200%2C702&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1568%2C917&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?w=2250&amp;ssl=1 2250w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1024%2C599&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=300%2C175&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=768%2C449&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1536%2C898&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=2048%2C1197&amp;ssl=1 2048w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1200%2C702&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1568%2C917&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?w=2250&amp;ssl=1 2250w" data-lazy-src="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=750%2C439&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><center><small>Image: Ion Stoica at the Ray Summit (“Programming the Cloud as Easily as your Laptop”)</small></center>
<p><span>Why is this exciting? Machine learning and AI are becoming central to many applications. But building machine learning applications can be extremely compute intensive. Even with the emergence of hardware accelerators, many machine learning workloads </span><a href="https://arxiv.org/pdf/2007.05558.pdf"><span>go beyond the capacity of a single server</span></a><span>. We need tools that enable regular developers to quickly build distributed applications. The Anyscale platform is a great step in this direction.</span></p>
<p><span>The company announced this morning that the Anyscale platform is currently <a href="https://anyscale.com/?utm_source=gradientflow&amp;utm_medium=post&amp;utm_campaign=anyscale">available as an invite-only Beta</a>. Learn more by watching the following demo from the Ray Summit:</span></p>
<p><span><iframe width="750" height="422" src="https://www.youtube.com/embed/8GTd8Y_JGTQ?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p><p>If you’re interested in Ray, read this new <a href="https://www.anyscale.com/blog/announcing-ray-1-0?utm_source=gradientflow&amp;utm_medium=post&amp;utm_campaign=anyscale">post describing the version 1.0 release</a>.</p>
<hr>
<p><small>[1] Full disclosure: the author is an advisor to Anyscale.</small></p><p><small><strong>Related Content:</strong> Download your free copy of the <a href="https://gradientflow.com/2020nlpsurvey/?utm_source=gradientflow&amp;utm_medium=blog&amp;utm_campaign=nlpsurvey">2020 NLP Industry Survey Results</a>.</small><br>
&nbsp;</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://gradientflow.com/towards-an-infinite-laptop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641674</guid>
            <pubDate>Wed, 30 Sep 2020 18:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimization: Making Rust Code Go Brrrr]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641608">thread link</a>) | @ajeetdsouza
<br/>
September 30, 2020 | https://aspenuwu.me/posts/rust-optimization.html | <a href="https://web.archive.org/web/*/https://aspenuwu.me/posts/rust-optimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Rust code can be fast. Very fast, in fact. If you look at the <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/rust.html">Benchmarks Game</a>, it goes head-to-head with C and C++.</p>
<p>But performance isn't effortless, although Rust's LLVM backend makes it seem so. I'm going to go over the ways I improve performance in my Rust projects.</p>
<h2>Rayon isn't a magic bullet</h2>
<p>It's really not. Many people think just slapping <code>par_iter</code> on the smallest operation will magically fix their performance. It won't. With that mindset, <em>synchronization overhead will eat you alive</em>.</p>
<p>Rayon has more than just <code>par_iter</code>. For example, <a href="https://docs.rs/rayon/*/rayon/slice/trait.ParallelSlice.html#method.par_chunks"><code>par-chunks</code></a> is very useful - you can split your task into parallel <em>chunks</em>, each thread processing a portion of the entire dataset at a time. This greatly reduces synchronization overhead, especially for situations where you have a large amount of small tasks. However, <em><strong>it still may be better to use <em><strong><code>par_iter</code></strong></em> for large tasks that take a while per iteration</strong></em>.</p>
<pre><code>iter.par_chunks(4096).for_each(|x| {
	for y in x {
		y.do_small_thing();
	}
});
</code></pre>
<h2>Buffering matters!</h2>
<p>This is simple. I/O involves syscalls. Syscalls are bad for performance. Therefore, you want to minimize syscalls and optimize I/O.</p>
<p>You should always wrap I/O (whether it be a <a href="https://doc.rust-lang.org/std/fs/struct.File.html"><code>File</code></a>, <a href="https://doc.rust-lang.org/std/net/struct.TcpStream.html"><code>TcpStream</code></a>, et cetera) in an <a href="https://doc.rust-lang.org/std/io/struct.BufReader.html"><code>BufReader</code></a> or <a href="https://doc.rust-lang.org/std/io/struct.BufWriter.html"><code>BufWriter</code></a>. These quite simply buffer I/O operations, preferring to write things in a single large batch, over many small batches. This reduces your total syscalls, and overall increases performance.</p>
<p><strong>Remember!!:</strong> If you use a <a href="https://doc.rust-lang.org/std/io/struct.BufWriter.html"><code>BufWriter</code></a>, make sure to call <a href="https://doc.rust-lang.org/std/io/struct.BufWriter.html#method.flush"><code>flush</code></a> and/or <a href="https://doc.rust-lang.org/std/fs/struct.File.html#method.sync_all"><code>sync_all</code></a> before it's dropped! This will allow you to handle any errors.</p>
<pre><code>let fd = File::create("example.bin").expect("Failed to create file!");
let mut writer = BufWriter::new(fd);
std::io::copy(&amp;mut buffer, &amp;mut writer).expect("Failed to copy buffer!");
writer.flush().expect("Failed to write file!");
</code></pre>
<h2>std isn't always the best.</h2>
<p>The Rust standard library is great. I mean, it really is. But it doesn't always offer the best options. Some crates provide near-identical interfaces at greatly increased performance.</p>
<ul>
<li><a href="https://crates.io/crates/parking_lot"><code>parking_lot</code></a> - Offers better <a href="https://docs.rs/parking_lot/*/parking_lot/type.Mutex.html"><code>Mutex</code></a> and <a href="https://docs.rs/parking_lot/*/parking_lot/type.RwLock.html"><code>RwLock</code></a> implementations than Rust's standard library. In addition to performing better, they don't poison (so no need for an additional match/unwrap).</li>
<li><a href="https://crates.io/crates/crossbeam-channel"><code>crossbeam-channel</code></a> and <a href="https://crates.io/crates/flume"><code>flume</code></a> - These provide alternative <code>Sender</code>/<code>Receiver</code> implementations to the ones in <a href="https://doc.rust-lang.org/std/sync/mpsc/index.html"><code>std::sync::mpsc</code></a>. I personally prefer <a href="https://crates.io/crates/flume"><code>flume</code></a>, as it's implemented in 100% safe code.</li>
<li><a href="https://crates.io/crates/dashmap"><code>dashmap</code></a> is a better solution than throwing <code>Arc&lt;RwLock&lt;HashMap&lt;K, V&gt;&gt;&gt;</code> everywhere - as it's optimized with sharding, allows for concurrent access, highly performant, and easy to use/convert to.</li>
<li><a href="https://crates.io/crates/ryu"><code>ryu</code></a> and <a href="https://crates.io/crates/lexical"><code>lexical</code></a> - These are highly performant interfaces for converting to and from decimal strings. Quite simply, they turn <code>"1.2345"</code> to <code>1.2345_f32</code> and do so fast, and vice versa.
<ul>
<li>Just prefer to avoid text processing when possible, truth be told.</li>
</ul>
</li>
</ul>
<h2>Allocating the path to hell</h2>
<p>Many Rust developers take types such as <code>String</code> and <code>Vec</code> for granted, without understanding the downsides. These are <em>dynamically allocated</em> types. Allocations are not your friend when you're optimizing for performance. </p>
<ul>
<li>In types that will be serialized/deserialized from another format, prefer <a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html"><code>Cow&lt;str&gt;</code></a>. This will allow you to borrow the string, and then convert it to an owned string if needed.</li>
<li>Look into crates such as <a href="https://crates.io/crates/tinyvec"><code>tinyvec</code></a> and <a href="https://crates.io/crates/smol_str"><code>smolstr</code></a>. These allow for you to have stack-optimized structures, with minimal effort.</li>
<li>Types that require an explicit <a href="https://doc.rust-lang.org/std/clone/trait.Clone.html"><code>clone</code></a> typically allocate! Prefer <a href="https://doc.rust-lang.org/std/marker/trait.Copy.html"><code>Copy</code></a> types where possible.</li>
</ul>
<p>In addition, look into alternative allocators which may yield better performance for your project, such as <a href="https://crates.io/crates/jemallocator">jemallocator</a> or <a href="https://crates.io/crates/mimalloc">mimalloc</a>.</p>
<h2>Advanced Magic Extensions</h2>
<p>Modern processor have tons of extremely useful extensions, such as <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX</a> and <a href="https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions">SSE</a>. Even on non-x86 platforms, extensions with similar functionality are available, such as <a href="https://en.wikipedia.org/wiki/ARM_architecture#Advanced_SIMD_(NEON)">NEON</a> on ARM, and the <a href="https://en.wikipedia.org/wiki/RISC-V#Packed_SIMD">proposed P and V extensions for RISC-V</a>.</p>
<p>While Rust allows you to directly interface with these extensions, and there are many packages for higher-level interfacing, such as <a href="https://crates.io/crates/packed_simd">packed_simd</a> and <a href="https://crates.io/crates/generic-simd">generic-simd</a>, the LLVM optimizer is capable of automatically optimizing code to use these extensions.</p>
<p>You may need to pass <code>-C target-cpu=native</code> or <code>-C target-features=+avx</code> through <code>RUSTFLAGS</code> in order to take advantage of this (see <code>rustc --print target-features</code> for available features for your target, and use somethng like <code>lscpu</code> to see what your CPU supports).</p>
<ul>
<li>Doing things in groups of 4/8 is good for vectorization.
<ul>
<li>Do note, <strong>branching will heavily reduce the chances of vectorization.</strong></li>
</ul>
</li>
</ul>
<p>See this function. It converts four <code>f32</code>s into four <code>u8</code>s.</p>
<pre><code>#[inline]
pub unsafe fn f32_to_u8(f: f32) -&gt; u8 {
	if f &gt; f32::from(u8::MAX) {
		u8::MAX
	} else {
		f32::to_int_unchecked(f)
	}
}

/// Converts a slice of 4 [f32] s into a tuple of 4 [u8]s, rounding it in the process
#[must_use]
pub fn f32s4_to_u8(f: [f32; 4]) -&gt; (u8, u8, u8, u8) {
	let f = &amp;f[..4];
	unsafe {
		(
			f32_to_u8(f[0]),
			f32_to_u8(f[1]),
			f32_to_u8(f[2]),
			f32_to_u8(f[3]),
		)
	}
}
</code></pre>
<p>Now, we can throw this code into <a href="https://godbolt.org/">Compiler Explorer</a> to see what assembly it generates. Don't forget the compiler flags!</p>
<pre><code>example::f32s4_to_u8:
        vmovss  xmm0, dword ptr [rip + .LCPI0_0]
        vminss  xmm1, xmm0, dword ptr [rdi]
        vcvttss2si      eax, xmm1
        vminss  xmm0, xmm0, dword ptr [rdi + 4]
        vcvttss2si      ecx, xmm0
        vmovsd  xmm0, qword ptr [rdi + 8]
        vbroadcastss    xmm1, dword ptr [rip + .LCPI0_0]
        vcmpleps        xmm2, xmm1, xmm0
        vblendvps       xmm0, xmm0, xmm1, xmm2
        vcvttps2dq      xmm0, xmm0
        vpand   xmm0, xmm0, xmmword ptr [rip + .LCPI0_1]
        vpsllvd xmm0, xmm0, xmmword ptr [rip + .LCPI0_2]
        movzx   ecx, cl
        shl     ecx, 8
        movzx   eax, al
        or      eax, ecx
        vmovd   ecx, xmm0
        or      ecx, eax
        vpextrd eax, xmm0, 1
        or      eax, ecx
        ret
</code></pre>
<p>Success! It generates AVX instructions, such as <a href="https://www.felixcloutier.com/x86/vbroadcast"><code>VBROADCASTSS</code></a> and <a href="https://www.felixcloutier.com/x86/movss"><code>VMOVSS</code></a>!</p>
<h2>Making the compiler brrrr harder</h2>
<p>It is entirely possible to configure the compiler to optimize more aggressively! For example, in <code>Cargo.toml</code> (<strong>Do note this will increase compile times!!</strong>):</p>
<pre><code>[profile.release]
lto = 'thin'
panic = 'abort'
codegen-units = 1

[profile.bench]
lto = 'thin'
codegen-units = 1
</code></pre>
<p>Each option explained:</p>
<ul>
<li><code>lto = 'thin'</code> - Quite simply enables <a href="https://clang.llvm.org/docs/ThinLTO.html">Thin LTO</a>. You can also try <code>lto = 'fat'</code>, performance gains should be similar.</li>
<li><code>panic = 'abort'</code> - Abort instead of unwinding on panic. You'll get a smaller, more performant binary, but you won't be able to catch panics anymore. See <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/aborting-on-panic.html">the Rust Guide for more info</a>.</li>
<li><code>codegen-units = 1</code> - Ensures that the crate is compiled with only one <a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#codegen-units">code generation unit</a>. This reduces the paralellization of the compilation, but will allow the LLVM to optimize it much better.</li>
</ul>
<h2>Edits</h2>
<ul>
<li><strong>9/30/2020, 3:40 PM EST</strong> - Re-phrased the Copy/Clone section, (thanks /u/SkiFire13) mentioned <code>sync_all</code> in the buffering section (thanks /u/Freeky), and also mentioned <code>lto = 'fat'</code> (thanks /u/po8)</li>
</ul>
<ul id="article_footer">
<li>tags: <a href="https://aspenuwu.me/tags/optimization.html">optimization<sup>1</sup></a><a href="https://aspenuwu.me/tags/rust.html">rust<sup>1</sup></a></li>
<li>date: 2020-09-29 21:46:19</li>
</ul>
</article></div>]]>
            </description>
            <link>https://aspenuwu.me/posts/rust-optimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641608</guid>
            <pubDate>Wed, 30 Sep 2020 18:01:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Snowflake so Valuable?]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 145 (<a href="https://news.ycombinator.com/item?id=24641481">thread link</a>) | @malisper
<br/>
September 30, 2020 | https://www.freshpaint.io/blog/why-is-snowflake-so-valuable | <a href="https://web.archive.org/web/*/https://www.freshpaint.io/blog/why-is-snowflake-so-valuable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Two weeks ago, Snowflake had the largest IPO ever for a software company. On the first day of trading, the stock price doubled, giving Snowflake a market cap of over $60 billion. Snowflake became all that everyone was talking about. There was so much hype, my mom, who doesn't even know what Snowflake is, decided to invest in Snowflake.</p><p>At first glance, the valuation of $60 billion seems absurd. Not only is Snowflake not profitable, having a net loss of $349 million in 2019, but their revenue is also small relative to their valuation. Their revenue over the last 12 months was $403 million. Based on that, their market cap is around 150x their revenue. So why exactly is their market cap so high? Besides revenue and profitability, there are a number of other metrics that investors look at. Compared to similar software businesses, Snowflake has god-like metrics. In this post, I'm going to go through a number of metrics from Snowflake's S-1, explain what the metrics mean, and give context on just how exceptional Snowflake's metrics are.</p><p>The first metric that stands out is Snowflakes 121% year over year growth. To give you a sense of how fantastic it is, you can compare it to the growth rates of other companies at IPO. <a href="https://techcrunch.com/2013/08/24/how-fast-should-you-be-growing/">Institutional Venture Partners looked at how quickly Internet and software companies were growing at IPO</a>.</p><figure><p><img src="https://uploads-ssl.webflow.com/5dad2b1e508f04886d0245c3/5f74c44d240d4de932d463c4_growth1.jpeg" alt="growth1"></p></figure><p>Based on their numbers, only 25% of companies that are between $75M-$500M in annual revenue are growing at just over 60% year over year. Snowflake's growth rate is nearly twice that! Snowflake's revenue was also $403M for the last 12 months, which would put them at the high end of that range. Not only are they growing significantly faster than other companies, but they are already significantly larger!</p><p>For companies that sell software to businesses an important number to look at is their retention rate. For Snowflake, their net retention rate is 158%. You may be asking, how do they have a retention rate over 100%? That's because companies that use Snowflake pay more for Snowflake over time. For every $1 of revenue Snowflake received from their customers a year ago, that same pool of customers are now paying $1.58. That means Snowflake could acquire no new customers, and they would still be doubling revenue every 18 months.</p><p>To compare that to other companies, <a href="https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29">Lenny Rachitsky surveyed a number of industry experts on what they thought good and great net retention would be</a>. On average, for enterprise subscription software, the category Snowflake would fall under, the experts surveyed said 110% net retention would be good and 130% net retention would be great. He also pulled the net retention rates for a number of public companies:</p><ul role="list"><li><strong>Alteryx</strong>: 135% (<a href="https://docs.google.com/spreadsheets/d/1ogELPtct2s6jj9wRBpOgqGUE5k4cO73XXcvqmEZE89M/edit#gid=0">source</a>)</li><li><strong>Fastly</strong>: 130% (<a href="https://www.saastr.com/5-interesting-learnings-from-fastly-as-it-gets-ready-to-ipo/">source</a>)</li><li><strong>Okta</strong>: 124% (<a href="https://docs.google.com/spreadsheets/d/1ogELPtct2s6jj9wRBpOgqGUE5k4cO73XXcvqmEZE89M/edit#gid=0">source</a>)</li><li><strong>Anaplan</strong>: 124% (<a href="https://www.key.com/kco/images/Public_SaaS_Company_Retention_Metrics_2019.pdf">source</a>)</li><li><strong>Workday</strong>: 100%+ (<a href="https://www.workday.com/content/dam/web/en-us/documents/investor/workday-financial-analyst-day-2018.pdf">source</a>)</li><li><strong>ServiceNow</strong>: 97% (<a href="https://www.publiccomps.com/tickers/NOW">source</a>)</li></ul><p>You will notice that Snowflake's net retention rate of 158% is significantly higher than all of these!</p><p>Net promoter score (NPS) is a way of measuring customer satisfaction. It's convenient because it's easy to calculate and boils down customer satisfaction to a single number, making it easy to compare NPS between different companies. To compute NPS, a company performs a survey of their customers. The company asks "On a scale of 0 to 10, how likely are you to recommend this company’s product or service to a friend or a colleague?". Anyone that answers 9 or 10 is deemed a "promoter" of the product, while anyone that answers 6 or less is considered to be a "detractor". To compute the NPS, you take the percentage of users that are promoters and subtract the percentage of users that are detractors. This results in a number between -100 and 100 which is the NPS.</p><p>To give some examples, an NPS of 0 means your company has just as many promoters as detractors, whereas an NPS of 100 means everyone loves your product. Here are the NPS's for a few well known companies according to <a href="https://www.satmetrix.com/infographic/2020-us-consumer-benchmarks/">satmetrix</a>:</p><ul role="list"><li>Apple - 62</li><li>AirBnB - 43</li><li>AT&amp;T - 20</li></ul><p>What is Snowflake's NPS score? It's 71. According to NPS, Snowflake's customers like Snowflake more than Apple's customers like Apple.</p><p>The average Snowflake customer pays Snowflake $165k a year. Average contract value (ACV) is a useful metric to look at because it gives you a rough sense of how efficient a sales team is. To elaborate, there's a similar amount of work needed for a sales person to sell a $50k deal as there is for a sales person to sell a $100k deal. This is because most of the work a sales person does such as giving a demo, dealing with the paper process, and negotiating, have to happen regardless of how much the contract actually winds up being. Closing a $100k deal brings in twice as much revenue as a $50k deal does, but it's not usually twice as much work.</p><p>For this reason, higher average contract values are usually better. According to <a href="https://dskok-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/2020-KBCM-SaaS-Survey.pdf">KBCM Technology Group</a>, 29% of software businesses have an ACV between $50k-$250k, and only 9% have an ACV greater than $250k. That gives Snowflake a relatively healthy ACV.</p><p>Not only does Snowflake have a high ACV, but their high end contract values are also really high. Snowflake has 56 customers that pay them over $1M a year. They also have Capital One, their largest customer, account for 11% of their 2019 revenue with approximately $29M.</p><p>Snowflake's net loss of $349M during 2019 does not sound good, but it does not tell the full story. There are two issues with using profit as a metric when looking at a subscription software business:</p><ul role="list"><li>Due to the generally accepted accounting principles (GAAP), a customer can give Snowflake money, but Snowflake can't count that money as revenue until a later date, even though that money is in Snowflake's bank account.</li><li>A net loss doesn't tell you where the money is coming in and where the money is going to.</li></ul><p>Addressing each of these points:</p><h3>Revenue under GAAP</h3><p>Under GAAP, Snowflake doesn't count revenue when a customer pays them, but instead when a customer uses the Snowflake product. To be more specific when a company pays Snowflake, they are purchasing a number of "Snowflake credits". When you are using the Snowflake product you exchange your credits for Snowflake compute time.</p><p>As an example, let's say a customer purchases one year of Snowflake credits for $100k. That money winds up in Snowflake's bank account, but Snowflake cannot count that $100k as revenue until Snowflake delivers the service, which is when the customer uses their credits for compute time. If the customer uses a quarter of the Snowflake credits within three months after purchases them, under GAAP, Snowflake would count that as $25k in revenue over those three months.</p><p>You can see the impact this has by looking at the $688M Snowflake has in "remaining performance obligations". This $688M is money that Snowflake's customers have either already given to Snowflake or have contractually committed to giving to Snowflake, but it won't show up as revenue until the customers use the credits they purchased.</p><h3>Where's the money going?</h3><p>The other thing to look at is what they are spending the money on. Snowflake is making money on every sale. They have a gross profit of 62% so they have no problem running the product. The thing is they are spending A LOT on sales and marketing. Their total net loss for the last six months was $171M while during the same time period they spent $191M on sales and marketing. If they wanted to, they could stop investing in growth, lay off their entire sales and marketing team, and they would become profitable. In other words, Snowflake could be profitable if they wanted to, but they are intentionally choosing not to, and are instead focusing on growing the customer base.</p><p>Not that they should. If we assume the $191M they spent in sales and marketing over the last six months was responsible for the $81M increase in revenue in the last six months compared to the prior six months, every $1 Snowflake invests in sales and marketing results in $.42 of revenue. With Snowflake's 158% net retention rate, that customer will pay back the initial investment in sales and marketing after around two years and then return many times the investment in the years following that.</p><p>In practice, Snowflake probably sees a return on investment much sooner. A company pays for Snowflake well before Snowflake is able to count that money as revenue.</p><p>So does it make sense for Snowflake's market cap to be 150x their revenue. I definitely think it's high, but I it's certainly plausible. They're growing faster, have higher customer satisfaction, and just have phenomenal metrics across the board when compared to similar businesses.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.freshpaint.io/blog/why-is-snowflake-so-valuable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641481</guid>
            <pubDate>Wed, 30 Sep 2020 17:50:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Save Millions with QSBS and Section 1045 Rollovers]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641348">thread link</a>) | @ankit77
<br/>
September 30, 2020 | https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/ | <a href="https://web.archive.org/web/*/https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Qualified Small Business Stock (QSBS) is some of the most tax-advantaged stock you can hold, yet few people know about it. If you’re a founder, early employee, or investor, you can potentially save millions of dollars by understanding the implications of QSBS.</p>



<p>In this article I will discuss the following:</p>



<ol><li>History of QSBS</li><li>QSBS Tax Savings</li><li>Requirements for QSBS</li><li>Section 1045 Rollover (applicable if you don’t meet the five year holding period, explained below)</li></ol>



<p>I recently sold shares in a company I co-founded and spoke to more than two dozen accountants in the process. I’m summarizing my findings and experiences in the article below. As such, the information in this article is not formal tax advice. I recommend you speak with your accountant prior to making any decisions.&nbsp;</p>



<h2>History of QSBS</h2>



<p>Section 1202 is the section of the tax code that outlines the QSBS tax exclusion. It was added to the tax code in 1993 to encourage individuals to invest in new ventures, far before the creation of Silicon Valley as we know it today. The act, however, failed to provide the intended incentive of spurring investments in new ventures.</p>



<p>Over the past three decades, a number of tailwinds have propelled QSBS back into the limelight. Congress reduced the tax on long-term capital gains in 1997, increased the tax savings of QSBS incrementally until 2010, and finally reduced corporate taxes from 35% to a flat 21% in 2017. These three forces have made QSBS far more relevant today than in the past.</p>



<h2>QSBS Tax Savings</h2>



<p><strong>Under Section 1202, your gains from selling QSBS may be eligible for up to 100% exclusion from federal and state taxes. This exclusion is limited to the </strong><strong><em>greater</em></strong><strong> of $10 million or 10 times your cost basis during a liquidity event.</strong></p>



<p>For instance, the excludable amount for a founder may be on $10 million of gain, while the exclusion for a VC may be much greater. If, for instance, a VC invests $20 million, the VC may obtain an exclusion for $200 million of gain. See the “Scenario Table” in the Appendix for more examples. Please also note that if you end up selling your shares in multiple tranches over multiple years, the excludable amount might vary. Reference<a href="https://www.thetaxadviser.com/issues/2018/nov/qualified-small-business-stock-more-attractive.html"> this</a> article for further details.</p>



<p><strong>If you qualify for a QSBS tax exclusion, you are 100% exempt from federal taxes. The current federal tax rate is 23.8% (20% federal + 3.8% medicare). This means you can save 23.8% in long-term capital gains that you would have been subject to otherwise. Depending on which state you live in (</strong><strong><em>not</em></strong><strong> which state the company is incorporated), you may qualify for state-level exclusion as well.</strong> States typically fall into one of four buckets:</p>



<ol><li>States with no individual income tax or no capital gains tax. These states are QSBS compliant by default.</li><li>States that follow the federal tax code and waive state taxes if an individual meets the federal-level QSBS requirements. These states are also QSBS compliant.&nbsp;</li><li>States that have their own QSBS exclusion statues.</li><li>States that do not recognize QSBS in any way, shape, or form (California notably falls in this bucket).&nbsp;</li></ol>



<p>I’ve provided a chart of applicable QSBS treatment in each of the 50 states and District of Columbia in the Appendix.</p>



<h2>Requirements for QSBS</h2>



<p><strong>For your stock to qualify as QSBS, you must meet certain requirements at the time of your stock issuance, and others during your entire holding period of the stock. If you sell QSBS, you must report the entire gain as a long-term gain on your Schedule D, and enter the allowable exclusion as a loss below the entry for the gain.</strong></p>



<h3>Requirements that must be met on the date of issuance:</h3>



<ul><li>Corporation issuing the stock must be a domestic C-Corp (and the stock must be issued after August 9, 1993)</li><li>You must acquire your stock directly from the company for money, property, or services. The only exception is if you acquire the stock by gift or inheritance. In this case, you are treated as having acquired the stock in the same manner as the original owner.<ul><li>Note: do not contribute the stock to a family LLC, limited partnership/trust, or to an LLC organized to manage the sale of your stock. This will disqualify the stock as QSBS.</li></ul></li><li><strong>Corporation must have assets of $50M or less at the time you receive your shares (or exercise your options).</strong><ul><li>Note: this is a continuous requirement and if at any point the assets of a corporation exceed $50M, the corporation can never again issue QSBS (even if the assets are below $50M on the date of the subsequent issuance).</li><li>Note: the assets of the corporation must not exceed $50M even after taking into account amounts the corporation received in the current issuance. If, for instance, a company has $40M in the bank and is raising a $20M Series B, none of the newly issued Series B stock will be QSBS.</li></ul></li><li>You must determine your stock issuance date. This is critical for three reasons:<ul><li><strong>Starts the clock for purposes of the five-year holding period requirement. In order to be eligible for the tax exemption outlined above, you must have held on to your stock for a minimum of five years.</strong> If you do not meet this minimum requirement, you can employ a Section 1045 rollover (described below) to extend your holding period.<ul><li><strong>Note: this requirement is yet another reason why you should early exercise your options and file an 83(b). Early exercise allows you to 1) start the one year holding period for long-term capital gains treatment, and 2) start the five year holding period for Section 1202. If you don’t file an 83(b) election, the clock on long-term capital gain only begins when your shares vest – so if there are multiple vesting dates, you will have multiple clocks to monitor for long-term capital gain – and, if eligible, QSBS. An unexercised option or warrant is not considered QSBS, even if the underlying stock would meet the definition of QSBS.</strong></li><li><strong>Note: for stock acquired through the exercise of an option, the company must pass the “$50M asset test” on the date of your exercise, not on the date of your grant.</strong> Similarly, for stock acquired through the vesting of RSUs, the company must pass the “$50M asset test” on vesting, and your five year holding period begins on vesting, not on grant.</li><li>Note: if the stock was received as a gift, inheritance, or as a distribution from a partnership, the acquisition date is the date on which the transferor acquired the stock.</li></ul></li><li>Determines whether gain from the sale of the QSB stock is eligible for a 50%, 75%, or 100% federal tax exclusion.<ul><li>50% federal tax exclusion for stock issued before February 18, 2009</li><li>75% federal tax exclusion for stock issued between February 18, 2009 and September 27, 2010</li><li>100% federal tax exclusion for stock issued after September 27, 2010</li></ul></li><li>Marks the date on which the company must have $50M or less in assets.&nbsp;</li></ul></li></ul>



<h3>Requirements that must be met during the shareholder’s holding period:</h3>



<ul><li>Corporation must be a C-corp for the entire holding period.</li><li><strong>The corporation must be an “active business” during the entire period you held your stock. This means that at least 80% (by value) of the assets in your corporation must be used to pursue business in industries </strong><strong><em>other</em></strong><strong> than the industries below. Note that if your business provides a service, then it most likely does not qualify as a qualified small business.&nbsp;</strong><ul><li>Health, law, non-software engineering (civil, electrical, etc), architecture, accounting, actuarial science, performing arts, consulting, athletics, financial services, or brokerage.</li><li>Banking, insurance, financing, leasing, investing, or similar business.</li><li>Farming.</li><li>Mining or natural resource production or extraction.</li><li>Operating a hotel, restaurant, or similar business.</li></ul></li><li>Cash held for burn requirements generally qualify under this “active business” requirement. However, after two years, technically no more than 50% of the corporation’s assets can qualify under this exemption. While startups usually satisfy this requirement, it isn’t always clear how to apply the rule, especially if the startup retains significant cash following an investment (in other words, overfunded startups sitting on cash). If you’re like most startups and you’re burning cash to fund business operations you will most likely pass this check.</li><li>If the corporation bought back 5% or more of its stock in the year before or after your stock issuance, your stock will not qualify as QSBS.&nbsp;</li></ul>



<h2>Section 1045 Rollover</h2>



<p><strong>In order to be eligible for preferential tax treatment under Section 1202, you must satisfy the requirements above and have held onto your stock for at least five years. If you have not met the five year minimum, however, you can employ a Section 1045 rollover to extend your holding period.</strong></p>



<p><strong>If you have held onto your QSBS for at least six months, you can sell your QSBS and roll the proceeds of the sale into another QSBS issuer without recognizing a gain under Section 1045.</strong> This is a similar concept to a Section 1031 exchange in real estate. <strong>Per Section 1045, you have 60 days from the date of the sale of your original QSBS to roll the sale proceeds into new QSBS.</strong> In general, you should roll all of the proceeds from your sale of original QSBS into the new QSBS. If you take any cash off the table after the initial sale, that amount would be subject to capital gains tax. <strong>The cost basis of the new QSBS is the same as the cost basis of the original QSBS, and the holding period from the original QSBS is counted towards the holding period of the new QSBS.</strong></p>



<p>Consider the following scenario: you acquire 5M shares of QSBS from “Company A” on January 1st, 2010 for $0.00001 per share. Your original cost basis is $50 (5M * $0.00001). Assume you then sell these shares in Company A for $4M on January 1st, 2012, and then reinvest this $4M to purchase 2,000 shares of QSBS in “Company B”. Your holding period will pick up from where it left off and the cost basis for your new shares in Company B will be the same as the original cost basis for your shares in Company A ($50). If you then sell your QSBS in Company B at any point after January 1, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/">https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/</a></em></p>]]>
            </description>
            <link>https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641348</guid>
            <pubDate>Wed, 30 Sep 2020 17:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Temporal reaches version 1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641125">thread link</a>) | @Sevein
<br/>
September 30, 2020 | https://docs.temporal.io/blog/temporal-v1-announcement/ | <a href="https://web.archive.org/web/*/https://docs.temporal.io/blog/temporal-v1-announcement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><strong>Latest Release at Time of Writing:</strong>&nbsp;V1.0.0</p><p>Hey Temporal community, I hope you've got your socks on because this isn't a typical transparency report. I am extremely happy to announce that we have officially reached stability which means that Temporal V1 production release is now available.</p><p>This is a huge milestone for the project, community and Temporal as a business. Without our community, Temporal would have never existed. For all of you who have been waiting or blocked by this release, your patience is appreciated. This release served as a learning process for the Temporal team and we hope that it reflects in our future behavior.</p><img alt="V1 pipeline" src="https://docs.temporal.io/img/v1-pipeline.png"><h2>What does this mean?</h2><p>Temporal version 1 is available and ready for production consumption with the caveats covered in our last report (reiterated below). This also means that the system has entered a backwards compatibility era where there will be no more breaking API or schema changes for publicly facing APIs. Note that we will have a deprecation policy (which will be made public in the near future) so we can continue evolving and improving the product.</p><p>In this release we improved how shard IDs are hashed. This may cause an elevated rate of errors when upgrading cluster in-place from a previous release. To be 100% clear there is no potential for data loss and this should only happen once. The practical impact is slightly higher resource usage on your cluster until the upgrade is complete.</p><h3>What is not included in the release?</h3><p>When scoping out the V1 stabilization work, we triaged features based on criticality and usage. During our triage we collected a list of features that we felt could be stabilized after the release and would not block the majority of users. We want to stress that these features are in no way "broken" and many users are already relying on them without issue. That being said, these features have not gone through the rigorous set of checks and validations that we require before deeming something "production ready". Moving forward, we will be referring to features that fall into this bucket as "experimental".</p><p>With this context, here are the features we consider experimental in this release:</p><ul><li>Archival</li><li>Cross data center replication</li><li>Batch operations (signal, terminate, cancel)</li><li>Dynamic config</li><li>Addition, removal and creation of searchable attributes with ElasticSearch</li></ul><h2>What's next?</h2><p>V1 is just the start of the Temporal story. Moving forward expect to see things like support for new languages, databases and security capabilities. We also plan to ramp up our engagement with users and have regular meetups, conferences and design sessions. On the business side, we are working on a cloud offering which will provide Temporal as a service. Aside from being a reasonably good way to support the company, we strongly believe that the requirement to run Temporal is one of the biggest barriers of adoption today. Having a cloud solution will make it much easier for new users to get started with Temporal and therefore enable us to continue growing this already great community. We still plan to release regular transparency updates but they may not come on such a strict schedule.</p><h3>Versioning</h3><p>We recently made some changes to how our versioning will work moving forward.</p><ol><li>All validation logic is on the server. Client only sends headers. If header is missing assume that "client doesn't care" and no restriction is applied.</li><li>Client sends to server following headers:</li></ol><ul><li><code>client-name</code>: one of <code>temporal-go</code>, <code>temporal-java</code>, <code>temporal-cli</code>,</li><li><code>client-version</code>: <code>1.0.0</code>,</li><li><code>supported-server-versions</code>: <code>&gt;=1.0.0 &lt;2.0.0</code>.</li></ul><ol start="3"><li>Server has <code>GetClusterInfo</code> API which returns its version and supported version ranges for every supported client.</li><li>All old clients and servers are supported because they don't send these headers and fit into "I don't care" category. Moving forward we will be able to restrict old clients and old servers. (edited)</li></ol><p>As always, feel free to reach out with questions, comments or critical feedback via email, Slack or our community forum.</p><p>Email:&nbsp;<a href="mailto:ryland@temporal.io" target="_blank" rel="noopener noreferrer">ryland@temporal.io</a></p><p>Slack:&nbsp;<a href="http://temporalio.slack.com/" target="_blank" rel="noopener noreferrer">temporalio.slack.com</a></p><p>Forum:&nbsp;<a href="https://community.temporal.io/" target="_blank" rel="noopener noreferrer">https://community.temporal.io/</a></p></section></div>]]>
            </description>
            <link>https://docs.temporal.io/blog/temporal-v1-announcement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641125</guid>
            <pubDate>Wed, 30 Sep 2020 17:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Telegram bot to get new HN stories by keywords]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24640924">thread link</a>) | @solus_factor
<br/>
September 30, 2020 | https://solus.life/hnbuzz/ | <a href="https://web.archive.org/web/*/https://solus.life/hnbuzz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://solus.life/hnbuzz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640924</guid>
            <pubDate>Wed, 30 Sep 2020 17:00:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ray 1.0]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640775">thread link</a>) | @robertnishihara
<br/>
September 30, 2020 | https://www.anyscale.com/blog/announcing-ray-1-0 | <a href="https://web.archive.org/web/*/https://www.anyscale.com/blog/announcing-ray-1-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3>Announcing Ray&nbsp;1.0</h3><p>Today, we’re happy to announce the release of <a href="https://github.com/ray-project/ray">Ray 1.0</a>. Ray 1.0 brings a <a href="https://docs.ray.io/en/master/package-ref.html">stable API</a> and new <a href="https://ray2020.sched.com/event/dhCy/ray-a-general-purpose-serverless-substrate-eric-liang-anyscale">general purpose serverless</a> features, both important steps towards the goal of providing a universal API for distributed computing. This past release has seen 67 contributors and 458 commits, making it the among the <a href="https://github.com/ray-project/ray/releases">largest yet</a> for Ray. In addition, 1.0 brings many new community <a href="https://docs.ray.io/en/master/ray-libraries.html">library integrations</a> to the growing Ray ecosystem.</p><h3>New Features</h3><p>Ray 1.0 makes it easier than ever to build and compose highly scalable libraries, applications, and services. Here are the highlights:</p><p><b>Resources, Not Machines: </b>Building distributed applications that run portably across different machine types, clusters, and clouds is a challenging task. Ray 1.0 makes this easy with an <a href="https://docs.ray.io/en/master/cluster/autoscaling.html">autoscaler</a> that intelligently selects the best <a href="https://docs.ray.io/en/master/cluster/autoscaling.html#multiple-node-type-autoscaling">node types</a> for an application’s <a href="https://docs.ray.io/en/master/advanced.html#accelerator-types">resource requests</a>. In addition, Ray 1.0 introduces <a href="https://docs.ray.io/en/master/placement-group.html">a placement group API</a> for fine-grained control over scheduling.</p><p><b>Production Serving: </b>A general purpose serverless framework hosts both offline batch and online serving workloads. Ray 1.0 ships with <a href="https://docs.ray.io/en/master/serve/">Ray Serve</a>, a production microservice and ML serving library. For custom serving applications, Ray 1.0 also introduces <a href="https://docs.ray.io/en/master/actors.html?highlight=lifetime#actor-lifetimes">detached</a> actor lifetimes, <a href="https://docs.ray.io/en/master/async_api.html">AsyncIO</a> actors, and application-level metrics via <a href="https://docs.ray.io/en/master/ray-metrics.html?highlight=prometheus">Prometheus</a>. Ray serving applications can be deployed in various <a href="https://docs.ray.io/en/master/cluster/cloud.html">cloud providers</a> and on <a href="https://docs.ray.io/en/master/cluster/kubernetes.html">Kubernetes</a>.</p><p><b>Automatic Memory Management</b>: Users of Ray 1.0 can say goodbye to “object evicted” errors, thanks to fully automated <a href="https://docs.ray.io/en/master/memory-management.html">memory management</a>. Application performance and memory usage can be debugged in the <a href="https://docs.ray.io/en/master/ray-dashboard.html">Ray dashboard</a>. To learn more about how Ray implements distributed reference counting with high-performance, reliability, and fault tolerance, check out the new <a href="https://docs.ray.io/en/master/whitepaper.html">Ray 1.0 whitepaper</a>.</p><p><b>Java and Windows Support: </b>Ray 1.0 brings native support for the Java and Windows platforms. This means that you can now use Ray to build <a href="https://docs.ray.io/en/master/cross-language.html">cross-language</a> and <a href="https://medium.com/distributed-computing-with-ray/build-distributed-java-applications-with-ray-90b381eff564">distributed Java</a> applications, and <a href="https://docs.ray.io/en/master/installation.html#windows-support">install Ray on Windows</a>.</p><h3>Community Update</h3><p><b>Community Integrations</b>: There are a growing number of <a href="https://docs.ray.io/en/master/ray-libraries.html">community libraries</a> that integrate with Ray 1.0 for distributed execution: <a href="https://classyvision.ai/tutorials/ray_aws">ClassyVision</a>, <a href="https://docs.ray.io/en/master/dask-on-ray.html">Dask</a>, <a href="https://github.com/asappresearch/flambe">Flambe</a>, <a href="https://horovod.readthedocs.io/en/stable/ray_include.html">Horovod</a>, <a href="https://huggingface.co/transformers/master/main_classes/trainer.html#transformers.Trainer.hyperparameter_search">HuggingFace</a>, <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/rayonspark/">Intel Analytics Zoo</a>, <a href="https://docs.ray.io/en/master/mars-on-ray.html">MARS</a>, <a href="https://github.com/modin-project/modin">Modin</a>, <a href="https://github.com/Intel-bigdata/oap-raydp">RayDP</a>, <a href="https://github.com/SeldonIO/alibi">Seldon Alibi</a>, and <a href="https://pypi.org/project/spacy-ray/">SpaCy</a>. This means users of these libraries can now scale their applications with Ray, and Ray users can easily leverage these libraries in their distributed applications.</p><p><b>Open Source</b>: At Anyscale, we’re proud to develop Ray along with the open source community. Many key Ray contributions are driven by the community — for example, ongoing projects around high availability, multi-tenancy, and placement groups are led by <a href="https://www.antgroup.com/en">Ant Group</a>, and improved autoscaler support for different Clouds has come from <a href="https://aws.amazon.com/">Amazon</a> and <a href="https://azure.microsoft.com/en-us/">Microsoft</a>.</p><h3>More Information</h3><p>To learn more about Ray, join us at <a href="https://events.linuxfoundation.org/ray-summit/">Ray Summit</a>, which runs from September 30 to October 1. You can also find out more about Ray 1.0 through the <a href="https://forms.gle/9TSdDYUgxYs8SA9e8">Ray Slack</a> or the <a href="https://docs.ray.io/en/master/index.html">Documentation</a>.</p></div></div></div>]]>
            </description>
            <link>https://www.anyscale.com/blog/announcing-ray-1-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640775</guid>
            <pubDate>Wed, 30 Sep 2020 16:49:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easy Ubuntu Hardening for Web Developers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640736">thread link</a>) | @mariuz
<br/>
September 30, 2020 | https://blog.openbloc.com/automated-hardening-for-ubuntu/ | <a href="https://web.archive.org/web/*/https://blog.openbloc.com/automated-hardening-for-ubuntu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 300w,
                            https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 600w,
                            https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 1000w,
                            https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png" alt="Easy Ubuntu Hardening for Web Developers">
            </figure>

            <section>
                <div>
                    <p>You may have good reasons to focus on developing your disrupting app. And you may well be a very talented developer. But like me, even after years of experience as a web engineer, comes a point where we have to admit we don't know that much about security.</p><p>Unless you only use fully managed solutions to host your web applications, your startup probably has a bunch of servers you have to monitor and maintain. And unless your company has the scale to pay for real DevOps, security engineers, audits or pentests, then quite frankly, we'll mainly focus on finishing the current sprint hoping to get some traction ;)</p><p>Today I got my first Ubuntu VPS from <a href="https://blog.openbloc.com/p/3f54a7d4-a161-4bf0-a9ee-8ea9c6daf259/www.ovh.com">OVH</a>, a fresh new image ready to host the next version of my website. And it's got me thinking: I do remember it's best practice to disable SSH login by password, what else should I do ? Do I need a firewall ? Surely I don't have time to fully audit this default Ubuntu image by myself...</p><p>In this article I'll show you how to harden a default Ubuntu Server 20.04 image using existing open-source tools:</p><ol><li><a href="https://www.inspec.io/">Inspec</a> to identify security issues and misconfiguration</li><li><a href="https://www.ansible.com/">Ansible</a> to automatically harden your server</li><li><a href="https://dev-sec.io/">The DevSec Hardening Framework</a> which provides:<br>- <a href="https://github.com/dev-sec/linux-baseline">An Inspec profile</a><br>- <a href="https://github.com/dev-sec">Ansible / Chef / Puppet recipes</a> to enforce above Inspec profile</li></ol><!--kg-card-begin: markdown--><h2 id="quicksshsetup">Quick SSH setup</h2>
<p>Make sure your server is defined in <code>~/.ssh/config</code></p>
<pre><code>Host servername
	HostName &lt;your server ip address&gt;
	User username
	Port 22
</code></pre>
<p>To ssh into the server with your ssh key without typing the password just run:</p>
<p><code>$ ssh-copy-id -i ~/.ssh/id_rsa.pub servername</code></p>
<h2 id="usinginspecwithlinuxbaselineprofile">Using Inspec with linux-baseline profile</h2>
<p>On the server:</p>
<pre><code># download and install Inspec
$ wget https://packages.chef.io/files/stable/inspec/4.20.2/ubuntu/20.04/inspec_4.20.2-1_amd64.deb
$ sudo dpkg -i inspec_4.20.2-1_amd64.deb

# clone the linux-baseline profile
$ git clone https://github.com/dev-sec/linux-baseline

# run the Inspec profile
$ inspec exec linux-baseline
</code></pre>
<p><a href="https://www.inspec.io/docs/reference/install/">Inspec installation instructions</a></p>
<p>You should see a similar output:<br>
<img src="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-01-40.png" alt="Capture-d--cran-de-2020-06-17-13-01-40"></p>
<p>Next thing will be to automatically apply better OS settings using Ansible and the recipes provided by the DevSec framework.</p>
<h2 id="usingansibletohardentheserver">Using Ansible to harden the server</h2>
<p>On your local machine:</p>
<pre><code># install Ansible
$ sudo apt update
$ sudo apt install software-properties-common
$ sudo apt-add-repository --yes --update ppa:ansible/ansible
$ sudo apt install ansible

# install the os and ssh hardening roles
$ ansible-galaxy install dev-sec.os-hardening
$ ansible-galaxy install dev-sec.ssh-hardening
</code></pre>
<p><a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html">Ansible installation instructions</a></p>
<p>We then need to write a playbook for each ansible role:</p>
<pre><code># ansible-os-hardening.yaml
- hosts: your-server
  become: true
  roles:
    - dev-sec.os-hardening
    
# ansible-ssh-hardening.yaml 
- hosts: your-server
  become: true
  roles:
    - dev-sec.ssh-hardening
</code></pre>
<p>Finally run these playbooks with the following commands:</p>
<pre><code>$ ansible-playbook -K ansible-os-hardening.yaml
$ ansible-playbook -K ansible-ssh-hardening.yaml
</code></pre>
<p>Then, re-running <code>inspec exec linux-baseline</code> on the server should give a similar output:<br>
<img src="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-00-59.png" alt="Capture-d--cran-de-2020-06-17-13-00-59"></p>
<p>Which is much better!</p>
<h2 id="finalthoughts">Final thoughts</h2>
<p>Though I can't say I have audited the DevSec framework per-se, I hope you now have a better understanding on how you can automate your servers security to stay up-to-date whith industry best practices.</p>
<p>Depending on what you then run on your server, you may have to allow some ports on the Ubuntu firewall, <a href="https://help.ubuntu.com/community/UFW">ufw</a>. Personally while testing <a href="https://caprover.com/">CapRover</a> I just had to run:</p>
<p><code>$ ufw allow 80,443,3000,996,7946,4789,2377/tcp; ufw allow 7946,4789,2377/udp;</code></p>
<h3 id="thanksforreadingandtakecare">Thanks for reading and take care !</h3>
<!--kg-card-end: markdown-->
                </div>
            </section>

                <section>
    <h3>Subscribe to Openbloc</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.openbloc.com/automated-hardening-for-ubuntu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640736</guid>
            <pubDate>Wed, 30 Sep 2020 16:46:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducting Guide: A GUI for your Deta Base]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640669">thread link</a>) | @mxek
<br/>
September 30, 2020 | https://blog.deta.sh/posts/base_guide/ | <a href="https://web.archive.org/web/*/https://blog.deta.sh/posts/base_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    <time datetime="2020-09-30T00:00:00Z">September 30, 2020</time>
  </header>
  

<h2 id="what-s-a-deta-base-guide">What’s a Deta Base Guide?</h2>

<p>Base Guide (beta) is a graphical user interface for Deta Base. Base Guide was inspired by the struggles of many developers in interacting with the data powering their apps, <em>outside the confines</em> <em>of the app  itself.</em></p>

<p>A video tour is available <a href="#tour">at the end of the post</a>.</p>

<h2 id="motivation"><strong>Motivation</strong></h2>

<p>Since shipping <a href="https://youtu.be/jHYFrS0LVY8?t=110">the earliest alpha of Deta &amp; Deta Base</a>, devs have resonated with the simplicity of spinning up a database using Deta. In it’s purest form, there is no marginal config step required, it’s just code.</p>

<p>This approach is great when you want to design state from the comforts of your text editor. While Base has provided a persistent state solution for some inspirational apps so far, we realized it was falling short on another dimension we didn’t initially expect.</p>

<p>The biggest shortcoming we’ve heard from users about Base is the lack of a UI. We often heard ‘<em>I want to be able to easily see and interact with the data my app generates</em>’.  We noticed some users would hack around this shortcoming, adding auxiliary logic to their application or a side script to quickly inspect or modify the records their main app generates.</p>

<p>But going through both a text editor and running a script to inspect and modify records is less than ideal. Two members of our community— turned summer fellows—both took it a step further, each hacking their own Base records viewers together (<a href="https://explorer.deta.dev/">first</a> w/ <a href="https://github.com/fillerInk/deta-base-explorer">source</a>; <a href="https://base-ui.jajoo.fun/">second</a> w/ <a href="https://github.com/jajoosam/base-ui">source</a>).</p>

<p>Suffice to say, we are extremely excited to address this need and launch Deta’s official Base GUI solution into beta, building off the work of the second solution. With Base Guide, you can rapidly inspect, add, delete, and modify the records contained in your Base.</p>

<h3 id="inspecting-records">Inspecting Records</h3>

<p>To view a Base’s records, all you need to do is open an individual Base from the Deta Project’s Sidebar. By default the Base’s records will load into Base Guide.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/ygo4vp291q1zz9g9bu6u.png" alt="Alt Text"></p>

<p>If you want to inspect a slice of the data within a Base, you can use <a href="https://docs.deta.sh/docs/base/sdk#queries">Base’s queries</a> to do so, i.e.:</p>

<pre><code>[{"cuisine": "Italian", "have_visited": false}]
</code></pre>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/qv2mz4uniqjlv0fcu0ky.png" alt="Alt Text"></p>

<h3 id="adding-records">Adding Records</h3>

<p>To add records to a base, click the ‘<strong>+ Add</strong>’ button and a new row will appear at the top of your Base’s UI.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/n184adeun585uvpr9k27.png" alt="Alt Text"></p>

<p>The new row will be treated as a candidate edit, with a yellow background, which can be permanently saved by clicking the ‘<strong>Save</strong>’ button.</p>

<h3 id="modifying-records">Modifying Records</h3>

<p>For primitive types (strings, booleans, and numbers), you can modify any record directly from within a cell.</p>

<p>For advanced editing, i.e. to change the type of a given value, or edit arrays or objects, you can expand the cell and do so.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/pom71tzotlie0s865n7i.png" alt="Alt Text"></p>

<p>Once you are satisfied with your edits, simply click the ‘<strong>Save Edits</strong>’ button, as before, to modify these records in your Base. If you want to discard all your edits locally, click ‘<strong>Undo Changes</strong>’.</p>

<h3 id="deleting-records">Deleting Records</h3>

<p>For every record displayed in Base UI, there is a checkbox on the left side. By clicking the checkbox, the record will be highlighted in red as a delete candidate. To go forward with the deletion, simply click the ‘<strong>Delete</strong>’ item.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/sootikirv2s5cmz0xj3o.png" alt="Alt Text"></p>

<p>For candidate adds, edits, and deletes, the ‘<strong>Undo</strong>’ button will revert the Base Guide to the state that was last pulled.</p>

<h3 id="start-with-base-guide-today">Start with Base Guide Today</h3>

<p>To get started with Base Guide, simply <a href="https://web.deta.sh/">log-in / sign-up</a> with Deta, grab a project key, and create a <a href="https://docs.deta.sh/docs/base/sdk">Deta Base</a> in your Python or Node.js app. Deta Guide will be accessible for any Base you create.</p>

<h3 id="tour">Tour</h3>


<p>
  <iframe src="https://www.youtube.com/embed/y11dOkP8ZTI" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<h3 id="thanks">Thanks</h3>

<p>We’d love to thank the Deta community for the incredible feedback that led to this initiative as well as Samarth Jajoo for the initial implementation which we built on top of!</p>

</article></div>]]>
            </description>
            <link>https://blog.deta.sh/posts/base_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640669</guid>
            <pubDate>Wed, 30 Sep 2020 16:41:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love Is the Only Antidote to Fear: A Lecture by John O'Donohue]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640573">thread link</a>) | @sbuccini
<br/>
September 30, 2020 | https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear | <a href="https://web.archive.org/web/*/https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <blockquote>
  <p>“It’s an old-fashioned thing to say, but I think that occasions of fear are invitations for freedom and for courage.”<br>
<em>—John O’Donohue</em></p>
</blockquote>

<p>It was just before Thanksgiving in 2017 and I was scared. The enormity of the decision I had just made – to leave behind 5 years worth of memories, friendships, and professional networks on the opposite side of the country to move home and run for office – was finally hitting home. I was lonely and afraid. So I decided to drive down to Durham to meet up with a close high school friend I hadn’t seen in a long, long time. After a couple of beers, I confessed my anxiousness. She recommended <a href="https://drive.google.com/open?id=1RpKTUDIhXlfXdoZXqt3gBlY0Zvy4_EZY">a lecture by an Irish thinker named John O’Donohue, specifically “Love is the Only Antidote to Fear”</a>. The words hit me like a thunderbolt. Ever since then, whenever I am weighing the pros and cons of a big decision, I make sure to re-listen to this talk.</p>

<p>These are confusing, chaotic, and uncertain times. It is natural to be afraid. I hope this lecture provides some level of comfort to you, just as it has for me throughout the years.</p>

<p>NB: I highly, highly recommend <em>listening</em> to this talk. <a href="https://drive.google.com/open?id=1RpKTUDIhXlfXdoZXqt3gBlY0Zvy4_EZY">You can find the link here</a>. O’Donohue is a noted lecturer for a reason, and it’s clear when you hear his highly conversational style in a Celtic lilt that those skills were honed at a lecturn during his years as a parish priest. However, if you prefer to read the text, I have transcribed it below.</p>

<hr>



<p><em>This text has been lightly edited to improve the flow while reading. I fed the recording through Descript to generate the original transcript, and then attempted to manually clean it up as I best I could. Transcription errors may remain. If you have suggestions or corrections, please email me.</em></p>

<p>Something that everyone has in common is the experience of fear, and the power of the presence of fear. There is no one that could say that they’re not afraid of something. Fear is present in every heart, and science and cultural studies show us that we’re right to be afraid to a level of about 10% in our experience that that corresponds with what’s actually the situation, but that 90% of the fear that we have is unreal. And that’s the haunting loneliness and incredible wastage of what fear does to the human heart.</p>

<p>Fear is the greatest trickster of all. It makes what is real seem unreal and it makes the unreal, real. I always think from nature that the most telling image to correspond to fear is fog. If you’ve ever been out in the mountains and you’ve got caught in fog, you’ll know what I’m talking about. Several years ago, in the mountains at home in the west of Ireland that I know very well, I brought a friend from Manchester for a day on the mountains. And about two hours up in the mountains, the fog came down. I know these mountains really well and we kept going because I told her that I knew where I was going. And about four hours later, we found ourselves exactly back in the place where we were on the fog came down, not knowing where we were. Eventually we got down off the mountains because I was able to hear the ocean and we went in that direction. But that’s what fear does. And your normal experience is that it inflates things and makes something that’s fairly small very, very huge.</p>

<p>Some years ago, I was talking to a friend of mine who is into psychology and psychotherapy about fear. He said that something that he found very helpful when he was afraid was to hold on to one question and stick with it. And the question is to ask yourself, “What is it, exactly, that I’m afraid of?” If you hold to this question, gradually what seems huge and amorphous and beyond your control begins to shrink right down to one moment, one thing that you can actually deal with and handle.</p>

<p>Part of the reason that fear has such power over us is we are vulnerable, and fear draws great strength from time. If you wake up one Monday morning and you realize that on the next Friday that you have something horrible waiting for you, the chances are that your days on Monday, Tuesday, Wednesday, and Thursday will be totally shadowed by the threat of Friday, and you waste four lovely days because the fear of what’s waiting for you robs you of the beauty of the days that you have.
Something that I try to do myself when I’m afraid is to sit myself down, and on an empty chair opposite me I’d imagine the thing (or person or situation or whatever) that I was afraid of. Then I’d say to myself, “Let’s do it now. Instead of being miserable about it, let’s have a blast at it.” And then I would imagine, I’d say to myself, “What’s the worst thing that could happen in this situation?” And I’d think about it until I realize what the worst thing was and then I would force myself to imagine all the elements of the worst aspect of it. And then by the time the situation actually arrives, it isn’t too bad at all. You’ll be incredibly relieved cause it’s never as bad as you thought!</p>

<p>One of the questions that’s always haunted me is what is the origin of fear? Why are humans afraid? One of the reasons is that the place we live in the world is in this clay tent of the human body. And it’s a very vulnerable old tent. Because once you’re in a body, you’re always somewhere. You can never successfully hide and you can always be gotten to. You know, like in some of these mafia films, when they go off for a while but somebody always turns up nearly and gets to them? It’s the same thing, but in a human life.</p>

<p>The other thing is that the way that we interpret the world is an incredibly painful and broken and tender way through birth, which was separation. And I always think that humans are really able for anything after successfully coming through the trauma of being born. Because it was loss, separation, alienation. I mean, I often think that’s an image I often use for myself in relation to death. Maybe we have death all wrong because we always think of it as an ending, as closure. A quenching.
But say you turn it the other way around. Say you conducted an interview with the baby in the womb before it was born. And say was a real “with it” baby, the kind that wanted to know what’s going down and you said:</p>

<p>“Okay, baby, you asked for it. You’re going to get it. Here’s the story. In a half an hour you will be expelled from the shelter of the womb where you have emerged and been formed. Secondly, you will come out along a passage (and we all did this) where you will feel that every moment you’re being smothered. Thirdly, you will arrive out into a huge vacancy, probably with merciless light in it. Fourthly, the cord that connects you to the mother heart will be cut. Fifthly, regardless of how close you ever come to anyone in your life afterwards, you will always be on your own. Sixthly, you’re going on a journey for which there is no map. And seventhly, you can’t turn back and eighth, anything can happen to you on the journey.”
Now, if the baby was still breathing at that stage, it would have to conclude, “Jesus, things were really nice and good here and now it looks like I’m going to die,” when in actual fact what’s happening is that has been born. And my suspicion in relation to death is that we only see all the destructive side of it, and that possibly, (I’ll address this bit tomorrow and my talk on beauty), that what’s happening actually in death is that we’re being born again. This time, in a way that the loneliness of space and time no longer has a hold over us.</p>

<p>But I think that if you were to ask, “What is the root of all fear?” the root of all fear is in the fear of death. And I have an old suspicion that if you sort out your fear of death as the worst thing – not something that just might happen to you but that IS going to happen to you – then you remove the soil and the nutrient that nourishes your normal fears.</p>

<p>I used to be very afraid of dying for a long time in my life. And then I became a Roman Catholic priest. And in my years as a priest, one of the immense privileges was to help people to die. And early on in my priesthood there was this woman that I knew. She was a lovely woman, 27 years old. She was a traveler, one of the gypsy people, and she had two children and she was pregnant with a third child when she got leukemia. She was being treated for it though, and it seemed to be working. I was visiting her once a week, and one evening I went in to see her and I was going to give her a hug and she said, “Don’t hug me, I’m bleeding.” And it turned out that the treatment wasn’t working. About four nights later, in the middle of the night, there was a knock at the door of my house. Her family was there and they said, “We’ve got news from the hospital that she’s really bad and we need to go in.” So I talked to the father and mother, and then they all came with their vans and we all went into the hospital. And as soon as I came in the hospital door, I saw the young woman on all these machines and tubes and everything. And she looked up at me, the poor pet, and she said, “Am I going to die?” And I said, “I don’t know whether you’re going to die or not. But when I do, I will tell you.” She said, “Okay.” So then everybody arrived and all the rest of it, and about 4:15 in the morning, she said to me, “Will you open the window?” And something told me that she was going to die. So I went out and I met the house doctor who was on duty and I said, “What’s the story here?” He said, “At 7:30, we are going to bring our downstairs and try one more procedure. But, in actual fact, we expect her to be dead by 10.” So I went back into the room and I said that I wanted some time on my own with her. All the family left and I sat down. I took her hand.</p>

<p>“You’re going to die,” is one of the most awful sentences any human being can ever hear, no matter how sick you are. Sometimes we think when people are sick that they know what’s coming, but they don’t. Because language is an incredible presence. There are some words that are said that are like …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear">https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear</a></em></p>]]>
            </description>
            <link>https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640573</guid>
            <pubDate>Wed, 30 Sep 2020 16:33:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Eltrot, a web app to have structured debates with results]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24640470">thread link</a>) | @jandehaan
<br/>
September 30, 2020 | https://about.eltrot.com/en/ | <a href="https://web.archive.org/web/*/https://about.eltrot.com/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>When might I use this?</h2>

            <p>When medium-sized groups (10 to 100 people) have to make decisions, it can be a lot of work to make
                sure that everyone gets the opportunity to voice their opinion. You could get everyone gathered in a
                room (not a good idea at the moment) to present arguments and then have a vote, but that is in most
                cases only feasible for a few issues that are deemed to be the most important.</p>

            <p>Asynchronous communication-tools such as instant-messaging groups lower the barrier to having a
                discussion,
                but their complete lack of structure makes it difficult for a decision to be reached, and
                participation
                is
                in most cases
                limited to a passionate few, leaving either the decision or, if a poll is conducted afterwards, the
                choices, without sufficient legitimacy.</p>

            <p>Eltrot is supposed to be the better choice in these situations.</p>
        </div><div>
            <h2>Why are votes not secret?</h2>

            <p>Preferential voting systems are not compatible with secret voting: You would only need 10 answers for
                there
                to be vastly more possible rankings than voters, enabling voters to identify themselves.</p>

            <p>Even when you ignore this problem, electronic voting is difficult or even impossible to get right. Making
                votes public ensures the system is not used when the stakes are too high. If the stakes are high enough
                to
                require secret voting, I recommend using paper ballots.</p>
            
        </div></div>]]>
            </description>
            <link>https://about.eltrot.com/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640470</guid>
            <pubDate>Wed, 30 Sep 2020 16:25:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief History of Neural Nets and Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640259">thread link</a>) | @andreyk
<br/>
September 30, 2020 | https://www.skynettoday.com/overviews/neural-net-history | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/overviews/neural-net-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</h2>

<blockquote>
  <p>“Deep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences.” -<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00239">Dr. Christopher D. Manning, Dec 2015</a> <sup id="fnref:part1_1" role="doc-noteref"><a href="#fn:part1_1">1</a></sup></p>
</blockquote>

<p>This may sound hyperbolic - to say the established methods of an entire field of research are quickly being superseded by a new discovery, as if hit by a research ‘tsunami’. But, this catastrophic language is appropriate for describing the meteoric rise of Deep Learning over the last several years - a rise characterized by drastic improvements over reigning approaches towards the hardest problems in AI, massive investments from industry giants such as Google, and exponential growth in research publications (and Machine Learning graduate students). Having taken several classes on Machine Learning, and even used it in undergraduate research, I could not help but wonder if this new ‘Deep Learning’ was anything fancy or just a scaled up version of the ‘artificial neural nets’ that were already developed by the late 80s. And let me tell you, the answer is quite a story - the story of not just neural nets, not just of a sequence of research breakthroughs that make Deep Learning somewhat more interesting than ‘big neural nets’  (that I will attempt to explain in a way that just about anyone can understand), but most of all of how several unyielding researchers made it through dark decades of banishment to finally redeem neural nets and achieve the dream of Deep Learning.</p>


<blockquote><p id="sources">
I am certainly not a foremost expert on this topic. In depth technical overviews with long lists of references written by those who actually made the field what it is include Yoshua Bengio's <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf">"Learning Deep Architectures for AI"</a>, Jürgen Schmidhuber's <a href="http://arxiv.org/pdf/1404.7828v4.pdf">"Deep Learning in Neural Networks: An Overview"</a> and LeCun et al.s' <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">"Deep learning"</a>. In particular, this is mostly a history of research in the US/Canada AI community, and even there will not mention many researchers; a particularly in depth history of the field that covers these omissions is Jürgen Schmidhuber's <a href="http://people.idsia.ch/~juergen/deep-learning-overview.html">"Deep Learning in Neural Networks: An Overview"</a>. I am also most certainly not a professional writer, and will cop to there being shorter and much less technical overviews written by professional writers such as Paul Voosen's <a href="http://chronicle.com/article/The-Believers/190147">"The Believers"</a>, John Markoff's <a href="http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html">"Scientists See Promise in Deep-Learning Programs"</a> and Gary Marcus's <a href="http://www.newyorker.com/news/news-desk/is-deep-learning-a-revolution-in-artificial-intelligence">"Is “Deep Learning” a Revolution in Artificial Intelligence?"</a>. I also will stay away from getting too technical here, but there is a plethora of tutorials on the internet on all the major topics covered in brief by me.
<br>
Any corrections would be appreciated, though I will note some ommisions are intentional since I want to try and keep this 'brief' and a good mix of simple technical explanations and storytelling. 
<br>
This piece is an updated and expanded version of blog posts originally released in 2015 on www.andreykurenkov.com. 
</p></blockquote>

<ul id="markdown-toc">
  <li><a href="#prologue-the-deep-learning-tsunami" id="markdown-toc-prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</a></li>
  <li><a href="#part-1-the-beginnings-1950s-1980s" id="markdown-toc-part-1-the-beginnings-1950s-1980s">Part 1: The Beginnings (1950s-1980s)</a>    <ul>
      <li><a href="#the-centuries-old-machine-learning-algorithm" id="markdown-toc-the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</a></li>
      <li><a href="#the-folly-of-false-promises" id="markdown-toc-the-folly-of-false-promises">The Folly of False Promises</a></li>
      <li><a href="#the-thaw-of-the-ai-winter" id="markdown-toc-the-thaw-of-the-ai-winter">The Thaw of the AI Winter</a></li>
    </ul>
  </li>
  <li><a href="#part-2-neural-nets-blossom-1980s-2000s" id="markdown-toc-part-2-neural-nets-blossom-1980s-2000s">Part 2: Neural Nets Blossom (1980s-2000s)</a>    <ul>
      <li><a href="#neural-nets-gain-vision" id="markdown-toc-neural-nets-gain-vision">Neural Nets Gain Vision</a></li>
      <li><a href="#neural-nets-go-unsupervised" id="markdown-toc-neural-nets-go-unsupervised">Neural Nets Go Unsupervised</a></li>
      <li><a href="#neural-nets-gain-beliefs" id="markdown-toc-neural-nets-gain-beliefs">Neural Nets Gain Beliefs</a></li>
      <li><a href="#neural-nets-make-decisions" id="markdown-toc-neural-nets-make-decisions">Neural Nets Make Decisions</a></li>
      <li><a href="#neural-nets-get-loopy" id="markdown-toc-neural-nets-get-loopy">Neural Nets Get Loopy</a></li>
      <li><a href="#neural-nets-start-to-speak" id="markdown-toc-neural-nets-start-to-speak">Neural Nets Start to Speak</a></li>
      <li><a href="#a-new-winter-dawns" id="markdown-toc-a-new-winter-dawns">A New Winter Dawns</a></li>
    </ul>
  </li>
  <li><a href="#part-3-deep-learning-2000s-2010s" id="markdown-toc-part-3-deep-learning-2000s-2010s">Part 3: Deep Learning (2000s-2010s)</a>    <ul>
      <li><a href="#the-funding-of-more-layers" id="markdown-toc-the-funding-of-more-layers">The Funding of More Layers</a></li>
      <li><a href="#the-development-of-big-data" id="markdown-toc-the-development-of-big-data">The Development of Big Data</a></li>
      <li><a href="#the-importance-of-brute-force" id="markdown-toc-the-importance-of-brute-force">The Importance of Brute Force</a></li>
      <li><a href="#the-deep-learning-equation" id="markdown-toc-the-deep-learning-equation">The Deep Learning Equation</a></li>
    </ul>
  </li>
  <li><a href="#epilogue-the-decade-of-deep-learning" id="markdown-toc-epilogue-the-decade-of-deep-learning">Epilogue: The Decade of Deep Learning</a></li>
</ul>


<p>The beginning of a story spanning half a century, about how we learned to make computers learn. In this part, we shall cover the birth of neural nets with the Perceptron in 1958, the AI Winter of the 70s, and neural nets’ return to popularity with backpropagation in 1986.</p>

<h2 id="the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</h2>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/Linear_regression.svg" alt="Linear Regression">     
    <figcaption>Linear regression <a href="https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg">(Source)</a></figcaption>
</figure>

<p>Let’s start with a brief primer on what Machine Learning is. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general function that can map any input value to an output value. This is known as linear regression, and it is a wonderful little <a href="https://en.wikipedia.org/wiki/Linear_regression#cite_note-4">200 year old</a> technique for extrapolating a general function from some set of input-output pairs. And here’s why having such a technique is wonderful: there is an incalculable number of functions that are hard to develop equations for directly, but are easy to collect examples of input and output pairs for in the real world - for instance, the function mapping an input of recorded audio of a spoken word to an output of what that spoken word is.</p>

<p>Linear regression is a bit too wimpy a technique to solve the problem of speech recognition, but what it does is essentially what <strong>supervised Machine Learning</strong> is all about: ‘learning’ a function given a <strong>training set</strong> of <strong>examples</strong>, where each example is a pair of an input and output from the function (we shall touch on the unsupervised flavor in a little while). In particular, machine learning methods should derive a function that can generalize well to inputs not in the training set, since then we can actually apply it to inputs for which we do not have an output. For instance, Google’s current speech recognition technology is powered by Machine Learning with a massive training set, but not nearly as big a training set as all the possible speech inputs you might task your phone with understanding.</p>

<p>This generalization principle is so important that there is almost always a <strong>test set</strong> of data (more examples of inputs and outputs) that is not part of the training set. The separate set can be used to evaluate the effectiveness of the machine learning technique by seeing how many of the examples the method correctly computes outputs for given the inputs. The nemesis of generalization is <strong>overfitting</strong> - learning a function that works really well for the training set but badly on the test set. Since machine learning researchers needed means to compare the effectiveness of their methods, over time there appeared standard <strong>datasets</strong> of training and testing sets that could be used to evaluate machine learning algorithms.</p>

<p>Okay okay, enough definitions. Point is - our line drawing exercise is a very simple example of supervised machine learning: the points are the training set (X is input and Y is output), the line is the approximated function, and we can use the line to find Y values for X values that don’t match any of the points we started with. Don’t worry, the rest of this history will not be nearly so dry as all this. Here we go.</p>

<h2 id="the-folly-of-false-promises">The Folly of False Promises</h2>

<p>Why have all this prologue with linear regression, since the topic here is ostensibly neural nets? Well, in fact linear regression bears some resemblance to the first idea conceived specifically as a method to make machines learn: <a href="http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;id=1959-09865-001">Frank Rosenblatt’s <strong>Perceptron</strong></a><sup id="fnref:part1_2" role="doc-noteref"><a href="#fn:part1_2">2</a></sup>.</p>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34998.jpg" alt="Perceptron">
    <figcaption>A diagram showing how the Perceptron works. <a href="http://cse-wiki.unl.edu/wiki/images/0/0f/Perceptron.jpg">(Source)</a></figcaption>    
</figure>

<p>A psychologist, Rosenblatt conceived of the Percetron as a simplified mathematical model of how the neurons in our brains operate: it takes a set of binary inputs (nearby neurons), multiplies each input by a continuous valued weight (the synapse strength to each nearby neuron), and thresholds the sum of these weighted inputs to output a 1 if the sum is big enough and otherwise a 0 (in the same way neurons either fire or do not). Most of the inputs to a Perceptron are either some data or the output of another Perceptron, but an extra detail is that Perceptrons also have one special ‘bias’ input, which just has a value of 1 and basically ensures that more functions are computable with the same input by being able to offset the summed value. This model of the neuron built on the work of Warren McCulloch and Walter Pitts <a href="http://www.minicomplexity.org/pubs/1943-mcculloch-pitts-bmb.pdf">Mcculoch-Pitts</a><sup id="fnref:part1_3" role="doc-noteref"><a href="#fn:part1_3">3</a></sup>, who showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions. This, in the early days of AI, was a big deal - the predominant thought at the time was that making computers able to perform formal logical reasoning would essentially solve AI.</p>

<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34832.jpg" alt="Perceptron 2"> 
    <figcaption>Another diagram, showing the biological inspiration. The <b>activation function</b> is what people now call the non-linear function applied to the weighted input sum to produce the output of the artificial neuron - in the case of Rosenblatt's Perceptron, the function just a thresholding operation.  <a href="http://cs231n.github.io/neural-networks-1/">(Source)</a> </figcaption>    
</figure>

<p>However, the Mcculoch-Pitts model lacked a mechanism for learning, which was crucial for it to be usable for AI. This is where the Perceptron excelled - Rosenblatt came up with a way to make such artificial neurons learn, inspired by the <a href="http://onlinelibrary.wiley.com/doi/10.1002/cne.900930310/abstract">foundational work</a><sup id="fnref:part1_4" role="doc-noteref"><a href="#fn:part1_4">4</a></sup> of Donald Hebb. Hebb put forth the unexpected and hugely influential idea that knowledge and learning occurs in the brain primarily through the formation and change of synapses between neurons - concisely stated as Hebb’s Rule:</p>

<blockquote>
  <p>“When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A’s efficiency, as one of the cells firing B, is increased.”</p>
</blockquote>

<p>The Perceptron did not follow this idea exactly, but having weights on the inputs allowed for a very simple and intuitive learning scheme: given a <strong>training set</strong> of input-output examples the Perceptron should ‘learn’ a function from, for each example increase the weights if the Perceptron output for that example’s input is too low compared to the example, and otherwise decrease the weights if the output is too high. Stated ever so slightly more formally, the algorithm is as follows:</p>

<ol>
  <li>Start off with a Perceptron having random weights and a training set</li>
  <li>For the inputs of an example in the …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/overviews/neural-net-history">https://www.skynettoday.com/overviews/neural-net-history</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/overviews/neural-net-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640259</guid>
            <pubDate>Wed, 30 Sep 2020 16:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Watching Your iPhone Work to Protect You from Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640216">thread link</a>) | @josephby
<br/>
September 30, 2020 | https://joseph.by/2020/09/30/watching-your-iphone-work-to-protect-you-from-covid-19/ | <a href="https://web.archive.org/web/*/https://joseph.by/2020/09/30/watching-your-iphone-work-to-protect-you-from-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	
	<div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-636">

	

	
			<figure>
				<img width="1568" height="1153" src="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=1568" alt="" loading="lazy" srcset="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=1568 1568w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=150 150w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=300 300w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=768 768w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=1024 1024w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg 1768w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="657" data-permalink="https://joseph.by/2020/09/30/watching-your-iphone-work-to-protect-you-from-covid-19/pexels-photo-699122/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg" data-orig-size="1768,1300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pexels-photo-699122.jpeg" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=300" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>Much has been written about the Apple + Google Covid-19 Exposure Notification framework. This is the software that is now part of Android and iOS (13.5+) and powers Covid-19 detection apps for Android and iPhone like COVID Alert (much of Canada), COVIDWISE (Virginia) and <a href="https://www.xda-developers.com/google-apple-covid-19-contact-tracing-exposure-notifications-api-app-list-countries/">dozens of other jurisdictions around the world</a> .</p>



<p>I’m in Ontario and use COVID Alert on my iPhone 8 Plus. The apps are fantastic pieces of work from the Canadian Digital Service and its private sector partners Shopify and BlackBerry. That said, I have always wished for more feedback from the app itself. Something that gives me a sense of it actually working. I’m the first to admit that this isn’t a rational need. When you open COVID Alert here is what you see:</p>



<figure><img loading="lazy" data-attachment-id="643" data-permalink="https://joseph.by/covid-alert-screen-shot-1/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg" data-orig-size="1242,2148" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="covid-alert-screen-shot-1" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=173" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=592" src="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=592" alt="" width="296" height="512" srcset="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=592 592w, https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=296 296w, https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=87 87w, https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=173 173w" sizes="(max-width: 296px) 100vw, 296px"><figcaption>Great! You’re active! But what does that mean?</figcaption></figure>



<p>I’m grateful that no exposure has been detected! But the app doesn’t <em>look</em> like it’s doing anything. I know that that’s not the case. I know that it is doing stuff but that’s because I’m a nerd and because the Canadian Digital Service maintains the source for both the Android and iPhone COVID Alert apps <a href="https://github.com/cds-snc/covid-alert-app.">on GitHub</a> .</p>



<h2>But how can I see it actually doing stuff?</h2>



<p>Well here’s one way. Both iPhone and Android allow you to see a log <a href="https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19/covid-alert/help.html#13">showing each time COVID Alert has downloaded a list of exposures</a> from the COVID Alert server.</p>



<p>On iPhone you can see the log in Settings -&gt; Exposure Notifications -&gt; Exposure Logging Status -&gt; Exposure Checks . </p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:181459260,&quot;permalink&quot;:&quot;https:\/\/joseph.by\/2020\/09\/30\/watching-your-iphone-work-to-protect-you-from-covid-19\/&quot;}"><li><figure><img data-attachment-id="648" data-permalink="https://joseph.by/img_1696/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg" data-orig-size="1242,2148" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1696" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=173" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=592" src="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=592" alt="" data-id="648" data-link="https://joseph.by/img_1696/" srcset="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=592 592w, https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=1184 1184w, https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=87 87w, https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=173 173w, https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=768 768w" sizes="(max-width: 592px) 100vw, 592px"><figcaption>A log of every time COVID Alert downloaded new exposures</figcaption></figure></li><li><figure><img data-attachment-id="647" data-permalink="https://joseph.by/img_1697/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg" data-orig-size="1242,2148" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1697" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=173" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=592" src="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=592" alt="" data-id="647" data-link="https://joseph.by/img_1697/" srcset="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=592 592w, https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=1184 1184w, https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=87 87w, https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=173 173w, https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=768 768w" sizes="(max-width: 592px) 100vw, 592px"><figcaption>A single log entry</figcaption></figure></li><li><figure><img data-attachment-id="646" data-permalink="https://joseph.by/img_1698/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg" data-orig-size="1227,2121" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1698" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=174" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=592" src="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=592" alt="" data-id="646" data-link="https://joseph.by/img_1698/" srcset="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=592 592w, https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=1184 1184w, https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=87 87w, https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=174 174w, https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=768 768w" sizes="(max-width: 592px) 100vw, 592px"><figcaption>Details for that exposure download event; COVID Alert received 246 IDs representing devices associated with a positive test. </figcaption></figure></li></ul></figure>



<p>What I believe this means is that in that one Exposure Check done at 10:09am ET COVID Alert downloaded 246 Tracing Keys (“device IDs”) of devices that had had a positive Covid-19 test reported over the past 14 days. It also determined that my iPhone did not get close enough to any of those phones, for a long enough period of time, to warrant me getting a Covid-19 test. It’s pretty cool to see the app at work.</p>



<h2>What else could it do?</h2>



<p>I would also love the app to help me understand:</p>



<ol><li><strong>How risky is my current behaviour?</strong><br>How many devices did my phone see in the past 24 hours? How many rolling proximity identifiers (RPIDs) did my phone log? I know that you are not supposed to be able to derive a Tracing Key from an RPID, but could the system run a function over a set of RPIDs and estimate the number of unique Tracing Keys they represent?<br></li><li><strong>How effective is the app at warning people about potential exposure?</strong><br>We had 625 new cases of Covid-19 reported yesterday in Ontario. How does that compare to the 246 Tracing Keys my phone received? Do the time frames line up? Can I compare them? <strong>What’s the effective penetration of the app?</strong></li></ol>



<h2>Closing thoughts</h2>



<p>You can’t tech your way out of a policy or political problem. That said, I strongly agree with the what Apple, Google, and the Government of Canada have done here. If the policy decision is to continue to deploy these decentralized, anonymous exposure notification applications on a voluntary basis then we need to keep looking for ways to make them more effective and more compelling to download and use. Sharing more useful information with people could be a way to get more people to use the app and better inform public health authorities on what to do next.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div><!-- #content -->

		<!-- #colophon -->

</div></div>]]>
            </description>
            <link>https://joseph.by/2020/09/30/watching-your-iphone-work-to-protect-you-from-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640216</guid>
            <pubDate>Wed, 30 Sep 2020 16:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the pervasive presence of military language elements in computer security]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24640198">thread link</a>) | @dijit
<br/>
September 30, 2020 | https://dustri.org/b/on-the-pervasive-presence-of-military-language-elements-in-computer-security.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/on-the-pervasive-presence-of-military-language-elements-in-computer-security.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="content">
  <article>
    <header>
      
    </header>

    <div>
      <p>As I was writing an article for the first edition of <a href="https://pagedout.institute/">Paged Out</a>,
I had an interesting (albeit too short) conversation regarding
its <a href="https://pagedout.institute/download/PagedOut_001_wallpaper_30.png">cover</a>
with <a href="https://gynvael.coldwind.pl/?id=50">Gynvael Coldwind</a>.
Drawn by <a href="https://www.deviantart.com/refiend">ReFiend</a>, it
features two people on the foreground, wielding what looks like guns.
This lead to a discussion on the omnipresence of military jargon, and thus violence,
in the world of computer security. I told him that I'll publish a blogpost 
to correctly articulate my thoughts on the topic, instead of the incoherent
rambling that I served him.</p>
<p>At every single security conference, there is someone with a direct quote of
the <a href="https://en.wikipedia.org/wiki/The_Art_of_War">Art of War</a> on their slide
deck, and there is a metric fuckton of assorted military-inspired bullshit
terms for almost everything: <a href="http://www.sans.org/reading-room/whitepapers/analyst/killing-advanced-threats-tracks-intelligent-approach-attack">cyber
kill-chain</a>/<a href="https://www.langner.com/2010/12/the-short-path-from-cyber-missiles-to-dirty-digital-bombs/">cyber
missiles</a>/<a href="https://www.techopedia.com/definition/29052/cyber-pearl-harbor">cyber
pearl
harbor</a>/<a href="https://www.arcyber.army.mil/">cyber
soldier</a>/<a href="https://www.langner.com/2010/12/the-short-path-from-cyber-missiles-to-dirty-digital-bombs/">cyber
strikes</a>/<a href="https://www.wired.com/2010/03/schmidt-cyberwar/">cyber</a>
<a href="https://www.theverge.com/2014/11/21/7259833/cyberwar-is-bullshit">war</a>/<a href="https://www.bloomberg.com/news/articles/2011-07-20/cyber-weapons-the-new-arms-race">cyber
weapons</a>/<a href="https://www.academic-conferences.org/conferences/iccws/">cyber</a>
<a href="https://en.wikipedia.org/wiki/cyberwarfare">warfare</a>/<a href="http://www.nsci-va.org/cyberreferencelib/2010-11-joint%20terminology%20for%20cyberspace%20operations.pdf">defensive counter
cyber</a>/<a href="https://nvd.nist.gov/800-53/rev4/control/sc-44">detonation
chamber capability</a>/<a href="https://www.cyberriskopportunities.com/notpetya-the-exploit-that-would-lead-to-many-attacks-part-3/">digital
munitions</a>/<a href="https://www.howtogeek.com/445096/what-does-military-grade-encryption-mean/">military-grade
encryption</a>/<a href="https://www.jstor.org/stable/26502756">next-generation
defensive cyber operations</a>/<a href="https://en.wikipedia.org/wiki/proactive_cyber_defence">proactive
cyber defence</a>/…</p>
<p>I understand that it's tempting to compare computer security to war: It takes our daily toil and
raises the stakes, makes us feel that victory is glorious; a battle of the
minds, that our work really matters and is important; and we are united against a common enemy.</p>
<p>But when you think about it, it's absurd: War is something terrible that should be avoided at
almost any cost, a <em>solution</em> of last resort. The worse outcome of
computer-related drama/problems probably doesn't imply entire populations
dying, being tortured, millions of refugees, camps, … Odds are that you won't
save actual lives by deploying a firewall: don't call it a "cyber bulletproof vest deployment".</p>
<p>War justifies terrible behaviours: who cares about you being screamed at when
you're <em>at war</em>? Who cares about your family life, your dinners plans, your hollidays, … when you're <em>at war</em>? What
are broken principles and despicable means, when you're <em>at war</em> ? …
which is a disastrous way to govern and organise a workspace.</p>
<p>Moreover, war maps poorly over computer security. What is a "<a href="https://en.wikipedia.org/wiki/Penetration_test">penetration
test</a>"
combat-wise? How do you map "<a href="https://en.wikipedia.org/wiki/Full_disclosure_">full disclosure</a>" to war? What is a
"prisoner's camp" or "<a href="https://en.wikipedia.org/wiki/Carpet_bombing">carpet bombing</a>" with a computer (apparently <a href="https://www.zdnet.com/article/proof-of-concept-carpet-bombing-exploit-released-in-the-wild/">zdnet</a> <a href="https://www.zdnet.com/article/carpet-bombing-ddos-attack-takes-down-south-african-isp-for-an-entire-day/">can</a> )? Rigidly mapping
one onto the other can and will create huge distortions.</p>
<p>Of course, nobody says that computer security stuff actually <em>is</em> war, but
as said in <a href="https://en.wikipedia.org/wiki/Metaphors_We_Live_By">Metaphors We Live By </a> by <a href="https://en.wikipedia.org/wiki/George_Lakoff">George Lakoff</a> and <a href="https://en.wikipedia.org/wiki/Mark_Johnson_(professor)">Mark
Johnson</a>, "Conceptual metaphors shape not just our communication, but also shape
the way we think and act.". Leading to nonsensical bullshit posts like <a href="https://twoscenarios.typepad.com/maneuver_marketing_commun/2005/05/military_metaph.html">this one</a>, <a href="https://www.forbes.com/sites/forbeslifestyle/2012/05/07/plea-for-a-cease-fire-in-business-as-warfare-advice/#f77cce37aa79">entire laughingly stupid books</a>,
and to despicable and hostile work climate.</p>
<p>An other perverse effect is that since military and violent imagery are traditionally, culturally and stereotypically associated with <a href="https://en.wikipedia.org/wiki/Toxic_masculinity">toxic masculinity</a>,
this doesn't help with increasing the <a href="https://www.isc2.org/research/women-in-cybersecurity">dramatically low</a> diversity in the computer security sector.</p>
<p>When we think about it, we have way better metaphors:</p>
<ul>
<li>Computer security as gardening: defending against bugs, growing programs,
     harvesting money, …</li>
<li>Computer security as building a house: everyone wants cosy stuff, yet you
    still need a solid door, maybe a couple of windows as well, definitely solid
    walls, …</li>
<li>Computer security as playing cards: there are adversaries, winning moves,
    gambles, influences, …</li>
<li>Computer security as guarding a museum: priceless artefacts, sneaky attackers
    à la Arsène Lupin, …</li>
<li>…</li>
</ul>
<p>The goal of computer security is to make safer systems, not about waging wars,
and thus shouldn't be envisioned as such. </p>
<p>Of course, if you're working in the military and in infosec, there are overlaps,
but I would argue that this is more about military than it is about computer security.</p>
<p>As <a href="https://www.linkedin.com/in/roybahat">Rob Bahat</a> said in 2016 in his <a href="https://shift.newco.co/2016/11/15/business-is-not-war-lets-stop-talking-like-it-is/">Business Is Not War. Let’s Stop Talking Like It Is.</a> article:</p>
<blockquote>
<p>Business, at its best, is creation — and war,
always, is destruction. They are opposites, and if we want industry to be a
positive force in our personal lives, environment, society, and future, we
should divorce our language about business from the tragic (if sometimes
necessary) conflicts that bring devastation. There are so many good businesses;
but it is hard to find a good war.</p>
</blockquote>
    </div>
  </article>
</section>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/on-the-pervasive-presence-of-military-language-elements-in-computer-security.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640198</guid>
            <pubDate>Wed, 30 Sep 2020 16:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Failed Promise of Web Components]]>
            </title>
            <description>
<![CDATA[
Score 330 | Comments 200 (<a href="https://news.ycombinator.com/item?id=24640151">thread link</a>) | @lemonberry
<br/>
September 30, 2020 | https://lea.verou.me/2020/09/the-failed-promise-of-web-components/ | <a href="https://web.archive.org/web/*/https://lea.verou.me/2020/09/the-failed-promise-of-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Web Components had so much potential to empower HTML to do more, and make web development more accessible to non-programmers and easier for programmers. Remember how exciting it was every time we got new shiny HTML elements that actually <em>do stuff</em>? Remember how exciting it was to be able to do sliders, color pickers, dialogs, disclosure widgets straight in the HTML, without having to include any widget libraries?</p>



<p>The promise of Web Components was that we’d get this convenience, but for a much wider range of HTML elements, developed much faster, as nobody needs to wait for the full spec + implementation process. We’d just include a script, and boom, we have more elements at our disposal!</p>



<p>Or, that was the idea. Somewhere along the way, the space got flooded by JS frameworks aficionados, who revel in complex APIs, overengineered build processes and dependency graphs that look like the roots of a banyan tree.</p>



<figure><img src="https://live.staticflickr.com/2025/32441377780_e3acf6de12_b.jpg" alt=""><figcaption>This is what the roots of a Banyan tree look like. <a href="https://www.flickr.com/photos/79721788@N00/32441377780/">Photo by David Stanley on Flickr (CC-BY)</a>. </figcaption></figure>



<p>Perusing the components on <a href="https://www.webcomponents.org/">webcomponents.org</a> fills me with anxiety, and I’m perfectly comfortable writing JS — I write JS for a living! What hope do those who can’t write JS have? Using a custom element from the directory often needs to be preceded by a ritual of npm flugelhorn, import clownshoes, build quux, all completely unapologetically because “here is my truckload of dependencies, yeah, what”. Many steps are even omitted, likely because they are “obvious”. Often, you wade through the maze only to find the component doesn’t work anymore, or is not fit for your purpose.</p>



<p>Besides setup, the main problem is that HTML is not treated with the appropriate respect in the design of these components. They are not designed as closely as possible to standard HTML elements, but <em>expect</em> JS to be written for them to do anything. HTML is simply treated as a shorthand, or worse, as merely a marker to indicate where the element goes in the DOM, with all parameters passed in via JS. I recall <a href="https://adactio.com/articles/12839#webcomponents">a wonderful talk by Jeremy Keith</a> a few years ago about this very phenomenon, where he discussed <a href="https://shop.polymer-project.org/">this e-shop Web components demo by Google</a>, which is the poster child of this practice. These are the entire contents of its <code>&lt;body&gt;</code> element:</p>



<pre><code>&lt;body&gt;
	&lt;shop-app unresolved=""&gt;SHOP&lt;/shop-app&gt;
	&lt;script src="node_assets/@webcomponents/webcomponentsjs/webcomponents-loader.js"&gt;&lt;/script&gt;
	&lt;script type="module" src="src/shop-app.js"&gt;&lt;/script&gt;
	&lt;script&gt;window.performance&amp;&amp;performance.mark&amp;&amp;performance.mark("index.html");&lt;/script&gt;
&lt;/body&gt;</code></pre>



<p>If this is how Google is leading the way, how can we hope for contributors to design components that follow established HTML conventions?</p>



<p>Jeremy criticized this practice from the aspect of backwards compatibility: when JS is broken or not enabled, or the browser doesn’t support Web Components, the entire website is blank. While this is indeed a serious concern, my primary concern is one of <strong>usability</strong>: <strong>HTML is a lower barrier to entry language</strong>. Far more people can write HTML than JS. Even for those who do eventually write JS, it often comes after spending years writing HTML &amp; CSS.</p>



<p>If components are designed in a way that requires  JS, this excludes thousands of people from using them. And even for those who <em>can</em> write JS, HTML is often easier: you don’t see many people rolling their own sliders or using JS-based ones once <code>&lt;input type="range"&gt;</code> became widely supported, right?</p>



<p>Even when JS is unavoidable, it’s not black and white. A well designed HTML element can reduce the amount and complexity of JS needed to a minimum. Think of the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog">&lt;dialog&gt;</a></code> element: it usually does require *some* JS, but it’s usually rather simple JS. Similarly, the <code>&lt;video&gt;</code> element is perfectly usable just by writing HTML, and has a comprehensive JS API for anyone who wants to do fancy custom things.</p>



<p>The other day I was looking for a simple, dependency free, tabs component. You know, the canonical example of something that is easy to do with Web Components, the example 50% of tutorials mention. I didn’t even care what it looked like, it was for a testing interface. I just wanted something that is small and works like a normal HTML element. Yet, it proved so hard I ended up writing my own!</p>



<h3>Can we fix this?</h3>



<p>I’m not sure if this is a design issue, or a documentation issue. Perhaps for many of these web components, there are easier ways to use them. Perhaps there are vanilla web components out there that I just can’t find. Perhaps I’m looking in the wrong place and there is another directory somewhere with different goals and a different target audience. </p>



<p>But if not, and if I’m not alone in feeling this way, we need a directory of web components with strict inclusion criteria:</p>



<ul><li><strong>Plug and play.</strong> No dependencies, no setup beyond including one <code>&lt;script&gt;</code> tag. If a dependency is absolutely <em>needed</em> (e.g. in a map component it doesn’t make sense to draw your own maps), the component loads it automatically if it’s not already loaded.</li><li>Syntax and API follows <a href="https://www.smashingmagazine.com/2017/02/designing-html-apis/"><strong>conventions established by built-in HTML elements</strong></a> and anything that <em>can</em> be done without the component user writing JS, <em>is</em> doable without JS, per <a href="https://www.w3.org/2001/tag/doc/leastPower.html">the W3C principle of least power</a>.</li><li><strong>Accessible by default</strong> via sensible ARIA defaults, just like normal HTML elements.</li><li><strong>Themable</strong> via <code><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/::part">::part()</a></code>, selective inheritance and custom properties. Very minimal style by default. Normal CSS properties should just “work” to the the extent possible.</li><li><strong>Only one component of a given type</strong> in the directory, that is <strong>flexible</strong> and <strong>extensible</strong> and continuously iterated on and improved by the community. Not 30 different sliders and 15 different tabs that users have to wade through. No branding, no silos of “component libraries”. Only elements that are designed as closely as possible to what a browser would implement in every way the current technology allows.</li></ul>



<p>I would be up for working on this if others feel the same way, since that is not a project for one person to tackle. <em>Who’s with me?</em></p>



<p><strong>UPDATE:</strong> Wow this post blew up! Thank you all for your interest in participating in a potential future effort. I’m currently talking to stakeholders of some of the existing efforts to see if there are any potential collaborations before I go off and create a new one. <a href="https://twitter.com/leaverou">Follow me on Twitter to hear about the outcome</a>!</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://lea.verou.me/2020/09/the-failed-promise-of-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640151</guid>
            <pubDate>Wed, 30 Sep 2020 15:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Garry Tan on Posterous, Palantir, YC, Initialized and Influencer Investing]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24639871">thread link</a>) | @rayshan
<br/>
September 30, 2020 | https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn | <a href="https://web.archive.org/web/*/https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>Transcript:</strong> <em>(disclaimer: may contain unintentionally confusing, inaccurate and/or amusing transcription errors)</em><strong><br></strong></p><div><p>David: Hello, Acquired LPs. We are coming at you today with a very special episode with Garry Tan of Initialized Fame and before that—Y Combinator, Posterous, and has a long and very illustrious career here in Silicon Valley. We are going to talk about the evolution of early-stage investing.</p><p>Garry has seen it all. I think he started back in the early days when early-stage investing meant a $2 million Series A at a $5 million poster. Maybe that was even high. </p><p>Garry: Yeah, it’s a while.</p><p>David: Goodness, things have changed. I'm so excited to have you here. Thanks for joining us and we can't wait to dive in.</p><p>Garry: Yeah, thank you for having me. Big fan of the show and it means a lot to me that you'd have me.</p><p>David: Likewise that you would come on. Let's just dive right in. We're going to weave in the story of Initialized along the way, but we thought maybe we'd start way back in those prehistoric days of what life is like?</p><p>Garry: So, Arthur Rock.</p><p>David: We've already done that on the Sequoia episodes. Not that far back but when was it that you started Posterous? Was it in 2005?</p><p>Garry: It was 2008, actually. </p><p>David: It was 2008. It’s later than I thought.</p><p>Garry: 2005 I was still at Palantir, so I had just designed the logo for Palantir and built one of the major product teams. Before that, I was Stanford Computer Engineering, and the crazy story for me is that friends of mine were starting a company. And I was the lowest of the low PM at Microsoft.</p><p>Ben: What that’s like?</p><p>Garry: Great place to start, great reach. Friends of mine were starting a company with Peter Thiel. They flew me down to San Francisco to have dinner with Peter right when he wrote the $500,000 check to Facebook. He said, “Garry, what are you doing at Microsoft? You're wasting your time.” I said, “I wanted to work at a startup, but they weren't startups in 2003, 2004.”</p><p>He said, “I'm so sure this is the right thing. You need to quit your job.” He asked me how much a year I made. I told him it was $70,000. He said, “Well, how about this? I'll write you a personal check from my bank account to yours. This is your risk opportunity. Quit your job.” I said, “Thank you very much, Mr. Thiel, but I might make it to level 60 next year,” and I got on a plane and went back to Seattle. That company turned into Palantir. </p><p>David: Oh my gosh.</p><p>Garry: I ended up joining a year later, they had hired away some of my closest friends who were way smarter than me. Bob McGrew, who now runs stuff over at OpenAI. Just so many smart people you get to meet in Silicon Valley over time. Once they hired away people smarter than, I was like, I need to quit my job at Microsoft. At the moment, when your friends are starting a business and you don't know anything about startups, tech, or how these things are funded. You say, well, I have a real job, and you say no.</p><p>David: We're talking about this with Kevin and Julia Hartz on the Eventbrite episode. I imagine you're right out of college. Your parents were probably (if you even told them about this) like, no way would they let you do this.</p><p>Garry: They’re like don’t do it. That seems unsafe. Yeah. The immigrant mentality for sure.</p><p>Ben: Garry, that's an amazing story, and it is absolutely one of survivorship bias because I want to share my story. I had a friend who was starting a YC Company. I had just moved to Seattle, and I was about to start my job at Microsoft. This friend lobbied and lobbied and lobbied. They’d come and get me to co-found the company with them.</p><p>For years, it looked like a huge mistake that I said, are you kidding me? I'd have to give back my signing bonus. I just moved here. This person told me something very similar that they would help definitely pay back the signing bonus. [...] your risk thing, they’d pay for my move. But as years have gone by, that company sold for exactly the preference. It would have been completely awash.</p><p>Garry: Yeah. That's tough.</p><p>Ben: For a while I was like, wow, that's one of several examples in my life where I really blew it on joining something early. Sometimes, not that my choice was the right choice, but unless it's Peter Thiel calling, the story doesn't always end the way you’re—</p><p>Garry: Yeah. These things are crazy risky. I often think about, wow, he was willing to pay that much upfront for an engineer. The rest of my career—even as an investor today—is now actually the inversion of that. Which is now I realize actually, it's the software engineers, designers, product people, and the builders who create the future. That's why we're able to do early-stage at all is that we look a lot more like them at that stage and so they'll pick us.</p><p>On the flip side, because I can still code a little bit and I still do design. I'm probably better at marketing now than I was 10 years ago.</p><p>David: You've diversified your skillset.</p><p>Garry: Yeah. That's right. We look more like them. Then that's the cool thing. I think that fits with the overall series. It's like we're talking about the traitorous eight—sending real typewritten letters across the country to financiers who were totally different from them. Now, what we're talking about—what you guys do and what we're doing—is we're no different. I think that time was for venture capitalists to say we're set apart, we're different.</p><p>David: We're in this ivory tower.</p><p>Garry: Yeah. The ivory tower is different. There's actually a ritualistic aspect that I was talking with Geoff Lewis at Bedrock. He has this theory that is really interesting. There is something to be said for I'm walking up the steps of Sequoia, this is what legends before me did, and I can be a part of that.</p><p>Now it's Zoom. If anything, now it's flipped. Now it's about the one on one conversation that you can have right here. That's why you have the rise of influencer investing. I know, we'll talk about it later, but that's part of the reason why I think YouTube is so important, for me anyway. I'm investing very deeply into it because I think it's a very interesting innovation in the course of how ventures are created.</p><p>David: VCs historically take a long time to catch on. YouTube was founded right around this time that we're talking about, and here we are in 2020 and people only just were starting to catch on.</p><p>Garry: 2005, yeah.</p><p>Ben: Garry, you talked about your time as a builder, and we're going to put a pin in this influencer investing and definitely come back to it because I think it'll be a nice way to round out the full story. Take us through founding Posterous, leaving Palantir, how you raised money for that, and how you went about getting enough proof that there's a there, there to invest more of your time.</p><p>Garry: There's nothing quite like seeing a super early-stage startup for your own eyes. Actually, I've always been really thankful for my time working with Stephen Cohen, Joe Lonsdale, and Alex Karp—just the founders of Palantir. Being able to build software from scratch. The more subtle interesting thing that I feel like I learned was how important it is to basically continue to hire people way smarter than you actually.</p><p>The cult making and the mythmaking of the startup very early are really underplayed. I don't feel like people talk about it enough, and Palantir, I think remains very good at it. The only cult that was stronger than our cult was the Facebook cult (I think). But it's interesting to see. Years later, that's an order of magnitude bigger as a company, which is fascinating to me. I think that actually is directly proportional. How strong your cult will result in how big your company ends up being.</p><p>Assuming you're in the right market and 10 other things that you need to survive. You need to be one of those survivors. A lot of things have to break your way.</p><p>Ben: What's an example of something that was done at Palantir to help build that cult brand?</p><p>Garry: Honestly, I think the simplest thing was even just trying to get the smartest, most capable, and hardworking people, which sounds really stupid simple. It seems like everyone should do that, but honestly, people just don't. When you think about hiring, the mistake that a lot of founders make—and honestly, I made this mistake at some level too when I worked on Posterous—was who can I get? And that's the wrong question.</p><p>You should start with who is the smartest person I know, and it doesn't matter where they're at. Because if I get them, then our self-fulfilling prophecy becomes destiny. If I don't, then it doesn't. I'm not doing myself or them a favor by not going after them. We would just go. </p><p>People would pass out yellow legal pads, and we would force everyone to step away from their computers, and it'd be like, write down the names of 20 people who were the smartest people you've ever met in any walk of life. It didn't have to be engineering, design, or whatever. It was just, who are the smartest people you know in your life. We take it into a backroom and cross-reference it and then those are like our hit list. It's like let's go get those people. We're going to take them to dinner, we're going to take them to lunch, we're going to meet them, we're going to chop down the tree, and we're going to go get them.</p><p>David: That mindset leads to doing things like what Peter offered to you. I can't believe I've never thought of that before. Yeah, you were ungettable. You were at Microsoft, but what if you just offered to personally cover the gap in your salary? It didn't work for you then, but a certain number of people, that's going to work with. And if you're not in that mindset of okay, I don't even go to try to get this person. Well then, you don't know, but once you're like, no, I'm going to try and get them. Well, what can I do?</p><p>Garry: Yeah. It just compounds from there because smart people want to work with smart people. I think that is testament and credit to what they've been able to build over the years. That becomes a self-fulfilling …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn">https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn</a></em></p>]]>
            </description>
            <link>https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639871</guid>
            <pubDate>Wed, 30 Sep 2020 15:37:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CycleGAN – Annotated PyTorch Implementation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24639803">thread link</a>) | @vpj
<br/>
September 30, 2020 | http://lab-ml.com/labml_nn/gan/cycle_gan.html | <a href="https://web.archive.org/web/*/http://lab-ml.com/labml_nn/gan/cycle_gan.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    
    
    <div id="section-0">
        
            <div>
                <div><pre><span></span><span>import</span> <span>itertools</span>
<span>import</span> <span>random</span>
<span>from</span> <span>pathlib</span> <span>import</span> <span>PurePath</span><span>,</span> <span>Path</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Tuple</span>

<span>import</span> <span>torch</span>
<span>import</span> <span>torch.nn</span> <span>as</span> <span>nn</span>
<span>import</span> <span>torchvision.transforms</span> <span>as</span> <span>transforms</span>
<span>from</span> <span>PIL</span> <span>import</span> <span>Image</span>
<span>from</span> <span>torch.utils.data</span> <span>import</span> <span>DataLoader</span>
<span>from</span> <span>torch.utils.data</span> <span>import</span> <span>Dataset</span>
<span>from</span> <span>torchvision.utils</span> <span>import</span> <span>make_grid</span>
<span>from</span> <span>torchvision.utils</span> <span>import</span> <span>save_image</span>

<span>from</span> <span>labml</span> <span>import</span> <span>lab</span><span>,</span> <span>tracker</span><span>,</span> <span>experiment</span><span>,</span> <span>monit</span><span>,</span> <span>configs</span>
<span>from</span> <span>labml.configs</span> <span>import</span> <span>BaseConfigs</span>
<span>from</span> <span>labml_helpers.device</span> <span>import</span> <span>DeviceConfigs</span>
<span>from</span> <span>labml_helpers.module</span> <span>import</span> <span>Module</span></pre></div>
            </div>
        </div>
    <div id="section-1">
        <div>
                
                <p>The generator is a residual network.</p>
            </div>
            <div>
                <div><pre><span>class</span> <span>GeneratorResNet</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-2">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>input_shape</span><span>:</span> <span>Tuple</span><span>[</span><span>int</span><span>,</span> <span>int</span><span>,</span> <span>int</span><span>],</span> <span>n_residual_blocks</span><span>:</span> <span>int</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span></pre></div>
            </div>
        </div>
    <div id="section-3">
            <div>
                
                <p>The number of channels in the input image, which is 3 for RGB images.</p>
            </div>
            <div>
                <div><pre>        <span>channels</span> <span>=</span> <span>input_shape</span><span>[</span><span>0</span><span>]</span></pre></div>
            </div>
        </div>
    <div id="section-4">
            <div>
                
                <p>This first block runs a $7\times7$ convolution and maps the image to
a feature map.
The output feature map has same height and width because we have
a padding of $3$.
Reflection padding is used because it gives better image quality at edges.</p>
<p><code>inplace=True</code> in <code>ReLU</code> saves a little bit of memory.</p>
            </div>
            <div>
                <div><pre>        <span>out_features</span> <span>=</span> <span>64</span>
        <span>layers</span> <span>=</span> <span>[</span>
            <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>channels</span><span>,</span> <span>out_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>7</span><span>,</span> <span>padding</span><span>=</span><span>3</span><span>,</span> <span>padding_mode</span><span>=</span><span>'reflect'</span><span>),</span>
            <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>out_features</span><span>),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
        <span>]</span>
        <span>in_features</span> <span>=</span> <span>out_features</span></pre></div>
            </div>
        </div>
    <div id="section-5">
            <div>
                
                <p>We down-sample with two $3 \times 3$ convolutions
with stride of 2</p>
            </div>
            <div>
                <div><pre>        <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>2</span><span>):</span>
            <span>out_features</span> <span>*=</span> <span>2</span>
            <span>layers</span> <span>+=</span> <span>[</span>
                <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_features</span><span>,</span> <span>out_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>stride</span><span>=</span><span>2</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>),</span>
                <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>out_features</span><span>),</span>
                <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
            <span>]</span>
            <span>in_features</span> <span>=</span> <span>out_features</span></pre></div>
            </div>
        </div>
    <div id="section-6">
            <div>
                
                <p>We take this through <code>n_residual_blocks</code>.
This module is defined below.</p>
            </div>
            <div>
                <div><pre>        <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>n_residual_blocks</span><span>):</span>
            <span>layers</span> <span>+=</span> <span>[</span><span>ResidualBlock</span><span>(</span><span>out_features</span><span>)]</span></pre></div>
            </div>
        </div>
    <div id="section-7">
            <div>
                
                <p>Then the resulting feature map is up-sampled
to match the original image height and width.</p>
            </div>
            <div>
                <div><pre>        <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>2</span><span>):</span>
            <span>out_features</span> <span>//=</span> <span>2</span>
            <span>layers</span> <span>+=</span> <span>[</span>
                <span>nn</span><span>.</span><span>Upsample</span><span>(</span><span>scale_factor</span><span>=</span><span>2</span><span>),</span>
                <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_features</span><span>,</span> <span>out_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>stride</span><span>=</span><span>1</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>),</span>
                <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>out_features</span><span>),</span>
                <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
            <span>]</span>
            <span>in_features</span> <span>=</span> <span>out_features</span></pre></div>
            </div>
        </div>
    <div id="section-8">
            <div>
                
                <p>Finally we map the feature map to an RGB image</p>
            </div>
            <div>
                <div><pre>        <span>layers</span> <span>+=</span> <span>[</span><span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>out_features</span><span>,</span> <span>channels</span><span>,</span> <span>7</span><span>,</span> <span>padding</span><span>=</span><span>3</span><span>,</span> <span>padding_mode</span><span>=</span><span>'reflect'</span><span>),</span> <span>nn</span><span>.</span><span>Tanh</span><span>()]</span></pre></div>
            </div>
        </div>
    <div id="section-9">
            <div>
                
                <p>Create a sequential module with the layers</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>layers</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span><span>*</span><span>layers</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-10">
            <div>
                
                <p>Initialize weights to $\mathcal{N}(0, 0.2)$</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>apply</span><span>(</span><span>weights_init_normal</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-11">
            
            <div>
                <div><pre>    <span>def</span> <span>__call__</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
        <span>return</span> <span>self</span><span>.</span><span>layers</span><span>(</span><span>x</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-12">
        <div>
                
                <p>This is the residual block, with two convolution layers.</p>
            </div>
            <div>
                <div><pre><span>class</span> <span>ResidualBlock</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-13">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>in_features</span><span>:</span> <span>int</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>block</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_features</span><span>,</span> <span>in_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>,</span> <span>padding_mode</span><span>=</span><span>'reflect'</span><span>),</span>
            <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>in_features</span><span>),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
            <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_features</span><span>,</span> <span>in_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>,</span> <span>padding_mode</span><span>=</span><span>'reflect'</span><span>),</span>
            <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>in_features</span><span>),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
        <span>)</span></pre></div>
            </div>
        </div>
    <div id="section-14">
            
            <div>
                <div><pre>    <span>def</span> <span>__call__</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span>
        <span>return</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>block</span><span>(</span><span>x</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-15">
        <div>
                
                <p>This is the discriminator.</p>
            </div>
            <div>
                <div><pre><span>class</span> <span>Discriminator</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-16">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>input_shape</span><span>:</span> <span>Tuple</span><span>[</span><span>int</span><span>,</span> <span>int</span><span>,</span> <span>int</span><span>]):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>channels</span><span>,</span> <span>height</span><span>,</span> <span>width</span> <span>=</span> <span>input_shape</span></pre></div>
            </div>
        </div>
    <div id="section-17">
            <div>
                
                <p>Output of the discriminator is also map of probabilities*
whether each region of the image is real or generated</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>output_shape</span> <span>=</span> <span>(</span><span>1</span><span>,</span> <span>height</span> <span>//</span> <span>2</span> <span>**</span> <span>4</span><span>,</span> <span>width</span> <span>//</span> <span>2</span> <span>**</span> <span>4</span><span>)</span>

        <span>self</span><span>.</span><span>layers</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span></pre></div>
            </div>
        </div>
    <div id="section-18">
            <div>
                
                <p>Each of these blocks will shrink the height and width by a factor of 2</p>
            </div>
            <div>
                <div><pre>            <span>DiscriminatorBlock</span><span>(</span><span>channels</span><span>,</span> <span>64</span><span>,</span> <span>normalize</span><span>=</span><span>False</span><span>),</span>
            <span>DiscriminatorBlock</span><span>(</span><span>64</span><span>,</span> <span>128</span><span>),</span>
            <span>DiscriminatorBlock</span><span>(</span><span>128</span><span>,</span> <span>256</span><span>),</span>
            <span>DiscriminatorBlock</span><span>(</span><span>256</span><span>,</span> <span>512</span><span>),</span></pre></div>
            </div>
        </div>
    <div id="section-19">
            <div>
                
                <p>Zero pad on top and left to keep the output height and width same
with the $4 \times 4$ kernel</p>
            </div>
            <div>
                <div><pre>            <span>nn</span><span>.</span><span>ZeroPad2d</span><span>((</span><span>1</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>)),</span>
            <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>512</span><span>,</span> <span>1</span><span>,</span> <span>kernel_size</span><span>=</span><span>4</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>)</span>
        <span>)</span></pre></div>
            </div>
        </div>
    <div id="section-20">
            <div>
                
                <p>Initialize weights to $\mathcal{N}(0, 0.2)$</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>apply</span><span>(</span><span>weights_init_normal</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-21">
            
            <div>
                <div><pre>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>img</span><span>):</span>
        <span>return</span> <span>self</span><span>.</span><span>layers</span><span>(</span><span>img</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-22">
        <div>
                
                <p>This is the discriminator block module.
It does a convolution, an optional normalization, and a leaky relu.</p>
<p>It shrinks the height and width of the input feature map by half.</p>
            </div>
            <div>
                <div><pre><span>class</span> <span>DiscriminatorBlock</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-23">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>in_filters</span><span>:</span> <span>int</span><span>,</span> <span>out_filters</span><span>:</span> <span>int</span><span>,</span> <span>normalize</span><span>:</span> <span>bool</span> <span>=</span> <span>True</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>layers</span> <span>=</span> <span>[</span><span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_filters</span><span>,</span> <span>out_filters</span><span>,</span> <span>kernel_size</span><span>=</span><span>4</span><span>,</span> <span>stride</span><span>=</span><span>2</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>)]</span>
        <span>if</span> <span>normalize</span><span>:</span>
            <span>layers</span><span>.</span><span>append</span><span>(</span><span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>out_filters</span><span>))</span>
        <span>layers</span><span>.</span><span>append</span><span>(</span><span>nn</span><span>.</span><span>LeakyReLU</span><span>(</span><span>0.2</span><span>,</span> <span>inplace</span><span>=</span><span>True</span><span>))</span>
        <span>self</span><span>.</span><span>layers</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span><span>*</span><span>layers</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-24">
            
            <div>
                <div><pre>    <span>def</span> <span>__call__</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span>
        <span>return</span> <span>self</span><span>.</span><span>layers</span><span>(</span><span>x</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-25">
        <div>
                
                <p>Initialize convolution layer weights to $\mathcal{N}(0, 0.2)$</p>
            </div>
            <div>
                <div><pre><span>def</span> <span>weights_init_normal</span><span>(</span><span>m</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-26">
            
            <div>
                <div><pre>    <span>classname</span> <span>=</span> <span>m</span><span>.</span><span>__class__</span><span>.</span><span>__name__</span>
    <span>if</span> <span>classname</span><span>.</span><span>find</span><span>(</span><span>"Conv"</span><span>)</span> <span>!=</span> <span>-</span><span>1</span><span>:</span>
        <span>torch</span><span>.</span><span>nn</span><span>.</span><span>init</span><span>.</span><span>normal_</span><span>(</span><span>m</span><span>.</span><span>weight</span><span>.</span><span>data</span><span>,</span> <span>0.0</span><span>,</span> <span>0.02</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-27">
        <div>
                
                <p>Loads an image and change to RGB if in grey-scale.</p>
            </div>
            <div>
                <div><pre><span>def</span> <span>load_image</span><span>(</span><span>path</span><span>:</span> <span>str</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-28">
            
            <div>
                <div><pre>    <span>image</span> <span>=</span> <span>Image</span><span>.</span><span>open</span><span>(</span><span>path</span><span>)</span>
    <span>if</span> <span>image</span><span>.</span><span>mode</span> <span>!=</span> <span>'RGB'</span><span>:</span>
        <span>image</span> <span>=</span> <span>Image</span><span>.</span><span>new</span><span>(</span><span>"RGB"</span><span>,</span> <span>image</span><span>.</span><span>size</span><span>)</span><span>.</span><span>paste</span><span>(</span><span>image</span><span>)</span>

    <span>return</span> <span>image</span></pre></div>
            </div>
        </div>
    <div id="section-29">
        
            <div>
                <div><pre><span>class</span> <span>ImageDataset</span><span>(</span><span>Dataset</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-30">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>root</span><span>:</span> <span>PurePath</span><span>,</span> <span>transforms_</span><span>,</span> <span>unaligned</span><span>:</span> <span>bool</span><span>,</span> <span>mode</span><span>:</span> <span>str</span><span>):</span>
        <span>root</span> <span>=</span> <span>Path</span><span>(</span><span>root</span><span>)</span>
        <span>self</span><span>.</span><span>transform</span> <span>=</span> <span>transforms</span><span>.</span><span>Compose</span><span>(</span><span>transforms_</span><span>)</span>
        <span>self</span><span>.</span><span>unaligned</span> <span>=</span> <span>unaligned</span>

        <span>self</span><span>.</span><span>files_a</span> <span>=</span> <span>sorted</span><span>(</span><span>str</span><span>(</span><span>f</span><span>)</span> <span>for</span> <span>f</span> <span>in</span> <span>(</span><span>root</span> <span>/</span> <span>f</span><span>'</span><span>{mode}</span><span>A'</span><span>)</span><span>.</span><span>iterdir</span><span>())</span>
        <span>self</span><span>.</span><span>files_b</span> <span>=</span> <span>sorted</span><span>(</span><span>str</span><span>(</span><span>f</span><span>)</span> <span>for</span> <span>f</span> <span>in</span> <span>(</span><span>root</span> <span>/</span> <span>f</span><span>'</span><span>{mode}</span><span>B'</span><span>)</span><span>.</span><span>iterdir</span><span>())</span></pre></div>
            </div>
        </div>
    <div id="section-31">
            
            <div>
                <div><pre>    <span>def</span> <span>__getitem__</span><span>(</span><span>self</span><span>,</span> <span>index</span><span>):</span>
        <span>return</span> <span>{</span><span>"x"</span><span>:</span> <span>self</span><span>.</span><span>transform</span><span>(</span><span>load_image</span><span>(</span><span>self</span><span>.</span><span>files_a</span><span>[</span><span>index</span> <span>%</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>files_a</span><span>)])),</span>
                <span>"y"</span><span>:</span> <span>self</span><span>.</span><span>transform</span><span>(</span><span>load_image</span><span>(</span><span>self</span><span>.</span><span>files_b</span><span>[</span><span>index</span> <span>%</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>files_b</span><span>)]))}</span></pre></div>
            </div>
        </div>
    <div id="section-32">
            
            <div>
                <div><pre>    <span>def</span> <span>__len__</span><span>(</span><span>self</span><span>):</span>
        <span>return</span> <span>max</span><span>(</span><span>len</span><span>(</span><span>self</span><span>.</span><span>files_a</span><span>),</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>files_b</span><span>))</span></pre></div>
            </div>
        </div>
    <div id="section-33">
        <div>
                
                <p>Replay buffer is used to train the discriminator.
Generated images are added to the replay buffer and sampled from it.</p>
<p>The replay buffer returns the newly added image with a probability of $0.5$.
Otherwise it sends an older generated image and and replaces the older image
with the new generated image.</p>
<p>This is done to reduce model oscillation.</p>
            </div>
            
        </div>
    <div id="section-34">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>max_size</span><span>:</span> <span>int</span> <span>=</span> <span>50</span><span>):</span>
        <span>self</span><span>.</span><span>max_size</span> <span>=</span> <span>max_size</span>
        <span>self</span><span>.</span><span>data</span> <span>=</span> <span>[]</span></pre></div>
            </div>
        </div>
    <div id="section-35">
            
            <div>
                <div><pre>    <span>def</span> <span>push_and_pop</span><span>(</span><span>self</span><span>,</span> <span>data</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-36">
            
            <div>
              …</div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lab-ml.com/labml_nn/gan/cycle_gan.html">http://lab-ml.com/labml_nn/gan/cycle_gan.html</a></em></p>]]>
            </description>
            <link>http://lab-ml.com/labml_nn/gan/cycle_gan.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639803</guid>
            <pubDate>Wed, 30 Sep 2020 15:32:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ideas from My Development Setup: Always Tmux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24639599">thread link</a>) | @ceda_ei
<br/>
September 30, 2020 | https://cedaei.com/posts/ideas-from-my-dev-setup-always-tmux/ | <a href="https://web.archive.org/web/*/https://cedaei.com/posts/ideas-from-my-dev-setup-always-tmux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Back when I first learnt tmux, I realized it was a really valuable tool. Soon
afterwards, I found myself in need of wanting to make a split only to find out
I wasn’t in tmux. This would lead to:</p>
<ul>
<li>Killing the running process.</li>
<li>Starting tmux.</li>
<li>Restarting the previous process.</li>
</ul>
<p>In pursuit of an ideal solution, I added a tiny script in my scripts directory
which was called by my bashrc.</p>
<h2 id="current-workflow">Current Workflow<a href="#current-workflow" arialabel="Anchor">⌗</a> </h2>
<p>My current workflow simply starts by opening the terminal. Instead of the bash
prompt, I am greeted by this.</p>
<pre><code>Choose the terminal to attach:
1 - 12: 3 windows (created Wed Sep 30 14:26:37 2020) (attached)
2 - tana: 3 windows (created Wed Sep 30 18:17:24 2020) (attached)
3 - userbot: 1 windows (created Tue Sep 29 18:37:19 2020)
4 - ytc: 1 windows (created Tue Sep 29 18:37:19 2020)

Create a new session by entering a name for it
</code></pre><p>At this point, I either</p>
<ul>
<li>enter a number (in this case from 1 to 4) to connect to an existing session.</li>
<li>enter a name to create a named tmux session.</li>
<li>hit enter (or C-D) to create an unnamed session (tmux will name it
sequentially).</li>
<li>type nil and hit enter to drop to shell without starting tmux</li>
</ul>
<h2 id="implementation">Implementation<a href="#implementation" arialabel="Anchor">⌗</a> </h2>
<p>In my <code>.bashrc</code>, live these lines.</p>
<div><pre><code data-lang="bash"><span>if</span> <span>[[</span> ! -v TMUX <span>&amp;&amp;</span> $TERM_PROGRAM !<span>=</span> <span>"vscode"</span> <span>]]</span>; <span>then</span>
	tmux_chooser <span>&amp;&amp;</span> exit
<span>fi</span>
</code></pre></div><p>Although I use vim as my sole editor, I needed to demo something in VSCode and
for that case I have added an exception so that the script does not run the
<code>tmux_chooser</code> in VSCode’s integrated terminal.</p>
<p>Here is the source of <code>tmux_chooser</code> called above.</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/bash
</span><span></span><span># shellcheck disable=SC2207</span>

<span># Doesn't let you press Ctrl-C</span>
<span>function</span> ctrl_c<span>()</span> <span>{</span>
	echo -e <span>"\renter nil to drop to normal prompt"</span>
<span>}</span>

trap ctrl_c SIGINT

no_of_terminals<span>=</span><span>$(</span>tmux list-sessions | wc -l<span>)</span>
IFS<span>=</span><span>$'\n'</span>
output<span>=(</span><span>$(</span>tmux list-sessions<span>)</span><span>)</span>
output_names<span>=(</span><span>$(</span>tmux list-sessions -F<span>\#</span>S<span>)</span><span>)</span>
k<span>=</span><span>1</span>
echo <span>"Choose the terminal to attach: "</span>
<span>for</span> i in <span>"</span><span>${</span>output[@]<span>}</span><span>"</span>; <span>do</span>
	echo <span>"</span>$k<span> - </span>$i<span>"</span>
	<span>((</span>k++<span>))</span>
<span>done</span>
echo
echo <span>"Create a new session by entering a name for it"</span>
read -r input
<span>if</span> <span>[[</span> $input <span>==</span> <span>""</span> <span>]]</span>; <span>then</span>
	tmux new-session
<span>elif</span> <span>[[</span> $input <span>==</span> <span>'nil'</span> <span>]]</span>; <span>then</span>
	exit <span>1</span>
<span>elif</span> <span>[[</span> $input <span>=</span>~ ^<span>[</span>0-9<span>]</span>+$ <span>]]</span> <span>&amp;&amp;</span> <span>[[</span> $input -le $no_of_terminals <span>]]</span>; <span>then</span>
	terminal_name<span>=</span><span>"</span><span>${</span>output_names[input - 1]<span>}</span><span>"</span>
	tmux attach -t <span>"</span>$terminal_name<span>"</span>
<span>else</span>
	tmux new-session -s <span>"</span>$input<span>"</span>
<span>fi</span>
exit <span>0</span>
</code></pre></div>
      </div></div></div>]]>
            </description>
            <link>https://cedaei.com/posts/ideas-from-my-dev-setup-always-tmux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639599</guid>
            <pubDate>Wed, 30 Sep 2020 15:16:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Beginner's Guide to Arguing Constructively]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24639504">thread link</a>) | @liamrosen
<br/>
September 30, 2020 | http://liamrosen.com/arguments.html | <a href="https://web.archive.org/web/*/http://liamrosen.com/arguments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div><p><span>First published September 2020</span></p><p>

<em>Questions? Suggestions? E-mail me:</em>&nbsp;<img alt="" height="22" src="http://liamrosen.com/liamrosen.png" title="" width="164"></p></div>

<h2>CONTENTS</h2>

<p><a href="#intro">PART I: INTRO</a><br>
<a href="#mindset">PART II: MINDSET</a><br>
<a href="#prework">PART III: PRE-WORK</a><br>
<a href="#debatebreakdown">PART IV: BREAKING DOWN A DEBATE</a><br>
<a href="#strategies">PART V: STRATEGIES</a><br>
<a href="#tips">PART VI: TIPS</a><br>
<a href="#thanks">PART VII: CONCLUSION</a></p>

<h2><a id="intro" name="intro">INTRO</a></h2>

<p>The vast majority of people on earth argue in a <em>destructive </em>fashion. Debates, especially in online spaces, are viewed as a battle of the wits in which egos are put on display and there can be only one "winner".</p>

<p>Instead, we should be arguing in a <em>constructive </em>fashion: treating arguments as an opportunity to expand knowledge, finding points of disagreement, and collaborating towards a common truth.</p>

<p>I have a confession to make: I used to be a destructive arguer. When I was younger, my goal in any argument was not to learn something new, but rather to assure my superiority over what I felt to be the clear stupidity of the other side. I even used to save screenshots of debates I had on various forums and social media platforms, returning periodically to reminisce about past skirmishes in which I "<a href="https://knowyourmeme.com/memes/trigger-the-libs">owned the conservatives</a>".</p>

<p>Luckily, several years spent abroad gave me a different perspective. I realized that in the small-sided debates I used to engage in back home, my positions lacked the nuance and context of the greater world. For the first time, I began to do deep research on how to think — and argue — &nbsp;more clearly, drawing from concepts from philosophy, psychology, and behavioral economics.</p>

<p>This widened outlook led me to see arguments as a chance to build value, rather than destroy it. Instead of going through the mental anguish of battle, I now follow a collaborative approach to debate that I'd like to share in this guide in hopes that it will inspire others to argue more constructively.</p>

<p>Note that the content in this guide will focus on arguments about public issues, like politics and religion, as opposed to personal issues, like "you need to communicate more" or "you haven't done the dishes in weeks". Though there is overlap between the two, interpersonal arguments are much more complex and require more nuance than this guide can provide, plus there are already a ton of great resources out there that explore these topics more thoroughly.</p>

<h2><a id="mindset" name="mindset">MINDSET</a></h2>

<blockquote>
<p><strong><span><em>&nbsp;"An argument should be a collaboration between two people to find the truth."</em></span></strong></p>
</blockquote>

<p>If I had to distill this guide down to one sentence, it would be the above. Even if you forget the individual tenets and strategies this guide has to offer, as long as you are treating any given argument as a collaboration in search of truth, you can't go wrong.</p>

<p>Arguing more effectively requires detaching yourself from the idea of "winning" in the traditional sense. Instead, you should declare victory when you have argued in good faith and kept an open mind.</p>

<p>True collaboration requires that both parties open an investigation into why they may be wrong and consider changing their beliefs. Which brings us to the three core tenets of a constructive debate mindset:</p>

<h3>Acknowledge You May Be Wrong, and Be Willing to Change Your Mind <a href="#Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" id="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" name="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Was there ever a time in which you had a deeply-held belief about something, but slowly came to realize that you were wrong? Maybe you thought a past partner was "the one", or you were devoted to a religious faith. Or perhaps something as simple as believing in Santa Claus.</p>

<p>What's to say that couldn't happen with the rest of your deeply-held beliefs, given enough evidence?</p>

<p>Go into every debate with the mindset that you may not know everything about the topic at hand, and in fact <em>may be wrong</em>.</p>

<p>If you successfully acknowledge that you may be wrong, it follows that you must then be willing to change your mind. Having the humility to admit that your mind has been changed is one of the most honorable positions in a good faith debate.</p>

<h3>Arguments Are Not Soldiers <a href="#Arguments Are Not Soldiers" id="Arguments Are Not Soldiers" name="Arguments Are Not Soldiers"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In a war, all soldiers take an oath to fight for their own side, no matter what amount they agree with its principles. <a href="https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer">Eliezer Yudkowsky once observed</a> that in political debates, arguments were treated like soldiers: "<em>Once you know which side you're on, you must support all arguments of that side, and attack all arguments that appear to favor the enemy side; otherwise it's like stabbing your soldiers in the back.</em>"</p>

<p>Because most people go into debate with a war-like mentality, they feel they must fly the flag for all points that <em>their</em><em> side</em> supports, regardless of how much they actually agree with them.</p>

<p>The red state gun-owner must be pro-religion, anti-abortion, anti-drugs, anti-tax, and skeptical of gender issues.</p>

<p>The blue state Subaru-owner must be anti-religion, pro-abortion, pro-drugs, pro-tax(ing-the-rich), and concerned about gender issues.</p>

<p>Most annoying is that given the societal expectations for this divide, being for or against one issue immediately assigns you to a "side" in the views of everyone involved. Breaking out of this Arguments as Soldiers mindset involves two steps:</p>

<p>1. Do not be afraid to agree with the arguments of the other side when they strike you as reasonable, and critique the arguments of your own side when they strike you as unreasonable (better yet, try not to have a side).</p>

<p>2. On the flip side, avoid stereotyping your debate partner based on one opinion. If you are engaging with someone in debate for the first time, assume that they agree with you on every other position than the one they are defending, until proven otherwise.</p>

<h3>There's Always Someone Who Thinks the Jedi Are Evil <a href="#There's Always Someone Who Thinks the Jedi Are Evil" id="There's Always Someone Who Thinks the Jedi Are Evil" name="There's Always Someone Who Thinks the Jedi Are Evil"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p><em>Brace yourself, Star Wars references incoming:</em></p>

<p>In a given debate, almost everyone thinks they are a member of the Jedi order, fighting for all that is virtuous and good in the universe. Yet for every Jedi, there's a Sith out there <a href="http://www.youtube.com/watch?v=llLKar19XhA">who thinks that the Jedi are evil</a> and wrong and that <em>they</em> are actually the ones fighting for virtue and good. Remember that this person might even be <em>you</em>.</p>

<p>Of course, you are not a full agent of good, and your debate partner is not an agent of evil, or vice versa. You are simply citizens of the galaxy who happen to be operating with different sets of information. Look at the situation from a different perspective: if you were raised with Sith beliefs from childhood, don't you think you might believe the exact same things a Sith would?</p>

<p>In debate, your goal should not be to <a href="https://www.youtube.com/watch?v=rMNKwZTv1d0">strike down the side of evil with all your hatred</a>, but rather work together with them to uncover the true facts about the universe, and in doing so perhaps change both your perspectives.</p>

<h2><a id="mindset" name="prework">PRE-WORK</a></h2>

<p>It would be great if choosing to pursue the path of arguing constructively was just a matter of changing your mindset overnight, but as Carl Sagan once said: <a href="https://youtu.be/BkHCO8f2TWs?t=9">"If you wish to bake an apple pie from scratch, you must first invent the universe."</a></p>

<p>In the same vein, if you wish to improve the constructiveness of the debates you engage in, you must first spend time re-inventing your entire mind.</p>

<p>This is because our mind is constantly working against us, plagued by ancient errors from the times in which we lived in caves and hunted woolly mammoths. These errors work against us in the form of cognitive biases and logical fallacies, which hinder our ability to clearly see reality and engage in sound debate.</p>

<h3>Recognize and Avoid Cognitive Biases <a href="#Recognize and Avoid Cognitive Biases" id="Recognize and Avoid Cognitive Biases" name="Recognize and Avoid Cognitive Biases"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Cognitive biases are limits and mistakes in human judgement that prevent someone from acting rationally. They are present in every aspect of human life, and in tense situations like arguments, they tend to appear more often as emotions are heightened and the brain gets overloaded.</p>

<p>Common examples that relate to debates are <em>confirmation bias</em>, or the tendency of humans to seek out information that confirms existing beliefs, and <em>ingroup bias</em>, or the tendency to agree more strongly with people that appear to be part of our "tribe", but there are over 100 identified biases, and it's worth reading through the Wikipedia article on the <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">most common cognitive biases</a> so you can recognize when they might be clouding your thinking.</p>

<h3>Recognize and Avoid Logical Fallacies <a href="#Recognize and Avoid Logical Fallacies" id="Recognize and Avoid Logical Fallacies" name="Recognize and Avoid Logical Fallacies"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In part caused by cognitive biases, logical fallacies are errors in argument that give off an air of decisiveness, despite making points that don't hold up to logical scrutiny. While these are often used unintentionally, due to bias, carelessness, or ignorance, unfortunately, they can also be wielded intentionally by a shrewd debate partner.</p>

<p>Common examples in debate include the <em>false dilemma fallacy</em>: "you're either with us or against us", and the <em>slippery slope fallacy</em>: "if we allow the gays to marry, what's next: plants?" Just like cognitive biases, there are a large number of identified logical fallacies, and it's worth it to review the <a href="https://en.wikipedia.org/wiki/List_of_fallacies">entire list</a>, so you can spot them in your own arguments and in those of others.</p>

<h2><a id="debatebreakdown" name="debatebreakdown">BREAKING DOWN A DEBATE</a></h2>

<p>To the untrained eye, a debate might look like two or more parties trading argumentative points back and forth. But interestingly, these points can almost perfectly be classified into a few categories. Understanding these categories, and why some types of arguments are better than others, is crucial for learning how we and those whom we engage with in debate might shape their points. In a brilliant post called <em><a href="https://slatestarcodex.com/2018/05/08/varieties-of-argumentative-experience/">Varieties of Argumentative Experience</a></em>, Scott Alexander does just this, illuminating and labeling practically every part of a debate. The post itself is basically required reading, but is long-ish<em>,</em> so I will summarize here.</p>

<p>Think of a debate as a pyramid: <a href="#debatepyramid" id="debatepyramid" name="debatepyramid"><img alt="" src="http://liamrosen.com/anchor.png"></a></p>

<p><img alt="" height="548" src="http://liamrosen.com/Pyramid%20of%20Argumentative%20Experience.svg" width="978"></p>

<p>In general, the lower on the pyramid you are, the worse debate you're having. The goal should be to start as high as possible and continue to work your way towards the top.</p>

<p>Debates on twitter and other forms of social media are almost guaranteed to never rise above the lower dotted line, as these platform don't allow for more nuanced debate. Everything above the higher dotted line is our gold standard: two intelligent, charitable, and versed debaters can successfully maintain a debate at this level until some form of resolution.</p>

<p>The blue side represents the discussion …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://liamrosen.com/arguments.html">http://liamrosen.com/arguments.html</a></em></p>]]>
            </description>
            <link>http://liamrosen.com/arguments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639504</guid>
            <pubDate>Wed, 30 Sep 2020 15:08:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personality Does Not Define Success]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24639493">thread link</a>) | @tmatthe
<br/>
September 30, 2020 | https://tiffanymatthe.com/personality-success | <a href="https://web.archive.org/web/*/https://tiffanymatthe.com/personality-success">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>30.09.2020</time> — <a href="https://tiffanymatthe.com/tags/success">Success</a> — <span>2<!-- --> min read</span></p><section><img src="https://tiffanymatthe.com/static/5e02aed394b5a39a819f8367c9cd4555/a6c62/personality-success.jpg"><p>Tim Cook <a href="https://poy.time.com/2012/12/19/runner-up-tim-cook-the-technologist/">wakes up at 3:45 am</a>. Yoshiro Nakamatsu <a href="https://web.archive.org/web/20120330154757/http://www.whatagreatidea.com/nakamatsu.htm">dives underwater for the best ideas</a>. Marissa Mayer <a href="https://www.reuters.com/article/us-yahoo-hiring-idUSBRE92B06R20130312">personally approves every hire</a>. These quirky habits of successful people are plastered throughout the internet, often lauded as the golden tickets to success.</p><p>This is as true as Oompa-Loompas. Habits and routines affect people differently, and they cannot exist by themselves. You could wake up at 3:45 am and do nothing of your day. You could dive underwater and come up with amazing ideas but never invent anything . You could approve every hire but have a weak business vision.</p><p>Similarly, personality does not define success.</p><p>Steve Jobs was known to be extremely harsh towards his employees if something wasn't up to his standards. This anecdote does not mean you need to be ruthless to be as successful as him. You could emulate all of his personality traits, but end up nowhere.</p><p>Although self-focused and competitive people seem to meet their goals more (<a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886917305962">at least for men</a>), they are more prone to be <a href="https://www.tandfonline.com/doi/abs/10.1080/02678370903282600?journalCode=twst20">less resilient in the workplace</a> and alienate those around them.</p><p>On the other hand, some may believe that being nice does not lead to anywhere either. You feel cheap, easy to please, relatable, the exact opposite of the elite successful class. And there is some truth to this. According to <a href="https://journals.sagepub.com/doi/abs/10.1177/001979391106400509">a study in the UK</a>, they found that there exists at least a weak "negative linear relationship between wages and agreeableness".</p><p>Agreeable people sacrifice their own success for others. They are passive in conflict. However, they also contribute to psychological safety, which is the most important dynamic of Google's <a href="https://rework.withgoogle.com/blog/five-keys-to-a-successful-google-team/">five keys to a successful team</a>.</p><p><strong>All personality traits have multiple facets that can be advantageous or detrimental to success.</strong> The difference between Steve Jobs and a regular grumpy manager is what their personality is built on. Is it built on a skillful person with a passion for their work? Or is it built on a hollow husk with no direction?</p><p>A house's external façade can play a big role in attracting buyers, but in the end, the prospective residents will be living inside. If it's ugly or empty, nothing will ever happen. The effectiveness of a personality is not self-contained. It depends on your passions, your skills, context, luck, etc.</p><p>You can change your personality to push you towards your goals, but remember that it is not the defining factor of success.</p></section></div></div>]]>
            </description>
            <link>https://tiffanymatthe.com/personality-success</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639493</guid>
            <pubDate>Wed, 30 Sep 2020 15:07:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Skill Stacking]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24639304">thread link</a>) | @mcrittenden
<br/>
September 30, 2020 | https://critter.blog/2020/09/30/skill-stacking/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/30/skill-stacking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-825">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Scott Adams, the creator of Dilbert, <a href="https://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html">wrote</a> about how to reach the top:</p>



<blockquote><p>If you want something extraordinary, you have two paths:</p><p>1. Become the best at one specific thing.<br>2. Become good (top 25%) at two or more things.</p><cite>Scott Adams (<a href="https://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html">source</a>)</cite></blockquote>



<p>Number one, he says, is as good as impossible but number two is easy. </p>



<p>It’s called <strong>Skill Stacking</strong>. I went down the rabbit hole and found <a href="https://forge.medium.com/how-to-become-the-best-in-the-world-at-something-f1b658f93428">this excellent post</a> with this image:</p>



<figure><img data-attachment-id="1710" data-permalink="https://critter.blog/stackiing/" data-orig-file="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png" data-orig-size="1400,787" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="stackiing" data-image-description="" data-medium-file="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=300" data-large-file="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=580" src="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=1024" alt="" srcset="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=1024 1024w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=150 150w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=300 300w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=768 768w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>See that little fella in the middle there? That’s the sweet spot. </p>



<p>I will never be the best in the world at running or programming or writing or agile process. But I can be in the top 25% of each. If I can find a way to combine two or more of them, then I can be the best at that combination. </p>



<p>I could build an audiobook reader app specifically for runners. I could create a niche blog for programmers who run. I could apply for Strava’s engineering team. I could write a book on how to apply agile principles to running. </p>



<p>Here’s another example, plucked from a random Hacker News comment:</p>



<blockquote><p>I learned this lesson from Clifford Stoll. He said that astronomers figure he must be an exceptional programmer, since he’s clearly a mediocre astronomer. While programmers figure he must be an exceptional astronomer, since his programming is strictly middle-of-the-road!</p><cite><a href="https://news.ycombinator.com/item?id=24263882">samatman on HN</a></cite></blockquote>



<p>Of course, there are different types of skills. You’ll have trouble combining some skills, but others are universal. Public speaking, writing, marketing, programming, charisma; these can stack with almost anything. Scott Adams says this about public speaking:</p>



<blockquote><p>I always advise young people to become good public speakers (top 25%). Anyone can do it with practice. If you add that talent to any other, suddenly you’re the boss of the people who have only one skill.</p><cite>Scott Adams</cite></blockquote>



<p>It’s a fun thought experiment. List the things you’re pretty good at, and brainstorm ways to combine 2 or more of them. What do you come up with?</p>



		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/30/skill-stacking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639304</guid>
            <pubDate>Wed, 30 Sep 2020 14:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Coinbase post was 100% right. Here's what you can do about it]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24638995">thread link</a>) | @ihm
<br/>
September 30, 2020 | https://parametricity.com/posts/2020-power/ | <a href="https://web.archive.org/web/*/https://parametricity.com/posts/2020-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Recently there was a minor controversy over a blogpost from Coinbase’s <a href="https://blog.coinbase.com/coinbase-is-a-mission-focused-company-af882df8804">CEO</a>
discouraging employees from thinking about politics, and encouraging them to focus on profit-making.
I really appreciated this post, because I think it can be very clarifying for those employees who think their
company can be a pure force for good. The Coinbase blogpost gives the honest truth that in the final calculus,
corporations whose primary goal is profit-maximization can only incidentally and in small ways advance any other
aim.</p>
<p>At the same time, there is a lot of promise for good in the actual technology underlying the crypto industry. This post will argue</p>
<ol>
<li><strong>If work is organized through for-profit corporations, there will be strong pressure from management and capital to
distort positive aspects of the technology in favor of profit-making</strong></li>
<li>The <strong>naive utopianism</strong> which has sustained the industry so far and helped produce some good technology <strong>is no match for this pressure</strong></li>
<li><strong>The only realistic way to combat this</strong> distorting pressure and focus on the socially-beneficial aspects of the technology <strong>is for workers</strong>
(the other human factor of production apart from management and capitalists) <strong>to use their collective power to push back</strong>.</li>
</ol>
<p>This argument is not surprisingly somewhat controversial among executives and VCs, but happily that same group loves
free speech and hates cancel-culture, so I assume I will not be attacked for expressing it.</p>
<h2 id="what-is-the-web-and-what-should-it-be">What is the web and what should it be?</h2>
<p>What should the web be? It should be a medium for personal communication, organization for people in projects, art and creative expression, etc. that is oriented around the goals of individual and collective flourishing. That would be ideal.</p>
<p>In reality, it is not operated that way. It – like almost everything in our society – is operated as a profit-extraction machine in the service of a small group of people.
This machine started off performing the above functions (of course, already distorted by its origins as a technology for the military and academia).
Soon, an industry of for-profit companies sprung up around developing the internet. Many of these companies became large enough to have a decisive influence on what the web would be.</p>
<p>As the years went by, the parts of it that did not contribute much to profit generation (like weird personal websites) were scrapped under the influence of these companies,
and new pieces which enhanced profit generation were added. It happened this way because there is enormous pressure from management and investors to focus on profit-generation
to the exclusion of all else.</p>
<p>Of course, because these modifications were made primarily in pursuit of profit with other reasons being secondary, this resulted in a bunch of unintended (or un-“cared about”) negative consequences like</p>
<ul>
<li>creepy data-collection and surveillance which is used to manipulate us into buying things</li>
<li>right-wing radicalization which has resulted in widespread political violence</li>
<li>distribution of misinformation</li>
<li>an enormous carbon footprint</li>
<li>collective billions in wasted minutes spent scrolling because we were tricked by the algorithm to stay on just a bit longer</li>
</ul>
<p>All of these things are natural results of a system that cannot “see” the concept of social good and can only see profits.
These problems just do not matter to the system, and only could in the event that they interfered with profit-generation.</p>
<h2 id="how-to-push-back">How to push back</h2>
<p>Let’s say you are a worker at a crypto company who sees this history and want to make sure that in crypto, socially useful aspects of
the technology are prioritized rather than those that make the most profit. What should you do?</p>
<p>First, I think it is necessary to deal with the most popular response, which is a utopian faith that the decentralized
nature of some crypto technology will inherently stop bad things from happening.</p>
<h3 id="crypto-utopianism">Crypto-utopianism</h3>
<p>There’s a lot of utopianism in crypto. This ranges from the lowest Bitcoin-booster all the way up to people like Vitalik.</p>
<p>This quote is somewhat <a href="https://www.coindesk.com/this-political-conversation-with-vitalik-buterin-shows-how-ethereum-could-change-the-world">examplary</a>:</p>
<blockquote>
<p>These three white men talked about the protests erupting across the United States. To his credit, the Russian-Canadian Buterin spoke broadly instead of attempting to comment on inequality in American politics. He said the current generation is facing a global “crisis of legitimacy,” concerning both corporations and “many types of governments.”</p>
</blockquote>
<blockquote>
<p>“The challenge here is can we create systems that allow some groups of people to cooperate without that downside of a centralized or trusted actor having to be in the middle,” Buterin said.</p>
</blockquote>
<p>Crypto-utopianism usually includes a suggestion that crypto will replace existing systems (which are bad because they’re “centralized” or some other vague reason) and be better because they are “decentralized” (whatever that might mean).</p>
<p>These analyses give crypto projects a sense of grandeur and importance which is motivating to developers and investors alike. Unfortunately, if your goal is to push back against the existing profit-maximizing power structures, you need to have a better analysis than “centralized bad, decentralized good”. It sounds good, but it doesn’t actually constitute a plan to defeat the Facebooks of the world or even to resist pressure from investors.</p>
<p>The crypto-utopian prescription for all that ails the web is some new technology.
Technology is great and a necessary part of the puzzle, but unless Glenn Weyl has a way of forcing Facebook to use quadratic voting for corporate governance, it’s not useful yet.
<strong>The existing power structure can always pick-and-choose the new technology that best advances its goals.</strong>
If you have goals which are distinct from theirs, you need to build power that is capable of a serious challenge.</p>
<h3 id="what-kind-of-power-do-they-have">What kind of power do they have?</h3>
<p>What kind of power does the existing “power structure” consisting of senior management and capitalists have?
It has</p>
<ul>
<li><a href="https://www.theverge.com/2019/11/25/20983053/google-fires-four-employees-memo-rebecca-rivers-laurence-berland-union-busting-accusation-walkout">the ability to fire people</a> that won’t comply with its goals</li>
<li>the ability to withhold funding from companies that won’t comply with its goals (this is kind of another version of the previous)</li>
<li><a href="https://parametricity.com/posts/2020-power/news.ycombinator.com">public platforms</a> to spread <a href="https://blog.coinbase.com/coinbase-is-a-mission-focused-company-af882df8804">messaging that argues in favor of its goals</a></li>
<li>control of platforms which allows them to <a href="https://itsgoingdown.org/on-facebook-banning-anarchist-and-antifascist-pages-the-digital-censorship-to-come/">censor unfavorable currents in the culture at large</a></li>
<li>endless legal resources to neutralize those that won’t comply with its goals</li>
<li>in some cases, relationships with law enforcement that can be used against those that won’t comply with its goals
and surely much more.</li>
</ul>
<p>Profit-maximization is the “prime directive” of the existing power structure and as a result challenging it inevitably provokes a fight.
This fight is usually waged (on their end) by making use of all the above tools and more.</p>
<h3 id="what-kind-of-power-do-you-have">What kind of power do you have?</h3>
<p>What kind of power do you, a worker at a crypto company, have to resist all of the above? On your own, basically none. If you
make too much trouble, you will simply be fired and then you’re out of luck. Some small number of people can try starting a company (which I have done)
but you’re still subject to some of the same kinds of retaliation as funding can be withheld, which either “fires” the company or redirects
it toward whatever profit-maximization opportunity is available. And even if you have an independent revenue stream, you will be competing
against firms that are willing to do whatever it takes to maximize profits.</p>
<p>As a group however, workers have an enormous amount of power. It is sometimes considered controversial to say so, but VCs and senior
management cannot actually do anything without workers. As such, if workers organize together into a strong company or industry-wide union,
they can make demands of the existing power structure and refuse to participate in the production process (i.e., strike) if those demands are not met.
This power can be augmented with legal resources, platforms of their own, etc.</p>
<p>If you are interested in building power with your fellow workers to advance your own goals rather than those of the profit-maximizers,
both within your company and across your industry, I recommend reaching out to <a href="https://techworkerscoalition.org/">Tech Workers Coalition</a>
who can provide further guidance. You can also get in touch with or <a href="https://act.dsausa.org/donate/membership2020">join your local DSA</a> to
build your analysis, help push more broadly for a world beyond profit maximization, and get support.</p>

		</div></div>]]>
            </description>
            <link>https://parametricity.com/posts/2020-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638995</guid>
            <pubDate>Wed, 30 Sep 2020 14:22:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How real-time stream processing works – a visual guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24638766">thread link</a>) | @rmoff
<br/>
September 30, 2020 | https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><section><div><p><time datetime="2020-09-29T17:50:00.000Z">September 29, 2020</time></p><div><div data-swiftype-name="body" data-swiftype-type="text"><p><a href="http://ksqldb.io/">ksqlDB</a>, the event streaming database, is becoming one of the most popular ways to work with Apache Kafka<sup>®</sup>. Every day, we answer many questions about the project, but here’s a question with an answer that we are always trying to improve: How does ksqlDB work?</p>
<p>The mechanics behind stream processing can be challenging to grasp. The concepts are abstract, and many of them involve motion—two things that are hard for the mind’s eye to visualize. Let’s pop open the hood of ksqlDB to explore its essential concepts, how each works, and how it all relates to Kafka.</p>
<p>If you like, you can follow along by executing the example code yourself. <a href="https://ksqldb.io/quickstart.html">ksqlDB’s quickstart</a> makes it easy to get up and running.</p>
<div>
<h2 id="declaring-a-stream"><a id="declaring-a-stream"></a>Declaring a stream</h2>
<p>Stream processing is a programming paradigm for computing over events as they arrive. But where do those events come from? In Kafka, you store a collection of events in a <em>topic</em>. Each event can contain any raw bytes that you want. In ksqlDB, you store events in a <em>stream</em>. A stream is a topic with a strongly defined schema. You declare it like this:</p>
<pre><code>
CREATE STREAM readings (
    sensor VARCHAR KEY,
    location VARCHAR,
    reading INT
) WITH (
    kafka_topic = 'readings',
    partitions = 3,
    value_format = 'json'
);
</code></pre>
<p>When you fire off this statement from ksqlDB’s client to its server, what actually happens? If the topic that backs this stream doesn’t exist, the server issues a call to the Kafka brokers to make a new topic with the specified number of partitions. The stream metadata, like the column layout, serialization scheme, and other information, is placed into ksqlDB’s command topic, which is its internal cluster communication channel. Each ksqlDB server materializes the command topic information to a local metadata store, giving it a global catalog of objects.</p>
<p>A newly declared stream has no data in it:</p>

</div>
<div>
<h2 id="inserting-rows"><a id="inserting-rows"></a>Inserting rows</h2>
<p>Empty collections aren’t terribly interesting. You need to write events to them to make something happen. In Kafka, you model an event as a <em>record</em> and put it into a topic. In ksqlDB, you model an event as a <em>row</em> and put it into a stream. A row is just a record with additional metadata. You <em>insert</em> rows like this:</p>
<pre><code>
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-1', 'wheel', 45);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-2', 'motor', 41);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-1', 'wheel', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-3', 'muffler', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-3', 'muffler', 40);

INSERT INTO readings (sensor, location, reading) VALUES ('sensor-4', 'motor', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-6', 'muffler', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-5', 'wheel', 41);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-5', 'wheel', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-4', 'motor', 41);

INSERT INTO readings (sensor, location, reading) VALUES ('sensor-7', 'muffler', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-8', 'wheel', 40);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-9', 'motor', 40);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-9', 'motor', 44);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-7', 'muffler', 41);
</code></pre>
<p>Each time you invoke an <code>INSERT</code> statement, a request with the payload is sent to a ksqlDB server. The server checks that the shape of the data is coherent with respect to the stream’s schema—malformed rows are rejected. If the row’s data types are sane, the server creates a record and automatically serializes its content using the format of choice as defined in the stream’s declaration. It uses the Kafka producer client to insert that record into the backing Kafka topic. All of the stream’s data is persisted on directly on the broker. None of it lives in ksqlDB’s servers.</p>
<p>After the inserts complete, the stream now looks like what you see below. Hover over each row to see its contents—the data displayed describes the underlying Kafka record. Notice how the rows are ordered by offset from right to left. In the animations you’ll see below, time is depicted as flowing rightward.</p>

<p>Why does some of the row data end up in the key of the record and some in the value? ksqlDB superimposes a flat column abstraction on top of Kafka’s key/value model. Here’s how it works in this case.</p>
<p>In the declaration of the stream, <code>sensor</code> is qualified with the <code>KEY</code> keyword. That piece of syntax tells ksqlDB to look for the data for this column in the key portion of the record. The data for other columns is read from the record’s value. When ksqlDB produces the record to the underlying topic, its key content is hashed to select a partition for it to reside in. This causes all rows with the same key to be written to the same partition, which is a useful <a href="https://docs.confluent.io/current/kafka/introduction.html#topics-and-logs">ordering guarantee</a>.</p>
</div>
<div>
<h2 id="transforming-a-stream"><a id="transforming-a-stream"></a>Transforming a stream</h2>
<p>No one ever sends data to Kafka just to let it sit there. You always want to do something with it. And most often, the data isn’t yet in the exact form that you need in order to work with it. You need to change it in some way.</p>
<p>The most elementary way you could do this is by writing a program that uses the Kafka producer and consumer clients. The program would read from the source topic whose data you want to change, apply a function to each record, and write the new record to the output topic. It would loop and run forever. This works, but it is rather low-level. You need to manage schemas, serializers, partitioning strategies, and other pieces of configuration.</p>
<p>In ksqlDB, you issue a <em>persistent query</em> to <em>transform</em> one stream into another using its SQL programming model. You derive a new stream from an existing one by selecting and manipulating columns of interest:</p>
<pre><code>
-- process from the beginning of each stream
set 'auto.offset.reset' = 'earliest';
                
CREATE STREAM clean AS
    SELECT sensor,
           reading,
           UCASE(location) AS location
    FROM readings
    EMIT CHANGES;
</code></pre>
<p>Persistent queries are little stream processing programs that run indefinitely. In this case, it continually reads rows from <code>readings</code>, applies the transformation logic, and writes rows to <code>clean</code>. You are relieved of all data janitorial work: There are no schemas to manage, no serializers to configure, no partitioning strategies to choose. But what is actually happening when you launch this query?</p>
<p>Each time you run a persistent query, ksqlDB’s server compiles the query’s textual representation to a physical execution plan as a Kafka Streams topology. The topology runs as a daemon, reacting to new topic records as soon as they become available. This means that all of the processing work happens on ksqlDB server; no processing work happens on the Kafka brokers. If you run ksqlDB as a cluster, the topology scales horizontally across the nodes by internally using Kafka Streams application IDs.</p>
<p>When everything is connected together and the data is flowing, it looks like this. Take it in for a few moments—we’ll walk through it in detail below.</p>

<p>What is going on here? What do the moving arrows mean? Why are those numbers changing? And what is <code>pq1</code>?</p>
<p>When a persistent query is created, it is assigned a generated name (in this case, we call it <code>pq1</code>). Rows are read from the stream partitions that the query selects from. As each row passes through the persistent query, the transformation logic is applied to create a new row, which is what the change of color signifies. Reading a record from Kafka does not delete it—you effectively receive a copy of it. That is why the leftmost rows remain in place, and clones of them appear to the right of each partition before they are sent to the persistent query box.</p>
<p>Persistent queries completely manage their own processing progression, even in the presence of faults. ksqlDB durably maintains the highest offset of each input partition. The incrementing numbers underneath the query box describe those values at each point in time. Moreover, the arrows that move from right to left on the input streams show the corresponding offsets currently being processed, giving you a spatial sense of progress. (If you’re an experienced Kafka user, note that these aren’t the <em>committed</em> offsets.)</p>
<p>Pause the animation and hover over the output rows. Notice how the column that the transformation targets has changed, while all the other columns remain intact. ksqlDB has taken care of all the bookkeeping for you.</p>
<p>As you watch the data flowing through the topology, you might be wondering how ksqlDB chooses which input partition it will read from next. Is it random? Is it round robin? The answer to that question is the foundation of how ksqlDB deals with out-of-order data, and it’s something that we’ll describe in a future blog post all on its own. (Spoiler: <a href="https://www.confluent.io/resources/kafka-summit-2020/the-flux-capacitor-of-kafka-streams-and-ksqldb">It picks the smallest timestamp available</a>.)</p>
</div>
<div>
<h2 id="filtering-rows-out-of-stream"><a id="filtering-rows-out-of-stream"></a>Filtering rows out of a stream</h2>
<p>Let’s look at another simple operation: filtering. Filters are used to discard rows that you do not need or want. Just like transforms, filters are specified using simple SQL syntax.</p>
<pre><code>
CREATE STREAM high_readings AS
    SELECT sensor, reading, location
    FROM clean
    WHERE reading &gt; 41
    EMIT CHANGES;
</code></pre>
<p>When you write ksqlDB programs, you chain streams (and tables) together. You create a figurative pathway for your data to traverse, with each step in the way performing a step of processing. ksqlDB handles the mechanics of how your data is propagated through the chain.</p>

<h2 id="combining-many-operations"><a id="combining-many-operations"></a>Combining many operations into one</h2>
<p>A crucial rule of thumb in data processing is that you should get rid of data that you don’t need as early as possible. The longer you keep irrelevant data around, the higher the cost to repeatedly store, process, and transfer it. If you use the Kafka client to process data, it is up to you to manage where each processing step takes place.</p>
<p>In…</p></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/">https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638766</guid>
            <pubDate>Wed, 30 Sep 2020 13:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Random forest classifier from scratch in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24638370">thread link</a>) | @the_origami_fox
<br/>
September 30, 2020 | https://liorsinai.github.io/coding/2020/09/29/random-forests.html | <a href="https://web.archive.org/web/*/https://liorsinai.github.io/coding/2020/09/29/random-forests.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>

        <p><em>A random forest classifier in 270 lines of Python code. It is written from (almost) scratch. It is modelled on Scikit-Learn’s RandomForestClassifier.</em></p>

<figure>
<img src="https://liorsinai.github.io/assets/posts/random-forests/Random_forest_diagram_complete.png" alt="Simplified random forest">
<figcaption>Simplified random forest classifier (source unknown) </figcaption>
</figure>

<p>I recently learnt about Random Forest Classifiers/Regressors. It is a supervised machine learning technique that performs well on interpolation problems. 
It was formally introduced in 2001 by <a href="https://link.springer.com/article/10.1023/A:1010933404324">Leo Breiman</a>.
They are much easier to train and much smaller than the more modern, but more powerful, neural networks.
They are often included in major machine learning software and libraries, including R and Scikit-learn.</p>

<p>There are many article describing the theory behind random forests. See for example <a href="https://www.kdnuggets.com/2017/10/random-forests-explained.html]">1</a> or <a href="https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76">2</a>. 
By far the best and most detailed explanation I have seen is given by Jeremy Howard in his <a href="https://course18.fast.ai/lessonsml1/lessonsml1.html]">FastAI course</a>.
A few sources describe how to implement them from scratch, such as <a href="https://carbonati.github.io/posts/random-forests-from-scratch/">3</a> or <a href="https://machinelearningmastery.com/implement-random-forest-scratch-python/">4</a>.</p>

<p>My aim here is to describe my own implementation of a random forest from scratch for teaching purposes. It is assumed the reader is already familiar with the theory. 
I hope this post will clarify in-depth questions.
The first version was based on the code in the FastAI course, but I have made it more advanced. The full code can be accessed at my Github <a href="https://github.com/LiorSinai/randomForests">repository</a>. 
The version presented here is slightly simpler and more compact.</p>

<p>Scikit-learn’s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">RandomForestClassifier</a> is far superior to mine. 
It is written in several thousand lines of code; mine was written in just 270.
The main advantages of it are:</p>
<ul>
  <li>it is much faster (by more than 100x) because it is written in Cython, utilises multiple cores to parallelise jobs and also because of more advanced coding optimisation algorithms.</li>
  <li>it has more options and features for the user.</li>
  <li>it does more data validation and input checking.</li>
</ul>

<p>Having been inspired by Jeremy Howard’s teaching methods, I will present this post in a top-down fashion.
First I’ll introduce two datasets and show how the random forest classifier can be used on them.
Next, I’ll explain the top level <code>RandomForestClassifier</code> class, then the <code>DecisionTree</code> class it is composed of, 
and finally the <code>BinaryTree</code> class that that is composed of.
All code is also explained top-down.</p>

<h2 id="practice-data-sets">Practice Data Sets</h2>

<h3 id="the-iris-flower-dataset">The Iris flower dataset</h3>

<p>The <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Iris flower dataset</a> is commonly used for beginner machine learning problems. The full dataset can be found on Kaggle at 
<a href="https://www.kaggle.com/arshid/iris-flower-dataset">www.kaggle.com/arshid/iris-flower-dataset</a>. 
It consists of 150 entries for 3 types of iris plants, and 4 features: sepal length and width, and petal length and width.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>The variable distributions are as follows:</p>
<figure>
<img src="https://liorsinai.github.io/assets/posts/random-forests/Iris_features.png" alt="Feature distributions for the Iris flower dataset">
</figure>

<p>Based on these, a simple baseline model can be developed:</p>
<ol>
  <li>If PetalLength &lt; 2.5cm, class is Setosa.</li>
  <li>Else determine scores score1 and score2 as follows:
	  <ul>
		 <li> score1: add 1 for each of the following that is true:
			 <ul>
			   <li> 2.5cm &lt; PetalLength ≤ 5.0cm </li>
			   <li> 1.0cm≤ PetalWidth ≤ 1.8cm </li>
			 </ul>
		 </li>
		 <li> score2: add 1 for each of the following that is true:
			<ul>
			   <li> 7.0cm≤ SepalLength  </li>
			   <li> 3.5cm≤ SepalWidth  </li>
			   <li> 5.0cm≤ PetalLength  </li>
			   <li> 1.7cm&lt; PetalWidth  </li>
			</ul>
		 </li>
	  </ul>
   </li>
   <li>If score1&nbsp;&gt;&nbsp;score2, classify as Veriscolor. If score1&nbsp;&lt;&nbsp;score2, classify as Virginica. If score1&nbsp;=&nbsp;score2, leave unknown, or classify at random. </li>
</ol>
<p>This simple strategy guarantees that 140 samples, which is 93.3% of the samples, will be correctly classified.</p>

<p>I used my code to make a random forest classifier with the following parameters:</p>

<p><code>forest = RandomForestClassifier(n_trees=10, bootstrap=True, max_features=2, min_samples_leaf=3)</code></p>

<p>I randomly split the data into 120 training samples and 30 test samples.
The forest took 0.23 seconds to train. 
It had trees with depths in the range of 3 to 7, and 65 leaves in total.
It  misclassified one sample in the training and test set each, for an accuracy of 99.2% and 96.7% respectively.
This is a clear improvement on the baseline.</p>

<p>This is a simple  flattened representation of one of the trees. Each successive dash represents a level lower in the tree, and left children come before right:</p>

<figure><pre><code data-lang="python"><span>000</span>  <span>n_samples</span><span>:</span> <span>120</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>43</span><span>,</span> <span>39</span><span>,</span> <span>38</span><span>];</span> <span>impurity</span><span>:</span> <span>0.6657</span><span>;</span> <span>split</span><span>:</span> <span>PetalLength</span><span>&lt;=</span><span>2.450</span>
<span>001</span> <span>-</span> <span>n_samples</span><span>:</span> <span>43</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>43</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>];</span> <span>impurity</span><span>:</span> <span>0.0000</span>
<span>002</span> <span>-</span> <span>n_samples</span><span>:</span> <span>77</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>39</span><span>,</span> <span>38</span><span>];</span> <span>impurity</span><span>:</span> <span>0.4999</span><span>;</span> <span>split</span><span>:</span> <span>PetalLength</span><span>&lt;=</span><span>4.750</span>
<span>003</span> <span>--</span> <span>n_samples</span><span>:</span> <span>34</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>34</span><span>,</span> <span>0</span><span>];</span> <span>impurity</span><span>:</span> <span>0.0000</span>
<span>004</span> <span>--</span> <span>n_samples</span><span>:</span> <span>43</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>5</span><span>,</span> <span>38</span><span>];</span> <span>impurity</span><span>:</span> <span>0.2055</span><span>;</span> <span>split</span><span>:</span> <span>PetalWidth</span><span>&lt;=</span><span>1.750</span>
<span>005</span> <span>---</span> <span>n_samples</span><span>:</span> <span>7</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>4</span><span>,</span> <span>3</span><span>];</span> <span>impurity</span><span>:</span> <span>0.4898</span><span>;</span> <span>split</span><span>:</span> <span>SepalWidth</span><span>&lt;=</span><span>2.650</span>
<span>006</span> <span>----</span> <span>n_samples</span><span>:</span> <span>3</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>];</span> <span>impurity</span><span>:</span> <span>0.4444</span>
<span>007</span> <span>----</span> <span>n_samples</span><span>:</span> <span>4</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>3</span><span>,</span> <span>1</span><span>];</span> <span>impurity</span><span>:</span> <span>0.3750</span>
<span>008</span> <span>---</span> <span>n_samples</span><span>:</span> <span>36</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>35</span><span>];</span> <span>impurity</span><span>:</span> <span>0.0540</span><span>;</span> <span>split</span><span>:</span> <span>SepalLength</span><span>&lt;=</span><span>5.950</span>
<span>009</span> <span>----</span> <span>n_samples</span><span>:</span> <span>5</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>4</span><span>];</span> <span>impurity</span><span>:</span> <span>0.3200</span>
<span>010</span> <span>----</span> <span>n_samples</span><span>:</span> <span>31</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>31</span><span>];</span> <span>impurity</span><span>:</span> <span>0.0000</span></code></pre></figure>

<p>The value is the number of samples in each class in that node. The impurity is a measure of the mix of classes in the node. A pure node has only 1 type of class and 0 impurity.
More will be explained on this later.
The split is the rule for determining which values go to the left or right child.
For example, the first split is almost the same as the first rule in the baseline model.</p>

<h3 id="universal-bank-loans">Universal Bank loans</h3>

<p>The next dataset I tested was the Bank_Loan_Classification dataset available on Kaggle at <a href="http://www.kaggle.com/sriharipramod/bank-loan-classification/">www.kaggle.com/sriharipramod/bank-loan-classification/</a>.
This dataset has 5000 entries with 11 features. The target variable is “Personal Loan”, and it can be 0 or 1. (Personal Loan approved? Or paid? I don’t know.)</p>

<p>The variable distributions are as follows:</p>
<figure>
<img src="https://liorsinai.github.io/assets/posts/random-forests/UniversalBank_features.png" alt="Feature distributions for the Universal Bank loans dataset">
</figure>

<p>The Pearson correlation coefficients between the features and the target variables are:</p>
<table>
<thead>
  <tr>
    <th></th>
    <th>Feature</th>
    <th>Correlation</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>Income</td>
    <td>0.5025</td>
  </tr>
  <tr>
    <td>2</td>
    <td>CCAvg</td>
    <td>0.3669</td>
  </tr>
  <tr>
    <td>3</td>
    <td>CD Account</td>
    <td>0.3164</td>
  </tr>
  <tr>
    <td>4</td>
    <td>Mortgage</td>
    <td>0.1421</td>
  </tr>
  <tr>
    <td>5</td>
    <td>Education</td>
    <td>0.1367</td>
  </tr>
  <tr>
    <td>6</td>
    <td>Family</td>
    <td>0.0614</td>
  </tr>
  <tr>
    <td>7</td>
    <td>Securities Account</td>
    <td>0.0220</td>
  </tr>
  <tr>
    <td>8</td>
    <td>Experience</td>
    <td>-0.0074</td>
  </tr>
  <tr>
    <td>9</td>
    <td>Age</td>
    <td>-0.0077</td>
  </tr>
  <tr>
    <td>10</td>
    <td>Online</td>
    <td>0.0063</td>
  </tr>
  <tr>
    <td>11</td>
    <td>CreditCard</td>
    <td>0.0028</td>
  </tr>
</tbody>
</table>

<p>For the baseline model, we could always predict a 0, and claim an accuracy of 90.4%. 
But this has an F1 score of 0.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> A better baseline is simply to have: 1 if Income&nbsp;&gt;&nbsp;100 else 0. This has an accuracy of 83.52% and a F1 score of  0.516 over the whole dataset.</p>

<p>I used my code to make a random forest classifier with the following parameters:</p>

<p><code>forest = RandomForestClassifier(n_trees=20, bootstrap=True, max_features=3, min_samples_leaf=3)</code></p>

<p>I randomly split the data into 4000 training samples and 1000 test samples and trained the <code>forest</code> on it.
The forest took about 10 seconds to train.
The trees range in depth from 11 to 17, with 51 to 145 leaves. The total number of leaves is 1609.
The training accuracy is 99.60% and the test accuracy is 98.70%. The F1 score for the test set is 0.926.
This is a large improvement on the baseline, especially for the F1 score.</p>

<p>We can inspect the random forest and calculate a feature importance for each feature. The following graph is a comparison between two types of (normalised) feature importances. 
The orange bars are based on how much that feature contributes to decreasing the impurity levels in the tree.
The blue bars are based on randomly scrambling that feature column, and recording how much this decreases the overall accuracy of the model.
More detail on these calculations will be given later.</p>

<figure>
<img src="https://liorsinai.github.io/assets/posts/random-forests/UniversalBank_feature_importances.png" alt="Feature importances for the Universal Bank classifier">
</figure>

<h2 id="code">Code</h2>
<h3 id="randomforestclassifier">RandomForestClassifier</h3>

<p>The first step is create the <code>RandomForestClassifier</code>. Initialising an instance of the class only sets the internal parameters and does not fit the data, 
as with the equivalent Scikit-learn class. I’ve included the most important parameters from Scikit-learn, and added one of my own, <code>sample_size</code>.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> 
This parameter sets the sample size used to make each tree. If <code>bootstrap=False</code>, it will randomly select a subset of unique samples for the training dataset. 
If <code>bootstrap=True</code>, it will randomly draw samples with replacement from the dataset, which will most likely result in duplicate samples.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>warnings</span>
<span>from</span> <span>DecisionTree</span> <span>import</span> <span>DecisionTree</span>
<span>from</span> <span>utilities</span> <span>import</span> <span>*</span>

<span>class</span> <span>RandomForestClassifier</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>n_trees</span><span>=</span><span>100</span><span>,</span> <span>random_state</span><span>=</span><span>None</span><span>,</span> <span>max_depth</span><span>=</span><span>None</span><span>,</span>  
                 <span>max_features</span><span>=</span><span>None</span><span>,</span> <span>min_samples_leaf</span><span>=</span><span>1</span><span>,</span> <span>sample_size</span><span>=</span><span>None</span><span>,</span> 
                 <span>bootstrap</span><span>=</span><span>True</span><span>,</span>  <span>oob_score</span><span>=</span><span>False</span><span>):</span>
        <span>self</span><span>.</span><span>n_trees</span> <span>=</span> <span>n_trees</span>
        <span>self</span><span>.</span><span>RandomState</span> <span>=</span> <span>check_RandomState</span><span>(</span><span>random_state</span><span>)</span>
        <span>self</span><span>.</span><span>max_depth</span> <span>=</span> <span>max_depth</span>
        <span>self</span><span>.</span><span>max_features</span> <span>=</span> <span>max_features</span>
        <span>self</span><span>.</span><span>min_samples_leaf</span><span>=</span><span>min_samples_leaf</span>
        <span>self</span><span>.</span><span>sample_size</span> <span>=</span> <span>sample_size</span>
        <span>self</span><span>.</span><span>bootstrap</span> <span>=</span> <span>bootstrap</span>
        <span>self</span><span>.</span><span>oob_score</span> <span>=</span> <span>oob_score</span></code></pre></figure>

<p>I’ve shown the imports for two internal modules, <code>DecisionTree</code> which I’ll describe later, and <code>utilities</code>, which imports some useful functions.
Many of those are also part of the Sklearn package; I just wanted my code to be completely independent. 
If you wish to see these, have a look at the Github <a href="https://github.com/LiorSinai/randomForests">repository</a></p>

<p>The supervised learning is done by calling the <code>fit()</code> function. 
First it internally one-hot encodes the target variable <em>Y</em>, which makes it easier to deal with multiple categories.
Then it creates the trees one at a time. 
Most of the heavy lifting is done by other functions. 
Afterwards, it sets attributes including the feature importances and the out-of-bag (OOB) score. 
The random state is saved before each tree is made, because this can be used to exactly regenerate the random indices for the OOB score.
This is much more memory efficient than saving the whole list of random indices for each tree.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>fit</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>,</span> <span>Y</span><span>):</span>
    <span>if</span> <span>Y</span><span>.</span><span>ndim</span> <span>==</span> <span>1</span><span>:</span>
        <span>Y</span> <span>=</span> <span>encode_one_hot</span><span>(</span><span>Y</span><span>)</span> <span># one-hot encoded y variable
</span>
    <span># set internal variables
</span>    <span>self</span><span>.</span><span>n_features</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
    <span>self</span><span>.</span><span>n_classes</span> <span>=</span> <span>Y</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
    <span>self</span><span>.</span><span>features</span> <span>=</span> <span>X</span><span>.</span><span>columns</span>
    <span>n_samples</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>self</span><span>.</span><span>sample_size_</span> <span>=</span> <span>n_samples</span> <span>if</span> <span>self</span><span>.</span><span>sample_size</span> <span>is</span> <span>None</span> <span>else</span> <span>self</span><span>.</span><span>sample_size</span>

    <span># create decision trees
</span>    <span>self</span><span>.</span><span>trees</span> <span>=</span> <span>[]</span>
    <span>rng_states</span> <span>=</span> <span>[]</span> <span># save the random states to regenerate the random indices for the oob_score
</span>    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>self</span><span>.</span><span>n_trees</span><span>):</span>
        <span>rng_states</span><span>.</span><span>append</span><span>(</span><span>self</span><span>.</span><span>RandomState</span><span>.</span><span>get_state</span><span>())</span>
        <span>self</span><span>.</span><span>trees</span><span>.</span><span>append</span><span>(</span><span>self</span><span>.</span><span>_create_tree</span><span>(</span><span>X</span><span>,</span> <span>Y</span><span>))</span>

    <span># set …</span></code></pre></figure></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://liorsinai.github.io/coding/2020/09/29/random-forests.html">https://liorsinai.github.io/coding/2020/09/29/random-forests.html</a></em></p>]]>
            </description>
            <link>https://liorsinai.github.io/coding/2020/09/29/random-forests.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638370</guid>
            <pubDate>Wed, 30 Sep 2020 13:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: We just cracked the problem with sneaker drops and sold out]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24638290">thread link</a>) | @skorski
<br/>
September 30, 2020 | https://gothelist.com/initial-product-offering | <a href="https://web.archive.org/web/*/https://gothelist.com/initial-product-offering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/products.gif" alt="No Waitlist"></p><h2>No Waitlist.</h2>
<h4>Introducing Initial Product Offering</h4>
<p>Get immediate access and shop highly demanded, limited and hard-to-get products without VIP status, waiting list or queue via IPOs in THE LIST App.</p>

</div>
</div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/listed.png" alt="LISTED.">
</p>
<div>
<h2>LISTED.</h2>
<p>We skip the waitlist for you. <br>Highly covetable items, collections &amp; <br>rare, unique products are listed <br>daily at 9:30 AM EST NYC.</p>
</div>
</div>
</div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/includes.gif" alt="MUST-HAVES INCLUDED.">
</p>
<div>
<h2>MUST-HAVES <br>INCLUDED.</h2>
<p>THE LIST App offers you over 1,200 brands, <br>from established luxury brands <br>to the coolest, emerging designer labels.</p>
</div>
</div>
</div>
<div>
<div>
<h2>HOW DOES IT WORK<span>?</span></h2>
<div>
<h2>HOW DOES IT WORK<span>?</span></h2>
<h2>SHOP.</h2>
<p>Purchase a product during an IPO <br>for a limited time period <br>at dynamic market price <br>depending on how demanded <br>a product is. Better be fast!</p>
</div>
<p><img src="https://gothelist.com/media/wysiwyg/how-does-it-works.png" alt="HOW DOES IT WORK?">
</p>
</div>
</div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/pay1.png" alt="PAY.">
</p>
<div>
<h2>PAY.</h2>
<p>Secure your piece fast <br>within the price lockdown. <br>Only pay a deposit when placing the order, <br>and the remaining balance, <br>once the item is ready to ship.</p>
</div>
</div>
</div>
<div>
<div>
<div>
<h2>GET.</h2>
<p>Your order will be directly delivered <br>from the authorized retailer to you <br>via express shipping.</p>
</div>
<p><img src="https://gothelist.com/media/wysiwyg/get1.png" alt="GET.">
</p>
</div>
</div>
<div>
<div>
<h2>What are you waiting for<span>?</span></h2>

</div>
</div>
</div></div>]]>
            </description>
            <link>https://gothelist.com/initial-product-offering</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638290</guid>
            <pubDate>Wed, 30 Sep 2020 13:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revisiting a 'Smaller Rust']]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24638129">thread link</a>) | @gbrown_
<br/>
September 30, 2020 | https://without.boats/blog/revisiting-a-smaller-rust/ | <a href="https://web.archive.org/web/*/https://without.boats/blog/revisiting-a-smaller-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			<p>A bit over a year ago, I wrote some <a href="https://without.boats/blog/notes-on-a-smaller-rust">notes on a “smaller Rust”</a> - a higher level language
that would take inspiration from some of Rust’s type system innovations, but would be simpler by
virtue of targeting a domain with less stringent requirements for user control and performance.
During my time of unemployment this year, I worked on sketching out what a language like that would
look like in a bit more detail. I wanted to write a bit about what new conclusions I’ve come to
during that time.</p>
<h2 id="the-purpose-for-our-language">The purpose for our language</h2>
<p>Re-reading my previous post, I’m struck by how vague my statement of purpose for this language is.
My entire blog post is really focused on differentiating the language from <em>Rust</em>, and I frame the
discussion in terms of what I would remove from Rust, and how the language would not support certain
use cases of Rust. This isn’t really surprising: I was working on Rust, and I never had taken the
time to think of this hypothetical language in itself the way I have now.</p>
<p>The goal of this design was to create a language that could compete as an “application programming
language.” The design goals of this language were:</p>
<ol>
<li>It should try not to be notably hard to learn. To the extent possible, it should be familiar to
most programmers. Since I’m comitting by the exercise to trying to apply ownership and borrowing
to the application domain, it will necessarily contain some features most programmers find
pretty novel (like Rust “lifetimes”). But in general, we will try to reduce the onboarding ramp
and simplify things.</li>
<li>It should typecheck and compile quickly. It should not have bad batch compilation performance,
and it should be designed with incremental recompilation in mind, to enable a good experience for
users who integrate their compiler into their development environment (with a full IDE or even
just with a plugin for a text editor). I didn’t even mention this concern in the previous post.
As others have discussed elsewhere; Rust’s poor compile times are not the result of its advanced
type system, but of a combination of other factors. Some are essential, like the runtime
guarantees it makes (e.g. monomorphization) whereas others are accidental, like some aspects of
its module system. None of these factors would be essential for our language, so we would
carefully avoid these pitfalls.</li>
<li>It should have a runtime which suits it well to the major use cases for application programming
languages today. This means mainly being well suited to the developing for the web, both
front-end and back-end. (Being well-suited to the mobile platforms is unrealistic for a language
not sponsored by those platform developers, unfortunately.) Being well-suited to CLIs would also
be beneficial.</li>
</ol>
<p>I want to focus the rest of this post on my thoughts for evolving Rust’s ownership and borrowing
system, but before I do that I want to briefly touch on other design decisions that fell out of this
thought process:</p>
<ul>
<li>I would target WASM, and only WASM, for this language. WASM with reference types is suitable as
an environment for application programming (with shims for future extensions like properly
integrated garbage collection). This way the language designers can piggy back on the work being
done at many companies to establish WASM as a good shared VM platform, instead of being
responsible for things like platform compatibility or using the very slow LLVM. Targeting WASM
would also mean easier FFI integration into other languages that run on the same VM as WASM; that
is, other languages targeting WASM (like Rust) and JavaScript.</li>
<li>I would explore control-flow-capturing closures as a core language abstraction, similar to Kotlin.
As I wrote in <a href="https://without.boats/blog/the-problem-of-effects">an earlier blog post</a> inspired by the design on this hypothetical
language, I think these are a great way to integrate effects well with higher order function
abstractions.</li>
<li>I would provide syntactic sugar for <code>Result</code> and <code>Option</code> as the way to handle null and errors,
similar to Swift.</li>
<li>As I wrote in a previous blog post, I would provide green threads as the sole concurrency model,
with language or standard library provided channels and cells (discussed later) as the way of
sharing data between threads. How these green threads are mapped to CPUs is a matter for the
runtime you choose to run the compiled WASM in.</li>
<li>I didn’t get to the point of designing a polymorphism system; I would probably start with a
strenuous comparison of Rust’s traits and Go’s interfaces, and (knowing the other features of the
language) try to figure out what from Rust’s traits is unimportant.</li>
<li>I would be hope the language could avoid macros, which (in the case of pattern based macros) add a
second meta language to the language that advanced users need to understand, and in all cases
substantially complicate compilation.</li>
</ul>

<p>But now onto the meat of this post: the ownership and borrowing model. In my previous post I made
some points that I largely agree with still, but would probably reframe. Here’s what I wrote:</p>
<blockquote>
<p>Rust works because it enables users to write in an imperative programming style, which is the
mainstream style of programming that most users are familiar with, while avoiding to an impressive
degree the kinds of bugs that imperative programming is notorious for. As I said once, pure
functional programming is an ingenious trick to show you can code without mutation, but Rust is an
even cleverer trick to show you can just have mutation.</p>
<p>…</p>
<p><strong>Resource acquisition is initialization:</strong> Objects should manage conceptual resources like file
descriptors and sockets, and have destructors which clean up resource state when the object goes
out of scope. It should be trivial to be confident the destructor will run when the object goes
out of scope. This necesitates most of ownership, moving, and borrowing.</p>
<p><strong>Aliasable XOR mutable:</strong> The default should be that values can be mutated only if they are not
aliased, and there should be no way to introduce unsynchronized aliased mutation. However, the
language should support mutating values. The only way to get this is the rest of ownership and
borrowing, the distinction between borrows and mutable borrows and the aliasing rules between
them.</p>
<p>In other words, the core, commonly identified “hard part” of Rust - ownership and borrowing - is
essentially applicable for any attempt to make checking the correctness of an imperative program
tractable. So trying to get rid of it would be missing the real insight of Rust, and not building
on the foundations Rust has laid out.</p>
</blockquote>
<p>I still think this is Rust’s “secret sauce” and it does mean what I said: the language would have to
have ownership and borrowing. But what I’ve realized since is that there’s a very important
distinction between the cases in which users <em>want</em> these semantics and the cases where they largely
get in the way. This distinction is between types which represent <em>resources</em> and types which
represent <em>data</em>.</p>
<p>In this mental model, resources are types which represent “a thing” - something with an identity and
a state which can change with time as the program executes. In Rust, almost everything is a
resource: a String is a resource a HashMap is a resource, most user types are resources. In
contrast, data types are just “information” - a fact, which has no meaningful identity, contains no
state that evolves over time, etc. In Rust, types like integers, <code>&amp;str</code>, and so on - which all
implement <code>Copy</code> - are data types. (However, a mutable reference to those types is a resource: more
on this later.)</p>
<p>In Rust, only types which can be cloned by a mempcy can implement <code>Copy</code>. This is because Rust is
designed to encourage treating all heap memory as a <em>resource</em>, the management of which the end
user can control by selecting when the type representing that memory is dropped. This is very
valuable in the domains which Rust is intended to target. However, for higher level applications
that most programmers write, control over heap memory is not <em>usually</em> important. This is what users
mean when they want to “turn off the borrow checker” - they want to let a garbage collector figure
it out for them when this bit of data is freed, because to them it is “just data” and not a
resource.</p>
<p>This hypothetical language would lean into that distinction. Using persistent data structures (like
those from Clojure) and garbage collection, the set of types which could be treated as data types
would not be restricted in this language. The string type would be a data type, rather than
a resource; a dynamically sized array of data types would be a data type as well, as would a map
with keys and values that are data types.</p>
<p>Meanwhile, types representing IO objects would always be resource types. Collections containing
resource types would also be resource types. Composite types (like structs and enums) which contain
a resource type would also have to be a resource type. There would be an easy way to convert data
types to fully owned resource types as well; in the case of persistent data structures, converting
a data type to a resource type would be the point at which the “copy on write” operation occurs.
As a result users can use ownership semantics for things which impact global and external state
(like IO) and for cases where they know it will be an important performance optimization.</p>
<p>And the difference in how the language treats data and resources would be identical to the
difference between how Rust treats Copy and non-Copy types. Only resources would have affine
“ownership” semantics - in which moving them invalidates the previous binding. Data types would have
the standard non-linear semantics users are familiar with from most languages. This means that
writing algorithms using data types would be functionally the same as writing algorithms in other
imperative languages, easing the onboarding of users to the language and limiting their errors
related to linear types to areas where they are certain to care.</p>
<h2 id="borrowing-and-the-two-reference-types">Borrowing and the two reference types</h2>
<p>The previous discussion covers the ground of …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://without.boats/blog/revisiting-a-smaller-rust/">https://without.boats/blog/revisiting-a-smaller-rust/</a></em></p>]]>
            </description>
            <link>https://without.boats/blog/revisiting-a-smaller-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638129</guid>
            <pubDate>Wed, 30 Sep 2020 12:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Hidden Costs from a DevOps Perspective]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637836">thread link</a>) | @gimmecoffee
<br/>
September 30, 2020 | https://pushbuildtestdeploy.com/on-hidden-costs-and-the-value-of-devops/ | <a href="https://web.archive.org/web/*/https://pushbuildtestdeploy.com/on-hidden-costs-and-the-value-of-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p><img src="https://pushbuildtestdeploy.com/images/hidden-cost-devops.png" alt=""></p>

<p>When you think about cost in the DevOps world, the first thing that will come to mind is your AWS bill, or maybe that Datadog subscription. However, the cost is not always as straightforward as receiving an invoice, and in the DevOps world, the hidden cost is about doing it wrong.</p>

<p>I believe that being aware of hidden costs is a “mental model” you can use when making decisions. Without taking it to account, you are making bets with only half of the information.</p>

<p>Hidden cost takes on many forms in DevOps:</p>

<ul>
<li>Idle developers are waiting for builds to finish.</li>
<li>Over architected Jira workflows that take forever to go through - Jireaucracy (not my term).</li>
<li>Automating things that don’t need to scale - we are all lazy engineers who would rather spend a full day scripting something than doing 5 minutes of manual work.</li>
<li>Trying to save cost where there is no real benefit.</li>
<li>Higher Churn Rate.</li>
<li>Technical debt.</li>
</ul>

<p>Let’s try to take a close look at some of these examples.</p>

<h3 id="not-accounting-for-the-human-element">Not accounting for the human element</h3>

<p>In these complicated days, companies are franticly working to reduce their cloud costs. However, there’s a trap that you need to be mindful of when going through such a process.</p>

<p>Let’s look at this oversimplified equation.</p>

<blockquote>
<p><strong>$100</strong> <em>(hourly cost of a developer)</em> <strong>x</strong> <strong>10</strong> <em>(developers)</em> <strong>x</strong> <strong>2</strong> <em>(idle hours a day)</em> <strong>x</strong> <strong>21</strong> <em>(work days in a month)</em> <strong>=</strong> <strong>$42,000</strong></p>
</blockquote>

<p>If, on average, a developer at a company waits on builds or deployment for two hours per day and there are 10 developers on the team, that’s <strong>$2,000/</strong> per day going down the drain. Multiply by 21 workdays per month, and you get <strong>$42,000</strong> of wasted developer time.</p>

<p>Now, suppose that you can cut the idle time by half by adding two new build workers, where each one costs $3000/month. Is it worth it?
It seems trivial when you present it this way but harder to consider when cutting costs across the board.</p>

<p>The problem is that employees are a “fixed cost”, a different budget, and you don’t think of them in the context of wasted resources.</p>

<p>Now think about that developer idling for two hours a day. An idle engineer is a bored engineer, which leads me to the next point -  chasing away competent engineers, or making it more challenging to attract new ones.</p>

<p>You spend significant resources to keep your top engineers, but then they will be the first to jump ship when work is just not fun.</p>

<p>Team leaders spend much of their time in the recruiting process when the company is growing. Time that could be used for onboarding new employees, or mentoring the team, or doing actual development work.</p>

<p>If it takes weeks for engineers to see their work in production or they spend their time chasing the DevOps team to get a simple thing running, they will not stay for long. And worse, you will start getting a bad reputation, resulting in fewer hiring options.</p>

<p>Add burnout to the mix, and now your top developers are producing less, which trickles down to more jr. engineers. You are now stuck with a disgruntled team and no new hires on the horizon.</p>

<h3 id="trying-to-automate-and-scale-at-all-cost">Trying to automate and scale at all cost</h3>

<p>Here is another example that I see all the time - A belief that everything has to be automated and scalable.</p>

<p>“Write this script to automate task XYZ, and don’t forget to document everything and make sure it’s IaC and write a confluence page and…”
But do you really need to automate it? How much time does this task take, and how many times are you planning to perform it?</p>

<p>If it’s an annoying task that takes an hour to perform, and you expect to repeat it three times in the future, does it justify a full week of an engineer to automate?</p>

<p>What about a deployment that is pretty much a one-off? Do you really need to automate it fully? Is it worth your time? Isn’t there something else that is more meaningful for you to do?</p>

<p>I mean, yes, we have standards and workflows and beliefs, but we don’t have to follow them blindly when it doesn’t make sense.</p>

<h3 id="technical-debt">Technical Debt</h3>

<p>Managers who brush off the importance of technical debt are a bit like people who never back up their system. They never saw how technical debt could cripple a company.</p>

<p>If you don’t account for the effects of technical debt, it’s hard to see the cost, but by looking closely, you will soon see how much it affects your velocity, churn, and pretty much every aspect of the value you deliver:</p>

<ol>
<li>It slows down your developers.</li>
<li>Each feature takes twice as much time to complete.</li>
<li>The system keeps crashing.</li>
<li>It burns out your team members.</li>
<li>It makes some business decisions impossible.</li>
</ol>

<p>Think about credit card debt. At one point, the interest rates will make you go bankrupt.
Yes, fixing some of the issues takes time and resources, but can you afford to continue rolling the snowball?</p>

<h2 id="opportunity-cost">Opportunity cost</h2>

<p>In a previous example, I referred to the cost “as is,” using the developer’s direct hourly cost.  But unless you are a service business, a developer hour is worth much more than the cost.</p>

<p>This is why software companies are worth so much - The Developer’s time is a force multiplier. Developers are adding value to the company that is much higher than their yearly cost. The value they add takes the the form of IP and products that you can sell over and over without scaling inventory and distribution.</p>

<p>If we go back to the previous example, if you instead have the developers work on a new product or initiative with those hours, it’s not $42k per month that you are losing, but giving up a much higher future revenue.</p>

<p>And of course, opportunity cost can take on other forms that may not be as intuitive:</p>

<h3 id="milestone-investing">Milestone Investing</h3>

<p>Suppose that you are an early startup that has raised capital with set milestones (<a href="https://avc.com/2009/08/milestone-based-investing/">Milestone Investing</a>). By hitting the next milestone, you will increase your valuation and get a hefty cash infusion.
Now imagine your runway running out, and you have yet to meet the milestone.</p>

<p>Wouldn’t it be great if you had more time to reach your goals?</p>

<p>Suppose that your developers worked much more efficiently. Instead of idling for two hours, automating and simplifying your developers’ workflow added an hour a day of “working in the zone” for each developer.</p>

<p>How much more could you accomplish by having three more hours a day per developer?</p>

<p>Could you meet that arbitrary board goal with an impossible deadline they set for you?</p>

<p>Is it going to help you meet the milestone the investors set for receiving the next cash infusion?</p>

<p>That’s where we, the DevOps engineers (or whatever you call this function at your company), can help move the needle. We can facilitate growth and improve the productivity of our engineering teams.
It’s not just about throwing new technology at the solution and implementing the latest fad.</p>

<h2 id="so-how-can-we-produce-value-as-devops-engineers">So how can we produce Value as DevOps engineers?</h2>

<p>DevOps has always been tied to business value, but it’s rare to see this idea fully implemented in corporate culture.
Even when it does, it’s usually wrapped around a vague user story with a soggy and generic statement that doesn’t make any sense.</p>

<blockquote>
<p><em>“This feature will increase user happiness and deliver more value by making the top navigation bar a bit more blueish.”</em></p>
</blockquote>

<p>One way to create value is by addressing the cost - by reversing it, we can generate value. All you need is to look at it from a different perspective.</p>

<p>I mentioned Churn before as a metric that the business is actively working to reduce, but for engineers, it’s just “downtime.” Engineers are seldomly exposed to the idea that lowering Churn increases customer lifetime value and affects customer acquisition cost.</p>

<p>So put your DevOps cap on for a minute. Can you think of ways to reduce the churn rate?</p>

<ul>
<li>Reduce downtime.</li>
<li>Reduce latency and load speed.</li>
<li>Optimize report generation time.</li>
<li>Increase email deliverability.</li>
<li>Enable toggle features to allow your product team to test their new features on users.</li>
</ul>

<p>The list goes on, and it’s just for reducing Churn.
And yes, these are obvious priorities for operations, but now you have a clear business value tied to it.</p>

<p>Almost every hidden cost I mentioned earlier could turn into a value proposition for a DevOps related project.</p>

<h2 id="make-sure-you-have-all-the-data">Make sure you have all the data</h2>

<p>All of this “Cost” and “Value” talk is almost meaningless or non-actionable if you don’t have metrics in place.</p>

<ul>
<li>You need to have a cloud provider cost breakdown to know how much you’re spending on a project or a server.</li>
<li>Build time statistics.</li>
<li>Build and deployment success rate over time.<br></li>
<li>How long it takes to onboard a new developer to the team.</li>
</ul>

<p>You need the metrics for three reasons:</p>

<ol>
<li>Visibility - You need to be aware of the cost in the first place.</li>
<li>When making a decision, you have to have a benchmark.</li>
<li>To see the impact of your actions when working to reduce the cost.</li>
</ol>

<p>You can’t make informed decisions without having all the data; otherwise, it’s just guessing.</p>



<p>Ask yourself the following questions:</p>

<ol>
<li>Do we really need to scale this?</li>
<li>How much time will it take to reduce a cost? What can your developers do instead?</li>
<li>How can you improve the development workflow? How much time can you save?</li>
<li>Do we have a culture that allows open discussion? Do engineers have a voice when it comes to new projects and features?</li>
<li>How can we share knowledge across the organization, so engineers are aware of the product, sales, and marketing struggles?</li>
</ol>

    </div></div>]]>
            </description>
            <link>https://pushbuildtestdeploy.com/on-hidden-costs-and-the-value-of-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637836</guid>
            <pubDate>Wed, 30 Sep 2020 12:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ruby One-Liners Cookbook]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24637797">thread link</a>) | @asicsp
<br/>
September 30, 2020 | https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>This chapter will give an overview of <code>ruby</code> syntax for command line usage and some examples to show what kind of problems are typically suited for one-liners.</p>
<h2><a href="#why-use-ruby-for-one-liners" id="why-use-ruby-for-one-liners">Why use Ruby for one-liners?</a></h2>
<p>I assume you are already familiar with use cases where command line is more productive compared to GUI. See also this series of articles titled <a href="https://sanctum.geek.nz/arabesque/series/unix-as-ide/">Unix as IDE</a>.</p>
<p>A shell utility like <code>bash</code> provides built-in commands and scripting features to make it easier to solve and automate various tasks. External *nix commands like <code>grep</code>, <code>sed</code>, <code>awk</code>, <code>sort</code>, <code>find</code>, <code>parallel</code> etc can be combined to work with each other. Depending upon your familiarity with those tools, you can either use <code>ruby</code> as a single replacement or complement them for specific use cases.</p>
<p>Here's some one-liners (options will be explained later):</p>
<ul>
<li><code>ruby -e 'puts readlines.uniq' *.txt</code> — retain only one copy if lines are duplicated from the given list of input file(s)</li>
<li><code>ruby -e 'puts readlines.uniq {|s| s.split[1]}' *.txt</code> — retain only first copy of duplicate lines using second field as duplicate criteria</li>
<li><code>ruby -rcommonregex -ne 'puts CommonRegex.get_links($_)' *.md</code> — extract only the URLs, using a third-party <a href="https://github.com/talyssonoc/CommonRegexRuby">CommonRegexRuby</a> library</li>
<li><a href="https://stackoverflow.com/questions/63954081/bash-remove-duplicate-of-key-values-with-preserving-order">stackoverflow: merge duplicate key values while preserving order</a> — a recent Q&amp;A that I answered with a simpler <code>ruby</code> solution compared to <code>awk</code></li>
</ul>
<p>The main advantage of <code>ruby</code> over tools like <code>grep</code>, <code>sed</code> and <code>awk</code> includes feature rich regular expression engine, standard library and third-party libraries. If you don't already know the syntax and idioms for <code>sed</code> and <code>awk</code>, learning command line options for <code>ruby</code> would be the easier option. The main disadvantage is that <code>ruby</code> is likely to be slower compared to those tools.</p>
<h2><a href="#command-line-options" id="command-line-options">Command line options</a></h2>
<table><thead><tr><th><strong>Option</strong></th><th><strong>Description</strong></th></tr></thead><tbody>
<tr><td><code>-0[octal]</code></td><td>specify record separator (<code>\0</code>, if no argument)</td></tr>
<tr><td><code>-a</code></td><td>autosplit mode with <code>-n</code> or <code>-p</code> (splits <code>$_</code> into <code>$F</code>)</td></tr>
<tr><td><code>-c</code></td><td>check syntax only</td></tr>
<tr><td><code>-Cdirectory</code></td><td>cd to directory before executing your script</td></tr>
<tr><td><code>-d</code></td><td>set debugging flags (set <code>$DEBUG</code> to true)</td></tr>
<tr><td><code>-e 'command'</code></td><td>one line of script. Several <code>-e</code>'s allowed. Omit [programfile]</td></tr>
<tr><td><code>-Eex[:in]</code></td><td>specify the default external and internal character encodings</td></tr>
<tr><td><code>-Fpattern</code></td><td><code>split()</code> pattern for autosplit (<code>-a</code>)</td></tr>
<tr><td><code>-i[extension]</code></td><td>edit <code>ARGV</code> files in place (make backup if extension supplied)</td></tr>
<tr><td><code>-Idirectory</code></td><td>specify <code>$LOAD_PATH</code> directory (may be used more than once)</td></tr>
<tr><td><code>-l</code></td><td>enable line ending processing</td></tr>
<tr><td><code>-n</code></td><td>assume <code>'while gets(); ... end'</code> loop around your script</td></tr>
<tr><td><code>-p</code></td><td>assume loop like <code>-n</code> but print line also like <code>sed</code></td></tr>
<tr><td><code>-rlibrary</code></td><td>require the library before executing your script</td></tr>
<tr><td><code>-s</code></td><td>enable some switch parsing for switches after script name</td></tr>
<tr><td><code>-S</code></td><td>look for the script using PATH environment variable</td></tr>
<tr><td><code>-v</code></td><td>print the version number, then turn on verbose mode</td></tr>
<tr><td><code>-w</code></td><td>turn warnings on for your script</td></tr>
<tr><td><code>-W[level=2|:category]</code></td><td>set warning level; 0=silence, 1=medium, 2=verbose</td></tr>
<tr><td><code>-x[directory]</code></td><td>strip off text before #!ruby line and perhaps cd to directory</td></tr>
<tr><td><code>--jit</code></td><td>enable JIT with default options (experimental)</td></tr>
<tr><td><code>--jit-[option]</code></td><td>enable JIT with an option (experimental)</td></tr>
<tr><td><code>-h</code></td><td>show this message, <code>--help</code> for more info</td></tr>
</tbody></table>
<p>This chapter will show examples with <code>-e</code>, <code>-n</code>, <code>-p</code> and <code>-a</code> options. Some more options will be covered in later chapters, but not all of them are discussed in this book.</p>
<h2><a href="#executing-ruby-code" id="executing-ruby-code">Executing Ruby code</a></h2>
<p>If you want to execute a <code>ruby</code> program file, one way is to pass the filename as argument to the <code>ruby</code> command.</p>
<pre><code>$ echo 'puts "Hello Ruby"' &gt; hello.rb
$ ruby hello.rb
Hello Ruby
</code></pre>
<p>For short programs, you can also directly pass the code as an argument to the <code>-e</code> option.</p>
<pre><code>$ ruby -e 'puts "Hello Ruby"'
Hello Ruby

$ # multiple statements can be issued separated by ;
$ ruby -e 'x=25; y=12; puts x**y'
59604644775390625
$ # or use -e option multiple times
$ ruby -e 'x=25' -e 'y=12' -e 'puts x**y'
59604644775390625
</code></pre>
<h2><a href="#filtering" id="filtering">Filtering</a></h2>
<p><code>ruby</code> one-liners can be used for filtering lines matched by a regexp, similar to <code>grep</code>, <code>sed</code> and <code>awk</code>. And similar to many command line utilities, <code>ruby</code> can accept input from both <code>stdin</code> and file arguments.</p>
<pre><code>$ # sample stdin data
$ printf 'gate\napple\nwhat\nkite\n'
gate
apple
what
kite

$ # print all lines containing 'at'
$ # same as: grep 'at' and sed -n '/at/p' and awk '/at/'
$ printf 'gate\napple\nwhat\nkite\n' | ruby -ne 'print if /at/'
gate
what

$ # print all lines NOT containing 'e'
$ # same as: grep -v 'e' and sed -n '/e/!p' and awk '!/e/'
$ printf 'gate\napple\nwhat\nkite\n' | ruby -ne 'print if !/e/'
what
</code></pre>
<p>By default, <code>grep</code>, <code>sed</code> and <code>awk</code> will automatically loop over input content line by line (with <code>\n</code> as the line distinguishing character). The <code>-n</code> or <code>-p</code> option will enable this feature for <code>ruby</code>. As seen before, the <code>-e</code> option accepts code as command line argument. Many shortcuts are available to reduce the amount of typing needed.</p>
<p>In the above examples, a regular expression (defined by the pattern between a pair of forward slashes) has been used to filter the input. When the input string isn't specified in a conditional context (for example: <code>if</code>), the test is performed against global variable <code>$_</code>, which has the contents of the input line (the correct term would be input <strong>record</strong>, see <a href="https://learnbyexample.github.io/learn_ruby_oneliners/record-separators.html#record-separators">Record separators</a> chapter). To summarize, in a conditional context:</p>
<ul>
<li><code>/regexp/</code> is a shortcut for <code>$_ =~ /regexp/</code></li>
<li><code>!/regexp/</code> is a shortcut for <code>$_ !~ /regexp/</code></li>
</ul>
<p><code>$_</code> is also the default argument for <code>print</code> method, which is why it is generally preferred in one-liners over <code>puts</code> method. More such defaults that apply to the <code>print</code> method will be discussed later.</p>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> See <a href="https://ruby-doc.org/core-2.7.1/doc/globals_rdoc.html">ruby-doc: Pre-defined global variables</a> for documentation on <code>$_</code>, <code>$&amp;</code>, etc.</p>
</blockquote>
<p>Here's an example with file input instead of <code>stdin</code>.</p>
<pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14

$ # same as: grep -oE '[0-9]+$' table.txt
$ ruby -ne 'puts $&amp; if /\d+$/' table.txt
42
7
14
</code></pre>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> The <a href="https://github.com/learnbyexample/learn_ruby_oneliners/tree/master/example_files">learn_ruby_oneliners repo</a> has all the files used in examples.</p>
</blockquote>
<h2><a href="#substitution" id="substitution">Substitution</a></h2>
<p>Use <code>sub</code> and <code>gsub</code> methods for search and replace requirements. By default, these methods operate on <code>$_</code> when the input string isn't provided. For these examples, <code>-p</code> option is used instead of <code>-n</code> option, so that the value of <code>$_</code> is automatically printed after processing each input line.</p>
<pre><code>$ # for each input line, change only first ':' to '-'
$ # same as: sed 's/:/-/' and awk '{sub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | ruby -pe 'sub(/:/, "-")'
1-2:3:4
a-b:c:d

$ # for each input line, change all ':' to '-'
$ # same as: sed 's/:/-/g' and awk '{gsub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | ruby -pe 'gsub(/:/, "-")'
1-2-3-4
a-b-c-d
</code></pre>
<p>You might wonder how <code>$_</code> is modified without the use of <code>!</code> methods. The reason is that these methods are part of Kernel (see <a href="https://ruby-doc.org/core-2.7.1/Kernel.html">ruby-doc: Kernel</a> for details) and are available only when <code>-n</code> or <code>-p</code> options are used.</p>
<ul>
<li><code>sub(/regexp/, repl)</code> is a shortcut for <code>$_.sub(/regexp/, repl)</code> and <code>$_</code> will be updated if substitution succeeds</li>
<li><code>gsub(/regexp/, repl)</code> is a shortcut for <code>$_.gsub(/regexp/, repl)</code> and <code>$_</code> gets updated if substitution succeeds</li>
</ul>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> This book assumes you are already familiar with regular expressions. If not, you can check out my free <a href="https://learnbyexample.github.io/Ruby_Regexp/">Ruby Regexp</a> book.</p>
</blockquote>
<h2><a href="#field-processing" id="field-processing">Field processing</a></h2>
<p>Consider the sample input file shown below with fields separated by a single space character.</p>
<pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre>
<p>Here's some examples that is based on specific field rather than the entire line. The <code>-a</code> option will cause the input line to be split based on whitespaces and the field contents can be accessed using <code>$F</code> global variable. Leading and trailing whitespaces will be suppressed and won't result in empty fields. More details is discussed in <a href="https://learnbyexample.github.io/learn_ruby_oneliners/field-separators.html#default-field-separation">Default field separation</a> section.</p>
<pre><code>$ # print the second field of each input line
$ # same as: awk '{print $2}' table.txt
$ ruby -ane 'puts $F[1]' table.txt
bread
cake
banana

$ # print lines only if last field is a negative number
$ # same as: awk '$NF&lt;0' table.txt
$ ruby -ane 'print if $F[-1].to_f &lt; 0' table.txt
blue cake mug shirt -7

$ # change 'b' to 'B' only for the first field
$ # same as: awk '{gsub(/b/, "B", $1)} 1' table.txt
$ ruby -ane '$F[0].gsub!(/b/, "B"); puts $F * " "' table.txt
Brown bread mat hair 42
Blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre>
<h2><a href="#begin-and-end" id="begin-and-end">BEGIN and END</a></h2>
<p>You can use a <code>BEGIN{}</code> block when you need to execute something before input is read and a <code>END{}</code> block to execute something after all of the input has been processed.</p>
<pre><code>$ # same as: awk 'BEGIN{print "---"} 1; END{print "%%%"}'
$ # note the use of ; after BEGIN block
$ seq 4 | ruby -pe 'BEGIN{puts "---"}; END{puts "%%%"}'
---
1
2
3
4
%%%
</code></pre>
<h2><a href="#env-hash" id="env-hash">ENV hash</a></h2>
<p>When it comes to automation and scripting, you'd often need to construct commands that can accept input from user, file, output of a shell command, etc. As mentioned before, this book assumes <code>bash</code> as the shell being used. To access environment variables of the shell, you can call the special hash variable <code>ENV</code> with the name of the environment variable as a string key.</p>
<pre><code>$ # existing environment variable
$ # output shown here is for my machine, would differ for you
$ ruby -e 'puts ENV["HOME"]'
/home/learnbyexample
$ ruby -e 'puts ENV["SHELL"]'
/bin/bash

$ # defined along with ruby command
$ # note that the variable is placed before the shell command
$ word='hello' ruby -e 'puts ENV["word"]'
hello
$ # the input characters are preserved as is
$ ip='hi\nbye' ruby -e 'puts ENV["ip"]'
hi\nbye
</code></pre>
<p>Here's another example when a regexp is passed as an environment variable content.</p>
<pre><code>$ cat word_anchors.txt
sub par
spar
apparent effort
two spare computers
cart part tart mart

$ # assume 'r' is a shell variable that has to be passed to the ruby command
$ r='\Bpar\B'
$ rgx="$r" ruby -ne 'print if /#{ENV["rgx"]}/' word_anchors.txt
apparent effort
two spare computers
</code></pre>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> As an example, see my repo <a href="https://github.com/learnbyexample/command_help/blob/master/ch">ch: command help</a> for a practical shell script, where commands are constructed …</p></blockquote></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html">https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html</a></em></p>]]>
            </description>
            <link>https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637797</guid>
            <pubDate>Wed, 30 Sep 2020 11:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making the Monte Hall problem weirder but obvious]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24637787">thread link</a>) | @dyno-might
<br/>
September 30, 2020 | https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        

<div>
    <div>
        <div>
            <p><strong>Sep 17, 2020</strong></p>
            



<p>The <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall problem</a> is famously unintuitive. This post starts with an extreme version where the solution is blindingly obvious. We then go through a series of small changes. It will be clear that these don’t affect the solution. At the end, we arrive at the classic Monte Hall problem.</p>

<p>For reference, the <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">classic formulation</a> goes:</p>

<blockquote>
  <p>Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?” Is it to your advantage to switch your choice?</p>
</blockquote>

<p>Intuitively, many people guess it doesn’t matter if you switch. But it does. You get the car 2/3 of the time if you switch, and 1/3 of the time if you don’t. Why?</p>



<p>Here’s our first game.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game1.png">
</p>

<p>There’s nothing mysterious here. You should choose option B. There’s only a 10% chance you picked the right door, so there’s a 90% chance the car is behind one of the others.</p>



<p>Now, we slightly update the game (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty says “Hey! I promise you that there is a goat behind at least 8 of the other 9 doors!”</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game2.png">
</p>

<p>Monty’s statement changes nothing. You don’t need to rely on his <a href="https://en.wikipedia.org/wiki/Monty_Hall#/media/File:Monty_hall_abc_tv.JPG">trustworthy looks</a>. You already <em>knew</em> there were at least 8 goats! Option B still gets you the car 90% of the time.</p>



<p>Let’s update the game again (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty looks behind the other 9 doors. He chooses 8 with goats behind them, and opens them.</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game3.png">
</p>

<p>The key insight is this: When Monty shows you that 8 of the 9 other doors contain goats, you haven’t learned anything relevant to your decision. You <em>already knew there were at least 8 goats behind the other doors</em>! So this is just like game 2. Option B still gets you the car 90% of the time.</p>

<p>Want more intuition? Suppose you picked door 3. Imagne Monty walking past the doors, opening doors 1, 2, 4, 5, 6, <strong>skipping 7</strong>, then opening 8, 9, and 10. Doesn’t door 7 seem special?</p>



<p>Let’s make another change. Finally, we arrive at a game very similar to Monty Hall.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other 9 doors. He chooses 8 of them with goats behind them, and opens them.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind <strong>the other closed door</strong>.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game4.png">
</p>

<p>The only difference with Game 3 is that option B doesn’t get you the 8 visible goats. Since you don’t care about goats, this makes no difference. This is still just like the game 3. You get the car 90% of the time by switching.</p>



<p>Here is the last game. We just change the number of doors from 10 to 3.</p>

<ol>
  <li>There are <strong>3</strong> doors. A car is randomly placed behind one, and goats behind the other <strong>2</strong>.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other <strong>2</strong> doors. He chooses one <strong>1</strong> of them with a goat behind it, and opens it.**</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind the other closed door.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game5.png">
</p>

<p>Of course, you still want to choose option B. The chance of success is now 2/3 instead of 9/10. This game is exactly Monty Hall, so we’re done.</p>



<ul>
  <li>
    <p>It’s important that Monty looked behind the doors before choosing which to open. This is where people’s intuition usually fails. If he had chosen a door at random — <em>in a way that he risked possibly exposing a car</em>, then the situation would be different. (In that case, there’s no advantage or harm in switching.) But he doesn’t choose the door at random. He deliberately chooses to show you goats. Since this is always possible, it tells you nothing. I think this is the crux of what makes this problem unintuitive. Many people intuitively think it doen’t matter if you switch. And that <em>would be correct</em> if the door had been opened at random!</p>
  </li>
  <li>
    <p>It might be helpful to draw a diagram of the relationship of the different games, starting with classic Monty Hall and ending with the extreme version.</p>
  </li>
</ul>

<blockquote>
  <p>Game 5 (Classic Monty Hall)<br>
 ↓<br>
 ↓ (Use 10 doors instead of 3)<br>
 ↓ <br>
Game 4<br>
 ↓<br>
 ↓ (If you switch, get the contents of <em>all</em> other doors, not just the other closed door.)<br>
 ↓<br>
Game 3<br>
 ↓<br>
 ↓ (Monty promises 8 goats behind the other doors instead of showing you.)<br>
 ↓<br>
Game 2<br>
 ↓<br>
 ↓ (Monty doesn’t bother promsising.)<br>
 ↓<br>
Game 1 (Dyno Might© Monty Hall)</p>
</blockquote>

<ul>
  <li>
    <p>There are <a href="https://marginalrevolution.com/marginalrevolution/2019/09/the-intuitive-monty-hall-problem.html">some</a> <a href="https://twitter.com/jben0/status/1174180200072011776">other</a> <a href="https://statmodeling.stat.columbia.edu/2019/09/19/alternative-more-intuitive-formulation-of-monte-hall-problem/">attempts</a> at <a href="https://math.stackexchange.com/questions/96826/the-monty-hall-problem/3360686#3360686">variants</a> of the Monte Hall problem, also intended to be more intuitive. These involve switching the doors for “boxers”.</p>
  </li>
  <li>
    <p>Monty Hall was actually named “Monte” at birth! Given that <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo simulations</a> are often used for exploring the Monty Hall problem, that’s either a tragedy for puns or a miracle for confused students.</p>
  </li>
</ul>

        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637787</guid>
            <pubDate>Wed, 30 Sep 2020 11:56:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unsupervised Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637758">thread link</a>) | @juanorozcov
<br/>
September 30, 2020 | https://www.brainstobytes.com/unsupervised-learning/ | <a href="https://web.archive.org/web/*/https://www.brainstobytes.com/unsupervised-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<!--kg-card-begin: markdown--><p>In a previous article, we learned about supervised learning: using labeled examples for creating models that solve a variety of tasks such as classification and regression.</p>
<p>There is another type of learning that doesn't require labeled examples: unsupervised learning. As it turns out, unlabeled data is much more common than labeled data. Often, you need to create the labels for the examples yourself, a process that might consume vast amounts of time and resources.</p>
<p>That's ok, lack of labels doesn't mean your data is totally useless. There are lots of machine learning tasks that do not require labeled examples, and you can use unsupervised learning to perform data exploration or to extract useful insights from the data that is readily available right now.</p>
<p>In this article, we will discuss some of the most common applications of unsupervised learning. Let's learn how to use unlabeled data to achieve valuable results.</p>
<h4 id="1associationrulelearning">1. Association rule learning</h4>
<p>Association rule learning/mining is a method for discovering relations between elements in large datasets. A typical example is using it to identify which products are more likely to be purchased together.</p>
<p>Association rule mining is usually used to support cross-selling. This is when companies offer the customer extra products they might have forgotten or don't know about yet. As an example, if you are buying a new guitar and an amplifier, you might also want to buy a cable or new strings.</p>
<p>This is done by algorithms that scan historic transactional information and look for the co-occurrence of items. It will generate a series of rules that model the likelihood of certain items being bought together. Two of the most important values generated by these algorithms are support and confidence.</p>
<ul>
<li><strong>Support</strong> is the ratio of transactions that include the specific set of items against the total number of transactions. It tells you <em>how frequently the set of items occur together</em>. For example, if {guitar, amplifier, cable} have a support value of 2%, it means that 2% of all purchases include all 3 items.</li>
<li><strong>Confidence</strong> is a measure of how likely it is that Z will be bought if we are already buying A. It is defined as the ratio between the transactions that include Z and A against all the ones that included A. A confidence of 30% between guitar and amplifier means that 30% of the customers who bought a guitar also bought an amplifier.</li>
</ul>
<p>These algorithms can generate massive amounts of rules and not all of them are useful. Often, only rules with high values of support and confidence are allowed to stay, the rest are discarded.</p>
<p>Physical stores can use this information to group items together to promote purchases, and online stores can offer you items at checkout-time and even provide some discounts for specific items. It is known that demographical information about customers increases the effectiveness of these algorithms, so most shops offer loyalty cards with discounts in exchange for your data.</p>
<h4 id="2segmentation">2. Segmentation</h4>
<p>Segmentation is one of the most useful data science techniques. It aims to group the elements of a dataset into subgroups that have characteristics in common. While the task is not that difficult in a 2d plane, sets with lots of attributes make it impossible for a human to accomplish this task. By leveraging data science you can find some useful and counterintuitive groups in data.</p>
<p>Segmentation can dramatically improve the effectiveness of marketing campaigns. Instead of sending the same campaign to everyone, you could create segments of users and target them with only the information they need. You can even create specialized campaigns aimed at different subgroups. This has two upsides: first, you don't bother people with offerings they don't care about. Second, it lets you save money and increase the success of campaigns by focusing the resources were you have the most chances to succeed.</p>
<p>Machines are much better at uncovering unknown subsets in data than humans are. After they have created segments, a human expert can inspect the set to ensure they make sense.</p>
<p>This technique transcends beyond marketing and has a wide array of applications, ranging from identifying gene sequences to patterns in population groups, ecosystems and documents.</p>
<p><img src="https://www.brainstobytes.com/content/images/2020/01/Segmentation.png" alt="Segmentation"></p>
<h4 id="3outlierdetection">3. Outlier detection</h4>
<p>Outlier detection is in some way the opposite of segmentation. In segmentation, you want to create groups containing only similar elements, in outlier detection you want to separate the instances that are different from the rest. The goal of outlier detection is to find anomalies or special cases within our dataset.</p>
<p>This can be achieved in 3 ways:</p>
<ul>
<li>Create two big clusters of data using segmentation. Typical cases will be grouped together and outliers will be the elements out of the group.</li>
<li>Measure the distance between each element and the center of the data. Anomalies will usually be the ones farther away from the group.</li>
<li>Train a classification model to divide instances into two groups. This is difficult because you need (as you remember) training data for the classifier, and outliers are by definition rare, representing just a small portion of the training set. This affects the performance of many types of classifiers.</li>
</ul>
<p>Outlier detection is used by financial institutions to identify fraudulent transactions or other forms of fraudulent behavior. It can also be used to detect malicious network activity or attacks on software systems.</p>
<p><img src="https://www.brainstobytes.com/content/images/2020/01/OutlierDetection.png" alt="OutlierDetection"></p>
<h2 id="unlabeleddataispowerful">Unlabeled data is powerful</h2>
<p>Unsupervised learning is a very powerful idea with lots of applications. Part of this power derives from being able to make use of the most common type of data available: unlabeled examples. We explored 3 common applications, but it doesn't mean those are the only things you can do with unsupervised learning. It's also possible to build classification and regression models!</p>
<p>For building a classifier, you could use a clustering algorithm (like k-means clustering) to discover natural segments in your data. After that, you could compute the distance between a new example and the centroids (among many other possibilities) to classify it in any of the clusters. Using a similar idea you can build a regression model: you could calculate the similarity between a new example and a specific number of data points in your data. After finding the data points with the most similarities with your new example, you can use their aggregated attributes to extrapolate the target value of the new example.</p>
<p>You can also use supervised learning to assist the process of creating a new data solution. A common first task when dealing with machine learning problems is using clustering and outlier detection to discover underlying patterns or clean your datasets from noise.</p>
<p>No matter what you choose, becoming familiar with this set of techniques and ideas will be very useful in your career as a data scientist.</p>
<p>Thank you for reading!</p>
<h2 id="whattodonext">What to do next</h2>
<ul>
<li>Share this article with friends and colleagues. Thank you for helping me reach people who might find this information useful.</li>
<li>This article is based on Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking. This and other very helpful books can be found in the <a href="https://www.brainstobytes.com/recommended-books/">recommended reading list</a>.</li>
<li>Send me an email with questions, comments or suggestions (it's in the <a href="https://www.brainstobytes.com/about">About Me page</a>)</li>
</ul>
<!--kg-card-end: markdown-->
					</div></div>]]>
            </description>
            <link>https://www.brainstobytes.com/unsupervised-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637758</guid>
            <pubDate>Wed, 30 Sep 2020 11:51:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotify’s Failed Squad Goals]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24637656">thread link</a>) | @cocoflunchy
<br/>
September 30, 2020 | https://www.jeremiahlee.com/posts/failed-squad-goals/?repost | <a href="https://web.archive.org/web/*/https://www.jeremiahlee.com/posts/failed-squad-goals/?repost">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<!-- Spread 1 -->
<section>
<section>
<video autoplay="true" muted="true" loop="true">
<source srcset="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" media="(prefers-reduced-motion: reduce)">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" alt="Taylor Swift and her squad walking away from an explosion in front of the Spotify office at Birger Jarlsgatan.">
</video>
</section>
<section>
<div>

<p><b>Spotify</b> doesn’t use <em>“the Spotify model”</em><br>and neither should you.</p>
<p>By Jeremiah Lee</p>
<p>Sunday, April 19, 2020 • <a href="https://anchor.fm/jeremiah-oral-lee/episodes/Spotifys-Failed-SquadGoals-edia0p">Listen</a> •&nbsp;<a href="https://oyomy.fr/2020/04/l-echec-du-modele-spotify/" hreflang="fr">En français</a> •&nbsp;<a href="https://jp.quora.com/q/agile/Spotify%E3%81%AF-Spotify%E3%83%A2%E3%83%87%E3%83%AB-%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84" hreflang="ja">日本語で</a> • <a href="https://flavioclesio.com/2020/05/18/o-modelo-de-squadgoals-do-spotify-falhou/" hreflang="pt-br">Português (Brasil)</a></p>
</div>
</section>
</section>
<!-- Spread 2 -->
<section>
<section>
<div>
<p>Of all the allures of startup culture, few are more desireable than the speed and nimbleness of a small team. Maintaining that feeling as a company grows is a challenge. In 2012, Spotify shared its way of working and suggested it had figured it out.<sup><a href="#1">1</a></sup></p>
<p>I was excited to see <em>the Spotify model</em> in action when I interviewed for a product management role at its Stockholm headquarters in 2017. However, the recruiter surprised me before the first interview. She cautioned me to not expect Spotify to be an <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile</a> utopia.</p>
<p>I joined the company after it had tripled in size to 3,000 people over 18 months. I learned the famed squad model was only ever aspirational and never fully implemented. I witnessed organizational chaos as the company’s leaders incrementally transitioned to more traditional management structures.</p>
<p>When I asked my coworkers why the content was not removed or updated to reflect reality, I never got a good answer. Many people ironically thought the posts were great for recruiting. I no longer work at Spotify, so I am sharing my experience to set the record straight. The Spotify squad model failed Spotify and it will fail your company too.</p>
</div>
</section>
<section>
<div>
<h3>But you don’t have to take my word for it.</h3>
<p>The co-author of the Spotify model<sup><a href="#2">2</a></sup> and multiple agile coaches who worked at Spotify have been telling people to not copy it for years. Unfortunately, truth doesn’t spread as quickly or as widely as an idea people want to believe in.</p>
<blockquote>
<p>“Even at the time we wrote it, we weren’t doing it. It was part ambition, part approximation. People have really struggled to copy something that didn’t really exist.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify&nbsp;2011–2017<sup><a href="#4">4</a></sup></p>
<blockquote>
<p><em>“It worries me when people look at what we do and think it’s a framework they can just copy and implement.</em> … We are really trying hard now to emphasize we have problems as well. It’s not all ‘shiny and everything works well and all our squads are super amazing’.”</p>
</blockquote>
<p>—Anders Ivarsson, co-author of the Spotify&nbsp;whitepaper<sup><a href="#3">3</a></sup></p>
</div>
</section>
</section>
<!-- Spread 3 -->
<section>
<section>
<div>
<h2>Recap</h2>
<p>You can read and watch the <a href="#1">original content</a> in less than 30 minutes or <a href="#spread-4">skip to the next section</a> if you are familiar. Here is a brief summary.</p>
<p>Spotify had teams it called <em>squads</em> because it sounded cooler (not joking). A group of teams were organized into a department called a <em>tribe</em>. Each team was intended to be an autonomous mini-startup, with a product manager acting as mini-CEO for a feature area. The teams had designers and software engineers with a range of specializations. The intent was that a team should have every skill necessary without needing to rely on another team for success.</p>
<p>Product managers had a traditional management structure. A product manager for a team reported to their department’s product director (<em>“tribe lead”</em>). Same for designers. Software engineers, however, were managed outside of the team structure.</p>
</div>
</section>
<section>
<div>
<p><em>“Chapter leads”</em> managed software engineers specializing in a specific type of software development across the department. For example, all of the software engineers working on backend APIs across all the teams within the department would have one manager and all of the Android mobile engineers in the department would have a different manager. The intent was to allow engineers to be moved between teams within the department to best meet business requirements without them having to change managers.</p>
<figure>
<video autoplay="true" muted="true" loop="true">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.png" alt="Spotify matrix organization diagram. A department is called a tribe and has multiple squads, another name for a team. Each squad has a product owner, another name for a product manager. Software engineers of the same discipline across multiple teams are called a chapter and managed by a chapter lead, another name for an engineering manager.">
</video>
<figcaption>Spotify tried a long-lived matrix team structure with unusual word choices.<sup><a href="#1">1</a></sup> It did not work well.</figcaption>
</figure>
</div>
</section>
</section>
<!-- Spread 4 -->
<section id="spread-4">
<section>

</section>
<section id="matrix-management-sucks">
<div>
<h3>Matrix management solved the wrong problem</h3>
<p>The “full stack” agile team worked well, but the matrix management of software engineers introduced more problems than it solved.</p>
<ul>
<li><p>Teams at Spotify were rather long-lived. The benefit of not having to change manager when moving to another team was limited.</p></li>
<li><p>Engineering managers in this model had little responsibility beyond the career development of the people they managed. Even then, their ability to help with interpersonal people skills development was limited. An engineering manager would not manage enough of the other people on the team or be involved enough in the daily context to independently assess conflict within the team.</p></li>
</ul>
</div>
</section>
</section>
<!-- Spread 5 -->
<section>
<section>
<div>
<ul>
<li><p>Without a single engineering manager responsible for the engineers on a team, the product manager lacked an equivalent peer—the mini-CTO to their mini-CEO role. There was no single person accountable for the engineering team’s delivery or who could negotiate prioritization of work at an equivalent level of responsibility.</p><p>When disagreements within the engineering team arose, the product manager needed to negotiate with all of the engineers on the team. If the engineers could not reach a consensus, the product manager needed to escalate to as many engineering managers as there were engineering specializations within the team. A team with backend, Web app, and mobile app engineers would have at least 3 engineering managers who might need to get involved. If those engineering managers could not reach a consensus, a single team’s issue would have to escalate to the department’s engineering director.</p></li>
</ul>
</div></section>
<section id="matrix-management-sucks">
<div>
<blockquote>
<p>“Chapter leads are servant-leaders who help you grow as an individual. They don’t really work with any team. They have direct reports on all the teams. They don’t have really any accountability for the delivery. They aren’t taking that responsibility. It’s easy to see the product owner as the manager for the team.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>A product—design—engineering team typically contains more engineers than designers or product managers. Having a single engineering manager for the engineers on the team creates an accountable escalation path for conflict within the team.</li>
<li>Product managers should have an equivalent peer for engineering. Product managers should be accountable for the prioritization of work. Engineering managers should be accountable for the engineers’ execution, which includes being able to negotiate speed and quality tradeoffs with the product manager.</li>
</ul>
</div>
</section>
</section>
<!-- Spread 6 -->
<section>
<section id="too-much-autonomy">
<div>
<h3>Spotify fixated on team autonomy</h3>
<p>When a company is small, teams have to do a wide range of work to deliver and have to shift initiatives frequently. As a company grows from startup to scale-up, duplicated functions across teams move to new teams dedicated to increasing organization efficiency by reducing duplication. With more teams, the need for a team to shift initiative decreases in frequency. Both of these changes allow for teams to think more deeply and long term about the problems they are scoped to solve. Faster iteration, however, is not guaranteed. Every responsibility a team cedes to increase its focus becomes a new cross-team dependency.</p>
<p>Spotify did not define a common process for cross-team collaboration. Allowing every team to have a unique way of working meant each team needed a unique way of engagement when collaborating. Overall organization productivity suffered.</p>
<p>The Spotify model was documented when Spotify was a much smaller company. It was supposed to be a multiple part series, according to Anders Ivarsson. Autonomy made the first cut, but the parts on alignment and accountability were never completed.</p>
</div>
</section>
<section>
<div>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>Autonomy requires alignment. Company priorities must be defined by leadership. Autonomy does not mean teams get to do whatever they want.</li>
<li>Processes for cross-team collaboration must be defined. Autonomy does not mean leaving teams to self-organize every problem.</li>
<li>How success is measured must be defined by leadership so people can effectively negotiate cross-team dependency prioritization.</li>
<li>Autonomy requires accountability. Product management is accountable for value. The team is accountable for delivering ‘done’ increments. Mature teams can justify their independence with their ability to articulate business value, risk, learning, and the next optimal move.<sup><a href="#6">6</a></sup></li>
</ul>
</div>
</section>
</section>
<!-- Spread 7 -->
<section>
<section id="too-much-autonomy">
<div>
<blockquote>
<p>“If I were to do one thing differently, I would say we should not be focusing so much on autonomy.</p>
<p>“Every time you have a new team, they have to reinvent the wheel in how they should be working. Maybe, just maybe, we should have a ‘minimum viable agility’. You start with that. You are free to opt out, but people shouldn’t have to opt-in all the time.</p>
<p>“At what point do you start inserting this process? Probably when it’s too late.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Henrik Kniberg talked about how we're not that good at large initiatives and we’re still not that good at large initiatives.</p>
<p>“If you have inconsistent ways of working, it’s more difficult for people to move. If it’s more difficult for people to move, it’s more likely you have inconsistent ways of working. It will just reinforce until all of a sudden, you’re not really working for the same company anymore. You’re working for these kind of weird subcultures.”</p>
</blockquote>
<p>—Jason Yip, agile coach at Spotify<br>2015–time of writing<sup><a href="#5">5</a></sup></p>
</div>
</section>
</section>
<!-- Spread 8 -->
<section>
<section id="collaboration-is-a-competency">
<div>
<h3>Collaboration was an assumed competency</h3>
<p>While Spotify gave teams control over their way of working, many people did not have a basic understanding of Agile practices. This resulted in teams iterating through process tweaks in blind hope of finding the combination that would help them improve their delivery. People lacked a common language to effectively discuss the process problems, the education to solve them, and the experience to evaluate performance. It was not really <em>agile</em>. It was just <em>not-waterfall</em>.</p>
<p><em>“Agile coaches”</em> were internal consultants Spotify provided teams to teach and suggest process improvements. While well-intentioned, there were not enough coaches to help every team. A coach’s engagement with a team was rarely long enough to span a project’s completion to help a team evaluate performance. More so, they were not accountable for anything.</p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Control without competence is chaos.”</p>
</blockquote>
<p>—L. David Marquet, <a href="https://www.indiebound.org/book/9781591846406"><cite>Turn the Ship Around!</cite></a></p>
<p><strong>Learn from Spotify’s …</strong></p></div></section></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jeremiahlee.com/posts/failed-squad-goals/?repost">https://www.jeremiahlee.com/posts/failed-squad-goals/?repost</a></em></p>]]>
            </description>
            <link>https://www.jeremiahlee.com/posts/failed-squad-goals/?repost</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637656</guid>
            <pubDate>Wed, 30 Sep 2020 11:35:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six Figures in 6 days]]>
            </title>
            <description>
<![CDATA[
Score 587 | Comments 274 (<a href="https://news.ycombinator.com/item?id=24637405">thread link</a>) | @brunojppb
<br/>
September 30, 2020 | https://tr.af/6 | <a href="https://web.archive.org/web/*/https://tr.af/6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-lax-preset="fadeIn">
        <p>This title is a little misleading.</p>

<p>Sure, it took me 6 days to amass 3,626 sales for a total of $101,528, but like any overnight success, it was years in the making. In my case, about 7 years.</p>

<p>In 2013, the jailbreaking days of iOS were in full effect. Inspired, I created and sold an icon set titled 'Greyish HD' on the Cydia store for $0.99. It was the first few dollars I ever made on the internet. I think I made a total of $17, and it was magical.</p>

<p>It wasn't about the $17, obviously; it was how I earned it. I spent time creating something that I thought was cool, then hit publish. After a few days, random strangers I've never met before decided to spend their hard-earned cents on my icon set, oftentimes while I was working on something else entirely. Without realizing it, I just discovered digital content leverage: <strong>create something once with sufficient effort, then sell it repeatedly with minimal effort.</strong></p>

<p>Fast forward 7 years later, minus 6 days. I saw some people sharing screenshots of their iPhones after discovering that iOS 14 now allows you to add custom icons to your home screen using the Siri Shortcuts app. This was the first time you can really customize iOS, and it was catching on. </p>

<p>This is something people have been doing for years on jailbroken iOS and Android devices, except this time, you can do it natively on iOS.</p>

<p>As soon as I noticed the hype, I put together some <a href="https://icons.tr.af/">icons</a> in my own style, downloaded some widgets, and tried it all out. I thought it looked cool, so I shared a screenshot of it on Twitter. Right away, people started asking about the icons in the screenshot. So I quickly packaged them, uploaded them to <a href="https://gumroad.com/">Gumroad</a>, and embedded them on a <a href="https://notion.so/">Notion</a> site using <a href="https://super.so/">Super</a>. All of this took about two hours.</p>

<p>The next day, the tweet had hundreds of retweets, thousands of likes, and over 100k impressions. The day after that, almost a million. The next thing I knew, it was everywhere. My icons got published on notable tech sites like <a href="https://www.cultofmac.com/723490/ios-14-iphone-home-screen-customization/">Cult of Mac</a>, <a href="https://www.imore.com/people-are-making-real-money-selling-icon-sets-ios-14-home-screens">iMore</a>, <a href="https://allthingst3ch.com/ios14homescreen">AllThingsTech</a>, and <a href="https://gridfiti.com/aesthetic-ios-home-screen-ideas">Gridfiti</a>. I think at this time I was around the $6k mark in sales.</p>

<p>Then, MKBHD happened. He shared a <a href="https://youtu.be/cH66LWWluVE">video</a> about all of this—using my icons for his setup, and linked them in the description. The next thing I knew, I was making $28 what felt like every 28 seconds. My phone turned into the ultimate dopamine dispenser (if it wasn't already). I had to disable notifications.</p>

<p>The day after, sales jumped from $6k to about $40k, and during the time of this writing, sales are at $116,147 from 4,188 customers.</p>

<p>All from one. Single. <a href="https://twitter.com/traf/status/1307707156788060160">Tweet</a>.</p>

<p>The right content, posted at the right time, can create unimaginable results. Although there's likely plenty of other variables that went into making this work, there are a few key insights that I think increased my odds.</p>

<h3>Publish often</h3>

<p>Continually putting things out into the world creates proof of work. The difference between where you are and where you want to be could be as little as sharing what you build, or even what you know.</p>

<p>There's only so much we can control once pushing something out into the world, but publishing often will increase your odds at finding something that sticks. They say that fortune favors the bold. In the internet age, the bold are those that aren't afraid to publish their work for the world to see. The internet is a never-ending stream of content, the idea of being annoying or over-sharing is only an idea that you invent to stop you from sharing. </p>

<h3>Act immediately</h3>

<p>I could have easily ignored the requests for the icons, or directed people to icon sets that already existed, but that would be a missed opportunity. Since I've done similar icon sets so many times already in the past, I was ready for it. Acting quickly is crucial if you plan on riding the wave. </p>

<h3>Be transparent</h3>

<p>I shared <a href="https://twitter.com/traf/status/1308158718975111175">this tweet</a> the day after posting my home screen with details of all the hype, and it created even more hype. It brought another 540,000 impressions and added fuel to an already growing fire. <strong>Share what works, and share what doesn't.</strong> Transparency is visibility.</p>

<h3>Have a clear schedule</h3>

<p>A lot of this was happening on a Monday morning. If I were working a more traditional job, or had time commitments that I had previously scheduled, I wouldn't have been able to act on my ideas as quickly as I did. I get that not everyone has the privilege of a flexible schedule, but almost anyone can start to move towards it if they want it badly enough. Freedom of a clear schedule allowed me to take action as soon as the inspiration hit, which was incredibly important to maximize exposure. Inspiration is a productivity-multiplier, but it's perishable—so act quickly.</p>

<h3>Charge more</h3>

<p>If I would have asked anyone what to price these at, most would have said $2, or maybe $5. One thing I knew for sure was that the people most likely to buy these were not the same people who were jailbreaking their iOS devices in the past. These are first time iOS customizers, so there's no notion of what an iOS icon set should be priced at.</p>

<h3>Do it for the art</h3>

<p>If I would have done this exclusively for the goal of making money, I'm convinced it wouldn't have worked nearly as well as it did. I see copycats showing up everywhere. They see success, and try to replicate exactly how it happened, but it won't work. At least not nearly as well. The reasons for this post is not to teach you how to sit on the edge of your seat, foaming at the mouth at the chance to exploit the next big internet trend, but it's to push you to keep working at the things you enjoy, share them with the world, and letting the internet do the rest.</p>

<h3>Aftermath</h3>

<p>So what came of all this? I suspect this is why most of you are here reading this, so here's a recap of everything that came from last week in numbers, from the time of this writing:</p>

<h4>Short-term metrics:</h4>

<ul><li>4,188 total icon sales</li><li>$116,147 in revenue</li><li>97% profit margins</li><li>6.2m impression</li><li>216,800 visitors</li></ul>

<h4>Long-term metrics:</h4>

<ul><li>5,216 email subscribers</li><li>4,620 Twitter followers</li><li>180 <a href="https://super.so/">Super</a> customers</li></ul>

<h3>What's next?</h3>

<p>In the same way that creating icon sets 7 years ago prepared me for last week, this whole experiment has likely prepared me for what's to come years from now.</p>

<p>The best part about this is the freedom its bought me, to keep building things that'll create even more freedom. <strong>Spending time on things that will buy you time is always a good use of it.</strong> When people buy into what ever it is you're selling, they're not only giving you money, but they're contributing to your future freedom.</p>

<p>The market will decide a huge part of what comes after sharing something, so continually increase your odds by building, publishing, then repeating. Try many things once to figure out what you want to do twice. Figure out what you've got stored in your brain that can be of value to others, then share it with the world. You might be surprised of what comes of it.</p>

<p>Thanks for reading.</p>

<p>PS. For proof that I did this in 2013, here's my <a href="https://deviantart.com/jtraf">DeviantArt profile</a>.<br>PPS. For details about the Notion/Super/Gumroad combo: <a href="https://www.makerpad.co/deep-dives/the-community-creator-how-to-run-a-low-cost-membership-community-or-creator-business-with-circle-memberspace-gumroad-notion-super-so">Makerpad deep-dive</a>.</p>

<p>— <a href="https://twitter.com/traf">@traf</a></p>
      </div></div>]]>
            </description>
            <link>https://tr.af/6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637405</guid>
            <pubDate>Wed, 30 Sep 2020 10:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitlab CI/CD for cross-platform Unreal Engine 4 projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24637248">thread link</a>) | @me2too
<br/>
September 30, 2020 | https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/ | <a href="https://web.archive.org/web/*/https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Continuous Integration (CI) is an essential step in the development pipeline of well-designed software infrastructure. The goal of CI is to <strong>automatize the boring stuff</strong> by letting the developers focusing on the code and, at the same time, helping them in producing good quality software.</p>
<p>Often, we read together two acronyms (and this article makes no exception) CI &amp; CD. While CI always stands for Continuous Integration, CD has two different meanings:</p>
<ol>
<li><strong>Continuous Delivery</strong> where a developer’s change is automatically bug-tested and uploaded to a repository, or</li>
<li><strong>Continuous Deployment</strong> where a developer’s change is automatically released to the production environment, where the customer can use this brand-new version.</li>
</ol>
<p>In this article, I’m going to show you how to configure and use the CI/CD tool provided by GitLab to correctly manage the CI/CD pipeline of an <strong>Unreal Engine 4 (UE4) project</strong> that needs to work (and thus, to be tested) on 3 different platforms:</p>
<ul>
<li>Windows</li>
<li>macOS</li>
<li>Linux</li>
</ul>
<p>In the following, “CD” will stand for Continuous Delivery - so I won’t cover the Deployment part.</p>

<p><a href="https://about.gitlab.com/">GitLab</a> is a complete DevOps platform: it offers us a complete CI/CD toolchain, an amazing issue tracking suite, and exposes in a user-friendly-way almost every Git’s feature.</p>
<p><img src="https://pgaleone.eu/images/ciue4/cicd_pipeline_infograph.png" alt="GitLab Continuous Integration pipeline"></p>
<p>The CI/CD toolchain is composed of 3 main parts:</p>
<ul>
<li>The <code>gitlab-ci.yml</code> file that contains the configuration of the CI/CD pipeline. Using this YAML file we can configure the CI/CD behavior: what should happen on every commit or merge request, what should happen at scheduled times, and <a href="https://docs.gitlab.com/ee/ci/yaml/">many many more</a>. This file contains the commands to execute (a batch of commands is called “job”) on the specified runner.</li>
<li><a href="https://docs.gitlab.com/runner/">GitLab Runners</a>. A runner is a software able to receive from GitLab a job, execute it, and send back the result to GitLab. Several runners can (and should) run in parallel, allowing the whole infrastructure to scale. The execution of the job is delegated to an “executor”.</li>
<li><strong>The executor</strong>. During the configuration of the runner, we can specify what type of executor to use. In particular, it’s possible to use the machine where the runner is installed to run directly in its shell the commands (that’s the shell executor), or use Docker to execute the commands into a container, or even use a virtual machine or a Kubernetes cluster (for a complete reference see: https://docs.gitlab.com/runner/executors/).</li>
</ul>
<p>The amazing thing is that GitLab Runner is a software written in Go: this means that it can run perfectly on our three target platforms: Windows, macOS, and Linux.</p>
<p>Moreover, installing it is trivial as explained in <a href="https://docs.gitlab.com/runner/#install-gitlab-runner">the documentation</a>.</p>
<h2 id="executors-for-ue4-projects">Executors for UE4 projects</h2>
<p><a href="https://www.unrealengine.com/en-US/">Unreal Engine</a> is a cross-platform game engine, quoting the official website:</p>
<blockquote>
<p>Unreal Engine is the world’s most open and advanced real-time 3D creation tool. Continuously evolving to serve not only its original purpose as a state-of-the-art game engine, today it gives creators across industries the freedom and control to deliver cutting-edge content, interactive experiences, and immersive virtual worlds.</p>
</blockquote>
<p>UE4 is really an amazing project, but this amazingness comes at a cost: it’s <strong>heavy</strong>. The engine itself, <a href="https://docs.unrealengine.com/en-US/GettingStarted/DownloadingUnrealEngine/index.html">available on GitHub</a>, weights ~132GB on Linux:</p>
<div><div><pre><code><span>du</span> <span>-hs</span> /opt/unreal-engine/
132G    /opt/unreal-engine/
</code></pre></div></div>
<p>Since our goal is to create an environment that contains the compiled engine (for our three target platforms) and use it inside our CI. Using a <strong>Docker executor</strong> it is perhaps the best possible solution.</p>
<h3 id="docker-executor">Docker executor</h3>
<p>As previously stated, one of the costs of using UE4 is its size: when we have enough resources this isn’t a problem (you need a good amount of storage and a lot of memory and CPU power to compile and use the engine), and it’s not a problem even when using Docker on Linux. However, building a Docker image containing UE4 on Windows is somehow a difficult and long process, because there is a well-know and <em>unresolved</em> issue about the creation of <a href="https://github.com/moby/moby/issues/37581">filesystem layers lager than 8 GiB</a>.</p>
<p>Although there are well-known issues (only on Windows), using a Docker executor have a lot of advantages like:</p>
<ul>
<li>Spawning a container is a cheap operation.</li>
<li>Every container is isolated.</li>
<li>It is possible to scale the solution easily (easy to parallelize).</li>
<li>Customizing/Creating a Dockerfile is easy.</li>
</ul>
<p>Creating docker containers with unreal-engine inside is a challenge that <a href="https://adamrehn.com/">Adam Rehn</a> with his <a href="https://unrealcontainers.com/">Unreal Containers</a> <strong>amazingly faced</strong>.</p>
<p><img src="https://pgaleone.eu/images/ciue4/ue-plus-docker.svg" alt="UnrealContainer logo"></p>
<p>The project, and Python package, <a href="https://docs.adamrehn.com/ue4-docker/read-these-first/introduction-to-ue4-docker">ue4-docker</a> contains all we need to create a docker image that we will later on use in our <code>.gitlab-ci.yml</code> file.</p>
<p>Using <code>ue4-docker</code> creating an image is so easy as:</p>
<div><div><pre><code><span>REPO_URL</span><span>=</span><span>"&lt;set url here&gt;"</span>
<span>BRANCH</span><span>=</span><span>"&lt;set branch here&gt;"</span>
ue4-docker build custom:4.25.3 <span>-repo</span><span>=</span><span>"</span><span>$REPO_URL</span><span>"</span> <span>-branch</span><span>=</span><span>"</span><span>$BRANCH</span><span>"</span> <span>\</span>
           <span>--exclude</span> debug <span>\ </span><span># exclude debug symbols to reduce the image and workaround the windows issue</span>
           <span>--exclude</span> templates <span>\ </span><span># exclude the templates since we don't need them in our CI</span>
           <span>--exclude</span> ddc <span># exclude DDC to speed up the image creation </span>
</code></pre></div></div>
<p>The same command can be executed in a Linux and in a Windows machine. Personally, I prefer having a Linux machine that executes a docker container, instead of using a Windows machine to execute a docker container containing a Linux image (for performance reasons and to save time during the creation of the images too).</p>
<p>At the end of the execution of the <code>ue4-docker</code> command, we end up with a set of images ready to use like:</p>
<div><div><pre><code>docker images | grep ue4

adamrehn/ue4-full                           4.25.3                        01562ee9c264        9 days ago          15.6GB
adamrehn/ue4-full                           4.25.3-opengl                 01562ee9c264        9 days ago          15.6GB
adamrehn/ue4-minimal                        4.25.3                        561beaae1f0f        9 days ago          14GB
adamrehn/ue4-minimal                        4.25.3-opengl                 561beaae1f0f        9 days ago          14GB
adamrehn/ue4-engine                         4.25.3                        717a019f5917        9 days ago          85.6GB
adamrehn/ue4-engine                         4.25.3-opengl                 717a019f5917        9 days ago          85.6GB
adamrehn/ue4-source                         4.25.3                        dce5e2cdbc65        9 days ago          54.7GB
adamrehn/ue4-source                         4.25.3-opengl                 dce5e2cdbc65        9 days ago          54.7GB
adamrehn/ue4-build-prerequisites            opengl                        ec75c0a656c0        7 months ago        584MB
</code></pre></div></div>
<p>A complete description of what is inside every image is available in the <a href="https://docs.adamrehn.com/ue4-docker/building-images/available-container-images">List of available container images</a> page.</p>
<p>Using Docker we can cover the CI for the Linux and Windows platforms. macOS, instead, can’t run inside a container :( hence we have to use another executor.</p>
<h3 id="shell-executor">Shell executor</h3>
<p>The shell executor is just “the current machine”. Thus, we can install <a href="https://docs.gitlab.com/runner/install/osx.html">GitLab Runner on macOS</a> and manually install all the dependencies that are, in our case, only unreal engine and the Xcode toolchain.</p>
<p>Differently from the Docker executor, the Shell executor has several disadvantages:</p>
<ul>
<li>No isolation at all.</li>
<li>No native support for parallel and isolated executions.</li>
<li>It doesn’t scale well.</li>
<li>We have to clean up the dirt left by the operations we do in the CI (e.g. temporary files).</li>
</ul>
<p>The only advantage we have is the simplicity of installation: we just have to install UE4 on our machine and we are ready to go.</p>
<p>Supposing to have Unreal Engine already installed (the setup on Mac, Linux, Windows is straightforward; it’s just a matter of following the <a href="https://docs.unrealengine.com/en-US/GettingStarted/Installation/index.html">guide</a>), the only thing we need to do is to install another Python tool created by Adam Rehn: <a href="https://docs.adamrehn.com/ue4cli/overview/introduction-to-ue4cli">ue4cli</a>.</p>
<p>This Python package implements a command-line tool called <code>ue4</code>: this tool simplifies the invocation/usage of the UE4 toolchain and, perhaps more importantly, it unifies the interface we have to use on different platforms.</p>
<p>The tool is installed into the <code>ue4-full</code> images and that’s the reason we’re going to use these images in our <code>gitlab-ci.yml</code> file.</p>
<h2 id="the-cicd-pipeline">The CI/CD pipeline</h2>
<p>As introduced at the beginning of the article, after setting up the runners and the executor, we are ready to describe the CI/CD pipeline in the <code>.gitlab-ci.yml</code> file.</p>
<h3 id="continuous-integration">Continuous Integration</h3>
<p>Let’s start with the automatization of the boring stuff, we need to find a way to automatically answer these questions:</p>
<ol>
<li>Is the code following the code style / required formatting?</li>
<li>Does the code I want to merge compile correctly on every platform?</li>
<li>Am I introducing regressions?</li>
</ol>
<p>To answer all these questions, and be ready for the continuous delivery stuff, we need to define the variables and the stages (of the pipeline) we plan to execute.</p>
<div><div><pre><code><span>variables</span><span>:</span>
    <span>GIT_SUBMODULE_STRATEGY</span><span>:</span> <span>"</span><span>recursive"</span>
    <span>GIT_STRATEGY</span><span>:</span> <span>"</span><span>fetch"</span>
    <span>GIT_CHECKOUT</span><span>:</span> <span>"</span><span>true"</span>
    <span>GIT_SSL_NO_VERIFY</span><span>:</span> <span>"</span><span>1"</span>
    <span>GET_SOURCES_ATTEMPTS</span><span>:</span> <span>"</span><span>10"</span>

<span>stages</span><span>:</span>
    <span>-</span> <span>static-analysis</span>
    <span>-</span> <span>build</span>
    <span>-</span> <span>tests</span>
    <span>-</span> <span>package</span>
</code></pre></div></div>
<ul>
<li>The <strong>static-analysis</strong> stage will contain the jobs related to the source code analysis. The checks for the source code formatting (the only one presented in this article) and other checks related to the analysis of the source code itself.</li>
<li>The <strong>build</strong> stage will contain the jobs that answer question 2.</li>
<li>The <strong>test</strong> stage contains the execution of the test cases (because every unreal project uses the unreal test suite - isn’t it?)</li>
<li>The <strong>package</strong> stage contains the continuous delivery part of the pipeline.</li>
</ul>
<h5 id="static-analysis">Static Analysis</h5>
<p>Every C++ project should follow a code style. This CI job uses <code>clang-format</code> and <code>dos2unix</code> to check if every committed file has the correct encoding (we need UTF-8 encoded files to be sure that every compiler on every platform can read them well) and follows the style rules present in the <code>.clang-format</code> file that should be present into every project :)</p>
<div><div><pre><code><span>clang-format</span><span>:</span>
    <span>image</span><span>:</span> <span>alpine</span>
    <span>stage</span><span>:</span> <span>static-analysis</span>
    <span>variables</span><span>:</span>
        <span>GIT_LFS_SKIP_SMUDGE</span><span>:</span> <span>"</span><span>1"</span>
    <span># empty dependencies = do not need artifacts from previous stages</span>
    <span>dependencies</span><span>:</span> <span>[]</span>
    <span>script</span><span>:</span>
        <span>-</span> <span>apk update &amp;&amp; apk add clang git bash dos2unix</span>
        <span>-</span> <span>exclude=$(for d in $(git …</span></code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/">https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/</a></em></p>]]>
            </description>
            <link>https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637248</guid>
            <pubDate>Wed, 30 Sep 2020 10:33:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book: Epic Alignment – How the best Product Managers work with feature documents]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24637233">thread link</a>) | @njanse
<br/>
September 30, 2020 | https://www.delibr.com/ebook | <a href="https://web.archive.org/web/*/https://www.delibr.com/ebook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>What's inside</h3>
<p>How can you drive the thinking on what to develop, why and how to
do it — leveraging the insights from both team and stakeholders — all the way from idea to
deploy?</p>
<p>This book tries to answer the above question. As part of our own
product development at Delibr, we interviewed over 300 Product Managers to understand how they work
and collaborate around feature development, what problems they face, and the many approaches to
solving those problems. </p>
<p>"Epic alignment" describes four broad approaches that we saw help
Product Managers excel.</p>
<h3>What you'll learn</h3>
<ul>
<li>How to drive product development towards impact based on research</li>
<li>How to use user stories as a shared language to align your entire team</li>
<li>How to write feature documents that drive joint understanding and act as a single source of
truth
</li>
<li>How to tackle the massive amounts of decisions needed for every epic</li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.delibr.com/ebook</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637233</guid>
            <pubDate>Wed, 30 Sep 2020 10:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most popular GraphgQL server implementations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637210">thread link</a>) | @oczek
<br/>
September 30, 2020 | https://blog.graphqleditor.com/graphql-servers/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/graphql-servers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GraphQL is a query language for APIs that describes how to ask &amp; fetch the data from the server to the client which of course requires setting up a server. Below you will find a list of the most popular GraphgQL server implementations. There’s quite a few of them so we’re not going to get through the lot of them in one go.</p>
<h2>Express GraphQL</h2>
<p>It is said that <a href="https://github.com/graphql/express-graphql">Express GraphQL</a> is the simplest way to run a GraphQL API server. Express is a popular web application framework for Node.js allowing you to create a GraphQL server with any HTTP web framework supporting connect styled middleware including <a href="https://expressjs.com/">Express</a>, <a href="http://restify.com/">Restify</a> and, of course, <a href="https://github.com/senchalabs/connect">Connect</a>. Getting started is as easy as installing some additional dependencies in form of <code>npm install express express-graphql graphql --save</code></p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/21b4d/express.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Express GraphQL" title="Express GraphQL" src="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/fcda8/express.png" srcset="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/12f09/express.png 148w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/e4a3f/express.png 295w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/fcda8/express.png 590w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/efc66/express.png 885w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/c83ae/express.png 1180w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/21b4d/express.png 1280w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://graphql.org/graphql-js/running-an-express-graphql-server/">graphql.org</a></h5>
<h2>Apollo GraphQL Server</h2>
<p><a href="https://github.com/apollographql/apollo-server">Apollo GraphQL Server</a> is an open-source GraphQL server compatible with any GraphQL client and it’s an easy way to build a production-ready, self-documenting GraphQL API that can use data from any source. Apollo Server can be used as a stand-alone GraphQL server, a plugin to your application’s Node.js middleware, or as a gateway for a federated data graph. Apollo GraphQL Server offers:</p>
<ul>
<li><strong>easy setup</strong> - client-side can start fetching data instantly,</li>
<li><strong>incremental adoption</strong> - elastic approach to adding new features, you can add them easily later on when you decide they’re needed,</li>
<li><strong>universality</strong> - compatibility with any data source, multiple
build tools and GraphQL clients,</li>
<li><strong>production-ready</strong> - tested across various enterprise-grade projects.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/23266/apollo.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Apollo GraphQL Server" title="Apollo GraphQL Server" src="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/fcda8/apollo.png" srcset="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/12f09/apollo.png 148w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/e4a3f/apollo.png 295w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/fcda8/apollo.png 590w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/efc66/apollo.png 885w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/23266/apollo.png 923w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/apollographql/apollo-server">apollographql.com</a></h5>
<h2>Hot Chocolate</h2>
<p><a href="https://hotchocolate.io/">Hot Chocolate</a> is a GraphQL server you can use to create GraphQL endpoints,  merge schemas, etc. Hot Chocolate is a part of a .NET based <a href="https://github.com/ChilliCream/hotchocolate">ChilliCream GraphQL Platform</a> that can help you build a GraphQL layer over your existing and new infrastructure. It provides pre-built templates that let you start in seconds, supporting both ASP.Net Core as well as ASP.Net Framework out of the box.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/23266/hotchoc.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hot Chocolate is a part of ChilliCream GraphQL Platform" title="Hot Chocolate is a part of ChilliCream GraphQL Platform" src="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/fcda8/hotchoc.png" srcset="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/12f09/hotchoc.png 148w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/e4a3f/hotchoc.png 295w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/fcda8/hotchoc.png 590w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/efc66/hotchoc.png 885w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/23266/hotchoc.png 923w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/ChilliCream/hotchocolate">github.com/ChilliCream/hotchocolate</a></h5>
<h2>Hasura GraphQL Engine</h2>
<p><a href="https://github.com/hasura/graphql-engine">Hasura GraphQL Engine</a> is a GraphQL server that gives you realtime GraphQL APIs over Postgres, making easy building your new Postgress-backed GraphQL app or adding a GraphQL layer for your existing Postgres bases app.  Hasura GraphQL Engine offers built-in filtering, pagination, merging remote schemas along with many other useful features. All that keeping high-performance &amp; footprint at the lowest possible rate.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/d9199/hasura.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hasura GraphQL Engine" title="Hasura GraphQL Engine" src="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/fcda8/hasura.png" srcset="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/12f09/hasura.png 148w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/e4a3f/hasura.png 295w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/fcda8/hasura.png 590w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/efc66/hasura.png 885w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/d9199/hasura.png 960w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/hasura/graphql-engine">github.com/hasura</a></h5>
<h2>API PLATFORM</h2>
<p><a href="https://github.com/api-platform/api-platform">API Platform</a> is a set of tools that combined build a modern framework for building REST and GraphQL APIs including GraphQL Server. The server solution is located in the API Platform Core Library which is built on top of Symfony 4 (PHP) microframework and the Doctrine ORM. API Platform Core Library is a highly flexible solution allowing you to build fully-featured GraphQL API in minutes.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/2cefc/apiplatform.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="API PLATFORM" title="API PLATFORM" src="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/fcda8/apiplatform.png" srcset="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/12f09/apiplatform.png 148w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/e4a3f/apiplatform.png 295w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/fcda8/apiplatform.png 590w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/efc66/apiplatform.png 885w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/c83ae/apiplatform.png 1180w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/2cefc/apiplatform.png 1400w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://api-platform.com/">api-platform.com</a></h5>
<h2>Parse Server GraphQL API</h2>
<p>In addition to the traditional REST API, Parse Server automatically generates a GraphQL API basing on a given schema. <a href="https://docs.parseplatform.org/graphql/guide/">Parse Server GraphQL API</a> follows Relay specification along with the latest industry standards which makes it a perfect choice for modern projects requiring the highest-scalability.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/00d43/parse.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Parse Server GraphQL API " title="Parse Server GraphQL API " src="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/fcda8/parse.png" srcset="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/12f09/parse.png 148w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/e4a3f/parse.png 295w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/fcda8/parse.png 590w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/efc66/parse.png 885w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/00d43/parse.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://docs.parseplatform.org/graphql/guide/">docs.parseplatform.org/graphql/guide</a></h5>
<p>That’s it for the first look at GraphQL servers. So if I missed your favorite one, just mention it in the comments and stay tuned for the next parts!</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/graphql-servers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637210</guid>
            <pubDate>Wed, 30 Sep 2020 10:26:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commodore 64 Program Discovered on 35-Year Old Vinyl Album]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637146">thread link</a>) | @clockworksoul
<br/>
September 30, 2020 | https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/ | <a href="https://web.archive.org/web/*/https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1304">
	
	<div>
		
<p>Friends, this should give you a little boost at the end of your day – because 8-Bit Show and Tell has located a Commodore 64 program hidden within Prodigal’s 1984 album entitled Electric Eye. I was just goofing around on YouTube when I came across this video – which was originally uploaded back on October 19th of this year. Since I have been known to talk about my love of the Commdore 64 computer of my youth – the title of the video caught my attention pretty quickly. And seriously, how absolutely amazing is it that in this day and age we can still be surprised by little Easter eggs from 35 years ago? As Robin will demonstrate on the video itself the program was hidden in the runout groove on the B side of <em>Electric Eye</em>  – which you can plainly see in this article image header has a “C-64” scratched into said groove. Probably one of the reasons that not a lot of people know about the program is because it needed to be played on your turntable where you could record the hidden program on a cassette tape to upload it on your C64… that is a little bit of work. As the video will show – sometimes using older technology takes a couple of tries – or even totally different equipment in some cases.</p>







<p>I will have to in the near future share an article about the Mattel Electronics Aquarius computer that we obtained at the arcade – in fact I talked just a bit about it in the <em><a href="https://popcultureretrorama.com/2019/11/24/diary-of-an-arcade-employee-podcast-1up-night-stalker/">Night Stalker</a></em> podcast earlier today. Robin was able to make contact with one of the surviving members of <strong>Prodigal</strong> by the way – which was a Christian rock group, active from 1975 until 1986 – to ask how and why this 35 year-old computer program was included on the <em>Electric Eye</em> album. </p>



<div><figure><img data-attachment-id="1306" data-permalink="https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/35-years-later-a-commodore-64-program-electric-eye/" data-orig-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=700%2C394&amp;ssl=1" data-orig-size="700,394" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="35-Years-Later-A-Commodore-64-Program-Electric-Eye" data-image-description="" data-medium-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=640%2C360&amp;ssl=1" loading="lazy" width="640" height="360" src="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=640%2C360&amp;ssl=1" alt="" srcset="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=150%2C84&amp;ssl=1 150w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=150%2C84&amp;ssl=1 150w" data-lazy-src="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=640%2C360&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>The discovery of what amounts to a simple message from <strong>Prodigal</strong> 35 years later might not be the most groundbreaking thing you’ll see today… but I thought it was special enough that I had to share it. Watching this particular 8-Bit Show and Tell video will in addition show you how to hack your turntable to disable the auto return if you need to!</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/6_CZpFqvDQo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<div>
	
	<p>
		An avid devotee to pretty much all things pop culture and retro related - I love to share my memories and passion for films, comics, gaming, podcasting... and curiously enough my overwhelming desire to never stop eating beef jerky.		<a href="https://popcultureretrorama.com/author/vicsagepopculture/" rel="author">
			View more posts		</a>
	</p><!-- .author-description -->
</div><!-- .author-bio -->
	
</article></div>]]>
            </description>
            <link>https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637146</guid>
            <pubDate>Wed, 30 Sep 2020 10:13:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Guide to OTP in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637121">thread link</a>) | @NaeosPsy
<br/>
September 30, 2020 | https://serokell.io/blog/elixir-otp-guide | <a href="https://web.archive.org/web/*/https://serokell.io/blog/elixir-otp-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the main advantages of Elixir is that it is awesome for server-side systems. Forget using a million different technologies for things like data persistence, background jobs, and service crash recovery, OTP can supply you with everything.</p><p><em>So what exactly is this magical thing?</em></p><p>In this article, I will introduce you to OTP, look at basic process loops, the GenServer and Supervisor behaviours, and see how they can be used to implement an elementary process that stores funds.</p><p>(This article assumes that you are already familiar with the basics of Elixir. If you’re not, you can check out the <a href="https://elixir-lang.org/getting-started/introduction.html">Getting Started guide</a> on Elixir’s website or use one of the other resources listed in our <a href="https://serokell.io/blog/learn-elixir">Elixir guide</a>.)</p><h2 id="what-is-otp%3F">What is OTP?</h2><p>OTP is an awesome set of tools and libraries that Elixir inherits from Erlang, <a href="https://serokell.io/blog/history-of-erlang-and-elixir">a programming language on whose VM it runs</a>.</p><p>OTP contains a lot of stuff, such as the Erlang compiler, databases, test framework, profiler, debugging tools. But, when we talk about OTP in the context of Elixir, we usually mean the Erlang actor model that is based on lightweight processes and is the basis of what makes Elixir so efficient.</p><h2 id="processes">Processes</h2><p><img src="https://serokell.io/files/dg/dg0wowcg.processes_(1).jpg" alt="Processes divider"></p><p>At the foundation of OTP, there are tiny things called processes.</p><p>Unlike OS processes, they are really, really lightweight. Creating them takes microseconds, and a single machine can easily run multiple thousands of them, simultaneously.</p><p>Processes loosely follow the <a href="https://en.wikipedia.org/wiki/Actor_model">actor model</a>. Every process is <em>basically</em> a mailbox that can receive messages, and in response to those messages it can:</p><ul>
<li>Create new processes.</li>
<li>Send messages to other processes.</li>
<li>Modify its private state.</li>
</ul><p><img src="https://serokell.io/files/j1/j1smm7kp.process.jpg" alt="Process graph"></p><h3 id="spawning-processes">Spawning processes</h3><p>The most basic way to spawn a process is with the spawn command. Let’s open IEx and launch one.</p><pre><code>iex(<span>1</span>)&gt; process = spawn(<span>fn</span> -&gt; IO.puts(<span>"hey there!"</span>) <span>end</span>)
</code></pre><p>The above function will return:</p><pre><code>hey there!

</code></pre><p>First is the result of the function, second is the output of spawn – PID, a unique process identification number.</p><p>Meanwhile, we have a problem with our process. While it did the task we asked it to do, it seems like it is now… dead? 😱</p><p>Let’s use its PID (stored in the variable <code>process</code>) to query for life signs.</p><pre><code>iex(<span>2</span>)&gt; Process.alive?(process)
<span>false</span>
</code></pre><p>If you think about it, it makes sense. The process did what we asked it to do, fulfilled its reason for existence, and closed itself. But there is a way to extend the life of the process to make it more worthwhile for us.</p><h3 id="receive-do-loop">Receive-do loop</h3><p>Turns out, we can extend the process function to a loop that can hold state and modify it.</p><p>For example, let’s imagine that we need to create a process that mimics the funds in a palace treasury. We’ll create a simple process to which you can store or withdraw funds, and ask for the current balance.</p><p>We’ll do that by creating a loop function that responds to certain messages while keeping the state in its argument.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.SimpleTreasury <span>do</span>

  <span><span>def</span> <span>loop</span></span>(balance) <span>do</span>
      receive <span>do</span>
        {<span>:store</span>, amount} -&gt;
          loop(balance + amount)
        {<span>:withdraw</span>, amount} -&gt;
          loop(balance - amount)
        {<span>:balance</span>, pid} -&gt;
          send(pid, balance)
          loop(balance)
      <span>end</span>
    <span>end</span>
<span>end</span>
</code></pre><p>In the body of the function, we put the receive statement and pattern match all the messages we want our process to respond to. Every time the loop runs, it will check from the bottom of the mailbox (in order they were received) for messages that match what we need and process them.</p><p>If the process sees any messages with atoms <code>store</code>, <code>withdraw</code>, <code>balance</code>, those will trigger certain actions.</p><p>To make it a bit nicer, we can add an <code>open</code> function and also dump all the messages we don’t need to not pollute the mailbox.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.SimpleTreasury <span>do</span>

  <span><span>def</span> <span>open</span></span>() <span>do</span>
    loop(<span>0</span>)
  <span>end</span>

  <span><span>def</span> <span>loop</span></span>(balance) <span>do</span>
    receive <span>do</span>
      {<span>:store</span>, amount} -&gt;
        loop(balance + amount)
      {<span>:withdraw</span>, amount} -&gt;
        loop(balance - amount)
      {<span>:balance</span>, pid} -&gt;
        send(pid, balance)
        loop(balance)
      <span>_</span> -&gt;
        loop(balance)
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre><p>While this seems quite concise, there’s already some boilerplate lurking, and we haven’t even covered corner cases, tracing, and reporting that would be necessary for production-level code.</p><p>In real life, we don’t need to write code with receive do loops. Instead, we use one of the behaviours created by people much smarter than us.</p><h2 id="behaviours">Behaviours</h2><p>Many processes follow certain similar  patterns. To abstract over these patterns, we use behaviours. Behaviours have two parts: abstract code that we don’t have to implement and a callback module that is implementation-specific.</p><p>In this article, I will introduce you to <a href="https://hexdocs.pm/elixir/GenServer.html">GenServer</a>, short for <em>generic server</em>, and <a href="https://hexdocs.pm/elixir/Supervisor.html">Supervisor</a>. Those are not the only behaviours out there, but they certainly are one of the most common ones.</p><h3 id="genserver">GenServer</h3><p><img src="https://serokell.io/files/za/za1kwa33.genserver.jpg" alt="GenServer divider"></p><p>To start off, let’s create a module called <code>Treasury</code>, and add the GenServer behaviour to it.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury <span>do</span>
  <span>use</span> GenServer
<span>end</span>
</code></pre><p>This will pull in the necessary boilerplate for the behaviour. After that, we need to implement the callbacks for our specific use case.</p><p>Here’s what we will use for our basic implementation.</p><table>
  <tbody><tr>
   <td>Callback
   </td>
   <td>What it does
   </td>
   <td>What it <em>usually</em> returns
   </td>
  </tr>
  <tr>
   <td><code>init(state)</code>
   </td>
   <td>Initializes the server.
   </td>
   <td><code>{:ok, state}</code>
   </td>
  </tr>
  <tr>
   <td><code>handle_cast(pid, message)</code>
   </td>
   <td>An async call that doesn’t demand an answer from the server.
   </td>
   <td><code>{:noreply, state}</code>
   </td>
  </tr>
  <tr>
   <td><code>handle_call(pid, from, message)</code>
   </td>
   <td>A synchronous call that demands an answer from the server.
   </td>
   <td><code>{:reply, reply, state}</code>
   </td>
  </tr>
</tbody></table><p>Let’s start with the easy one – <code>init</code>. It takes a state and starts a process with that state.</p><pre><code> <span><span>def</span> <span>init</span></span>(balance) <span>do</span>
   {<span>:ok</span>, balance}
 <span>end</span> 
</code></pre><p>Now, if you look at the simple code we wrote with <code>receive</code>, there are two types of triggers. The first one (<code>store</code> and <code>withdraw</code>)  just asks for the treasury to update its state asynchronously, while the second one (<code>get_balance</code>) waits for an answer. <code>handle_cast</code> can handle the async ones, while <code>handle_call</code>can handle the synchronous one.</p><p>To handle adding and subtracting, we will need two casts. These take a message with the command and the transaction amount and update the state.</p><pre><code><span><span>def</span> <span>handle_cast</span></span>({<span>:store</span>, amount}, balance) <span>do</span>
  {<span>:noreply</span>, balance + amount}
<span>end</span>

<span><span>def</span> <span>handle_cast</span></span>({<span>:withdraw</span>, amount}, balance) <span>do</span>
  {<span>:noreply</span>, balance - amount}
<span>end</span>
</code></pre><p>Finally, <code>handle_call</code>takes the balance call, the caller, and state, and uses all that to reply to the caller and return the same state.</p><pre><code><span><span>def</span> <span>handle_call</span></span>(<span>:balance</span>, _from, balance) <span>do</span>
  {<span>:reply</span>, balance, balance}
<span>end</span>
</code></pre><p>These are all the callbacks we have:</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury <span>do</span>
  <span>use</span> GenServer

  <span><span>def</span> <span>init</span></span>(balance) <span>do</span>
    {<span>:ok</span>, balance}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:store</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance + amount}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:withdraw</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance - amount}
  <span>end</span>

  <span><span>def</span> <span>handle_call</span></span>(<span>:balance</span>, _from, balance) <span>do</span>
    {<span>:reply</span>, balance, balance}
  <span>end</span>
<span>end</span>
</code></pre><p>To hide the implementation details, we can add client commands in the same module. Since this will be the only treasury of the palace, let’s also give a name to the process equal to its module name when spawning it with <code>start_link.</code>This will make it easier to refer to it.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury <span>do</span>
  <span>use</span> GenServer

  

  <span><span>def</span> <span>open</span></span>() <span>do</span>
    GenServer.start_link(__MODULE_<span>_</span>, <span>0</span>, <span>name:</span> __MODULE_<span>_</span>)
  <span>end</span>

  <span><span>def</span> <span>store</span></span>(amount) <span>do</span>
    GenServer.cast(__MODULE_<span>_</span>, {<span>:store</span>, amount})
  <span>end</span>

  <span><span>def</span> <span>withdraw</span></span>(amount) <span>do</span>
    GenServer.cast(__MODULE_<span>_</span>, {<span>:withdraw</span>, amount})
  <span>end</span>

  <span><span>def</span> <span>get_balance</span></span>() <span>do</span>
    GenServer.call(__MODULE_<span>_</span>, <span>:balance</span>)
  <span>end</span>

  

  <span><span>def</span> <span>init</span></span>(balance) <span>do</span>
    {<span>:ok</span>, balance}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:store</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance + amount}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:withdraw</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance - amount}
  <span>end</span>

  <span><span>def</span> <span>handle_call</span></span>(<span>:balance</span>, _from, balance) <span>do</span>
    {<span>:reply</span>, balance, balance}
  <span>end</span>
<span>end</span>
</code></pre><p>Let’s try it out:</p><pre><code><span><span>iex</span><span>(<span>1</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.open</span>()
{:ok, #PID&lt;<span>0.138</span>.<span>0</span>&gt;}
<span><span>iex</span><span>(<span>2</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.store</span>(<span>400</span>)
:ok
<span><span>iex</span><span>(<span>3</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.withdraw</span>(<span>100</span>)
:ok
<span><span>iex</span><span>(<span>4</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.get_balance</span>()
<span>300</span>
</code></pre><p>It works. 🥳</p><p>Here’s <a href="https://elixir-lang.org/cheatsheets/gen-server.pdf">a cheatsheet on GenServer</a> to help you remember where to put what.</p><h3 id="supervisor">Supervisor</h3><p><img src="https://serokell.io/files/7j/7jpa2q4j.supervisor_(1).jpg" alt="Supervisor divider"></p><p>However, just letting a treasury run without supervision is a bit irresponsible, and a good way to lose your funds or your head. 😅</p><p>Thankfully, OTP provides us with the <a href="https://hexdocs.pm/elixir/Supervisor.html">supervisor behaviour</a>. Supervisors can:</p><ul>
<li>start and shutdown applications,</li>
<li>provide fault tolerance by restarting crashed processes,</li>
<li>be used to make a hierarchical supervision structure, called a <em>supervision tree</em>.</li>
</ul><p>Let’s equip our treasury with a simple supervisor.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury.Supervisor <span>do</span>
  <span>use</span> Supervisor

  <span><span>def</span> <span>start_link</span></span>(init_arg) <span>do</span>
    Supervisor.start_link(__MODULE_<span>_</span>, init_arg,  <span>name:</span> __MODULE_<span>_</span>)
  <span>end</span>

  <span><span>def</span> <span>init</span></span>(_init_arg) <span>do</span>
    children = [
      %{
       <span>id:</span> Palace.Treasury,
       <span>start:</span> {Palace.Treasury, <span>:open</span>, []}
      }
    ]   


    Supervisor.init(children, <span>strategy:</span> <span>:one_for_one</span>)
  <span>end</span>
<span>end</span>
</code></pre><p>In its most basic, a supervisor has two functions: <code>start_link()</code>, which runs the supervisor as a process, and <code>init</code>, which provides the arguments necessary for the supervisor to initialize.</p><p>Things we need to pay attention to are:</p><ul>
<li><strong>The list of children.</strong> Here, we list all the processes that we want the supervisor to start, together with their init functions and starting arguments. Each of the processes is a map, with at least the <code>id</code>and <code>start</code> keys in it.</li>
<li><strong>Supervisor’s <code>init</code> function.</strong> To it, we supply the list of children processes and a supervision strategy. Here, we use <code>:one_for_one</code>– if a child process will crash, only that process will be restarted. There are <a href="https://hexdocs.pm/elixir/Supervisor.html#module-strategies">a few more</a>.</li>
</ul><p>Running the <code>Palace.Treasury.Supervisor.start_link()</code> function will open a treasury, which will be supervised by the process. If the treasury crashes, it will get restarted with the initial state – 0.</p><p>If we wanted, we could add several other processes to this supervisor that are relevant to the treasury function, such as a process that can exchange looted items for their monetary value.</p><p>Additionally, we could also duplicate or persist the state of the treasury …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/elixir-otp-guide">https://serokell.io/blog/elixir-otp-guide</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/elixir-otp-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637121</guid>
            <pubDate>Wed, 30 Sep 2020 10:08:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Little Book of Algorithms: Teach Python to kids (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636942">thread link</a>) | @asg
<br/>
September 30, 2020 | http://www.mrlaulearning.com/2019/04/LBOA.html | <a href="https://web.archive.org/web/*/http://www.mrlaulearning.com/2019/04/LBOA.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4531756548067310499" itemprop="description articleBody">
<div dir="ltr" trbidi="on">
<p><a href="https://1.bp.blogspot.com/-6azi-qqwv_U/XoBdl891T6I/AAAAAAAAF8w/CUTzpWBgM2gMYKcvanWVmE1LOXrfuZovQCLcBGAsYHQ/s1600/LBOA%2Bkindle.tif" imageanchor="1"><img data-original-height="1240" data-original-width="874" height="320" src="https://1.bp.blogspot.com/-6azi-qqwv_U/XoBdl891T6I/AAAAAAAAF8w/CUTzpWBgM2gMYKcvanWVmE1LOXrfuZovQCLcBGAsYHQ/s320/LBOA%2Bkindle.tif" width="225"></a></p>
<p><span><br></span>
<span><br>Version 2.0 has now been released and you can read about this <a href="http://www.mrlaulearning.com/2020/06/LBOA2.html" target="_blank">here</a>.&nbsp;</span><br>
<span><br></span>
<span>The text below refers to the original version.</span>
<span><br></span><br>
<span>The Little book of Algorithms is designed to help students build fluency in their Python programming. The book would suit students who have already been introduced to the three basic programming constructs of structured programming, namely sequence, selection and iteration.</span><br>
<span><span><br></span>
<span><span>Following the publishing philosophy of Al Sweigart, "I write books to teach beginners to code. I put them online for free, because programming is too valuable and needs to be accessible to all. (Though I sell print versions to pay rent.)&nbsp;</span></span><span>Get started. It's a great journey."</span></span><br>
<span><span><br></span>
<span>You can buy printed copies directly <a href="https://www.computercombatcards.com/shop" target="_blank">here</a>&nbsp; or via Amazon&nbsp;<a href="https://www.amazon.co.uk/dp/1916116302" target="_blank">here</a>.</span><span><span></span></span></span><br>
<span><span><br></span>
<span>Download the PDF <a href="https://drive.google.com/drive/folders/1FCAfXUKKfVu-i_HzKC9pOaRMM_DjjnvJ?usp=sharing" target="_blank">here</a>&nbsp;which you can print yourself</span></span><br>
<span><span><br></span>
<span>An embedded book is also below:</span></span><br>
<span>

<span><span>Full description:</span></span></span><br>
<span><span><br>This book is designed to help those learning and teaching Computer Science. The aim of the book is to help students build fluency in their Python programming. The book would suit students who have already been introduced to the three basic programming constructs of structured programming, namely sequence, selection and iteration. The learning curve for programming can be quite steep and this book aims to ease this transition by encouraging practise and gradually introducing more complex concepts such as lists and 2D lists, file writing and using procedures and functions. Originally, the book was written for my 14-16 year old students studying for their GCSE Computer Science programming exam. However, I hope a wide range of students and teachers will find this book useful.</span></span></p></div>

</div></div>]]>
            </description>
            <link>http://www.mrlaulearning.com/2019/04/LBOA.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636942</guid>
            <pubDate>Wed, 30 Sep 2020 09:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letter to the Patent Office from Professor Donald Knuth (1994)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24636837">thread link</a>) | @pncnmnp
<br/>
September 30, 2020 | http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html | <a href="https://web.archive.org/web/*/http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2><cite>Programming Freedom</cite> - February 1995 - Number 11</h2>

<p>League For Programming Freedom<br>
1 Kendall Square #143<br>
P.O. Box 9171<br>
Cambridge, MA 02139 </p>

<p><em>Programming Freedom</em> is the Newsletter of The League For Programming Freedom.
Visit our web page: <a href="http://lpf.ai.mit.edu/">http://lpf.ai.mit.edu </a>. 
Reproduction of <em>Programming Freedom</em> via all media is encouraged. To reproduce a signed 
article individually, please contact the author for permission.</p>

<hr>

<h2><a name="knuth">Letter to the Patent Office From Professor Donald Knuth</a></h2>

<p>Professor Donald Knuth of Stanford University is the world's leading authority on
algorithms. His magnum opus, the three volume work the "The Art of Computer
Programming," is the most important reference work on algorithms. Knuth also
developed the mathematical text formatter TeX and the idea of "literate
programming". Supporting evidence of Knuth's position are the following distinctions:

</p><dl>
  <dt>National Medal of Science </dt>
  <dt>Member, National Academy of Sciences </dt>
  <dt>Member, National Academy of Engineering </dt>
  <dt>Fellow, American Academy of Arts and Sciences </dt>
  <dt>Turing Award, Association for Computing Machinery </dt>
  <dt>18 Honorary Doctorates </dt>
</dl>

<p>The first four of these distinctions are the highest American awards for scientists.
Since there is no Nobel prize in computing, the receipt of the Turing award is often
regarded as having a similar status.</p>

<p>Through these honors, Knuth is perhaps the most distinguished living exponent of the
field of computer science. He is also now a member of the League for Programming Freedom.</p>

<p>Here is the letter he sent in February 1994 to the Patent Commissioner on the subject
of software patents.</p>

<pre>Commissioner of Patents and Trademarks
Box 4
Patent and Trademark Office
Washington, DC 20231

Dear Commissioner:

Along with many other computer scientists, I would like to ask you to 
reconsider the current policy of giving patents for computational 
processes.  I find a considerable anxiety throughout the community of 
practicing computer scientists that decisions by the patent courts and the 
Patent and Trademark Office are making life much more difficult for 
programmers.

In the period 1945-1980, it was generally believed that patent law did not 
pertain to software.  However, it now appears that some people have 
received patents for algorithms of practical importance - e.g., Lempel-Ziv 
compression and RSA public key encryption - and are now legally preventing 
other programmers from using these algorithms.

This is a serious change from the previous policy under which the computer 
revolution became possible, and I fear this change will be harmful for 
society.  It certainly would have had a profoundly negative effect on my 
own work: For example, I developed software called TeX that is now used to 
produce more than 90% of all books and journals in mathematics and physics 
and to produce hundreds of thousands of technical reports in all scientific 
disciplines.  If software patents had been commonplace in 1980, I would not 
have been able to create such a system, nor would I probably have ever 
thought of doing it, nor can I imagine anyone else doing so.

I am told that the courts are trying to make a distinction between 
mathematical algorithms and nonmathematical algorithms.  To a computer 
scientist, this makes no sense, because every algorithm is as mathematical 
as anything could be.  An algorithm is an abstract concept unrelated to 
physical laws of the universe.

Nor is it possible to distinguish between "numerical" and "nonnumerical" 
algorithms, as if numbers were somehow different from other kinds of 
precise information.  All data are numbers, and all numbers are data.  
Mathematicians work much more with symbolic entities than with numbers.

Therefore the idea of passing laws that say some kinds of algorithms belong 
to mathematics and some do not strikes me as absurd as the 19th century 
attempts of the Indiana legislature to pass a law that the ratio of a 
circle's circumference to its diameter is exactly 3, not approximately 
3.1416.  It's like the medieval church ruling that the sun revolves about 
the earth.  Man-made laws can be significantly helpful but not when they 
contradict fundamental truths.

Congress wisely decided long ago that mathematical things cannot be 
patented.  Surely nobody could apply mathematics if it were necessary to 
pay a license fee whenever the theorem of Pythagoras is employed.  The 
basic algorithmic ideas that people are now rushing to patent are so 
fundamental, the result threatens to be like what would happen if we 
allowed authors to have patents on individual words and concepts.  
Novelists or journalists would be unable to write stories unless their 
publishers had permission from the owners of the words.  Algorithms are 
exactly as basic to software as words are to writers, because they are the 
fundamental building blocks needed to make interesting products.  What 
would happen if individual lawyers could patent their methods of defense, 
or if Supreme Court justices could patent their precedents?

I realize that the patent courts try their best to serve society when they 
formulate patent law.  The Patent Office has fulfilled this mission 
admirably with respect to aspects of technology that involve concrete laws 
of physics rather than abstract laws of thought.  I myself have a few 
patents on hardware devices.  But I strongly believe that the recent trend 
to patenting algorithms is of benefit only to a very small number of 
attorneys and inventors, while it is seriously harmful to the vast majority 
of people who want to do useful things with computers.

When I think of the computer programs I require daily to get my own work 
done, I cannot help but realize that none of them would exist today if 
software patents had been prevalent in the 1960s and 1970s.  Changing the 
rules now will have the effect of freezing progress at essentially its 
current level.  If present trends continue, the only recourse available to 
the majority of America's brilliant software developers will be to give up 
software or to emigrate.  The U.S.A.  will soon lose its dominant position.

Please do what you can to reverse this alarming trend.  There are far 
better ways to protect the intellectual property rights of software 
developers than to take away their right to use fundamental building 
blocks.

Sincerely,
Donald E. Knuth
Professor Emeritus
</pre>

<hr>

<p><a href="http://lpf.ai.mit.edu/">http://lpf.ai.mit.edu</a>


</p></div>]]>
            </description>
            <link>http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636837</guid>
            <pubDate>Wed, 30 Sep 2020 09:02:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things you should know before beginning with AI projects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636568">thread link</a>) | @danroseai
<br/>
September 30, 2020 | http://www.danrose.ai/blog/6-things-you-should-know-before-beginning-with-ai-projects | <a href="https://web.archive.org/web/*/http://www.danrose.ai/blog/6-things-you-should-know-before-beginning-with-ai-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f743a28e5310349ea445dcf"><div><div><div data-block-type="2" id="block-c8418527ee189da586b5"><div><p>Artificial intelligence(AI) projects are becoming commonplace for big business and entrepreneurs alike. As a result many people with no prior experience with AI are now being put in charge of AI projects. Almost 5 years ago that happened to me for the first time and I’ve since learned a lot. So here’s six things I wish I had known, when I did my first AI project.</p><h2>1. Data is the most expensive part</h2><p>AI is often talked about as being technically very difficult requiring extensive resources to develop. But in fact that’s not the complete truth. The development can be costly but the vast majority of the work and resources needed is usually in acquiring, cleaning and preparing data for the development to take place.&nbsp;<br></p><p>Data is also the most crucial element when trying to make the AI successfully do its job. As a result you should always prefer superior data over superior technology when making AI models.<br></p><p>So when budgeting for an AI project make sure that you set a side most of the time and money for getting a lot of good quality data. And remember that you might even need to acquire fresh data continuously if the domain you work in has changing conditions.</p><h2>2. AI technology is more accessible than you think</h2><p>In a very short time AI have made the jump from requiring specialist data scientists and machine learning engineers to where we can now make AI models without a single line of code. A multitude of AutoML(Automatic machine learning) vendors have appeared in the later years and they are rapidly improving. That means that getting started on AI doesn’t require as much investment as before.&nbsp;<br></p><p>The data acquisition and the human processes, like training and onboarding, still requires hard work though and neither should be underestimated.</p><h2>3. AI is experimental&nbsp;</h2><p>Developing AI is an experimental process. You cannot know how long it will take to develop what you have in mind or how good it will be. In some cases you cannot even be sure that AI is a feasible solution to your problem before trying.&nbsp;<br></p><p>The best way to succeed with uncertain project conditions like this, is to time cap and milestone fund the project. Set short milestones and only release more funds for a project if the goals for each milestone has been met or at least that you see meaningful progress. If you fund the whole project up front you might end up pouring all your money into a dead end that could have been caught early.&nbsp;</p><h2>4. Be clear on what the succes is to your project&nbsp;</h2><p>Before getting started you should be very clear with your stakeholders what a successful project will look like. New technology like AI can quickly be held to golden standards that it will never achieve. If expectations are not aligned before the kick off you might end up thinking you made a fantastic solution while some of your stakeholders are disappointed. In my experience the exact same AI solution can amaze some people and seem novel to others.<br></p><p>A good way to deal with this is to make all stakeholders agree that the first version of the AI should just be able to deliver the status quo. From there you can improve and gradually increase the value.</p><h2>5. Users will lose sense of control</h2><p>It can be hard to explain the inner workings and the reasoning behind an AI’s output. At the same time you cannot exactly know what output it will give, given a specific input. That will make it feel just as or even more unpredictable than humans doing the same tasks. As the users of an AI cannot ask questions or know if feedback given the AI will make a difference, the users will often feel a lost sense of control.&nbsp;<br></p><p>To avoid that feeling you must first of all prepare the user of this new paradigm. It’s much easier if they buy in on these conditions before they get to try the AI. If possible you can also provide feedback mechanisms so the users will at least feel that they can make a difference. Not that it will work every time but it’s better than nothing.&nbsp;<br></p><p>It’s also a good idea to manage expectations through the right narrative. Make it clear if the AI is a decision system, that makes decisions on it’s own or a support system that is just suggesting. By clearly understanding the purpose of the AI the users usually get more comfortable with it quicker.</p><h2>6. People have very different understandings of what AI is&nbsp;</h2><p>As a rule of thumb everyone has a different understanding of AI. The managers, users, developers and all other stakeholders will have their unique understanding of what AI actually is. That’s very fair since AI does not have one definite definition, but it will be a source of problems if everyone involved in a project has a different understanding of what is going on. So before you start a project, make sure not to take for granted that anybody thinks the way you do. Be explicit about what AI means to you and how you will approach it.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>http://www.danrose.ai/blog/6-things-you-should-know-before-beginning-with-ai-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636568</guid>
            <pubDate>Wed, 30 Sep 2020 08:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Dark Side of ITER]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24636418">thread link</a>) | @olvy0
<br/>
September 30, 2020 | https://news.newenergytimes.net/2020/06/15/the-dark-side-of-iter/ | <a href="https://web.archive.org/web/*/https://news.newenergytimes.net/2020/06/15/the-dark-side-of-iter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
<p><img src="http://newenergytimes.com/v2/images/ITER-dark.jpg"></p>
<p><a href="http://news.newenergytimes.net/iter-fusion-power-output-consumption-facts-and-falsehoods/">Return to ITER Power Facts Main Page</a></p>
<p><strong>Summary</strong></p>
<p>Since at least 1993, scientists representing the nuclear fusion community have convinced members of the U.S. Congress that the International Thermonuclear Experimental Reactor (ITER), under construction in Southern France, is designed to produce 500 million Watts of thermal power, ten times more electrical power than the reactor is designed to consume.</p>
<p>This is not true.</p>
<p>Later, other fusion scientists convinced the European Parliament and European Commission to publish similar falsehoods about ITER. In fact, the <a href="http://newenergytimes.com/v2/sr/iter/ITER-fusion-reactor-effects.shtml">list of organizations</a> that have, as a result of the fusion scientists’ <a href="http://newenergytimes.com/v2/sr/iter/ITER-fusion-reactor-causes.shtml">claims</a>, inadvertently published falsehoods about ITER in the last decade is extensive.</p>
<p>As revealed by <em>New Energy Times</em> in 2017 and in a subsequent 2019 statement from the United Kingdom Atomic Energy Authority, if the ITER reactor works according to design, the ITER reactor should produce about as much power from fusion as the electricity required to operate the entire device. A statement by a Japanese government fusion organization also describes the expected overall device power balance accurately: “ITER is about equivalent to a zero (net) power reactor, when the plasma is burning.” A German government document uncovered by <em>New Energy Times</em> also reveals that the reactor’s overall output will be equivalent to zero net power.</p>
<p>The actual design goal for the ITER reactor is to create a plasma of 500 megawatts (thermal) for around twenty minutes while 50 megawatts of thermal power are injected into the tokamak, resulting in a ten-fold gain of plasma heating power, not reactor power.</p>
<p>The enormity of this false science claim, in terms of involved scientists, expenditure of taxpayer funds from China, the European Union, India, Japan, Korea, Russia, and the United States is unprecedented and is therefore difficult to conceive. Deception and fraud are ugly words that nobody in the scientific world wants to be associated with. Nevertheless, over the course of three decades, it happened.</p>
<p>Much like the perpetual motion frauds from a century ago, which employed hidden mechanical devices to supply power, scientists promoting ITER have hidden the reactor’s expected input power through specific wording, omitted facts, undisclosed terminology, and deceit.</p>
<p>“<a href="http://newenergytimes.com/v2/sr/iter/The-Dark-Side-of-ITER-20200615.pdf">The Dark Side of ITER</a>,” published on June 15, 2020, by Steven B. Krivit, editor of <em>New Energy Times</em>, explains what happened.</p>
			</div><!--/entry -->
		</div></div>]]>
            </description>
            <link>https://news.newenergytimes.net/2020/06/15/the-dark-side-of-iter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636418</guid>
            <pubDate>Wed, 30 Sep 2020 07:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Is Never a Compiler Bug Until It Is]]>
            </title>
            <description>
<![CDATA[
Score 236 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24636326">thread link</a>) | @nullc
<br/>
September 30, 2020 | http://r6.ca/blog/20200929T023701Z.html | <a href="https://web.archive.org/web/*/http://r6.ca/blog/20200929T023701Z.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Last week I was trying to add some <a href="https://github.com/bitcoin-core/secp256k1/pull/822/commits/aa833603a6b4c947c21da04aeac40d80444ebcc1#diff-b04459e37839cd223176618536295715R425">testing code to libsecp256k1</a> and I was pulling out my hair trying to get it to work.
No amount of <code>printf</code> was working to illuminate what I was doing wrong.
Finally, out of desperation, I thought I would do a quick check to see if there are any compiler bugs related to <code>memcmp</code>, and lo and behold, I found <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95189">GCC bug #95189: memcmp being wrongly stripped like strcmp</a>.</p><p>Honestly this was a pretty horrifying bug to read about.
Under some circumstances GCC 9 and 10 will cause <code>memcmp</code> to return an incorrect value when one of the inputs is statically known array that contains <code>NULL</code> bytes.
As I rushed to <a href="https://gist.githubusercontent.com/roconnor/2b8e22e829ed80088ed6690cc3c7f3a8/raw/455571a6d9053c597c1585debe6f9dbd6af85071/gistfile1.txt">recompile my computer system using GCC 8</a>, I contemplated the vast consequences of such a bug could be, and pondered how it was possible that computers could function at all.</p><p>However over the week, with the help of my colleagues, we managed to get a better understanding of the scope of the bug.
The bug can only convert non-zero values to zero values.
The static array needs to have a <code>NULL</code> byte within the first 4 bytes.
Most importantly, the <code>memcmp</code> result must not immediately be compared to <code>0</code> for equality or inequality, or any equivalent test.
A different code path is taken in the compiler in that case.
That explained why computers were still functioning.
I expect the vast majority of the uses of <code>memcmp</code> does an immediate test for equality with <code>0</code>.</p><p>I still wondered though, how much code was being affected. My colleague Tim suggested that it would be possible to instrument GCC to emit a message when it was about to miscompile a program.
Together we came up with <a href="https://gcc.gnu.org/bugzilla/attachment.cgi?id=49276&amp;action=diff">a patch</a> to GCC 9 and 10 that would print a debugging message.
Once again, I recompiled my entire system, to see what GCC was miscompiling.
This is what I found:</p><ul>
<li><a href="https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709">https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709</a></li>
<li><a href="https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310">https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310</a></li>
<li><a href="https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172">https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172</a></li>
<li><a href="https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425">https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425</a></li>
<li><a href="https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70">https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70</a></li>
<li><a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279</a></li>
<li><a href="https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203">https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203</a></li>
<li><a href="https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412">https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412</a></li>
</ul>
<p>On my entire system I only found 10 lines of code that were miscompiled.
Three lines are tests.
All of the lines could be rewritten as a comparison to 0.
None of the lines looked that serious.
I am not sure which one is the worse: the reduced message integrity code(?) from some ARCFOUR implementation or the something something from an ATM driver?</p><p>The mplayer miscompilation is the most mysterious.
The code surrounding that function all appears to be immediately compare <code>memcmp</code> with <code>0</code>.
And given that my debug message refused to point to exactly what line is being miscompiled in that function, I fear some set of optimizations has happened to allow this code to be miscompiled in some way.</p><p>With more hardware I could do <a href="https://hydra.nixos.org/jobset/nixpkgs/trunk#tabs-jobs">a more thorough investigation</a> of the consequences of this GCC bug.
Until then I am going to stick with GCC 8 until GCC 9 and 10 have a new point releases.

</p></div></div>]]>
            </description>
            <link>http://r6.ca/blog/20200929T023701Z.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636326</guid>
            <pubDate>Wed, 30 Sep 2020 07:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deutsch's Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636246">thread link</a>) | @keyboardman
<br/>
September 29, 2020 | https://leimao.github.io/blog/Deutsch-Algorithm/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Deutsch-Algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Deutsch’s algorithm is the simplest quantum computing algorithm invented to solve a slightly contrived problem. Suppose we have a black-box function $f(x)$ which maps from the set $\{0,1\}$ to the set $\{0,1\}$. It is easy to speculate that there are four possible mappings for $f(x)$. We call the function $f(x)$ constant if $f(0) = f(1)$, otherwise we call the function $f(x)$ balanced.</p>



<p>With classical circuits, we would have to run the black-box $f(x)$ twice to evaluate $f(0)$ and $f(1)$ and compare the values of $f(0)$ and $f(1)$ to see if they are equivalent or not. With quantum circuits, because we could take advantage of superposition, probably we could do better with fewer runs and operations.</p>



<p>In this blog post, I would like to discuss the Deutsch’s algorithm.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="separable-and-entangled-states">Separable and Entangled States</h4>

<p>States that can be broken into the Kronecker product of states from the constituent subsystems are called separable states, whereas states that are unbreakable are referred to as entangled states.</p>



<p>For example, we have the following two states $| \psi \rangle$ and $| \psi^{\prime} \rangle$.</p><p>

\[\begin{align}
| \psi \rangle &amp;= \frac{| 0, 0 \rangle - | 0, 1 \rangle + | 1, 0 \rangle - | 1, 1 \rangle}{2}\\
&amp;= \frac{| 0\rangle \otimes | 0 \rangle - | 0\rangle \otimes | 1 \rangle + | 1\rangle \otimes | 0 \rangle - | 1\rangle \otimes | 1 \rangle}{2}\\
&amp;= \frac{| 0 \rangle + | 1 \rangle}{\sqrt{2}} \otimes \frac{| 0 \rangle - | 1 \rangle}{\sqrt{2}} \\
| \psi^{\prime} \rangle &amp;= \frac{| 0, 1 \rangle + | 1, 0 \rangle}{\sqrt{2}}\\
\end{align}\]

</p><p>$| \psi \rangle$ is separable and $| \psi^{\prime} \rangle$ is entangled.</p>

<h4 id="unitary-quantum-operator">Unitary Quantum Operator</h4>

<p>Every quantum operator $U$ is unitary and thus reversible. Because $UU^{\dagger} = U^{\dagger}U = I$, we have</p><p>

\[\begin{align}
U^{\dagger} (U |\varphi\rangle) &amp;= (U^{\dagger} U) |\varphi\rangle \\
&amp;= I |\varphi\rangle \\ 
&amp;= |\varphi\rangle \\ 
\end{align}\]

</p><h4 id="hadamard-operator">Hadamard Operator</h4>

<p>Hardmard operator is a special quantum operator.</p><p>

\[\begin{align}
H &amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  
\end{align}\]

</p><p>Notice that $H^{\dagger} = H$, therefore</p><p>

\[\begin{align}
H^{\dagger} (H |\varphi\rangle) &amp;= H (H |\varphi\rangle) \\
&amp;= (H^2) |\varphi\rangle \\
&amp;= I |\varphi\rangle \\ 
&amp;= |\varphi\rangle \\ 
\end{align}\]

\[\begin{align}
H|0\rangle &amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  
\begin{bmatrix} 
    1 \\
    0 \\
\end{bmatrix}  \\
&amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} \\
\end{bmatrix}  \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}}
\end{align}\]

\[\begin{align}
H\frac{|0\rangle + |1\rangle}{\sqrt{2}} &amp;= HH|0\rangle \\
&amp;= I|0\rangle \\
&amp;= |0\rangle \\
\end{align}\]

\[\begin{align}
H|1\rangle &amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  
\begin{bmatrix} 
    0 \\
    1 \\
\end{bmatrix}  \\
&amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} \\
    -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  \\
&amp;= \frac{|0\rangle - |1\rangle}{\sqrt{2}}
\end{align}\]

\[\begin{align}
H\frac{|0\rangle - |1\rangle}{\sqrt{2}} &amp;= HH|1\rangle \\
&amp;= I|1\rangle \\
&amp;= |1\rangle \\
\end{align}\]

</p><h4 id="reducing-sum-or-difference-to-boolean">Reducing Sum or Difference to Boolean</h4>

<p>If $f(x)$ maps from the set $\{0,1\}$ to the set $\{0,1\}$, we have</p><p>

\[\begin{align}
(-1)^{f(1) - f(0)} = (-1)^{f(0) \oplus f(1)}
\end{align}\]

</p><p>Where $\oplus$ is $\text{XOR}$ (binary addition modulo 2).</p>

<h3 id="deutschs-algorithm">Deutsch’s Algorithm</h3>

<p>The black-box $f(x)$ is represented using a quantum gate $U_f$. Just like the classical gate for $f(x)$, it has four possible candidates. Our job is to determine whether the $f(x)$ corresponding to the $U_f$ is constant or balanced.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-23-Deutsch-Algorithm/Uf.png">
    <figcaption>$U_f$</figcaption>
</figure>
</div>

<p>The quantum gate $U_f$ is a unitary matrix which maps from $| x \rangle \otimes | y \rangle$ to $| x \rangle \otimes | y \oplus f(x) \rangle$, namely $U_f (| x \rangle \otimes | y \rangle) = | x \rangle \otimes | y \oplus f(x) \rangle$, for $x, y \in \{0, 1\}$. When $y = 0$, $| y \oplus f(x) \rangle = | 0 \oplus f(x) \rangle = | f(x) \rangle $, $| y \oplus f(x) \rangle$ is just $| f(x) \rangle$.</p>



<p>Note that the above mapping is only valid when $| x \rangle$ and $| y \rangle$ are basic qubit states $| 0 \rangle$ or $| 1 \rangle$. When $| x \rangle$ and $| y \rangle$ are superpositions, the mapping does not necessarily hold.</p>



<p>Let’s further check when $| x \rangle$ and $| y \rangle$ are superpositions, what the outputs from $U_f$ will be. Perhaps we could achieve fewer runs with superpositions.</p>

<h4 id="first-attempt">First Attempt</h4>

<p>In the first attempt, we made the first qubit input to $U_f$ a superposition, which is achieved by applying a Hadamard operator to the input basic state $|0\rangle$. The superposition is</p><p>

\[\begin{align}
H|0\rangle &amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}}
\end{align}\]

</p><p>The second qubit input to $U_f$ is just a normal  basic state $|0\rangle$.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-23-Deutsch-Algorithm/attempt-1.png">
    <figcaption>First Attempt</figcaption>
</figure>
</div><p>

\[\begin{align}
|\varphi_0\rangle &amp;= |0\rangle \otimes |0\rangle\\
&amp;= |0, 0\rangle \\
\end{align}\]

\[\begin{align}
|\varphi_1\rangle &amp;= (H \otimes I) |\varphi_0\rangle \\
&amp;= (H \otimes I) (|0\rangle \otimes |0\rangle) \\
&amp;= H|0\rangle \otimes I |0\rangle \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}} \otimes |0\rangle \\
&amp;= \frac{|0\rangle \otimes |0\rangle + |1\rangle \otimes |0\rangle }{\sqrt{2}} \\
&amp;= \frac{|0, 0\rangle + |1, 0\rangle}{\sqrt{2}} \\
\end{align}\]

\[\begin{align}
|\varphi_2\rangle &amp;= U_f |\varphi_1\rangle \\
&amp;= U_f \frac{|0, 0\rangle + |1, 0\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f |0, 0\rangle + U_f |1, 0\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f (|0\rangle \otimes |0\rangle) + U_f (|1\rangle \otimes |0\rangle)}{\sqrt{2}} \\
&amp;= \frac{|0\rangle \otimes |0 \oplus f(0)\rangle + |1\rangle \otimes |0 \oplus f(1)\rangle}{\sqrt{2}} \\
&amp;= \frac{|0\rangle \otimes |f(0)\rangle + |1\rangle \otimes |f(1)\rangle}{\sqrt{2}} \\
&amp;= \frac{|0, f(0)\rangle + |1, f(1)\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>If $f(0) = 0$, $f(1) = 1$, one of the balanced cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 0\rangle + |1, 1\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>Note that this $|\varphi_2\rangle$ is entangled and could be be expressed as the Kronecker product of two qubits. The first qubit output from $U_f$ is not $H|0\rangle$ either. In fact it could not be described using single qubit! The two qubits must be described as a whole due to quantum entanglement. When we observe either the first qubit output or the second qubit output, we immediately know the observation of the other qubit. For example, if we observed the second qubit is 0, we know the observation of the first qubit must be 0. There are 50-50 percent chance observing 0 or 1 for both the first qubit and the second qubit.</p>



<p>If $f(0) = 1$, $f(1) = 0$, one of the balanced cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 1\rangle + |1, 0\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>This $|\varphi_2\rangle$ is entangled and there are 50-50 percent chance observing 0 or 1 for both the first qubit and the second qubit.</p>



<p>If $f(0) = 0$, $f(1) = 0$, one of the constant cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 0\rangle + |1, 0\rangle}{\sqrt{2}} \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}} \otimes |0\rangle\\
&amp;= \frac{-|0\rangle - |1\rangle}{\sqrt{2}} \otimes (-|0\rangle)\\
\end{align}\]

</p><p>This $|\varphi_2\rangle$ is separable. Although we are not sure the exact state the two qubit outputs would be in, due to the phase is not defined, we are sure that the observation of the bottom qubit must be 0.</p>



<p>If $f(0) = 1$, $f(1) = 1$, one of the constant cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 1\rangle + |1, 1\rangle}{\sqrt{2}} \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}} \otimes |1\rangle\\
&amp;= \frac{-|0\rangle - |1\rangle}{\sqrt{2}} \otimes (-|1\rangle)\\
\end{align}\]

</p><p>This $|\varphi_2\rangle$ is separable. Although we are not sure the exact state the two qubit outputs would be in, due to the phase is not defined, we are sure that the observation of the bottom qubit must be 1.</p>



<p>However, all of these are not helpful if we are only allowed to run once. After running once, no matter what we observed from the first qubit and the second qubit, we are not sure whether $f(x)$ is constant or balanced.</p>

<h4 id="second-attempt">Second Attempt</h4>

<p>In the second attempt, we made the second qubit input to $U_f$ a superposition, which is achieved by applying a Hadamard operator to the input basic state $|1\rangle$. The superposition is</p><p>

\[\begin{align}
H|1\rangle &amp;= \frac{|0\rangle - |1\rangle}{\sqrt{2}}
\end{align}\]

</p><p>The second qubit input to $U_f$ is a variable and it could be either $|0\rangle$ or $|1\rangle$.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-23-Deutsch-Algorithm/attempt-2.png">
    <figcaption>Second Attempt</figcaption>
</figure>
</div><p>

\[\begin{align}
|\varphi_0\rangle &amp;= |x\rangle \otimes |1\rangle\\
&amp;= |x, 1\rangle \\
\end{align}\]

\[\begin{align}
|\varphi_1\rangle &amp;= (I \otimes H) |\varphi_0\rangle \\
&amp;= (I \otimes H) (|x\rangle \otimes |1\rangle) \\
&amp;= I|x\rangle \otimes H |1\rangle \\
&amp;= |x\rangle \otimes \frac{|0\rangle - |1\rangle}{\sqrt{2}} \\
&amp;= \frac{|x, 0\rangle - |x, 1\rangle}{\sqrt{2}} \\
\end{align}\]

\[\begin{align}
|\varphi_2\rangle &amp;= U_f |\varphi_1\rangle \\
&amp;= U_f \frac{|x, 0\rangle - |x, 1\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f |x, 0\rangle - U_f |x, 1\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f (|x\rangle \otimes |0\rangle) - U_f (|x\rangle \otimes |1\rangle)}{\sqrt{2}} \\
&amp;= \frac{|x\rangle \otimes |0 \oplus f(x)\rangle - |x\rangle \otimes |1 \oplus f(x)\rangle}{\sqrt{2}} \\
&amp;= \frac{|x\rangle \otimes |f(x)\rangle - |x\rangle \otimes |\overline{f(x)}\rangle}{\sqrt{2}} \\
&amp;= |x\rangle \otimes \frac{|f(x)\rangle - |\overline{f(x)}\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>Because $\frac{|f(x)\rangle - |\overline{f(x)}\rangle}{\sqrt{2}}$ is either $\frac{|0\rangle - |1\rangle}{\sqrt{2}}$ or $\frac{|1\rangle - |0\rangle}{\sqrt{2}}$, $|\varphi_2\rangle $ could be further simplified as</p><p>

\[\begin{align}</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Deutsch-Algorithm/">https://leimao.github.io/blog/Deutsch-Algorithm/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Deutsch-Algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636246</guid>
            <pubDate>Wed, 30 Sep 2020 06:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding How UUIDs Are Generated]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24636204">thread link</a>) | @aryamansharda
<br/>
September 29, 2020 | https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/ | <a href="https://web.archive.org/web/*/https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636204</guid>
            <pubDate>Wed, 30 Sep 2020 06:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A categorized list of all Java and JVM features since JDK 8 to 15]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636197">thread link</a>) | @pjmlp
<br/>
September 29, 2020 | https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/ | <a href="https://web.archive.org/web/*/https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><strong>Last updated</strong> on 2020/09/29 to include changes up to <a href="https://openjdk.java.net/projects/jdk/15/">JDK 15</a>.</p> <p>Since the release of version 8, up to version 15, Java is shaped by 163 <a href="http://openjdk.java.net/jeps/0">JDK Enhancement Proposals</a> (JEPs), each of which brings some improvement to the platform. This page is a <strong>categorized</strong> and <strong>curated</strong> list of the most important improvements.</p> <p><img alt="JDK timeline" integrity="sha256-LaVVHICMYi3voV98aHwg0mrUzl6D7m+MpNnEXwTXOWk=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/post_java_8/jdktimeline-v3-2da5551c808c622defa15f7c687c20d26ad4ce5e83ee6f8ca4d9c45f04d73969.jpg"></p> <p><strong>Contents of this page:</strong></p> <ul> <li><a href="#new-language-features">New Language Features</a></li> <li><a href="#new-apis">New APIs</a></li> <li><a href="#performance-improvements">Performance Improvements</a></li> <li><a href="#security-improvements">Security Improvements</a></li> <li><a href="#bytecode">Bytecode Changes</a></li> <li><a href="#launching">Launching</a></li> <li><a href="#packaging">Packaging</a></li> <li><a href="#javadoc">Javadoc</a></li> <li><a href="#new-supported-platforms">New Platforms</a></li> <li><a href="#deprecation-and-removal">Deprecation and Removal</a></li> <li><a href="#new-version-scheme">New Version Scheme</a></li> </ul> <p>The full list of JEPs can be found on the OpenJDK website under the <a href="https://openjdk.java.net/projects/jdk/">jdk</a> and <a href="https://openjdk.java.net/projects/jdk9/">jdk9</a> projects.</p> <p>All features are generally available and enabled by default, except if they are labelled with one of the following:</p> <ul> <li> <strong>Preview</strong> 🔍 features are fully specified and implemented, but not yet considered to be final. They are considered to be almost complete, waiting for an additional round of real-world feedback. They have to be <a href="https://openjdk.java.net/jeps/12">explicitly enabled</a>.</li> <li> <strong>Experimental</strong> 💥 features are less stable, and more likely to change. They also have to be explicitly enabled.</li> <li> <strong>Incubator</strong> 🥚 modules are non-final tools and API’s, and are <a href="https://openjdk.java.net/jeps/11">distributed in separate modules</a>.</li> </ul> <h2 id="new-language-features">New Language Features</h2> <p>When Java 8 introduced lambdas it was a pretty huge change. While recent versions did not add such impactful features, lots of smaller improvements were made to the language.</p> <p>Here’s a quick recap on what happened in the last years. For a more in-depth guide, see <a href="https://advancedweb.hu/new-language-features-since-java-8-to-14/">New language features since Java 8</a>.</p><div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/new-language-features-since-java-8-to-14/"> <img integrity="sha256-Ko5UWYfecL05QXbtkFEINWvtXxZRNvydy8FQEPm7Vsw=" crossorigin="anonymous" src="https://advancedweb.hu/assets/53487f-15f99cf9213eacf6f30f40e8d76a4dea7f587df024e1fe2ffa4cf085fa462d21.jpg"> </a> </p> <div>  <p> Enhancements to the Java language you should know </p> </div> </div> </div> <ul> <li>Text Blocks<br> <a href="https://openjdk.java.net/jeps/378">JDK 15</a> (Preview in <a href="https://openjdk.java.net/jeps/368">JDK 14</a> <a href="https://openjdk.java.net/jeps/355">JDK 13</a>) <div> <div><pre><code><span>String</span> <span>html</span> <span>=</span> <span>"""
            &lt;html&gt;
                &lt;body&gt;
                    &lt;p&gt;Hello, world&lt;/p&gt;
                &lt;/body&gt;
            &lt;/html&gt;
            """</span><span>;</span>
</code></pre></div> </div> </li> <li>Sealed Classes can restrict which other classes may extend them (<strong>Preview</strong> 🔍)<br> <a href="https://openjdk.java.net/jeps/360">JDK 15</a> <div> <div><pre><code><span>public</span> <span>abstract</span> <span>sealed</span> <span>class</span> <span>Shape</span>
    <span>permits</span> <span>Circle</span><span>,</span> <span>Rectangle</span> <span>{...}</span>

<span>public</span> <span>class</span> <span>Circle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// OK</span>
<span>public</span> <span>class</span> <span>Rectangle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// OK</span>
<span>public</span> <span>class</span> <span>Triangle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// Compile error</span>

<span>// No need for default case if all permitted types are covered</span>
<span>double</span> <span>area</span> <span>=</span> <span>switch</span> <span>(</span><span>shape</span><span>)</span> <span>{</span>
    <span>case</span> <span>Circle</span> <span>c</span>    <span>-&gt;</span> <span>Math</span><span>.</span><span>pow</span><span>(</span><span>c</span><span>.</span><span>radius</span><span>(),</span> <span>2</span><span>)</span> <span>*</span> <span>Math</span><span>.</span><span>PI</span>
    <span>case</span> <span>Rectangle</span> <span>r</span> <span>-&gt;</span> <span>r</span><span>.</span><span>a</span><span>()</span> <span>*</span> <span>r</span><span>.</span><span>b</span><span>()</span>
<span>};</span>
</code></pre></div> </div> </li> <li>Records (<strong>Preview</strong> 🔍)<br> <a href="https://openjdk.java.net/jeps/384">JDK 15</a> <a href="https://openjdk.java.net/jeps/359">JDK 14</a> <div> <div><pre><code><span>record</span> <span>Point</span><span>(</span><span>int</span> <span>x</span><span>,</span> <span>int</span> <span>y</span><span>)</span> <span>{</span> <span>}</span>
</code></pre></div> </div> </li> <li>Pattern Matching for instanceof (<strong>Preview</strong> 🔍)<br> <a href="https://openjdk.java.net/jeps/375">JDK 15</a> <a href="https://openjdk.java.net/jeps/305">JDK 14</a> <div> <div><pre><code><span>if</span> <span>(</span><span>obj</span> <span>instanceof</span> <span>String</span> <span>s</span><span>)</span> <span>{</span>
    <span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>"obj is a String and it' length is "</span> <span>+</span> <span>s</span><span>.</span><span>length</span><span>());</span>
<span>}</span>
</code></pre></div> </div> </li> <li>Switch Expressions<br> <a href="https://openjdk.java.net/jeps/361">JDK 14</a> (Preview in <a href="https://openjdk.java.net/jeps/325">JDK 12</a> <a href="https://openjdk.java.net/jeps/354">JDK 13</a>) <div> <div><pre><code><span>int</span> <span>numLetters</span> <span>=</span> <span>switch</span> <span>(</span><span>day</span><span>)</span> <span>{</span>
    <span>case</span> <span>MONDAY</span><span>,</span> <span>FRIDAY</span><span>,</span> <span>SUNDAY</span> <span>-&gt;</span> <span>6</span><span>;</span>
    <span>case</span> <span>TUESDAY</span>                <span>-&gt;</span> <span>7</span><span>;</span>
    <span>default</span>      <span>-&gt;</span> <span>{</span>
      <span>String</span> <span>s</span> <span>=</span> <span>day</span><span>.</span><span>toString</span><span>();</span>
      <span>int</span> <span>result</span> <span>=</span> <span>s</span><span>.</span><span>length</span><span>();</span>
      <span>yield</span> <span>result</span><span>;</span>
    <span>}</span>
<span>};</span>
</code></pre></div> </div> </li> <li>Helpful NullPointerExceptions describing precisely which variable was null<br> <a href="https://bugs.openjdk.java.net/browse/JDK-8233014">JDK 15</a> (Enabled with <code>-XX:+ShowCodeDetailsInExceptionMessages</code> in <a href="https://openjdk.java.net/jeps/358">JDK 14</a>) <div> <div><pre><code><span>a</span><span>.</span><span>b</span><span>.</span><span>c</span><span>.</span><span>i</span> <span>=</span> <span>99</span><span>;</span>
<span>---</span>
<span>Exception</span> <span>in</span> <span>thread</span> <span>"main"</span> <span>java</span><span>.</span><span>lang</span><span>.</span><span>NullPointerException</span><span>:</span>
      <span>Cannot</span> <span>read</span> <span>field</span> <span>"c"</span> <span>because</span> <span>"a.b"</span> <span>is</span> <span>null</span>
</code></pre></div> </div> </li> <li>Introduction of <code>var</code> to make local variable declarations less ceremonious<br> <a href="https://openjdk.java.net/jeps/323">JDK 11</a> (Without lambda support in <a href="https://openjdk.java.net/jeps/286">JDK 10</a>) <div> <div><pre><code><span>var</span> <span>greeting</span> <span>=</span> <span>"Hello World!"</span><span>;</span>
</code></pre></div> </div> </li> <li>Opt-in and backwards-compatible Module System to avoid <code>ClassDefNotFoundErrors</code> at runtime and create internal APIs<br> <a href="https://openjdk.java.net/jeps/261">JDK 9</a> (Project Jigsaw) <div> <div><pre><code><span>module</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>helloworld</span> <span>{</span>
    <span>requires</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>somedependency</span><span>;</span>
    <span>exports</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>hello</span>
<span>}</span>
</code></pre></div> </div> </li> <li> <p>Private methods in interfaces<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p>Diamond operator for anonymous inner classes<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p>Try-with-resources allows effectively final variables<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p><code>@SafeVargs</code> on private instance methods<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li>No deprecation warnings on <code>import</code> statements<br> <a href="https://openjdk.java.net/jeps/211">JDK 9</a> </li> </ul> <p> We write articles like this regularly. <a href="#bottom-promo">Join our mailing list</a> and let's keep in touch. </p> <h2 id="new-apis">New APIs</h2> <p>Let’s continue with the Java Standard Library, focusing on the new features that we can use in day-to-day coding.</p> <p>If you are curious about all the API level differences between Java 8 and 14, check the <a href="https://github.com/AdoptOpenJDK/jdk-api-diff">AdoptOpenJDK/jdk-api-diff on GitHub</a>.</p> <h3 id="general">General</h3> <ul> <li> <p>Support Non-Volatile Mapped Byte Buffers in the FileChannel API<br> <a href="https://openjdk.java.net/jeps/352">JDK 14</a></p> </li> <li> <p><code>Files.mismatch</code>: find the first mismatched byte in the content of two files<br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/nio/file/Files.html">JDK 12</a></p> </li> <li> <p><code>Collectors.teeing</code> to create a Collector that is a composite of two downstream collectors<br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/stream/Collectors.html#teeing(java.util.stream.Collector,java.util.stream.Collector,java.util.function.BiFunction)">JDK 12</a></p> </li> <li> <p>String enhancements: <code>indent</code> and <code>transform</code><br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/lang/String.html">JDK 12</a></p> </li> <li>Standard HTTP Client featuring HTTP/2, WebSocket support and non-blocking API<br> <a href="https://openjdk.java.net/jeps/321">JDK 11</a> (<strong>Incubator</strong> 🥚 in <a href="https://openjdk.java.net/jeps/110">JDK 9</a>) <div> <div><pre><code><span>HttpClient</span> <span>httpClient</span> <span>=</span> <span>HttpClient</span><span>.</span><span>newBuilder</span><span>().</span><span>build</span><span>();</span>

<span>HttpRequest</span> <span>request</span> <span>=</span>
  <span>HttpRequest</span><span>.</span><span>newBuilder</span><span>()</span>
    <span>.</span><span>uri</span><span>(</span><span>URI</span><span>.</span><span>create</span><span>(</span><span>"https://advancedweb.hu/"</span><span>))</span>
    <span>.</span><span>GET</span><span>()</span>
    <span>.</span><span>build</span><span>();</span>

<span>HttpResponse</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>response</span> <span>=</span>
  <span>httpClient</span><span>.</span><span>send</span><span>(</span><span>request</span><span>,</span> <span>BodyHandlers</span><span>.</span><span>ofString</span><span>());</span>
</code></pre></div> </div> </li> <li> <p>String enhancements, like <code>isBlank</code>, <code>lines</code>, <code>repeat</code> and <code>strip</code><br> <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html">JDK 11</a></p> </li> <li>Convenience Factory Methods for Collections to ease the pain of not having collection literals<br> <a href="https://openjdk.java.net/jeps/269">JDK 9</a> <div> <div><pre><code><span>Set</span><span>&lt;</span><span>Integer</span><span>&gt;</span> <span>mySet</span> <span>=</span> <span>Set</span><span>.</span><span>of</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>);</span>
<span>List</span><span>&lt;</span><span>Integer</span><span>&gt;</span> <span>myList</span> <span>=</span> <span>List</span><span>.</span><span>of</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>);</span>
<span>Map</span><span>&lt;</span><span>String</span><span>,</span> <span>Integer</span><span>&gt;</span> <span>myMap</span> <span>=</span> <span>Map</span><span>.</span><span>of</span><span>(</span><span>"one"</span><span>,</span> <span>1</span><span>,</span> <span>"two"</span><span>,</span> <span>2</span><span>);</span>
</code></pre></div> </div> </li> <li> <p>Reactive Streams publish-subscribe framework for asynchronous stream processing with non-blocking backpressure<br> <a href="https://openjdk.java.net/jeps/266">JDK 9</a></p> </li> <li> <p>Time-based enhancements to <code>CompletableFuture</code> (timeout, delay)<br> <a href="https://openjdk.java.net/jeps/266">JDK 9</a></p> </li> <li> <p>More options to transform (<code>dropWhile</code>, <code>takeWhile</code>) and generate (<code>iterate</code>, <code>ofNullable</code>) streams; readonly collectors (<code>toUnmodifiableList</code>); optionals can be transformed to streams<br> <a href="https://docs.oracle.com/javase/9/docs/api/java/util/stream/Stream.html#iterate-T-java.util.function.UnaryOperator-">JDK 9</a></p> </li> <li> <p><code>Arrays.mismatch</code>: find the first mismatching element between two arrays<br> <a href="https://docs.oracle.com/javase/9/docs/api/java/util/Arrays.html#mismatch-java.lang.Object:A-java.lang.Object:A-">JDK 9</a></p> </li> <li> <p>Stack-Walking API that allows laziness and stack-frame filtering<br> <a href="https://openjdk.java.net/jeps/259">JDK 9</a></p> </li> <li> <p>Process API provides more info and control (e.g. process ID, arguments, CPU time, parent/child processes), enhance <code>ProcessBuilder</code> to aid the creation of process pipelines<br> <a href="https://openjdk.java.net/jeps/102">JDK 9</a></p> </li> <li> <p><code>VarHandle</code> API to replace the field and array related operations of <code>java.util.concurrent.atomic</code> and <code>sun.misc.Unsafe</code> in order to and provide low-level access mechamisms, e.g. atomic write.<br> <a href="https://openjdk.java.net/jeps/193">JDK 9</a></p> </li> <li> <p>New combinators and lookup methods for <code>MethodHandle</code><br> <a href="https://openjdk.java.net/jeps/274">JDK 9</a></p> </li> <li> <p>Enhanced Deprecation policy. <code>@Deprecated</code> can be marked with <code>forRemoval</code>, which emits a new warning.<br> <a href="https://openjdk.java.net/jeps/277">JDK 9</a></p> </li> <li> <p>OASIS Standard XML Catalog API to manage external resources in XMLs in a secure and performant manner<br> <a href="https://openjdk.java.net/jeps/268">JDK 9</a></p> </li> <li> <p>Update JDK’s XML parser, Xerces, to version 2.11.0<br> <a href="https://openjdk.java.net/jeps/255">JDK 9</a></p> </li> <li>TIFF Support for Image I/O Framework<br> <a href="https://openjdk.java.net/jeps/262">JDK 9</a> </li> </ul> <h3 id="internationalization">Internationalization</h3> <ul> <li> <p>Unicode 10.0, adding roughly 27.000 characters, 10 blocks, and more than 30 scripts<br> <a href="https://openjdk.java.net/jeps/327">JDK 11</a> (Unicode 8.0 support in <a href="https://openjdk.java.net/jeps/267">JDK 9</a>)</p> </li> <li> <p><code>java.util.Locale</code> and related APIs support currency type, time zone and more<br> <a href="https://openjdk.java.net/jeps/314">JDK 10</a></p> </li> <li> <p><code>ResourceBundle</code> loads properties files in UTF-8 instead of ISO-8859-1<br> <a href="https://openjdk.java.net/jeps/226">JDK 9</a></p> </li> <li> <p>CLDR Locale Data Enabled by Default<br> <a href="https://openjdk.java.net/jeps/252">JDK 9</a></p> </li> </ul> <h3 id="graphics-and-desktop-applications">Graphics and Desktop Applications</h3> <ul> <li> <p>Desktop features for all platforms like login/logout/lock event listener and task bar interactions<br> <a href="https://openjdk.java.net/jeps/272">JDK 9</a></p> </li> <li> <p><code>MultiResolutionImage</code> that makes easy to retrieve a resolution-specific image for a DPI<br> <a href="https://openjdk.java.net/jeps/251">JDK 9</a></p> </li> <li> <p>HiDPI Graphics on Windows and Linux<br> <a href="https://openjdk.java.net/jeps/263">JDK 9</a></p> </li> <li> <p>Enable GTK 3 on Linux for JavaFX, Swing, and AWT<br> <a href="https://openjdk.java.net/jeps/283">JDK 9</a></p> </li> <li> <p>Replace <code>@beaninfo</code> Javadoc tags with <code>@BeanInfo</code> annotations for Swing<br> <a href="https://openjdk.java.net/jeps/256">JDK 9</a></p> </li> <li> <p>Update GStreamer included in JavaFX/Media to version 1.4.4<br> <a href="https://openjdk.java.net/jeps/257">JDK 9</a></p> </li> <li> <p>Replace the existing ICU OpenType font-layout engine with HarfBuzz<br> <a href="https://openjdk.java.net/jeps/258">JDK 9</a></p> </li> </ul> <h2 id="performance-improvements">Performance Improvements</h2> <h3 id="general-1">General</h3> <ul> <li> <p>Foreign-Memory Access API to safely and efficiently use off-heap memory (<strong>Incubator</strong> 🥚)<br> <a href="https://openjdk.java.net/jeps/383">JDK 15</a> <a href="https://openjdk.java.net/jeps/370">JDK 14</a></p> </li> <li> <p>Enable dynamic archiving of classes at the end of Java application execution<br> <a href="https://openjdk.java.net/jeps/350">JDK 13</a></p> </li> <li> <p>Application Class-Data Sharing to improve startup time and reduce footprint by sharing class metadata between Java processes.<br> <a href="https://openjdk.java.net/jeps/310">JDK 10</a></p> </li> <li> <p>Class-Data Sharing archive of the default class list is enabled by default to improve out-of-the-box startup time<br> <a href="https://openjdk.java.net/jeps/341">JDK 12</a></p> </li> <li> <p>Space-efficient, Compact Strings that stores Latin-1 only Strings more efficiently<br> <a href="https://openjdk.java.net/jeps/254">JDK 9</a></p> </li> <li> <p>Code caches of profiled and non-profiled compiled code is separated, resulting in improved performance and memory footprint<br> <a href="https://openjdk.java.net/jeps/197">JDK 9</a></p> </li> <li> <p>Store Interned Strings in Class-Data Sharing archives to reduce memory consumption<br> <a href="https://openjdk.java.net/jeps/250">JDK 9</a></p> </li> </ul> <h3 id="library">Library</h3> <ul> <li> <p>Improved intrinsics for <code>java.lang.Math</code> <code>sin</code>, <code>cos</code> and <code>log</code> functions on AArch64 processors<br> <a href="https://openjdk.java.net/jeps/315">JDK 11</a></p> </li> <li> <p>Security Manager performance improvements<br> <a href="https://openjdk.java.net/jeps/232">JDK 9</a></p> </li> <li> <p>Spin-Wait Hint (<code>Thread#onSpinWait</code>) to optimize busy-waiting style loops<br> <a href="https://openjdk.java.net/jeps/285">JDK 9</a></p> </li> <li> <p>Use Marlin Renderer in Java 2D as the default graphics rasterizer instead of Pisces<br> <a href="https://openjdk.java.net/jeps/265">JDK 9</a></p> </li> <li> <p>Improved GHASH and RSA performance by leveraging recently-introduced SPARC and Intel x64 CPU instructions<br> <a href="https://openjdk.java.net/jeps/246">JDK 9</a></p> </li> </ul> <h3 id="concurrency">Concurrency</h3> <ul> <li> <p>Thread-Local Handshakes to stop individual threads<br> <a href="https://openjdk.java.net/jeps/312">JDK 10</a></p> </li> <li> <p>Improved performance of contended object monitors<br> <a href="https://openjdk.java.net/jeps/143">JDK 9</a></p> </li> <li> <p>Extra space on thread stack for critical sections, mitigating the risk of a deadlock in <code>java.util.concurrent</code> locks in case of a stack overflow<br> <a href="https://openjdk.java.net/jeps/270">JDK 9</a></p> </li> </ul> <h3 id="compiler">Compiler</h3> <ul> <li> <p>Ahead-of-Time Compilation capability for Linux (<strong>Experimental</strong> 💥)<br> <a href="https://openjdk.java.net/jeps/246">JDK 10</a> (Graal as an experimental JIT Compiler) <a href="https://openjdk.java.net/jeps/243">JDK 9</a> (JVM Compiler Interface) <a href="https://openjdk.java.net/jeps/295">JDK 9</a> (Graal as an AoT Compiler)</p> </li> <li> <p>Performance improvement in javac: new strategy for type checking poly expressions<br> <a href="https://openjdk.java.net/jeps/215">JDK 9</a></p> </li> </ul> <h3 id="g1-garbage-collector-default">G1 Garbage Collector (default)</h3> <ul> <li> <p>NUMA-Aware Memory Allocation<br> <a href="https://openjdk.java.net/jeps/345">JDK 14</a></p> </li> <li> <p>Abortable mixed collections to meet user-supplied pause goals<br> <a href="https://openjdk.java.net/jeps/344">JDK 12</a></p> </li> <li> <p>Automatically return heap memory to the operating system when idle<br> <a href="https://openjdk.java.net/jeps/346">JDK 12</a></p> </li> <li> <p>Parallel Full GC to improve worst-case latencies<br> <a href="https://openjdk.java.net/jeps/307">JDK 10</a></p> </li> <li> <p>G1 Garbage Collector is now the default instead of Parallel GC<br> <a href="https://openjdk.java.net/jeps/248">JDK 9</a></p> </li> </ul> <h3 id="other-garbage-collectors">Other Garbage Collectors</h3> <ul> <li> <p>Z Garbage Collector, offering very low pause times on large heaps<br> <a href="https://openjdk.java.net/jeps/379">JDK 15</a> (<strong>Experimental</strong> 💥 in <a href="https://openjdk.java.net/jeps/365">JDK 14</a> (Windows) <a href="https://openjdk.java.net/jeps/364">JDK 14</a> (OS X) <a href="https://openjdk.java.net/jeps/333">JDK 11</a> (Linux) )</p> </li> <li> <p>Shenandoah Garbage Collector, offering similar benefits as ZGC but based on a different algorithm<br> <a href="https://openjdk.java.net/jeps/377">JDK 15</a> (<strong>Experimental</strong> 💥 in <a href="https://openjdk.java.net/jeps/189">JDK 12</a> )</p> </li> <li> <p>Epsilon Garbage Collector, which does not implement actual memory reclamation, striving for the lowest overhead possible<br> <a href="https://openjdk.java.net/jeps/318">JDK 11</a></p> </li> <li> <p><code>XX:AllocateHeapAt=&lt;path&gt;</code> to support Alternative Memory Devices<br> <a href="https://openjdk.java.net/jeps/316">JDK 10</a></p> </li> </ul> <h3 id="diagnostic-and-tools">Diagnostic and Tools</h3> <ul> <li> <p>Flight Recorder Event Streaming: profiling data is available via an <a href="https://cr.openjdk.java.net/~egahlin/jep-349/javadocs/api/jdk.jfr/jdk/jfr/consumer/package-summary.html">API</a>, making …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/">https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/</a></em></p>]]>
            </description>
            <link>https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636197</guid>
            <pubDate>Wed, 30 Sep 2020 06:29:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s T2 security chip jailbreak]]>
            </title>
            <description>
<![CDATA[
Score 699 | Comments 345 (<a href="https://news.ycombinator.com/item?id=24636166">thread link</a>) | @Yeri
<br/>
September 29, 2020 | https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/ | <a href="https://web.archive.org/web/*/https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The Apple T2 security chip has finally been jailbroken! Here’s all you need to know about it.&nbsp; &nbsp; &nbsp;</p>
<h2><span id="The_Apple_T2_Security_chip_now_has_a_jailbreak"><strong>The Apple T2 Security chip now has a jailbreak</strong><span></span></span></h2>
<p>The <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">latest update of checkra1n</a> adds support for bridgeOS – the operating system that powers the Apple T2 security chip.</p>
<p>For what it’s worth, the T2 chip is not A10 per se but it is derived from the Apple A10 Fusion architecture.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p><strong>bridgeOS</strong> is a proprietary operating system created by Apple for its hardware. It is responsible for operating the Touch Bar and managing secure data.&nbsp;&nbsp;&nbsp;</p>
<p>Here’s what hacker Jamie Bishop had to say about this development.&nbsp;&nbsp;</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">With <a href="https://twitter.com/checkra1n?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">@checkra1n</a> 0.11.0, you can now jailbreak the T2 chip in your Mac. An incredible amount of work went into this and it required changes at multiple levels.</p>
<p>There’s too many people to tag, but shoutout to everyone who worked on getting this incredible feature shipped.</p>
<p>— Jamie Bishop (@jamiebishop123) <a href="https://twitter.com/jamiebishop123/status/1308355178307948545?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">September 22, 2020</a></p>
</blockquote>
<p>Since checkra1n is still in beta, there are a few issues you need to be aware of. Firstly, you might have to reconnect your device after jailbreaking for bootstrap upload.</p>
<p>Secondly, macOS takes over the USB connection and blocks communication after bootup.&nbsp;</p>
<p>If you are interested in jailbreaking the T2 chip, download checkra1n jailbreak v0.11 from this <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">link</a>.&nbsp;</p>
<h2><span id="What_can_a_bridgeOS_jailbreak_be_used_for"><strong>What can a bridgeOS jailbreak be used for?&nbsp;</strong><span></span></span></h2>
<p>The T2 security processor and the Touch Bar can run while the operating system is shutdown.</p>
<p>Apparently, jailbreak tweak developers could develop tweaks for the Touch Bar if it gets Substrate support in the future.</p>
<p>At present, there are no publicly dumped headers available for bridgeOS. It lacks a MobileSubstrate port too. However, that could change in the future because it shares some of the components of watchOS and iOS frameworks.</p>
<p>Once we get Substrate working, <strong>tweaking and theming could become possible.</strong></p>

<p>The ability to exploit the T2 processor could also allow you to bypass the anti-repair mechanism built into the Touch Bar. Further, it may allow hackers to get rid of the password or unlock MDM-locked systems.&nbsp;</p>
<p>As far as the OS goes, we could also add secure boot certificates like Microsoft’s secure boot signing or a self-signed Linux certificate.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p>It will definitely be interesting to see what the future holds for the <em>T2 security chip</em> following the release of checkra1n.&nbsp; &nbsp; &nbsp;</p>
<p>Don’t forget to follow us on Twitter and Facebook for the latest jailbreak news and updates.&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>
</div></div>]]>
            </description>
            <link>https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636166</guid>
            <pubDate>Wed, 30 Sep 2020 06:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elements of Programmnig]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24635947">thread link</a>) | @todsacerdoti
<br/>
September 29, 2020 | http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html | <a href="https://web.archive.org/web/*/http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>

<p>The C++ STL may be the most impressive achievement in language standard libraries. Where most programmers are stuck complaining that their language’s default strings aren’t performant enough, about every standard C++ function for strings actually runs on arbitrary character sequences. Design your own container? <span>std::find_if</span> works just as well as for the built-ins. And it does this while often being more performant than the code you’d write yourself.</p>

<p>Alex Stepanov is the man who made this happen, and Elements of Programming (EOP) is his 200-page paean to his method for writing generic code. He’s a believer that programming can be turned from an art to a rigorous discipline based on mathematics, and I’ve long admired him for his deep knowledge and impact. Indeed, he’s spent years at  #1 on my list of people I’d like to have lunch with. (Hey readers — can anyone help?)</p>

<p>And now, I’m about to ruin all that by writing a negative review.</p>

<p>EOP has a strong beginning and a strong finish. The first chapter explains core programming language concepts such as types and state — using non-standard terminology, but probably intentionally, judging by the explanation’s lucidity. This culminates in his big idea of being able to write programs on any type that offers a bundle of operations and properties called a concept, explained in this book over a decade before they entered the C++ standard. The afterword is a few pages of reflection on the power of this approach.</p>

<p>Between them is 11 chapters where he plays the same game: define a new abstraction and then show a bunch of functions that can be written using it. And unfortunately, these functions and abstractions are largely not very interesting.</p>

<p>There’s a famous site called Project Euler, where users write code to solve mathy problems such as “In a modified version of the board game Monopoly, on what three squares is a player most likely to land?” My former programming-contest coach advocated against using it to practice, because “It’s not really programming, and it’s not really math.”</p>

<p>I think this is an apt description of EOP, particularly the first half. This starts from Chapter 2, which is about cool algorithms that involve applying some function to itself repeatedly (iteration). One of my <a href="https://www.cs.cmu.edu/~cdm/pdf/lect-05.pdf">favorite lectures</a> in undergrad was on this topic, and yet I still couldn’t enjoy this chapter, as I know no application of these algorithms outside of niche mathematical topics. This gets taken up another notch in Chapter 5, where, in about 5 pages, he goes from explaining commutativity to defining the algebraic structures of monoids, groups, and rings, all the way up to algebraic modules (no relation to software modules). I cannot fathom these explanations being useful to someone who does not already know these concepts, and certainly not to someone who already does. And while I do know many uses of groups in software engineering — as an abstraction of the idea of an invertible operation — he actually spends the remainder of this chapter considering generalizations of the greatest common divisor function.</p>

<p>I slogged through these chapters, excited for the second half of the book, which focused largely on iterators and containers, things more relevant to typical software engineering. Yet after encountering endless listings of variations of list-copy functions, I found myself no more fulfilled, and soon regressed to skimming through the pages.</p>

<p>Aside from my long-term goal to find all the good writing on software design, I had a short-term goal when reading this book: a student wanted me to teach a lesson based on it. But, halfway through the book, my deadline was fast approaching, and I hadn’t found any material useful enough for a software design lesson for experienced engineers.</p>

<p>I then noticed all the chapters were generated by the deeper principle of coming up with a good abstraction to write generic functions against. I got the idea that maybe I could use EOP as a problem book, telling them to look at the descriptions of generic functions, and then come up with both the code and the abstractions they can be written against. Alas, the topic selection is not suitable for this purpose. One section of the book, for example, deals with computing integer sequences by matrix exponentiation. Asking students to come up with this themselves would be too familiar for many who have taken a linear algebra course, and impossible for those who haven’t. I did design a lesson where students come up with their own abstractions for generic programming problems, but I used examples completely unrelated to the book.</p>

<p>I asked the friend who recommended EOP what he got out of the book, and his first answer was a technique for elegantly expressing state machines using goto’s. I similarly loved that part, but, alas, that was the only concrete thing I got out of this book. I’ll explain it at the end of this review and spare you the other 200 pages.</p>

<p>I have an undergraduate degree in mathematics and have authored several papers on generic programming, so I knew I was reading it for others’ benefit. Still, I don’t think my opinion would be changed were this not the case, and I’d really like help understanding the viewpoint of the many readers who did thoroughly enjoy it. Instead, I find myself agreeing with this Amazon reviewer, although I have too much admiration for Stepanov to contemplate a 1-star rating:</p>

<blockquote>If you've ever written a generic function, you already know that the type parameters must obey a set of preconditions. This book lays out a big pile of definitions for types, numbers, algebraic structures, iterators, and such, so as to bamboozle people easily impressed by mathematical notation. It does so sloppily and writes some trivial generic algorithms in C++. To whatever extent one might accomplish something interesting with this topic, this book doesn't. Avoid.</blockquote>

<p>As I read other material by Stepanov, I mourn for the book that could have been. Stepanov clearly cares about these abstractions and algorithms, to the point where he wrote a <a href="https://www.amazon.com/Mathematics-Generic-Programming-Alexander-Stepanov/dp/0321942043">second book</a> on largely the same material, with a chattier exposition and chapters more explicitly focusing on pure math. How different would it be had he managed to transmit this appreciation to me? The day after finishing, I watched <a href="https://www.youtube.com/watch?v=W2tWOdzgXHA&amp;t=1344s">this talk</a> by a close colleague of Stepanov. “In this menu, you can select a bunch of rows and drag them somewhere else,” he explained over animated slides. “How many of you could implement this in one line?” It made me want to open section 10.4 on “rotation algorithms” again.</p>

<p>I’ve started watching <a href="https://www.youtube.com/playlist?list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD">a seminar</a> he gave at Amazon. I’m only a few lectures in, but I’m already enthralled by his high teaching ability. I feel like I’m there with him working through problems. I feel like I’ve learned a great secret as he tells the story of how he invented “regular types,” something used throughout EOP but never motivated. To be honest, I still don’t know what this lecture series is about, but nonetheless expect to recommend it when I’m done.</p>

<p>In short, Stepanov has given many gifts to the world of programming, and EOP is not one of them.</p>

<p><b>Overall rating</b>: <span>Not recommended</span></p>

<p>With a smattering of exceptions, EOP neither teaches abstractions useful in everyday programming, nor teaches you the skills to invent your own.</p>

<h2><b>Addendum</b>: State machines by goto’s</h2>

<blockquote>“The fastest way to go from one place in code to another is goto.”</blockquote><p>

— <a href="https://www.youtube.com/watch?v=sp_IBYVqMeQ&amp;list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD">Alexander Stepanov</a></p><p>Many iterative algorithms can be described as state machines: first it looks for an X, then it does Y with it, then it looks for another X, and so on. Rather than trying to massage the cycles in the state machine into structured loops, Stepanov advocates a style using goto’s, with one goto-label per machine state.</p>

<p>In searching for an example to best illustrate this, I wanted something where the code was under 40 lines (which ruled out Stepanov’s examples), understandable with little context or knowledge of C++, and which was not equivalent to a regular expression. And so:</p>

<p>In my defunctionalization talk, I showed that many state machines are derived from recursive functions, being turned into iterative traversals by creating a state for each point in the program between recursive calls. For that talk, I demonstrated this in full for the example of printing a binary tree. It turns out that adding parentheses makes this derivation substantially harder, as an arbitrary number of close-parentheses may need to be printed after processing a node. And that difficulty comes from trying to massage a state machine into a loop.</p>

<p>In this case, seeing as I came up with this example by starring with a recursive function, the recursive version is quite simple:</p>

<div><pre><span>void</span> <span>print_tree_rec</span><span>(tree</span> <span>*</span><span>t)</span> <span>{</span>
  <span>if</span> <span>(t</span> <span>!=</span> <span>NULL)</span> <span>{</span>
    <span>printf(</span><span>"("</span><span>);</span>
    <span>print_tree_rec(t</span><span>-&gt;</span><span>left);</span>
    <span>printf(</span><span>" %d "</span><span>,</span> <span>t</span><span>-&gt;</span><span>element);</span>
    <span>print_tree_rec(t</span><span>-&gt;</span><span>right);</span>
    <span>printf(</span><span>")"</span><span>);</span>
  <span>}</span>
<span>}</span>
</pre></div>


<p>But, for other state machines, the recursive version is not so easy. For example, Dijkstra created the “shunting yard” algorithm for parsing an arithmetic expression all the way back in 1961, yet I’m not aware of the recursive equivalent being discovered <a href="https://www.brics.dk/RS/07/7/BRICS-RS-07-7.pdf">until 2007</a>, using the technique of refunctionalization.</p>

<p>Here’s the state machine:</p><p><span id="docs-internal-guid-068c5e82-7fff-aeae-61d2-74453ca23aeb"><span><span><img height="566" src="https://lh4.googleusercontent.com/bfYT7CeU0eo8KAoMt8gB5Y4FDgD7Y1UlUJYSNI3ndYZ6jQpZv5Nwpyqyqoqffi_tgSRBYslU93EZy_nCil9ub6FZraaRGOBoABGPk0i9DoNbgr1fWAnkQzXMxPvLvEYFSDRWZ1RL" width="572"></span></span></span></p>

<p>A confession: the first time I thought about how to make this recursive function function iterative, I didn’t get it, and had to look it up. The solution is to merge the “Next from stack” state in the diagram with its successors, resulting in a solution with two nested while-loops, at the cost of some duplicated code.</p>

<p>However, the version based on goto’s reads off this diagram rather nicely. One C++-ism in this code to note: while the stack s is initialized to NULL, the  <span>push()</span> and  <span>pop()</span> calls can actually change it.</p>

<!--HTML generated using hilite.me--><div><pre><span>void</span> <span>print_tree</span><span>(tree</span> <span>*</span><span>t)</span> <span>{</span>
  <span>tree</span> <span>*</span><span>cur</span> <span>=</span> <span>t;</span>
  <span>stack</span> <span>*</span><span>s</span> <span>=</span> <span>NULL;</span>
  
<span>begin_print_node:</span>
  <span>if</span> <span>(cur</span> <span>==</span> <span>NULL)</span> <span>{</span>
    <span>goto</span> <span>dispatch_stack_frame;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>printf(</span><span>"("</span><span>);</span>
    <span>push(LEFT_CHILD,</span> <span>cur,</span> <span>s);</span>
    <span>cur</span> <span>=</span> <span>cur</span><span>-&gt;</span><span>left;</span>
    <span>goto</span> <span>begin_print_n…</span></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html">http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html</a></em></p>]]>
            </description>
            <link>http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635947</guid>
            <pubDate>Wed, 30 Sep 2020 05:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on the future of media by Balaji S]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635654">thread link</a>) | @dayve
<br/>
September 29, 2020 | https://cephalopods.blog/2020/09/18/some-notes-on-balaji-srinivasans-talk-on-the-future-of-media/ | <a href="https://web.archive.org/web/*/https://cephalopods.blog/2020/09/18/some-notes-on-balaji-srinivasans-talk-on-the-future-of-media/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>A few weeks ago Balaji Srinivasan was featured in a virtual meetup hosted by Joshua Fox. Balaji gave a talk on decentralized alternatives to legacy media, with a definite overtone of<em> New York Times delenda est</em>. It was a very good talk. I feel the need to get my head around what he said, and I often find the “5th grade book report” approach of summarizing something to be highly useful in this regard.  So this post is just me going over some of his arguments and predictions. </p>



<h2>Of Oracles and Advocates</h2>



<p>Balaji imagines a future where there is a separation between truth aggregation and narrative in  journalism. That is, he predicts that mechanisms will arise that will reliably correlate with reality, expressing the appropriate degrees of uncertainty. And then on top of the mechanisms, either decentralized contractors, or eventually text models like GPT-3, will apply a layer of narrative gloss, obsoleting the publisher and maybe even the journalists altogether. He refers to this class of mechanisms as “feeds/oracles” and those people or algorithms that apply the narrative gloss as “advocates”</p>



<p>He mentions financial and sports journalism as prototypical examples where such a separation exists today. Many such stories are largely just raw scores or stock prices converted rather mechanically (whether by a human or an algorithm) into narrative form. <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Narrative_Science" target="_blank">Narrative Science</a> is a company with a rather old-fashioned template-based text generator which is writing millions of such stories every day, using the feed + narrative gloss approach. He has a great line about this in the talk:</p>



<blockquote><p>Stock market stories are just text wrappers around Bloomberg data, sports stories just <em>text wrappers</em> around scores, and political stories are just <em>text wrappers</em> around tweets.</p></blockquote>



<p>I particularly like “Political stories are just text wrappers around tweets” – both true,  discomfiting and amusing all at once.</p>



<p>After introducing this distinction between “feeds/oracles” and “advocates” he then described the “ledger of record,” which is his word for the sort of generalized space of all active blockchains. </p>



<p>To place my possibly unjustified biases on the table, since reading all the white papers of some of  the highest market-cap ERC20 tokens, I have been pretty skeptical of cryptocurrency. I will refrain from writing the three-paragraph rant that would be required to adequately describe the amount of stupid that was present in some those white papers but suffice it to say it turned me off the whole scene. </p>



<p>But despite my distaste for the stuff, a good cook can make a fine meal of the most exotic ingredients and Balaji waxes quite well on the value of decentralized ledgers. The main value-adds he mentions are payments and trustless timestamps, particularly the role of timestamps in allowing pseudonyms to accrue reputation. His slogan for this is “first payments, then truth.”</p>



<p>One easy thing you can prove with a blockchain is that this particular string was signed with this particular key, and existed at this particular time. By hashing the string, you can do this without revealing the contents. One can imagine a pseudonymous data aggregator establishing a reputation by time-stamping facts in this way before they become commonly known. And then selling access to a stream of such data. </p>



<p>One problem that pops up in my head now is it seems like you would end up with a lot of <a href="https://en.wikipedia.org/wiki/List_of_confidence_tricks#Baltimore_Stockbroker_/_Psychic_Sports_Picks">Baltimore stockbrokers</a>. Maybe this would not be a problem though, as once you are aware of a data aggregator you are immune to such selection effects going forward. Time is not on the side of a Baltimore stockbroker.  So maybe prominence would screen off such people. But these types of selection effects confuse my squib brain and my intuitions here are not very clear. I wish I had asked him about the Baltimore stockbroker problem during the Q&amp;A.</p>



<p>Regardless, a plain-text public feed does not have this problem, and will probably be the most common. Especially if it is not pseudonymous. If pseudonymous, there is always the temptation of defecting, especially if your feeds are used by smart contracts to settle various bets. I know Augur and other projects are working on solutions to this, and his opinion on the efficacy of such mechanisms is another question I regret not asking. </p>



<p>My impression so far is there does not appear to be much activity on any decentralized prediction markets, despite them existing for many years. Perhaps this is related to it being provably irrational to participate in an unsubsidized predication market. </p>



<p>Subsidizing a prediction market with inflation seems like it could have been a good idea for Bitcoin or Ethereum, but would be hard to implement now. In general, inflation strikes me as an ideal way to subsidize public goods (such as information aggregation) and I think it is a big lost opportunity that Ethereum and Bitcoin use it exclusively to fund security.  It’s a shame inflation is such a dirty word among the blockchain crowd, as it is ironically the most powerful tool in their arsenal. </p>



<h2>Advocates or Agents?</h2>



<p><br>He talked about the incentives for citizen journalists, and one of them is a notion of duty. One problem with duty as a sole incentive is that a pathological means of amplifying one’s sense of duty is indoctrination into an ideology.  And I wonder if, in a world where duty is one of the only remaining incentives for journalism, this will only amplify ideologues of various stripes. </p>



<p>I would prefer a sort of “mechanisms all the way up” approach, and (as mentioned) Balaji speculated about  a means to do this. It certainly seems science fictional now, but the idea of prediction markets, centralized or decentralized, solidifying a sort of agreed-upon ontology of the present and future is highly appealing to me. </p>



<p>Scott Alexander describes this potential well here:</p>



<blockquote><p>A democratic vote among the scientific establishment is insufficient to settle these topics. The most important problem is that it gives massive power to the people who determine who gets to be part of “the scientific establishment”. … So not having any Schelling point – being hopelessly confused about the legitimacy of academic ideas – sucks. But a straight democratic vote of academics would also suck and be potentially unfair.</p><p>Prediction markets avoid these problems. There is no question of who the experts are: anyone can invest in a prediction market. There’s no question of special interests taking it over; this just distributes free money to more honest investors. Not only do they escape real bias, but more importantly they escape perceived bias. It is breathtakingly beautiful how impossible it is to rail that a prediction market is the tool of the liberal media or whatever. …</p><p>Nate Silver might do better than a prediction market, I don’t know. But Nate Silver is not a Schelling point. Nobody chose him as Official Statistics Guy via a fair process. And if someone objected to his beliefs, they could accuse him of bias and he would have no recourse until it was too late. If a prediction market is almost as good as Nate, and it is also unbiased and impossible to accuse of bias, we have our Schelling point. …</p></blockquote>



<p>In Balaji’s vision, this shelling point would be reified in the “ledger of record” mentioned earlier. </p>



<p>A humorous thought I had is if we do get an agreed upon method of selecting policies that is effective then a utilitarian could have their GPT-N bot rationalize these policies to them through a utilitarian lens, and others could have their GPT-N rationalize these policies as what Marx truly intended, the culmination of the non-aggression principle, the obvious result of Kantian universality, or the culmination of neo-liberalism. A recipe for Utopia if I ever heard one!</p>



<p>Balaji addressed the obvious objection that most news consumption is largely about affiliation rather than truth-seeking, saying that those people who want truth will have an incentive to use the best means available even if most people prefer a circus. And this should undoubtedly be an improvement over what we have today. </p>



<p>After the talk,  Balaji hanged out for a bit in the breakout rooms with our regulars.</p>



<p> I won’t go too far into details here but he mentioned this on Twitter so I think it is safe to share: I made a claim about the inability to transfer reputation between pseudonyms and within about 20 seconds he came up with a scheme, using known cryptographic primitives, that partially bypassed my objections, pointing out that things like Reddit and Stack Overflow karma are fungible and so can be transferred to pseudonyms without unmasking them using something like Zcash.  I did a little Googling afterward and it appears it was an entirely novel idea that seems likely to work, and it just popped into his head before I had finished making my point. </p>



<p>I am still skeptical about pseudonyms being useful given the 33 bit problem, but it was impressive.</p>



<p>It is quite plausible that my interpretations of his arguments are much weaker than his actual arguments, so sign up to his mailing list at <a href="https://balajis.com/signup/">https://balajis.com/signup/</a>, where he will be releasing a video of a more polished version of the same talk to get the pure stuff.</p>
	</div></div>]]>
            </description>
            <link>https://cephalopods.blog/2020/09/18/some-notes-on-balaji-srinivasans-talk-on-the-future-of-media/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635654</guid>
            <pubDate>Wed, 30 Sep 2020 04:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From zero to main(): How to write a bootloader from scratch]]>
            </title>
            <description>
<![CDATA[
Score 323 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24635383">thread link</a>) | @tigerlily
<br/>
September 29, 2020 | https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>This is the third post in our <a href="https://interrupt.memfault.com/blog/tag/zero-to-main">Zero to main() series</a>,
where we bootstrap a working firmware from zero code on a
cortex-M series microcontroller.</p>

<p>Previously, <a href="https://interrupt.memfault.com/blog/zero-to-main-1">we wrote a startup file to bootstrap our C environment</a>, and <a href="https://interrupt.memfault.com/blog/how-to-write-linker-scripts-for-firmware">a linker
script to get the right data at the right addresses</a>. These two will allow us to
write a monolithic firmware which we can load and run on our microcontrollers.</p>

<p>In practice, this is not how most firmware is structured. Digging through vendor
SDKs, you’ll notice that they all recommend using a <em>bootloader</em> to load your
applications. A bootloader is a small program which is responsible for loading
and starting your application.</p>

<!-- excerpt start -->
<p>In this post, we will explain why you may want a
bootloader, how to implement one, and cover a few advanced techniques you may
use to make your bootloader more useful.
<!-- excerpt end --></p>

<p>Like Interrupt? <a href="http://eepurl.com/gpRedv" target="_blank">Subscribe</a> to get our latest posts straight to your mailbox.</p>



<h2 id="why-you-may-need-a-bootloader">Why you may need a bootloader</h2>

<p>Bootloaders serve many purposes, ranging from security to software architecture.</p>

<p>Most commonly, you may need a bootloader to load your software. Some
microcontrollers like Dialog’s
<a href="https://www.dialog-semiconductor.com/products/connectivity/bluetooth-low-energy/smartbond-da14580-and-da14583">DA14580</a>
have little to no onboard flash and instead rely on an external device to store
firmware code. In that case, it is the bootloader’s job to copy code from
non-executable storage, such as a SPI flash, to an area of memory that can be
executed from, such as RAM.</p>

<p>Bootloaders also allow you to decouple parts of the program that are mission
critical, or that have security implications, from application code which
changes regularly.  For example, your bootloader may contain firmware update
logic so your device can recover no matter how bad a bug ships in your
application firmware.</p>

<p>Last but certainly not least, bootloaders are an essential component of a
trusted boot architecture.  Your bootloader can, for example, verify a
cryptographic signature to make sure the application has not been replaced or
tampered with.</p>

<h2 id="a-minimal-bootloader">A minimal bootloader</h2>
<p>Let’s build a simple bootloader together. To start, our bootloader must do two
things:</p>

<ol>
  <li>Execute on MCU boot</li>
  <li>Jump to our application code</li>
</ol>

<p>We’ll need to decide on a memory map, write some bootloader code, and update our
application to make it bootload-able.</p>

<h3 id="setting-the-stage">Setting the stage</h3>

<p>For this example, we’ll be using the same setup as we did in our previous Zero
to Main posts:</p>
<ul>
  <li>Adafruit’s <a href="https://www.adafruit.com/product/3505">Metro M0 Express</a> as our
development board,</li>
  <li>a simple <a href="https://www.adafruit.com/product/2764">CMSIS-DAP Adapter</a></li>
  <li>OpenOCD (the <a href="https://github.com/arduino/OpenOCD">Arduino fork</a>) for
programming</li>
</ul>

<h3 id="deciding-on-a-memory-map">Deciding on a memory map</h3>

<p>We must first decide on how much space we want to dedicate to our bootloader.
Code space is precious - your application may come to need more of it - and you
will not be able to change this without updating your bootloader, so make
this as small as you possibly can.</p>

<p>Another important factor is your flash sector size: you want to make sure you
can erase app sectors without erasing bootloader data, or vice versa.
Consequently, your bootloader region must end on a flash sector boundary
(typically 4kB).</p>

<p>I decided to go with a 16kB region, leading to the following memory map:</p>

<div><div><pre><code>        0x0 +---------------------+
            |                     |
            |     Bootloader      |
            |                     |
     0x4000 +---------------------+
            |                     |
            |                     |
            |     Application     |
            |                     |
            |                     |
    0x30000 +---------------------+
</code></pre></div></div>

<p>We can transcribe that memory into a linker script:</p>

<div><div><pre><code>/* memory_map.ld */
MEMORY
{
  bootrom  (rx)  : ORIGIN = 0x00000000, LENGTH = 0x00004000
  approm   (rx)  : ORIGIN = 0x00004000, LENGTH = 0x0003C000
  ram      (rwx) : ORIGIN = 0x20000000, LENGTH = 0x00008000
}

__bootrom_start__ = ORIGIN(bootrom);
__bootrom_size__ = LENGTH(bootrom);
__approm_start__ = ORIGIN(approm);
__approm_size__ = LENGTH(approm);
</code></pre></div></div>

<p>Since linker scripts are composable, we will be able to <code>include</code> that memory
map into the linker scripts we write for our bootloader and our application.</p>

<p>You’ll notice that the linker script above declares some variables. We’ll need
those for our bootloader to know where to find the application. To make them
accessible in C code, we declare them in a header file:</p>

<div><div><pre><code><span>/* memory_map.h */</span>
<span>#pragma once
</span>
<span>extern</span> <span>int</span> <span>__bootrom_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__bootrom_size__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_size__</span><span>;</span>
</code></pre></div></div>

<h3 id="implementing-the-bootloader-itself">Implementing the bootloader itself</h3>
<p>Next up, let’s write some bootloader code. Our bootloader needs to start
executing on boot and then jump to our app.</p>

<p>We know how to do the first part from our previous post: we need a valid stack
pointer at address <code>0x0</code> , and a valid <code>Reset_Handler</code>  function setting up our
environment at address <code>0x4</code>. We can reuse our previous startup file and linker
script, with one change: we use  <code>memory_map.ld</code> rather than define our own
<code>MEMORY</code> section.</p>

<p>We also need to put our code in the <code>bootrom</code> region from our memory rather than
the <code>rom</code> region in our previous post.</p>

<p>Our linker script therefore looks like this:</p>

<div><div><pre><code>/* bootloader.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; bootrom
  ...
}
</code></pre></div></div>

<p>To jump into our application, we need to know where the <code>Reset_Handler</code> of the
app is, and what stack pointer to load.  Again, we know from our previous post
that those should be the first two 32-bit words in our binary, so we just need
to dereference those addresses using the <code>__approm_start__</code> variable from our
memory map.</p>

<div><div><pre><code><span>/* bootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>/* TODO: Start app */</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<p>Next we must load that stack pointer and jump to the code. This will require a
bit of assembly code.</p>

<p>ARM MCUs use the <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289882044.htm"><code>msr</code> instruction
</a> to
load immediate or register data into system registers, in this case the MSP
register or “Main Stack Pointer”.</p>

<p>Jumping to an address is done with a branch, in our case with a <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289866466.htm"><code>bx</code>
instruction</a>.</p>

<p>We wrap those two into a <code>start_app</code> function which accepts our <code>pc</code> and <code>sp</code> as
arguments, and get our minimal bootloader:</p>

<div><div><pre><code><span>/* app.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>start_app</span><span>(</span><span>uint32_t</span> <span>pc</span><span>,</span> <span>uint32_t</span> <span>sp</span><span>)</span> <span>__attribute__</span><span>((</span><span>naked</span><span>))</span> <span>{</span>
    <span>__asm</span><span>(</span><span>"           </span><span>\n</span><span>\
          msr msp, r1 /* load r1 into MSP */</span><span>\n</span><span>\
          bx r0       /* branch to the address at r0 */</span><span>\n</span><span>\
    "</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>start_app</span><span>(</span><span>app_start</span><span>,</span> <span>app_sp</span><span>);</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>Note: hardware resources initialized in the bootloader must be de-initialized
before control is transferred to the app. Otherwise, you risk breaking
assumptions the app code is making about the state of the system</p>
</blockquote>

<h3 id="making-our-app-bootloadable">Making our app bootloadable</h3>

<p>We must update our app to take advantage of our new memory map. This is again
done by updating our linker script to include <code>memory_map.ld</code> and changing our
sections to go to the <code>approm</code> region rather than <code>rom</code>.</p>

<div><div><pre><code>/* app.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; approm
  ...
}
</code></pre></div></div>

<p>We also need to update the <a href="https://developer.arm.com/docs/dui0552/latest/the-cortex-m3-processor/exception-model/vector-table"><em>vector
table</em></a>
used by the microcontroller. The vector table contains the address of every
exception and interrupt handler in our system. When an interrupt signal comes
in, the ARM core will call the address at the corresponding offset in the vector
table.</p>

<p>For example, the offset for the Hard fault handler is <code>0xc</code>, so when a hard
fault is hit, the ARM core will jump to the address contained in the table at
that offset.</p>

<p>By default, the vector table is at address <code>0x0</code>, which means that when our chip
powers up, only the bootloader can handle exceptions or interrupts! Fortunately, ARM
provides the <a href="https://developer.arm.com/docs/dui0552/latest/cortex-m3-peripherals/system-control-block/vector-table-offset-register">Vector Table Offset
Register</a>
to dynamically change the address of the vector table. The register is at
address <code>0xE000ED08</code> and has a simple layout:</p>

<div><div><pre><code>31                                  7              0
+-----------------------------------+--------------+
|                                   |              |
|              TBLOFF               |   Reserved   |
|                                   |              |
+-----------------------------------+--------------+
</code></pre></div></div>

<p>Where <code>TBLOFF</code> is the address of the vector table. In our case, that’s the start
of our text section, or <code>_stext</code>. To set it in our app, we add the following to
our <code>Reset_Handler</code>:</p>

<div><div><pre><code><span>/* startup_samd21.c */</span>
<span>/* Set the vector table base address */</span>
<span>uint32_t</span> <span>*</span><span>vector_table</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span> <span>&amp;</span><span>_stext</span><span>;</span>
<span>uint32_t</span> <span>*</span><span>vtor</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>0xE000ED08</span><span>;</span>
<span>*</span><span>vtor</span> <span>=</span> <span>((</span><span>uint32_t</span><span>)</span> <span>vector_table</span> <span>&amp;</span> <span>0xFFFFFFF8</span><span>);</span>
</code></pre></div></div>

<p>One quirk of the ARMv7-m architecture is the alignment requirement for the
vector table, as specified in section B1.5.3 of the <a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">reference
manual</a>:</p>

<blockquote>
  <p>The Vector table must be naturally aligned to a power of two whose alignment value is greater than or equal
to (Number of Exceptions supported x 4), with a minimum alignment of 128 bytes.The entry at offset 0 is
used to initialize the value for SP_main, see The SP registers on page B1-8. All other entries must have bit
[0] set, as the bit is used to define the EPSR T-bit on exception entry (see Reset behavior on page B1-20 and
Exception entry behavior on page B1-21 for details).</p>
</blockquote>

<p>Our SAMD21 MCU has 28 interrupts on top of the 16 system reserved exceptions,
for a total of 44 entries in the table. Multiply that by 4 and you get 176. The
next power of 2 is 256, so our vector table must be 256-byte aligned.</p>

<h3 id="putting-it-all-together">Putting it all together</h3>

<p>Because it is hard to witness the bootloader execute, we add a print line to
each of our programs:</p>

<div><div><pre><code><span>/* boootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>s…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635383</guid>
            <pubDate>Wed, 30 Sep 2020 03:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UX of Banking]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635364">thread link</a>) | @Garbage
<br/>
September 29, 2020 | https://builtformars.co.uk/banks/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/banks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="3032" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="2898fc6" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
							
							<div>
				<div>
				<div data-id="4964a44" data-element_type="column">
			<div>
					<div>
				
				<div data-id="0a3485f" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h3>What the challenger banks did differently: a study into the UX of banking.</h3>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="535cf2f" data-element_type="section">
						
		</section>
				<section data-id="9be0ee4" data-element_type="section">
						<div>
				<div>
				<div data-id="bf5c18d" data-element_type="column">
			<div>
					<div>
				
				<div data-id="b431a25" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h4>Billion dollar experiences</h4>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="b910384" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="96fe065" data-element_type="column">
			<div>
					<div>
				<div data-id="3c618a0" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Monzo, Revolut and Starling—often called the challenger banks—have built billion-dollar businesses around the belief that they offer the best overall banking experience.</p>
				</div>
				</div>
				<div data-id="941ff44" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>But are they actually any better, or is it all clever marketing? To answer that question I opened 12 real bank accounts, and logged <em>everything</em>.</p>
				</div>
				</div>
				<div data-id="8bb4b6b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Each chapter provides a forensic analysis of a particular feature or user journey.</p>
				</div>
				</div>
				<div data-id="78b3d97" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>But more importantly, I’ve highlighted what can we all learn from the challenger banks, and used real examples to teach you how to craft better experiences in the future.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="560e042" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<div data-id="9643ce0" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><strong>Subscribe to get more content like this!</strong></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="546fd67" data-element_type="section">
						<div>
				<div>
				<div data-id="4cd7bfe" data-element_type="column">
			<div>
					<div>
				<div data-id="bdaeb8e" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.com/banks/opening/">
							<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed.jpg" alt="" srcset="https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="29b9a8f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It took <strong>18x longer</strong> to open an account with HSBC that it did with Monzo.</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				<div data-id="4a8ea32" data-element_type="column">
			<div>
					<div>
				<div data-id="c26ace2" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.com/banks/first-payment">
							<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1.jpg" alt="" srcset="https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="410d84b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Payment notifications were <strong>at least 2x faster</strong> with the challenger banks, and in some cases <strong>100x faster</strong>.</p>
				</div>
				</div>
				
				<div data-id="5892a2c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>⚡️ Includes <strong>12</strong><strong>&nbsp;case studies</strong></p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="671df6e" data-element_type="column">
			<div>
					<div>
				<div data-id="2d3db91" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.com/banks/freezing/">
							<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed.jpg" alt="" srcset="https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="caa9ed8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There were the <strong>only 3</strong> banks to send notifications when someone attempted to use a frozen card.</p>
				</div>
				</div>
				
				<div data-id="f06833c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>⚡️ Includes <strong>10</strong><strong>&nbsp;case studies</strong></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="894506f" data-element_type="section">
						<div>
				<div>
				<div data-id="df064b1" data-element_type="column">
			<div>
					<div>
				<div data-id="28c4ea8" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.com/banks/international/">
							<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed.jpg" alt="" srcset="https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="b437d79" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It cost <strong>at least £20</strong> to send £1 (GBP) to a US bank (USD) with three banks.</p>
				</div>
				</div>
				
				<div data-id="f6c6bbc" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>⚡️ Includes <strong>12</strong><strong>&nbsp;case studies</strong></p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="8e4c759" data-element_type="column">
			<div>
					<div>
				<div data-id="c4df7a5" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.com/banks/open-banking/">
							<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed.jpg" alt="" srcset="https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="977ae52" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It took nearly <strong>4x longer</strong>&nbsp;to authorise an Open Banking payment with Lloyds than it did with Starling.</p>
				</div>
				</div>
				
				<div data-id="4b3bec9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>⚡️ Includes <strong>10</strong><strong>&nbsp;case studies</strong></p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="4ff6bfc" data-element_type="column">
			<div>
					<div>
				<div data-id="3fac4a8" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.com/banks/support/">
							<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed.jpg" alt="" srcset="https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="56418e4" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Revolut only ever replied to <strong>20%</strong> of my live chat support messages, and don’t have a phone line.</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="178d96c" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
				<section data-id="d2d652f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="39958a6" data-element_type="column">
			<div>
					<div>
				
				<div data-id="bd6b341" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h4>Thank you for all your support</h4>		</p>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="832fa78" data-element_type="section">
						<div>
				<div>
				<div data-id="4d4f429" data-element_type="column">
			<div>
					<div>
				<div data-id="0df1ab9" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="2136" height="839" src="https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller.png" alt="" srcset="https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller.png 2136w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-300x118.png 300w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-1024x402.png 1024w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-768x302.png 768w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-1536x603.png 1536w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-2048x804.png 2048w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-100x39.png 100w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-700x275.png 700w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-1600x628.png 1600w" sizes="(max-width: 2136px) 100vw, 2136px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c7e323d" data-element_type="section">
						<div>
				<div>
				
				<div data-id="75df2de" data-element_type="column">
			<div>
					<div>
				<div data-id="f2bc236" data-element_type="widget" data-widget_type="html.default">
				<div>
			<blockquote><p lang="en" dir="ltr">No research could be crisper in explaining the sense of "Frictionless experience" and Frictionless IT that I kept talking about for years. Must-read and must-subscribe. &gt; "What the challenger banks did differently" by <a href="https://twitter.com/PeteRamsey?ref_src=twsrc%5Etfw">@PeteRamsey</a> <a href="https://t.co/zWmxpYG0LT">https://t.co/zWmxpYG0LT</a></p>— Alessandro Perilli ✪ AI￨Automation￨Cybersecurity (@giano) <a href="https://twitter.com/giano/status/1263436408745844741?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote> 		</div>
				</div>
				
				
				
				
						</div>
			</div>
		</div>
				<div data-id="9072e4a" data-element_type="column">
			<div>
					<div>
				<div data-id="c9ef61c" data-element_type="widget" data-widget_type="html.default">
				<div>
			<blockquote data-conversation="none"><p lang="en" dir="ltr">This should be required reading by every exec at traditional banks. Fantastic work</p>— Alex Barkley (@alexfintec) <a href="https://twitter.com/alexfintec/status/1264827065725059072?ref_src=twsrc%5Etfw">May 25, 2020</a></blockquote> 		</div>
				</div>
				
				
				
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/banks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635364</guid>
            <pubDate>Wed, 30 Sep 2020 03:15:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Raspberry Pi Touchscreen Internet Radio, Music Player and Weather Display]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635359">thread link</a>) | @azeemarif
<br/>
September 29, 2020 | https://smarttechnotes.com/raspberry-pi-touchscreen-internet-radio | <a href="https://web.archive.org/web/*/https://smarttechnotes.com/raspberry-pi-touchscreen-internet-radio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-42">

	

	
			<figure>
				<img width="1568" height="1118" src="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=1568" alt="" loading="lazy" srcset="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=1568 1568w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=768 768w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg 1883w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="140" data-permalink="https://smarttechnotes.com/2020/08/21/raspberry-pi-touchscreen-internet-radio/20200831_125150-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg" data-orig-size="1883,1342" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G960W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598878310&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.028571428571429&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200831_125150-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>In this post I’d like to share how to make a Raspberry Pi internet radio player with music, audio-books and podcast playback over Bluetooth. In addition to all these features, it also serves as a weather station.</p>



<figure><img data-attachment-id="45" data-permalink="https://smarttechnotes.com/20200821_114111/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg" data-orig-size="1874,2200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598010000&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20200821_114111" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=256" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=872" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=872 872w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=1744 1744w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=128 128w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=256 256w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=768 768w" sizes="(max-width: 872px) 100vw, 872px"></figure>



<p>When fully setup, the player can be controlled using the touch screen or remotely via a web interface. It plays media on wireless Bluetooth speaker.</p>



<p>We need the following items for this project</p>



<h4>Hardware</h4>



<ul><li>Raspberry Pi<ul><li>power supply</li><li>micro SD card</li></ul></li><li>Touchscreen LCD</li><li>Raspberry Pi case fit for holding an LCD</li><li>Bluetooth speaker</li><li>for initial setup, it would be nice to have<ul><li> Keyboard and Mouse</li><li>Monitor</li></ul></li></ul>



<h4>Software</h4>



<ul><li>Raspberry Pi OS</li><li>Peppy media player</li></ul>



<p>Any Raspberry Pi board with Wifi and Bluetooth is good for this project.</p>



<figure><img data-attachment-id="49" data-permalink="https://smarttechnotes.com/maker0x4cdate2017-9-26ver4lenskan03actlar01e-y/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg" data-orig-size="3417,2197" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 2 XL&quot;,&quot;caption&quot;:&quot;Maker:0x4c,Date:2017-9-26,Ver:4,Lens:Kan03,Act:Lar01,E-Y&quot;,&quot;created_timestamp&quot;:&quot;1523482264&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.459&quot;,&quot;iso&quot;:&quot;522&quot;,&quot;shutter_speed&quot;:&quot;0.033298&quot;,&quot;title&quot;:&quot;Maker:0x4c,Date:2017-9-26,Ver:4,Lens:Kan03,Act:Lar01,E-Y&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Maker:0x4c,Date:2017-9-26,Ver:4,Lens:Kan03,Act:Lar01,E-Y" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi</figcaption></figure>



<p>I used a 3.5 inch touchscreen LCD from <a href="http://www.kumantech.com/kuman-35-inch-tft-lcd-display-480x320-rgb-pixels-touch-screen-monitor-for-raspberry-pi-3-2-model-b-b-a-a-module-spi-interface-with-touch-pen-sc06_p0014.html">Kuman tech</a>.</p>



<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="53" data-permalink="https://smarttechnotes.com/samsung-camera-pictures-2/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg" data-orig-size="2922,1793" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NX3000&quot;,&quot;caption&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;created_timestamp&quot;:&quot;1524004145&quot;,&quot;copyright&quot;:&quot;Copyright 2014&quot;,&quot;focal_length&quot;:&quot;28&quot;,&quot;iso&quot;:&quot;1600&quot;,&quot;shutter_speed&quot;:&quot;0.02&quot;,&quot;title&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SAMSUNG CAMERA PICTURES" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi and Touchscreen</figcaption></figure></div>



<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="57" data-permalink="https://smarttechnotes.com/samsung-camera-pictures-4/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg" data-orig-size="4769,2177" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NX3000&quot;,&quot;caption&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;created_timestamp&quot;:&quot;1524004110&quot;,&quot;copyright&quot;:&quot;Copyright 2014&quot;,&quot;focal_length&quot;:&quot;28&quot;,&quot;iso&quot;:&quot;3200&quot;,&quot;shutter_speed&quot;:&quot;0.02&quot;,&quot;title&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SAMSUNG CAMERA PICTURES" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=2046 2046w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi and Touchscreen</figcaption></figure></div>



<p>We need a case that can hold the LCD screen securely so that it does not move when using the touchscreen. I used <a href="https://www.amazon.ca/MagiDeal-Acrylic-Enclosure-Raspberry-3-5inch/dp/B07FTB1RCD">this case</a> from Amazon but you may find many others like this if you search for “Layer Acrylic Case Raspberry Pi”.</p>



<figure><img data-attachment-id="55" data-permalink="https://smarttechnotes.com/20200821_111038-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg" data-orig-size="3274,1753" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598008238&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_111038-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Acrylic Case for Raspberry Pi  with 3.5 inch LCD Display</figcaption></figure>



<p>And finally, we need a speaker to play the sound. It could very well be a wired speaker that is directly connected to Raspberry Pi using the 3.5mm headphone connector or a USB port but I used a wireless Bluetooth speaker so that we I can move it around easily.</p>



<figure><img data-attachment-id="60" data-permalink="https://smarttechnotes.com/20200821_231233-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg" data-orig-size="3410,1688" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598051553&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_231233-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Bluetooth Speaker</figcaption></figure>







<h4>Initial Setup</h4>



<p>For the initial setup, connect a USB keyboard and mouse and a monitor (using HDMI cable) to the Raspberry Pi. On a computer download Raspberry Pi OS and install the image on a micro SD card.</p>



<p><a href="https://www.raspberrypi.org/downloads/raspberry-pi-os/">Raspberry Pi OS download</a></p>



<p><a href="https://www.raspberrypi.org/documentation/installation/installing-images/README.md">Installing Raspberry Pi OS on a micro SD card</a></p>



<p>After SD card is ready, insert it into Raspberry Pi board and switch the power on. Follow the instructions on the screen to complete <a href="https://projects.raspberrypi.org/en/projects/install-raspberry-pi-desktop/5">Raspberry Pi OS installation</a>. After the installation you should see Raspberry Pi desktop.</p>



<figure><img data-attachment-id="65" data-permalink="https://smarttechnotes.com/raspbian_2019-04_application_menu/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg" data-orig-size="1280,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="raspbian_2019.04_application_menu" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=768 768w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi Desktop</figcaption></figure>



<p>Using icons on top right connect to your WiFi network and pair with your Bluetooth speaker. Play some music or a YouTube video to test that the network and Bluetooth connections are working.</p>



<p>Also, using the menu <em>“Preferences-&gt;Raspberry Pi Configuration</em>” enable SSH to be able to login to Raspberry Pi remotely from other computers.</p>



<figure><img data-attachment-id="74" data-permalink="https://smarttechnotes.com/enable-ssh-raspberry-pi/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg" data-orig-size="404,389" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="enable-ssh-raspberry-pi" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=404" src="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=300" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg 404w" sizes="(max-width: 300px) 100vw, 300px"></figure>







<h5>Install Peppy media player</h5>



<p>While searching for a media player for Raspberry Pi that is suitable for a small touchscreen I came across <a href="https://github.com/project-owner/Peppy.doc/wiki">Peppy</a>. It is an open source media player that includes internet radio, audio-books and podcast playback along with the usual audio file and stream playback.  The source code for Peppy is available at GitHub <a href="https://github.com/project-owner/Peppy">https://github.com/project-owner/Peppy</a>.</p>



<p>Follow the instructions at <a href="https://github.com/project-owner/Peppy.doc/wiki/Expert">https://github.com/project-owner/Peppy.doc/wiki/Expert</a> to install Peppy except don’t change the Raspberry Pi OS Boot Option to <em>“login to console with automatic login as pi user”</em> and don’t modify <em>“/etc/rc.local”</em> yet as we want to make sure that the player works fine as a Desktop application before we switch to full screen mode.</p>



<p>I also skipped most other configuration listed on this page that I did not need at this time including <em>“shairport-sync installation”</em>, <em>“raspotify installation”</em>, <em>“Equalizer Configuration”</em>, <em>“Peppyalsa Plugin Configuration”</em>, <em>“Splash Screen Configuration”</em>, <em>“Configure LIRC and Pylirc”</em> and <em>“Rotary Encoders Configuration”</em>.</p>



<p>I did not follow <em>“Adafruit 3.5″ LCD Configuration”</em> as I used a different LCD (from Kumantech as mentioned above).</p>



<p>But I did set up Peppy to play audio via Bluetooth speaker we connected earlier by following instructions <em>“Configure Bluetooth speaker as ALSA device”</em> given at <a href="https://github.com/project-owner/Peppy.doc/wiki/Bluetooth-Devices">https://github.com/project-owner/Peppy.doc/wiki/Bluetooth-Devices</a>. Also, change the configuration in <code>/home/pi/Peppy/config.txt</code>.</p>


<pre title="">bluetooth = True
</pre>


<p>When the player is installed, open a terminal window and launch the player by running the following command (assuming that the player is installed at<code> /home/pi/Peppy</code>)</p>


<pre title="">cd /home/pi/Peppy
python3 peppy.py
</pre>


<p> This should open Peppy as a normal Desktop application. Make sure that the controls are working and Peppy is able to play an internet radio via the Bluetooth speaker. If something is not working, we need to fix it now before attempting to run Peppy full screen.</p>



<figure><img data-attachment-id="97" data-permalink="https://smarttechnotes.com/2020-08-24-181722_480x320_scrot/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png" data-orig-size="480,320" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-08-24-181722_480x320_scrot" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=480" src="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=480" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png 480w, https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=300 300w" sizes="(max-width: 480px) 100vw, 480px"></figure>







<h4>Making LCD touchscreen work</h4>



<p>After Peppy media player is fully working as a Desktop application, it is time to make the LCD touchscreen work.</p>



<p>Peppy player’s wiki gives instruction to configure <a href="https://github.com/project-owner/Peppy.doc/wiki/Adafruit-PiTFT">Adafruit LCD</a> and most other Raspberry Pi displays work with <a href="https://github.com/goodtft/LCD-show">goodtft </a>driver from GitHub.  But for the LCD I used I download the LCD driver from Kumantech website (go to the <a href="http://www.kumantech.com/help/documents-and-recources_h0037.html">download page</a> and select 3.5″ LCD) as none of the other drivers worked.</p>



<p>Extract the driver compressed file and run</p>


<pre title="">sudo LCD35-show
</pre>


<p> It installs a bunch of stuff and modifies <em>/boot/config.txt</em>. After the reboot the LCD touchscreen should work.</p>



<p>One thing I noticed that the picture was upside-down (the power connection was at the bottom but I wanted it at the top so that I can place the Raspberry Pi on a desk)</p>



<p>It is easy to rotate the picture by changing</p>


<pre title="">dtoverlay=tft35a
</pre>


<p>to</p>


<pre title="">dtoverlay=tft35a:rotate=270
</pre>


<p>in <em>/boot/config.txt</em> file.</p>







<h4>Starting Peppy player in fullscreen mode</h4>



<p>First we need to disable the Desktop environment starting at reboot. To do this, connect to your Raspberry Pi through SSH from a computer and run the following command after logging in</p>


<pre title="">sudo raspi-config
</pre>


<p>Select the following items in menu:</p>



<ul><li>Boot Options<br>Desktop CLI/Console Autologin To login to console with automatic login as pi user</li></ul>



<p>Installation instructions in Peppy player’s wiki suggest that if we add the following line at the end of<code> <em>/etc/rc.local</em></code> file just before <code>'exit 0'</code> line, We should get Peppy player started at reboot in the fullscreen mode.</p>


<pre title="">su pi -c 'cd /home/pi/Peppy; openvt -s -- python3 peppy.py'
</pre>


<p>It worked except that there was no touchscreen functionality. It seems that the touchscreen driver is not loaded when we try to run Peppy this way. One thing to note was that touchscreen was working in the Desktop environment in the previous step before we disabled it and decided to boot in the console mode.</p>



<p>I came up with the following workaround which is not the most elegant one but it did the job. First, I reverted the change in <code><em>/etc/rc.local</em></code> file. Then I created the <em><code>/home/pi/.xinitrc</code></em> file with the following code</p>


<pre title="">session=${1:-lxde}

case $session in
    lxde           ) exec startlxde-pi;;
    lxterm         ) exec lxterminal;;
    peppy          ) exec lxterminal -e "cd /home/pi/Peppy; python3 peppy.py";;
esac
</pre>


<p>If after booting into the console mode, the <code>startx</code> command is run with the first option <code>lxde</code> (which is also the default option), it starts Raspberry Pi OS Desktop.</p>


<pre title="">startx ~/.xinitrx lxde
</pre>


<p>The second option starts an <code>lxterminal</code> in full screen mode. Even though it is a terminal, it is a desktop terminal application, so X server is started and touchscreen driver is loaded.</p>


<pre title="">startx ~/.xinitrc lxterm
</pre>


<p> The third option starts an <code>lxterminal</code> with a command to run inside it. The command passed using the <code>'-c'</code> tells <code>lxterminal</code> to change directory to Peppy player’s installation directory and start the player from there.</p>


<pre title="">startx ~/.xinitrc peppy
</pre>


<p>If this command is added to <code>.bashrc</code> file, it will be executed automatically after every reboot (actually after every login, but we have selected to boot to console with autologin above). We just have to make sure that we don’t run this command when logging in via SSH from a remote computer.</p>


<pre title="">if [ -n "$SSH_CLIENT" ] || [ -n "$SSH_TTY" ]; then
        echo "SSH session, not starting X server."
else
        startx ~/.xinitrc peppy
fi
</pre>






<h4>Raspberry Pi Touchscreen Internet Radio, Music Player</h4>



<p>And here is it. After the reboot, Peppy player should start in full screen mode with touchscreen functionality.</p>



<figure><img data-attachment-id="104" data-permalink="https://smarttechnotes.com/20200827_143923-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg" data-orig-size="3121,1863" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.1&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598539164&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;6&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200827_143923-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Internet Radio</figcaption></figure>



<figure><img data-attachment-id="105" data-permalink="https://smarttechnotes.com/20200826_214143/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg" data-orig-size="4032,1908" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598478103&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.0083333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200826_214143" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Internet Radio</figcaption></figure>



<figure><img data-attachment-id="127" data-permalink="https://smarttechnotes.com/20200828_143507-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg" data-orig-size="1790,1141" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.1&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598625219&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;6&quot;,&quot;iso&quot;:&quot;640&quot;,&quot;shutter_speed&quot;:&quot;0.0169&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200828_143507-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=768 768w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg 1790w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Internet Radio</figcaption></figure>


<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="106" data-permalink="https://smarttechnotes.com/20200827_160212_1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif" data-orig-size="490,368" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20200827_160212_1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif?w=490" srcset="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif?strip=info&amp;w=368 368w" alt="" data-height="368" data-id="106" data-link="https://marifnotes.wordpress.com/20200827_160212_1/" data-url="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif" data-width="490" src="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif"></figure></div></div></div></div>


<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="98" data-permalink="https://smarttechnotes.com/20200821_113525/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg" data-orig-size="4032,1908" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598009726&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_113525" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg" alt=""><figcaption>Audio book player</figcaption></figure></div>



<figure><img data-attachment-id="144" data-permalink="https://smarttechnotes.com/20200831_125037-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg" data-orig-size="2099,1710" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G960W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598878183&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.027777777777778&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20200831_125037-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Podcast player</figcaption></figure>







<h4>Weather station</h4>



<p>Another good thing about Peppy player is that it has a <a href="https://github.com/project-owner/Peppy.doc/wiki/Configuration">WebUI for configuration</a>. It can be used to configure your current location to fetch the weather information from the internet.</p>





<p>After configuring the location, just set ‘weather’ as the screensaver and we have a weather station.</p>



<figure><img data-attachment-id="90" data-permalink="https://smarttechnotes.com/20200821_111038-1-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg" data-orig-size="3274,1753" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598008238&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_111038-1-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Weather Station</figcaption></figure>



<figure><img data-attachment-id="94" data-permalink="https://smarttechnotes.com/20200821_111502/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg" data-orig-size="2464,1764" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598008502&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.025641025641026&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_111502" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Weather Station</figcaption></figure>



<p>And that’s it! Enjoy your new internet radio.&nbsp;</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://smarttechnotes.com/raspberry-pi-touchscreen-internet-radio</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635359</guid>
            <pubDate>Wed, 30 Sep 2020 03:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nobody seems to give a crap about Google’s monopoly on search, not even Google]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24635322">thread link</a>) | @pcr910303
<br/>
September 29, 2020 | https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google | <a href="https://web.archive.org/web/*/https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><a href="https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google">29 September 2020</a></p>
<p>Quick summary of the situation, from the <a href="https://www.android.com/choicescreen/">Choice Screen webpage on the Android website</a>:</p>
<blockquote>
<p>On August 2, 2019, following the European Commission’s July 2018 Android decision, Google announced that it would implement a choice screen for general search providers on all new Android phones and tablets shipped into the European Economic Area (<span>EEA</span>) where the Google Search app is pre-installed. This updated Help Center article describes a modified choice screen design that was developed in consultation with the European Commission.</p>
<p>The choice screen will appear during initial device setup and will feature multiple search providers, including Google. An illustrative version of the choice screen follows. Providers may vary by country. […]</p>
<p>Eligible search providers will need to fill out an application form and can bid for inclusion based on an auction. The auction process is explained in greater detail below.</p>
</blockquote>
<p>Considering how much this farce has been <a href="https://www.neowin.net/news/duckduckgo-blasts-googles-android-choice-screen-says-it-incentivizes-ads">covered</a> <a href="https://techcrunch.com/2020/07/30/googles-no-choice-screen-on-android-isnt-working-says-ecosia-querying-the-eus-approach-to-antitrust-enforcement/">already</a>, I will not repeat what <a href="https://www.businessinsider.com/google-android-choice-screen-eu-duckduckgo-2020-9?IR=T">everybody knows</a>. Instead I will just point out how Google announced the result of the auctions <a href="https://www.android.com/choicescreen-winners/">on the Android website</a>: four sentences, two footnotes, a table listing the<span></span> <span>“</span>winners” per country, a title that reads do-not-give-a-shit, and that’s it.</p>
<p>Also, I don’t think I have ever heard of — <em>check notes</em> — PrivacyWall and info.com.<span></span> <span>’</span>What are they?’, you may ask: they are search engines apparently, and they are the only two search engine options offered to Android users in France that are not Google or Bing. And yes, in case you’re wondering, <a href="https://www.youtube.com/watch?v=nfHuZ5qrYX4">Bing is still around</a>. Ecosia, DuckDuckGo, barely appear on the list.</p>
<p>If anything, this whole thing will reinforce Google’s monopoly on search. Users will see this<span></span> <span>’</span>choice screen’ and think:<span></span> <span>“</span><span>OK</span>, so two shady things I don’t know, Bing (laughs), and yep, Google. Why would they even ask me to choose?”</p>
<p>It’s like asking kids who have only ever watched the movie <em>Ratatouille</em> if they want to watch Ratatouille again, or another movie from this list: <a href="https://www.imdb.com/title/tt2120120/?ref_=fn_al_tt_1"><em>Pixels</em></a> (even the kids would know it sucks), <em><a href="https://www.imdb.com/title/tt0257778/?ref_=ttls_li_tt">The Hunchback of Notre Dame <span>II</span>: The Secret of the Bell</a></em> (you’re lucky if the kids even know about the first one), and <em><a href="https://www.imdb.com/title/tt0083630/?ref_=nv_sr_srsg_0">The Beastmaster</a></em>.</p>

          
          <p>
            <a href="https://thejollyteapot.com/tagged/technology">Technology</a>
          </p>

          
          


      

          <a href="https://thejollyteapot.com/2020/08/18/samsung-commits-to-deliver-three-years-of-android-updates-for-its-phones">
            <h5>Previous post</h5>
            <span>Samsung commits to deliver three years of Android updates for its phones</span>
            
          </a>

          <a href="https://thejollyteapot.com/2020/10/1/looking-back-at-my-short-list-of-apple-wishes-from-april">
            <h5>Next post</h5>
            <span>Looking back at my short list of Apple wishes from April</span>
          </a>

        </div></div>]]>
            </description>
            <link>https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635322</guid>
            <pubDate>Wed, 30 Sep 2020 03:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Live dashboard of every email Trump and Biden are sending]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24635143">thread link</a>) | @greggblanchard
<br/>
September 29, 2020 | https://sendview.io/trump-v-biden | <a href="https://web.archive.org/web/*/https://sendview.io/trump-v-biden">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <!--
            <h2 style="margin-bottom: 25px;">
              <em class="fa fa-calendar"></em>
              Live Campaign Timeline
              <span>Last 50, Newest to Oldest</span>
            </h2>-->
            <div>
              <p>
                <h2>
                  <em></em>
                  Live Campaign Timeline
                  <span>Camapaigns Listed Newest to Oldest</span>
                </h2>
              </p>
              
              
            </div>
              
                                        <p><a href="https://sendview.io/s/a_KqnCSMGkw07LHFQZ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'd like to give you a call <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  35mins ago</span>
              </a>
                                        <a href="https://sendview.io/s/a_fSAgmyN2U7MGpI8H" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Lyinâ€™ Obama <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3h 39m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_hcWgLrIAMy5zpSFK" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                re: your RSVP for my event today <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  5h 8m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_7iE9KWVLCjR3kozY" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your Matching Check <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5h 50m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_CXtLcqnNoMbSPAz6" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Youâ€™re going to love this <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6h 54m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_XbEVhKT8d6nFH2oR" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                President Obama and Kamala are counting on you <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  7h 28m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_1UjPHg54QoMSaYsu" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your flight to Houston <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  13h 50m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_IkizDcuOT8ylBC4H" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Update on our goal <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  15h 52m ago </span>
              </a></p><p>
                THURSDAY, OCT 1, 2020              </p>
                            <p><a href="https://sendview.io/s/a_Rlb26OAG8p9JSZjq" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                You + Me in LA <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_T0cKaYwRMfSVeX5G" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Are you free tomorrow? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  11:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_8wfpsh7CGvimO3nQ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Become a Trump MVP <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:15pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_Ok52vWoDCfpXqJcA" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your chance, Donald <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:13pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_nTg8lvFtqHN7rh2I" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                You, me, and President Obama tomorrow <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  7:36pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_C49HAINZvdL7qfYF" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Weâ€™ve got some just for you <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_F9iYc1rtlGE0ex8p" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ðŸŒž Sunny LA ðŸŒž <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:13pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_FeVqHJo9mNEpId6j" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We are in the fight of our life <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_986tWrmfPQL7d3TA" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Time is running out <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:24pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_BaW56ywqAEbDr7iP" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                President Obama and Kamala Harris want to know if you're free tomorrow <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  1:32pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_eBGadSwkztgQc6xF" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Congratulations! <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:28pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_1sBaJHTnCL6QMkhG" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                September 31st <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:46am</span>
              </a>
                                        <a href="https://sendview.io/s/a_P2Kcmzw5H38fXiB9" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Thank you for your support <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  10:36am</span>
              </a>
                                        <a href="https://sendview.io/s/a_u7YIdQZaELOiHhWm" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Letâ€™s meet up <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:07am</span>
              </a>
                                        <a href="https://sendview.io/s/a_fSjtBVY9CzRmWT35" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Itâ€™s not too late <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:13am</span>
              </a>
                                        <a href="https://sendview.io/s/a_MYU9n5oZziDfXmy6" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Take the Official Presidential Debate Approval Poll NOW <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:08am</span>
              </a>
                                        <a href="https://sendview.io/s/a_okW9C2DTvq8bdcwE" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ðŸš¨ End-of-Quarter ALERT ðŸš¨ <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:07am</span>
              </a>
                                        <a href="https://sendview.io/s/a_4psIDmQouE7Oyg3G" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your 850%-MATCHING check <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:07am</span>
              </a></p><p>
                WEDNESDAY, SEP 30, 2020              </p>
                            <p><a href="https://sendview.io/s/a_8PVaoth0nDJNEykg" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Will you be one of our final September donors? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  11:23pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_RpcftUMWwi8JkxG3" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Deadline: MIDNIGHT <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_35UwrGOA0ezop4l8" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We have to do this FIRST <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  10:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_sOn9lPbojwGCEKMu" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                FINAL THREE HOURS <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_g2hXH6RLT8MpJejP" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Election Day is ALMOST here <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:23pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_aT8wySMDbYRtKlQn" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Joe, Kamala, Barack, Hillary, and more all emailed you <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  8:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_mbgOeCs2aNpLfH3w" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We need to CRUSH our goal <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:38pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_uW3BVxv78zT9oUjh" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Itâ€™s now or never <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:52pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_cuLdqJb0gS6zPXCQ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ONLY 6 hours to step up <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_e8MqBiXOY4bt2Fzm" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'm worried we might fall short <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  5:42pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_g6weXC74azqjEROk" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                FINAL NOTICE <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:21pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_ZGMDk7Jf520IUnHE" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We need to keep going <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  4:06pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_gGD6aAfpl1SZ2W7i" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                BIDEN WILL PACK THE COURTS <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_EAJO4ailPtzcrvj2" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'm asking personally <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  12:45pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_YRjK5yF0L6euZxVi" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                â�°â�° 12-hour deadline alert â�°â�° <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_UC0hbDl6nYpSAFq9" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Please <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  10:40am</span>
              </a>
                                        <a href="https://sendview.io/s/a_i8Wxynv2m4AYKISe" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                âœ”ï¸� First Presidential Debate <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_PqzUhvEjTtuSNp3A" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                What did you think of the debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_8yrCmnIS4P7ZwaMc" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Special 800%-MATCH <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:08am</span>
              </a>
                                        <a href="https://sendview.io/s/a_T3yfNaQluA6vPtpX" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Did you watch the debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:05am</span>
              </a>
                                        <a href="https://sendview.io/s/a_GT7vWI6naMJZkmXc" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Iâ€™m upping the stakes <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_lnjKFNfErRepQAGg" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                800%-MATCH <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_N4Fuym97MhcG6RAx" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I hope I made you proud <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  12:30am</span>
              </a>
                                        <a href="https://sendview.io/s/a_s1EUWeLk89dGDzp2" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ðŸš¨ 850%-MATCH ðŸš¨ <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:09am</span>
              </a></p><p>
                TUESDAY, SEP 29, 2020              </p>
                            <p><a href="https://sendview.io/s/a_h8VmH9snxRl7GyJ3" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                I just stepped off stage <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:05pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_Yd1aZVuA8hbsSweX" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                My father is debating Joe Biden <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  10:40pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_4uZ0b1Ne9jEkwOgV" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Make it the BEST quarter EVER <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:28pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_HXN4R8D5sVU6hcfy" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Are you watching my father debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:28pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_0acVqb5pgKFn89Hx" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Are you watching? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  9:23pm</span>
              </a>
    …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sendview.io/trump-v-biden">https://sendview.io/trump-v-biden</a></em></p>]]>
            </description>
            <link>https://sendview.io/trump-v-biden</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635143</guid>
            <pubDate>Wed, 30 Sep 2020 02:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I tracked and analyzed 13,159 Hacker News posts. Here's what I learned]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24634991">thread link</a>) | @mellosouls
<br/>
September 29, 2020 | https://www.ankle.io/posts/hacker-news-analysis | <a href="https://web.archive.org/web/*/https://www.ankle.io/posts/hacker-news-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="motivation"><a href="#motivation" aria-label="motivation permalink"></a>Motivation</h2>
<p>Hitting the front page of Hacker News is an incredible source of short-term traffic to your website or article.</p>
<p>According to this <a href="https://thehftguy.com/2017/09/26/hitting-hacker-news-front-page-how-much-traffic-do-you-get" rel="nofollow">article</a>, in 2017, being on the front page brings a sudden influx of between 10k and 30k visitors to your website/article, something many content marketers, product people, and entrepreneurs undoubtedly salivate over, including me.</p>
<p>I occasionally post to Hacker News (with random things and personal stuff) but have never reached the front page before. Therefore, I decided to dig a little deeper into the mechanics of Hacker News and the best approach to take if the sole goal is to hit the front page.</p>
<p>Obviously, a critical part of hitting the front page is submitting an interesting article which resonates with the HN audience. But beyond this, there are other factors at play—timing, title, upvotes, etc.</p>
<h2 id="methodology-a-unique-approach"><a href="#methodology-a-unique-approach" aria-label="methodology a unique approach permalink"></a>Methodology: A unique approach</h2>
<p>I am not the only person to want to know the best approach to hitting the front page. A few people have analyzed data from <a href="https://console.cloud.google.com/marketplace/details/y-combinator/hacker-news" target="_blank" rel="nofollow noopener noreferrer">Google’s Hacker News Dataset</a> on BigQuery to find the best time to submit to Hacker News.</p>
<p>The problem with this approach is that BigQuery doesn’t know how long a post spent on the front page, nor how long it was there for or what position it reached. It can only provide the total number of upvotes.</p>
<p>With this in mind, I wrote a small NodeJS script to poll Hacker News every 2 minutes. Using a Postgres database, I stored every post, user, and upvote over two weeks.</p>
<p>With this information, I compiled a list of useful information and insights below.</p>
<p>Note: To filter out posts that are either flagged or transiently featured, I set an arbitrary duration of 60+ minutes as a time requirement in the top for a post to be considered a “front page post.”</p>
<h2 id="limitations"><a href="#limitations" aria-label="limitations permalink"></a>Limitations</h2>
<p>Obviously, the lack of data (13,159 posts) and time spent collecting data (2 weeks) is the most significant limitation of my results. Nonetheless, I believe the results are still relatively useful, at least for the next few weeks or months.</p>
<h2 id="results"><a href="#results" aria-label="results permalink"></a>Results</h2>
<h3 id="basic-stats"><a href="#basic-stats" aria-label="basic stats permalink"></a>Basic stats</h3>
<ul>
<li>I tracked a total of 13,159 posts over two weeks.</li>
<li>Of these, 1,073 made the front page for more than 60 minutes.</li>
<li>That’s a hit rate of 8.15%</li>
<li>Frontpage posts stayed at the top for an average of 483.3 minutes (8 hours)</li>
<li>30% of posts reaching the front page were posted by users who posted more than once over the two weeks.</li>
</ul>
<p><strong>Takeaway:</strong> In my opinion, more posts reach the front page than expected and for longer than expected.</p>
<h3 id="types-of-posts-breakdown"><a href="#types-of-posts-breakdown" aria-label="types of posts breakdown permalink"></a>Types of posts breakdown</h3>

<h3 id="hit-rate--of-different-post-types-making-the-front-page"><a href="#hit-rate--of-different-post-types-making-the-front-page" aria-label="hit rate  of different post types making the front page permalink"></a>Hit rate % of different post types making the front page</h3>

<p><strong>Takeaway:</strong> Interestingly, “Show HN” posts make the front page by proportion very slightly less than “Links,” which goes against previous thought that “Show HN” posts perform better due to an algorithm bias. That being said, there may well be an algorithm bias, just many “Show HN” posts are simply not worth upvoting.</p>
<h3 id="when-is-the-best-day-to-post-to-hacker-news-in-2020"><a href="#when-is-the-best-day-to-post-to-hacker-news-in-2020" aria-label="when is the best day to post to hacker news in 2020 permalink"></a>When is the best day to post to Hacker News in 2020?</h3>

<p>The chart above shows that you should post on the weekend to stand the best chance of reaching the front page of Hacker News. The difference from the worst to the best day is only 3.2%, so there’s not a lot in it.</p>
<p>The weekend likely gives you a higher chance to reach the front page because fewer posts are submitted, probably due to lower traffic.</p>
<p><strong>Takeaway</strong>: If your goal is to reach the front page regardless of traffic, posting on the weekend is your best bet. However, because the difference in chance is relatively low throughout the week, posting on a more popular day might be a better risk-reward ratio based on the considerable difference in the traffic you’d likely receive.</p>
<h3 id="when-is-the-best-time-to-post-to-hacker-news-in-2020"><a href="#when-is-the-best-time-to-post-to-hacker-news-in-2020" aria-label="when is the best time to post to hacker news in 2020 permalink"></a>When is the best time to post to Hacker News in 2020?</h3>

<p>Taking a more granular look at the combined hours of all the posts submitted, the chart above highlights a much more significant difference (10.9%) between the chance of reaching the front page of Hacker News.</p>
<p>The best time to post to Hacker News is between 6 am—12 pm UTC (11 pm—5 am PDT). Again, the reason is likely because this is when the website traffic is at it’s lowest, and therefore the competition is relatively low.</p>
<p>I imagine the US is responsible for most of Hacker News’s web traffic, which lines up with the results above. Therefore, if you are posting a link for a US-specific audience to HN, it’s probably best to pick a different time like 4 pm UTC (9 am PDT), or midnight UTC (5 pm PDT).</p>
<p><strong>Takeaway:</strong> If your link requires a US-specific audience, post at 4 pm UTC (9 am PDT / 12 pm EDT), or midnight UTC (5 pm PDT). Otherwise, post between 6 am—12 pm UTC (11 pm—5 am PDT) for the best chance of reaching the front page of Hacker News.</p>
<h3 id="when-in-the-best-day-and-time-to-post-to-hacker-news-in-2020"><a href="#when-in-the-best-day-and-time-to-post-to-hacker-news-in-2020" aria-label="when in the best day and time to post to hacker news in 2020 permalink"></a>When in the best day and time to post to Hacker News in 2020?</h3>
<p>Combining both days and hours into a total weekly picture is even more evident when it is best to post. However, please note, the lack of data makes this chart vulnerable to skewed results.</p>

<p>The chart above illustrates wild fluctuations between the different hours of the week. The lowest chance of reaching the front page is 1-2%, and the highest is 18%-27%. That’s a massive difference.</p>
<p>Looking at the chart, below are generally the best days &amp; times to post to Hacker News:</p>
<ul>
<li><strong>Monday:</strong> 1 am—4 pm UTC (6 pm—9 am PDT)</li>
<li><strong>Tuesday, Wednesday &amp; Thursday:</strong> 12 am—6 am &amp; 9 am—12 pm UTC (5 pm—11 pm &amp; 2 am—5 am PDT)</li>
<li><strong>Friday:</strong> 5 am—12 pm UTC (10 pm—5 am PDT)</li>
<li><strong>Saturday:</strong> 4 am—9 am UTC (9 pm—2 am PDT)</li>
<li><strong>Sunday:</strong> 3 am—8 am &amp; 10 am—6 pm UTC (8 pm—1 am &amp; 3 am—11 am PDT)</li>
</ul>
<p>And here are the best times specifically (bear in mind these may not be the case week-in-week-out because the amount of data limits the results):</p>
<ul>
<li><strong>Monday:</strong> 12 pm UTC (5 am PDT)</li>
<li><strong>Tuesday:</strong> 9 am UTC (2 am PDT)</li>
<li><strong>Wednesday:</strong> 10 am UTC (3 am PDT)</li>
<li><strong>Thursday:</strong> 12 pm UTC (5 pm PDT)</li>
<li><strong>Friday:</strong> 8 am UTC (1 am PDT)</li>
<li><strong>Saturday:</strong> 9 am UTC (2 am PDT)</li>
<li><strong>Sunday:</strong> 5 am OR 1 pm (10 pm OR 6 am PDT)</li>
</ul>
<p><strong>Takeaway:</strong> It’s pretty clear that the best times to post on Hacker News to reach the front page are usually around 6 am UTC (11 pm PDT), 9 am UTC (2 am PDT), or 12 pm UTC (5 am PDT), when the US is asleep.</p>
<p>However, given that 8 hours is the average time spent on the front page, it’s probably best to post at 12 pm UTC on Monday, Thursday, Saturday or Sunday to maximize traffic for when the US wakes up.</p>
<h3 id="how-many-votes-does-a-post-need-to-reach-the-front-page-of-hacker-news-in-2020"><a href="#how-many-votes-does-a-post-need-to-reach-the-front-page-of-hacker-news-in-2020" aria-label="how many votes does a post need to reach the front page of hacker news in 2020 permalink"></a>How many votes does a post need to reach the front page of Hacker News in 2020?</h3>
<p>5.22 is the average number of votes a post needed within an average time of 27.1 minutes to reach the front page for the first time.</p>
<p>Below is a chart of box plots to illustrate the variation of votes required over 24 hours.</p>

<p>Interestingly, this graph clearly shows every post, regardless of time, required at least three upvotes, and for 75% of posts, they never needed more than eight votes to reach the front page of Hacker News.</p>
<p>Expectedly, the range of upvotes required is lower for the first half of the day than the second half, roughly matching up to the timings above.</p>
<p>In some cases, posts required a lot more votes to reach the front page. Presumably, because either the time it took to get these votes was over more time, or there was a lot of competition.</p>
<p><strong>Takeaway:</strong> The votes required to be seen on the front page is relatively small. For the best chance of getting on the front page, you’ll need between 4-6 votes in about 30 minutes, posting in the first half of the day (12 am—12pm UTC).</p>
<h3 id="how-much-karma-do-you-need-to-reach-the-front-page-of-hacker-news-in-2020"><a href="#how-much-karma-do-you-need-to-reach-the-front-page-of-hacker-news-in-2020" aria-label="how much karma do you need to reach the front page of hacker news in 2020 permalink"></a>How much karma do you need to reach the front page of Hacker News in 2020?</h3>
<p>Finally, I thought it would be interesting to see the relationship between karma and reaching the front page of Hacker News.</p>
<p>This first pie chart demonstrates the proportion of posts being posted by users with varying levels of karma.</p>

<p>Surprisingly, over 50% of posts are submitted by users with over 1,000 karma points. However, the largest single segment is by users with little to no karma.</p>

<p>The chart above shows that newer users (0-50 karma) make the front page proportionally less than more experienced users. Interestingly, really experienced users (over 10,000 karma) reached the front page significantly more than experienced users.</p>
<p><strong>Takeaway:</strong> It’s hard to say whether karma has anything to do with rankings. Likely, users with more karma are just better at posting content that resonates with the Hacker News audience.</p></div></div>]]>
            </description>
            <link>https://www.ankle.io/posts/hacker-news-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634991</guid>
            <pubDate>Wed, 30 Sep 2020 01:43:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guima Cloud – TLA+ Online Simple REPL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634705">thread link</a>) | @pfeodrippe
<br/>
September 29, 2020 | https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ== | <a href="https://web.archive.org/web/*/https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ==">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ==</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634705</guid>
            <pubDate>Wed, 30 Sep 2020 00:42:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Presentation on the noa voxel game engine, made and presented in-engine (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634564">thread link</a>) | @trynewideas
<br/>
September 29, 2020 | http://andyhall.github.io/noa-lt/ | <a href="https://web.archive.org/web/*/http://andyhall.github.io/noa-lt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="slideBox">
      
      
      <div id="intro1">
        <p>Voxels in V8</p>
        <div><p>
          To start, click and allow pointer lock.
          </p><p>Slides thataway! → 
        </p></div>
        <p>Andy Hall
          <br>2015.7.16
        </p>
      </div>
      
      
      
      <div id="intro2">
        <p>
          Using this presentation:
        </p>
        <div>
          <p>
            move around:<br>
            invert mouse:<br>
            destroy block:<br>
            place block:<br> 
            pick block:<br> 
            camera zoom:<br> 
            jump:<br> 
            jet pack:<br>
            pause:
          </p>
          <p><code>WASD</code>, arrows
            <br> <code>I</code>
            <br> LMB, tap
            <br> <code>E</code>, RMB
            <br> <code>Q</code>, middle mouse
            <br> <code>F</code>, scroll
            <br> <code>space</code>
            <br> <code>R</code>
            <br> <code>P</code>
          </p>
        </div>
        <p>
          (mobile users: sorry lol)
        </p>
      </div>

      <div id="intro3">
        <p>
          About me:
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/profile.png"></p><p><span>
            @fenomas
          </span>
          <br> free gamedev, sometime technical evangelist
          <br> github/andyhall
          <br> aphall.com
        </p>
      </div>



      <div id="voxel1">
        <p>
          Voxels - definition
        </p>
        <div><p>
          tl;dr:
          </p><p>
            Ever seen Minecraft? 
            <br> Yeah those.
          </p>
        </div>
      </div>

      <div id="voxel2">
        <p>
          Voxels - proper definition
        </p>
        <p>
            Rasterized 3D data.
          </p>
        <p>
          Colloquially, if pixels represent
          the rasterization of 2D data,
          voxels are the 3D equivalent.
        </p>
        <p>
          (Hence "voxel": volumetric pixel)
        </p>
      </div>

      <div id="voxel3">
        <p><img src="http://andyhall.github.io/noa-lt/pics/sampling.png"></p><p>
          Conceptually, voxels are a <i>sampling</i> over some 3D space,
          just as pixels in a bitmap are samples of 
          some 2D data (vector graphics, photos, etc).
        </p>
        <p>
          (Note: click this block for the 
          <i>amazing</i> webGL demo <br>I stole that image from)
        </p>
        <!-- note to any semantic purists viewing source: -->
        <!-- Those <i> tags are just my way of saying "howdy!" <3 -->
      </div>

      <div id="voxel4">
        <p>
          Note: nothing (per se) to do with gaming!
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/ct_scan.jpg"></p><p>
          (CT scan data)
        </p>
      </div>




      <div id="game1">
        <p>
          Voxels and Gaming
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/Comanche_1992.png"></p><p>
          Comanche, 1992
        </p>
        <p>
          (Click: list of games with voxels)
        </p>
      </div>

      <div id="game2">
        <p>
          Voxel advantages
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/Shogi_Ban_Koma.jpg"></p><p>
          Provides game with easily grasped structure -
          <br>
          Equivalent to grids in 2D games
        </p>
      </div>

      <div id="game3">
        <p>
          Conceptually easy to work with
        </p>
        <div>
          <ul>
            <li>Technical tradeoffs (e.g. CPU vs memory) 
              largely similar to vectors/bitmaps</li>
            <li>Some hard things become easy 
              (raycasting, collision tests..)</li>
            <li>(Of course some easy things become hard..)</li>
          </ul>
        </div>
      </div>

      <div id="game4">
        <p>
          Voxel advantages
        </p>
        <p>
            Mutable worlds for free! (ish)
          </p>
        <p>
          (click: anywhere but here, yo)
        </p>
      </div>

      <div id="game5">
        <p>
          World-affecting game rules
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/Gospers_glider_gun.gif"></p><p>
          c.f. "Emergent gameplay"
        </p>
        <div>
          <p>
            Note:
          </p>
          <p><code>"3"</code> to place a Conway Block
            <br><code>"4"</code> to stop/start simulation
            <br><span>(click: explanation)</span>
          </p>
        </div>
      </div>

      <div id="game6">
        <p>
          Note: not just for rendering!
        </p>
        <p>
          Voxels are often useful behind the scenes 
          regardless of how a game looks
          (e.g. for physics simulation).
        </p>
        <p>
          Conceptually: 3D games should use voxels wherever 
          a 2D game would use a grid.
        </p>
      </div>




      <div id="render1">
        <p>
          Rendering Voxels
        </p>
        <p>
            GPUs do not grok voxels!
          </p>
        <p>
          In general a conversion step ("meshing")
          is necessary to convert voxels into 
          stuff that GPUs understand
          (vertex lists, normals, etc).
        </p>
        <p>
          Here are three approaches:
        </p>
      </div>

      <div id="render2">
        <p>
          Naive Meshing
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/doob.png"></p><p>
          (click: mrdoob's voxel demo)
        </p>
        <p>
          Create one cubic mesh per voxel
        </p>
        <p>
          Problems: poly counts, draw calls
        </p>
      </div>

      <div id="render3">
        <p>
          Culled Meshing
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/culled.png"></p><p>
          Merge voxels into one large mesh, 
          <br>omitting faces between adjacent voxels.
        </p>
        <p>
          Result: fewer draw calls, still a lot of polys
        </p>
      </div>

      <div id="render4">
        <p>
          "Greedy Meshing"
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/greedy.png"></p><p>
          Scan across voxel slices, merging faces of 
          adjacent voxels (of the same value).
        </p>
        <p>
          Credit: all-around genius 
          <span>Mikola Lysenko</span>
        </p>
        <p>
          (click: algo explanation + live demo)
        </p>
      </div>

      <div id="render5">
        <p>
          Chunking
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/chunk.png"></p><p>
          Necessary tradeoff for large worlds:
          <br> faster meshing, more draw calls.
        </p>
        <p>
          Minecraft chunks: 16x16x256 (divided vertically)
          <br>This demo: arbitrary (32x32x32 at the moment)
        </p>
      </div>

      <div id="render6">
        <p>
          Ambient Occlusion
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/ao.jpg"></p><p>
          Comparatively simple for voxels, 
          <br> and greatly improves visuals
        </p>
        <p><span>Click: toggle AO in this demo</span>
          <br>(then place a block to trigger meshing)
        </p>
      </div>

      <div id="render7">
        <p>
          Note: Voxels needn't be blocks!
        </p>
        <div>
          <div>
            <p><img src="http://andyhall.github.io/noa-lt/pics/voxel-quest.png">
            </p>
            <p>
              Voxel Quest
            </p>
            <p>
              (click: it's beautiful)
            </p>
          </div>
          <div>
            <p><img src="http://andyhall.github.io/noa-lt/pics/ct.jpg">
            </p>
            <p>
              CT scan data
            </p>
            <p>
              (google "marching squares")
            </p>
          </div>
        </div>
      </div>

      <div id="render8">
        <p>
          In fact...
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/crooked.png"></p>
      </div>



      <div id="world1">
        <p>
          World generation
        </p>
        <p>
          Driven deterministically by 
          noise (Perlin, simplex) and hashing.
        </p>
        <p>
          In this demo:
        </p>
        <p>
          2D noise: height map
          <br> 3D noise: clouds
          <br> Hashing: tree/flower placement
        </p>
        <p>
          (click: my homemade n-dimensional hash!)
        </p>
      </div>

      <div id="world2">
        <p>
          Other world algorithms
        </p>
        <p>
          Many voxel algos extend naturally from 
          2D cases (often heavily researched).
        </p>
        <div>
          <ul>
            <li>Collision tests: simple grid check</li>
            <li>Raycasting: equivalent to line rasterization (e.g. Bresenham)</li>
            <li>Physics: had to roll my own, but easier than 3D</li>
          </ul>
        </div>
      </div>




      <div id="noa1">
        <div><p>
          noa (this engine)
          </p><p>
           And how I built it
        </p></div>
      </div>

      <div id="noa2">
        <p>
          Dev stack:
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/browserify_with_hat.png"></p><p>
          node | npm | browserify | beefy
        </p>
        <p>
          (this slide is out of date, <br>I use webpack now..)
        </p>
      </div>

      <div id="noa3">
        <p>
          Why roll a new engine?
        </p>
        <p>
          I started trying to use 
          <span>voxel.js</span>
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/voxeljs.png"></p><div>
          <p>
            Pros:
            <br> Tons of great code
            <br> Extremely modular
          </p>
          <p>
            Cons:
            <br> Massively coupled
            <br> Dependency hell
            <br> Renders on bare metal
          </p>
        </div>
      </div>

      <div id="noa4">
        <p>
          noa's approach:
        </p>
        <div>
          <ul>
            <li>Reuse code from voxel.js where feasible 
              <br> (raycasting, meshing..)</li>
            <li>Otherwise written from scratch 
              <br> (physics, rendering, controls, AO..)</li>
            <li><span>Babylon.js for rendering (click)</span></li>
          </ul>
        </div>
      </div>

      <div id="noa5">
        <p>
          State of the project
        </p>
        <div>
          <ul>
            <li>Works(?), performant(?) </li>
            <li>No docs, all APIs in flux</li>
            <li><span>Features: see testbed app (click)</span></li>
            <li>Collaboration welcome, drop me a mail/issue/etc</li>
          </ul>
        </div>
      </div>



      <div id="thoughts1">
        <p>
          "Is [HTML/JS] really [ready/fast enough] for gaming yet?"
        </p>
        <p>
          My thoughts after 5 months:
        </p>
      </div>
      
      
      <div id="thoughts2">
        <p>
          Mainly depends on how broad your scope is
        </p>
        <div>
          <ul>
            <li>Targeting one version of one browser makes for an easy life ;)</li>
            <li>Modern JS is a solid dev platform, if you modularize responsibly</li>
            <li>The more you use the DOM, the more performance will vary across browsers</li>
            <li>Mobile: what's that? Does it taste good?</li>
          </ul>
        </div>
      </div>


      <div id="thoughts3">
        <p>
          Performance in V8
        </p>
        <div>
          <ul>
            <li>V8 is very fast, but temperamental</li>
            <li>Getting great performance is still ~50% black magic</li>
          </ul>
        </div>
      </div>


      <div id="thoughts4">
        <p>
          Key takeaway #1:
        </p>
        <div>
          <ul>
            <li>Don't waste time guessing what will perform well in V8 - it can't be done</li>
            <li>Master the dev tools instead</li>
            <li><strong>Profile</strong></li>
          </ul>
        </div>
      </div>

      <div id="thoughts5">
        <p>
          Key takeaway #2:
        </p>
        <div>
          <ul>
            <li><strong>Deopts</strong> murder performance!</li>
            <li>They can occur unpredictably, and for bizarre reasons.</li>
            <li>When all else fails: <br><code>chrome --js-flags = "--trace-deopt"</code></li>
          </ul>
        </div>
      </div>



      <div id="thanks">
        <p>
          Thanks!
        </p>
        <p>
          @fenomas
          <br>
          <span>github.com/andyhall</span>
        </p>
      </div>

      
      
      
      
      
    </div></div>]]>
            </description>
            <link>http://andyhall.github.io/noa-lt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634564</guid>
            <pubDate>Wed, 30 Sep 2020 00:17:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bad Steak Led to a $4B Organization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634465">thread link</a>) | @aml183
<br/>
September 29, 2020 | https://www.arilewis.com/aris-posts/how-a-bad-steak-led-to-a-4b-organization | <a href="https://web.archive.org/web/*/https://www.arilewis.com/aris-posts/how-a-bad-steak-led-to-a-4b-organization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-bc7fa26ba5a57652a526"><div><p>In 1975, Harold Etling went to eat a steak. Harold, a lifelong rancher, left the meal disappointed. His steak didn't meet his expectations. Harold decided to do something about it. He approached the American Angus Association. In January 1978 in West Salem, Ohio, the brand <a href="https://www.certifiedangusbeef.com/">Certified Angus Beef</a> (CAB) launched.</p><p>In the mid-‘70s the USDA lowered their standards for beef. Less quality control over beef meant that the quality could be lessened. If consumers experienced a wide range of tastes when eating beef it could lead to lower consumer demand. This was the issue that Harold Ettling faced.</p><p>The establishment of the Certified Angus Beef brand would solve this. The American Angus Association would manage the brand. Every piece of meat would need to go through rigorous process.</p><p>The program sold its first piece of beef in October 1978. Right after this sale, the USDA canceled the program. They believed the program was misleading. CAB branded beef sold at a premium, which the USDA thought was unfair marketing.</p><p>Mick Colvin, an employee of the American Angus Association, fought the USDA and won. On April 2nd, 1979, the USDA re-approved the brand. In order to be a CAB, you needed to meet <a href="https://davesjubilee.com/departments/meat">10 standards</a>:</p><ul data-rte-list="default"><li><p>Modest or higher marbling – for the taste it ensures customer satisfaction</p></li><li><p>Medium to fine marbling texture – the white “flecks of flavor” in the beef that ensure consistent flavor and juiciness in every bite</p></li><li><p>“A” Maturity – the youngest classification of product delivers superior color, texture and tenderness</p></li><li><p>10- to 16-square-inch ribeye area</p></li><li><p>Less than 1,000-pound carcass weight</p></li><li><p>Less than 1 inch external fat</p></li><li><p>Superior beef muscling – restricts the influence of less-tender dairy cattle</p></li><li><p>Practically free of capillary rupture – ensures the most visually appealing steak</p></li><li><p>No dark cutters – ensures the most visually appealing steak</p></li><li><p>No neck hump exceeding 2 inches – safeguards against cattle with variability in tenderness</p></li></ul><p>Independent USDA graders determine if the beef meets the proper requirements. In the first few years, the CAB grew slowly. <a href="https://www.google.com/search?ei=k5RzX_XbDIyF9PwPy5ux2AQ&amp;gs_lcp=CgZwc3ktYWIQAzIECAAQDTIECAAQDTIECAAQDTIECAAQDTIECAAQDTIKCC4QxwEQrwEQDTIECAAQDTIGCAAQDRAeMgYIABANEB4yBggAEA0QHjoECAAQRzoFCAAQkQI6CwguELEDEMcBEKMCOggILhCxAxCDAToFCAAQsQM6CAgAELEDEIMBOggILhDHARCjAjoCCAA6BAgAEEM6CgguEMcBEKMCEEM6AgguOgcILhCxAxBDOhAILhCxAxCDARDHARCjAhBDOgcILhBDEJMCOgcIABCxAxBDOgQILhBDOgUILhCxAzoHCC4QChCTAjoECAAQCjoFCC4QkwI6BAguEAo6BggAEBYQHlCIGFjMIWD-ImgAcAN4AYABqQGIAcIKkgEEMS4xMJgBAKABAaoBB2d3cy13aXrIAQXAAQE&amp;oq=mick%20colvin&amp;q=mick%20colvin&amp;sclient=psy-ab&amp;sxsrf=ALeKk01A4an2KEZkMMf_XL6Jk0C9hAxEeA%3A1601410195216&amp;uact=5&amp;ved=0ahUKEwi18czulY_sAhWMAp0JHctNDEsQ4dUDCA0">But by, 1983, the program was profitable</a>. The CAB had a leg up on burgeoning competitors. Its tacit endorsement from the USDA was heavily promoted.</p><p>In 2012, <a href="http://www.angus.org/pub/newsroom/releases/101812_SixthRecordSalesYearforTopQualityBeefBrand.html">CAB's growth</a> was far and away above any of its competition:</p><ul data-rte-list="default"><li><p>16,000 licensed partners</p></li><li><p>$4B in annual consumer sales worldwide</p></li><li><p>10% increase year over year wholesale value of a carcass</p></li></ul><p>The last stat is the most impressive. In 2011, the price of CAB carcass was $180.99/cwt. In 2012, the price was $199.71. This proved that consumers <a href="https://www.beefmagazine.com/blog/cab-nolan-ryan-prove-quality-consistency-pay">cared about the CAB brand</a>. Even with a national cattle shortage in 2012, consumers were willing to pay a premium to buy CAB over non CAB beef. Branding really does work.</p><p>It's a significant reason why consumers equate the word Angus with a higher-quality beef. It's also the reason why many associations have started competing certification programs.</p><p>Take McDonald's for an example. Over the past decade, McDonald's has advertised their hamburgers as <a href="https://www.thestreet.com/personal-finance/credit-cards/should-you-pay-extra-angus-beef-12803768">"made with 100% Angus beef"</a>. However, Angus beef isn't always certified Angus beef. If I wasn't writing this article, I wouldn't have known that. How would the average consumer know that?The CAB says that McDonald's burgers aren't CAB. They issued a statement, "Certified Angus Beef does not go to fast-food restaurants. It’s at the higher-end restaurants,” That's been a defining differentiator of CAB since it's inception: premium beef.</p><p>CAB has positioned the company for a middle-upper class audience. Its customer cares about the quality of its beef, has disposable income and is typically white-collar.</p><p>CAB <a href="https://www.hartinc.com/work/case-studies/cab">hired PR firm</a>, Hart, to ensure it's brand wasn't diluted further by fast-food restaurants. Its goal was simple: remind consumers that CAB was the finest premium beef on the market. They used paid, owned and earned media to tell the story. It featured ranchers working from early morning to late evening raising cattle.</p><p>The campaign worked: </p><ul data-rte-list="default"><li><p>92% aided awareness of the Certified Angus Beef brand reached an all-time high. </p></li><li><p>2 to 1 consumer preference of the brand over competing grades and brands of beef. </p></li><li><p>76% of consumers said they would pay $1 extra per pound for Certified Angus Beef </p></li></ul><p>Today, CAB is recognized as the premium beef in the market. It's combination of superior branding and excellent messaging has succeeded. When you think of premium beef, you think Certified Angus Beef. In the fiscal year 2019, <a href="https://news.certifiedangusbeef.com/certified-angus-beef-brand-announces-15th-consecutive-year-of-growth/">CAB sold 1.25B pounds of meat</a>.</p><p>Harold Etling's bad steak in 1975 led to the creation of a brand with $4B+ of sales. The next time you have a good steak at a restaurant, don't forget to thank Harold Etling. He is probably the reason why.</p></div></div></div>]]>
            </description>
            <link>https://www.arilewis.com/aris-posts/how-a-bad-steak-led-to-a-4b-organization</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634465</guid>
            <pubDate>Tue, 29 Sep 2020 23:58:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop API Bugs by Inferring Data Formats]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634262">thread link</a>) | @jeanyang
<br/>
September 29, 2020 | https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f739975679d4246c3a8f013" data-item-id="5f739975679d4246c3a8f013">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1601411504262" id="item-5f739975679d4246c3a8f013"><div><div><div data-block-type="2" id="block-ec1b34ef166efd6e8b4c"><div><p>If you work on web apps, you’ve probably been bitten by a sneaky bug. You know, the kind that takes a long time to debug, but is not glamorous to explain. The whitespace errors; the data format errors. The kind of bug that might torment you for a whole weekend, that you emerge with no victorious war story to tell. This is the kind of bug that types have largely solved in languages like TypeScript and MyPy… but that still lurk at the boundaries of APIs.</p><p>In our <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_product_update">last blog post</a>, we talked about how to catch cross-service bugs by watching API traffic. In this blog post, we show specifically how checking data formats across APIs can catch some nasty bugs.</p><h2>😈 An Error that Evades Any Type Checker</h2><p>You finish implementing a new feature. Your unit tests pass and you get that rush of excitement. The integration tests go green; you think today is a good day. Your co-worker and #bff Aki give your changes a +1 and your pull request gets merged. For one moment, everything seems right with the world.</p><p>And then, hours later, DISASTER! You’re playing online games with Aki—and doing better than you ever have before—when you get a page. Customer support creates an incident that has to do with&nbsp; your new code. Customers are irate that they can’t log into your website.&nbsp;</p><p>You rush home and, after spending the rest of your night combing through logs and writing more tests, you figure it out. It turns out that you accidentally used phone.ToString() instead of phone.ToInternationalString(), causing you to send a domestic phone number instead of an international phone number as a string to a third-party API. The integration tests didn’t cover this because they mocked out this third-party API. But now you’ve lost your rare chance to beat Aki at Fall Guys—and you’ve also tripped up some of your customers.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_54474"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411677399-5IDG23VYLQXROLTDUU55/ke17ZwdGBToddI8pDm48kPpDoBIqNy1gGho9uyT02YZZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFMU71HPrJlrka-k3KdzI_LQkclrYoo_JyQT2V0r-tdNKQvevUbj177dmcMs1F0H-0/taylor_sad.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411677399-5IDG23VYLQXROLTDUU55/ke17ZwdGBToddI8pDm48kPpDoBIqNy1gGho9uyT02YZZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFMU71HPrJlrka-k3KdzI_LQkclrYoo_JyQT2V0r-tdNKQvevUbj177dmcMs1F0H-0/taylor_sad.gif" data-image-dimensions="474x264" data-image-focal-point="0.5,0.5" alt="taylor_sad.gif" data-load="false" data-image-id="5f739a4eee510b07270a2163" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_54774"><div><div><p>After the incident, you do a postmortem and you become worried. Aki pointed out that even if you adopt language-level type-checking (like TypeScript or MyPy) to catch simple errors, application-level type checking can’t prevent these kinds of errors because it doesn’t check across APIs.&nbsp; And once the type-checked values hit the wire they all get flattened to the same thing, so you would need some sort of magical tool to check across APIs. But what if such a tool existed!</p></div><h2>✅ Find Bugs by Inferring Data Formats</h2><p>Worry no more! We’ve designed Akita to solve exactly this problem of spotting mismatched data formats across the API. With Akita, you can use our data format detection to easily detect issues like this phone number change, without requiring code changes or proxies, simply by allowing Akita to watch your API.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_59847"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411952800-JK2S67YP5CF31NPWCLI6/ke17ZwdGBToddI8pDm48kMyRRiflT06lnOxwOXunTyhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIA6t7DZobKPBVSOztKpfySwZxaCI6SYU1XSvACXqsgGM/Screenshot+from+2020-09-28+22-15-02+cropped.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411952800-JK2S67YP5CF31NPWCLI6/ke17ZwdGBToddI8pDm48kMyRRiflT06lnOxwOXunTyhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIA6t7DZobKPBVSOztKpfySwZxaCI6SYU1XSvACXqsgGM/Screenshot+from+2020-09-28+22-15-02+cropped.png" data-image-dimensions="913x327" data-image-focal-point="0.5,0.5" alt="Screenshot from 2020-09-28 22-15-02 cropped.png" data-load="false" data-image-id="5f739b7077323e2df7bfc2db" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411952800-JK2S67YP5CF31NPWCLI6/ke17ZwdGBToddI8pDm48kMyRRiflT06lnOxwOXunTyhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIA6t7DZobKPBVSOztKpfySwZxaCI6SYU1XSvACXqsgGM/Screenshot+from+2020-09-28+22-15-02+cropped.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_60146"><p>Because Akita doesn’t require code changes or proxying, our client is flexible enough to run in either production or test, allowing you to compare cross-API data formats in production with cross-API data formats in test. In this case, Akita would alert you that the data format it observed differed from what it’s been observing, alerting you to the fact that something doesn’t check out, allowing this change to never ever hit production in the first place.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_64928"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412109060-KGP84JD9ODP52RRUX779/ke17ZwdGBToddI8pDm48kJpyheux0nskDQnuBO6NswxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzOPLDh9C41HHctUU2yVgyeUpUWeQq1WB4LsiaPpGbT1yQsc-5Y5TXjYGqI9wQD6R0/taylor_never_ever.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412109060-KGP84JD9ODP52RRUX779/ke17ZwdGBToddI8pDm48kJpyheux0nskDQnuBO6NswxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzOPLDh9C41HHctUU2yVgyeUpUWeQq1WB4LsiaPpGbT1yQsc-5Y5TXjYGqI9wQD6R0/taylor_never_ever.gif" data-image-dimensions="500x256" data-image-focal-point="0.5,0.5" alt="taylor_never_ever.gif" data-load="false" data-image-id="5f739c09679d4246c3a99af4" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_65227"><div><p><br>Akita is able to identify:</p><ul data-rte-list="default"><li><p><strong>Simple Types:</strong> Strings, Integers, Booleans, Floats</p></li><li><p><strong>Countries</strong> - 2 and 3 Letter Country Codes, Names and TLDs</p></li><li><p><strong>Currencies</strong> - Names and Abbreviations</p></li><li><p><strong>Dates and Times</strong> - ISO 8601, RFC 822, RFC 3339, RFC 850, Unix Timestamps and many more</p></li><li><p><strong>Email Address </strong>- RFC 5322 Address and Names</p></li><li><p><strong>Languages</strong> - Language names and ISO 639 2 and 3 Letter abbreviations</p></li><li><p><strong>Phone Numbers -</strong> International and US formatting</p></li><li><p><strong>URLs</strong> - HTTP and HTTPs URLs</p></li></ul><p>Akita works for traffic both to other internal services and for third-party SaaS APIs you might call, like Stripe or Twilio. We’ll talk more in an upcoming blog post about Akita’s specific mechanism for watching outbound API traffic.</p><h2>⚡️ Powered By API-Level Data Format Inference</h2><p>Under the hood, Akita is automatically inferring data formats from the API traffic that it sees. When Akita sees a request hit your service, it infers the data format for each argument as part of the automated API spec generation we described in the <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_product_update">last post.</a></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_99871"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412377516-AVPK5MR1GWHX5VZQDXKS/ke17ZwdGBToddI8pDm48kKabkCx_A6_n5l8sjGWuzexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIN_WYAvM0X0a_DzWYffUj58M1ML9geH0aEkZDHcuKpmg/Screen+Shot+2020-09-28+at+10.19.01+PM.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412377516-AVPK5MR1GWHX5VZQDXKS/ke17ZwdGBToddI8pDm48kKabkCx_A6_n5l8sjGWuzexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIN_WYAvM0X0a_DzWYffUj58M1ML9geH0aEkZDHcuKpmg/Screen+Shot+2020-09-28+at+10.19.01+PM.png" data-image-dimensions="915x476" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-09-28 at 10.19.01 PM.png" data-load="false" data-image-id="5f739d19fd31ed0454ae3504" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412377516-AVPK5MR1GWHX5VZQDXKS/ke17ZwdGBToddI8pDm48kKabkCx_A6_n5l8sjGWuzexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIN_WYAvM0X0a_DzWYffUj58M1ML9geH0aEkZDHcuKpmg/Screen+Shot+2020-09-28+at+10.19.01+PM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_105841"><div><p>It turns out inferring data formats is not as simple as just watching each argument. There might be multiple data formats that a field is eligible for. For instance, `18001112222` could be either a phone number or a time stamp, but a second call to the same endpoint with `1-800-333-4444` makes it clear that parameter is a phone number. A field that accepts strings may accept the occasional email. To infer the most accurate type, Akita compares data from <em>all </em>requests to the same endpoint and identifies the data formats common across all calls.&nbsp; We also use a bit of secret sauce to compare data formats across <em>data flows</em> we detect across your API, but that's the topic of another post.</p><p>Of course, there's always the chance that your API successfully accepts, say, phone numbers and timestamps (or email addresses, country codes, and so on) in the same parameter.&nbsp; In that case, we'll let you know all the data formats that fit the data.</p><p>There are a couple of cool things about how we’re inferring data formats. First, we’re using type inference to infer types at the API level, rather than analyzing source code. Second, we’re inferring specific data formats, with the ability to tell the difference between different phone number formats, on top of simple types like string or int. A bonus is that since Akita automatically infers the entire API spec under the hood, our type inference can use the structure of that spec. More on this in a later post!</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_107297"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412447877-RPBWJLV50EOV6NNQMLXQ/ke17ZwdGBToddI8pDm48kIisVeufsLaqPYS75OuX1FxZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGUIyZMpo6jDvOlV8ELZznZDi-rr9EJ6o3n8IpvEJDIMaEcAfnVBrEqrgp1UxUHGkY/taylor_never_find_another.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412447877-RPBWJLV50EOV6NNQMLXQ/ke17ZwdGBToddI8pDm48kIisVeufsLaqPYS75OuX1FxZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGUIyZMpo6jDvOlV8ELZznZDi-rr9EJ6o3n8IpvEJDIMaEcAfnVBrEqrgp1UxUHGkY/taylor_never_find_another.gif" data-image-dimensions="480x270" data-image-focal-point="0.5,0.5" alt="taylor_never_find_another.gif" data-load="false" data-image-id="5f739d4d556a54782e7388f8" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_107596"><div><h2>👀 What’s next?</h2><p>We’ve recently released type inference and would love to have you try it out. We believe we have a one-of-a-kind tool and would love your help in making it as useful as possible in helping developers build great software.</p><ul data-rte-list="default"><li><p><a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_product_update">Sign up for our private beta</a> if you’re interested in trying things out!</p></li><li><p>We’re constantly trying to make our tool better! If change analysis is an issue for you, please <a href="https://akitasoftware.typeform.com/to/iAbs1tB5?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_product_update">fill out this survey</a>—and the opportunity to win a $50 Amazon gift card.</p></li><li><p>Have data formats you’d like us to support? <a href="https://akitasoftware.typeform.com/to/lNd7IT7g?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_data_type_survey">Fill out this survey</a> to tell us what you care about.</p></li><li><p>Please spread the word! We’d love all the feedback we can get.</p></li></ul></div></div></div></div></div>

    

    

    <section id="comments-5f739975679d4246c3a8f013">
      
  


    </section>

  </article>





  <nav>

    

    
      <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior">
        <div>
          <p>Next</p>
          <h4>Earlier, Faster, Better, Stronger: Catch Breaking Changes by Diffing API Behavior</h4>
          <div>
            <!--

            Categories

            --><p><span>Approach, Releases</span></p><!--

            Author

            --><p><span>Jean Yang</span></p><!--

            Date

            --><p><time datetime="2020-09-22">September 22, 2020</time></p><!--

            Tags

            --><p><span>semantic diffs, API spec generation</span>
          </p></div>
        </div><!--
        --><svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="1.5,45.7 20.4,23.5 1.5,1.3 "></polyline>
          </g>
        </svg>
      </a>
    

  </nav>
              </section>
            
          </main>

        </div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634262</guid>
            <pubDate>Tue, 29 Sep 2020 23:28:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hitboxes That Feel Good: Reinventing the Goomba Stomp]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634144">thread link</a>) | @kuiro5
<br/>
September 29, 2020 | https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/ | <a href="https://web.archive.org/web/*/https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">


		
			<article id="post-479">
    
    		<section>
		    
<p>Update: Ready Set Goat has been released! Check out more at <a href="https://www.readysetgoat.com/">www.ReadySetGoat.com</a></p>



<p>iOS: <a href="https://apps.apple.com/us/app/ready-set-goat/id1498158058?ls=1">https://apps.apple.com/us/app/ready-set-goat/id1498158058?ls=1</a><br>Android: <a href="https://play.google.com/store/apps/details?id=net.subpixel.ReadySetGoat">https://play.google.com/store/apps/details?id=net.subpixel.ReadySetGoat</a></p>



<p>If you’re in a hurry, <a href="#implementation">skip to the approach I used</a>.</p>



<hr>



<p>We’re developing a game that utilizes an age old mechanic – the <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/GoombaStomp">Goomba Stomp</a>.</p>



<figure><video autoplay="" controls="" loop="" muted="" src="https://www.subpixel.net/wp-content/uploads/2020/03/79214DBD-5D6D-4FBF-8F7D-5FC56D851537.mp4" playsinline=""></video><figcaption>Ready Set Goat gameplay clips</figcaption></figure>



<p>There’s a common classical approach to this mechanic. A single, monolithic hitbox representing the physical space of the character. And that space is used for everything – stomping, getting hurt, and bumping into walls. (If you can’t tell, I’m foreshadowing here.)</p>



<p>Here’s what the Goomba Stomp looks like in Mario, with an overlay of the hitboxes next to it:</p>



<p><img src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/ezgif.com-optimize.gif?ssl=1" alt="Mario stomping" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"> <img src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Mario-Hitboxes.gif?ssl=1" alt="Mario stomping with hitboxes" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>



<p>By the way, there’s a great video on YouTube that overlays the hitboxes for an entire speedrun. This is just fun to watch; check it out:</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/eDaYK1cOCmw?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p><figcaption>Courtesy user <a href="https://www.youtube.com/channel/UCzYROBp4ypAEOEy7G89aGaQ">qvidz on Youtube</a></figcaption></figure>



<p>The first thing you’ll notice is, <strong>you suck at Mario</strong>.</p>



<p>Just kidding, this is an AI playing the game. At least I think it is…</p>



<p>The second thing you might notice is, the hitboxes are <strong>tight</strong>. They are typically smaller than the character, which gives the player some <strong>breathing room</strong>. You can overlap a few pixels with an enemy – maybe a hair on a mustache, a cheek, or a toe – and not be damaged.</p>



<p>There’s some fudge factor here, and that makes the game slightly more forgiving. This is generally considered a good approach and should help produce a good <a href="https://en.wikipedia.org/wiki/Game_feel">Game Feel</a>. Mario’s movement and feel were largely responsible for its success back in the 80s.</p>



<p>Tight hitboxes are a tried and true method for implementing this mechanic. So why devote a whole blog post to them?</p>



<p>In the course of implementing the Goomba Stomp in Ready Set Goat, I learned that just because it worked in one game, doesn’t mean it would work in mine. And after weeks of playtesting, we decided that <em>something</em> needed to be changed.</p>



<h3>1. Tight Hitboxes</h3>



<p>With tight hitboxes, Mario can stand next to a Goomba and not get punished for being a few pixels off. This is great. It’s forgiving to the player; they probably won’t even notice when it happens. They’d just notice if it <em>wasn’t </em>there.</p>



<p>But here’s the problem:</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Mario-Tight.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Mario visually stomps an enemy, but gets killed</figcaption></figure></div>



<p>See that? That extra breathing room works both ways. Now it benefits the Goomba.</p>



<p>In this scenario, Mario appears to stomp some of the enemy’s pixels, yet the player receives no reward. What’s worse is that the Goomba continues moving, eventually slamming into Mario, causing the plumber’s untimely demise.</p>



<p>In Ready Set Goat, the action is much more fast paced than Mario; there’s less time for the player to react to a misstep. So these weird situations can happen way more often. Let’s look at some other hitbox approaches and see if they’re any better.</p>



<h3>2. Loose Hitboxes</h3>



<p>Loose hitboxes work the opposite way. They give the player a huge footprint, allowing them to stomp from greater distances. In fact, the player might earn a stomp without any pixels touching. Right out of thin air.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Mario-Loose1.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Mario doesn’t quite earn a stomp yet, but is awarded one</figcaption></figure></div>



<p>There are a few downsides to this approach. The first is that it might be too easy to stomp. You might think that that makes the game less challenging. But it actually makes it less <em>predictable</em>. In some cases, the player might not want to stomp because the implications could lead them to their death. So by trying to make things easier, we’ve just made the game more challenging.</p>



<p>In Ready Set Goat, choosing when to stomp is just as important as choosing when not to stomp.</p>



<figure><video autoplay="" controls="" loop="" muted="" src="https://www.subpixel.net/wp-content/uploads/2020/03/5E6F3418-3F1D-40BF-AA8B-8F381B2CAF95.mp4" playsinline=""></video><figcaption>Stomping an enemy at the wrong time could accidentally bounce the goat off into a different enemy.</figcaption></figure>



<p>The worst problem though, is that the player might time a jump <em>really</em> close to the enemy, and clip them on the way up, resulting in the player’s death.</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Mario-Loose2-1.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Mario should safely jump over the Goomba with this trajectory. But the hitboxes are too big and he gets owned.</figcaption></figure></div>



<h3>3. Pixel Perfect</h3>



<p>Pixel Perfect hitboxes are an opinionated response to the question “How much breathing room should I give the player?” Its answer is<strong> exactly none</strong>. The player’s stomps will connect predictably, but the player gets no leeway if they make a mistake.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image-8.png?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image-8.png?resize=300%2C300&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Unforgiving pixel-perfect collisions</figcaption></figure></div>



<p>While the community over at <strong><a href="http://reddit.com/r/hitboxporn">/r/hitboxporn</a></strong> might disagree, I believe this approach leads to an unforgiving game. While testing it out, I found myself frustrated with the exactness of Pixel Perfection.</p>



<p>Of course, there are simple ways to correct this. For example, you could only count a collision if more than a certain percentage of pixel overlap. But that still suffers from the problem of being unpredictable.</p>



<h3>4. Composite Hitboxes</h3>



<p>The last common approach I can think of is Composite Hitboxes. However this approach doesn’t answer the question “How much breathing room should I give the player?” It gives you a more accurate representation of the player’s volume (just like Pixel Perfect), but the developer is still left to decide whether that space should be Tight or Loose.</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image-6.png?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image-6.png?resize=300%2C300&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Example of composite hitboxes</figcaption></figure></div>



<p>The approach by itself doesn’t solve anything for us. But what about the idea in general? Multiple hitboxes… maybe we’re on to something here.</p>



<h3>The Elephant… Er…. Goat in the Room</h3>



<p>After considering these four approaches, finally, it hit me like a ton of brick blocks. The hitboxes in Mario (and games like it) are having an identity crisis.</p>



<p>The space where Mario attacks from is the same space in which he’s vulnerable. To complicate things further, it’s also his physical space in the world; platforms and walls use this hitbox to determine if Mario bumped into them.</p>



<p>To some, this sort of ambiguity might be an obvious problem. To me, it was an epiphany.</p>



<h2>A New Player Has Entered the Game</h2>



<p>To solve the problem, I looked outside the platformer genre for inspiration. A common pattern from a different genre gave me some ideas.</p>



<p>Fighting games use a different concept; a <strong>hurtbox</strong> and a <strong>hitbox</strong>. A hurtbox is the space where the player is vulnerable; where they get hurt. A hitbox is where a player’s hits land.</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Ryu-HurtboxHitbox.png?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Ryu-HurtboxHitbox.png?resize=300%2C300&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Fighter games break out character space into two types: Hitboxes and Hurtboxes</figcaption></figure></div>



<p><strong>A quick note on terminology:</strong> I come from a First Person Shooter background. In FPS’s, we define a hitbox as <strong><a href="https://counterstrike.fandom.com/wiki/Hitbox">the area where a character can be hit</a></strong>. If you shoot a bullet at their hitbox, you hit them.</p>



<p>But fighting games would call that a hurtbox.</p>



<p>Regardless, in Mario, there is no differentiation. Your hurtbox is your hitbox, and vice versa. </p>



<p>The swapped terminology is <em>bound</em> to cause confusion, possibly anger. I’m sticking to the FPS-friendly terminology for the rest of the article, because that’s what I know best. But the point of this article is less about terminology, and more about the concept. Call these boxes whatever works best for you in your own projects. AttackBox and DefenseBox are one suggestion.</p>



<p>The different identification of these boxes led me to my final approach: multiple boxes, each defining a different spatial representation of the player.</p>



<h2 id="solution">Hitboxes and Hurtboxes and Bounding Boxes, Oh My!</h2>



<p>I categorized and defined the three different spatial representations of the characters:</p>



<ol><li><strong>Hitbox</strong><br>The area where the character can get hit (where they are vulnerable)</li><li><strong>Hurtbox</strong><br>The area where the character hurts others (where they attack)</li><li><strong>Bounding Box</strong><br>The space the character occupies according to obstacles (platforms, walls)</li></ol>



<p>Then I organized my colliders in game to represent this scheme.</p>



<div><figure><img src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Goat-HitHurtBoundingBox-1.gif?ssl=1" alt="" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Final box design of my Goat character</figcaption></figure></div>



<p>And I did the same thing with the enemies.</p>



<p>Then I set up my game engine (Unity) with the following rules:</p>



<ol><li>Player Hurtboxes should collide with Enemy Hitboxes</li><li>Enemy Hurtboxes should collide with Player Hitboxes</li><li>Players or Enemies bump into the environment</li></ol>



<p>(I explain how to do all of this in Unity <a href="#implementation">further below</a>)</p>



<h3>The Results</h3>



<p>I’m really happy with this solution, it solves a lot of the problems of the other four. </p>



<p>The player can get a stomp even when the Goat is a few pixels away. This fixes the problem with Tight Hitboxes. See how the Goat’s Hurtbox and the Enemy’s Hitbox connect even from some distance:</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Goat-ForgiveStomp.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>But they can still narrowly avoid an Enemy on the upward jump. This is an improvement over the Loose Hitboxes. Check out how the Goat’s Hitbox and Enemy’s Hurtbox near-miss eachother in this gif:</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Goat-CloseCall.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>The player gets room to breath, but can still stomp without feeling cheated.</p>



<p>I didn’t want my game to be <em>too </em>easy, but now I at least have control over how easy it is. For example, I could increase the width of the Goat’s Hurtbox and the Enemy’s Hitbox with no negative side effects. This would make it easier for the Goat to get a Stomp in, and still stay safe while jumping upward.</p>



<p>It’s pretty easy to get this all set up.</p>



<h2 id="implementation">Implementation in Unity</h2>



<h3><strong>Step 1: Setup your layers</strong></h3>



<p>For a one-size-fits-all solution to this problem in Unity, you’ll need six layers. You could probably get away with less, but this really makes it obvious what’s happening under the hood.</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Screen-Shot-2020-03-19-at-2.04.48-PM-1.png?resize=312%2C417&amp;ssl=1" alt="" width="312" height="417" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Screen-Shot-2020-03-19-at-2.04.48-PM-1.png?resize=312%2C417&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>6 Layers for Hitboxes That Feel Good™️</figcaption></figure></div>



<h3><strong>Step 2: Setup the collision matrix</strong></h3>



<p>You’ll need to tweak the collision matrix to support this scheme, as follows:</p>



<figure><img src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Notice how few checkmarks there are. There’s really only 3 collisions we need to worry about</p>



<ol><li>Player hurts an Enemy</li><li>Player gets hurt by an Enemy</li><li>Player or Enemy bump into the environment</li></ol>



<h3><strong>Step 3: Setup your characters’ boxes</strong></h3>



<p>Now for the actual characters. Each box will be represented as a Collider2d (this concept works in 3d too however). Since Unity only allows one  Collider per GameObject, we need to store 2 of the Colliders on child GameObjects. This makes the solution a bit more complex, but it’s manageable.</p>



<p>So that’s one parent GameObject representing the character’s Bounding Box. One child GameObject for the …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/">https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/</a></em></p>]]>
            </description>
            <link>https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634144</guid>
            <pubDate>Tue, 29 Sep 2020 23:12:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking vol. 2: Pitting Actix against Rocket v0.4 and v0.5-dev (Rust)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634107">thread link</a>) | @strohel
<br/>
September 29, 2020 | https://matej.laitl.cz/bench-actix-rocket/ | <a href="https://web.archive.org/web/*/https://matej.laitl.cz/bench-actix-rocket/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://matej.laitl.cz/images/2020-09-29-bench-actix-rocket/cover.png" alt="illustration">
I present a Rust-specific sequel to my <a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/">previous benchmark of 2 Kotlin and a Rust microservice</a>
â€” itâ€™s hard to resist oneâ€™s own curiosity and popular demand, especially when youâ€™ve been
<a href="https://www.reddit.com/r/rust/comments/is9onc/what_i_learnt_from_benchmarking_http4k_ktor/g57n93y/?utm_source=share&amp;utm_medium=web2x&amp;context=3">nerd</a>-<a href="https://xkcd.com/356/">sniped</a>.
Letâ€™s stress-test the two prominent web frameworks: Actix Web and Rocket.
In addition to stable â€œthreads &amp; blocking callsâ€� Rocket v0.4,
I have included a development snapshot of in-the-works Rocket v0.5,
which is async and <a href="https://github.com/SergioBenitez/Rocket/commit/56a61726">no longer requires nightly Rust</a>.</p>

<p><em>Impatient? <a href="#results">Jump to the results</a>.</em></p>

<h2 id="preamble">Preamble</h2>

<p>Iâ€™ll take advantage of the previous article to fully describe
aspects that apply equally well to this round:</p>
<ul>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#on-techempower-framework-benchmarks">How this is different than TechEmpower benchmarks</a>.
<em>TL;DR: we want to capture finer nuances and test idiomatic implementations with error reporting,
logging, etc. â€” rather than highly optimised ones.</em></li>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#the-service">The microservice weâ€™ve benchmarking</a>.
<em>TL;DR: a simple endpoint that does one call to Elasticsearch server.</em></li>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#recipe">The testing methodology</a>.
<em>TL;DR: repeated runs of a Python script that spins microservice Docker container
and exposes it to an increasing number of concurrent connections using <a href="https://github.com/wg/wrk">wrk</a>.</em></li>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#runtime-environment">Runtime Environment</a>.
<em>TL;DR: we limit the microservice to 1.5 CPU cores and 512 MiB memory using Docker.</em></li>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#hardware">Hardware</a>.
<em>TL;DR: Google Cloud Platform VM with 4-core AMD Epyc Rome CPU for the microservice + 12-core machine for the Elasticsearch server.</em></li>
</ul>

<p>We still compile in release mode, target <code>skylake</code>, and utilize <a href="https://deterministic.space/high-performance-rust.html">cheap performance tricks</a>.
What changed is Rust version, we have to use <strong>nightly</strong> because of Rocket v0.4.
More specifically, all implementations are compiled using
<code>rustc 1.47.0-nightly (2d8a3b918 2020-08-26)</code>.<sup id="fnref:nightly" role="doc-noteref"><a href="#fn:nightly">1</a></sup></p>

<h2 id="actix-v30">Actix v3.0</h2>

<p>Code as benchmarked: <a href="https://github.com/strohel/locations-rs/tree/actix-v30">locations-rs tag <code>actix-v30</code></a>.
Uses <strong>Actix Web 3.0.2</strong>.</p>

<p>Just some small things have changed
since the <a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#the-story-of-locations-rs">version described in the last post</a>:</p>
<ul>
  <li>We now use version 3.0, but note that <a href="https://storage.googleapis.com/strohel-pub/bench-actix-versions/bench-results.html">its performance matches v2.0 in our case</a>.</li>
  <li>OpenAPI (Swagger) support is reintroduced as I was able to <a href="https://github.com/wafflespeanut/paperclip/pull/218">make Paperclip support v3.0, too</a>.</li>
</ul>

<h2 id="rocket-v04">Rocket v0.4</h2>

<p>Code as benchmarked: <a href="https://github.com/strohel/locations-rs-rocket/tree/rocket-v04">locations-rs-rocket tag <code>rocket-v04</code></a>.
Uses stable <strong>Rocket 0.4.5</strong>.</p>

<p>Porting from Actix to Rocket v0.4 was a matter of
<a href="https://github.com/strohel/locations-rs-rocket/commit/f37de2fe">one +175 -150 lines commit</a>.<sup id="fnref:lines" role="doc-noteref"><a href="#fn:lines">2</a></sup>
It looks a bit scary but was mostly mechanical:
converting Actix type to Rocketry ones, and then fixing all compiler errors â€”
I love how <code>rustc</code> essentially works as your to-do list.
There was only one major hurdle:</p>

<h3 id="calling-async-functions-from-blocking-handlers">Calling Async Functions from Blocking Handlers</h3>

<p>Rocket v0.4 handlers are classic blocking (sync) functions, but Reqwest-based
<a href="https://github.com/elastic/elasticsearch-rs">elasticsearch-rs</a> only provides an async API.
Whoops.</p>

<p>The general advice is to propagate the asynchronicity up in caller stack
instead of trying to call async functions from sync code.
But what if we really want to? These are our options:</p>

<ol>
  <li><code>global-rt</code>: launch a global <a href="https://docs.rs/tokio/0.2/tokio/runtime/index.html#threaded-scheduler">threaded Tokio runtime</a>
alongside Rocket workers.
Then call runtimeâ€™s <a href="https://docs.rs/tokio/0.2/tokio/runtime/struct.Handle.html#method.block_on">Handle::block_on()</a>
in endpoint handlers to delegate the work to the global async runtime,
pausing the Rocket worker until the future resolves.</li>
  <li><code>per-worker-rt</code>: create a <a href="https://docs.rs/tokio/0.2/tokio/runtime/index.html#basic-scheduler">basic single-threaded Tokio runtime</a>
<em>per each Rocket worker</em>.<sup id="fnref:per-worker" role="doc-noteref"><a href="#fn:per-worker">3</a></sup>
In endpoint handlers then call <a href="https://docs.rs/tokio/0.2/tokio/runtime/struct.Runtime.html#method.block_on">Runtime::block_on()</a>,
which here has different semantics (!) than the <code>Handle::block_on()</code> above:
the future, and any other spawned async tasks, actually run within this Rocket worker thread.<sup id="fnref:worker-run" role="doc-noteref"><a href="#fn:worker-run">4</a></sup>
This comes with a caveat.
Reqwest::client() seems to <em>attach</em> itself to the async runtime it is first used in.
I had to make Elasticsearch client also local to each Rocket worker.
Otherwise, I got deadlocks or <a href="https://github.com/hyperium/hyper/issues/2112">problems described in hyper issue #2112</a>.</li>
  <li><code>per-req-rt</code>: launch a fresh basic Tokio runtime per each request.
It feels wrong, and it is wrong. Iâ€™ve tried and benchmarked this so that we know <em>how much</em> wrong.</li>
  <li>Patch elasticsearch-rs to provide a blocking API â€” by employing Requestâ€™s
<a href="https://docs.rs/reqwest/0.10/reqwest/blocking/index.html">optional blocking API</a>.
That would be futile, and essentially a sophisticated variant of 2.,
given <a href="https://github.com/seanmonstar/reqwest/blob/v0.10.8/src/blocking/client.rs#L715-L783">the implementation details of the blocking client</a>.</li>
</ol>

<p><a href="https://storage.googleapis.com/strohel-pub/rocket-async-approach/bench-results.html"><strong>Here are the results of benchmarking the first three approaches.</strong></a>
Source code of each variant is available under the respective <a href="https://github.com/strohel/locations-rs-rocket/tags">tag in the locations-rs-rocket repository</a>.</p>

<p>You can almost hear the server crying as it tries to cope with the inefficiency of <code>per-req-rt</code>:
it is more than 7âœ• less efficient than the best performing variant.</p>

<p>The other two more realistic variants are close to each other.
<code>per-worker-rt</code> has a slight edge in peak performance and a clear edge in efficiency,
especially for low connection counts.
It is therefore proclaimed a winner of this qualification round
and represents Rocket v0.4 in later benchmarks.</p>

<p>It is not a surprise that highly-optimised Actix uses a similar approach:
independent single-threaded Tokio runtimes per each worker
instead of a global work-stealing threaded one.</p>

<h3 id="keep-alive-connections">Keep-Alive Connections</h3>

<p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Connection_management_in_HTTP_1.x#Persistent_connections">Keep-Alive (persistent) connections</a>
save latency and resources when a client makes more than one request to a given server,
especially when the connection is secured by TLS.
Unfortunately, Rocket v0.4 is not their friend.</p>

<p><strong>First</strong>, to the best of my knowledge,
<a href="https://github.com/SergioBenitez/Rocket/issues/580#issuecomment-698286249">persistent connections donâ€™t work at all in Rocket v0.4</a>
â€” the server closes the connection before reading a second request.
Iâ€™ve <a href="https://github.com/hyperium/hyper/pull/2288/commits/3109103">traced the problem down to a bug in BufReader in old hyper 0.10.x and submitted a fix</a>.
In the 0.11.x branch, the same bug was <a href="https://github.com/hyperium/hyper/commit/d35992d0198d733c251e133ecc35f2bca8540d96#diff-078f367374debbc894f7cc1c4084e467R64-R66">fixed a long ago</a> and released with 0.11.0 in June 2017.
My pull request was <a href="https://github.com/hyperium/hyper/pull/2288#issuecomment-698492487">closed without merging</a>,
as the maintainers were (understandably) not keen on releasing a new version of a legacy branch that was superseded 3 years ago.
In other words, <em>Rocket v0.4 depends on unmaintained hyper</em> for its HTTP handling.</p>

<p><strong>Second,</strong> even if the bug in hyper is patched,
keep-alive connections in hyper 0.10.x are <a href="https://github.com/hyperium/hyper/blob/0.10.x/src/server/mod.rs#L282-L351">implemented naÃ¯vely</a>:
the worker thread is kept busy waiting for the client on the persistent connection,
unable to process other requests.
It is therefore easy to (accidentally) trigger denial-of-service
by opening more persistent connections than available workers,
even with the default keep-alive timeout of 5 s.<sup id="fnref:browsers" role="doc-noteref"><a href="#fn:browsers">5</a></sup>
Note that the first problem prevents this second problem from happening. ;-)</p>

<p>Both issues were long resolved in more modern hyper 0.11+,
and therefore in Rocket v0.5-dev which I happen to benchmark too.</p>

<p>If you run Rocket v0.4 in production,
I recommend you to turn off persistent connections in Rocket config (set <code>keep-alive</code> to <code>0</code>)
â€” while most clients retry the failed second request on a persistent connection gracefully,
at least some versions of Python <code>requests</code> and <code>urllib3</code> were raising exceptions instead.
If you care about latency, I suggest you put an HTTP load-balancer in front of Rocket v0.4 server
to reintroduce persistent connections at least to the client &lt;-&gt; load-balancer hop.</p>

<p><a href="https://storage.googleapis.com/strohel-pub/rocket-keep-alive/bench-results.html"><strong>The benchmarks show that disabling keep-alive causes only a mild performance hit in our case.</strong></a></p>

<p>The red <code>oneshot-*</code> line is Rocket with keep-alive disabled and 16 workers,
while other <code>persistent-*</code> lines represent Rocket with patched hyper, enabled keep-alive, and 16, 32 and 64 workers.
It can be seen that disabling keep-alive hurts latency, but not necessarily throughput
â€” if the number of connections can be increased.
Note that the effect will be more pronounced in reality,
real network latencies are much more significant than that of our loopback interface.</p>

<p>Unfortunately, <code>wrk</code> does not indicate that some of its concurrent connections have failed to connect to the server at all.
But another demonstration of the denial-of-service behaviour is present when keep-alive is enabled:
Notice how the latencies of the 16-, 32-, and 64-worker instances of Rocket <em>cut-off</em> at
16, 32, respectively 64 concurrent connections.
When such saturation happens,
it is indeed impossible to make a new connection using e.g. <code>curl</code> to the Rocket instance.</p>

<p>Because of these 2 problems, Rocket v0.4 has keep-alive disabled in all other benchmarks.</p>

<h3 id="tuning-the-number-of-workers">Tuning The Number of Workers</h3>

<p>If you want to squeeze the highest possible efficiency from a Rocket v0.4 instance,
you should tweak the number of its worker threads.
The optimal count will depend mainly on the number of available CPU cores,
and the ratio of time your endpoints spend CPU-crunching and waiting for I/O.</p>

<p><a href="https://storage.googleapis.com/strohel-pub/rocket-worker-count/bench-results.html"><strong>Here I have benchmarked worker counts from 8 to 256.</strong></a></p>

<p>Instance with 16 workers is the most efficient, although the differences are small.
Most notable variance is, as expected, in memory consumption.
Having in mind that 1.5 CPUs is available the microservice, we arrive at around 10 workers per core.
Rocketâ€™s default is more conservative 2 workers per core.</p>

<h2 id="rocket-v05-dev">Rocket v0.5-dev</h2>

<p><em><strong>Big fat warning</strong>: Rocket v0.5 is still under development.
Version tested in this post is its <a href="https://github.com/SergioBenitez/Rocket/commit/1369dc4">1369dc4 commit</a>.
A lot of things may change in the final release, including all observations here.
You can track Rocket v0.5 progress in its <a href="https://github.com/SergioBenitez/Rocket/issues/1065">async migration tracking issue</a>
and related GitHub milestone.</em></p>

<p>Code as benchmarked: <a href="https://github.com/strohel/locations-rs-rocket/tree/rocket-v05-dev">locations-rs-rocket tag <code>rocket-v05-dev</code></a>.</p>

<p>Porting from async Actix to async Rocket v0.5-dev was even easier than to Rocket v0.4.
<a href="https://github.com/strohel/locations-rs-rocket/commit/879cd88">Here is the 147 insertions, 140 deletions commit that did the job</a>.<sup id="fnref:lines:1" role="doc-noteref"><a href="#fn:lines">2</a></sup></p>

<p>Compared to v0.4, Rocket v0.5-dev is <em>boring</em>, in the best possible sense of the word.
Persistent connections are without problems.
There is no need to fiddle with the number of workers.
I attribute this to porting to up-to-date hyper 0.13.x and async Rust ecosystem.</p>

<h2 id="results">Results</h2>

<p>All graphs below are interactive and infinitely scalable SVGs â€” zoom in if necessary.</p>

<p>The startup time is measured from the moment Docker finishes setting up the container
to the moment when we receive a valid HTTP response to <code>GET /</code>.</p>

<p>No real difference, single-digit milliseconds correspond to the required round-trip to Elasticsearch server.</p>

<p>Error response ratio in percents.</p>

<p>Nicely flat for all frameworks up to extreme 1024 and 2048 connections.
Actix manages to be slightly better there with ~1% of errors, compared to ~1.5% of both Rocket versions.</p>

<p>High-water mark <em>successful</em> requests per second as the number of concurrent connections grows, one of our main metrics.</p>

<p>Recurrin…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matej.laitl.cz/bench-actix-rocket/">https://matej.laitl.cz/bench-actix-rocket/</a></em></p>]]>
            </description>
            <link>https://matej.laitl.cz/bench-actix-rocket/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634107</guid>
            <pubDate>Tue, 29 Sep 2020 23:05:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SkyGrid launches drone app that automates every phase of flight]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634034">thread link</a>) | @finphil
<br/>
September 29, 2020 | https://nuadox.com/post/630634164690075648/skygrid-drone-automation-app | <a href="https://web.archive.org/web/*/https://nuadox.com/post/630634164690075648/skygrid-drone-automation-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="630634164690075648">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/630634164690075648/skygrid-drone-automation-app"><h2>SkyGrid launches drone app that automates every phase of flight</h2></a>
                                <figure data-orig-width="1199" data-orig-height="616"><img src="https://64.media.tumblr.com/c5261fbf1a95dac4c9a0a495b62d10c7/e15e14b7497ce16a-8c/s1280x1920/1120360c201c3fc5d18bb73afaa37ec56c13f996.jpg" alt="image" data-orig-width="1199" data-orig-height="616" width="1199" height="616"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.skygrid.com%2F&amp;t=ODZmOGU1OTA1OWY0MzJhNzFlYmZiMjMyNjVhMmYzYmMzZjdlMmZkMSxWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601687116">SkyGrid</a> -</b></p><p>

SkyGrid, a Boeing, SparkCognition company, today launched a new application for drone operators and enterprises to automate every phase of flight in one unified solution.&nbsp;</p><p>Now available for free in the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fc212.net%2Fc%2Flink%2F%3Ft%3D0%26l%3Den%26o%3D2931428-1%26h%3D455054367%26u%3Dhttps%253A%252F%252Fapps.apple.com%252Fus%252Fapp%252Fskygrid-flight-control%252Fid1500582074%26a%3DiPad%2BApp%2BStore&amp;t=NmY4MjNiNzFlYzBkMzg2ZDI5ZGJkMGVlNTM3NGZmNGQxYjVhNDY1MixWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601687116">iPad App Store</a>, <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.skygrid.com%2Fflight-control%2F%3Futm_source%3Dskygrid%26utm_medium%3Dpressrelease%26utm_campaign%3Dflightcontrol&amp;t=ODY1OTYwNTRkZmQ5OWJlMmZhN2FiMjI3MWY0ZmQzOTRlOTU1NjNlNSxWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601687116">SkyGrid Flight Control</a>&nbsp;simplifies mission planning and execution, allowing drone operators to autonomously surveil a defined area and detect objects in real-time. Powered by artificial intelligence (AI) computer vision, the solution enables more efficient search and rescue missions, disaster response, perimeter surveillance, site inspections, and more.

<br></p><p>“Traditionally, drone operators have used several different tools to check airspace, get LAANC, plan and execute flights, and gather insights, but it’s a manual, cumbersome process,” said Amir Husain, CEO and founder of SkyGrid. “Recognizing this challenge, SkyGrid has minimized the burden on drone operators by creating one solution that automates airspace, flights, and insights. As the only drone solution built on AI and blockchain technologies, we give operators and enterprises the assurances they need to execute safe, compliant missions.”</p><p>Powered by SkyGrid’s AerialOS, SkyGrid Flight Control enables drone operators to automate airspace authorization, mission planning, flight execution, and object detection in one end-to-end solution. The following features and functionality are available for free within the iPad application:</p><ul><li><b>Airspace intelligence:</b> Provides a map of airspace classes, boundaries, temporary flight restrictions, notices to airmen, and other advisories.</li><li><b>Ground intelligence: </b>Displays population density, obstacles, elevation, and more.</li><li><b>Advanced weather data:</b> Details hyper-local precipitation, wind speed and direction, temperature, cloud cover, and more.</li><li><b>Real-time airspace authorization:</b> Automates authorization to fly in U.S. controlled airspace under 400 feet through integration with the Federal Aviation Administration’s Low Altitude Authorization and Notification Capability (LAANC) 4.0.</li><li><b>Automated mission planning:</b> Automatically generates area exploration, waypoint, and multi-objective missions based on custom flight parameters, such as desired speed, altitude, and location.</li><li><b>Autonomous flight execution:</b> Autonomously launches the drone and performs the pre-defined flight plan.</li><li><b>AI object recognition:</b> Detects objects in real-time as a drone surveils the defined area with AI computer vision.</li></ul><p>More advanced enterprise features are also available for organizations to better manage all drones, pilots, and airspace operations. These features include AI-based mission planning and rerouting, multi-drone missions, custom object detection and counting, geofencing and alerts, and more.</p><p>“SkyGrid Flight Control is an important stepping-stone to enable more complex commercial drone operations and advanced air mobility in urban, regional, and global markets,” said Steve Nordlund, vice president and general manager of Being NeXt and executive board advisor of SkyGrid. “SkyGrid is solving complex problems in unmanned aviation with a system that will safely integrate the future volume of drones, passenger air vehicles, and other autonomous aircraft in the global airspace.”</p><p>–</p><p><i>Header image:&nbsp;SkyGrid Flight Control. Credit <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fskygrid-launches-all-in-one-drone-app-to-automate-every-phase-of-flight-301139488.html&amp;t=ODYzZTlkYzdlNmEwNjc0ZWNjNDgwM2M4NzliMjQ2MmM5OWIwMDJjOCxWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601687116">SkyGrid</a>.</i></p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fskygrid-launches-all-in-one-drone-app-to-automate-every-phase-of-flight-301139488.html&amp;t=ODYzZTlkYzdlNmEwNjc0ZWNjNDgwM2M4NzliMjQ2MmM5OWIwMDJjOCxWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601687116">SkyGrid</a></b></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/183243493212/drones-search-and-rescue">Autonomous drones can help search and rescue after disasters</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/drone">drone</a>
                                    
                                        <a href="https://nuadox.com/tagged/drones">drones</a>
                                    
                                        <a href="https://nuadox.com/tagged/ai">ai</a>
                                    
                                        <a href="https://nuadox.com/tagged/artificial-intelligence">artificial intelligence</a>
                                    
                                        <a href="https://nuadox.com/tagged/computer-vision">computer vision</a>
                                    
                                        <a href="https://nuadox.com/tagged/aviation">aviation</a>
                                    
                                        <a href="https://nuadox.com/tagged/search-and-rescue">search and rescue</a>
                                    
                                        <a href="https://nuadox.com/tagged/disaster">disaster</a>
                                    
                                        <a href="https://nuadox.com/tagged/inspection">inspection</a>
                                    
                                        <a href="https://nuadox.com/tagged/featured">featured</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/630634164690075648/skygrid-drone-automation-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634034</guid>
            <pubDate>Tue, 29 Sep 2020 22:55:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microservices: Architecture Nihilism in Minimalism's Clothes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633840">thread link</a>) | @aratno
<br/>
September 29, 2020 | https://vlfig.me/posts/microservices | <a href="https://web.archive.org/web/*/https://vlfig.me/posts/microservices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some recent <a href="https://twitter.com/gergelyorosz/status/1247132806041546754" target="_blank" rel="nofollow noopener noreferrer">backtracking</a> <a href="https://twitter.com/copyconstruct/status/1247130488667394049" target="_blank" rel="nofollow noopener noreferrer">from</a> what we have been calling “Microservices” has sparked anew the debate around that software architecture pattern. It turns out that for increasingly more software people, having a backend with (<a href="https://www.infoq.com/presentations/monzo-microservices/" target="_blank" rel="nofollow noopener noreferrer">sometimes several</a>) hundreds of services wasn’t that great an idea after all. The debate has <a href="https://riak.com/posts/technical/microservices-please-dont/" target="_blank" rel="nofollow noopener noreferrer">been going on for a while</a> and much has already been said, but there are still a couple of things I’d like to say.</p>
<p><strong>TL;DR</strong> “Microservices” was a good idea taken too far and applied too bluntly. The fix isn’t just to dial back the granularity knob but instead to 1) focus on the split-join criteria as opposed to size; and 2) differentiate between the project model and the deployment model when applying them.</p>
<p>I explain. Allow me to rant a bit first.</p>


<p>There were three main reasons for the initial success of <em>microservices</em> as an architectural pattern for software: 1) forced modularisation, 2) weakened dependencies, and 3) an excuse for having no architecture. In order:</p>
<ol>
<li>In the monoliths of old, you could in theory enforce module boundaries. You could say that your <code>acme-helpers</code> or <code>acme-data-tools</code> could not depend on <code>acme-domain</code>, say, and you even had some tooling to enforce that, but it was fallible. Especially in big companies where these monoliths spanned more than a team’s cognitive horizon, violations of those boundaries were often a simple <code>import</code> away, and of course rife. Angry architects saw in microservices the promise of making those a thing of the past: now the developer is forced to only deal with the API. Codebases parted ways and calls were made to go down the network stack and back.</li>
<li>
<p>So then, one wouldn’t depend on a fellow service at build time, only at runtime. Great. Method calls became http calls. “Now we don’t need to care about dependencies” — actual people said this, as if the dependency wasn’t fundamental and instead just an accidental artifact of the build setup. Everybody brushed up on their HTTP and different server and client implementations, read all about REST and Soap (and RPC, RMI and CORBA while at it) and merrily created a layer of indirection between modules — now <em>services</em> — that was <em>very</em> loose. Typed APIs, granular network policies and contract testing came much later.</p>
<p>It felt liberating until the complexities of API versioning, delivery semantics, error propagation, distributed transaction management and the sprawl of client code in all callers of a service began to show up. This was a gigantic <strong>shift right</strong>, but hey, the build process was simpler.</p>
</li>
<li>
<p>More insidious perhaps was the validation that “doing microservices” brought to organisations that lacked a thesis about how their architecture should be. There was now a sanctioned answer to most architectural dilemmas: another microservice. Another entry in the service catalog for any and all interested parties to call. This ecology of interacting parties, each acting in their own interest for the common good spoke to an underlying, tacit belief that the emergent mesh of services would approximate the latent natural architecture of the domain.</p>
<p>So soft and convenient was the lure of not having to draw hard architectural lines that we got lazy where we weren’t and accepted our lazyness where we already were. If you didn’t subscribe to that belief, the problem was you and your lack of understanding of complex systems, you objectivist cretin.</p>
</li>
</ol>
<p>Yes, there was real pain in managing monoliths and sure, many systems were too monolithic (i.e. had deployables too large) but the zealotry of a newfound purity swung the pendulum too far, as they always do. Not only do we not need to run so many services so small, we also don’t benefit from isolating their codebases so much. To summarise:</p>
<ol>
<li>having a big flat permissive build is no good reason to split deployables;</li>
<li>weakening dependencies between different parts of our systems is a “shift-right” loan with high interest; and</li>
<li>having a ready answer when the thinking gets tough is a soothing lie that just moves complexity about. There is no substitute to the effortful application of cognitive power to a problem.</li>
</ol>

<p>Two things: focus on the right criteria for splitting a service instead of on its size, and apply those criteria more thoughtfully.</p>
<h2 id="size-is-not-the-answer"><a href="#size-is-not-the-answer" aria-label="size is not the answer permalink"></a>Size is not the answer</h2>
<p>The <em>micro</em> in microservices ought to be at best a prediction, never a goal. We may predict services <em>will be</em> micro but they don’t <em>have to be</em>. <a href="https://kalele.io/microservices-and-microservices/" target="_blank" rel="nofollow noopener noreferrer">Vaugh Vernon is right</a> when he speaks about “cohesion for a reason”.</p>
<p>There should be no prescribed <em>a priori</em> granularity of services. There <em>is</em> no prescribed size of a service. There are instead <strong>good and bad reasons to split</strong> parts of a software system.</p>
<p>So the heuristic is:</p>
<div data-language="text"><pre><code>                      Start one, split with a reason.</code></pre></div>
<p>Conversely, if a reason ceases to exist, consider joining them.</p>
<h2 id="the-missing-hinge"><a href="#the-missing-hinge" aria-label="the missing hinge permalink"></a>The missing hinge</h2>
<p>There are however different realms in which “software systems” exist: they exist both as artifacts we interact with and as artifacts computers interact with. Code and binary. We organise them in different ways: the <strong>project model</strong> (repositories, projects, modules and their dependencies) and the <strong>deployment model</strong> (what production environments look like and how deployables run in them).</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A monolithic setup where one big repo builds one single big deployable." title="A monolithic setup where one big repo builds one single big deployable." src="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg" srcset="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/09b79/monolith.jpg 240w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/7cc5e/monolith.jpg 480w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg 960w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/644c5/monolith.jpg 1440w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg 1463w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A monolithic setup where one big repo builds one single big deployable.</p></figcaption>
  </figure>
<p>In the process of going from coarse to granular (i.e. from monolith to microservices) however, little attention was paid to the difference — and possible indirection — between those two models. The hammer hit both fairly indiscriminately and made us split codebases because of runtime concerns and split deployables due to project concerns.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A set of repositories each building their own self-contained independent service." title="Excessive mirroring between the project and deployment models." src="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg" srcset="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/09b79/stiff-1-1.jpg 240w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/7cc5e/stiff-1-1.jpg 480w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg 960w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg 1062w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Excessive mirroring between the project and deployment models.</p></figcaption>
  </figure>
<p>Much like stiffness in a part of the human spine can result in pain in another, <strong>stiffness in our build DAGs is causing excessive mirroring between our project and deployment models</strong>; between our repositories and our services; between the way we organise our code and the way our services run. That mirroring is on the one hand preventing us from shifting left concerns about the relationships between modules that have often been made weak and fragile runtime dependencies, while on the other hand encouraging us to have more services than what the runtime reality would call for. That brings pain.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The build DAG as a hinge between the project model and the deployment model." title="A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly." src="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg" srcset="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/09b79/hinge.jpg 240w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/7cc5e/hinge.jpg 480w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg 960w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg 1335w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly.</p></figcaption>
  </figure>
<p>Central to resolving this stiffness is the realisation that the build flow, at least conceptually, is a DAG – Directed Acyclic Graph – where the nodes are <em>jobs</em> and <em>versioned artifacts</em> and the edges connect either a job to a versioned artifact (“produces”) or a versioned artifact to a jobs (“dependency_of”). Deployables are by definition the versioned artifacts that are consumed by the deployment jobs.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." title="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." src="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg" srcset="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/09b79/dag.jpg 240w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/7cc5e/dag.jpg 480w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg 960w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg 1384w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A graph of two types of nodes, jobs and versioned artifacts, connected by edges ‘dependency_of’ and ‘produces’. Versioned artifacts can be further specialised.</p></figcaption>
  </figure>
<p>For too long we overlooked how much a flexible and frictionless build DAG allows us to improve our architecture on both sides. With moderately rich build patterns we can have our code where its intent is clearer and more constraints can be validated at build time and still have it deployed into its simplest viable form, running where its execution is cheaper, faster and safer.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Cheesy cisgender, neurotypical westernised image of a wedding altar with the build dag marrying developer effectiveness with mechanical sympathy." title="Sorry. I had to." src="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" srcset="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/09b79/wedding-altar.jpg 240w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/7cc5e/wedding-altar.jpg 480w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg 612w" sizes="(max-width: 612px) 100vw, 612px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Sorry. I had to.</p></figcaption>
  </figure><p>.</p>
<h3 id="why-so-stiff-bro"><a href="#why-so-stiff-bro" aria-label="why so stiff bro permalink"></a>Why so stiff, bro?</h3>
<p>I’m not sure what the historically accurate account is that would explain the excessive simplicity of build patterns across the industry. I do know from experience that too many practices make do with very simple and linear flows where one repository builds independently one and only one service. Regardless of the legitimate argument about code duplication and its tradeoffs, there seems to be an aversion to build-time internal dependencies, even when these bring in clearly desirable data or logic such as message format definitions.</p>
<p>I suspect it might have something to do with how very few CI tools support composition natively (i.e. the outputs of jobs being able to be the inputs of others), how fallible semantic versioning in practice is and the difficulty of automating deterministic version propagation.</p>
<p>By that I mean keeping local copies in sync with CI, builds repeatable, and new upstream versions automatically used by their downstream dependents. It isn’t trivial and requires some versioning and build-fu that, to my knowledge, most practices end up shortcutting to either sacrifice repeatability by using <code>latest</code> or stifling the flow by requiring repeated manual work. Hence the pressure to have a simple build setup.</p>
<p>The exact cause is unimportant though. What is important is that overcoming this is crucial.</p>

<p>Many criteria for splitting or joining software systems, ranging from the social (teams, bounded contexts) to the mechanical (cpu or io boundedness) have been put forth, and they all make some form of sense. However, most of them are either a good reason to split projects or modules, or a good reason to split deployables, rarely both. Keeping that in mind will help us apply them more effectively.</p>
<p>Below are a few possible criteria and some comments about their application. I’m not trying to be exhaustive, just illustrating the kind of reasoning makes sense to me.</p>
<h2 id="runtime-deployment-side-criteria"><a href="#runtime-deployment-side-criteria" aria-label="runtime deployment side criteria permalink"></a>Runtime, deployment side criteria</h2>
<ul>
<li><strong>Different Runtime</strong> – If a part of the codebase compiles to a different runtime it becomes a different deployable and we call it a different service.</li>
<li><strong>Elasticity Profile</strong> – Some parts of the system may have a spikier load profile. It might pay off to have them scale in and out separately from the rest.</li>
<li><strong>Load Type</strong> – Some parts of a generally latency-oriented io-bound system may generate occasional peaks of cpu-bound load which can hurt response times. It might be better to put them in a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vlfig.me/posts/microservices">https://vlfig.me/posts/microservices</a></em></p>]]>
            </description>
            <link>https://vlfig.me/posts/microservices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633840</guid>
            <pubDate>Tue, 29 Sep 2020 22:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Engineer Interview Study Guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633780">thread link</a>) | @dataguy12
<br/>
September 29, 2020 | https://www.coriers.com/the-interview-study-guide-for-data-engineers/ | <a href="https://web.archive.org/web/*/https://www.coriers.com/the-interview-study-guide-for-data-engineers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
					<p>Interviewing for any technical position generally requires preparing, studying and long-all day interviews. As a data engineer, what we need to study is not always clear. Some positions require Hadoop, others SQL, some roles require understanding statistics while still others require heavy amounts of system design.</p>
<p>We have gathered many of the resources that we have used to study and get jobs at companies int the FAANG family as well as other major tech companies. We have yet to find one that requires you to know anything about Hadoop during the interview so that has not bee included in this study guide.</p>
<p>However, as part of this study guide we have created the checklist. Sometimes, studying for interviews can feel like you are getting nothing done. Thus, this checklist will help you keep track so you know where to improve and what you have done.<a href="https://docs.google.com/spreadsheets/d/1GOO4s1NcxCR8a44F0XnsErz5rYDxNbHAHznu4pJMRkw/edit?usp=sharing"> You can find the checklist here.</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.google.com/spreadsheets/d/1GOO4s1NcxCR8a44F0XnsErz5rYDxNbHAHznu4pJMRkw/edit#gid=0"><span>Download The Data Engineering Interview Checklist</span></a></p><p><strong>Outline</strong></p>
<ol>
<li>SQL Pre-Video Problems</li>
<li>SQL Videos</li>
<li>SQL Post Video Problems</li>
<li>Database, Data Warehouse And ETL Design</li>
<li>Algorithm And Data Structures Programming Problems</li>
<li>Operational Programming Problems</li>
<li>System Design Videos</li>
<li>Udemy Courses</li>
<li>Books</li>
</ol>
<h3><strong>SQL&nbsp;</strong></h3>
<p><span>As a data engineer it is almost inevitable that you will get some SQL questions. As someone who has participated in many interviews for a lot of top tech companies like Amazon and Capital One. They usually follow some similar patterns. </span></p>
<p><span>Typically there will be at least one question that requires an aggregation with a filter, another that requires a few joins and then one that requires a subquery. Along with that, there might be a few curve ball questions that require self-joins, recursions and analytic functions. So let’s look at a couple concepts that are good to cover</span></p>
<p><img src="https://i0.wp.com/www.coriers.com/wp-content/uploads/2019/05/d1e66b8f46fed3b4fb839e9b41025f82.gif?resize=450%2C164&amp;ssl=1" alt="" width="450" height="164" data-recalc-dims="1"></p>
<h4>SQL Pre-Video Problems</h4>
<p>These first few problems will help you gauge where you are on different concepts. That way you can take notes on the <a href="https://docs.google.com/spreadsheets/d/1GOO4s1NcxCR8a44F0XnsErz5rYDxNbHAHznu4pJMRkw/edit?usp=sharing">study guide</a> and go back and review what you feel you were not comfortable with.</p>
<h4><strong>Join with Aggregation</strong></h4>
<p><strong><a href="https://leetcode.com/problems/trips-and-users/">262.&nbsp;Trips and Users</a></strong></p>
<p><strong>Problem:</strong> The <code>Trips</code>&nbsp;table holds all taxi trips. Each trip has a unique Id, while Client_Id and Driver_Id are both foreign keys to the Users_Id at the&nbsp;<code>Users</code>&nbsp;table. Status is an ENUM type of (‘completed’, ‘cancelled_by_driver’, ‘cancelled_by_client’).</p>
<p><span>This is usually the 3rd or 4th style of question.</span></p>
<h4><strong>Sql Questions With Complex Logic</strong></h4>
<p><span>Sometimes, you get lucky and only have to deal with SQL questions that involve one point o logic. Sometimes it gets a little trickier. For instance this question asks you to both find cities with 3 consecutive rows and has populations over 100. </span></p>
<p><span>This is usually pretty easy to do when you are working, but can sometimes be a little difficult when you are in the middle of an interview.</span></p>

<p><strong><a href="https://leetcode.com/problems/human-traffic-of-stadium/">601. Human Traffic of Stadium</a></strong></p>
<p><strong>Problem:</strong> X city built a new stadium, each day many people visit it and the stats are saved as these columns:&nbsp;<b>id</b>,&nbsp;<strong>visit_</strong><b>date</b>,&nbsp;<b>people</b></p>
<p>Please write a query to display the records which have 3 or more consecutive rows and the amount of people more than 100(inclusive).</p>

<p><strong><a href="https://leetcode.com/problems/department-top-three-salaries/">185.&nbsp;Department Top Three Salaries</a></strong></p>
<p><strong>Problem: </strong>Write a SQL query to find employees who earn the top three salaries in each of the department. For the above tables, your SQL query should return the following rows (order of rows does not matter).</p>

<p><strong><a href="https://leetcode.com/problems/rising-temperature/">197.&nbsp;Rising Temperature</a></strong></p>
<p><strong>Problem: </strong>Given a&nbsp;<code>Weather</code>&nbsp;table, write a SQL query to find all dates’ Ids with higher temperature compared to its previous (yesterday’s) dates.</p>

<h4><strong>Advanced Join</strong></h4>
<p><strong><a href="https://leetcode.com/problems/exchange-seats/">626. Exchange Seats</a></strong></p>
<p><strong>Problem: </strong>Mary is a teacher in a middle school and she has a table&nbsp;<code>seat</code>&nbsp;storing students’ names and their corresponding seat ids.</p>
<p>The column&nbsp;<b>id</b>&nbsp;is continuous increment.</p>
<p>Mary wants to change seats for the adjacent students.</p>
<p>Can you write a SQL query to output the result for Mary?</p>
<p><a id="508752" href="https://constant-contact.ibfwsl.net/c/2043780/508752/3411"><img src="https://a.impactradius-go.com/display-ad/3411-508752" alt="Help grow your blog with Constant Contact email marketing" width="300" height="250"></a><img src="https://constant-contact.ibfwsl.net/i/2043780/508752/3411" width="0" height="0"></p>
<h4><strong>Simple Joins</strong></h4>
<p><strong><a href="https://www.hackerrank.com/challenges/the-report/problem">The Report</a></strong></p>
<p><em><strong>Problem: </strong>Ketty</em>&nbsp;gives&nbsp;<em>Eve</em> a task to generate a report containing three columns: <em>Name</em>,&nbsp;<em>Grade</em>&nbsp;and&nbsp;<em>Mark</em>.&nbsp;<em>Ketty</em>&nbsp;doesn’t want the NAMES of those students who received a grade lower than&nbsp;<em>8</em>. The report must be in descending order by grade — i.e. higher grades are entered first. If there is more than one student with the same grade (8-10) assigned to them, order those particular students by their name alphabetically. Finally, if the grade is lower than 8, use “NULL” as their name and list them by their grades in descending order. If there is more than one student with the same grade (1-7) assigned to them, order those particular students by their marks in ascending order.</p>
<p>Write a query to help Eve.<img src="https://ad.linksynergy.com/fs-bin/show?id=GjbDpcHcs4w&amp;bids=507388.2192850&amp;type=2&amp;subid=0" width="1" height="1"><br>
<img src="https://ad.linksynergy.com/fs-bin/show?id=GjbDpcHcs4w&amp;bids=596027.14166323990&amp;type=2&amp;subid=0" width="1" height="1"></p>
<h4><strong>Ranking, Row Numbers And Analytic Functions</strong></h4>
<p><strong><a href="https://leetcode.com/problems/nth-highest-salary/">177.&nbsp;Nth Highest Salary</a></strong></p>
<p><strong>Problem: </strong>Write a SQL query to get the&nbsp;<em>n</em><sup>th</sup>&nbsp;highest salary from the&nbsp;<code>Employee</code>table.<br>
<img src="https://ad.linksynergy.com/fs-bin/show?id=GjbDpcHcs4w&amp;bids=596027.816&amp;type=4&amp;subid=0" width="1" height="1"></p>
<h4>Complex Self Joins</h4>
<p><strong><a href="https://www.hackerrank.com/challenges/symmetric-pairs/problem">Symmetric Pairs</a></strong></p>
<p><strong>Problem: </strong>You are given a table,&nbsp;<em>Functions</em>, containing two columns:&nbsp;<em>X&nbsp;</em>and&nbsp;<em>Y</em>.</p>
<p>Two pairs&nbsp;<em>(X<sub>1</sub>, Y<sub>1</sub>)</em>&nbsp;and&nbsp;<em>(X<sub>2</sub>, Y<sub>2</sub>)</em>&nbsp;are said to be&nbsp;<em>symmetric</em>&nbsp;<em>pairs</em>&nbsp;if&nbsp;<em>X<sub>1</sub>&nbsp;= Y<sub>2</sub></em>&nbsp;and&nbsp;<em>X<sub>2</sub>&nbsp;= Y<sub>1</sub></em>.</p>
<p>Write a query to output all such&nbsp;<em>symmetric</em>&nbsp;<em>pairs</em>&nbsp;in ascending order by the value of&nbsp;<em>X</em>.</p>
<p><span>If you need more SQL try these one as well:</span></p>
<p><strong><a href="https://www.hackerrank.com/challenges/occupations/problem">Occupations</a></strong></p>
<p><strong><a href="https://www.hackerrank.com/challenges/harry-potter-and-wands/problem">Ollivander’s Inventory</a></strong></p>


<h4><strong>Videos:</strong></h4>
<p><strong>IQ15: 6 SQL Query Interview Questions</strong></p>
<p><span><iframe type="text/html" width="893" height="503" src="https://www.youtube.com/embed/uAWWhEA57bE?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>

<p><a href="https://www.youtube.com/watch?v=QFj-hZi8MKk"><strong>Learning about ROW_NUMBER and Analytic Functions</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=G3kYPzLWtpo&amp;t=4s"><strong>Advanced Implementation Of Analytic Functions Running Total</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=XecU6Ieyu-4&amp;t=54s"><strong>Advanced Implementation Of Analytic Functions Median</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=2-1XQHAgDsM&amp;list=PL6EDEB03D20332309"><strong>Wise Owl SQL Videos</strong></a></p>
<h3>Post Video SQL Problems</h3>
<p>Once you have finished watching the SQL videos above. Consider trying the new problems below. Try to see if you feel like you are improving. Again, note down any specific topics you feel weak on.</p>
<p><strong><a href="https://www.hackerrank.com/challenges/binary-search-tree-1/problem">Binary Tree Nodes</a></strong></p>
<p><strong><a href="https://leetcode.com/problems/big-countries/">595.&nbsp;Big Countries</a></strong></p>
<p><strong><a href="https://leetcode.com/problems/exchange-seats/" target="_blank" rel="noopener noreferrer">626. Exchange Seats</a></strong></p>
<p><strong><a href="https://www.hackerrank.com/challenges/weather-observation-station-18/problem">Weather Observation Station 18</a></strong></p>
<p><strong><a href="https://www.hackerrank.com/challenges/challenges/problem">Challenges</a></strong></p>
<p><strong><a href="https://www.hackerrank.com/challenges/print-prime-numbers/problem">Print Prime Numbers</a></strong></p>
<p><strong><a href="https://data36.com/sql-interview-questions-tech-screening-data-analysts/">SQL Interview Questions: 3 Tech Screening Exercises (For Data Analysts)</a></strong></p>

<h3><strong>Databases, ETL and Data Warehouses</strong></h3>
<p><img src="https://i0.wp.com/www.coriers.com/wp-content/uploads/2019/05/MySQL-Sample-Database-Schema.png?resize=429%2C343&amp;ssl=1" alt="database interview questions" width="429" height="343" srcset="https://i0.wp.com/www.coriers.com/wp-content/uploads/2019/05/MySQL-Sample-Database-Schema.png?w=701&amp;ssl=1 701w, https://i0.wp.com/www.coriers.com/wp-content/uploads/2019/05/MySQL-Sample-Database-Schema.png?resize=300%2C240&amp;ssl=1 300w" sizes="(max-width: 429px) 100vw, 429px" data-recalc-dims="1"></p>
<p>For database, ETL and data warehouse design questions we have gathered and even created some videos we hope will help you out when it comes to explaining your design in an interview. In addition, we have listed out a few plausible database/DW concepts you could attempt to design out on your own.</p>
<p>*We are working on making similar videos. <a href="https://forms.gle/yfMf7bnckZTyG6Ln7">Sign up to get future emails</a> about our videos.</p>
<p><a href="https://www.youtube.com/watch?v=I_rxqSJAj6U"><strong>Designing A Traditional Relational Database Video</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=--OJpdPeH80"><strong>Data Warehouse Design Video</strong></a></p>
<p><strong>ETL Design Video</strong></p>
<p><span><iframe type="text/html" width="893" height="503" src="https://www.youtube.com/embed/sLhInuwdwcc?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>


<h3>Self Practice Problems:</h3>
<p>For this part of your interview practice we are going to list out a few business systems that you can try to design out. First we recommend designing a relational database, then thinking about how you would design an ETL and DW that rely on that relational DB.</p>
<p>*In addition, we have found it very common that interviewers will base their interview questions off of your design. So think about some of the questions you could answer with your DB and list them out.</p>
<p>Design a Database/ETL and DW for a:</p>
<ul>
<li>Dating App</li>
<li>Bicycle Rental Service</li>
<li>Music Streaming App</li>
<li>Job Search Website</li>
<li>Udemy like website</li>
</ul>
<p>These are just a few ideas. We hope they help you have a clearer idea of what you can practice modeling and designing. Take some time to think about how users interact with these websites before getting started.</p>

<h2>Programming Problems</h2>
<p>Data engineers do a significant amount of programming in there daily life. There are several specific languages data engineers use. In particular, Python is arguable the most common.</p>
<p>If the role requires a lot of Hadoop work, then Java is also a useful language to have. There are a few other useful languages like Java and Powershell (if you work at a Microsoft shop).</p>
<p>There are two types of questions we have experienced. Some interviewers will ask you more operational questions. Others will ask classic algorithm and data structure questions.</p>
<p><img src="https://ad.linksynergy.com/fs-bin/show?id=GjbDpcHcs4w&amp;bids=596027.488&amp;type=4&amp;subid=0" width="1" height="1"></p>
<p>Below are list of them…</p>
<h3>Algorithms And Data Structures</h3>
<p>Before going to deep into data structure and algorithms. Let’s do a quick check to see how you are currently doing in this area. We have listed out 8 leetcode problems that vary in difficulty. Try these out and try to gauge yourself on how long it takes you as well as how many hints you needed. If you are following along with the study guide, then note this down. At the end of this list are a few more questions. So once you have watched all the videos, consider doing those problems and see if you feel like you are improving!</p>
<p><strong>Pre-Study Problems</strong></p>
<ol>
<li><strong><a href="https://leetcode.com/problems/sum-of-even-numbers-after-queries/">985. Sum of Even Numbers After Queries</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/robot-return-to-origin/">657.&nbsp;Robot Return to Origin</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/n-repeated-element-in-size-2n-array/">961.&nbsp;N-Repeated Element in Size 2N Array</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/balanced-binary-tree/">110.&nbsp;Balanced Binary Tree</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/longest-substring-without-repeating-characters/">3.&nbsp;Longest Substring Without Repeating Characters</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/remove-nth-node-from-end-of-list/">19.&nbsp;Remove Nth Node From End of List</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/merge-k-sorted-lists/">23.&nbsp;Merge k Sorted Lists</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/next-permutation/">31.&nbsp;Next Permutation</a></strong></li>
</ol>

<p>Now that you have gone through these 8 questions, and shaken off the rust. Let’s start reviewing these concepts.</p>
<p><strong>Data Structures</strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=bum_19loj9A">Data Structures &amp; Algorithms #1 – What Are Data Structures?</a></strong></p>
<p><strong><a href="https://youtu.be/njTh_OwMljA">Data Structures: Linked Lists</a></strong></p>
<p><strong><a href="https://youtu.be/oSWTXtMglKE" target="_blank" rel="noopener noreferrer">Data Structures: Trees</a></strong></p>
<p><strong><a href="https://youtu.be/t0Cq6tVNRBA" target="_blank" rel="noopener noreferrer">Data Structures: Heaps</a></strong></p>
<p><strong><a href="https://youtu.be/shs0KM3wKv8" target="_blank" rel="noopener noreferrer">Data Structures: Hash Tables</a></strong></p>
<p><strong><a href="https://youtu.be/wjI1WNcIntg" target="_blank" rel="noopener noreferrer">Data Structures: Stacks and Queues</a></strong></p>
<p><strong><a href="https://youtu.be/DuDz6B4cqVc" target="_blank" rel="noopener noreferrer">Data Structures: Crash Course Computer Science #14</a></strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=zIjfhVPRZCg">Data Structures: Tries</a></strong></p>

<p><strong>Algorithms</strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=p65AHm9MX80">Python Algorithms for Interviews</a></strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=zaBhtODEL0w&amp;list=PLX6IKgS15Ue02WDPRCmYKuZicQHit9kFt">Algorithms: Graph Search, DFS and BFS</a></strong></p>
<p><strong><a href="https://youtu.be/P3YID7liBug">Algorithms: Binary Search</a></strong></p>
<p><strong><a href="https://youtu.be/KEEKn7Me-ms" target="_blank" rel="noopener noreferrer">Algorithms: Recursion</a></strong></p>
<p><strong><a href="https://youtu.be/6Gv8vg0kcHc" target="_blank" rel="noopener noreferrer">Algorithms: Bubble Sort</a></strong></p>
<p><strong><a href="https://youtu.be/KF2j-9iSf4Q" target="_blank" rel="noopener noreferrer">Algorithms: Merge Sort</a></strong></p>
<p><strong><a href="https://youtu.be/SLauY6PpjW4" target="_blank" rel="noopener noreferrer">Algorithms: Quicksort</a></strong></p>

<p><strong>Big O Notation</strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=D6xkbGLQesk">Introduction to Big O Notation and Time Complexity (Data Structures &amp; Algorithms #7)</a></strong></p>
<p><strong>Some Interview Walk Throughs</strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=5o-kdjv7FD0">Amazon Coding Interview Question – Recursive Staircase Problem</a></strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=7HgsS8bRvjo">Google Coding Interview – Universal Value Tree Problem</a></strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=GJdiM-muYqc">Google Coding Interview Question and Answer #1: First Recurring Character</a></strong></p>

<p><strong>Post Study Problems</strong></p>
<p>Once you have finished the videos above. Consider trying the algorithm and data structure problems below. Make sure you keep track of how comfortable you felt when working on the problems.</p>
<ol>
<li><strong><a href="https://www.hackerrank.com/challenges/bigger-is-greater/problem">Bigger Is Greater</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/zigzag-conversion/">6.&nbsp;ZigZag Conversion</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/reverse-integer/">7.&nbsp;Reverse Integer</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/combination-sum-ii/">40.&nbsp;Combination Sum II</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/multiply-strings/">43.&nbsp;Multiply Strings</a></strong></li>
<li><strong><a href="https://www.hackerrank.com/challenges/larrys-array/problem">Larry’s Array</a></strong></li>
<li><strong><a href="https://www.hackerrank.com/challenges/short-palindrome/problem">Short Palindrome</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/valid-number/">65.&nbsp;Valid Number</a></strong></li>
</ol>

<p>If you still feel like you need help, then consider taking a course on <a href="https://click.linksynergy.com/deeplink?id=GjbDpcHcs4w&amp;mid=39197&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcoding-interview-bootcamp-algorithms-and-data-structure%2F">algorithms and data structures</a>.</p>
<h2>Operational Programming Problems</h2>
<p>Operational interview questions are harder to prep for. There are no “classic” interview questions here. However, they are also often easier to figure …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.coriers.com/the-interview-study-guide-for-data-engineers/">https://www.coriers.com/the-interview-study-guide-for-data-engineers/</a></em></p>]]>
            </description>
            <link>https://www.coriers.com/the-interview-study-guide-for-data-engineers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633780</guid>
            <pubDate>Tue, 29 Sep 2020 22:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Syllabus for teaching Scratch programming to kids]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24633742">thread link</a>) | @mathnmusic
<br/>
September 29, 2020 | https://learnawesome.org/items/1c96e03a-ffff-4579-b69a-0387b968b7c6-syllabus-scratch-programming-for-kids | <a href="https://web.archive.org/web/*/https://learnawesome.org/items/1c96e03a-ffff-4579-b69a-0387b968b7c6-syllabus-scratch-programming-for-kids">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>I noticed that these days, a lot of parents are being pressured by edtech industry to buy paid courses on "programming for kids" which are all simply using Scratch with bad instructions. Worse, many of them are using industrial languages like Javascript or Python which are completely unsuitable for the purpose of pedagogy. So, I have put together this syllabus/sequence of high-quality learning resources (apps/free courses/articles/videos) that I followed for my own daughter with spectacular success.</p>

<p>We have a peer group of parents and children learning Scratch programming using this syllabus. If you'd like to join, come to <a href="https://learnawesome.org/join_slack">our Slack group</a>.</p>

<h2>Why learn Scratch programming?</h2>

<p>Computational thinking skills may have a lot of practical value. It helps kids understand how computers work, and how to make new things with them. But <a href="https://twitter.com/nileshtrivedi/status/1261600393382883329">if you think programming is all about computers, you're wrong</a>. The core idea of programming is that a tiny set of simple instructions can be combined to produce immensely complex structures. We see this in cooking, knitting, chess, mathematics and much more. Your DNA, for example, is a series of instructions or a  "program".</p>

<p>But more importantly, programming is the only skill that lets you create "interactive" art. Other creators have "readers", "audience", "spectators" etc, but only programmers have "users". <a href="https://twitter.com/nileshtrivedi/status/1261601737854472192">If you haven't felt the joy of programming, you're really missing out</a>.</p>

<p>This joy is what should be the main motivation for teaching programming to kids. Not career success. We don't know what careers will be in vogue 15 years from now, but the joy of creation is an eternal human blessing.</p>

<p>Scratch is a visual programming language, built at MIT, that is used by children all over the globe. This visual language is in the shape of blocks (like Lego), and it allows its users to create online projects, games, apps, and many other things. The blocks eliminate the major source of frustration which comes from syntax errors. Scratch has a very active online community which makes this experience very engaging for kids, and they also learn collaboration and teamwork - besides figuring out how programs work.</p>

<p>Scratch, which is completely free, is what's being used by many edtech platforms. You don't need to pay a lot of money for paid courses because I have collected the best quality resources here for you and put them in a sequence that is not rushed.</p>

<p>In my opinion, it would be a mistake to start too soon with industrial languages like Python, Javascript because the child would be intimidated with a lot of details that only distract. Motivation is the #1 resource with the shortest supply. Do whatever you can to preserve it. I'd actually explore computer games like Age of Empires which provoke questions in their minds: "I wonder how they wrote code for this game!".</p>

<h2>Preparedness:</h2>

<p>Can the child count things correctly? It's NOT easy. Suppose your boss wants you to work from 8am to 11am, and mop floors 8 to 11. Simple - it's one floor per hour, right?</p>

<p>Nope! There are 4 floors to mop (8, 9, 10 and 11) but only 3 hours to work (8-9, 9-10, and 10-11).</p>

<p>Whoa -- we count floors and hours differently? You bet. And somehow, if the boss said "Mop floors 8 to 11 on April 8th to 11th" everything would be ok.</p>

<p>To understand this, read <a href="https://learnawesome.org/items/b269d560-c519-4242-91d5-66ad547cc43b-learning-how-to-count-avoiding-the-fencepost-problem-betterexplained">this article</a> under <a href="https://learnawesome.org/topics/b49bc6fd-b9bc-46c9-a6d3-ebcef2f01b07-counting">Counting</a></p>

<p>Does the child have some exposure to 2D coordinate systems? It's not a prerequisite, but will have to be discussed during the practice stage.
When you reach that stage, use resources from our <a href="https://learnawesome.org/topics/9d1d4677-7ebd-4077-9f1f-218806a340e9-coordinate-plane">co-ordinate plane topic</a>.</p>

<p>Is any one of the parents experienced with <a href="https://learnawesome.org/topics/13b5f596-e6e4-4a45-81f1-843ff7b42d82-computational-thinking">computational thinking</a>? If not, they too should go through this Scratch course. Following along with the child is also fine.</p>

<p>Do you have a computing device at home (a desktop / laptop / tablet)?</p>

<p>Parents should read <a href="https://scratch.mit.edu/parents/">this</a> and <a href="https://learnawesome.org/items/7a92e34a-982d-4d02-8c58-17de1de7f5db-scratch-team-scratch-twitter">follow the Scratch team on Twitter</a></p>

<h2>Motivation and priming:</h2>

<p>A lot of difficulty in programming is how it requires you to be very precise with language and instructions. Bringing this sensitivity is important. You can watch the <a href="https://www.youtube.com/watch?v=cDA3_5982h8">"Exact Instructions Challenge" videos</a>.</p>

<p>It is also important to create the REASON/MOTIVATION to learn Scratch such as to create your own games. So, first you should explore games made on <a href="https://learnawesome.org/items/3e9de8b8-ef9f-4a61-a091-6608d264b1a4-scratch-homepage">Scratch website</a>. See what is possible with Scratch. Remember, kids want to DO interesting things, and not LEARN something.</p>

<h2>Experience:</h2>

<p>Cooking is not very different from algorithms. You can start in the kitchen. Parent and child can enact any of the  <a href="https://www.youtube.com/watch?v=cDA3_5982h8">"Exact Instructions Challenges"</a> on their own. You might want to record a video, but no need to publish it anywhere.</p>

<p>After this, I recommend playing at least the first two levels of the programming puzzle game <a href="https://learnawesome.org/items/2d6e8e6d-0e95-46d6-a4b8-0cf8d83c1634-lightbot">Lightbot</a>. It's a free app which gives a highly-constrained and playful environment for algorithmic thinking that feels like playing a game instead of "learning". Remember, kids want to be able to "do" interesting stuff, not "learn" something.</p>

<p>Avoid <a href="https://learnawesome.org/items/9d0fe359-b80a-4446-bdd5-c7e62afbbccc-scratchjr-home">Scratch Junior</a>. It's better to stop after Lightbot and wait for them to be ready for main Scratch.</p>

<h2>Instruction and Practice:</h2>

<p>Scratch is available both as a website and as an <a href="https://scratch.mit.edu/download">app that works offline</a>.</p>

<p>First try the <a href="https://scratch.mit.edu/projects/editor/?tutorial=getStarted">interactive online tutorial</a>.</p>

<p>More tutorials are available <a href="https://scratch.mit.edu/ideas">here</a>.</p>

<p>Now we are ready for a "course".  <a href="https://learnawesome.org/items/a2dbab26-0c93-49b7-ae52-105f312c075a-programming-in-scratch">The best one is this free course on edX</a> which will explain all the concepts in detail. Complete it as far as you can. Remember to try things out. Coding, like swimming, can only be learnt by doing.</p>

<p>You can join other parents going through this syllabus in <a href="https://learnawesome.org/join_slack">our Slack group</a>. :-)</p>

<h2>Getting help:</h2>

<p>Instead of helping you once, we will teach you how to find help yourself on the Internet:</p>

<ul>
<li>Try these <a href="https://learnawesome.org/items/8cb38a52-03a2-4587-8f20-efc404291590-getting-unstuck-strategies">strategies for getting unstuck</a> here.</li>
<li>Check on <a href="https://learnawesome.org/items/a7b45674-d23e-4d65-bc57-f80c07cf1ed9-scratch-wiki">Scratch wiki</a>.</li>
<li>And the <a href="https://learnawesome.org/items/08fdd0dc-792d-49b2-a24d-a0b16050cedc-discuss-scratch">Scratch forum</a>.</li>
<li>There's a <a href="https://learnawesome.org/items/6afac218-ee56-4539-b9f8-24d8d83125d9-teaching-with-scratch-public-group-facebook">Facebook group</a>.</li>
<li>Tweet to <a href="https://learnawesome.org/items/7a92e34a-982d-4d02-8c58-17de1de7f5db-scratch-team-scratch-twitter">Scratch team</a> or <a href="https://twitter.com/ScratchJr">Scratch Junior team</a></li>
<li>Ask fellow Scratch learners in <a href="https://learnawesome.org/join_slack">our Slack group</a></li>
</ul>

<h2>Performance:</h2>

<ul>
<li>Basic: The student should be able to Create a game with her own idea and publish it on scratch website.</li>
<li>Advanced: Complete this <a href="https://learnawesome.org/items/0db431c8-f480-4a96-8907-85fef9eb6a4a-creative-computing-lab-at-the-harvard-graduate-school-of-education">series of Scratch challenges</a>.</li>
</ul>

<h2>Learn from the experts</h2>

<ul>
<li><p>Let the kid play games on Scratch. They should know what "apps" are, before they get interested in how apps get made. Occasionally, they will get curious and click on the "See Inside" button to bypass a difficult game level. At that point, they are hacking in its true spirit. Count yourself as a successful parent at this point! 😄</p></li>
<li><p>Watch Scratch tutorials on YouTube, such as how to create their own platformer game in Scratch. Be patient at this point though. Let them make simpler games, stories etc before reaching this slightly difficult level.</p></li>
<li><p>Learn how to create custom blocks. This is a rough simulation of how functions work in industrial programming languages.</p></li>
</ul>

<h2>Teach:</h2>

<p>Your child should now teach Scratch to a friend or sibling. Teaching is one of the best ways to consolidate your <a href="https://learnawesome.org/topics/4e9769cb-5233-44fe-91d4-c49d601f6dbe-learning">learning</a>.</p>

<h2>What next after Scratch?</h2>

<p>Frankly, there is no need to rush. Scratch alone can expose them to a wide variety of programming techniques, but if you do want to go forward, try these topics:</p>

<ul>
<li><p><a href="https://learnawesome.org/topics/efde49a5-47bf-4689-88b1-303a7bca5f4b-programming-languages-snap">Snap!</a> This adds two key features to Scratch: Lists as a first-class object (so you can introduce data-structures like tree, stack, queue etc) and higher-order functions. But it doesn't have a great UI or an active community like Scratch does.</p></li>
<li><p><a href="https://learnawesome.org/topics/4cfd43da-19d7-40d4-b3d6-95297b1a31da-programming-languages-processing">Processing</a> is a textual language that still makes it easy to generate concrete, visual things like animations or games. It is important to work on concrete things because it shortens the feedback loop which is crucial for formation of concepts.</p></li>
<li><p><a href="https://learnawesome.org/topics/13b5f596-e6e4-4a45-81f1-843ff7b42d82-computational-thinking">Computational Thinking</a></p></li>
</ul>

<h2>Help us spread the word.</h2>

<p>We are building a community of lifelong learners. If you have landed here, you probably have an immense love for learning like us. We would love to have you join <a href="https://learnawesome.org/join_slack">our Slack group</a>.</p>

				
			
		</div></div>]]>
            </description>
            <link>https://learnawesome.org/items/1c96e03a-ffff-4579-b69a-0387b968b7c6-syllabus-scratch-programming-for-kids</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633742</guid>
            <pubDate>Tue, 29 Sep 2020 22:24:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nix-copy-closure your nix-shell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633664">thread link</a>) | @setheron
<br/>
September 29, 2020 | https://fzakaria.com/2020/09/28/nix-copy-closure-your-nix-shell.html | <a href="https://web.archive.org/web/*/https://fzakaria.com/2020/09/28/nix-copy-closure-your-nix-shell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>
        Published 2020-09-28
        on <a href="https://fzakaria.com/">Farid Zakaria's Blog</a>
        <span>
          —
          <a href="https://fzakaria.com/2020/09/28/nix-copy-closure-your-nix-shell.html">
            Permalink
          </a>
        </span>
    </p>
    
    <article>
      <blockquote>
  <p>This is a synopsis of <a href="https://github.com/NixOS/nix/issues/1985">https://github.com/NixOS/nix/issues/1985</a>. I recommend reading it for additional detail. Many thanks to contributors on the issue like <a href="https://github.com/Infinisil">Infinisil</a> for adding context.</p>
</blockquote>

<p>Someone reached out to me over e-mail to discuss my previous post on <a href="https://fzakaria.com/2020/08/11/caching-your-nix-shell.html">caching your nix-shell</a>.</p>

<p><em>“What I wish to do is to copy a particular development environment (nix-shell)
from A to B, so that I could run nix-shell on server B. Server B is only accessible through SSH and <strong>does not</strong> have Internet access.”</em></p>

<!--more-->

<p>Seems straightforward, so let’s investigate. Let’s use a very basic <em>shell.nix</em> file.</p>

<blockquote>
  <p>Very important we make sure to pin <em>nixpkgs</em>. In the example below I do it inline in the Nix expression but you can also use <a href="https://github.com/nmattia/niv">niv</a> or pin the channel to a particular commit.</p>
</blockquote>

<div><div><pre><code><span>let</span>
  <span>nixpkgs</span> <span>=</span> <span>import</span> <span>(</span><span>builtins</span><span>.</span><span>fetchTarball</span> <span>{</span>
    <span>name</span> <span>=</span> <span>"nixos-unstable-2020-09-24"</span><span>;</span>
    <span>url</span> <span>=</span>
      <span>"https://github.com/nixos/nixpkgs/archive/5aba0fe9766a7201a336249fd6cb76e0d7ba2faf.tar.gz"</span><span>;</span>
    <span>sha256</span> <span>=</span> <span>"05gawlhizp85agdpw3kpjn41vggdiywbabsbmk76r2dr513188jz"</span><span>;</span>
  <span>})</span> <span>{</span> <span>};</span>
<span>in</span> <span>with</span> <span>nixpkgs</span><span>;</span>
<span>with</span> <span>stdenv</span><span>;</span>
<span>with</span> <span>stdenv</span><span>.</span><span>lib</span><span>;</span>
<span>mkShell</span> <span>{</span>
  <span>name</span> <span>=</span> <span>"example-shell"</span><span>;</span>
  <span>buildInputs</span> <span>=</span> <span>[</span> <span>hello</span> <span>];</span>
  <span>shellHook</span> <span>=</span> <span>''</span><span>
</span><span>    export MESSAGE="$(hello)";</span><span>
</span><span>  ''</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Let’s see it in action:</p>
<div><div><pre><code>❯ nix-shell shell.nix

<span>[</span>nix-shell:~/code/nix/playground]<span>$ </span><span>echo</span> <span>$MESSAGE</span>
Hello, world!
</code></pre></div></div>

<p>Recently an improvement <a href="https://github.com/NixOS/nixpkgs/pull/95536">#95536</a> by <a href="https://github.com/Infinisil">Infinisil</a> made the workflow to discover the <em>transitive runtime closure</em> much simpler than what I had <a href="https://fzakaria.com/2020/08/11/caching-your-nix-shell.html">blogged about</a>.</p>

<p>✨ A new attribute for derivations <em>inputDerivation</em> is introduced that is <em>always buildable</em> and whose runtime dependences are it’s build dependencies; exactly what we need for nix-shell!</p>

<div><div><pre><code>❯ nix-build <span>--no-out-link</span> shell.nix <span>-A</span> inputDerivation
these derivations will be built:
  /nix/store/bjn4imm9dw7xnxpjrwyrpk0wsy0j7xwh-example-shell.drv
building <span>'/nix/store/bjn4imm9dw7xnxpjrwyrpk0wsy0j7xwh-example-shell.drv'</span>...
/nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell
</code></pre></div></div>

<p>We now have a store path <em>/nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell</em> which we can check the immediate dependencies.</p>

<blockquote>
  <p>The below is simply the <em>immediate</em> dependencies and not the full transitive closure for brevity.</p>
</blockquote>

<div><div><pre><code>❯ nix-store <span>--query</span> <span>--references</span> <span>\</span>
    /nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell

/nix/store/2jysm3dfsgby5sw5jgj43qjrb5v79ms9-bash-4.4-p23
/nix/store/333six1faw9bhccsx9qw5718k6b1wiq2-stdenv-linux
/nix/store/9krlzvny65gdc8s7kpb6lkx8cd02c25b-default-builder.sh
/nix/store/w9yy7v61ipb5rx6i35zq1mvc2iqfmps1-hello-2.10
/nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell
</code></pre></div></div>

<p>I will now copy the <em>shell.nix</em> file to my other machine &amp; copy the transitive closure to it.</p>
<div><div><pre><code>❯ scp shell.nix machine-b:~

❯ nix-copy-closure <span>--to</span> machine-b <span>\</span>
    /nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell
copying 36 paths...
</code></pre></div></div>

<p>Let’s hop on <em>machine B</em> and create a network namespace to pretend we do not have Internet access.</p>

<blockquote>
  <p>A network namespace is logically another copy of the network stack,
with its own routes, firewall rules, and network devices.</p>
</blockquote>

<div><div><pre><code>❯ ssh machine-b

<span># since we won't have any Internet access, hydrate the cache</span>
<span># with our nixpkgs version</span>
❯ nix-prefetch-url <span>--unpack</span> <span>\</span>
https://github.com/nixos/nixpkgs/archive/5aba0fe9766a7201a336249fd6cb76e0d7ba2faf.tar.gz <span>\</span>
<span>--name</span> <span>"nixos-unstable-2020-09-24"</span>

❯ <span>sudo </span>ip netns add nixshell
<span># enter the namespace</span>
❯ <span>sudo </span>ip netns <span>exec </span>nixshell su <span>$USER</span> <span>-c</span> zsh

<span># let's confirm we do not have Internet access</span>
❯ ping google.com
ping: google.com: Temporary failure <span>in </span>name resolution
</code></pre></div></div>

<p>Let’s fire up our <em>nix-shell</em> and see if it works.</p>

<div><div><pre><code><span># don't forget we are within our network namespace</span>
<span># without access to the Internet</span>
❯ nix-shell shell.nix
bash: cannot <span>set </span>terminal process group <span>(</span><span>-1</span><span>)</span>: Inappropriate ioctl <span>for </span>device
bash: no job control <span>in </span>this shell

<span>[</span>nix-shell:~]<span>$ </span><span>echo</span> <span>$MESSAGE</span>
Hello, world!
</code></pre></div></div>

<p>🎆 Huzzah!
We have now copied over our development environment <em>hermetically</em> with the help of Nix. This is a great demonstration of the power of Nix &amp; reproducibility.</p>

<blockquote>
  <p>An important take-away though is that it’s important to make sure <em>we pin</em> the exact version of <em>nixpkgs</em> otherwise the <em>nix-shell</em> may calculate different hashes.</p>
</blockquote>

<p>Do you have an interesting workflow or innovative use of Nix with development environments? <a href="mailto:farid.m.zakaria@gmail.com">Let me know about it.</a></p>


<hr>
    </article>
</div></div>]]>
            </description>
            <link>https://fzakaria.com/2020/09/28/nix-copy-closure-your-nix-shell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633664</guid>
            <pubDate>Tue, 29 Sep 2020 22:15:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How India Censors the Web]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24633490">thread link</a>) | @srean
<br/>
September 29, 2020 | http://iamkush.me/how-india-censors-the-web/ | <a href="https://web.archive.org/web/*/http://iamkush.me/how-india-censors-the-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><b>Update (11th April 2020): This paper has been accepted at <a href="https://websci20.webscience.org/">ACM Web Science 2020</a>. A preprint can be accessed on <a href="https://arxiv.org/pdf/1912.08590.pdf" target="_blank">arXiv</a>.</b></p>

<p>Nation states around the world engage in web censorship using a variety of legal and technical methods. India is no different in this regard: the Government of India can legally order internet service providers (ISPs) operating in its jurisdiction to block access to certain websites for its users. This makes the situation different from jurisdictions like Iran and China, where internet censorship is largely centralised. Legal provisions in India, namely Section 69A and Section 79 of the Information Technology (IT) Act, allow the Central Government and the various courts in the country to issue website-blocking orders that ISPs are legally bound to comply with. <strong>Most of these orders are not publically available</strong>.</p>

<p>Recent events and the opaque nature of internet censorship in India motivated us at <a href="https://cis-india.org/" target="_blank">The Center for Internet and Society</a> to study India's censorship mechanism in detail. We spent the last year trying to answer two questions pertaining to how internet users in India experience web censorship:</p>

<ol>  
<li>What are the technical methods of censorship used by ISPs in India?</li>  
<li>Are all ISPs blocking the same websites?</li>  
</ol>

<p><strong>Our work has been so far the largest study of web censorship in India</strong>, both in terms of the number of censorship mechanisms that we test for and the number of potentially-blocked websites (PBWs). </p>

<h3 id="datacuration">Data curation</h3>

<p>We compiled a list of PBWs from three sources:  </p>

<ul>  
<li><b>Government orders</b>: A website/URL blocking order may come from the Government of India (Section 69A, IT Act). These orders are usually not in the public domain, as a confidentiality clause prevents any party from disclosing its contents. We collect published and leaked Government orders.</li>  
<li><b>Court orders</b>: The various courts in India also have the power to issue website blocking orders (Section 79, IT Act). Not all such orders are available in the public domain. However, the Government and BSNL (a public company operating as an ISP) have provided portions of this list when under pressure to respond to Right to Information (RTI) requests.</li>  
<li><b>User reports</b>: <a href="https://internetfreedom.in/" target="_blank">The Internet Freedom Foundation</a> collects and publishes reports from internet users who notice blocked websites.</li>  
</ul>

<p>Collecting data from these sources led to a total of 9673 unique URLs, which yielded 5798 unique websites. To limit ourselves to active websites, we exclude all websites for which we could not resolve via Tor circuits, culminating in a corpus of 4379 PBWs.</p>

<h3 id="networktestsfordetectingcensorship">Network tests for detecting censorship</h3>

<p>We designed four network tests that probe the existence of censorship at the DNS, TCP, HTTP, and TLS level. For the sake of brevity, I'll skip elaborating on the tests in this post; the details can be found in our <a href="https://arxiv.org/pdf/1912.08590.pdf" target="_blank">preprint</a>.</p>

<p>We run these tests for each website in our corpus from connections of six different ISPs (Jio, Airtel, Vodafone, MTNL, BSNL, and ACT), <strong>which together serve more than 98% of Internet users in India</strong>. Our findings not only confirm that ISPs are using different techniques to block websites, but also demonstrate that different ISPs are not blocking the same websites.</p>

<h3 id="results">Results</h3>

<p>In terms of censorship methods, our results confirm that ISPs in India are at liberty to use any technical filtering mechanism they wish: there was, in fact, no single mechanism common across ISPs. </p>

<p>We observe ISPs to be using a melange of techniques for blocking access, such as DNS poisoning and HTTP host header inspection. <b>Our tests also discern the use of SNI inspection being employed by the largest ISP in India (Jio) to block HTTPS communication, the use of which is previously undocumented in the Indian context</b>.</p>

<p><img src="https://i.imgur.com/vDAgGnf.png" alt="img">
</p><center>Censorship techniques employed by Indian ISPs</center>

<p>Further, we notice that all ISPs using multiple censorship mechanisms are not blocking the same websites with each mechanism. For instance, ACT uses only DNS censorship for blocking 233 websites, only HTTP censorship for 1873 websites, and both to block 1615 websites. Such irregularities are illustrated below.</p>

<p><img src="https://i.imgur.com/azWaVJW.png" alt="img">
</p><center>Censorship techniques used by (i) ACT, (ii) Airtel, and (iii) Jio for blocking websites. We notice the same ISP using multiple techniques for blocking different websites.</center>

<h3 id="somealarmingdiscoveries">Some alarming discoveries</h3>

<p>Our study has recorded large inconsistencies in website blocklists of different Indian ISPs. From our list of 4379 PBWs, we find that 4033 are being blocked by at least one ISP’s blocklist. In terms of absolute numbers, we notice that ACT blocks the maximum number of websites (3721). Compared to ACT, Airtel blocks roughly half the number of websites (1892).</p>

<p>Perhaps most surprisingly, we find that only 1115 websites out of the 4033 (just 27.64%) are blocked by all six ISPs. <b>Simply stated, we find conclusive proof that Internet users in India can have wildly different experiences of web censorship.</b></p>

<p><img src="https://i.imgur.com/XXaRpuf.png" alt="img"></p>

<p>Analysing inconsistencies in blocklists also makes it clear that ISPs in India are:</p>

<ol>  
<li>Not properly complying with website blocking (or subsequent unblocking orders), and/or </li>  
<li>Arbitrarily blocking websites without the backing of a legal order.</li>  
</ol>

<p>This has important legal ramifications: <b>India’s <a href="https://bit.ly/netneutralityframework" target="_blank">Net Neutrality regulations</a>, codified in the license agreements that ISPs enter with the Government of India, explicitly prohibit such behaviour</b>.</p>

<p>Our study also points to how the choice of technical methods used by ISPs to censor websites can decrease transparency about state-ordered censorship in India. While some ISPs were serving censorship notices, other ISPs made no such effort. For instance, Airtel responded to DNS queries for websites it wishes to block with <strong>NXDOMAIN</strong>. Jio used <strong>SNI-inspection</strong> to block websites, a choice which makes it <strong>technically impossible for them to serve censorship notices</strong>. Thus, the selection of certain technical methods by ISPs exacerbates the concerns created by the opaque legal process that allows the Government to censor websites.</p>

<h3 id="summingup">Summing up</h3>

<p>Web censorship is a curtailment of the right to freedom of expression guaranteed to all Indians. There is an urgent need to reevaluate the legal and technical mechanisms of web censorship in India to make sure the curtailment is transparent, and the actors accountable. </p>

<p>The whimsical attitude towards web censorship from both ISPs and the Government necessitates the development of a crowdsourced tool to <strong>monitor and measure such censorship from different vantage points in the country</strong>. This will shed further light into the geographical variation of censorship practices by ISPs across India, which is still unclear.</p>

<p>To probe this further we have ported our network tests into an android application, and are looking for volunteers who are willing to run it on their mobile networks. The entire process will be <strong>completely anonymous</strong>; we will not be collecting any user-specific information. If you live in India, please consider running <a href="https://play.google.com/store/apps/details?id=com.censorwatch.netprobesapp">Censorwatch</a>.</p>

<p><strong>Acks</strong> - This study was done in collaboration with <a href="https://gurshabad.github.io/" target="_blank">Gurshabad Grover</a> and <a href="https://www.linkedin.com/in/bansalvarun96/" target="_blank">Varun Bansal</a> at <a href="https://cis-india.org/" target="_blank">The Center for Internet and Society</a>, graciously supported by the <a href="https://www.macfound.org/" target="_blank">MacArthur Foundation</a>.</p>
			</section></div>]]>
            </description>
            <link>http://iamkush.me/how-india-censors-the-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633490</guid>
            <pubDate>Tue, 29 Sep 2020 21:55:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D and Covid: A Review]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633248">thread link</a>) | @usefulcat
<br/>
September 29, 2020 | https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><div id="viewer-6p6al"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e" data-pin-media="https://static.wixstatic.com/media/a27d24_e10b0ace71dc4bf5a0aa0e0dd52147fa~mv2.jpg/v1/fit/w_900,h_458,al_c,q_80/file.png" src="https://static.wixstatic.com/media/a27d24_e10b0ace71dc4bf5a0aa0e0dd52147fa~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-7n7r8">Recent headlines suggest that I could protect myself from Covid and also cut my risk of dying from Covid <em>by half </em>just by taking Vitamin D. If that is the case, why aren't we all taking it? We hand out masks; why not Vitamin D?</p><p id="viewer-di3pq">Let's pause here for a reality check: Lots of diseases are correlated with Vitamin D deficiency – but most are not caused by it. It’s a correlation, not a causation. Vitamin D deficiency is often a marker of overall poor health; sicker individuals are more likely to develop low Vitamin D. Treating the deficiency treats the symptom, not the cause. In trials of Vitamin D vs. placebo for preventing disease, <a href="https://www.devaboone.com/post/vitamin-d-part-3-the-evidence" target="_blank" rel="noopener"><u>Vitamin D often disappoints.</u></a> </p><p id="viewer-avjvo">But maybe Covid is different. Covid is a respiratory infection, and in meta-analyses severe Vitamin D deficiency does appear to increase the risk of respiratory infections. We also have a plausible mechanism through which Vitamin D could influence Covid. The latest hypothesis asserts that a “bradykinin storm” is largely responsible for the severe symptoms of Covid. A surge of bradykinin, a peptide related to inflammation, leads to blood vessel dilation and increased permeability (“leaky vessels”). This contributes to swelling and fluid retention in the lungs and numerous other effects throughout the body, including cognitive deficits, severe hypokalemia and resulting cardiac arrythmias, and hypotension.</p><p id="viewer-eg7lh">There are complicated pathways involved in the production and regulation of bradykinin. Covid involves the renin-angiotensin system (RAS), which is involved in blood pressure control, fluid management, and inflammation. Vitamin D modulates this system somewhat, which is how it could play a role in modulating the inflammation and bradykinin storm that can occur with Covid. The relationship between Vitamin D and bradykinin is not simple or  straightforward, but it is there (find Vitamin D in the top left of the following image).</p><h3 id="viewer-a9vd1">Pathways involved in a bradykinin storm</h3><div id="viewer-6u3jj"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e" data-pin-media="https://static.wixstatic.com/media/3e0600_7997c2251a1040b8be64237b3c6d8346~mv2.jpg/v1/fit/w_1000,h_1000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_7997c2251a1040b8be64237b3c6d8346~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-f1rr2"><em>From: </em><a href="https://pubmed.ncbi.nlm.nih.gov/32633718/" target="_blank" rel="noopener"><em><u>Garvin MR, Alvarez C, Miller JI, Prates ET, Walker AM, Amos BK, Mast AE, Justice A, Aronow B, Jacobson D. A mechanistic model and therapeutic interventions for COVID-19 involving a RAS-mediated bradykinin storm. Elife. 2020 Jul 7;9:e59177.</u></em></a></p><p id="viewer-dpsa1"><strong>It’s not enough, though, to have a plausible explanation for Vitamin D’s role. </strong>We need human studies, and we now have them. Let’s go through some of the studies that have received the most attention. </p><p id="viewer-bd2aq"><strong>1: Observational study of individuals tested for Covid (U.S<span>.): </span></strong><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2770157" target="_blank" rel="noopener"><strong><u>Association of Vitamin D Status and Other Clinical Characteristics With COVID-19 Test Results [1]</u></strong></a></p><p id="viewer-f2tn1"><span><strong>Question asked:</strong> Do individuals with low Vitamin D have higher rates of Covid infection?</span></p><p id="viewer-9gacj"><span><strong>How the question was answered:</strong> Researchers reviewed records for 489 adults who had been tested for Covid and had had Vitamin D testing within the last year, at a single center in the U.S.</span></p><p id="viewer-5cdp9"><span><strong>Findings</strong>: Those who were deficient in Vitamin D (less than 20 ng/ml) had higher rates of Covid than those with sufficient Vitamin D: 19% vs. 12%. The risk of having a positive test persisted even when correcting for other medical conditions.</span></p><p id="viewer-eo35u"><span><strong>Conclusion: </strong>There is likely an association between Vitamin D deficiency and developing Covid. </span>This does not necessarily imply that the low Vitamin D caused a susceptibility to Covid. People with low Vitamin D could be more susceptible to infection because they have other health issues. For example, nursing home residents are more likely to be deficient in Vitamin D – and they are also at high risk for Covid spread. The study did attempt to correct for some of this and still found an association between Vitamin D and Covid. Overall, this study provides a solid basis for future research, and reinforces the recommendation to correct Vitamin D deficiencies.</p><p id="viewer-d4961"><span><strong>2. Observational study of individuals tested for Covid (U.S.): </strong></span><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0239252" target="_blank" rel="noopener"><strong><u>SARS-CoV-2 positivity rates associated with circulating 25-hydroxyvitamin D levels [2]</u></strong></a></p><p id="viewer-8pk9p"><strong>Question asked:</strong> Is low Vitamin D associated with rate of Covid infection?</p><p id="viewer-46bul"><strong>How the question was answered</strong>: Researchers sifted through Quest lab results to find patients who had had Covid testing and had also had Vitamin D levels checked within the last year. They ended up with over 190,000 individuals from the United States. All had zip code information available (which was used to estimate race). Vitamin D levels were grouped and then the rate of Covid positivity was compared between groups. </p><p id="viewer-6qj8d"><strong>Finding:</strong> Low Vitamin D levels associated with higher rates of Covid</p><p id="viewer-6l5lr">Here is one graph from the study, showing that as Vitamin D levels rise, Covid positivity rates fall:</p><div id="viewer-ba99b"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e" data-pin-media="https://static.wixstatic.com/media/3e0600_e6c5ae0b792f407d86855628a1ce559b~mv2.jpg/v1/fit/w_1000,h_1000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_e6c5ae0b792f407d86855628a1ce559b~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-4emce"><em>For Vitamin D levels under 30 ng/ml, Covid rates appear clearly higher than for levels above 30. After getting above 40 ng/ml, the benefit is less clear. [2]</em></p><p id="viewer-bdn8n"><strong>Conclusion:</strong> This is a convincing association, but not evidence for causation. People with Vitamin D levels under 30 ng/ml seem to have higher rates of Covid infection. But those with low Vitamin D likely had other medical conditions, which were not addressed. This study was not designed to address this – it only looked at lab results, not medical history.</p><p id="viewer-7bq6o">Having said that, the data include a large number of individuals and the effect of Vitamin D level is striking. This provides a solid basis for further research. </p><p id="viewer-bh966"><strong>3. Observational study of Covid patients (Iran): </strong><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0239799" target="_blank" rel="noopener"><strong><u>Vitamin D sufficiency, a serum 25-hydroxyvitamin D at least 30 ng/mL reduced risk for adverse clinical outcomes in patients with COVID-19 infection [3]</u></strong></a></p><p id="viewer-42e4h"><strong>Question asked</strong>: Is low Vitamin D associated with poor outcomes in patients diagnosed with Covid?</p><p id="viewer-6fd60"><strong>How the question was answered:</strong> Researchers reviewed the records of 235 patients diagnosed with symptomatic Covid in a single emergency department in Iran. They compared patients with Vitamin D levels greater than or equal to 30 ng/ml to those with Vitamin D levels below 30. The also compared the mortality of patients over age 40.</p><p id="viewer-e4o8k"><strong>Findings:</strong> </p><p id="viewer-6cp5">ICU admission and intubation: The two groups had similar rates.</p><p id="viewer-a49o2">Severity of disease: For patients who were sufficient in Vitamin D (30 ng/ml or higher), 63% had “severe” disease, compared to 77% of those who were deficient. Severe disease defined as: reporting shortness of breath, breathing fast, oxygen saturation below or equal to 93%, or lung infiltrates on CT scan covering more than half of the lungs. </p><p id="viewer-3vln1">Mortality: When looking at adults over age 40, the mortality rate was higher for deficient adults: 20% vs. 9.7%. </p><p id="viewer-d8kl7">Scatterplot from the study showing mortality risk.</p><div id="viewer-e4bei"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e" data-pin-media="https://static.wixstatic.com/media/3e0600_623993a79fef40719ab14eacbbc54380~mv2.png/v1/fit/w_1000,h_881,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_623993a79fef40719ab14eacbbc54380~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-9anh4"><em>Patients who had sufficient levels of Vitamin D had lower death rates than those with deficient Vitamin D. Note that low Vitamin D was not a death sentence - most people with low Vitamin D survived. [3]</em></p><p id="viewer-21b1t"><strong>Interesting to note:</strong> When comparing mortality, they excluded everyone under the age of 40. You can see on the graph that there were lots of young people with low Vitamin D levels who did not die. (No one under 40 died.) This was not described in the methods, which leads me to believe that it was done after the fact in order to find a statistically significant difference in mortality.</p><p id="viewer-bqd04"><span><strong>Conflict of interest alert: </strong></span>The senior author on the last two studies listed was Michael F Holick, MD. Holick has been a very vocal advocate of Vitamin D testing and supplementation. He also has extensive financial ties to the lab testing industry (Quest, as well as two companies that produce Vitamin D tests) and the pharmaceutical industry (multiple corporations that sell supplements and medications frequently prescribed with Vitamin D). He has even received money from the tanning industry. Liz Szabo wrote an <a href="https://www.nytimes.com/2018/08/18/business/vitamin-d-michael-holick.html" target="_blank" rel="noopener"><u>excellent article on Holick</u></a> that was published in the New York Times in 2018.</p><p id="viewer-f414g">Holick's level of association with these industries is concerning. It does not mean that the studies are wrong. But it definitely adds a possibility of bias in the data collection and interpretation.</p><p id="viewer-d24re"><strong>Conclusion:</strong> Ignoring the possible influence that Holick's conflicts of interest had on the study: this is a convincing association between Vitamin D deficiency and disease severity. It was not designed to show causation. It does provide a basis for further studies. </p><p id="viewer-ea8n4"><strong>4. Randomized controlled trial of Covid patients (Spain):<u> </u></strong><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7456194/" target="_blank" rel="noopener"><strong><u>Effect of calcifediol treatment and best available therapy versus best available therapy on intensive care unit admission and mortality among patients hospitalized for COVID-19: A pilot randomized clinical study. [4]</u></strong></a></p><p id="viewer-4v9n0"><strong>Question asked:</strong> Will giving Vitamin D to hospitalized Covid patients improve outcomes?</p><p id="viewer-5ei89"><strong>How the question was answered: </strong>76 Covid patients admitted to a single hospital in Spain were randomized to receive calcifediol with standard therapy vs. standard therapy alone. Calcifediol is Vitamin D 25-OH; it is converted to the active form of Vitamin D. It was given orally on hospitalization days 1, 3 and 7, then weekly. The outcomes reviewed were ICU admission and mortality. </p><p id="viewer-10lrb"><strong>Findings</strong></p><ul><li id="viewer-fu8rq"><p>ICU admission: Just one of the 50 patients (2%) receiving Vitamin D needed to be admitted to the ICU, while 13 of the 26 (50%!) of the patients not receiving Vitamin D were admitted to the ICU. </p></li><li id="viewer-9psdo"><p>Mortality: None of the 50 patients treated with Vitamin D died, while 2 of the 26 patients in the control group died.</p></li></ul><p id="viewer-dlu5i"><strong>Interesting to note:</strong> The patients were randomized, but the groups were small, and they ended up with several notable differences between the groups. Several comorbidities (other diseases that predispose someone to have more severe disease) were more common in the control group than in the Vitamin D treatment group: 19% vs. 6% for diabetes, and 58% vs 24% for hypertension. The control group also had a higher percentage of men. All of these factors could make the control group more likely to develop severe disease (whether Vitamin D had any effect or not). In addition, ICU admission was based partly on comorbidities, so the untreated group was already more likely to go to the ICU. </p><p id="viewer-7gn40"><strong>Another note:</strong> The authors did not look at BMI or the rate of obesity, which is now a well-known risk factor for Covid severity. Vitamin D levels were not measured, so we …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e">https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633248</guid>
            <pubDate>Tue, 29 Sep 2020 21:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fujitsu FM Towns Rescue Boot Loader Project]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24633036">thread link</a>) | @app4soft
<br/>
September 29, 2020 | http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html | <a href="https://web.archive.org/web/*/http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">





        
        
        <p>Let's say you have a almost-functioning FM TOWNS, but its internal 
		CD-ROM drive is dead, floppy-disk drive is dead, and CMOS battery is 
		gone.&nbsp; In that situation, all you could do was pretty much power it 
		up and watch boot-device cycles at the lower-right corner.</p>
<p>Until now.</p>
        
        <p>I have already released a SCSI CD-ROM driver,
		<a href="http://ysflight.in.coocan.jp/FM/towns/internalCDROM/YSSCSICD_E.html">YSSCSICD.SYS</a>.&nbsp; This 
		driver let Towns OS think SCSI-connected CD-ROM drive is an internal 
		drive.&nbsp; However, it had some problems.&nbsp; First, you need to 
		make separate boot disks for Towns OS V1.1 and V2.1.&nbsp; Or, even if 
		your game title is not directly accessing CD-ROM I/O, some of those 
		titles use a special driver or BIOS, in which case you needed a separate 
		boot disk for your game title.</p>
        
        <p>  The second problem is<!--webbot bot="HTMLMarkup" startspan -->
<!--webbot bot="HTMLMarkup" endspan i-checksum="53585" -->

		it doesn't help your FM TOWNS if internal floppy-disk drive is dead as 
		well.&nbsp; In that situation, possible boot devices left were SCSI hard 
		drive, or IC memory card.&nbsp; However, to boot Towns OS from a SCSI 
		hard drive, you need to assign a drive letter, but to assign a drive 
		letter you need to boot Towns OS.&nbsp; It's a same old chicken and egg 
		problem.&nbsp; IC memory card that can be accessed from FM TOWNS 
		virtually doesn't exist any more.</p><p>  The third problem is since it 
relies on a floppy disk, it is impossible to manufacture using Windows 10.&nbsp; 
Well, you could with an earlier version of Windows 10, but not any more.&nbsp; 
If you are able to format a 1232KB floppy disk, you may be able to do something, 
but to do so you need TOWNS.&nbsp; Again, it's a salmon and ikura problem.</p><p>  
On the other hand, <a href="http://ysflight.in.coocan.jp/FM/towns/Tsugaru/e.html">my FM TOWNS Emulator "Tsugaru"</a> 
is now able to emulate SCSI CD-ROM drive.&nbsp; I am able to develop and debug 
an IPL (Initial Program Loader) and boot loader in Tsugaru.</p><p>  So I started FM 
TOWNS Rescue Boot Loader project.&nbsp; TOWNS reads and executes the IPL sector 
of a hard drive regardless of the drive-letter assignment.&nbsp; Therefore, 
theoretically it should be possible to write an IPL that loads IO.SYS from 
external SCSI CD-ROM drive, intercept before it hands off the control to 
MSDOS.SYS, install BIOS redirector, and continue the rest of the boot process.&nbsp; 
Then, TOWNS will think an external SCSI CD-ROM drive is the internal drive.&nbsp; 
Since it installs the BIOS redirector much earlier than CONFIG.SYS, it won't 
require separate disk for different versions of TownsOS.</p><h2>Updates</h2>
<h3>2020/10/02</h3>
<ul>
	<li>Hard-disk image is available.</li>
	<li>CDIMAGE and HDIMAGE both boot into a boot menu in which you can 
	configure drive-letter assignment, not just boot an app from a SCSI CD 
	drive.</li>
	<li>FDIMAGE does the same if you boot without inserting a CD in the SCSI CD 
	drive.</li>
	<li>Added 10ms delay in direct SCSI-command PROC to prevent break down in 
	the Pentium models.</li>
	<li>Not an update, but apparently TOWNS SYSROM mistakes a SCSI CD drive as a 
	MO drive and issues a READ10 command.&nbsp; Lucky mistake!&nbsp; "FM TOWNS 
	SYSTEM SETUP GUIDE" tells that all TOWNS models except 1st, 2nd, and 3rd 
	generations (2/2F/20F) can boot directly from a MO drive.&nbsp; Therefore, I 
	believe all other TOWNS are bootable from the CDIMAGE and CD Boot Sector.</li>
</ul>
<h3>2020/09/30</h3>
<ul>
	<li>Got a report that it doesn't work on FM TOWNS HC (Pentium model).&nbsp; 
	I experimentally added delay before issuing a SCSI command.</li>
	<li>By upgrading YSSCSICD.SYS, it uses DMA to read data directly to physical 
	address on INT 93H AX=05C0H CH=FFH.</li>
</ul>
<h3>2020/09/29</h3>
<ul>
	<li>CD Boot Sector now supports both internal CD and SCSI CD drives.&nbsp; 
	You don't have to keep two separate discs for internal CD and SCSI CD.</li>
</ul>
<h3>  
2020/09/28</h3>
<ul>
	<li>Added invitation to Demosplash 2020 in the Boot Loader message.&nbsp; 
	Please join us at Demosplash 2020 (and 2021, 2022, ...)&nbsp;
	<a href="http://www.demosplash.org/">http://www.demosplash.org</a> </li>
	<li>Release CD Boot Loader</li>
	<li>Release CD Boot Sector</li>
</ul>
<h3>2020/09/26</h3>
<ul>
	<li>Release FD Boot Loader</li>
</ul>
<h2>What You Need</h2>
<ul>
	<li>A almost-functioning FM TOWNS (of course)</li>
	<li>A SCSI CD-ROM drive (CD-R should work too)</li>
	<li>Cable for connecting FM TOWNS and SCSI CD drive.</li>
</ul>
<p>Now I don't think new SCSI CD drive exists any more, but still you can get 
one from eBay.&nbsp; Good luck!</p>
<h2>CD Boot Loader</h2>
<p>A ground-breaking discovery.&nbsp; FM TOWNS II MX and FM TOWNS II HR's system 
ROM read IPL sector from a SCSI CD drive and jump to IPL.&nbsp; TOWNS 2F didn't.&nbsp; 
My guess is TOWNS II CX and newer models models' system ROM reads IPL from SCSI 
CD drive.&nbsp; On the emulator I confirmed with MX ROM, and actual HR did the 
same.</p>
<p>Therefore, if I write an IPL, I can start a program from SCSI CD-ROM drive 
directly without relying on a floppy disk.</p>
<p>So I did it.&nbsp; How to use is extremely easy.&nbsp; Download the ISO image 
from the following URL and burn to a CD-R.</p>
<p>
<a href="https://github.com/captainys/FM/tree/master/TOWNS/IPL/DISKIMG">https://github.com/captainys/FM/tree/master/TOWNS/IPL/DISKIMG</a></p>
<p>Start your TOWNS II with this CD-R in the SCSI CD drive.&nbsp; You will be 
prompted to change the disc to the one you want to boot and press a button on 
game pad or mouse.&nbsp; If you follow the instruction, your app will start from 
the SCSI CD drive.</p>
<p>There are some limitations:</p>
<ul>
	<li>Some CD drives spin up very slowly, in which case the drive may not be 
	ready before the boot-device cycle reaches the drive.&nbsp; But, it should 
	be recognized in the second cycle.&nbsp; It happens in my TOWNS HR.&nbsp; 
	Well, it happened in my HR, but for some reason it started waiting long time 
	for HD0 since this morning, and therefore it finds my boot loader in SCSI ID 
	3 in the first cycle.&nbsp; I don't know what changed this guy's mind.</li>
	<li>Due to the reason above, make sure to unplug other hard drives and keep 
	floppy-drive empty, or TOWNS will try to boot from whatever boot media found 
	first.&nbsp; (And may fail if CMOS is gone.)</li>
	<li>TOWNS' system ROM apparently only checks SCSI ID from 0 to 4.&nbsp; So, 
	make sure to configure your CD drive to one of four numbers.</li>
	<li>This CD image is confirmed with HR.&nbsp; MX system ROM also seems to be 
	able to recognize it.&nbsp; But, I can set up only one TOWNS at a time due 
	to space limitation.&nbsp; I haven't had chance to test with actual MX.&nbsp; 
	But, 2F ROM is confirmed NOT work.&nbsp; Probably this ISO image is good for 
	TOWNS II models, but not sure.&nbsp; I appreciate if you report successes.</li>
</ul>
<h2>CD Boot Sector</h2>
<p>Actually, you can make a Towns OS directly boot from the SCSI CD drive.&nbsp; 
It's extremely easy.&nbsp; Make an ISO image of the Towns OS disc (can be system 
software or any game), and overwrite the first 6KB with the following binary:</p>
<p><a href="https://github.com/captainys/FM/tree/master/TOWNS/IPL/BOOTSECT">
https://github.com/captainys/FM/tree/master/TOWNS/IPL/BOOTSECT</a></p>
<p>You can just open a .ISO file in a binary editor and overwrite first part 
with this boot sector.&nbsp; In CUE/BIN format, if the data track sector length 
is 2048, you can do the same for BIN file.&nbsp; If the sector length is not 
2048, there are gaps between sector data, and you need to skip those gaps.&nbsp; 
I don't know if there is such a tool.&nbsp; I might write one if there is a 
demand.</p>
<p>Due to some resource issues, I could confirm only Towns System Software 
V2.1L31 on my TOWNS II HR, but on the emulator, it seems to work with majority 
of Towns OS apps as long as it is not directly beating CD-ROM I/O.&nbsp; (Same 
limitation as YSSCSICD.SYS)&nbsp;</p>
<h2>Floppy-Disk Boot Loader</h2>
<p>Floppy-Disk Boot Loader does not solver the problem of floppy-disk 
dependency.&nbsp; However, it at least solves a problem: YSSCSICD.SYS approach 
needed separate disks for Towns OS V1.1 and V2.1.&nbsp; If you have a 
functioning FM TOWNS unit, maybe it's a good idea to make one for the doomsday 
when its CD/FD drives are gone.</p>
<p>In addition to "What You Need", you need at least one floppy disk.</p>
<p>I have confirmed the following image successfully starting Towns OS from 
external CD-ROM drive with FM Towns II MX and II HR.&nbsp; Download FDIMAGE.BIN 
or FDMINI.BIN and write to 1232KB-format floppy disk.</p>
<p>  
        <a href="https://github.com/captainys/FM/tree/master/TOWNS/IPL/DISKIMG">
		https://github.com/captainys/FM/tree/master/TOWNS/IPL/DISKIMG</a></p>
<p>  
        The boot loader uses first 160KB (I reserve 160KB just in case.&nbsp; It 
		is actually using much less.)&nbsp; You can write first 160KB using 
		FDMINI.BIN or entire disk with FDIMAGE.BIN.</p>
<p>  
        Now it is difficult to find a floppy disk without bad sectors.&nbsp; 
		Even in that case, you only need first 160KB.&nbsp; If you have a floppy 
		disk with a bad sector in the middle, you can still recycle it for 
		emergency-boot disk.&nbsp; This boot loader is environmentally friendly.</p>
<p>Once you have a disk, connect your SCSI-CD drive, put Towns OS V1.1 or V2.1 
system disk (or whatever game you have) in the SCSI-CD drive, insert the boot 
floppy disk in drive A or B, and power on.&nbsp; After a while, it boots from 
external SCSI-CD drive.</p>
<p>Well, it's getting more and more difficult to manufacture a 1232KB-format 
floppy disk.&nbsp; But, if you have a working TOWNS, you can format in Towns OS, 
and then use the following command-line tool to write a disk image.</p>
<p>  
        <a href="https://github.com/captainys/FM/tree/master/TOWNS/FDWRITE/EXE">
		https://github.com/captainys/FM/tree/master/TOWNS/FDWRITE/EXE</a></p>
<p>  
        You need to format your floppy disk in 1232KB format with Towns OS or 
		DOS.&nbsp; Then, go into Towns OS Command Mode, and type like:</p>
<p>RUN386 -nocrt FDWRITE.EXP A: FDMINI.BIN</p>
<p>It won't confirm before write.&nbsp; Be careful not to overwrite your 
important floppy disk.</p>
<p>You can see how it goes using my <a href="http://ysflight.in.coocan.jp/FM/towns/Tsugaru/e.html">FM TOWNS 
Emulator "Tsugaru"</a>.&nbsp; Tsugaru GUI is not supporting this, but from CUI, 
you can type like:</p>
<p>.\Tsugaru_CUI.exe ROM_MX -SCSICD5 
TownsOSV2.1L20.cue -FD0 FDIMAGE.BIN</p>
<p>to see how this boot loader starts from SCSI-CD drive.</p>
<h2>SCSI Hard Disk Boot Loader</h2>
<p>Let's say your TOWNS has bad floppy-disk drives.&nbsp; None of drive A nor B 
reads a disk.&nbsp; Or, it can be like your TOWNS has a dead CD drive and cannot 
start Towns OS.&nbsp; You don't have a spare TOWNS in working condition.&nbsp; 
And you upgraded your Windows 10 and you can no longer format a floppy disk in 
1232KB format.&nbsp; (Good job, Microsoft!)&nbsp; Or, you may have ended up with 
getting a SCSI CD drive that cannot be configured to SCSI ID between 0 and 4.&nbsp; 
I have seen many portable CD drives that could only be configured to SCSI ID 5 
and 6.&nbsp; In that case, SCSI CD boot image and boot sector don't help.</p>
<p>Now, you can use an emulator, such as UNZ or Tsugaru to make a bootable 
hard-disk image for Towns.&nbsp; You can bring it to the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html">http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html</a></em></p>]]>
            </description>
            <link>http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633036</guid>
            <pubDate>Tue, 29 Sep 2020 21:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD on the Desktop (Part II)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633030">thread link</a>) | @upofadown
<br/>
September 29, 2020 | https://paedubucher.ch/articles/2020-09-12-openbsd-on-the-desktop-part-ii.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-12-openbsd-on-the-desktop-part-ii.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A week ago, I've installed <a href="https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">OpenBSD on my
Thinkpad</a>.
I've been using it now and then, and already have changed a couple of things in
respect to the original setup described in the article. I also installed OpenBSD
on the Dell Optiplex on which I <a href="https://paedubucher.ch/articles/2020-08-11-freebsd-on-the-desktop.html">previously installed
FreeBSD</a>
a month before. This means that I'm no longer using FreeBSD on the desktop, at
least not for the moment. However, FreeBSD is running on a disk station I built
earlier this summer. Maybe I'll describe that particular setup (using ZFS) in a
later article.</p>
<p>Except for that storage server, I'd like to use OpenBSD for most of my private
computing. In this article, I describe some GUI tweaks and additional setup
tasks I perfmormed in order to feel more at home on my OpenBSD machines. Some of
the tasks performed are <em>not</em> specific to OpenBSD, but could also be applied to
a Linux setup.</p>

<p><code>sudo</code> originally came from the OpenBSD community. It is almost as widely used
in the Unix world as SSH, which is the most prominent OpenBSD project.  However,
<code>sudo</code> became bigger and harder to configure. Therefore, Ted Unangst came up
with a simpler alternative called <code>doas</code>, which stands for <em>Dedicated OpenBSD
Application Subexecutor</em>. <code>doas</code> is less powerful than <code>sudo</code>, but much smaller,
easier to configure, and, thus, more secure. The full rationale can be read in
<a href="https://flak.tedunangst.com/post/doas">Ted Unangst's Blog</a>.</p>
<p>A basic <code>doas</code> setup requires to login as root for one last time. The
configuration shall be kept extremely simple. I'd like to permit all users from
the <code>wheel</code> group (which is just me on my computers) to use <code>doas</code> without
entering the password every time but only once when executing a command that
requires <code>root</code> permissions. This is only a single line in <code>/etc/doas.conf</code>:</p>
<pre><code>permit persist :wheel
</code></pre>
<p>Let's check this setup by logging in as a user of the wheel group and trying to
update the packages:</p>
<pre><code>$ doas pkg_add -u
</code></pre>
<p>This works, so bye bye <code>root</code> account.</p>

<p>By default, <code>dwm</code>, <code>dmenu</code>, and <code>st</code> use a monospace font of size 10, or
pixelsize 12, respectively, which is hard to read on a screen with a high
resolution. On Linux, I use the the TrueType font DejaVu Sans Mono. For OpenBSD,
I'd rather use something more minimalistic: the <a href="http://terminus-font.sourceforge.net/">Terminus bitmap
font</a>.</p>
<p>As <code>pkg_info -Q terminus</code> shows, this font comes in different versions. I prefer
the version with the centered tilde, which I install:</p>
<pre><code>$ doas pkg_add terminus-font-4.47p0-centered_tilde
</code></pre>
<p>Let's reconfigure <code>st</code> first, for testing changes doesn't require a restart of
the window manager. I stored my suckless sources in <code>~/suckless</code>, so the
font for <code>st</code> can be configured in <code>~/suckless/config.h</code>. I replace the existing
font configuration</p>
<pre><code>static char *font = "Liberation Mono:pixelsize=12:antialias=true:autohint=true";
</code></pre>
<p>with</p>
<pre><code>static char *font = "Terminus:pixelsize=24";
</code></pre>
<p>The options <code>antialias</code> and <code>autohinting</code> are not needed for a bitmap font, so I
left them away. 24 pixels is rather big, but my screen is big enough to show two
text editors with more than 80 characters per line next to each other, so let's
keep it this way. I rebuild and reinstall <code>st</code>, then switch to <code>dwm</code>:</p>
<pre><code>$ doas make install
$ cd ../dwm
</code></pre>
<p>The font configuration in the <code>config.h</code> file looks a bit different here:</p>
<pre><code>static const char *fonts =      { "monospace:size=10" };
static const char dmenufont =   "monospace:size=10";
</code></pre>
<p>Let's just use the same font as for <code>st</code> here:</p>
<pre><code>static const char *fonts =      { "Terminus:pixelsize=24" };
static const char dmenufont =   "Terminus:pixelsize=24";
</code></pre>
<p>Note that I'm using <code>pixelsize</code> instead of <code>size</code> here. (24pt would be much
bigger than 24px.) Then I rebuild and reinstall <code>dwm</code>.</p>
<pre><code># make install
</code></pre>
<p>This configuration appllies also to <code>dmenu</code> and <code>slstatus</code>, so we're done with
the fonts.</p>

<p>By default, the desktop background is a pattern of black and grey dots, which is
a strain to the eye. Even though I rarely look at an empty desktop for long, I'd
rather change this to a solid color. This can be done by adding a command to
<code>~/.xinitrc</code>:</p>
<pre><code>xsetroot -solid black
</code></pre>
<p>Right before <code>dwm</code> is executed.</p>

<p>Even though SSH is almost ubiquitous nowadays, a USB flash drive is still useful
when it comes to exchanging data between computers, especially if Windows is
involved, or if the network does not allow SSH.</p>
<p>Block storage devices are accessible through the device nodes <code>/dev/sd*</code>,
whereas <code>*</code> stands for the number of the disk. The disks can be listed as
follows:</p>
<pre><code>$ sysctl hw.disknames
hw.disknames=sd0:ef0268c97ae7a246
</code></pre>
<p>Only <code>sd0</code> is active, even though I already plugged in my USB dongle. However,
the system already figured out that there is a second disk:</p>
<pre><code>$ sysctl hw.diskcount
hw.diskcount=2
</code></pre>
<p>The next free disk would have the name <code>sd1</code>. The device nodes can be created by
running the <code>MAKEDV</code> script in <code>/dev</code>:</p>
<pre><code>$ cd /dev
$ doas sh MAKEDEV sd1
</code></pre>
<p>Let's initialize a new MBR partition schema on <code>sd1</code>:</p>
<pre><code>$ doas fdisk -iy sd1
</code></pre>
<p>The new disk layout can be checked using <code>disklabel</code>:</p>
<pre><code>$ doas disklabel sd1
# /dev/rsd1c
...
</code></pre>
<p>The first line of the output tells us that there's a partition under
<code>/dev/rsd1c</code>. (The <code>r</code> refers to «raw», as opposed to «block».) The partition
can be formatted using <code>newfs</code> by referring to that partition name:</p>
<pre><code>$ doas newfs sd1c
</code></pre>
<p>This creates a default FFS (Fast File System) partition, which is useful to
exchange data between BSD operating systems. The formatted partition is then
ready to be mounted:</p>
<pre><code>$ doas mount /dev/sd1c /mnt
</code></pre>
<h2>Other Partition Types</h2>
<p>Other partition types are available under other utilities.</p>
<h3>FAT32</h3>
<p>The following command creates a FAT32 partition:</p>
<pre><code>$ doas newfs_msdos -F 32 sd1c
</code></pre>
<p>The <code>-F 32</code> parameter specifies FAT32 (as opposed to FAT16 or FAT8). To mount
the partition, use the according <code>mount</code> command:</p>
<pre><code>$ doas mount_msdos /dev/sd1c /mnt
</code></pre>
<h3>EXT2</h3>
<p>In order to create an <code>ext2fs</code> file system, the partition type needs to be
specified accordingly. First, you might consider a GPT partition schema instead
of MBR (additional <code>-g</code> parameter):</p>
<pre><code>$ doas fdisk -igy sd1
</code></pre>
<p>Then use <code>disklabel</code> interactively to define a new partition:</p>
<pre><code>$ doas disklabel -E sd1
</code></pre>
<p>First, delete all the partitions with <code>z</code>. Then, create a new partition with
<code>a</code>, and make sure to specify the type as <code>ext2fs</code> instead of the default
<code>4.2BSD</code>. Notice that the new partition has a different letter (say, <code>a</code>), so
you need to use <code>sd1a</code> instead of <code>sd1c</code> for the next steps. Write the changes
by typing <code>w</code>, then exit with <code>q</code>. Now you can format and mount the partition:</p>
<pre><code>$ doas newfs_ext2fs sd1a
$ doas mount_ext2fs /dev/sd1a /mnt
</code></pre>

<p>In order to access my GitHub repositories, I first create a new SSH key:</p>
<pre><code>$ ssh-keygen -t rsa -b 4096
</code></pre>
<p>Since I manage my passwords with <code>pass</code> (of which more later), I don't know most
of them by heart. So I can't just login to GitHub and add my public key.
Therefore, I copy my public key to my laptop, on which I'm already logged in to
GitHub.</p>
<p>This can be either done using <code>scp</code>, for which <code>sshd</code> has to be running on my
laptop (which currently has the IP <code>192.168.178.53</code>):</p>
<pre><code>$ scp ~/.ssh/id_rsa.pub 192.168.178.53:/home/patrick
</code></pre>
<p>Or using the USB flash drive formatted with <code>ext2</code> from before:</p>
<pre><code>$ doas newfs_ext2fs -I sd1a
$ doas mount_ext2fs /dev/sd1a /mnt
$ doas cp ~/.ssh/id_rsa.pub /mnt/
</code></pre>
<p>Then <code>id_rsa.pub</code> can be copied into the according <a href="https://github.com/settings/ssh/new">GitHub Settings
Page</a>, after which cloning GitHub
repositories should work on the OpenBSD machine:</p>
<pre><code>$ git clone git@github.com:patrickbucher/conf
</code></pre>

<p>My passwords are encrypted using GPG. To encrypt them, I need to copy my private
key from my other machine. First, I list my private keys:</p>
<pre><code>$ gpg --list-keys --keyid-format SHORT
pub   rsa2048/73CE6620 2016-11-11 [SC]
      22F91EE20D641CBCF5B8678E82B7FE3A73CE6620
uid         [ultimate] Patrick Bucher &lt;patrick.bucher@mailbox.org&gt;
sub   rsa2048/AF6246E3 2016-11-11 [E]
</code></pre>
<p>Then I export both public and private key to an according file using the armored
key format:</p>
<pre><code>$ gpg --export --armor 73CE6620 &gt; public.key
$ gpg --export-secret-key --armor 73CE6620 &gt; private.key
</code></pre>
<p>The two key files can be copied via SSH or the USB flash disk again, which I
won't show here.</p>
<p>Back on my OpenBSD machine, I need to install GnuPG first, because OpenBSD only
has <code>signify</code> installed by default:</p>
<pre><code>$ doas pkg_add gnupg
</code></pre>
<p>I pick the 2.2 version. Now I can import my keys:</p>
<pre><code>$ gpg2 --import private.key
$ gpg2 --import public.key
</code></pre>
<p>The key is not trusted so far, so I need to change that:</p>
<pre><code>$ gpg2 --edit-key 73CE6620
&gt; trust
&gt; 5
&gt; y
&gt; quit
</code></pre>
<p>5 stands for ultimate trust, which seems appropriate.</p>

<p>I use <code>pass</code> as a password manager, which can be installed as the
<code>password_store</code> package in OpenBSD:</p>
<pre><code>$ doas pkg_add password-store
</code></pre>
<p>Now that I have both my GPG private key and a working SSH key for GitHub, I can
clone my passwords stored on a private GitHub repository:</p>
<pre><code>$ git clone git@github.com:patrickbucher/pass .password-store
</code></pre>
<p>Now I can copy my GitHub password to the clipboard as follows:</p>
<pre><code>$ pass -c github
</code></pre>

<p>I use a lot of aliases, such as <code>gcl</code> as a shortcut for <code>git clone</code>, and <code>gad</code>
for <code>git add</code>, etc. Since OpenBSD uses a Public Domain Korn Shell by default,
the <code>.bashrc</code> configuration from my Linux machines won't work here, unless I
switch to <code>bash</code>, which is not exactly the point of using OpenBSD.</p>
<p>I define my aliases in <code>~/.kshrc</code> (excerpt):</p>
<pre><code>alias gcl='git clone'
alias gad='git add'
</code></pre>
<p>In order to load those settings, an according <code>ENV</code> parameter needs to be
defined in <code>~/.profile</code> (see <code>man 1 ksh</code> for details):</p>
<pre><code>export ENV=$HOME/.kshrc
</code></pre>
<p>After the next login, <code>~/.profile</code> is reloaded, and the aliases are ready to be
used.</p>

<p>Not only is my enhanced setup now ready to do some serious work, but I also
increased my understanding of some OpenBSD subjects. There are still things to
be improved and to be understood, but my setup is now good enough so that I no
longer need a Linux machine running next to it. I'm looking forward to use and
learn about OpenBSD in the time to come. I'll write additional articles on the
subject as soon as I have enough subject material ready.</p></div></div>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-12-openbsd-on-the-desktop-part-ii.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633030</guid>
            <pubDate>Tue, 29 Sep 2020 21:10:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error handling under Unix and Windows: A retrospective and outlook]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632979">thread link</a>) | @DSpinellis
<br/>
September 29, 2020 | https://www.spinellis.gr/blog/20200929/ | <a href="https://web.archive.org/web/*/https://www.spinellis.gr/blog/20200929/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <!-- Left content -->
  <p>One thing that struck me when I first encountered the 4.3BSD Unix system call documentation in the 1980s, was that each call was followed by an exhaustive list of the errors associated with it. Ten years later, when I was going through the Windows API, I was disappointed to see that very few functions documented their error conditions. This is a big deal.</p>
<p>Consider as an example how the <em>open</em> function can fail. The <a href="https://github.com/dspinellis/unix-history-repo/blob/BSD-4_3/usr/man/man2/open.2#L86">4.3BSD manual page</a> documents 23 possible error conditions. Here is the complete list.</p>
<ul>
<li><strong>[ENOTDIR]</strong> A component of the path prefix is not a directory.</li>
<li><strong>[EINVAL]</strong> The pathname contains a character with the high-order bit set.</li>
<li><strong>[ENAMETOOLONG]</strong> A component of a pathname exceeded 255 characters, or an entire path name exceeded 1023 characters.</li>
<li><strong>[ENOENT]</strong> O_CREAT is not set and the named file does not exist.</li>
<li><strong>[ENOENT]</strong> A component of the path name that must exist does not exist.</li>
<li><strong>[EACCES]</strong> Search permission is denied for a component of the path prefix.</li>
<li><strong>[EACCES]</strong> The required permissions (for reading and/or writing) are denied for the named flag.</li>
<li><strong>[EACCES]</strong> O_CREAT is specified, the file does not exist, and the directory in which it is to be created does not permit writing.</li>
<li><strong>[ELOOP]</strong> Too many symbolic links were encountered in translating the pathname.</li>
<li><strong>[EISDIR]</strong> The named file is a directory, and the arguments specify it is to be opened for writting.</li>
<li><strong>[EROFS]</strong> The named file resides on a read-only file system, and the file is to be modified.</li>
<li><strong>[EMFILE]</strong> The system limit for open file descriptors per process has already been reached.</li>
<li><strong>[ENFILE]</strong> The system file table is full.</li>
<li><strong>[ENXIO]</strong> The named file is a character special or block special file, and the device associated with this special file does not exist.</li>
<li><strong>[ENOSPC]</strong> O_CREAT is specified, the file does not exist, and the directory in which the entry for the new file is being placed cannot be extended because there is no space left on the file system containing the directory.</li>
<li><strong>[ENOSPC]</strong> O_CREAT is specified, the file does not exist, and there are no free inodes on the file system on which the file is being created.</li>
<li><strong>[EDQUOT]</strong> O_CREAT is specified, the file does not exist, and the directory in which the entry for the new fie is being placed cannot be extended because the user's quota of disk blocks on the file system containing the directory has been exhausted.</li>
<li><strong>[EDQUOT]</strong> O_CREAT is specified, the file does not exist, and the user's quota of inodes on the file system on which the file is being created has been exhausted.</li>
<li><strong>[EIO]</strong> An I/O error occurred while making the directory entry or allocating the inode for O_CREAT.</li>
<li><strong>[ETXTBSY]</strong> The file is a pure procedure (shared text) file that is being executed and the open call requests write access.</li>
<li><strong>[EFAULT]</strong> Path points outside the process's allocated address space.</li>
<li><strong>[EEXIST]</strong> O_CREAT and O_EXCL were specified and the file exists.</li>
<li><strong>[EOPNOTSUPP]</strong> An attempt was made to open a socket (not currently implemented).</li>
</ul>
<p>This list allows programmers to judge which errors are likely to occur in a given situation, which can be handled, and what to do about the rest. Modern FreeBSD expands this list to <a href="https://www.freebsd.org/cgi/man.cgi?query=open&amp;apropos=0&amp;sektion=2&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">40 documented errors</a>, while the Debian distribution of GNU/Linux <a href="https://www.freebsd.org/cgi/man.cgi?query=open&amp;apropos=0&amp;sektion=2&amp;manpath=Debian+8.1.0&amp;arch=default&amp;format=html">documents 32</a>.</p>
<p>In contrast, the <a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-openfile">documentation</a> of the Windows <em>OpenFile</em> function only specifies that "If the function fails, the return value is HFILE_ERROR. To get extended error information, call GetLastError.", which can return any of about <a href="https://docs.microsoft.com/en-us/windows/win32/debug/system-error-codes">6000 error codes</a>. As this information is returned at runtime, the main way programmers can find out which errors they need to handle in order to make their programs more resilient is by painful trial and error.</p>
<p>I first identified this problem in an article I wrote in 1997, titled <a href="https://www.spinellis.gr/pubs/jrnl/1997-CSI-WinApi/html/win.html">A Critique of the Windows Application Programming Interface</a>. At that time the possible error codes were 1130. As exemplified by the <a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-openfile">documentation</a> of the Windows <em>OpenFile</em> function, things have not improved much in the past quarter century. Yet, there is a glimmer of hope. As I was reading the <a href="https://docs.microsoft.com/en-us/windows/win32/api/winreg/nf-winreg-regqueryvalueexa">documentation</a> of the <em>RegQueryValueExA</em> function, I was struck that it actually documented the reasons it could fail.</p>
<ul>
<li>If the lpData buffer is too small to receive the data, the function returns ERROR_MORE_DATA.</li>
<li>If the lpValueName registry value does not exist, the function returns ERROR_FILE_NOT_FOUND.</li>
</ul>
<p>Excitedly, I installed the 1999 MSDN Library documentation to see how it was documented back then. The error conditions were indeed missing: "ERROR_SUCCESS indicates success. A nonzero error code defined in Winerror.h indicates failure. To get a generic description of the error, call FormatMessage with the FORMAT_MESSAGE_FROM_SYSTEM flag set." Although the error behavior of thousands of Windows functions must still be properly specified, adding such documentation a move in the right direction. After all the <a href="https://s3.amazonaws.com/plan9-bell-labs/7thEdMan/v7vol1.pdf">1979 Seventh Research Edition Unix manual</a> also lacked detailed system call error documentation, lamely arguing that "The possible error numbers are not recited with each writeup in section 2, since many errors are possible for most of the calls." This was fixed a few years later, and we're still enjoying the fruits of that labor.</p>

<p>
<!-- COMMENTS --> <a href="https://www.spinellis.gr/cgi-bin/comment.pl?date=20200929#comments">Read and post comments</a>, or share through&nbsp;&nbsp;&nbsp;
<!-- Go to www.addthis.com/dashboard to customize your tools -->
</p>

</div></div>]]>
            </description>
            <link>https://www.spinellis.gr/blog/20200929/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632979</guid>
            <pubDate>Tue, 29 Sep 2020 21:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disinformation Demystified]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24632586">thread link</a>) | @animationwill
<br/>
September 29, 2020 | https://icyphox.sh/blog/disinfo/ | <a href="https://web.archive.org/web/*/https://icyphox.sh/blog/disinfo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
            <h2>Misinformation, but deliberate</h2>
            <p>As with the disambiguation of any word, let’s start with its etymology and definiton.
According to <a href="https://en.wikipedia.org/wiki/Disinformation">Wikipedia</a>,
<em>disinformation</em> has been borrowed from the Russian word — <em>dezinformatisya</em> (дезинформа́ция),
derived from the title of a KGB black propaganda department.</p>

<blockquote>
  <p>Disinformation is false information spread deliberately to deceive.</p>
</blockquote>

<p>To fully understand disinformation, especially in the modern age, we need to understand the
key factors of any successful disinformation operation:</p>

<ul>
<li>creating disinformation (what)</li>
<li>the motivation behind the op, or its end goal (why)</li>
<li>the medium used to disperse the falsified information (how)</li>
<li>the actor (who)</li>
</ul>

<p>At the end, we’ll also look at how you can use disinformation techniques to maintain OPSEC.</p>

<p>In order to break monotony, I will also be using the terms “information operation”, or the shortened
forms—“info op” &amp; “disinfo”.</p>

<h2 id="creating-disinformation">Creating disinformation</h2>

<p>Crafting or creating disinformation is by no means a trivial task. Often, the quality
of any disinformation sample is a huge indicator of the level of sophistication of the
actor involved, i.e. is it a 12 year old troll or a nation state?</p>

<p>Well crafted disinformation always has one primary characteristic — “plausibility”.
The disinfo must sound reasonable. It must induce the notion it’s <em>likely</em> true. 
To achieve this, the target — be it an individual, a specific demographic or an entire
nation — must be well researched. A deep understanding of the target’s culture, history,
geography and psychology is required. It also needs circumstantial and situational awareness,
of the target.</p>

<p>There are many forms of disinformation. A few common ones are staged videos / photographs, 
recontextualized videos / photographs, blog posts, news articles &amp; most recently — deepfakes.</p>

<p>Here’s a tweet from <a href="https://twitter.com/thegrugq">the grugq</a>, showing a case of recontextualized
imagery:</p>

<blockquote data-dnt="true" data-theme="dark" data-link-color="#00ffff">
<div lang="en" dir="ltr"><p>Disinformation.
</p><p>
The content of the photo is not fake. The reality of what it captured is fake. The context it’s placed in is fake. The picture itself is 100% authentic. Everything, except the photo itself, is fake.
</p><p>Recontextualisation as threat vector. 
<a href="https://t.co/Pko3f0xkXC">pic.twitter.com/Pko3f0xkXC</a></p></div>— thaddeus e. grugq (@thegrugq) 
<a href="https://twitter.com/thegrugq/status/1142759819020890113?ref_src=twsrc%5Etfw">June 23, 2019</a>
</blockquote>

 

<h2 id="motivations-behind-an-information-operation">Motivations behind an information operation</h2>

<p>I like to broadly categorize any info op as either proactive or reactive. 
Proactively, disinformation is spread with the desire to influence the target
either before or during the occurence of an event. This is especially observed
during elections.<sup id="fnref-1"><a href="#fn-1">1</a></sup>
In offensive information operations, the target’s psychological state can be affected by
spreading <strong>fear, uncertainty &amp; doubt</strong>, or FUD for short.</p>

<p>Reactive disinformation is when the actor, usually a nation state in this case,
screws up and wants to cover their tracks. A fitting example of this is the case
of Malaysian Airlines Flight 17 (MH17), which was shot down while flying over 
eastern Ukraine. This tragic incident has been attributed to Russian-backed 
separatists.<sup id="fnref-2"><a href="#fn-2">2</a></sup> 
Russian media is known to have desseminated a number of alternative &amp; some even
conspiratorial theories<sup id="fnref-3"><a href="#fn-3">3</a></sup>, in response. The number grew as the JIT’s (Dutch-lead Joint
Investigation Team) investigations pointed towards the separatists. 
The idea was to <strong>muddle the information</strong> space with these theories, and as a result,
potentially correct information takes a credibility hit.</p>

<p>Another motive for an info op is to <strong>control the narrative</strong>. This is often seen in use
in totalitarian regimes; when the government decides what the media portrays to the
masses. The ongoing Hong Kong protests is a good example.<sup id="fnref-4"><a href="#fn-4">4</a></sup> According to <a href="https://www.npr.org/2019/08/14/751039100/china-state-media-present-distorted-version-of-hong-kong-protests">NPR</a>:</p>

<blockquote>
  <p>Official state media pin the blame for protests on the “black hand” of foreign interference, 
  namely from the United States, and what they have called criminal Hong Kong thugs.
  A popular conspiracy theory posits the CIA incited and funded the Hong Kong protesters, 
  who are demanding an end to an extradition bill with China and the ability to elect their own leader.
  Fueling this theory, China Daily, a state newspaper geared toward a younger, more cosmopolitan audience, 
  this week linked to a video purportedly showing Hong Kong protesters using American-made grenade launchers to combat police.
  …</p>
</blockquote>



<p>As seen in the above example of totalitarian governments, national TV and newspaper agencies
play a key role in influence ops en masse. It guarantees outreach due to the channel/paper’s
popularity.</p>

<p>Twitter is another, obvious example. Due to the ease of creating accounts and the ability to
generate activity programmatically via the API, Twitter bots are the go-to choice today for 
info ops. Essentially, an actor attempts to create “discussions” amongst “users” (read: bots),
to push their narrative(s). Twitter also provides analytics for every tweet, enabling actors to
get realtime insights into what sticks and what doesn’t.
The use of Twitter was seen during the previously discussed MH17 case, where Russia employed its troll
factory — the <a href="https://en.wikipedia.org/wiki/Internet_Research_Agency">Internet Research Agency</a> (IRA)
to create discussions about alternative theories.</p>

<p>In India, disinformation is often spread via YouTube, WhatsApp and Facebook. Political parties
actively invest in creating group chats to spread political messages and memes. These parties
have volunteers whose sole job is to sit and forward messages.
Apart from political propaganda, WhatsApp finds itself as a medium of fake news. In most cases,
this is disinformation without a motive, or the motive is hard to determine simply because
the source is impossible to trace, lost in forwards.<sup id="fnref-5"><a href="#fn-5">5</a></sup>
This is a difficult problem to combat, especially given the nature of the target audience.</p>

<h2 id="the-actors-behind-disinfo-campaigns">The actors behind disinfo campaigns</h2>

<p>I doubt this requires further elaboration, but in short:</p>

<ul>
<li>nation states and their intelligence agencies</li>
<li>governments, political parties</li>
<li>other non/quasi-governmental groups</li>
<li>trolls</li>
</ul>

<p>This essentially sums up the what, why, how and who of disinformation. </p>

<h2 id="personal-opsec">Personal OPSEC</h2>

<p>This is a fun one. Now, it’s common knowledge that
<strong>STFU is the best policy</strong>. But sometimes, this might not be possible, because
afterall inactivity leads to suspicion, and suspicion leads to scrutiny. Which might
lead to your OPSEC being compromised.
So if you really have to, you can feign activity using disinformation. For example,
pick a place, and throw in subtle details pertaining to the weather, local events
or regional politics of that place into your disinfo. Assuming this is Twitter, you can
tweet stuff like:</p>

<ul>
<li>“Ugh, when will this hot streak end?!”</li>
<li>“Traffic wonky because of the Mardi Gras parade.”</li>
<li>“Woah, XYZ place is nice! Especially the fountains by ABC street.”</li>
</ul>

<p>Of course, if you’re a nobody on Twitter (like me), this is a non-issue for you.</p>

<p>And please, don’t do this:</p>

<p><img src="https://icyphox.sh/static/img/mcafeetweet.png" alt="mcafee opsecfail"></p>

<h2 id="conclusion">Conclusion</h2>

<p>The ability to influence someone’s decisions/thought process in just one tweet is 
scary. There is no simple way to combat disinformation. Social media is hard to control.
Just like anything else in cyber, this too is an endless battle between social media corps
and motivated actors.</p>

<p>A huge shoutout to Bellingcat for their extensive research in this field, and for helping
folks see the truth in a post-truth world.</p>


 
          </article></div>]]>
            </description>
            <link>https://icyphox.sh/blog/disinfo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632586</guid>
            <pubDate>Tue, 29 Sep 2020 20:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The SaaS Marketing Educational Series]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632541">thread link</a>) | @hronis
<br/>
September 29, 2020 | https://allfactors.com/blog/saas-marketing/ | <a href="https://web.archive.org/web/*/https://allfactors.com/blog/saas-marketing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>


<p>This is a free educational series of comprehensive blog posts intended to give you the knowledge and tools you need to take your SaaS marketing to the next level.</p>
<p>Whether you’re just starting out and want to figure out SaaS marketing or you’re an experienced SaaS marketer who wants to refresh your knowledge and learn new techniques, you’ve come to the right place!</p>
<p>In this SaaS marketing educational series we’ll release a new comprehensive blog post every week covering a topic in SaaS marketing. Starting from the fundamentals, all the way to advanced strategies and tactics. Including step by step guides and examples from other SaaS companies who’ve done it well. </p>
<p>Topics will include:</p>
<h2>1. The SaaS Marketing Plan</h2>
<figure><img loading="lazy" src="https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-1024x682.png" alt="SaaS Marketing Plan allfactors" width="467" height="311" srcset="https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-1024x682.png 1024w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-300x200.png 300w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-768x512.png 768w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-600x400.png 600w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan.png 1280w" sizes="(max-width: 467px) 100vw, 467px"></figure>
<h3>How to create a SaaS marketing strategy</h3>
<p>SaaS marketing is different from selling products in an e-commerce store. Different goals, different customer behavior, different key performance indicators (KPIs), and a different business type. </p>
<p>The good news is that there is a pattern about SaaS and you can create a marketing strategy for it. We’ll go over the patterns you should know and how to think about marketing for SaaS.</p>
<h3>How to assess strategy-business-fit</h3>
<p>In SaaS you can have product-led motion and pricing structure, and you can have sales led motion and pricing structure. Your strategy has to take into consideration what customer acquisition and pricing motion is right for you, so you can tailor your plan according to that.</p>
<p>We’ll talk in detail about the differences between the go-to-market motions, and how you should approach your marketing so you can plan for strategy-business-fit for your SaaS. </p>
<h3>How to determine who does what </h3>
<p>Once you’ve defined your SaaS marketing strategy, you need to divide and conquer. Allocating the right tasks to the right people and empowering the team with the right tools and knowledge is super important in order to achieve productivity.</p>
<p>We’ll discuss the best ways to break silos between teams and teammates so everyone can be empowered to achieve the collective goals.</p>
<h2>2. The SaaS Marketing Techniques</h2>
<figure><img src="https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-1024x685.png" alt="SaaS Marketing Techniques_allfactors" width="467" srcset="https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-1024x685.png 1024w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-300x201.png 300w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-768x514.png 768w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-600x401.png 600w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques.png 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<h3>The techniques that actually work in SaaS</h3>
<p>Online marketing has many techniques, we’ll talk about how to choose the right techniques for SaaS marketing specifically. From SEO to content marketing, to social media platforms and which ones make the most sense. To advertising and what you need to know about running ads for SaaS products.</p>
<p>There are lots of nuances in marketing techniques. It can take a lot of time to figure out what works for SaaS marketing, we’re here to save you time and share all the best practices. </p>
<h3>How to turn techniques into measurable tasks</h3>
<p>There is a popular quote in management that applies to marketing “you can’t manage what you can’t measure.” – Peter Drucker</p>
<p>Once you learn what techniques you should be using for your SaaS marketing, it’s very important to learn how to measure the tasks that every technique entails. </p>
<h3>Common mistakes to avoid when executing</h3>
<p>If you can learn what mistakes to avoid you’ll shorten the learning curve, and achieve your desired results faster. </p>
<p>We’ll have a collection of stories and examples for you of what mistakes to avoid when it comes to SaaS marketing.</p>
<h3>Key Performance Indicators that matter</h3>
<p>When it comes to key performance indicators for your SaaS marketing results, there can be a ton of data points. But there are only a few that really matter and move the needle.</p>
<p>We’ll show you the most important KPIs for SaaS companies and how they should be aligned with the team’s marketing activities. </p>
<h2>3. How to Optimize SaaS Marketing</h2>
<figure><img src="https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-1024x651.png" alt="optimize saas marketing" width="467" srcset="https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-1024x651.png 1024w, https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-300x191.png 300w, https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-768x488.png 768w, https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-600x381.png 600w, https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2.png 1471w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<h3>What metrics you should pay attention to</h3>
<p>To drive growth and move the needle forward we need to pay attention to specific metrics, and ignore other metrics because they can be a distraction or just vanity.</p>
<p>We’ll discuss how to recognize which metrics are the most important for driving growth and which metrics are vanity for SaaS marketing. </p>
<h3>What it takes to consistently move the needle</h3>
<p>The thing about growth is that depending on the SaaS marketing technique, at some point the growth slows down. Especially when it comes to driving growth through ads, when you stop the ads, does the growth stop?</p>
<p>We’ll cover how to make sure that growth doesn’t stop even if one of your techniques stops working or if you run out of budget for ads.</p>
<h3>How to automate and do more of what works</h3>
<p>You can save a lot of time by putting certain SaaS marketing activities on autopilot by using marketing tools. From email marketing automation, to SEO, to advertising. </p>
<p>We’ll look at ways to automate those marketing activities, so they can be ‘working for you while you sleep’. </p>
<h3>Case studies of other SaaS companies doing marketing well</h3>
<p>A great way to learn how to do SaaS marketing and take action is by getting inspired with other SaaS companies who’ve done it well using best practices.</p>
<p>We’ll look at SaaS marketing case studies of companies who are role models for certain strategies executed very well. We’ll go over the execution step by step and explain how they did things, our hypothesis for why it worked, and how it can work for you.</p>
<p><strong>Subscribe to the series and share</strong> </p>
<p>If you haven’t yet, make sure to subscribe to our newsletter via the email box so you can receive a free educational piece every week.</p>
<p>Follow us on Twitter <a href="https://twitter.com/AllFactors" target="_blank" rel="noopener">@AllFactors</a> to receive the latest SaaS marketing tips. </p>
</div>
</div>

</div></div>]]>
            </description>
            <link>https://allfactors.com/blog/saas-marketing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632541</guid>
            <pubDate>Tue, 29 Sep 2020 20:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Oil Shell is a nice alternative to Bash]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632513">thread link</a>) | @roetlich
<br/>
September 29, 2020 | https://till.red/b/3/ | <a href="https://web.archive.org/web/*/https://till.red/b/3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
    
    <p>created:  29.09.2020</p>
    <p>The Oil project aims to transform the Unix shell into a better programming language. Under its umbrella live two languages: <a href="https://www.oilshell.org/release/0.8.0/doc/osh-manual.html">OSH</a> and the <a href="https://www.oilshell.org/release/latest/doc/idioms.html">Oil language</a>. OSH is a bash compatible shell, while the Oil language is an improved, safer, and nicer shell. I played with Oil for a while, and I talked to the creator of the Oil project, Andy Chu. I like Oil, and I think you might like it too.</p>

<hr>

<p>Disclaimer: The Oil language is still in early development. It absolutely can be tried out already, but it’s not complete and you will run into some bugs and crashes. OSH is more stable. In the following text, I will refer to the Oil language as “Oil” out of laziness.</p>

<hr>

<p>Let’s start with a simple problem and solve it with bash first, then with Oil. In node projects, there is typically a <a href="https://docs.npmjs.com/files/package.json"><code>package.json</code></a> file that includes dependencies and build scripts. The build scripts can be run with CLI tools like npm or yarn. My idea for a super simple script: Let’s execute the scripts from a package.json without using npm or yarn. (You shouldn’t do this in real life, because the npm dependencies would be missing.)</p>

<p>A simple package.json may look like this:</p>

<div><div><pre><code><span>{</span><span>
  </span><span>"name"</span><span>:</span><span> </span><span>"example"</span><span>,</span><span>
  </span><span>"version"</span><span>:</span><span> </span><span>"1.0.0"</span><span>,</span><span>
  </span><span>"description"</span><span>:</span><span> </span><span>"This is just an example package.json"</span><span>,</span><span>
  </span><span>"main"</span><span>:</span><span> </span><span>"index.js"</span><span>,</span><span>
  </span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"test"</span><span>:</span><span> </span><span>"echo </span><span>\"</span><span>all good :)</span><span>\"</span><span>"</span><span>,</span><span>
    </span><span>"say hello"</span><span>:</span><span> </span><span>"echo </span><span>\"</span><span>Hello world!</span><span>\"</span><span>"</span><span>
  </span><span>},</span><span>
  </span><span>"author"</span><span>:</span><span> </span><span>"Till"</span><span>,</span><span>
  </span><span>"license"</span><span>:</span><span> </span><span>"WTFPL"</span><span>
</span><span>}</span><span>

</span></code></pre></div></div>

<p>With this package.json, running <code>npm run test</code> will print “all good :)”. And I want to be able to run something like <code>my-script.sh test</code> to do the same, but without calling npm.</p>

<p>First, I need to get the script out of the json file. For this, I can use <code>jq</code>, a nice tool for handling json in the command line. To get the test command, you can write <code>jq -r .scripts.test package.json</code>. In a shell script, the first argument of the script is called <code>$1</code>, so I’ll use <code>jq -r .scripts.$1 package.json</code>. Then I just need to run <code>eval</code> on that to execute the script:</p>

<div><div><pre><code><span>#!/bin/bash</span>
<span>eval</span> <span>$(</span>jq <span>-r</span> .scripts.<span>$1</span> package.json<span>)</span>
</code></pre></div></div>

<p>Easy enough. Let’s make it slightly less simple by also printing the script before we run it.</p>

<div><div><pre><code> <span>#!/bin/bash</span>
<span>script</span><span>=</span> <span>$(</span>jq <span>-r</span> .scripts.<span>$1</span> package.json<span>)</span>
<span>echo</span> <span>$script</span> :
<span>eval</span> <span>$script</span>
</code></pre></div></div>

<p>Hmmmm, when I run this, the results look a bit odd:</p>

<div><div><pre><code><span>$ </span>./bash-simple.sh <span>test</span>
<span>"all good :)"</span>
:
</code></pre></div></div>

<p>That’s not what I want. Even worse, <code>./bash-simple.sh "say hello"</code> doesn’t work at all, complaining about <code>hello</code> not being a file. Can you spot all the mistakes I made?</p>

<p>Let me try explaining them:</p>

<ol>
  <li>Variable definitions in bash can’t have spaces. Bash, therefore, evaluates <code>script= </code> (with a space in the end) just like <code>script=""</code>, and then executes the rest as a command. The <code>$(...)</code> causes the script to be executed right away.</li>
  <li>The <code>$1</code> is not quoted, therefore it’s split up into <code>jq -r .scripts.say hello</code>, which causes jq to think we want to read from a file called <code>hello</code>.</li>
  <li>Fun fact: Should our script variable be “-n”, the <code>echo</code> command would only print <code>:</code>, without a new line at the end. That’s because “-n” is an option for <code>echo</code>.</li>
</ol>

<p>It’s a very simple shell script, yet it would be understandable for a beginner to overlook all three of these mistakes. Especially quoting is often a problem. The issues can only be solved by making the script uglier.</p>

<div><div><pre><code><span>script</span><span>=</span><span>$(</span>jq <span>-r</span> .scripts.<span>"</span><span>\"</span><span>$1</span><span>\"</span><span>"</span> package.json<span>)</span>
<span>echo</span> <span>"</span><span>$script</span><span> :"</span>
<span>eval</span> <span>$script</span>
</code></pre></div></div>

<p>But bash is already ugly enough, I don’t want to write stuff like this. Also, bash has a lot more gotchas, and it’s just annoying to fight with it all the time. I recommend reading <a href="https://mywiki.wooledge.org/BashPitfalls">the article in Greg’s wiki on bash pitfalls</a>.</p>

<h2 id="oil-as-a-better-way">Oil as a better way</h2>

<p>Oil has <a href="https://www.oilshell.org/release/0.8.0/doc/json.html">built-in json support</a>. That means you can not only work on flat text, but you can use nested json like in every other language:</p>

<div><div><pre><code>json <span>read</span> :pkg &lt; ./package.json
</code></pre></div></div>

<p>Oil has a <code>setvar</code> keyword for defining and updating variables:</p>

<div><div><pre><code>setvar scripts <span>=</span> pkg[<span>"scripts"</span><span>]</span>
</code></pre></div></div>

<p>Yes, you can put white space around the <code>=</code>! There is also the <code>var</code> keyword, used only for defining new variables. The <code>set</code> keyword updates them.</p>

<p>Oil also changes the defaults. Splitting requires explicitly writing <code>@split(variable)</code>, while <code>$variable</code> will not be split. No double quoting is needed.</p>

<p>So the complete Oil script now looks like this:</p>

<div><div><pre><code><span>#!/usr/local/bin/oil</span>

json <span>read</span> :pkg &lt; ./package.json
setvar script <span>=</span> pkg[<span>"scripts"</span><span>][</span><span>$1</span><span>]</span>
write <span>--</span> <span>$script</span>:
<span>eval</span> <span>$script</span>
</code></pre></div></div>

<p>This looks much nicer in my opinion, and you’re way less likely to make mistakes. Using a dedicated keyword makes it possible to differentiate declaring and updating variables.</p>

<h2 id="some-other-nice-features">Some other nice features</h2>

<p>Let me show you some other cool things in Oil.</p>

<p>Oil has better arrays:</p>

<div><div><pre><code>oil<span>$ </span>setvar files <span>=</span> <span>[</span><span>"image with spaces.png"</span>, <span>"notes.txt"</span><span>]</span>
oil<span>$ </span><span>rm</span> @files
</code></pre></div></div>

<p>“<a href="https://www.oilshell.org/release/0.8.0/doc/eggex.html">Egg Expressions</a>” are nicer Regular Expressions. You can assign them to variables and compose them easily. They “compile” to normal regular expressions, so you can use them with existing tools like grep.</p>

<div><div><pre><code><span># Define a subpattern that matches three digits</span>
oil<span>$ </span>setvar D <span>=</span> / digit<span>{</span>1,3<span>}</span> /

<span># Use the subpattern to describe ip addresses</span>
oil<span>$ </span>setvar ip_pat <span>=</span> / D <span>'.'</span> D <span>'.'</span> D <span>'.'</span> D /

<span># Use the pattern with grep</span>
oil<span>$ </span><span>grep</span> <span>-E</span> <span>$ip_pat</span> log.txt
</code></pre></div></div>

<p>Currently, you can fry your Egg Expressions only in Oil, but hopefully, other tools will adopt something like this as well.</p>

<p>Also “functions” (now reasonably renamed to <a href="https://www.oilshell.org/release/latest/doc/oil-proc-func-block.html">“proc”</a>) can declare their parameters and don’t have dynamic scoping.</p>

<p>Overall, I believe that lots of the changes Oil is making are an improvement over bash.</p>

<p>One planned Oil feature that I’m particularly looking forward too is <a href="https://www.oilshell.org/release/latest/doc/oil-proc-func-block.html#block-syntax">blocks</a>. Andy Chu plans to add Ruby-like blocks, that could allow simple meta programming in Oil. This relatively simple feature, if done well, could allow shell to grow into several areas that are already close to its usual uses: Shell as configuration language? Shell as a build system?</p>

<h2 id="adoption-and-compatibility">Adoption and compatibility</h2>

<p>I’m convinced that Oil is already better than bash for most scripting tasks, and Oil is rapidly improving. But is better good enough?<br>
Bash is preinstalled on most unix systems, and there are large shell scripts that already exist that nobody wants to rewrite.</p>

<p>Oil Shell attempts to solve this with the backward compatible OSH. OSH runs bash scripts just fine, and you can still use some of the new features, such as the built-in json support.</p>

<p>OSH has fine-grained settings to make it stricter and enable more advanced features. Oil is just OSH with a bunch of these settings enabled. Step by step, you can turn the crude OSH into the refined Oil language. So you don’t have to adopt Oil all at once, you just enable the nicer features one at a time when you want them.</p>

<h2 id="can-you-hear-the-c">Can you hear the C?</h2>

<p>Unix shell never was the cleanest or prettiest language. But at some point it was simple and when it grew to more platforms new implementations added new features. Now shell is a big family of complex languages. Shell is a <a href="https://youtu.be/lw6TaiXzHAE">language that grows</a> in two ways: It grows with each new implementation, and it grows in features because everyone can easily make CLI programs.  Almost every language can write CLI apps since everything is just plain text. Shell is the glue that holds these apps together.</p>

<p>In a way, Oil is the logical next step, yet another shell dialect that solves the issues that bash has accumulated over the decades. On the other hand, Oil adds new data structures that can’t be trivially expressed in plain text, so it’s harder to extend it naturally with CLI apps. This way, shell loses its connection with C.</p>

<p>To give an example: in shell code like <code>if [ $variable = "something ]; then ...</code> the <code>[</code> is a command. That means the variable, <code>=</code>, the string on the right and even <code>]</code> are passed to it as arguments. Practically, that’s super inconvenient since you have to have spaces between all operands. But conceptually it’s almost amazing, it means you can just write your own <code>[</code>, in whatever language you like! Do you want to be able to do math inside your <code>if</code>? Feel free to write that in Haskell or VisualBasic.Net or whatever.</p>

<p>As a counter-example, take the <code>json</code> built-in from Oil. <code>json</code> can assign a Dict to a variable. If you want to write your own <code>json</code> command or add an <code>xml</code> command, you can only write it in Oil.</p>

<p>This problem isn’t new, Bash already has associative arrays that aren’t just plaintext. This might be the necessary step shell programming has to take to improve. It might be worth pointing out that PowerShell is the extreme conclusion to this, in PowerShell everything is an object instead of a string. PowerShell is in this way very anti-unix. And Oil is therefore also not really following the “unix philosophy”. But I think it’s doing the right thing.</p>

<h2 id="oil-has-a-sales-problem">Oil has a sales problem</h2>

<p>While I believe that Oil is an improvement over the status quo, its features aren’t “flashy”. Shell has two purposes: It’s a scripting language, and an interactive enviroment. Oil focuses on the scripting part. If you run it interactively, it’s not (yet) as convenient as the alternatives. Its tooling is not yet as good as bash’s (No shellcheck, no debuggers, no proper syntax highlighting, etc). As with any upcoming programming language, this will take time.</p>

<p>In contrast, the <a href="https://fishshell.com/">fish shell</a> focuses on the interactive experience. If you get someone to install fish, they <em>immediately</em> see cool things that make their life easier right away. Pitching Oil needs more time. You have to explain how Oil allows better-structured code, what kind of bugs you can avoid in Oil, etc. I started using Oil for some small private scripts, and I’m happy with those. I will continue writing personal scripts in Oil. But I’ll go back to fish as my default interactive shell, probably until <a href="https://www.oilshell.org/blog/2020/02/recap.html#fish-oil-is-a-good-idea-link">“fish oil”</a> becomes a reality.</p>

<p>This kind of goes back to the old “<a href="https://www.dreamsongs.com/WIB.html">worse is better</a>” problem. I think Oil is better (than bash), but that doesn’t necessarily mean it will see adoption. I hope it will. I’d prefer a world where <code>/bin/sh</code> is typically a link to OSH or Oil.</p>

<p>If you agree with me and have some free time over, <a href="https://www.oilshell.org/blog/2019/12/09.html#help-wanted">consider helping out with the development of Oil</a>. There are lots of exciting …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://till.red/b/3/">https://till.red/b/3/</a></em></p>]]>
            </description>
            <link>https://till.red/b/3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632513</guid>
            <pubDate>Tue, 29 Sep 2020 20:23:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing a commenting plugin and integrating Hyvor Talk in Hugo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632394">thread link</a>) | @lokethien
<br/>
September 29, 2020 | https://www.andreasrein.net/posts/hyvor-talk-hugo-commenting-systems/ | <a href="https://web.archive.org/web/*/https://www.andreasrein.net/posts/hyvor-talk-hugo-commenting-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>
  
  <div><p>You can see Disqus on most blogs, but there are multiple privacy-respecting, cheap and appealing alternatives. I have decided to add Hyvor Talk to my blog.</p>

<h2 id="why">Why</h2>

<p>This post is an opinionated guide to picking a cheap/free, appealing, and functional third-party <code>non-self-hosted</code> commenting plugin for a static blog. I have only included service-based plugins to keep it simple.</p>

<p>When I first created this blog, I chose to not include a commenting system since I didn’t see the point of it, and it made the site sluggish (Disqus). I have never been much of a commenter, and you can find my social accounts if you have any questions about the content. But I guess it’s much more convenient for people to drop in a comment without leaving the article.</p>

<p>So the plan is to test it a year and see if the activity can justify the price and maintenance.</p>

<h2 id="alternatives">Alternatives</h2>

<p>There are quite some to choose from, but they vary by their level of trustworthiness and the number of ads, trackers, and <em>American spies</em> they inject.</p>



<ul>
<li>Price from: Free</li>
<li>Size: <strong>267,14 KB</strong> (241,13 KB JS and 26,01 KB CSS)</li>
<li>Ads: Yes but you can remove it by paying</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/disqus-look.png"></p>

<p>The de-facto standard for online comments, but I have never been a fan of it. It’s also huge and loads nasty ads, so no thanks.</p>

<p>A blog should load blazingly fast so we cannot sacrifice precious speed by adding an enormous amount of JS just for the sake of providing a commenting system. One option is to have a button that loads it so it won’t affect the initial page load.</p>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/disqus-js-files.png"></p>



<ul>
<li>Price: Free</li>
<li>Size: <strong>600,39 KB</strong> (576,65 KB JS and 23,74 KB CSS)</li>
<li>Ads: Yes</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/fb-look.png"></p>

<p>Ah, Facebook. The interface and overall commenting system are not bad at all. But it’s loaded with trackers, ads, and more trackers. It’s gloomy that we have to load 600 KB of data just to comment online in 2020.</p>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/fb-js-files.png"></p>



<ul>
<li>Price from: $7/month</li>
<li>Size: <strong>49,18 KB</strong> (43,65 KB JS and 5,53 KB CSS)</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/remarkbox-look.png"></p>

<p>Well, it’s lightweight, fast and have markdown support. Apart from that, it doesn’t have too much going for it. The landing page is nice and you can easily control the behaviour and apperance which is a nice addition.</p>



<ul>
<li>Price from: $5</li>
<li>Size: <strong>36,94 KB</strong> JS</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/justcomments-look.png"></p>

<p>First impressions from the landing page is good but I don’t feel the same when I see the commenting system itself. It is customizable and JustComments is a pay-as-you-go service so that’s swell.</p>



<ul>
<li>Price from: Free (100 comments per month). $10 for unlimited comments.</li>
<li>Size: <strong>9,79 KB</strong> JS</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/commentbox-look.png"></p>

<p>CommentBox has a limited free plan and the interface feels familiar. You can reply, vote, flag and pin comments. It’s also extremely lightweight with just under 10 KB of JS.</p>



<ul>
<li>Price from: $5</li>
<li>Size: <strong>14,04 KB</strong> JS</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/fastcomments-look.png"></p>

<p>FastComments is also very lightweight. The interface is functional and simplistic. They also have a lot of neat features like spam fighting and the ability to import from other commenting systems like Disqus.</p>



<ul>
<li>Price from: $10</li>
<li>Size: <strong>16,48 KB</strong> (9,51 KB JS and 6,97 KB CSS)</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/commento-look.png"></p>

<p>I like the catchphrase “Embed comments without giving up your privacy.”. The website itself gives a good first impression. Modern, sleek and fast. The design is sleek and pretty. The cheapest plan is tad expensive for a simple dev blog compared to other offers.</p>

<h3 id="hyvor-talk-https-talk-hyvor-com-aff-10484"><a href="https://talk.hyvor.com/?aff=10484">Hyvor Talk</a></h3>

<ul>
<li>Price from: $5</li>
<li>Size: <strong>112,3 KB</strong> (104,34 KB JS and 7,96 KB CSS)</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/hyvor-look.png"></p>

<p>Hyvor Talk boosts more KB but at least it’s lazy-loaded so it won’t affect the page performance. What wins me over is the playful, lovely, and feature-packed interface. The reactions part is a delightful addition since it doesn’t require much effort for readers to click on and it gives me valuable feedback on my posts.</p>

<p>In other words, Hyvor Talk feels like it was built with love and passion. Those are values I can stand behind and it feels good to support them. So let’s see how it goes and if you want to test it out, scroll to the bottom and write a comment.</p>

<h2 id="add-hyvor-talk-to-hugo">Add Hyvor Talk to Hugo</h2>

<p>To add Hyvor Talk to your Hugo based blog, simply paste this code in the bottom of the footer (found in the template you are using). This code may change so be sure to verify with the <a href="https://talk.hyvor.com/docs/code">official docs</a>.</p>

<pre><code>{{ if in .Page.Dir "posts" }}
&lt;script type="text/javascript"&gt;
    var HYVOR_TALK_WEBSITE = 2018; // DO NOT CHANGE THIS
    var HYVOR_TALK_CONFIG = {
        url: "URL_TO_YOUR_WEBSITE",
        id: 'UNIQUE_POST_ID'
    };
&lt;/script&gt;
{{ end }}
</code></pre>

<p>The ID is a unique ID that links the comments and your post. You can use <code>ìd: '{{ .File.UniqueID }}'</code> but remember that if you change the file name of the post, the ID will also change since it’s a hash of the file name.</p>

<p>The better way is to include an ID in the filename. Example filename: <code>07-hyvor-talk-hugo.md</code> and if you want to use 07 as the ID, use this code <code>id: '{{ index (split .File.LogicalName "-") 0 }}'</code>.</p>

<p>If you disagree, agree, or have anything in your heart, please, feel free to <em>write a comment</em>.</p></div>
</article>
</div></div>]]>
            </description>
            <link>https://www.andreasrein.net/posts/hyvor-talk-hugo-commenting-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632394</guid>
            <pubDate>Tue, 29 Sep 2020 20:13:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Thoughts on Cloudflare Web Analytics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632382">thread link</a>) | @jlelse
<br/>
September 29, 2020 | https://jlelse.blog/thoughts/2020/09/cwa/ | <a href="https://web.archive.org/web/*/https://jlelse.blog/thoughts/2020/09/cwa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Cloudflare currently celebrate their 10th birthday and launch a new product or feature everyday for a week. Today they launched <a href="https://www.cloudflare.com/web-analytics/" target="_blank" rel="noopener">Cloudflare Web Analytics</a>. Until now you had to proxy your site through Cloudflare to use their analytics, because they collected those stats – “at the edge” – on their servers. But now they are adding an JavaScript-based option, similar to Google Analytics and all the new privacy-focused analytics services like <a href="https://www.goatcounter.com/" target="_blank" rel="noopener">GoatCounter</a> and <a href="https://plausible.io/" target="_blank" rel="noopener">Plausible</a>. But like GoatCounter and Plausible and unlike Google, they promise privacy, because they don’t make their money tracking users, but selling products (that aren’t users) – at least that’s what they say in <a href="https://blog.cloudflare.com/free-privacy-first-analytics-for-a-better-web/" target="_blank" rel="noopener">the announcement post on their blog</a>:</p><blockquote><p>Cloudflare’s business has never been built around tracking users or selling advertising. We don’t want to know what you do on the Internet — it’s not our business. So we wanted to build an analytics service that gets back to what really matters for web creators, not necessarily marketers, and to give web creators the information they need in a simple, clean way that doesn’t sacrifice their visitors' privacy.</p></blockquote><p>They try to be even more privacy-friendly then most of the privacy-focused analytics services by taking a different approach regarding “unique visits”:</p><blockquote><p>What does it mean for us to make our analytics “privacy-first”? Most importantly, it means we don’t need to track individual users over time for the purposes of serving analytics. We don’t use any client-side state, like cookies or localStorage, for the purposes of tracking users. And we don’t “fingerprint” individuals via their IP address, User Agent string, or any other data for the purpose of displaying analytics. (We consider fingerprinting even more intrusive than cookies, because users have no way to opt out.)</p></blockquote><p>That’s the thing that made me write <a href="https://jlel.se/kis3" target="_blank" rel="noopener">my own analytics tool</a>. I don’t need those “unique” statistics, I just want to see very basic stats about which page gets how many views – and I can’t just look at my server logs because I use <a href="https://bunnycdn.com/" target="_blank" rel="noopener">BunnyCDN</a> in front of my origin server. Even many privacy-focused analytics tools generate some kind of identifier (even if they reset it every day) to fingerprint specific users and calculate “unique visitors”.</p><p>I’m interested into whether they provide this analytics service for free or charge some money for it. Currently it’s only available for users who already have a paid Cloudflare plan. But they promise to make this service even available for people not yet using Cloudflare, so that they don’t have to change any DNS entries etc. While I see Cloudflare’s internet dominance with a critical eye and am annoyed when their bot protection system shows me a captcha, I’m grateful that they provide their DNS service for free and also allow at-cost domain registration.</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/thoughts/2020/09/cwa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632382</guid>
            <pubDate>Tue, 29 Sep 2020 20:11:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I healed by finding the right diet thanks to a few lines of code]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632308">thread link</a>) | @camilleroux
<br/>
September 29, 2020 | https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/ | <a href="https://web.archive.org/web/*/https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>I was diagnosed over a year ago with an <a href="https://en.wikipedia.org/wiki/Irritable_bowel_syndrome" target="_blank" rel="noreferrer noopener">Irritable Bowel Syndrom</a> (also called functional colopathy, IBS, Irritable Colon Syndrom or ICS for those in the know). For about 6 months, I was continuously sick.</p>
<p>I will tell you the story of my chaotic (and sadly common) medical journey with this disease, which strikes about 10% of the world population (<a href="https://www.gastrojournal.org/article/S0016-5085(02)00481-X/abstract" target="_blank" rel="noreferrer noopener">source</a>). I’m also going to tell you about its important negative and positive impacts on my life.</p>
<p>Today, I’m much better. After meeting many doctors and specialists, I have finally found the personalized diet which allows me not to be sick anymore. It was mainly thanks to the help of a dieticien and by reading many articles. I also spent a lot of time finding the links between my episodes and my meals.&nbsp;</p>
<p>For a long time; I was reluctant to openly talk about my disease because I was afraid it could harm me one day. But after a <a href="https://twitter.com/CamilleRoux/status/1138066899110105088" target="_blank" rel="noreferrer noopener">post</a> on Twitter, a lot of comments encouraged me to do so and convinced me it was useful. The lack of information and support by doctors seems unfortunately very common. </p>
<p>I wrote this article in order to:&nbsp;&nbsp;&nbsp;&nbsp; </p>
<ul><li>Encourage and maybe give some ideas to people with the same disease</li><li>Show doctors that some existing diets works. It’s not inevitably about stress. It was useless to recommend alternative medicines to me.</li><li>Show the medical field that, like many patients, I have wasted a lot of time because of the lack of information and doctor’s support.</li><li>Add a witness for the press, patient associations and doctors and show them the urgency for doctors to get training, for the food industry and restaurants to adjust and ease the life of low-FODMAP diet patients, to show the importance of getting sure, true and updated information in French on the web.</li><li>Help to talk openly about intestinal diseases. </li><li>Thank my entourage who support me and adapt to my constraints.&nbsp;&nbsp;&nbsp;&nbsp;</li></ul>
<h2>Act 1: Symptoms Emergence&nbsp;</h2>
<p>All seemed to begin on May 12th, 2018. It was about 7 p.m., I was having a cocktail dinner at home with some common foods: some French cheese (Comté, Ossau-Iraty), hummus, bread and beer. Around the end of the evening, I began to feel nauseous and to get abdominal pain.<br>The next day when I woke up, I felt more nauseous. I was not hungry at all. I forced myself to eat a little bit of white rice at lunch and, at the end of the afternoon, all got right back and I could normally eat again. </p>
<p>Everything was fine in my life. My job was going well and I was going on vacation in the next few days. Nothing was a source of stress for me. </p>
<p>May 15th: For lunch I was preparing a salad, again with some common products: lettuce, tomato, pepper, beetroot, seeds, cereal mix and dried vegetables. At the end of the afternoon, I got nausea and abdominal pain again that lasted all evening. The next morning, my health got back to normal.&nbsp;</p>
<p>But the same thing happened on may 18th and 24th… After each episode, I naively tried to change my diet based on what I read online. I tried to eat less acidic, less fat, to follow a diet advised by a gastroenterologist but nothing got better. </p>
<p>At the first episode, I guessed it could be due to a virus, a gastroenteritis, or food poisoning… But with time it looked like nothing I had ever known.&nbsp;As soon as I came back home from vacation, I decided to see my general practitioner (GP).</p>
<p>I took the habit of writing everything I ate, my symptoms, and my episodes. That allowed me to easily explain the situation to my GP and check any link with food. You’re going to understand its usefullness!</p>
<h3>Description of my usual episode</h3>
<p>All attacks looked alike. Intensity and duration could vary, but it usually started with nausea (that gradually appeared in about 1-2 hours), then tiredness. Nausea lasted for some hours. I rarely skipped more than one meal. Most of the time, I postponed my meal for few hours. It could be along with variable intense abdominal pain and bloating. </p>
<p>Then, usually, I got some intestinal disorders and abdominal pain for few days. Then everything got slowly better.&nbsp;</p>
<p>Unfortunately, I rarely got back to a normal state. Usually, a new episode appeared before the previous one completely disappeared.&nbsp;</p>
<h2>Act 2: The first disapointment</h2>
<div><figure><img loading="lazy" width="244" height="300" src="https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-244x300.png" alt="" srcset="https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-244x300.png 244w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-500x615.png 500w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-400x492.png 400w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-250x307.png 250w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-200x246.png 200w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-100x123.png 100w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-76x93.png 76w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-50x61.png 50w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1.png 602w" sizes="(max-width: 244px) 100vw, 244px" data-srcset="https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-244x300.png 244w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-500x615.png 500w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-400x492.png 400w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-250x307.png 250w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-200x246.png 200w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-100x123.png 100w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-76x93.png 76w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-50x61.png 50w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1.png 602w" data-src="https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-244x300.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>
<p>At the end of May, I went to my GP. I showed her my diet diary, but all seemed right to her. She supposed it was a acidic stomach disorder and prescribed, for few weeks, a treatment with an impressive name: a proton pump inhibitor drug called Lansoprazole in French.&nbsp;</p>
<p>I don’t remember this period very well, but I think I didn’t get any episode until the beginning of July. I thought the drug was working at first but, unfortunately, the episodes reappeared at the beginning of July while I was taking this treatment for a month. </p>
<p>Episodes were linked and overlapped.&nbsp;</p>
<h2>Act 3: Failed attempts of GP</h2>
<p>It was summerime, either my GP or me went on vacation alternatively. So, I consulted different GPs.&nbsp;</p>
<p>Mid-July, I was on vacation in the Pyrenees. I decided to consult a local GP because I’ve been in pain&nbsp; for one week and the long treatment prescribed by my GP wasn’t working at all.&nbsp;<br>I explained the regular episodes I got since the last 2 months. This GP prescribed me a wormer treatment (Fluvermal in French) and charcoal against bloating.<br>No effect at all. </p>
<p>The impact on my life was quite important. I often felt pain and regularly tired. As attacks could happen in a matter of minutes/hours, I often cancelled my outings with my entourage. <br>I finally decided not to plan anything ahead. I dropped&nbsp; all my summer projects. I saw my entourage less and less. This disease started to isolate me. <br>I got more and more episodes and they were linking up. I rarely spent a day without symptoms. </p>
<p>Back from my vacation, I got a new episode. I consulted my GP and she prescribed a treatment against gastric reflux (SODIUM ALGINATE/SODIUM BICARBONATE) and a yeast (Saccharomyces boulardii) in order to go over my intestinal disorders and restore my intestinal flora.<br>No effect at all.</p>
<p>At the end of July, I consulted GP emergency because I was getting an attack during the weekend. It was more painful than usual and my GP was on vacation. For this GP, nothing was alarming and he prescribed me Spasfon and a blood test (which results were normal).&nbsp;<br>Spasfon had no effect. </p>
<p>Consulting different GP was exhausting. Each time I had to explain my situation again, show my diary, detail what the previous GPs ever did.&nbsp;<br>Many of them only focused on stress factor. I often had to argue that stress was not what made me sick. Some of them even argue that I could have been stressed unconsciously.&nbsp;<br>Regularly, they stepped out of their expertise fields by suggesting some alternative medicines: naturopathy, homeopathy, acupuncture… which I categorically refused. </p>
<p>At the beginning of August, after a few days of serenity, a new crisis came. I went again to see my GP who was back from her vacations at least. <br>She took things seriously and sent me for an echography. Results: normal.<br>I also went for a stool analysis. Results: normal.<br>Then, she sent me for a last test for <em>Helicobacter Pylori Infection</em> and said that she would send my to consult a gastroenterologist if the result was negative. <br>One week later, the resultats came back, negative.</p>
<p>I went back to my GP and she gave me a letter to consult a specialist. At that time, I was pretty confident, about a possible solution. I was impatient to meet the specialist in order to finally find why I was so sick.&nbsp;</p>
<p>I made my first phone call but they proposed an appointment several months later. </p>
<p>While my disease was ruining my life, preventing me from working and getting a social life, doctors all agreed that there was no emergency. I just had to take my pain patiently.&nbsp;</p>
<p>I spotted a practice that proposed an appointment at the end of September. This was by far the best date. I have a long month to wait…<br>I asked them if they sometimes had some cancellations. They answered me positively and advised me to call when I want to check if they had any cancellation. I called them twice a day… until I got an appointment on September 5th.&nbsp;</p>
<h2>Act 4: The reserved diagnosis of the gastroenterologist</h2>
<p>September 5th: I was happy to finally explain my situation to a specialist.<br>But I was quickly disillusioned. The consultation was cold and fast (15 minutes). The gastroenterologist didn’t know if the problem was due to the stomach or the intestine. So she decided to prescribe a treatment for both. I left her with very few additional information and a 3 months renewable prescription:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<ul><li>Aflorex (one month): food supplement used to balance the intestinal microbiota</li></ul>
<ul><li>Bedelix: digestive clay dressing</li></ul>
<ul><li>Meteospasmyl: antispasmodic and a silicone dressing</li></ul>
<ul><li>Imodium: antidiarrheal</li></ul>
<ul><li>Trimebutine: regulates intestine motricity</li></ul>
<p>At the end of the appointment, I asked her if she knew what I had. She told me it could be a stomach inflammation, functional colopathy… (the list went on)</p>
<p>The functional colopathy was one of the most probable hypothesis according to her. If so, she told me that the treatment should help me and that, anyway, she wouldn’t be able to do much better.</p>
<h3>Some astonishing food recommendations</h3>
<p>She also gave me dietary advices to regulate my transit and therefore reduce my pain and my episodes:</p>
<p><em>– 2 fresh kiwis on mornings, preferably on an empty belly<br>– Pineapple juice <br>– Non-whole grains at breakfast <br>– Mineral water (brand HEPAR) up to 1 liter a day <br>– Oil RESTRICAL to spice hot meals (do not cook) <br>– Spinach <br>– Oleaginous dry fruits (nuts, hazelnuts, almonds, …) <br>– Cooked prunes on the evening (3 to 4 with cooking juice) <br>– AXAROLA, one pill an evening <br>– FRUITS AND FIBERS, one pill an evening</em></p>
<p>This came from a very good intention, except that with a suspicion of functional colopathy, it was absurd (in my opinion) for several reasons<strong>.</strong></p>
<p>I’m going to explain my point of view later below, but when you have a colopathy, it is often beneficial to remove (or at least diminish) FODMAPs from your diet. The efficiency looks obvious: a study showed that a low-FODMAP diet had a beneficial effect on 86% of …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/">https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/</a></em></p>]]>
            </description>
            <link>https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632308</guid>
            <pubDate>Tue, 29 Sep 2020 20:05:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Miniaudio – single file audio playback and capture library]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632136">thread link</a>) | @jakearmitage
<br/>
September 29, 2020 | https://miniaud.io/index.html | <a href="https://web.archive.org/web/*/https://miniaud.io/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://miniaud.io/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632136</guid>
            <pubDate>Tue, 29 Sep 2020 19:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nothing in user acceptance testing is technical. It’s wholly political]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632093">thread link</a>) | @ohjeez
<br/>
September 29, 2020 | https://www.functionize.com/blog/3-things-you-ought-to-know-about-user-acceptance-testing/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/3-things-you-ought-to-know-about-user-acceptance-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/ft-acceptance-beer.jpg" alt="3 things you ought to know about User Acceptance Testing" srcset="https://www.functionize.com/wp-content/uploads/2020/09/ft-acceptance-beer.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/09/ft-acceptance-beer-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/09/ft-acceptance-beer-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/09/ft-acceptance-beer-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>The problems you encounter with user acceptance testing aren’t technical. They’re all political. You can’t solve all of the messes when things go wrong – but you can do quite a bit to prevent them.</p></blockquote>
<p>Users are required to have intimate involvement with application development at only two points in a project: at the beginning, and at the very end. At the beginning of the project, the user has to explain what he wants the software to do, so that requirements can be created – whether that specification is as simple as, “I need a utility to back up these files” or a requirements document as long as some novels.</p>
<p>Agile methodologies encourage user participation throughout the development process, which can improve the likelihood of a positive result. Be that as it may, the other point where an end user <em>must</em> get involved is at the end of the project: <a href="https://www.functionize.com/blog/understanding-user-acceptance-testing-for-better-results/">user acceptance testing</a> (UAT). That project phase has a lot of names, though my own working definition is “the last phase of the testing cycle, right before the team goes out for a celebratory beer.”</p>
<p>Only a few challenges in “acceptable” acceptance testing are about the tests. The transition from “bits of code that might work” to an application ready to go into production is more political than technical. The Acceptance Testing phase is the last opportunity for someone outside the QA or development team to stick a thumb in the pie. You know whom I’m talking about: the people for whom the word “deadline” doesn’t seem to apply (“I know I was supposed to identify problems last month, but gosh this is really important”); political shenanigans when management wants to take credit or cover their butts; consulting clients who are determined to find problems to avoid paying a time-based delivery bonus.</p>
<p>As a result, the celebratory beer is short lived if users respond, “This is wrong, and that is not right, and I really wanted this over here, and oh, by the way, we decided that we really didn’t need this functionality after all, so could you take it out?”</p>
<p>Good beer should never be wasted, so let’s see what we can do about this issue. (Note that I collected this input years ago, so I filed off my QA contacts’ names. However, none of their advice has changed.)</p>
<h3>Set expectations</h3>
<p>I seem to have a bullet point about correctly setting expectations in <a href="https://www.functionize.com/blog/5-rules-for-successful-test-automation/">every article I write</a>, but it’s become obvious how much it matters for <em>every</em> QA endeavor. None more importantly, however, than in defining up front what the user considers acceptable. That’s simply <em>got</em> to happen at the beginning of the project – or, failing that, at some point before you drop the completed application in their laps.</p>
<p>When developers create a requirements document, they think primarily about establishing what the application needs to do, and what it must accomplish before the software goes to production. However, defining the acceptance criteria early – as part of the requirements process – both helps you find hidden, unspoken requirements, and shows users what this testing stuff is all about.</p>
<p>As consultant David says, “End users discover something they don’t like – whether it is a real problem or not, whether it is per spec or not. Then they promptly declare the entire product rubbish based on that single point observation. They have no accountability, but seemingly magical authority to send the entire project back to the drawing board, and at the very last stage of the game.”</p>
<p>“An acceptance test is a type of contract between the users (or their representatives) and the producers, saying in essence ‘If you can do <em>this</em>, then the product is acceptable,'” says a tester named Joe. “But as professional QA testers can attest, it’s never quite that simple.” All sorts of unstated assumptions are left out of the Acceptance Criteria, and can become the subject of negotiation near the end of the development cycle. Those can turn into political shenanigans, development bashing, or delaying tactics, if not handled well.</p>
<h3>Put someone In charge</h3>
<p>While it won’t necessarily solve all the problems – I don’t think anything will – some QA professionals find that you can discover or prevent difficulties by creating a UAT team (even if that’s only one person) to deal with the users. That person works closely with the customer, holds their hand, guides them, and cajoles them throughout the project to do what they need to do. That individual should be experienced, able to build relationships, and well respected. (A heart that’s pure and the strength of ten would not go amiss, either.)</p>
<p>It’s also important for the liaison to <a href="https://www.functionize.com/blog/how-to-do-a-product-evaluation-for-enterprise-software/">deal with the right users</a>. The business users who define the functional specs may not be the people who use the system. One tester described a project that had to go back to the drawing board; this time, the functional requirements were created by people who actually used the system. Imagine that.</p>
<p>In other situations, as QA professional Christian points out, managers show up at the beginning of the project to approve milestones and budgets. The managers let actual users or their representatives define requirements and ensure that budgets and timetables are on track. But then, says Christian, the managers show up again at UAT time because the project needs their go-ahead (such as to approve the use of people or machine resources). Suddenly, project management responsibilities are reshuffled. People who were previously uninvolved or had little to say if budgets were on track, are now confronted with the reality of the work and all the imperfections it holds. “<a href="https://www.functionize.com/blog/how-to-recognize-the-warning-signs-of-a-project-crisis/">Here comes the political mess</a>,” Christian says.</p>
<h3>Will the dog eat it?</h3>
<p>Software developers, testers, and users can get so wrapped up in the process of creating an application that they lose sight of the effect of deploying it. Unfortunately, this may not become apparent until it’s time for user acceptance testing.</p>
<p>Fritz, a project management consulting, explains, “A damn good reason for acceptance testing that is to make sure the new functionality will actually enhance, not hinder, business operations. Until a workable product is demonstrated for evaluation, the users may find it hard to understand the ins-and-outs of how their operation will change once the software is deployed, which makes UAT a major risk management effort.” In other words: Once the users discover how the new software affects their jobs, they realize they don’t want it after all.</p>
<p>Fritz sees this as a reason to adopt, if not the full Agile development set of methodologies, at least some of its underlying philosophy. The requirements-development-UAT cycle “demonstrates that the requirements are merely a starting point and the user feedback is essential to refine requirements prior to the next cycle,” he says.</p>
<p>Stephen, a consultant, concurs. “We deliver early, pre-production code, for demonstration and further definition. We go back to the shop to re-tool around the aspects found during the latest discovery session. This can be repeated – based on the scope of the project – several times.”</p>
<p>Whether you do this as an application prototype or as <a href="https://www.functionize.com/blog/lets-make-testing-agile-they-said-uh-what-did-they-mean-by-that/">an Agile development cycle</a>, developers and testers say that it make a huge difference. “This process puts 90% of the acceptance testing up front, and allows us a way to challenge scope creep once the&nbsp; requirements and prototype have been signed off on,” says Scott, an independent software vendor.</p>
<p>In the end, the question comes down to creating an application that adds value to the user. And that’s exactly what makes UAT so messy. “The number one problem with UAT testing is that it is political. Some of the things the user may not like, or that negatively impact their workflow, are not actual functional errors. Therefore, the system may have passed every test run with flying colors and is still ‘wrong,’ says Linda a QA manager. “Overall, it doesn’t matter if you produce a perfectly-balanced, perfectly priced, perfectly packaged dog food if the dog won’t eat it.”</p>
<blockquote><p>One candidate to serve as a end-user liaison might be a <a href="https://www.functionize.com/project/why-your-enterprise-needs-a-cqo-chief-quality-officer/">Chief Quality Officer</a>. Have you considered hiring someone for that role?</p></blockquote>
  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/3-things-you-ought-to-know-about-user-acceptance-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632093</guid>
            <pubDate>Tue, 29 Sep 2020 19:46:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Accidentally Reported a Fake Terror Incident]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632018">thread link</a>) | @jermaustin1
<br/>
September 29, 2020 | https://jeremyaboyd.com/post/that-time-i-accidentally-reported-a-fake-terror-incident | <a href="https://web.archive.org/web/*/https://jeremyaboyd.com/post/that-time-i-accidentally-reported-a-fake-terror-incident">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
            <div>
                <div>
                    <p>The year was 2007, And I just started as a junior/mid/lead developer at a small web development agency called Humankind.</p>
<blockquote>
<p>I've mentioned Humankind a few times, but for a deeper dive into our first product, see <a href="https://jeremyaboyd.com/post/my-first-product-launches">My First Product Launches</a></p>
</blockquote>
<p>My first task after being hired was to fix some bugs and SaaS-ify a product we were partners on called Citizen Notification Service (CNS). It was basically a platform for towns to send out email and SMS blasts to residents about events, or emergencies. The customer was typically a town's Office of Emergency Management.</p>
<p>Our partner, who was a Chief of Police in a Dallas, Texas, suburb, also ran another service called CrimeWeb. CrimeWeb was a similar concept to CNS, but here the customers were police, and journalists. Basically you could sign up for CrimeWeb as a police force and disseminate crime information to journalists. The product was genius. Collect money on both ends.</p>
<p>After a few weeks on the job, I had fixed most of the bugs, and SaaS-ified the CNS product as best as I could with its current code-base (we would rewrite this later), and my next task was to add video upload to CrimeWeb.</p>
<h3 id="out-of-my-depths">Out of my depths</h3>
<p>I'm almost never one to back down from a challenge, but CrimeWeb was written in classic ASP/VBscript, and I was an ASP.Net/C# developer, so I told the owner I wasn't completely sure if I could make this work, but he told me to try anyway, and if I couldn't get the ASP to work, maybe try to add an ASP.Net site to the classic ASP through IIS.</p>
<p>First step though, was to get the site working on my local environment. I grabbed the code off the server, and set it up on my local IIS. I grabbed a database backup from the server and restored it on my local SQL Server. I pointed my IIS to the code, and changed the config file, and like magic, it all worked. I was browsing around CrimeWeb.</p>
<h3 id="dressed-to-impress">Dressed to impress</h3>
<p>That night after dinner, I wanted to impress my new boss, so I changed into something a little more comfortable, and continued working on the site. </p>
<p>I added the video upload service so that after you added a crime, the UUID was passed to the ASP.Net site, and you uploaded a video, and once it was uploaded to YouTube, the YouTube link was saved back on the crime's database record.</p>
<h3 id="all-that-was-left-was-to-test-it">All that was left was to test it.</h3>
<p>So I logged into my super administrator account, and created a new crime that was going to be limited to my local town of only 30,000 people. The title of the crime was something along the lines of "Suspected Terrorist Attack at First National Bank of Alvin. Alligators are reported fine."</p>
<blockquote>
<p>The bank had Alligators... in the bank... Locally the bank was known as Alligator Bank, and the story us kids all heard is the alligators kept your money safe at night. 
My first bank account was there. My first 3 digits of wealth were accumulated there. 
And after 10 years of saving a quarter here and there, my first $100 withdraw was at their counter, in singles.</p>
</blockquote>
<p>The application errored when saving the crime, and it was too late for me to investigate further.</p>
<h3 id="so-i-went-to-bed">So, I went to bed.</h3>
<p>At around 2 in the morning, I woke up to my phone ringing. I answered, and it was my boss.</p>
<p>He had just spent the last hour on the phone with our partner, and he had just spent the last 2 hours answering phone calls from journalists and city officials from my town... who were apparently customers... who saw my crime posting. I felt sick. I said, there is no way for that to have happened, I edited the config, it is pointing to my local database, my browser says local host. </p>
<p>And then I learned about reverse proxying. It was a term I had never come across, in my many many years (2) of web development. </p>
<p>Apparently hidden away (on the main include file, at the very top), there was code that compared your HTTP_HOST variable to "www1" through "www10" and if it wasn't any of them, it would do a reverse proxy to a random "www1-10". </p>
<p>So while I had configured my site to use my local database server, and I was hosting it on my local IIS, I didn't understand the code well enough to know I wasn't on my local host.</p>
<h3 id="i-should-have-been-fired">I should have been fired</h3>
<p>I apologized profusely to my boss, and asked him if I could at least come and get my things from the office in the morning. I didn't have much, but I had a couple of desk ornaments I had accumulated over the month and a half I had been working there.</p>
<p>He asked what I meant. I said that I assumed I was fired, but he said he couldn't answer that yet, as he wasn't sure what the fall out would be with our customers or our partner. I asked him if there was anything I could do. To which he replied the obvious.</p>
<h3 id="i-could-call-our-partner-and-apologize-for-my-colossal-fuck-up">I could call our partner and apologize for my colossal fuck up</h3>
<p>I steeled myself for the worst phone call I had ever had to make... for no reason. Bob was probably the kindest and most gentle person I'd ever met. He basically chalked it up to a learning experience, told me everyone fucks up. He even gave me a great pro-tip. </p>

<p>Words to live by.</p>
<h3 id="i-wasnt-fired">I wasn't fired</h3>
<p>In fact, I stayed at Humankind for 8 very long and mostly fun years.</p>
<p>Through the ups and downs of the economy.</p>
<p>Through the ups and downs in clients.</p>
<p>And eventually firing all of our clients (or really not taking new ones), and working on our own products.</p>
<p>It was a great place to learn, and grow, and discover who I was and who I could become.</p>

                </div>
            </div>
        </div>
    </article></div>]]>
            </description>
            <link>https://jeremyaboyd.com/post/that-time-i-accidentally-reported-a-fake-terror-incident</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632018</guid>
            <pubDate>Tue, 29 Sep 2020 19:40:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduce data-driven culture to your dev team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631924">thread link</a>) | @necco908
<br/>
September 29, 2020 | https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><img src="https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2-1024x536.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2-1024x536.png 1024w, https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2-300x157.png 300w, https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2-768x402.png 768w, https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><table><tbody><tr><td data-align="left"><strong>TL;DR</strong></td></tr><tr><td data-align="left">-Tailoring the “why” for your metrics differently to different people helps w/ translation<p>-Starting small reduces risk and increases the likelihood of bottom-up adoption&nbsp; </p><p>-Adapting your metrics to company goals can increase business alignment&nbsp;</p><p>-Embedding your use of data into daily rituals can help with stickiness</p></td></tr></tbody></table></figure>



<p>The first time I ever thought about using data to help run my team was in 2015. CloudLock was growing fast and overnight (it felt like) I went from leading a single team of 6 devs to leading 5 teams with 50+ devs combined (as VP of Engineering). </p>



<p>I had no experience dealing with an organization of that size. The processes that had worked for us when we were smaller weren’t scaling for our current size and situation. I was pretty sure I needed to be doing more to help my team but I wasn’t sure what. </p>



<p><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://linearb.io/blog/3-dev-leaders-open-up-about-remote-software-development/" target="_blank">I’m not afraid to ask for help</a> so I hired an agile consultant to come in and talk to our entire team – engineering, product management and UX. She made a huge difference. I’m still using a lot of what I learned from her today. </p>



<p>One of the most common challenges I hear from software development leaders is…</p>



<figure><blockquote><p><strong><em>“I want my team to be more data-driven but I’m not sure where to start.”&nbsp;</em></strong></p></blockquote></figure>



<p>Every time I share how we do things at LinearB I hear <a rel="noreferrer noopener" aria-label="Kara Minotti Becker  (opens in a new tab)" href="https://www.linkedin.com/in/karaminottibecker/" target="_blank">Kara Minotti Becker’s </a>voice in my head. So I figured I better see what she’s doing now. It turns out she is still a software development consultant in high demand. It also turns out I still have a lot to learn from her.&nbsp;</p>



<p>The ideas and videos below come from our Zoom conversation on Friday, April 10th.</p>



<p>After we caught up (she has a 7-year old girl, I’m expecting my first later this month), Kara asked me…</p>



<p><em>What prompted you to reach out to me in 2015?&nbsp;</em></p>



<iframe width="560" height="400" src="https://www.youtube.com/embed/eNv-E5Cougw?rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>



<p>The short answer is, I was in over my head 😀</p>



<p>I asked her what she remembered about our engagement.</p>



<p>She mentioned “You guys were really hungry for understanding the cultural piece of agile. How it helps people work together. Not just how we set the machinery up.”&nbsp;</p>



<p>I remember that too. I’ve always cared about culture. When it comes down to it, as a dev leader, I can’t do anything without great engineers who are driven to help the team. So if I don’t create an environment where talented people want to work, where they feel safe to be themselves, where they can make friends and explore their creativity and learn and have fun… I have no chance to deliver results for the business. I also believe in the power of data. And that’s why I’m passionate about this question.&nbsp;</p>







<h2><strong>What steps can engineering leaders take to get their entire team to buy-in to a data-driven culture?&nbsp;</strong></h2>



<p>Kara and I landed on four key areas.&nbsp;</p>



<h3>1. <strong>Start small and take an agile approach</strong></h3>







<blockquote><p><strong><em>“Engineering leaders need to be careful not to crush their teams under the weight of too many metrics.” </em></strong></p><cite>-Kara</cite></blockquote>







<p>When it comes to a new product or feature, we collect the most important requirements, ship an MVP, collect feedback and iterate over time to make it better. For some reason we forget to take that approach with our internal processes.&nbsp;</p>



<p>If we try to measure too many things from the beginning, we introduce risk. Scope creep. Delays. Loss of momentum. Just like a new feature, the first version of your metrics probably won’t be perfect regardless of how long you take to roll them out. You’re better off shipping something fast because you’ll start learning sooner. </p>



<p>Starting small also gives you a better chance of getting bottom-up support. When you pick 1-2 north star metrics that really represent the main goal for your team, it’s easy for everyone to get on board. Anything more than that increases the likelihood of confusion.&nbsp;</p>







<p><strong><em>PRO TIP:</em></strong> At CloudLock, when I had a new indicator I wanted to measure, I would try it out with a single team to start. After they spent some time using it, I would incorporate their feedback. Not only did this help me work out the kinks before rolling it out broadly, but it also created champions with the team who helped me convince everyone else it was a good idea.&nbsp;</p>







<p>See Kara explain the importance of starting small and iterating.</p>



<iframe width="560" height="400" src="https://www.youtube.com/embed/oUgM1NmPWgM?rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>







<h3>2. <strong>Align your engineering metrics to business objectives&nbsp;</strong></h3>



<p>Obviously the next big question is…</p>



<p><strong><em>What are the most important things I should be measuring?&nbsp;</em></strong></p>



<p>If only it were that easy 🙂&nbsp;</p>



<p>Kara emphasized “There are no standard metrics that all agile teams should measure. It’s all about knowing what your company’s goals are and picking metrics that help you figure out how you’re contributing to that.”&nbsp;</p>



<p>She also believes that what you measure needs to adapt over time as your company’s goals change. “<a href="https://linearb.io/blog/align-engineering-metrics-to-your-business-kpis/" target="_blank" rel="noreferrer noopener" aria-label="If your metrics are not aligned to company goals they are pointless. (opens in a new tab)">If your metrics are not aligned to company goals they are pointless.</a>”&nbsp;</p>



<p>I went through three iterations in 5 years at CloudLock.&nbsp;</p>







<p><strong>Value mode:</strong> Early on the company’s mission was to deliver as much new product value as possible. So for engineering, it was all about speed to value for us. We had a lot of incredible ideas for our product and our job was to implement them as quickly as possible. I was an individual contributor developer for most of this phase and I got promoted to team lead towards the end.&nbsp;</p>



<p>I remember our leadership focusing a lot on velocity during this time – the number of story points each team delivered in each sprint.&nbsp;</p>



<p><strong><em>Disclaimer</em></strong></p>



<figure><div>I think velocity is the most dangerous, most misused metric in software development. It can be useful to inform sprint planning within an individual team. But it should never be shared outside of that team and it should definitely never be used to measure productivity.&nbsp;<p>Our leadership was trying to measure dimensions of our process like speed and efficiency. We probably would have benefited from measuring Cycle Time but back then the ideas and tools didn’t exist to get that data easily. So we settled for what we could measure – things like velocity. </p><p>More on Cycle Time later in this post.</p></div></figure>







<p><strong>Growth mode</strong>: At this point, we had a lot of customers but adding more was still the main goal for the company. We had a bunch of salespeople and they were making commitments to prospects. We had a lot of new marketing people and they had launches and PR announcements. We still needed to ship fast but it was even more important to hit our deadlines. Changing from the mindset of “ship new value as fast as possible” to “ship new value more predictably” was not easy. We were still under pressure to deliver more value but we couldn’t change priorities on the fly anymore.&nbsp;</p>



<p>This phase became all about predictability. By now I was the VP of Engineering. I measured iteration churn (how many items came in and out of the sprint after it started) and the percentage of story points delivered versus committed. These metrics were the best proxies I had to determine our consistency.&nbsp;And, to be clear, we only looked at this data for each team and never published these to the whole org or compared teams against each other using these metrics. </p>







<p><strong>Customer mode:</strong> Eventually we reached the point where 500+ large enterprise customers used our product every day and really relied on it. Keeping them happy became our priority. We brought in a VP of Customer Success. We had a top-line company goal of 90% customer retention year over year. This phase was all about quality.</p>



<p>You might think changing our mindset from predictability to quality would be a little easier than changing from speed to predictability. It was actually harder – for three reasons. First, our org was much bigger at this point so there more people we needed to get buy-in from. Second, going fast feels good to everyone. Devs like it. And the business likes it. Nobody likes being told we need to delay a release even if they know a potential bug can have big consequences. Finally, our most important internal customer changed. In predictability, your main internal customers are still sales and marketing. With quality, your main internal customer becomes customer success and technical support.&nbsp;There were new people we had to get to know. </p>



<p>We measured the number of issues, bugs and outages per release which we called “change failure rate”, as well as mean time to restore and mean time to resolve support tickets.&nbsp;</p>







<p><strong><em>PRO TIP: </em></strong>Looking back on it, we were using a lot of output metrics when we should have been using process metrics. When you focus on an output like how many story points you delivered or how many bugs you had, what do you do when you miss your mark? <a href="https://linearb.io/blog/dev-productivity-is-way-down-at-linearb/">Measuring the process</a> helps you figure out where and how you can improve. And many process metrics are leading indicators of your outputs so measuring them actually helps you predict when you have a problem coming and allows you to do something about it proactively.&nbsp;</p>



<figure><a href="https://linearb.io/wp-content/uploads/2020/04/Cycle-time-after-remote.png"><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png.webp 2493w" sizes="(max-width: 2493px) 100vw, 2493px">
<img src="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png" alt="data-driven culture thrives with the right metrics, like cycle time" srcset="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png 2493w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-300x145.png 300w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-1024x493.png 1024w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-768x370.png 768w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-1536x740.png 1536w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-2048x987.png 2048w" sizes="(max-width: 2493px) 100vw, 2493px">
</picture>
</a></figure>



<p>For example, at LinearB right now, instead of using velocity to measure speed, we look at <a href="https://linearb.io/cycle-time/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Cycle Time</a> which is the time it takes us to deliver new work from first commit to release. By measuring each phase of our cycle, when this metric goes up like it did for us recently after our transition to 100% work-from-home, we know exactly where to focus to get back on track. </p>



<figure><a href="https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition.png"><img src="https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition.png" alt="LinearB Cycle time after going remote. data-driven culture" srcset="https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition.png 1600w, https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition-300x139.png 300w, https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition-1024x476.png 1024w, https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition-768x357.png 768w, https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition-1536x713.png 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></a></figure>







<h3>3. <strong>Translate the “why” behind your metrics to different audiences differently&nbsp;</strong></h3>







<blockquote><p><strong><em>“Members of software development teams, including engineers, are often scare of metrics… who they’re going to be exposed to.”&nbsp;</em></strong></p><cite>-Kara </cite></blockquote>







<p>I think Kara is right. And it’s not just engineers. </p>



<p>When shared in the wrong way, engineering metrics can be confusing to the rest of the business too.&nbsp;</p>



<iframe width="560" height="400" src="https://www.youtube.com/embed/ZAej8aqlx8Q?rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>



<p>“It is true that you have to show executive staff numbers that have meaning at their level.”</p>



<p>But that doesn’t mean we shouldn’t make an effort to teach our business the key aspects of software development.&nbsp;</p>



<p><a href="https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/">As dev leaders we are somewhat caught in the middle</a>. So what can we do?&nbsp;</p>



<p>Context is everything. If you tailor the “why” behind each of your metrics differently for different audiences, you’ll have a better chance to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/">https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631924</guid>
            <pubDate>Tue, 29 Sep 2020 19:30:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA["Know Your Ropes"–Intro to Spinnaker for Financial Services by Armory (YC W17)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631837">thread link</a>) | @drodio
<br/>
September 29, 2020 | https://www.armory.io/blog/know-your-ropes-the-introduction-to-spinnaker-for-financial-services/ | <a href="https://web.archive.org/web/*/https://www.armory.io/blog/know-your-ropes-the-introduction-to-spinnaker-for-financial-services/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                

        <main id="global-main">

                        
                        



<section>
    <div>
        <div id="post-6818">
          
            
            <div><figure><img width="680" height="432" src="https://www.armory.io/wp-content/uploads/2020/09/which-rope-01.gif" alt="" loading="lazy"></figure></div>            <div>
                
                <h2>Introducing “Know Your Ropes” Blog Series</h2>
<p>What does sailing and the Financial Services segment have in common? There are many sailing terms that apply to Financial Services – “Batten down the hatches”, “Hand over fist”, “Loose cannon”, “By and large”, “Know your Ropes”, “A clean bill of health”, and more.</p>
<p>This blog series aim is to focus on the Financial Services industry – Banks, Credit Card Companies, Credit Rating Companies, Financial Services, Insurance, and FinTech Startups.</p>
<p>We will look at real-life examples about how Spinnaker is being used within organizations like the largest U.S. bank, <a href="https://youtu.be/64rhl9sxhSQ">JP Morgan Chase</a> all the way to top-valued fintech, <a href="https://blog.spinnaker.io/future-of-sre-robert-keng-builds-a-deploybot-withspinnaker-70ff3e37c56a">Chime</a> to <a href="https://spinnaker.io/success-stories/">TransUnion</a>, an American consumer credit reporting agency.</p>
<h2>“Know Your Ropes” History</h2>
<p>This idiom originated from shipping. A sailing ship had many ropes that operated the ship’s sails. Sailors had to learn exactly which rope operated each sail and they also had to learn how to tie many different types of knots. When a sailor knew all of this, he “knew the ropes”.</p>
<p>The first known use of the term “Know Your Ropes” comes to us from Richard H. Dana Jr.’s memoir, “Two Years Before the Mast,” in 1840. Old sailing ships had a lot of ropes, and they each had a specific purpose. Those of you who were in Scouts also know the ropes, and realize that most knots have a sailing origin. Today, we use this term when referring to people who are really on top of their game and understand their industry.</p>
<h2>Financial Services Customer Quotes</h2>
<p>“We love the simple command-line interface for administration, integration with multiple platforms, and easy configurability using pipelines.” – <a href="https://www.transunion.com/">TransUnion</a></p>
<p>“We are seeing a significant increase in both frequency and volume of releases with Armory’s integration.” – <a href="https://www.jpmorganchase.com/">JP Morgan Chase</a></p>
<p>“cutting edge! this is where we want to be!” – <a href="https://www.chime.com/">Chime</a></p>
<h2>FinServe Solutions Brief</h2>
<p>The Armory Financial Services Whitepaper is now available! <a href="https://at.armory.io/WEB-FinServe_1Go.html">Download</a> High Yield: Policy-Driven Software Delivery for Financial Services.</p>
<p><a href="https://at.armory.io/WEB-FinServe_1Go.html"><img data-src="https://at.armory.io/rs/644-NAF-166/images/2.jpg" src="https://at.armory.io/rs/644-NAF-166/images/2.jpg"></a></p>
<h2>Sailing Tip</h2>
<p>Sailing is a sport fueled by the wind and the passion of the sailors who take the <a href="https://helm.sh/">helm</a>. Each blog, I’ll plan to include a sailing story, tip, or lesson learned.</p>
<p>The San Francisco Bay is a world-renowned sailing destination. With 25 knots of wind on a regular basis, strong currents, and heavy shipping traffic, the Bay provides the perfect environment for learning to sail.</p>
<p>I have been sailing recreationally in the last few years, but only until the beginning of 2020 did I officially take lessons to get my American Sailing Association license to become a skipper. I won’t be the first and I won’t be the last person, but you really need to “know your ropes” before you go sailing.</p>
<p><a href="https://www.modernsailing.com/">Modern Sailing School &amp; Club</a> provides sailing lessons on San Francisco Bay from the <a href="https://asa.com/">American Sailing Association</a>. In addition to sharing stories from the field, I’ll also share some sailing tips and stories along our journey together.</p>
<p>If you happen to live in the Bay Area or find yourself visiting this year or another time, join Armory on an afternoon sail around the SF Bay. <a href="https://go.armory.io/sail">Sign up</a> if you are interested.</p>
<h2>Keep up to date with Armory</h2>
<p>Get monthly updates and stay up to date with our <a href="https://www.armory.io/blog/">blog</a>.</p>
            </div>
        </div>
    </div>
</section>



<section>
  
</section>
<section>
  <div>
    <div>
      <div>
        <div>

      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/02/LandingPage-opt-01-I-Have-Jenkins-768x196.png" alt=""></p>
  
    
  
    <p>Upcoming Webinar: I have Jenkins, why do I need Spinnaker?</p>
  
    <p>Jenkins has been offloading developers for years by centralizing continuous integration (CI). Over time, developers have been tasked with understanding and coding for different cloud and Kubernetes deployment targets instead of just writing great code. Find out how Spinnaker has again offloaded the developer from that cognitive thinking and accelerated innovation and time to market. […]</p>
  
  
</div>
      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/09/working-from-anywhere-768x70.png" alt=""></p>
  
    
  
    <p>Working from anywhere: Living Armory's remote-first culture</p>
  
    <p>The future of work looks very different than it did just a year ago, pre-COVID. Armory has embraced and extended our strong remote culture to become a remote-first company, which means that although we have a physical HQ in San Mateo, CA, we don’t require anyone to be in a physical office, and that HQ […]</p>
  
  
</div>
      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/09/spring-el.png" alt=""></p>
  
    
  
    <p>Upcoming Webinar: SpEL (aka Pipeline Expressions) Tips and Tricks</p>
  
    <p>Learn some best practices and tips and tricks for using Spinnaker’s Pipeline expressions (otherwise known as the Spring Expression Language or SpEL). Whether you are new to Spinnaker or an intermediate user wanting to learn how to empower your pipelines to do more, this session will cover the basics of getting started with Pipeline Expressions, […]</p>
  
  
</div>
  
        </div>
      </div>
    </div>
  </div>
</section>


        </main>

        

        </div></div>]]>
            </description>
            <link>https://www.armory.io/blog/know-your-ropes-the-introduction-to-spinnaker-for-financial-services/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631837</guid>
            <pubDate>Tue, 29 Sep 2020 19:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Configuration for Reusability in Vue]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631795">thread link</a>) | @michaelthiessen
<br/>
September 29, 2020 | https://michaelnthiessen.com/using-configuration-for-reusability/ | <a href="https://web.archive.org/web/*/https://michaelnthiessen.com/using-configuration-for-reusability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  <iframe src="https://player.vimeo.com/video/456391976" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
</p>
<p><em>This is an excerpt of my upcoming course, <a href="https://michaelnthiessen.com/reusable-components">Reusable Components</a>, which will be released on November 3!</em></p>
<p>In Module 3 of Reusable Components we cover the second <a href="https://michaelnthiessen.com/6-levels-of-reusability">level of reusability</a>, Configuration.</p>
<p>Configuration is all about using props to allow for variations in how a component works (you're likely doing some form of this already). For example, instead of writing an entirely new component for each type of button, you can add in a <code>type</code> prop that allows you to switch between the different styles.</p>
<p>In this video we also go over <strong>configuration props</strong> and <strong>state props</strong>, and how they're different.</p>
</div><div data-v-17f0bb0f=""><h2 data-v-17f0bb0f="">Most Popular</h2><!----><div data-v-17f0bb0f=""><a href="https://michaelnthiessen.com/6-levels-of-reusability/" data-v-17f0bb0f=""><h3 data-v-17f0bb0f="">
        The 6 Levels of Reusability
      </h3></a><p data-v-17f0bb0f="">June 2020</p><p data-v-17f0bb0f="">We all want to write less code, but get more done. To make this happen, we build our components so they can be reused more than just once.</p></div><div data-v-17f0bb0f=""><a href="https://michaelnthiessen.com/underdog-framework/" data-v-17f0bb0f=""><h3 data-v-17f0bb0f="">
        The Underdog Framework
      </h3></a><p data-v-17f0bb0f="">January 2020</p><p data-v-17f0bb0f="">If React is so much more popular than Vue, wouldn't it be better to just stick with that? There are 3 specific things here I'd like to cover: 1. Growth of the framework itself (innovation) 2. Career opportunities 3. Ease of learning/getting better</p></div><div data-v-17f0bb0f=""><a href="https://michaelnthiessen.com/most-important-feature-vue/" data-v-17f0bb0f=""><h3 data-v-17f0bb0f="">
        The Most Important Feature in Vue
      </h3></a><p data-v-17f0bb0f="">November 2019</p><p data-v-17f0bb0f="">I've said it before and I'll say it again: Computed properties are the most important feature in Vue. Sure, scoped slots let you create some nice abstractions and watchers are useful too. But I don't think anything comes close to how valuable computed props are.</p></div></div></div>]]>
            </description>
            <link>https://michaelnthiessen.com/using-configuration-for-reusability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631795</guid>
            <pubDate>Tue, 29 Sep 2020 19:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A request to a YouTube video downloads the title 14 times and displays it twice]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24631698">thread link</a>) | @anderspitman
<br/>
September 29, 2020 | https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice | <a href="https://web.archive.org/web/*/https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <div>
              <p>I have a project idea that could involve doing some scraping of YouTube videos, so I started poking
around the HTML output of curling YT links. These things are a site (sp) to behold. If you curl the following
well-known URL and store it in a file:</p>
<p><code>https://www.youtube.com/watch?v=dQw4w9WgXcQ</code></p>
<p>Just searching for the title yields 14 results, spread throughout random HTML and JS. But it's only actually
displayed to the user once on the page, and probably again in the browser tab. It's not just the title
either, there's a ton of duplicated data and bloat throughout the file. I'm guessing it compresses well. I
checked a few other files and they all had between 10 and 18 copies of the title.</p>
<p>I'm not sure what conclusions to draw from this. A lot of them are obviously intended to be
machine-readable for things like <a href="https://ogp.me/">ogp</a>, but do you really need 14 identical copies?</p>
<p>EDIT:</p>
<p>Since this errant observation somehow made it to the <a href="https://news.ycombinator.com/item?id=24631698">Hacker News front page</a>, and eventually got flagged, I have a few more thoughts:</p>
<ul>
<li><p>Sorry the title ended up more clickbatey than intended. It's not making 14 extra HTTP requests just for the title. It originally started with "An HTTP request" but it was a few characters too long for HN, and I didn't spend much time rethinking it.</p>
</li>
<li><p>I agree the extra text isn't a problem (like I said, that'll compress well). I'm more concerned about the underlying complexity it signals. There is more obvious evidence of this complexity (it makes 70 network requests when you load the page even if you pause the video immediately), this is just a novel one for me.</p>
</li>
<li><p>I appreciate the copies which are intended to interoperate with other systems like Twitter and OGP.</p>
</li>
<li><p>I actually appreciate the fact that a JSON blob of all the video metadata is embedded in the HTML. It'll make my scraping task much simpler.</p>
</li>
</ul>

            </div>
          </div></div>]]>
            </description>
            <link>https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631698</guid>
            <pubDate>Tue, 29 Sep 2020 19:08:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How real-time stream processing works with ksqlDB, animated]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631670">thread link</a>) | @mjdrogalis
<br/>
September 29, 2020 | https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><section><div><p><time datetime="2020-09-29T17:50:00.000Z">September 29, 2020</time></p><div><div data-swiftype-name="body" data-swiftype-type="text"><p><a href="http://ksqldb.io/">ksqlDB</a>, the event streaming database, is becoming one of the most popular ways to work with Apache Kafka<sup>®</sup>. Every day, we answer many questions about the project, but here’s a question with an answer that we are always trying to improve: How does ksqlDB work?</p>
<p>The mechanics behind stream processing can be challenging to grasp. The concepts are abstract, and many of them involve motion—two things that are hard for the mind’s eye to visualize. Let’s pop open the hood of ksqlDB to explore its essential concepts, how each works, and how it all relates to Kafka.</p>
<p>If you like, you can follow along by executing the example code yourself. <a href="https://ksqldb.io/quickstart.html">ksqlDB’s quickstart</a> makes it easy to get up and running.</p>
<div>
<h2 id="declaring-a-stream"><a id="declaring-a-stream"></a>Declaring a stream</h2>
<p>Stream processing is a programming paradigm for computing over events as they arrive. But where do those events come from? In Kafka, you store a collection of events in a <em>topic</em>. Each event can contain any raw bytes that you want. In ksqlDB, you store events in a <em>stream</em>. A stream is a topic with a strongly defined schema. You declare it like this:</p>
<pre><code>
CREATE STREAM readings (
    sensor VARCHAR KEY,
    location VARCHAR,
    reading INT
) WITH (
    kafka_topic = 'readings',
    partitions = 3,
    value_format = 'json'
);
</code></pre>
<p>When you fire off this statement from ksqlDB’s client to its server, what actually happens? If the topic that backs this stream doesn’t exist, the server issues a call to the Kafka brokers to make a new topic with the specified number of partitions. The stream metadata, like the column layout, serialization scheme, and other information, is placed into ksqlDB’s command topic, which is its internal cluster communication channel. Each ksqlDB server materializes the command topic information to a local metadata store, giving it a global catalog of objects.</p>
<p>A newly declared stream has no data in it:</p>

</div>
<div>
<h2 id="inserting-rows"><a id="inserting-rows"></a>Inserting rows</h2>
<p>Empty collections aren’t terribly interesting. You need to write events to them to make something happen. In Kafka, you model an event as a <em>record</em> and put it into a topic. In ksqlDB, you model an event as a <em>row</em> and put it into a stream. A row is just a record with additional metadata. You <em>insert</em> rows like this:</p>
<pre><code>
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-1', 'wheel', 45);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-2', 'motor', 41);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-1', 'wheel', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-3', 'muffler', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-3', 'muffler', 40);

INSERT INTO readings (sensor, location, reading) VALUES ('sensor-4', 'motor', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-6', 'muffler', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-5', 'wheel', 41);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-5', 'wheel', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-4', 'motor', 41);

INSERT INTO readings (sensor, location, reading) VALUES ('sensor-7', 'muffler', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-8', 'wheel', 40);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-9', 'motor', 40);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-9', 'motor', 44);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-7', 'muffler', 41);
</code></pre>
<p>Each time you invoke an <code>INSERT</code> statement, a request with the payload is sent to a ksqlDB server. The server checks that the shape of the data is coherent with respect to the stream’s schema—malformed rows are rejected. If the row’s data types are sane, the server creates a record and automatically serializes its content using the format of choice as defined in the stream’s declaration. It uses the Kafka producer client to insert that record into the backing Kafka topic. All of the stream’s data is persisted on directly on the broker. None of it lives in ksqlDB’s servers.</p>
<p>After the inserts complete, the stream now looks like what you see below. Hover over each row to see its contents—the data displayed describes the underlying Kafka record. Notice how the rows are ordered by offset from right to left. In the animations you’ll see below, time is depicted as flowing rightward.</p>

<p>Why does some of the row data end up in the key of the record and some in the value? ksqlDB superimposes a flat column abstraction on top of Kafka’s key/value model. Here’s how it works in this case.</p>
<p>In the declaration of the stream, <code>sensor</code> is qualified with the <code>KEY</code> keyword. That piece of syntax tells ksqlDB to look for the data for this column in the key portion of the record. The data for other columns is read from the record’s value. When ksqlDB produces the record to the underlying topic, its key content is hashed to select a partition for it to reside in. This causes all rows with the same key to be written to the same partition, which is a useful <a href="https://docs.confluent.io/current/kafka/introduction.html#topics-and-logs">ordering guarantee</a>.</p>
</div>
<div>
<h2 id="transforming-a-stream"><a id="transforming-a-stream"></a>Transforming a stream</h2>
<p>No one ever sends data to Kafka just to let it sit there. You always want to do something with it. And most often, the data isn’t yet in the exact form that you need in order to work with it. You need to change it in some way.</p>
<p>The most elementary way you could do this is by writing a program that uses the Kafka producer and consumer clients. The program would read from the source topic whose data you want to change, apply a function to each record, and write the new record to the output topic. It would loop and run forever. This works, but it is rather low-level. You need to manage schemas, serializers, partitioning strategies, and other pieces of configuration.</p>
<p>In ksqlDB, you issue a <em>persistent query</em> to <em>transform</em> one stream into another using its SQL programming model. You derive a new stream from an existing one by selecting and manipulating columns of interest:</p>
<pre><code>
-- process from the beginning of each stream
set 'auto.offset.reset' = 'earliest';
                
CREATE STREAM clean AS
    SELECT sensor,
           reading,
           UCASE(location) AS location
    FROM readings
    EMIT CHANGES;
</code></pre>
<p>Persistent queries are little stream processing programs that run indefinitely. In this case, it continually reads rows from <code>readings</code>, applies the transformation logic, and writes rows to <code>clean</code>. You are relieved of all data janitorial work: There are no schemas to manage, no serializers to configure, no partitioning strategies to choose. But what is actually happening when you launch this query?</p>
<p>Each time you run a persistent query, ksqlDB’s server compiles the query’s textual representation to a physical execution plan as a Kafka Streams topology. The topology runs as a daemon, reacting to new topic records as soon as they become available. This means that all of the processing work happens on ksqlDB server; no processing work happens on the Kafka brokers. If you run ksqlDB as a cluster, the topology scales horizontally across the nodes by internally using Kafka Streams application IDs.</p>
<p>When everything is connected together and the data is flowing, it looks like this. Take it in for a few moments—we’ll walk through it in detail below.</p>

<p>What is going on here? What do the moving arrows mean? Why are those numbers changing? And what is <code>pq1</code>?</p>
<p>When a persistent query is created, it is assigned a generated name (in this case, we call it <code>pq1</code>). Rows are read from the stream partitions that the query selects from. As each row passes through the persistent query, the transformation logic is applied to create a new row, which is what the change of color signifies. Reading a record from Kafka does not delete it—you effectively receive a copy of it. That is why the leftmost rows remain in place, and clones of them appear to the right of each partition before they are sent to the persistent query box.</p>
<p>Persistent queries completely manage their own processing progression, even in the presence of faults. ksqlDB durably maintains the highest offset of each input partition. The incrementing numbers underneath the query box describe those values at each point in time. Moreover, the arrows that move from right to left on the input streams show the corresponding offsets currently being processed, giving you a spatial sense of progress. (If you’re an experienced Kafka user, note that these aren’t the <em>committed</em> offsets.)</p>
<p>Pause the animation and hover over the output rows. Notice how the column that the transformation targets has changed, while all the other columns remain intact. ksqlDB has taken care of all the bookkeeping for you.</p>
<p>As you watch the data flowing through the topology, you might be wondering how ksqlDB chooses which input partition it will read from next. Is it random? Is it round robin? The answer to that question is the foundation of how ksqlDB deals with out-of-order data, and it’s something that we’ll describe in a future blog post all on its own. (Spoiler: <a href="https://www.confluent.io/resources/kafka-summit-2020/the-flux-capacitor-of-kafka-streams-and-ksqldb">It picks the smallest timestamp available</a>.)</p>
</div>
<div>
<h2 id="filtering-rows-out-of-stream"><a id="filtering-rows-out-of-stream"></a>Filtering rows out of a stream</h2>
<p>Let’s look at another simple operation: filtering. Filters are used to discard rows that you do not need or want. Just like transforms, filters are specified using simple SQL syntax.</p>
<pre><code>
CREATE STREAM high_readings AS
    SELECT sensor, reading, location
    FROM clean
    WHERE reading &gt; 41
    EMIT CHANGES;
</code></pre>
<p>When you write ksqlDB programs, you chain streams (and tables) together. You create a figurative pathway for your data to traverse, with each step in the way performing a step of processing. ksqlDB handles the mechanics of how your data is propagated through the chain.</p>

<h2 id="combining-many-operations"><a id="combining-many-operations"></a>Combining many operations into one</h2>
<p>A crucial rule of thumb in data processing is that you should get rid of data that you don’t need as early as possible. The longer you keep irrelevant data around, the higher the cost to repeatedly store, process, and transfer it. If you use the Kafka client to process data, it is up to you to manage where each processing step takes place.</p>
<p>In…</p></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/">https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631670</guid>
            <pubDate>Tue, 29 Sep 2020 19:06:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Kubernetes Services and Ingress Networking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631671">thread link</a>) | @anishdhar
<br/>
September 29, 2020 | https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking | <a href="https://web.archive.org/web/*/https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the previous<a href="https://www.getcortexapp.com/post/understanding-kubernetes" target="_blank"> article</a>, we looked into the basics of Kubernetes and setting up and running Kubernetes in a local machine. There we had briefly discussed Kubernetes objects called Services. Services are Kubernetes resources that enable network access to Pods. In this article, we will look deeply into the concepts of Kubernetes Services and its different types. We will also look into Kubernetes Ingress, which is not a service but is another way of routing traffic to your services and your cluster.</p><h3><strong>Kubernetes Services</strong></h3><p>As we know, a Kubernetes cluster consists of a set of node machines, running containerized applications inside objects named <em>Pods</em>. The pods are grouped based on the type of service they provide into various groups. Pods must be able to accept connections in some way, from your cluster or from outside your cluster.</p><p>In the case of external access, we know that pods inside the cluster are present inside an internal pod network and cannot be accessed by the node’s IP address. A user should be able to communicate with the application using the IP address of the node.&nbsp;</p><p>In the case of internal communication, we know that each pod in the system is assigned with its own unique IP known as Pod IP. But these IPs are not static, as we know the pods can go down any time and new pods are created all the time in a cluster. So we cannot rely on these IPs for Internal communication.</p><p>So we need something that is consistent so that things outside or inside the cluster might be able to access it persistently. A <strong>Service</strong> is a Kubernetes object that acts as an endpoint for enabling the communication between various components within and outside the application. In other words, a service is a stable address for pods. The three important Service types in Kubernetes are:</p><ol role="list"><li>ClusterIP</li><li>NodePort</li><li>LoadBalancer</li></ol><h4><strong>ClusterIP</strong></h4><p>A full-stack web application typically is made up of different kinds of pods hosting different parts of the application. It may have a set of pods running a backend server, a set of pods running the front-end web server and a set of pods running a database, and so on. All these sets of pods need to communicate with each other. As we discussed, we can’t depend on the IP addresses of pods, since they are not static.</p><p>ClusterIP is a Kubernetes service type that is used to group pods together and provide a single interface to access them. For example, an incoming request by another service will be forwarded to one of the pods in the ClusterIP randomly.</p><p>Now let’s look at an example. Before creating the ClusterIP service we can start by creating a simple pod based on a definition file.</p><p><em>front-end-pod-definition.yml</em></p><blockquote>apiVersion: v1<br>kind: Pod<br>metadata:<br> name: myapp-pod<br> labels:<br> &nbsp; app: myapp<br> &nbsp; type: front-end<br>spec:<br> containers:<br> &nbsp; - name: nginx-container<br> &nbsp; &nbsp; image: nginx</blockquote><p>As we can see our pod is simply a container that has the Nginx web server behind it. We have added labels <em>app</em> and <em>type</em>. Pod will be grouped into the type front-end. Next, we need to run the create command to create the pod.</p><blockquote>kubectl create -f frontend-pod-definition.yml</blockquote><p>Let's look at the ClusterIP service definition:</p><p><em>fe-clusterip-service-definition.yml</em></p><blockquote>apiVersion: v1<br>kind: Service<br>metadata:<br> name: front-end-service<br>spec:<br> type: ClusterIP<br> selector:<br> &nbsp; app: myapp<br> &nbsp; type: front-end<br> ports:<br> &nbsp; - targetPort: 80<br> &nbsp; &nbsp; port: 80</blockquote><p>The Service definition has type as ClusterIP (it's not mandatory, as by default services are of kind ClusterIP). We can see that we have used the selector to link the service to a set of pods. Under ports, we have a target port and port.&nbsp;</p><p>The <strong>target port</strong> is the port where the front-end service is exposed which in this case is 80 and the <strong>port</strong> is where the ClusterIP service is exposed which is also 80.</p><p>Now we can create the service by the create command.</p><blockquote>kubectl create -f clusterip-service-definition.yml</blockquote><p>Let’s look at the service created</p><figure><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5f6bc5225587b6be7c95e156_i9voFNRyRthFr7g2dH40vaqeQNw7srlhOe4BlZKsWJBlBZrw1lQdb6hmio0_vxDbohpPx_qdCNZHTV3KcsXhPb1fNYLCrN-QHIlusoMKlOhSmvW3ov44pDqbL377PWbZQT6hb3g.png" alt=""></p></figure><p>We can see that in addition to the default Kubernetes ClusterIP a new ClusterIP of the name <em>front-end-service</em> is created with an IP address. The name of the service can be used by other pods to access it.</p><h4><strong>NodePort</strong></h4><p>NodePort is a Kubernetes service type that listens on a port on the node and forward requests on that port to a pod on the node. Let's look at an example.&nbsp;</p><ul role="list"><li>We have a node with IP address <em>10.1.3.4</em>.&nbsp;</li><li>The internal pod network of the node is in the range 10.244.0.0</li><li>The pod itself has an IP of 10.244.0.2.&nbsp;</li><li>The actual web server is running on port 80 in the pod.&nbsp;</li></ul><p>Essentially, we want to forward requests coming to 10.1.3.4 to the pod.</p><p>When we create a NodePort service, the service is assigned a high port on all nodes. When a request comes in for <em>node:port</em>, it will act as a built-in load balancer and send the request to one of the pods at random.</p><p>Let’s create a NodePort service to forward the incoming request to the node to port 80 of the pod. Let’s start by creating a service definition:</p><p>nodeport-service-definition.yml</p><blockquote>apiVersion: v1<br>kind: Service<br>metadata:<br> name: myapp-service<br>spec:<br> type: NodePort<br> selector:<br> &nbsp; app: myapp<br> &nbsp; type: front-end<br> ports:<br> &nbsp; - targetPort: 80<br> &nbsp; &nbsp; port: 80<br> &nbsp; &nbsp; nodePort: 32593</blockquote><p>We can see three values in the ports section.&nbsp;</p><p><strong>targetPort</strong>: The port on the pod where the actual web server is running, that is 80 in this case. Service forwards the requests to the target port. If no ports are provided in the spec, it will default to 80</p><p><strong>port</strong>: Like all Kubernetes objects, the Service is a virtual server inside the node. Inside the cluster, it will have its own IP address. The ‘port’ is the port exposed to the NodePort service itself. This value is mandatory.</p><p><strong>nodePort: </strong>The port on the node which is used to access the web server externally. These ports can only be in a valid range from 30000 to 32767. This is not a mandatory field, if it is not provided a free port from the range is selected.</p><p>Now we can create the service by the command,</p><blockquote>kubectl create -f nodeport-service-definition.yml</blockquote><p>Let's check if the service is created.</p><figure><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5f6bc522c1dac43f794be000_AIDxqYyNHBc2JxSPheW8ML0VJVtHeUW6PN6kSD0u-LShhTA4_2oZTcPs9N7nYvjIcJg_--8EYDoPyFO-xqmjPavONwZo9Uee4JKd8Jan3nNJg1M8xPSOCEJsoQabVJuFqT4VLXM.png" alt=""></p></figure><p>Let's try to access the service using the IP of the node</p><p>Since I am using Minikube, the IP of the node is different from the local IP of the system. To get that value, type the command below&nbsp; in the terminal</p><blockquote>minikube ip</blockquote><p>Let's use curl to access the app using the NodePort in this IP</p><blockquote>curl 192.168.99.101:32593</blockquote><figure><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5f6bc5224d5a3d39180e7560_Xphy_GvMOUKXeCtxr8yqhjNzsjqB9Ud_3LsLCtTmoooC6Q8oZmRHWvm2NxoWczFNJG2CMlNy9_Rl-ApmBicvvTffdy-V_ip1pluzFWqDl3_5SSWHaMMv_hbiewo8ZC9X6C7dHC8.png" alt=""></p></figure><p>Great! We got a response from the pod.</p><h4><strong>LoadBalancer</strong></h4><p>Using nodePort we were able to expose our web app to the internet. However, there’s a problem - multiple instances of the web app can be deployed across multiple nodes in our cluster. To access this web app, we’d need to provide both a node IP and the node port to the user. In real life, it’s difficult to determine which node IP and node port should be provided to the user, manually. Instead, we need to have a load balancer to expose our web app to the internet.</p><p>A LoadBalancer is a service that provides (as you may have guessed) a load balancer for our application, in supported cloud providers. The service becomes accessible through a provided load balancer service. Most cloud providers like AWS, GCP, Azure offer this functionality. Once you create a service of type LoadBalancer, cloud providers will create a load balancer in the backend and generate a public IP address. This public IP can be used to access our web app from the public internet.</p><p>This is the standard way to directly expose a service to the Internet. It is similar to the NodePort where all the traffic on the port we specify will be forwarded to the service. Almost all kinds of traffic like HTTP, TCP, UDP, Websockets, gRPC etc can be sent to this service.</p><p>Let's look at an example definition file:</p><blockquote>apiVersion: v1<br>kind: Service<br>metadata:<br> name: my-service<br>spec:<br> selector:<br> &nbsp; app: myapp<br> type: LoadBalancer<br> ports:<br> &nbsp; - nodePort: 31000<br> &nbsp; &nbsp; port: 80<br> &nbsp; &nbsp; targetPort: 9376</blockquote><p>We can see that this is almost the same as a NodePort definition file.</p><p>Let's create the service with create command</p><blockquote>kubectl create -f load-balancer-service-definition.yml</blockquote><p>Now let's look at the service that got created using the command.&nbsp;</p><blockquote>kubectl get services</blockquote><figure><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5f6bc522e9914240281c4d1a_I27mI6NbO5gl6KqJFVQ0zJTr8t7r5aV43JKZEGNtfUkG_XXarnt1_RavpLnhhL66aDErRKDQemO728-Uog59_xwdOhUGwbuUU9c6gncjaDP43Aq71OVTM13Oq6GzRCao3bnrlB0.png" alt=""></p></figure><p>You can see that since I am using Minikube the value of the external IP is shown as &lt;pending&gt;. However, in an actual cloud setup, the IP will be generated and can be used to access the application. This is the IP that can be used by our users to access our web app from the internet.</p><h3><strong>Ingress Networking</strong></h3><p>We have seen in the Kubernetes services sections on how to expose our application to the outside world using the NodePort and LoadBalancer. If we only have to have a single service port we can use NodePort. In the case of multiple instances of the same service, we have to use the LoadBalancer.&nbsp;</p><p>But what if we have to add one more service to our node and access it from another URL. In this case, we will have to add another load balancer to our cluster. This means that each service exposed with a LoadBalancer will get its own IP address and we will have to pay for each of these load balancers which can be quite expensive.</p><p>An Ingress is used when we have multiple services on our cluster and we want the user request routed to the service based on their path. Consider an example, I have two services foo and bar in our cluster. When we type<a href="http://www.example.com/foo"> www.example.com/foo</a> we should be routed to the foo service and <a href="http://www.example.com/bar">www.example.com/bar</a> should be routed to bar service. These routings will be performed by an Ingress. Unlike NodePort or LoadBalancer, Ingress is not actually a type of service. Instead, it is an entry point that sits in front of multiple services in the cluster. It can be defined as a collection of routing rules that govern how external users access services running inside a Kubernetes cluster.</p><p>Ingress is most useful if you want to expose multiple services under the same IP address, and these services all use the same L7 protocol (typically HTTP). You only pay for one load balancer if you are using the native GCP integration, and because Ingress is “smart” you can get a lot of features out of the box (like SSL, Auth, Routing, etc)</p><p>Ingress can be considered as the best way to expose multiple services under the same IP. Also, we should only pay for a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking">https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking</a></em></p>]]>
            </description>
            <link>https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631671</guid>
            <pubDate>Tue, 29 Sep 2020 19:06:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We built an app to fix our own meeting fatigue]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24631659">thread link</a>) | @tylertreat
<br/>
September 29, 2020 | https://witful.com/our-story/ | <a href="https://web.archive.org/web/*/https://witful.com/our-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="4a8b33e4" data-element_type="section">
						<div>
							<div>
					<div data-id="4f865481" data-element_type="column">
			<div>
							<div>
						<div data-id="5c040c31" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div>
<h2><strong>How we built an app to fix our own meeting fatigue</strong><img loading="lazy" src="https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-1024x374.png" alt="" width="580" height="212" srcset="https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-1024x374.png 1024w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-300x109.png 300w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-768x280.png 768w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-1536x561.png 1536w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-1200x438.png 1200w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution.png 1918w" sizes="(max-width: 580px) 100vw, 580px"></h2>


<p>We’re not building a generic notes app. We’re also not building an app for everyone. We are building a product that reduces the cognitive load for people with lots of meetings. Something that enables people with lots of context switching to ensure they don’t miss follow-ups. Something that makes relevant information immediately accessible. We care about being on point in our meetings. This means clearing away all the clutter and noise to help us be prepared and focused.</p>


<p>The idea for Witful started when I was managing a large team of people. I believe one-on-one meetings are a crucial part of being an effective manager, and I take lots of notes in my one-on-ones. I like to track what is happening with my coworkers and reports because it allows me to better support them. As I was managing larger and larger teams across diverse products and projects, I noticed how difficult it was to keep this all organized and feel in touch with my teams.</p>


<p>When we started <a href="https://realkinetic.com/">Real Kinetic</a>, I focused on&nbsp;the administrative tasks of starting and running a consulting business in addition to being responsible for our business development and sales. I quickly realized that the same need existed in these roles. I was in several meetings with various attorneys and accountants each week. I was on calls with multiple clients and sales prospects daily. I was on calls with our team internally. <em>I was constantly switching contexts, jumping from one meeting to the next.</em></p>


<p>Then, in an effort to develop leads and grow our client base, I started developing relationships with investors and other networkers. This added a new level of complexity to my note organization because I wanted to associate notes from these calls with that person, but also with other clients. I tried every note-taking solution on the market and none met my needs.</p>


<p>After a lot of fruitless searching for the right solution, I began sketching mockups on my whiteboard. These sketches quickly evolved into code, resulting in a simple prototype that let me play with the idea. It was immediately obvious that it was something worth pursuing.</p>


<p>In early 2019, we decided to have Alex dedicate time to build out the prototype. He translated the rough prototype into a usable product by the end of August 2019. Mike, Tyler, Nick, and myself started using Witful in our day-to-day consulting work. The value of our idea was clear, and we started getting excited. I showed Witful to my wife who was responsible for project management and managing client relationships at a software development consulting group. In her role managing a large number of client and internal relationships, the value of the product was even more apparent. After a couple weeks of using it, she came home and told me, “I no longer stress missing follow-ups because they’re just there.”</p>


<p>We decided to invest in developing the product and hired Coury to accelerate development. Through the fall, Coury and I worked to build and deploy features that helped us, as actual users, do our <em>real jobs</em> more efficiently.&nbsp;</p>


<p>We have continued to both add and remove features as we iterate on the product. We are constantly finding that some features seem like clear and certain must-haves, but after they have been implemented everyone uses it for a day and then never again. We realized smart organization, intelligent layout, intuitive user experience, and search are far more important than one-off home run features.</p>


<p>What has been most exciting for me is seeing how seemingly minor additions, revisions, and touches have been the most impactful to the experience.</p>


<p>We’re real users of our product and we’re excited to share it with you. We are hopeful that Witful can improve your work and restore sanity to your day as it has for us. Our vision for Witful is to build the product that lets you be brilliant at what you do.</p>
<p><img loading="lazy" src="https://witful.com/wp-content/uploads/2020/09/2020-09-24-171018_570x266_scrot-300x140.png" alt="" width="176" height="82" srcset="https://witful.com/wp-content/uploads/2020/09/2020-09-24-171018_570x266_scrot-300x140.png 300w, https://witful.com/wp-content/uploads/2020/09/2020-09-24-171018_570x266_scrot.png 570w" sizes="(max-width: 176px) 100vw, 176px"></p>


<p>– Robert&nbsp;&nbsp;</p>
</div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section></div>]]>
            </description>
            <link>https://witful.com/our-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631659</guid>
            <pubDate>Tue, 29 Sep 2020 19:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swallowing the Elephant (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631637">thread link</a>) | @noch
<br/>
September 29, 2020 | https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html | <a href="https://web.archive.org/web/*/https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Walt Disney Animation Studios (WDAS) has just given the rendering research
community an incredible gift with their release of the <a href="https://www.disneyanimation.com/technology/datasets">full scene
description for the island from
<em>Moana</em></a>.  Between
geometry and textures, it’s just over 70 GB of data on disk for a single
frame, making it a stellar example of the degree of complexity that
production rendering deals with today; never before have rendering
researchers and developers outside of film studios been able to
work with realistic production scenes like this.</p>

<p>Here’s a rendering of it with today’s pbrt:</p>

<p><img src="https://pharr.org/matt/blog/images/pbrt-moana-island.jpg"> Moana
<i>island rendered with <a href="https://github.com/mmp/pbrt-v3">pbrt-v3</a> at 2048x858 resolution
with 256 samples per pixel.  Total rendering time using a 12 core / 24
thread Google Compute Engine instance running at 2 GHz with the latest
version of pbrt-v3 was 1h 44m 45s.</i></p>

<p>It was a huge amount of work on Disney’s side to extract the scene from
their internal scene representation and convert it to a format that’s
generally accessible; major props to them for taking the time to package
and prepare this data for widespread use.  I’m confident that their work to
do this will be well repaid in the future as researchers use this scene to
dig into the issues related to efficiently rendering scenes of this
complexity.</p>

<p>This scene has already taught me a lot and has made pbrt a better renderer,
but before we get into that, first a little story for context.</p>

<h2 id="the-hash-table-that-wasnt">The hash table that wasn’t</h2>

<p>Years ago while interning in the rendering group at Pixar, I learned an
important lesson: “interesting” things almost always come to light when a
software system is given input with significantly different characteristics
than it’s seen before.  Even for well-written and mature software systems,
new types of input almost always expose heretofore unknown shortcomings in
the existing implementation.</p>

<p>I first learned this lesson while <em>Toy Story 2</em> was in production.  At some
point, someone noticed that a surprising amount of time was being spent
parsing the RIB scene description files.  Someone else in the rendering
group (I believe it was Craig Kolb) whipped out the profiler and started
digging in.</p>

<p>It turned out that most of the parsing time was spent doing lookups in a
hash table that was used to <a href="https://en.wikipedia.org/wiki/String_interning">intern
strings</a>.  The hash table
was a small fixed size, perhaps 256 elements, and it used chaining when
multiple values hashed to the same cell.  Much time had passed since the
hash table was first implemented and scenes now had tens of thousands of
objects, so naturally such a small hash table would quickly fill and become
ineffective.</p>

<p>The expedient thing to do was to just make the hash table larger—all this
was happening in the thick of production, so there was no time to do
something fancy like make the hash table grow as it filled up.  One line
change, rebuild and do a quick test before committing, and… no
performance improvement whatsoever.  Just as much time was being spent on
hash table lookups.  Fascinating!</p>

<p>Upon further digging, it was discovered that the hash function that was
being used was the equivalent of:</p>

<div><pre><code>int hash(const char *str) {
    return str[0];
}
</code></pre>
</div>

<p>(Forgive me Pixar, if I’ve posted super-secret RenderMan source code
there.)</p>

<p>The “hash” function had been implemented in the 1980s, at which time
someone had apparently decided that the computational expense of actually
incorporating some contribution from all of the characters in the string in
the hash value wasn’t worth it.  (And if you’ve only got a handful of
objects in the scene and a 256 entry hash table, maybe, I guess.)</p>

<p>Another historic implementation detail added insult to injury: once Pixar
started making movies, the names for objects in scenes had grown fairly
long, along the lines of “BuzzLightyear/LeftArm/Hand/IndexFinger/Knuckle2”.
However, some earlier phase of the production pipeline used a fixed-size
buffer for storing object names and would shorten any longer names, keeping
only the end and helpfully adding a few periods to show that something had
been lost: “…year/LeftArm/Hand/IndexFinger/Knuckle2”.</p>

<p>Thence, all of the object names the renderer saw were of that form, the
hash function hashed all of them to the bucket for ‘.’, and the hash table
was actually a big linked list.  Good times.  At least the fix was simple
once all that was figured out.</p>

<h2 id="an-intriguing-invitation">An intriguing invitation</h2>

<p>That lesson came to mind last year when Heather Pritchett and Rasmus
Tamstorf from WDAS reached out to me and asked if I was interested in
helping make sure that the <em>Moana</em> scene would render reasonably well with
<a href="https://pbrt.org/">pbrt</a>.<sup id="fnref:ptex"><a href="#fn:ptex">1</a></sup> Naturally I said yes.  I was delighted to
help out and curious to see how it’d go.</p>

<p>The foolish optimist in me was hopeful that there wouldn’t be any huge
surprises—after all, pbrt was first released around 15 years ago and many
people have used it and studied the code over the years.  It should be safe
to assume there weren’t any embarrassments like RenderMan’s old hash
function, right?</p>

<p>Of course, the answer is “wrong”.  (And that’s why we’re here today, and
for a few more posts after this one.)  While I was a little disappointed
that pbrt wasn’t awesome out of the box, I think that my experience working
with the <em>Moana</em> scene is a first validation of the value of having this scene
available; pbrt is already a better system from my having dug into how it
performed with it.</p>

<h3 id="first-renderings">First renderings</h3>

<p>I immediately downloaded the scene once I had access to it (waiting a few
hours for it to make its way over my home Internet connection) and untarred
it, giving me 29 GB of pbrt files and 38 GB of <a href="http://ptex.us/">ptex</a>
texture maps<sup id="fnref:size"><a href="#fn:size">2</a></sup>.  I threw caution into the wind, and tried to render it
on my home system (feat. 16 GB of RAM and a 4 core CPU).  I came back a
little while later to find the computer unresponsive, all of the RAM used,
and pbrt still trying to finish parsing the scene description.  The OS was
doing its best to make it happen with virtual memory, but it seemed
hopeless.  After killing the job, it was still about a minute before the
system was responsive again.</p>

<p>Next up was a Google Compute Engine instance, allowing for more RAM (120 GB)
and more CPUs (32 threads on 16 CPUs).  The good news is that pbrt could
successfully render the scene (thanks to Heather and Rasmus’s efforts
to get it into pbrt’s format). Seeing that pbrt could generate reasonable
pixels for feature film content was thrilling, but the performance was
something else: 34m 58s just to parse the scene description, with memory
use upward of 70 GB during rendering.</p>

<p>Now, it was 29 GB of pbrt scene description files on disk to parse and turn
into something that could be rendered, so I wasn’t expecting a ten second
startup phase.  But half an hour before rays start being traced? That’s bad
enough to make it fairly difficult to work with the scene at all.</p>

<p>One good thing about seeing that sort of performance is that it seemed very
likely that there’s some really stinky stuff going on; not just “matrix
inversion could be made 10% faster”, but “oops, we’re walking through a
100,000 element linked list”. I was optimistic that it’d be possible to
chop that down significantly once I understood what was happening.</p>

<h3 id="no-help-from-the-statistics">No help from the statistics</h3>

<p>The first place I looked for insight was the statistics that pbrt dumps out
after rendering. pbrt’s major phases of execution are instrumented so that
rough profiling data can be gathered by recording what’s actually running
at periodic interrupts during rendering.  Unfortunately, the statistics
didn’t explain much: of the nearly 35 minutes before rendering started, 4m
22s was reported to be spent building BVHs, but none of the rest of the
time was accounted for in any further detail.</p>

<p>Building BVHs is the only meaningful computational task that happens during
scene parsing; everything else is essentially just deserializing shape and
material descriptions.  Knowing how much time was spent on BVH construction
gave a sense of how (in)efficient the system was: what’s left is roughly
30 minutes to parse 29 GB of data, or about 16.5 MB/s.  Well-optimized JSON
parsers, which perform essentially the same task, seem to run at the rate
of 50-200 MB/s, which validates the sense that there’s room for
improvement.</p>

<p>To better understand where the time was going, I ran pbrt using the Linux
<a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> tool, which I’d
never used before, but seemed like it would do the trick.  I did have to
instruct it to actually look at the DWARF symbols to get function names
(<code>--call-graph dwarf</code>), and had to dial down the sampling frequency from
the default 4000 samples per second to 100 (<code>-F 100</code>) so I didn’t get 100
GB trace files, but with that, things were lovely, and I was pleasantly
surprised that the <code>perf report</code> tool had a nice curses interface.</p>

<p>Here’s what it had to say after a run with pbrt as it was at the start of
all this:</p>

<p><img src="https://pharr.org/matt/blog/images/perf-screenshot.png">
<i>I'm actually serious about “nice curses interface”.</i>
</p>

<p>We can see that over half of the time was spent on the mechanics of
parsing: <code>yyparse()</code> is the parser generated by
<a href="https://www.gnu.org/software/bison/">bison</a> and <code>yylex()</code> is the lexer
generated by <a href="https://github.com/westes/flex">flex</a>.  Over half of the time
in <code>yylex()</code> was spent in <code>strtod()</code>, which converts strings to doubles.
We’ll hold off on attacking <code>yyparse()</code> and <code>yylex()</code> until the third
posting in this series, but we already have a good indication that
reducing the amount of data we throw at the renderer might be a good idea.</p>

<h3 id="from-text-to-ply">From text to PLY</h3>

<p>One way to spend less time parsing a text representation of data is to
convert the data to something more efficient to parse.  Quite a bit of
those 29 GB of scene description files is triangle meshes, and pbrt already
had native support for <a href="https://en.wikipedia.org/wiki/PLY_(file_format)">PLY
files</a>, which provide an
efficient binary representation of polygon meshes.  pbrt also has a
<code>--toply</code> command-line flag that will parse a pbrt scene description file,
convert any triangle meshes it finds to PLY files, and emit a new pbrt file
that refers to those PLY files instead.</p>

<p>One catch was that the Disney scene makes extensive use of
<a href="http://ptex.us/">ptex</a> textures, which in turn require a <code>faceIndex</code> value</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html">https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html</a></em></p>]]>
            </description>
            <link>https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631637</guid>
            <pubDate>Tue, 29 Sep 2020 19:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust 2021: GUI]]>
            </title>
            <description>
<![CDATA[
Score 359 | Comments 228 (<a href="https://news.ycombinator.com/item?id=24631611">thread link</a>) | @clarkmoody
<br/>
September 29, 2020 | https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This is a response to the Rust <a href="https://blog.rust-lang.org/2020/09/03/Planning-2021-Roadmap.html">call for blogs 2021</a> and also a followup to <a href="https://raphlinus.github.io/rust/druid/2019/10/31/rust-2020.html">last year’s entry</a>. It will be entirely focused on GUI.</p>

<p>There is considerable interest in GUI toolkits for Rust. As one data point, it was the 6th highest rated challenge for adoption in the <a href="https://blog.rust-lang.org/2020/04/17/Rust-survey-2019.html#rust-adoption---a-closer-look">2019 Rust survey</a>, just behind async I/O. There is also a fair amount of activity towards this goal, though as a community it still feels a bit unfocused. A characteristic sign is that a new GUI toolkit seems to pop up every couple of months or so.</p>

<p>I believe there is great potential for a high-quality GUI toolkit in Rust. At the same time, it’s an incredibly ambitious task. Subtasks within it, for example accelerated GPU drawing and text layout, are in and of themselves incredibly ambitious tasks. I wouldn’t consider a toolkit “ready” for production use until it supported accessibility, and as far as I know there is nothing in the Rust space even starting to work on this.</p>

<p>Yet, perhaps against my better judgment, I find myself devoting most of my time and energy towards building GUI in Rust. In this post I will set out my hopes but also frankly discuss the challenges.</p>

<h2 id="why-gui-in-rust">Why GUI in Rust?</h2>

<p>Simply put, I believe that the strengths of Rust translate well to writing GUI applications, and that the missing piece is the existence of a good toolkit. One strength is Rust’s wide “dynamic range” – the ability to describe application logic in high level terms while still being attentive to low level details. Another is <em>strong</em> cross-platform compatibility. The increasingly rich crate ecosystem is compelling in many domains. And don’t lose sight of the importance of safety. In traditional object-oriented GUI in C++ especially, object lifetimes can be complicated, and it’s not hard to cause crashes, especially on takeoffs and landings.</p>

<p>I do pay attention to the competitive space, and one thing I see is Electron being used more and more, because it solves real problems. But I also believe that the success of Electron creates a real opportunity for a higher performance, lighter weight alternative. And in general for the projects I see in other languages, I find myself <em>wanting</em> to compete against them.</p>

<h2 id="about-druid">About Druid</h2>

<p>The <a href="https://github.com/linebender/druid">Druid</a> toolkit has made impressive progress in the last year, but is still nowhere near stable or complete. If you are looking for a GUI toolkit to develop your application today, Druid is not it.</p>

<p>We are developing the font editor <a href="https://github.com/linebender/runebender">Runebender</a> as the primary motivating application, but, while a lot of pieces are in place, it is sadly not yet usable for day to day font creation work. One of my goals for the rest of the year is to start creating a font in it.</p>

<p>That said, I am very proud of the work that’s been done in the last year. To hit on some of the highlights, we’re just landing basic but capable <a href="https://www.cmyr.net/blog/piet-text-work.html">rich text layout</a>. The keyboard event is close to browser quality (based on <a href="https://crates.io/crates/keyboard-types">keyboard-types</a>). There is incremental painting based on damage regions. Multi-window support is solid, with support for controlling window placement and dynamic hi-dpi. There is tab-focusing between text boxes. All of these are hard problems. Even more so, I am pleased that a lot of the work came from people in the community.</p>

<h2 id="converging-a-vision">Converging a vision</h2>

<p>Imagine a thought experiment for a bit. Obviously Rust is promising for implementing async, but there isn’t a consensus on the best way to do it. Some people feel it should be done with callbacks, and invest considerable effort into overcoming the serious problems with that approach. Others feel it should be done with a polling future trait, but there are multiple versions of that trait: some get the context from thread local storage, others pass it into the poll method. And of course some people feel the syntax should be <code>future.await</code> while others insist on <code>await!(future)</code>. Every couple of months somebody pops up on /r/rust with a new crate that promises to solve “the async problem,” complete with a nice-looking echo server demo.</p>

<p>That’s about where we are today with GUI toolkits. In many ways, I think converging on a single vision in GUI is a harder problem than for async. For one, people have different things they want to do. I’m personally most interested in things that resemble document editors. Others want 3D or video content. In the future, there might be commercial interest in enterprise line-of-business apps or interfaces for medical devices. These all have quite different requirements in the best ways to express UI logic, and how to build them. Not to mention the endless opportunities to bikeshed.</p>

<p>I am not (yet) proposing Druid as the singular vision that the Rust community should converge on. I’m enjoying reading codebases and learning from other Rust GUI projects. In particular, I’m finding lots to like about <a href="https://github.com/hecrj/iced">Iced</a>: it has good solutions to async, 3D graphics (through wgpu), being able to function in a guest window (important for VST plug-ins), among other problems. And I’m getting the sense that it’s easier for developers. The Elm-like reactive architecture maps nicely to Rust, and depending on exactly what you’re trying to do, it’s not hard to figure out how to express your app-specific logic. By contrast, Druid’s reactive model, while efficient and powerful in many ways, has complex concepts such as Haskell-like lenses, and places a burden on the developer to carefully design the “app data” to fit the Druid model. The <a href="https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">Crochet research prototype</a> is an active exploration into making that simpler. I am thankful to Iced (and other toolkits) for being a model to study.</p>

<p>The work to build consensus is complex and multifaceted, and it cannot be rushed. From my side, I hope to improve the designs and implementations to the point where they are compelling. I also hope to listen to criticisms, many of which are valid. I also think there is more work the community can be doing here. I’d love to see more active effort in trying to learn from the ongoing work and try to synthesize it. The GUI-related threads on /r/rust are sadly not a place where that happens; they most often consist of a statement of requirements (usually presented very informally), followed by a bit of bikeshedding. I don’t have a good answer for how to improve this situation, but put it out there as a problem I’m feeling.</p>

<p>While I think a converged vision is an admirable and ambitious goal, it may not be necessary for a successful GUI ecosystem in Rust. It’s possible that different types of GUI programs will simply require different infrastructure, so even in the long term it makes sense to have ecosystem diversity. Certainly that’s the case in the short and medium term as well, just to explore the space. And even without a grand unifying vision, there is lots of scope to work on infrastructural crates for important pieces of the GUI story, including text layout and related problems.</p>

<h2 id="learning-and-community">Learning and community</h2>

<p>Many Rust projects these days come with what’s basically a marketing pitch: “adopt this codebase, it’s awesome.” I am starting to see the Druid project in a somewhat different light. I consider its primary mission to be <em>teaching and learning</em> the knowledge required to build GUI. To that extent, the community we’re building, hosted on <a href="https://xi.zulipchat.com/">our Zulip instance,</a> is just as important as the code.</p>

<p>The knowledge needed to build GUI has many aspects, and is at all levels. Some of it is at a high level, like the best way to express reactive UI. Some of it is at a low level, like the keyboard event processing. A common thread is that a lot of it is very arcane, not really written down properly anywhere. Fortunately, a lot of it is accessible through reading the code of other open source projects, whether in Rust or in other languages (I’ve found both Chromium and Gecko to be especially useful).</p>

<p>So I consider this a goal, a success criterion, of the Druid project. If somebody wants to know how to solve a problem in GUI, the Druid codebase should be one of the best places to look for answers.</p>

<p>I love research more than most anything, and a lot of my own work has a strong research flavor. That has caused some confusion; some of the things I’m exploring are very speculative and will likely take years to come to fruition. Certainly my research into compute-centric GPU rendering is of that nature; I’m excited about the fact that it promises dramatic performance improvements over the current state of the art, but it’s nowhere near ready to put into production yet. I’m striving for clearer communication so people can have a better idea what is speculative, based on grand futuristic visions, and what is on track to being usable reasonably soon. But both are important aspects of what I consider to be the main mission: fostering learning about how to build GUI.</p>

<h2 id="baby-steps">Baby steps</h2>

<p>While I am driven by a long-term, ambitious vision, the goal of Druid in 2021 is not to deliver a general UI toolkit. Rather, we are deliberately continuing to follow a narrow scope. The primary goal remains the font editor project, and we plan to re-focus attention on that. I do think this is an attainable goal. I also think that what we learn from trying to build a real application with users will be extremely valuable to the more ambitious task.</p>

<p>One project management technique that is proving effective is “cycles.” Instead of trying to solve the most ambitious version of a problem, we choose up front what to push to a future cycle, reducing the scope for the current implementation cycle. An example is the choice to defer BiDi from our recent text work. This is obviously an essential feature for a real GUI toolkit, but we also know it could take weeks or months to get it right. To have any chance of shipping, we have to carefully budget our time and energy on subprojects that easily could expand to absorb our full attention.</p>

<p>A common development pattern for a fledgling GUI toolkit is to have a “hero app” that drives development. It really helps clarify requirements, and also makes it …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html">https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631611</guid>
            <pubDate>Tue, 29 Sep 2020 19:00:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have a Feedback Loop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631466">thread link</a>) | @jerodsanto
<br/>
September 29, 2020 | https://www.iamjonas.me/2020/09/have-feedback-loop.html | <a href="https://web.archive.org/web/*/https://www.iamjonas.me/2020/09/have-feedback-loop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.iamjonas.me/2020/09/have-feedback-loop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631466</guid>
            <pubDate>Tue, 29 Sep 2020 18:48:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What 4M Slack Messages Tell Us About Collaboration]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631435">thread link</a>) | @knoxa2511
<br/>
September 29, 2020 | https://productiv.com/what-4-million-slack-messages-tell-us-about-collaboration/ | <a href="https://web.archive.org/web/*/https://productiv.com/what-4-million-slack-messages-tell-us-about-collaboration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="64352fa9" data-element_type="section">
						<div>
							<div>
					<div data-id="5bad87c" data-element_type="column">
			<div>
							<div>
						<div data-id="3d378fd8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><img loading="lazy" src="https://productiv.com/wp-content/uploads/2020/09/Is-Slack-Worth-the-SaaS-Investment_600x.jpg" alt="" width="600" height="300" srcset="https://productiv.com/wp-content/uploads/2020/09/Is-Slack-Worth-the-SaaS-Investment_600x.jpg 600w, https://productiv.com/wp-content/uploads/2020/09/Is-Slack-Worth-the-SaaS-Investment_600x-300x150.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></p><p><span>What value is your company getting out of Slack?</span></p><p><span>We’ve got the data. Using engagement analytics from Productiv’s SaaS Management platform, we looked at over </span><b>4,000,000 Slack messages</b><span> across approximately </span><b>40,000 users</b><span>. We compared this data to a similar number of messages from companies using other messaging tools. From this data we pulled concrete observations around how enterprises are using — and driving value — from Slack.</span></p><p><span>Read on to get the hard numbers on how Slack drives open collaboration, cross-team collaboration, and external collaboration — as well as how you can use Productiv’s engagement analytics to prove the value you’re getting from SaaS platforms like Slack.</span></p><h3><b>Understanding Productiv and its Data</b></h3><p><span>Before diving into the data itself, let’s provide context for where the data comes from. Productiv is an enterprise </span><a href="http://productiv.com/"><span>SaaS management</span></a><span> platform. Our mission is to unlock productivity from your SaaS portfolio by giving you insights into how your employees are using their applications. Whether its collaboration, communications, project management, or any other SaaS application, Productiv serves as your central system of record for how these applications are used; licensing costs; and renewals.</span></p><p><span>Our focus on </span><a href="https://productiv.com/application-engagement-analytics-the-key-to-rethinking-saas-management/"><span>application engagement analytics</span></a><span>, combined with this centralized system puts us into an excellent place to extract trends across many enterprises for any number of applications. All of the data presented below is derived solely from Productiv’s platform, and aggregated across customer environments. This data in turn can help enterprises better understand how they are getting ROI out of the applications they invest time and money into.</span></p><h3><b>How to Measure Slack ROI</b></h3><p><a href="https://techcrunch.com/2020/03/19/slack-adds-7k-customers-in-7-weeks-amid-remote-work-boom-besting-its-preceding-2-quarters-results/"><span>Slack is booming</span></a><span>, as companies invest heavily in collaboration solutions that allow people to work more effectively, even as more people are working from home. But how do you know how much value youâ€™re getting out of a collaboration solution such as Slack?Â&nbsp;</span></p><p><span>We looked at the common questions asked by CIOs:</span></p><ul><li><span>If we invest in Slack, how much will our employees actually use it?Â&nbsp;</span></li><li><span>Does Slack improve collaboration between employees?Â&nbsp;</span></li><li><span>How do we measure the value of this collaboration to show Return on Investment?</span></li></ul><p><span>On a day-to-day basis, you might be able to measure messages across public and private channels. What does that really mean, though — are employees making the most of Slack?Â&nbsp;</span></p><p><span>To understand the value your organization is getting from a SaaS investment such as Slack, itâ€™s not enough to look at how many licenses you have provisioned. In fact, itâ€™s not enough to look at </span><a href="https://slack.com/blog/news/work-is-fueled-by-true-engagement"><span>daily average users</span></a><span> either – what you need to measure is </span><b>user engagement </b><span>to see if employees are truly getting value from their tools</span><b>.</b><span>Â&nbsp;</span></p><p><span>User engagement is how an individual interacts with a product or service.</span></p><p><span>Engagement looks at what features your employees use, how frequently they use it, and (critically) what kind of value they get from it — as value for employees translates into value for the business.</span></p><p><span>You can tell when employees are engaged with their collaboration tools and using it for deep work when they’re doing more with the platform than just using the basic features – for example in the case of messaging, lightweight private messages to other team members. Specifically, we break down value from thisÂ&nbsp; engagement into three metrics.</span></p><h3><b>An Analysis of The Three Metrics of Slack Engagement</b></h3><p>Many think of Slack simply as a chat platform. Our data however supports the idea that Slack has evolved into a collaboration platform, with three types of collaboration that we can measure. Let’s break down these three types of collaboration and examine the supporting data.</p><h4><span>1. Open Collaboration</span></h4><p>The idea ofÂ&nbsp;<a href="https://opensym.org/about-us/definition/">open collaboration</a>Â&nbsp;is employees freely working with other employees. Compared to rigid, hierarchical structures, open collaboration mixes things up. Anyone can join in. (Think company-wide brainstorming sessions, or town hall-style meetings.)</p><p>In Slack,Â&nbsp;<span>â€œopen collaborationâ€� can be measured by how users utilize public channels</span>.Â&nbsp;<a href="https://medium.com/ragtag-notes/set-up-your-team-for-organizing-27563b0ab189">Public channels</a>Â&nbsp;are open to anyone in the workplace, with the exception of guests — theyâ€™re meant for company-wide announcements, updates, or general information sharing.</p><p>According to Productiv data,Â&nbsp;<span>those who use Slack are more than twice as likely to use public channels for messaging</span>Â&nbsp;than comparable messaging products.</p><p>Our analytics show thatÂ&nbsp;<span>74% of Slack users send messages through public channels</span>, compared to justÂ&nbsp;<span>34% of users for other enterprise collaboration platforms</span>. Slack isnâ€™t just a private chat platform — it drives open, public collaboration.</p><p>Anecdotally, we see Slack customers echo this philosophy. For example,Â&nbsp;<a href="https://slack.com/customer-stories/td-ameritrade">Neal Obermeyer at TD Ameritrade</a>Â&nbsp;noted, â€œ<a href="https://slack.com/features/channels/">Slack channels</a>, virtual spaces for sharing information and files, cut through information silos by making company knowledge available across the organization. By moving communication to public channels, we removed the subjectivity of sharing information so internal knowledge could scale as needed.â€� This type of approach is well reflected in our data.</p><h4><span>2. Cross-Team Collaboration</span></h4><p>Beyond open collaboration (conversations that anyone can join), cross-team collaboration means teams using Slack to work together. For example, someone from HR communicating to someone in Accounting, versus accounting only talking to accounting or HR only messaging HR.</p><p>On average, we found thatÂ&nbsp;<span>~80% of Slack users send cross-team messages</span>.</p><p><img loading="lazy" src="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM-1024x422.png" alt="" width="1024" height="422" srcset="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM-1024x422.png 1024w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM-300x124.png 300w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM-768x317.png 768w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM.png 1377w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p><i>How a high-growth software company (1000+ employees) uses Slack between teams. (Source: Productiv analytics)</i></p><p>Our analytics show that companies see much greater cross-team collaboration with Slack than other messaging platforms. In fact,Â&nbsp;<span>90%+ of companies using Slack</span>Â&nbsp;haveÂ&nbsp;<span>70%+ of their users engaging in cross-team collaboration.Â&nbsp;</span></p><p><img loading="lazy" src="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM-1024x526.png" alt="" width="1024" height="526" srcset="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM-1024x526.png 1024w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM-300x154.png 300w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM-768x394.png 768w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM.png 1472w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p><i>How a large technology company (10,000+ employees) uses Slack for cross-team collaboration. (Source: Productiv analytics)</i></p><h4><span>3. External Collaboration</span></h4><p><a href="https://innovationmanagement.se/2017/01/06/a-quick-guide-to-external-collaboration/">External collaboration</a>Â&nbsp;refers to how well employees work outside your company — say, with suppliers, consultants, or customers. While employees certainly need to collaborate with each other, external collaboration leads to greater innovation, happier customers, and a more valuable business.</p><p>According to our data, Slack is effective at driving more external collaboration.Â&nbsp;<span>For every ten messages in internal public channels,</span>Â&nbsp;<span>Productivâ€™s Slack users send an average of 4.8 external messages.Â&nbsp;</span>In other words, the ratio is about 1 external message for every 2 internal messages.</p><p>And that number is growing: between August 2019 and August 2020,Â&nbsp;<span>43% of the businesses we analyzed have increased the volume of external messages sent through Slack</span>.</p><p>Slack Connect allows teams to move the conversations theyâ€™re having with external partners, vendors, or customers into Slack channels.</p><p><img loading="lazy" src="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM-1024x362.png" alt="" width="1024" height="362" srcset="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM-1024x362.png 1024w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM-300x106.png 300w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM-768x271.png 768w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM.png 1460w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p><i>How Slack increases internal collaboration (black line), cross-team collaboration (green line), and external collaboration (blue line). (Source: Productiv analytics)</i><i>Â&nbsp;</i></p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section></div>]]>
            </description>
            <link>https://productiv.com/what-4-million-slack-messages-tell-us-about-collaboration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631435</guid>
            <pubDate>Tue, 29 Sep 2020 18:44:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Kubernetes Init Containers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631324">thread link</a>) | @pj3677
<br/>
September 29, 2020 | https://www.learncloudnative.com/blog/2020-09-26-init-containers/ | <a href="https://web.archive.org/web/*/https://www.learncloudnative.com/blog/2020-09-26-init-containers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Init containers allow you to separate your application from the initialization logic and provide a way to run the initialization tasks such as setting up permissions, database schemas, or seeding data for the main application, etc. The init containers may also include any tools or binaries that you don't want to have in your primary container image due to security reasons.</p><p>The init containers are executed in a sequence before your primary or application containers start. On the other hand, any application containers have a non-deterministic startup order, so you can't use them for the initialization type of work.</p><p>The figure below shows the execution flow of the init containers and the application containers.</p><p><span>
      <a href="https://www.learncloudnative.com/static/9d90a818ebe0c8029d1b58facf7e414a/9f82e/init-containers.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Init Containers" title="Kubernetes Init Containers" src="https://d33wubrfki0l68.cloudfront.net/9eec2180e1c0fbe463738e707c7a23e64f161f5c/efbec/static/9d90a818ebe0c8029d1b58facf7e414a/9f82e/init-containers.png" srcset="https://d33wubrfki0l68.cloudfront.net/974b7854c6dd364ca80b766e83b5fcc160ed52a8/85291/static/9d90a818ebe0c8029d1b58facf7e414a/2eb24/init-containers.png 215w,https://d33wubrfki0l68.cloudfront.net/b19eb655fd61ef64249f1a32972ca729f67eb88a/5ea0c/static/9d90a818ebe0c8029d1b58facf7e414a/05ed2/init-containers.png 430w,https://d33wubrfki0l68.cloudfront.net/9eec2180e1c0fbe463738e707c7a23e64f161f5c/efbec/static/9d90a818ebe0c8029d1b58facf7e414a/9f82e/init-containers.png 820w" sizes="(max-width: 820px) 100vw, 820px" loading="lazy">
  </a>
    </span></p><p>The application containers will wait for the init containers to complete successfully before starting. If the init containers fail, the Pod is restarted (assuming we didn't set the restart policy to <code>RestartNever</code>), which causes the init containers to run again. When designing your init containers, make sure they are idempotent, to run multiple times without issues. For example, if you're seeding the database, check if it already contains the records before re-inserting them again.</p><p>Since init containers are part of the same Pod, they share the volumes, network, security settings, and resource limits, just like any other container in the Pod. </p><p>Let's look at an example where we use an init container to clone a GitHub repository to a shared volume between all containers. The Github repo contains a single <code>index.html</code>. Once the repo is cloned and the init container has executed, the primary container running the Nginx server can use <code>index.html</code> from the shared volume and serve it.</p><p>You define the init containers under the <code>spec</code> using the <code>initContainers</code> field, while you define the application containers under the <code>containers</code> field. We define an <code>emptyDir</code> volume and mount it into both the init and application container. When the init container starts, it will run the <code>git clone</code> command and clone the repository into the <code>/usr/share/nginx/html</code> folder. This folder is the default folder Nginx serves the HTML pages from, so when the application container starts, we will be able to access the HTML page we cloned. </p><div data-language="yaml"><pre><code><span>apiVersion</span><span>:</span> v1
<span>kind</span><span>:</span> Pod
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> website
<span>spec</span><span>:</span>
  <span>initContainers</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> clone<span>-</span>repo
      <span>image</span><span>:</span> alpine/git
      <span>command</span><span>:</span>
        <span>-</span> git
        <span>-</span> clone
        <span>-</span> <span>-</span><span>-</span>progress
        <span>-</span> https<span>:</span>//github.com/peterj/simple<span>-</span>http<span>-</span>page.git
        <span>-</span> /usr/share/nginx/html
      <span>volumeMounts</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> web
          <span>mountPath</span><span>:</span> <span>"/usr/share/nginx/html"</span>
  <span>containers</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> nginx
      <span>image</span><span>:</span> nginx
      <span>ports</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> http
          <span>containerPort</span><span>:</span> <span>80</span>
      <span>volumeMounts</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> web
          <span>mountPath</span><span>:</span> <span>"/usr/share/nginx/html"</span>
  <span>volumes</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> web
      <span>emptyDir</span><span>:</span> <span>{</span><span>}</span></code></pre></div><p>Save the above YAML to <code>init-container.yaml</code> and create the Pod using <code>kubectl apply -f init-container.yaml</code>.</p><p>If you run <code>kubectl get pods</code> right after the above command, you should see the status of the init container:</p><div data-language="bash"><pre><code>$ kubectl get po
NAME      READY   STATUS     RESTARTS   AGE
website   <span>0</span>/1     Init:0/1   <span>0</span>          1s</code></pre></div><p>The number <code>0/1</code> indicates a total of 1 init containers, and 0 containers have been completed so far. In case the init container fails, the status changes to <code>Init:Error</code> or <code>Init:CrashLoopBackOff</code> if the container fails repeatedly.</p><p>You can also look at the events using the <code>describe</code> command to see what happened:</p><div data-language="text"><pre><code>Normal  Scheduled  19s   default-scheduler  Successfully assigned default/website to minikube
Normal  Pulling    18s   kubelet, minikube  Pulling image "alpine/git"
Normal  Pulled     17s   kubelet, minikube  Successfully pulled image "alpine/git"
Normal  Created    17s   kubelet, minikube  Created container clone-repo
Normal  Started    16s   kubelet, minikube  Started container clone-repo
Normal  Pulling    15s   kubelet, minikube  Pulling image "nginx"
Normal  Pulled     13s   kubelet, minikube  Successfully pulled image "nginx"
Normal  Created    13s   kubelet, minikube  Created container nginx
Normal  Started    13s   kubelet, minikube  Started container nginx</code></pre></div><p>You will notice as soon as Kubernetes schedules the Pod, the first Docker image is pulled (<code>alpine/git</code>), and the init container (<code>clone-repo</code>) is created and started. Once that's completed (the container cloned the repo) the main application container (<code>nginx</code>) starts.</p><p>Additionally, you can also use the <code>logs</code> command to get the logs from the init container by specifying the container name using the <code>-c</code> flag:</p><div data-language="bash"><pre><code>$ kubectl logs website -c clone-repo
Cloning into <span>'/usr/share/nginx/html'</span><span>..</span>.
remote: Enumerating objects: <span>6</span>, done.
remote: Counting objects: <span>100</span>% <span>(</span><span>6</span>/6<span>)</span>, done.
remote: Compressing objects: <span>100</span>% <span>(</span><span>4</span>/4<span>)</span>, done.
remote: Total <span>6</span> <span>(</span>delta <span>0</span><span>)</span>, reused <span>0</span> <span>(</span>delta <span>0</span><span>)</span>, pack-reused <span>0</span>
Receiving objects: <span>100</span>% <span>(</span><span>6</span>/6<span>)</span>, done.</code></pre></div><p>Finally, to actually see the static HTML page can use <code>port-forward</code> to forward the local port to the port <code>80</code> on the container:</p><div data-language="bash"><pre><code>$ kubectl port-forward pod/website <span>8000</span>:80
Forwarding from <span>127.0</span>.0.1:8000 -<span>&gt;</span> <span>80</span>
Forwarding from <span>[</span>::1<span>]</span>:8000 -<span>&gt;</span> <span>80</span></code></pre></div><p>You can now open your browser at <code>http://localhost:8000</code> to open the static page as shown in figure below.</p><p><span>
      <a href="https://www.learncloudnative.com/static/9c0a3a9db42df7251937675e882b29f9/01e7c/simple-http-page.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Static HTML From Github Repo" title="Static HTML From Github Repo" src="https://d33wubrfki0l68.cloudfront.net/eb837020adf8929b21c1216ccba09d735bfe4686/ef2be/static/9c0a3a9db42df7251937675e882b29f9/01e7c/simple-http-page.png" srcset="https://d33wubrfki0l68.cloudfront.net/2178c0862319f9f33792560202123e4702a50d89/8edeb/static/9c0a3a9db42df7251937675e882b29f9/2eb24/simple-http-page.png 215w,https://d33wubrfki0l68.cloudfront.net/187c313f77573848e4ade2d37023d3376329ec92/2b16d/static/9c0a3a9db42df7251937675e882b29f9/05ed2/simple-http-page.png 430w,https://d33wubrfki0l68.cloudfront.net/eb837020adf8929b21c1216ccba09d735bfe4686/ef2be/static/9c0a3a9db42df7251937675e882b29f9/01e7c/simple-http-page.png 512w" sizes="(max-width: 512px) 100vw, 512px" loading="lazy">
  </a>
    </span></p><p>Lastly, delete the Pod by running <code>kubectl delete po website</code>.</p></article></div>]]>
            </description>
            <link>https://www.learncloudnative.com/blog/2020-09-26-init-containers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631324</guid>
            <pubDate>Tue, 29 Sep 2020 18:33:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Magnum Engine integrates Python and C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631106">thread link</a>) | @jakearmitage
<br/>
September 29, 2020 | https://blog.magnum.graphics/announcements/introducing-python-bindings/ | <a href="https://web.archive.org/web/*/https://blog.magnum.graphics/announcements/introducing-python-bindings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
<!-- content -->
<p>The new Mag­num Python bind­ings, while still
<abbr title="to allow breaking API changes">la­beled ex­per­i­men­tal</abbr>, al­ready give you
a pack­age us­able in re­al work­flows — a NumPy-com­pat­i­ble con­tain­er li­brary,
graph­ics-ori­ent­ed math class­es and func­tions, OpenGL buf­fer, mesh, shad­er and
tex­ture APIs, im­age and mesh da­ta im­port and a SDL / GLFW ap­pli­ca­tion class
with key and mouse events. Head over to the
<a href="https://doc.magnum.graphics/python/building/">in­stal­la­tion doc­u­men­ta­tion</a> to get it your­self; if you
are on Arch­Lin­ux or use Home­brew, pack­ages are al­ready there, wait­ing for you:</p>
<pre>brew tap mosra/magnum
brew install --HEAD corrade magnum magnum-plugins magnum-bindings</pre>
<p>And of course it has all good­ies you’d ex­pect from a “Python-na­tive” li­brary
— full slic­ing sup­port, er­rors re­port­ed through Python ex­cep­tions in­stead of
re­turn codes (or hard as­serts) and prop­er­ties in­stead of set­ters/get­ters where
it makes sense. To get you a quick over­view of how it looks and how is it used,
the first few ex­am­ples are port­ed to it:</p>


<section id="enter-pybind11">
<h2><a href="#enter-pybind11">En­ter py­bind11</a></h2>
<p>I dis­cov­ered <a href="https://github.com/pybind/pybind11">py­bind11</a> by a lucky ac­ci­dent in
<a href="https://github.com/mosra/magnum/issues/228">ear­ly 2018</a> and im­me­di­ate­ly had to try it. Learn­ing
the ba­sics and ex­pos­ing some min­i­mal ma­trix/vec­tor math took me about
<em>two hours</em>. It was an ex­treme fun and I have to thank all py­bind11 de­vel­op­ers
for mak­ing it so straight­for­ward to use.</p>
<figure>
<pre><span>py</span><span>::</span><span>class_</span><span>&lt;</span><span>Vector3</span><span>&gt;</span><span>(</span><span>m</span><span>,</span> <span>"Vector3"</span><span>)</span>
    <span>.</span><span>def_static</span><span>(</span><span>"x_axis"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>xAxis</span><span>,</span> <span>py</span><span>::</span><span>arg</span><span>(</span><span>"length"</span><span>)</span> <span>=</span> <span>1.0f</span><span>)</span>
    <span>.</span><span>def_static</span><span>(</span><span>"y_axis"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>yAxis</span><span>,</span> <span>py</span><span>::</span><span>arg</span><span>(</span><span>"length"</span><span>)</span> <span>=</span> <span>1.0f</span><span>)</span>
    <span>.</span><span>def_static</span><span>(</span><span>"z_axis"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>zAxis</span><span>,</span> <span>py</span><span>::</span><span>arg</span><span>(</span><span>"length"</span><span>)</span> <span>=</span> <span>1.0f</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>init</span><span>&lt;</span><span>Float</span><span>,</span> <span>Float</span><span>,</span> <span>Float</span><span>&gt;</span><span>())</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>init</span><span>&lt;</span><span>Float</span><span>&gt;</span><span>())</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>==</span> <span>py</span><span>::</span><span>self</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>!=</span> <span>py</span><span>::</span><span>self</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>"is_zero"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>isZero</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>"is_normalized"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>isNormalized</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>+=</span> <span>py</span><span>::</span><span>self</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>+</span> <span>py</span><span>::</span><span>self</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>*=</span> <span>Float</span><span>{})</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>*</span> <span>Float</span><span>{})</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>*=</span> <span>py</span><span>::</span><span>self</span><span>)</span></pre>
<p>That’s what it took to bind a vec­tor class.</p>
</figure>
<p>How­ev­er, dif­fer­ent things took a pri­or­i­ty and so the pro­to­type got shelved
un­til it got re­vived again this year. But I learned one main thing — even
just the math class­es alone were some­thing <em>so use­ful</em> that I kept the built
Python mod­ule around and used it from time to time as an en­hanced cal­cu­la­tor.
Now, with the <a href="https://doc.magnum.graphics/python/magnum/math/">mag­num.math</a> mod­ule be­ing al­most com­plete, it’s an ev­ery­day
tool I use for quick cal­cu­la­tions. Feel free to do the same.</p>
<div>
<figure>
<pre><span>&gt;&gt;&gt; </span><span>from</span> <span>magnum</span> <span>import</span> <span>*</span>
<span>&gt;&gt;&gt; </span><span>Matrix3</span><span>.</span><span>rotation</span><span>(</span><span>Deg</span><span>(</span><span>45</span><span>))</span>
<span>Matrix(0.707107, -0.707107, 0,</span>
<span>    0.707107, 0.707107, 0,</span>
<span>    0, 0, 1)</span></pre>
<p>Quick, where are the mi­nus signs in a 2D ro­ta­tion ma­trix?</p>
</figure>
</div>
</section>
<section id="what-python-apis-and-docs-could-learn-from-c">
<h2><a href="#what-python-apis-and-docs-could-learn-from-c">What Python APIs (and docs) could learn from C++</a></h2>
<p>Ev­ery time some­one told me they’re us­ing <a href="https://numpy.org/">numpy</a> for
“do­ing math quick­ly in Python”, I as­sumed it’s the rea­son­able thing to do —
un­til I ac­tu­al­ly tried to use it. I get that my use case of 4×4 ma­tri­ces
<em>at most</em> might not align well with NumPy’s goals, but the prob­lem is, as far
as I know,
<span>there’s no full-fea­tured math li­brary for Python that would give me the whole pack­age</span><a href="#id2" id="id1">1</a>
in­clud­ing <a href="https://doc.magnum.graphics/python/magnum/Quaternion/">Quater­nion</a>s or <a href="https://doc.magnum.graphics/python/magnum/Matrix4/">2D/3D trans­for­ma­tion ma­tri­ces</a>.</p>
<p>As an ex­cer­cise, for us­abil­i­ty com­par­i­son I tried to ex­press the ro­ta­tion
ma­trix shown in the box above in SciPy / NumPy. It took me a good half an hour
of star­ing at the docs of <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.html#scipy.spatial.transform.Rotation">scipy.spa­tial.trans­form.Ro­ta­tion</a> un­til I
ul­ti­mate­ly de­cid­ed it’s not worth my time. The over­ar­ch­ing prob­lem I have with
all those APIs is that it’s not clear at all what types I’m ex­pect­ed to feed to
them and pro­vid­ed ex­am­ple code looks like I’m sup­posed to do half of the
cal­cu­la­tions my­self any­way.</p>
<figure>
<pre><span>&gt;&gt;&gt;</span> <span>from</span> <span>scipy.spatial.transform</span> <span>import</span> <span>Rotation</span> <span>as</span> <span>R</span>
<span>&gt;&gt;&gt;</span> <span>r</span> <span>=</span> <span>R</span><span>.</span><span>from_quat</span><span>([</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>np</span><span>.</span><span>pi</span><span>/</span><span>4</span><span>),</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>np</span><span>.</span><span>pi</span><span>/</span><span>4</span><span>)])</span></pre>
<blockquote>
<p>Ro­ta­tion.from_quat(quat, nor­mal­ized=False)</p>
<p>Pa­ram­e­ters:</p>
<dl>
<dt><strong>quat: ar­ray_­like, shape (N, 4) or (4,)</strong></dt>
<dd>Each row is a (pos­si­bly non-unit norm) quater­nion in scalar-last
(x, y, z, w) for­mat.</dd>
</dl>
<p>—<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_quat.html#scipy.spatial.transform.Rotation.from_quat">scipy.spa­tial.trans­form.Ro­ta­tion.from_quat()</a></p>
</blockquote>
<p>Type in­for­ma­tion in the SciPy doc­u­men­ta­tion is vague at best.
<em>Al­so, I’d like some­thing that would make the quater­nion for me, as well.</em></p>
</figure>
<p>To avoid the type con­fu­sion, with Mag­num Python bind­ings I de­cid­ed to use
strong types where pos­si­ble — so in­stead of a sin­gle dy­nam­ic ma­trix / vec­tor
type akin to <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray">numpy.ndar­ray</a>, there’s a clear dis­tinc­tion be­tween ma­tri­ces
and vec­tors of dif­fer­ent sizes. So then if you do <code><span>Matrix4x3</span><span>()</span> <span>@</span> <span>Matrix2x4</span><span>()</span></code>,
docs of <a href="https://doc.magnum.graphics/python/magnum/Matrix4x3/#__matmul__-da39a">Ma­trix4x3.__­mat­mul__()</a> will tell you the re­sult is <a href="https://doc.magnum.graphics/python/magnum/Matrix2x3/">Ma­trix2x3</a>.
For NumPy it­self, there’s a pro­pos­al for im­proved type an­no­ta­tions at
<a href="https://github.com/numpy/numpy/issues/7370">numpy/numpy#7370</a> which would help a lot, but the doc­u­men­ta­tion tools
<em>have to</em> make use of that. <a href="#everyone-just-uses-sphinx-you">More on that be­low</a>.</p>
<p>One lit­tle thing with big im­pact of the C++ API is strong­ly-typed an­gles. You
no longer need to re­mem­ber that trig func­tions use ra­di­ans in­ter­nal­ly but HSV
col­ors or Ope­nAL jug­gles with de­grees in­stead — sim­ply use what­ev­er you
please. So Python got the <a href="https://doc.magnum.graphics/python/magnum/Deg/">Deg</a> and <a href="https://doc.magnum.graphics/python/magnum/Rad/">Rad</a> as well. Python doesn’t
have any us­er-de­fined lit­er­als (and I’m not aware of any pro­pos­als to add it),
how­ev­er <a href="https://stackoverflow.com/a/37204095">there’s a way to make Python rec­og­nize them</a>.
I’m not yet sure if this amount of mag­ic is wise to ap­ply, but I might try it
out once.</p>
<dl>
<dt id="id2">1.</dt>
<dd><span><a href="#id1">^</a></span> As <a href="https://www.reddit.com/r/cpp/comments/d5pilr/how_magnum_engine_exposes_c_to_python/f0nqese/">/u/Ni­hon­Nukite point­ed out on Red­dit</a>,
there’s <a href="https://github.com/adamlwgriffiths/Pyrr">Pyrr</a> that pro­vides
the above miss­ing func­tion­al­i­ty, ful­ly in­te­grat­ed with numpy. The on­ly
po­ten­tial down­side is that it’s all pure Python, not op­ti­mized na­tive code.</dd>
</dl>
</section>
<section id="hard-things-are-suddenly-easy-if-you-use-a-different-language">
<h2><a href="#hard-things-are-suddenly-easy-if-you-use-a-different-language">Hard things are sud­den­ly easy if you use a dif­fer­ent lan­guage</a></h2>
<pre><span>&gt;&gt;&gt; </span><span>a</span> <span>=</span> <span>Vector4</span><span>(</span><span>1.5</span><span>,</span> <span>0.3</span><span>,</span> <span>-</span><span>1.0</span><span>,</span> <span>1.0</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>b</span> <span>=</span> <span>Vector4</span><span>(</span><span>7.2</span><span>,</span> <span>2.3</span><span>,</span> <span>1.1</span><span>,</span> <span>0.0</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>a</span><span>.</span><span>wxy</span> <span>=</span> <span>b</span><span>.</span><span>xwz</span>
<span>&gt;&gt;&gt; </span><span>a</span>
<span>Vector(0, 1.1, -1, 7.2)</span></pre>
<p>If you ev­er used GLSL or any oth­er shad­er lan­guage, you prob­a­bly fell in love
with vec­tor swiz­zles right at the mo­ment you saw them … and then be­came sad
af­ter a re­al­iza­tion that such APIs are <em>prac­ti­cal­ly im­pos­si­ble</em><a href="#id5" id="id3">2</a> to have
in C++. Swiz­zle op­er­a­tions are nev­er­the­less use­ful and as­sign­ing each com­po­nent
sep­a­rate­ly would be a pain, so Mag­num pro­vides <a href="https://doc.magnum.graphics/magnum/namespaceMagnum_1_1Math.html#aeda0faa04b927f5c7aa2bbc3a8794d7d">Math::gath­er()</a> and
<a href="https://doc.magnum.graphics/magnum/namespaceMagnum_1_1Math.html#a04d57d5b0e229035590046fed3496502">Math::scat­ter()</a> that al­low you to ex­press the above:</p>
<pre><span>a</span> <span>=</span> <span>Math</span><span>::</span><span>scatter</span><span>&lt;</span><span>'w'</span><span>,</span> <span>'x'</span><span>,</span> <span>'y'</span><span>&gt;</span><span>(</span><span>a</span><span>,</span> <span>Math</span><span>::</span><span>gather</span><span>&lt;</span><span>'x'</span><span>,</span> <span>'w'</span><span>,</span> <span>'z'</span><span>&gt;</span><span>(</span><span>b</span><span>));</span></pre>
<p>Ver­bose<a href="#id7" id="id4">3</a> but <em>prac­ti­cal­ly</em> pos­si­ble. Point is, how­ev­er, that the above is
im­ple­mentable very eas­i­ly in Python us­ing <code><span>__getattr__</span><span>()</span></code> and
<code><span>__setattr__</span><span>()</span></code> … and a ton of er­ror check­ing on top.</p>
<dl>
<dt id="id5">2.</dt>
<dd><span><a href="#id3">^</a></span> GLM <em>does have</em> those, if you en­able <code><span>GLM_FORCE_SWIZZLE</span></code>, but do­ing
so adds <em>three sec­onds</em><a href="#id8" id="id6">4</a> to com­pi­la­tion time of each file that
in­cludes GLM head­ers. I’d say that makes swiz­zles pos­si­ble <em>in the­o­ry</em> but
such over­head makes them <em>prac­ti­cal­ly</em> use­less.</dd>
<dt id="id7">3.</dt>
<dd><span><a href="#id4">^</a></span> Math func­tions are <em>func­tions</em> and so do not mu­tate their ar­gu­ments,
that’s why the fi­nal self-as­sign­ment. It would of course be bet­ter to be
able to write <code><span>Math</span><span>::</span><span>gather</span><span>&lt;</span><span>"wxy"</span><span>&gt;</span><span>(</span><span>b</span><span>)</span></code> or at least
<code><span>Math</span><span>::</span><span>gather</span><span>&lt;</span><span>'</span><span>wxy</span><span>'</span><span>&gt;</span><span>(</span><span>b</span><span>)</span></code> but C++ <em>in­sists</em> on the first be­ing
im­pos­si­ble and the sec­ond be­ing un­portable. And
<a href="https://github.com/SephDB/constexpr-format">cre­at­ing a us­er-de­fined lit­er­al</a> just to
spec­i­fy a swiz­zle seems ex­ces­sive.</dd>
<dt id="id8">4.</dt>
<dd><span><a href="#id6">^</a></span> I did a cou­ple of bench­marks for a yet-to-be-pub­lished ar­ti­cle com­par­ing
math li­brary im­ple­men­ta­tions, and this was a shock­er. The on­ly oth­er
li­brary that could come close was <a href="https://github.com/boostorg/geometry">Boost.Ge­om­e­try</a>,
with two sec­onds per file.</dd>
</dl>
<section id="but-on-the-contrary-c-has-it-easier-with-overloads">
<h3><a href="#but-on-the-contrary-c-has-it-easier-with-overloads">… but on the con­trary, C++ has it eas­i­er with over­loads</a></h3>
<p>I was very de­light­ed up­on dis­cov­er­ing that py­bind11 sup­ports func­tion over­loads
<em>just like that</em> — if you bind more than one func­tion of the same name, it’ll
take a type­less <code><span>(</span><span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>)</span></code> and dis­patch to a cor­rect over­load
based on ar­gu­ment types. It’s prob­a­bly not blaz­ing­ly fast (and in some cas­es
you could prob­a­bly beat its speed by do­ing the dis­patch you­self), but it’s
there and much bet­ter than hav­ing to in­vent new names for over­load­ed func­tions
(and con­struc­tors!). With the <abbr title="well, relatively">new</abbr> <a href="https://docs.python.org/3/library/typing.html#module-typing">typ­ing</a>
mod­ule, it’s pos­si­ble to achieve a sim­i­lar thing in pure Python us­ing the
<a href="https://docs.python.org/3/library/typing.html#typing.overload">@over­load</a> dec­o­ra­tor — though on­ly for doc­u­men­ta­tion
pur­pos­es, you’re still re­spon­si­ble to im­ple­ment the type dis­patch your­self. In
case of <a href="https://doc.magnum.graphics/python/magnum/math/#dot">math.dot()</a> im­ple­ment­ed in pure Python, this could look like
this:</p>
<pre><span>@overload</span>
<span>def</span> <span>dot</span><span>(</span><span>a</span><span>:</span> <span>Quaternion</span><span>,</span> <span>b</span><span>:</span> <span>Quaternion</span><span>)</span> <span>-&gt;</span> <span>float</span><span>:</span>
    <span>...</span>
<span>@overload</span>
<span>def</span> <span>dot</span><span>(</span><span>a</span><span>:</span> <span>Vector2</span><span>,</span> <span>b</span><span>:</span> <span>Vector2</span><span>)</span> <span>-&gt;</span> <span>float</span><span>:</span>
    <span>...</span>
<span>def</span> <span>dot</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>):</span>
    <span># actual implementation</span></pre>
<p>What was ac­tu­al­ly <em>hard</em> though, was the fol­low­ing, look­ing com­plete­ly or­di­nary
to a C++ pro­gram­mer:</p>
<figure>
<pre><span>&gt;&gt;&gt; </span><span>a</span> <span>=</span> <span>Matrix3</span><span>.</span><span>translation</span><span>((</span><span>4.0</span><span>,</span> <span>2.0</span><span>))</span>
<span>&gt;&gt;&gt; </span><span>a</span>
<span>Matrix(1, 0, 4,</span>
<span>       0, 1, 2,</span>
<span>       0, 0, 1)</span>
<span>&gt;&gt;&gt; </span><span>a</span><span>.</span><span>translation</span> <span>=</span> <span>Vector2</span><span>(</span><span>5.0</span><span>,</span> <span>3.0</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>a</span>
<span>Matrix(1, 0, 5,</span>
<span>       0, 1, 3,</span>
<span>       0, 0, 1)</span></pre>
<p>Is the Python lan­guage po­lice go­ing to ar­rest me now?</p>
</figure>
<p>While the case of <a href="https://doc.magnum.graphics/python/magnum/Matrix3/#scaling-da39a">Ma­trix3.scal­ing()</a> vs. <code><span>mat</span><span>.</span><span>scaling</span><span>()</span></code> — where
the for­mer re­turns a scal­ing <a href="https://doc.magnum.graphics/python/magnum/Matrix3/">Ma­trix3</a> and lat­ter a scal­ing <a href="https://doc.magnum.graphics/python/magnum/Vector3/">Vec­tor3</a>
out of a scal­ing ma­trix — was eas­i­er and could be done just via a dis­patch
based on ar­gu­ment types (“if the first ar­gu­ment is an in­stance of <a href="https://doc.magnum.graphics/python/magnum/Matrix3/">Ma­trix3</a>,
be­have like the mem­ber func­tion”), in case of <a href="https://doc.magnum.graphics/python/magnum/Matrix3/#translation">Ma­trix3.trans­la­tion()</a> it’s
ei­ther a stat­ic method or an in­stance <em>prop­er­ty</em>. Ul­ti­mate­ly I man­aged to solve
it by sup­ply­ing a cus­tom meta­class that does a cor­rect dis­patch when
en­coun­ter­ing ac­cess to the <code>translation</code> at­tribute.</p>
<p>But yeah, while al­most any­thing is pos­si­ble in Python, it could give a hand
here — am I the first per­son ev­er that needs this func­tion­al­i­ty?</p>
</section>
</section>
<section id="zero-copy-data-transfer">
<h2><a href="#zero-copy-data-transfer">Ze­ro-copy da­ta trans­fer</a></h2>
<p>One very im­por­tant part of Python is the <a href="https://docs.python.org/3/c-api/buffer.html">Buf­fer Pro­to­col</a>.
It al­lows ze­ro-copy shar­ing of ar­bi­trati­ly shaped da­ta be­tween C and Python —
sim­ple tight­ly-packed lin­ear ar­rays, 2D ma­tri­ces, or a green chan­nel of a low­er
right quar­ter of an im­age flipped up­side down. Hav­ing a full sup­port for the
buf­fer pro­to­col was among the rea­sony why <a href="https://doc.magnum.graphics/corrade/classCorrade_1_1Containers_1_1StridedArrayView.html">Con­tain­ers:…</a></p></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.magnum.graphics/announcements/introducing-python-bindings/">https://blog.magnum.graphics/announcements/introducing-python-bindings/</a></em></p>]]>
            </description>
            <link>https://blog.magnum.graphics/announcements/introducing-python-bindings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631106</guid>
            <pubDate>Tue, 29 Sep 2020 18:11:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recurrent neural networks: building a custom LSTM cell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631016">thread link</a>) | @sergioskar
<br/>
September 29, 2020 | https://theaisummer.com/understanding-lstm/ | <a href="https://web.archive.org/web/*/https://theaisummer.com/understanding-lstm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            
                            

<p>An infinite amount of times I have found myself in desperate situations because I had no idea what was happening under the hood. And, for a lot of people in the computer vision community, recurrent neural networks (RNNs) are like this. More or less, <strong>another black box in the pile</strong>.</p>

<p>However, in this tutorial, we will attempt to open the RNN magic black box and unravel its mysteries!</p>

<p>Even though I have come across hundreds of tutorials on LSTM’s out there, I felt there was something missing. Therefore, I honestly hope that <strong>this tutorial serves as a modern guide to RNNs</strong>. We try to deal with multiple details of practical nature. To this end, we <strong>will build upon their fundamental concepts.</strong></p>

<p>The vast application field of RNN’s includes <a href="https://theaisummer.com/Bitcon_prediction_LSTM/" target="_blank">sequence prediction</a>, activity recognition, video classification as well as a variety of natural language processing tasks. After a careful inspection of the equations, <strong>we will build our own LSTM cell to validate our understanding</strong>. Finally, we will make some associations with convolutional neural networks to maximize our comprehension. Accompanying code for this tutorial can be found <a href="https://drive.google.com/file/u/0/d/1Rb8OiF-AZ_Y3uFj1O2S0IyocFMhHoTCV/edit" rel="noopener" target="_blank">here</a>.</p>

<p>It is true that by the moment you start to read about RNN’s, especially with a computer vision background, concepts misleadings start to arise. Less literally:</p>

<p>“Backpropagation with stochastic gradient descent (SGD) does not magically make your network work. Batch normalization does not magically make it converge faster. <strong>Recurrent Neural Networks (RNNs) don’t magically let you “plug in” sequences</strong>. (…) If you insist on using the technology without understanding how it works you are likely to fail.” ~ <strong><a href="https://twitter.com/karpathy" rel="noopener" target="_blank">Andrey Karpathy</a></strong> (Director of AI at Tesla)</p>

<p>The abstraction of RNN’s implementations doesn’t allow users to understand how we deal with the time dimension in sequences! However, by understanding how it works you can write optimized code and practice extensibility, in a way that you weren’t confident enough to do before.</p>

<p>Finally, a more holistic approach in RNN’s can be found on <a href="https://click.linksynergy.com/deeplink?id=r24KwW5qbBo&amp;mid=40328&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fnlp-sequence-models" rel="noopener" target="_blank">Sequence models from the Deep Learning specialization course</a> offered by Coursera.</p>

<h3 id="contents">Contents</h3>
<ul id="markdown-toc">
  <li><a href="#a-simple-rnn-cell" id="markdown-toc-a-simple-rnn-cell">A simple RNN cell</a></li>
  <li><a href="#what-is-back-propagation-through-time" id="markdown-toc-what-is-back-propagation-through-time">What is Back-propagation through time?</a></li>
  <li><a href="#lstm-long-short-term-memory-cells" id="markdown-toc-lstm-long-short-term-memory-cells">LSTM: Long-short term memory cells</a></li>
  <li><a href="#writing-a-custom-lstm-cell-in-pytorch" id="markdown-toc-writing-a-custom-lstm-cell-in-pytorch">Writing a custom LSTM cell in Pytorch</a></li>
  <li><a href="#connecting-lstm-cells-across-time-and-space" id="markdown-toc-connecting-lstm-cells-across-time-and-space">Connecting LSTM cells across time and space</a></li>
  <li><a href="#validation-learning-a-sine-wave-with-an-lstm" id="markdown-toc-validation-learning-a-sine-wave-with-an-lstm">Validation: Learning a sine wave with an LSTM</a></li>
  <li><a href="#bidirectional-lstm-and-its-pytorch-documentation" id="markdown-toc-bidirectional-lstm-and-its-pytorch-documentation">Bidirectional LSTM and it’s Pytorch documentation</a></li>
  <li><a href="#input-to-output-mappings-with-recurrent-models" id="markdown-toc-input-to-output-mappings-with-recurrent-models">Input to output mappings with recurrent models</a></li>
  <li><a href="#the-theoretical-limit-of-modeling-a-large-dimension-recurrency-vs-convolution" id="markdown-toc-the-theoretical-limit-of-modeling-a-large-dimension-recurrency-vs-convolution">The theoretical limit of modeling a large dimension: Recurrency VS Convolution</a></li>
  <li><a href="#discussion-and-conclusion" id="markdown-toc-discussion-and-conclusion">Discussion and conclusion</a></li>
</ul>

<h2 id="a-simple-rnn-cell">A simple RNN cell</h2>

<p>Recurrent cells are neural networks (usually small) for processing <strong>sequential data</strong>. As we already know, convolutional layers are specialized for processing grid-structured values (i.e. images). On the contrary, <strong>recurrent layers are designed for processing long sequences</strong>, without any extra sequence-based design choice [1].</p>

<p>One can achieve this by connecting the timesteps’ output to the input! This is called sequence <strong>unrolling.</strong> By processing the whole sequence, we have an algorithm that takes into account the previous states of the sequence. In this manner, we have the <strong>first notion of memory</strong> (a cell)! Let’s look at it:</p>

<p><img src="https://theaisummer.com/assets/img/posts/understanding-lstm/rnn-cell-time-unfold.png" alt="rnn-cell-time-unfold">
<em>Visualization is borrowed from <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="noopener" target="_blank">Wiki</a></em></p>

<p>The majority of common recurrent cells can also process sequences of variable length. This is really important for many applications such as videos, that contain a different number of images. One can view the RNN cell as a common <strong>neural network with</strong> <strong>shared weights for the multiple timesteps.</strong> With this modification, the weights of the cell now have access to the previous states of the sequence.</p>

<p>But <strong>how</strong> can we possibly train such sequential models?</p>

<h2 id="what-is-back-propagation-through-time">What is Back-propagation through time?</h2>

<p>Most practitioners with computer vision background have little idea of what recurrency means. And it is indeed difficult to understand. Because the frameworks assume that you already know how it works. However, if you want to find an efficient solution to your problem, you should carefully design your architecture based on the problem.</p>

<p><strong>The magic of RNN networks that nobody sees is the input unrolling</strong>. The latter means that given a sequence of length N, you process the input into timesteps.</p>

<blockquote>
  <p>We choose to model the time dimension with RNN’s, because we want to learn temporal and often long-term dependencies.</p>
</blockquote>

<p>Right now, it is true that convolutions cannot handle because they have a finite receptive field. Note that, in theory, you can apply a recurrent model in any dimension.</p>

<p>In terms of training an RNN model, the issue is that now we have a time-sequence. That’s why input unrolling is the only way we can make backpropagation work!</p>

<p>So, how can you learn a time-sequence? Ideally, we would like the memory (parameters) of the cells to have taken into account all the input sequences. Otherwise, we would not be able to learn the desired mapping. In essence, <strong>backpropagation requires a separate layer for each time step with the same weights for all layers</strong> (<strong>input unrolling)</strong>! The following image helps to understand this tricky idea.</p>

<p><img src="https://theaisummer.com/assets/img/posts/understanding-lstm/input-unrolling-and-backpropagation-through-time.png" alt="input-unrolling-and-backpropagation-through-time">
<em>Source: O’Reilly: hands-on-reinforcement-learning](Source: O’Reilly: hands-on-reinforcement-learning)</em></p>

<p>Backpropagation through time was created based on the pre-described observation. So, <strong>based on the chunked (unrolled) input, we can calculate a different loss per timestep</strong>. Then, we can backpropagate the error of multiple losses to the memory cells. In this direction, <strong>one can compute the gradients from multiple paths (timesteps) that then are added to calculate the final gradient</strong>. For this reason, we may use different optimizers or normalization methods in recurrent architectures.</p>

<p>In other words, we represent the RNN as a repeated (feedforward) network. More importantly, <strong>the time and space complexity to produce the output of the RNN is asymptotically linear to the input length (timesteps)</strong>. This practical bottleneck introduces the computational limit of training really large sequences.</p>

<p>In fact, a similar idea is implemented in practice when you have a small GPU and you want to train your model with a bigger batch size than your memory supports. You perform forward propagation with the first batch and calculate the loss. Afterwards, you repeat the same thing with the second batch and average the losses from different batches. In this way, gradients are <strong><a href="https://www.quora.com/What-does-it-mean-that-gradients-are-accumulated-in-Pytorch-and-what-is-the-use-for-it" rel="noopener" target="_blank">accumulated</a>.</strong> With this trick of the low budget machine learners, you basically perform a similar operation to backpropagation through time. Finally,<a href="https://www.youtube.com/watch?v=6jfw8MuKwpI" rel="noopener" target="_blank"> siamese networks</a> with shared weights also roughly exploit this concept.</p>

<p>Let’s now see the inside of an LSTM [5] cell.</p>

<h2 id="lstm-long-short-term-memory-cells">LSTM: Long-short term memory cells</h2>

<h3 id="why-lstm">Why LSTM?</h3>

<p>One of the most fundamental works in the field was by <a href="https://arxiv.org/abs/1503.04069" rel="noopener" target="_blank">Greff et al. 2016</a> [4]. Briefly, they showed that <strong>the proposed variations of RNN do not provide any significant improvement in a large scale study compared to LSTM</strong>. Therefore, LSTM is the dominant architecture in RNNs. That’s why we will focus on this RNN variation.</p>

<h3 id="how-lstm-works">How LSTM works?</h3>

<p>We can write forever about what an LSTM cell is, or how it is used in many applications. However, the language of mathematics makes this world beautiful and compact for us. Let’s see the math. Don’t be scared! <strong>We will slowly clarify every term, by inspecting every equation separately</strong>.</p>

<blockquote>
  <p>Before we begin, note that in all the equations, the weight matrices (W) are indexed, with the <strong>first index being the vector that they process</strong>, while the <strong>second index refers to the representation</strong> (i.e. input gate, forget gate).</p>
</blockquote>

<p>To avoid confusion and maximize understanding, we will use the common notation: <strong>matrices are depicted with capital bold letters while vectors with non-capital bold letters</strong>. For the element-wise multiplication, I used the dot with the outer circle symbol, referred to as the <a href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)" rel="noopener" target="_blank">Hadamard product</a> [9] in the bibliography.</p>

<h3 id="equations-of-the-lstm-cell">Equations of the LSTM cell</h3>

<p>For \(\textbf{x}_t \in R^{N}\) , where N is the feature length of each timestep, while \(\textbf{i}_t,\textbf{f}_t,\textbf{o}_t,\textbf{h}_t,\textbf{h}_{t-1},\textbf{c}_t,\textbf{c}_{t-1},\textbf{b}  \in R^{H}\) , where H is the hidden state dimension, the LSTM equations are the following:</p><p>

\[\textbf{i}_t = \sigma( \textbf{W}_{xi} \textbf{x}_t + \textbf{W}_{hi} \textbf{h}_{t-1} + \textbf{W}_{ci} \textbf{c}_{t-1} + \textbf{b}_i)  \quad\quad(1)\]

\[\textbf{f}_t = \sigma( \textbf{W}_{xf} \textbf{x}_t + \textbf{W}_{hf} \textbf{h}_{t-1} + \textbf{W}_{cf} \textbf{c}_{t-1} + \textbf{b}_f) \quad\quad(2)\]

\[\textbf{c}_t = \textbf{f}_t \odot \textbf{c}_{t-1} + \textbf{i}_t \odot tanh( \textbf{W}_{xc} x_t + \textbf{W}_{hc} \textbf{h}_{t-1} + \textbf{b}_c ) \quad\quad(3)\]

\[\textbf{o}_t = \sigma( \textbf{W}_{xo} \textbf{x}_t + \textbf{W}_{h0} \textbf{h}_{t-1} + \textbf{W}_{co} \textbf{c}_{t} + \textbf{b}_o)  \quad\quad(4)\]

\[\textbf{h}_t = \textbf{o}_t \odot tanh(\textbf{c}_t) \quad\quad(5)\]

</p><p>The LSTM cell equations were written based on <a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM" rel="noopener" target="_blank">Pytorch documentation</a> because you will probably use the existing layer in your project. In the original paper, \(\textbf{c}_{t-1}\)  is included in the Equation (1) and (2), but you can omit it. For consistency reasons with the Pytorch docs, I will not include these computations in the code. For the record, these kind of connections are called peephole connection in the literature.</p>

<h3 id="equation-1-the-input-gate">Equation 1: the input gate</h3><p>

\[\textbf{i}_t = \sigma( \textbf{W}_{xi} \textbf{x}_t + \textbf{W}_{hi} \textbf{h}_{t-1} + \textbf{W}_{ci} \textbf{c}_{t-1} + \textbf{b}_i)\]

</p><p>The depicted <strong>weight matrices represent the memory of the cell</strong>. You see the input \(\textbf{x}_t\) is in the current input timestep, <strong>while h and c are indexed with the previous timestep</strong>. Every matrix <strong>W</strong> is a linear layer (or simply a matrix multiplication). This equation enables us to the following:</p>

<p>a) take multiple linear combinations of <strong>x</strong>,<strong>h</strong>,<strong>c</strong>, and</p>

<p>b) match the dimensionality of input <strong>x</strong> to the one of <strong>h</strong> and <strong>c</strong>.</p>

<p>The dimensionalities of <strong>h</strong> and <strong>c</strong> are basically the <strong>hidden states</strong> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theaisummer.com/understanding-lstm/">https://theaisummer.com/understanding-lstm/</a></em></p>]]>
            </description>
            <link>https://theaisummer.com/understanding-lstm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631016</guid>
            <pubDate>Tue, 29 Sep 2020 18:03:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[He Social Dilemma Is a Great Conversation Starter but What Does the Science Say?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630893">thread link</a>) | @laurex
<br/>
September 29, 2020 | https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say | <a href="https://web.archive.org/web/*/https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-3d2d994e3c2ce78e7eaa"><div><p>Despite the occasional dash of <a href="https://ourworldindata.org/"><span>statistical optimism</span></a>, it’s difficult to escape the sense that things — broadly considered — are not going well. The pandemic wears on. Protesters fill the streets. The election is imperiled. Wherever one looks, the world (or at least the United States) appears to be on a downward slide. It is tempting, amid this plethora of apparent problems, to seek out a root cause. <a href="https://www.netflix.com/browse?jbv=81254224"><span><em>The Social Dilemma</em></span></a>, a new documentary from Netflix, makes the case for a potential culprit: social media, the business models that drive it, and the misaligned incentives that inevitably result.</p><p>As an activist call-to-arms, the film is chilling and effective. Using a mix of interviews and dramatizations, director Jeff Orlowski depicts and describes all the headline issues: addiction, distraction, depression, anxiety, social comparison, echo chambers, polarization, radicalization, misinformation, and conspiracy theory. Readers acquainted with the <a href="https://www.humanetech.com/"><span>Center for Humane Technology</span></a> will recognize many familiar faces and arguments. Tristan Harris, the Center’s founder, headlines a long list of technology insiders explaining how they’ve come to view the products they built as destructive.</p><p>Harris <a href="https://samharris.org/podcasts/218-welcome-cult-factory/"><span>has stated</span></a> that one of his great hopes is that, in a world where shared realities have broken down, this film will at least provide “a new shared reality <em>about that breakdown of our shared reality</em>.” But as <a href="https://twitter.com/ShuhBillSkee/status/1305805667735830529?s=20"><span>mixed reactions</span></a> to the film attest, building consensus about a topic as complex and controversial as this one is difficult in our day and age. If <em>The Social Dilemma</em> works to stir up a larger public conversation about technology and its damaging effects, we hope that the next phase of that conversation can be informed by the best scientific research. In that spirit, below we address some of the issues raised in the film and what the science has to say about them.</p><h3><strong>Addiction</strong></h3><p>Dr. Anna Lembke, a Stanford psychiatrist and addiction expert, summarizes her view in the film thus: “Social media is a drug.” Depending on who is saying it and what they say afterwards, this statement can mean many things, from the banal claim that “social media can be fun to use” to the preposterous <em>Independent</em> headline, <a href="https://www.independent.co.uk/news/education/education-news/child-smart-phones-cocaine-addiction-expert-mandy-saligari-harley-street-charter-clinic-technology-teenagers-a7777941.html"><span>“Giving your child a smartphone is like giving them a gram of cocaine.”</span></a> Lembke’s view falls somewhere in between: she doesn’t draw any direct comparisons to cocaine, but she warns that social media plays upon our “biological imperative to connect with other people,” which acts through “the release of dopamine in the reward pathway” -- the <a href="https://www.drugabuse.gov/publications/research-reports/cocaine/how-does-cocaine-produce-its-effects"><span>same pathway</span></a> the cocaine acts on.&nbsp;</p><p>Of course, connecting with others in person releases dopamine as well. If social media is an addiction, we have to explain why in terms that go beyond a healthy teenage interest in social life. Psychology of Technology Institute (PTI) advisor Adam Alter is <a href="https://www.youtube.com/watch?v=F3WZv5sv-qI&amp;list=PLhM_FlxNBM3pyKEcnphj1wHO12GR52x3l&amp;index=12"><span>quick to distinguish</span></a> between substance addictions of the kind fostered by drugs and behavioral addictions like gambling. Social media addiction would fall in the latter category. But as he points out in <a href="https://www.youtube.com/watch?v=3-szkJew1j4&amp;list=PLhM_FlxNBM3pyKEcnphj1wHO12GR52x3l&amp;index=13"><span>our interview with him</span></a>, using the term “addiction” too loosely can lead to the conclusion that a compulsive behavior like <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1360-0443.1990.tb01618.x"><span>breathing is an “addiction”</span></a> too. Pathology is the crucial factor here: to claim that social media is addictive in the clinical sense, we have to show that it has harmful effects.</p><p>In the film, Lembke’s commentary is played alongside a dramatization in which a family attempts to impose a no-screens-at-dinner rule. The attempt fails when the younger daughter in the family smashes the time-locked container the phones are being held in with a hammer. In the process, she breaks her older brother’s phone screen, leading to a deal: if the son can abstain from using his phone for a week, the mother agrees to buy him a new screen.&nbsp;</p><p>Here, the filmmakers make an important point. The powerful algorithms and engagement teams behind social media platforms are personified in the film by a three-person team (all played by Vincent Kartheiser) in a control room. When the son begins his week of abstinence, the team springs into action, sending him a notification that his crush has begun dating another guy. The fact that these dramas of teenage life are now frequently mediated by third parties with independent interests (even if those third parties are faceless algorithms) should give all of us cause for concern. Plausibly, the sight of the notification leads the son to forfeit the deal and check his phone, only to be thrown into a depressive scrolling stupor by the news.&nbsp;</p><p>But the film’s dramatic strategies raise some questions as well. The negative effect on the son’s mood is determined by the bad news in his social life, not by social media alone. Whereas a night of binge-drinking might have negative effects independent of what spurred it, social media platforms are hard to distinguish from the content -- good and bad -- that they host. To avoid a <a href="https://journals.sagepub.com/doi/full/10.1177/1745691620919372"><span>moral panic</span></a> borne of careless cocaine analogies, we have to be clear about the precise conditions and mechanisms that lead social media to be harmful, when in fact it is.</p><h3><strong>Wellbeing</strong></h3><p>Ben, the son in the film, begins a steady descent soon after his night of scrolling. He begins losing sleep and cutting sports practices to stare into his phone. This downward slide is presented as all but inexorable, as the three men in the control room guide Ben’s every choice. <a href="https://www.youtube.com/watch?v=YSV8GT7y3_E">The reality is more complicated</a>. A <a href="https://www.psychologytoday.com/us/blog/brain-waves/201905/worry-over-social-media-use-and-well-being-may-be-misplaced"><span>large meta-analysis</span></a> of social media’s impact on wellbeing by PTI advisor Jeff Hancock revealed little to no effect. <a href="https://www.pnas.org/content/pnas/116/21/10226.full.pdf"><span>Other studies</span></a> have shown that social media’s negative impact on teens in particular is gender-specific (it is more harmful for girls), and dependent on excessive use. A growing consensus suggests a <a href="https://journals.sagepub.com/doi/10.1177/0956797616678438"><span>“goldilocks effect”</span></a>: both too little use of social media and too much are associated with reduced wellbeing, while moderate use can have beneficial effects.</p><p>This shouldn’t be cause for complacency; after all, social media companies do not have any concept of “too much use.” From their point of view, the more we use their services, the better. As Harris points out in the film, we have regulations to prevent energy companies from profiting from our excessive use. To the extent that social media companies have a similar perverse incentive, regulation may be in order.&nbsp;</p><p>But just as “screen-time” is too imprecise a metric to be useful, different types and uses of social media can have very different effects. This shouldn’t be surprising: three hours spent messaging with the love of one’s life over Facebook Messenger likely has more salutary effects on wellbeing than even 15 minutes of indulging in political outrage. <a href="https://www.researchgate.net/publication/283283846_It's_Complicated_Facebook's_Relationship_with_the_Need_to_Belong_and_Depression"><span>Some research</span></a> has borne this out, but much more will be needed if we want to approach regulation responsibly.&nbsp;</p><h3><strong>Echo Chambers</strong></h3><p>Ben’s woes take a dystopian turn when he gets sucked into the rabbithole of an unspecified conspiracy and becomes radicalized by the “extreme center.” His sister’s efforts to dissuade him fall on deaf ears, and soon his whole world becomes enveloped by propagandists telling him not to trust the system. If <em>The Social Dilemma</em> has a primary thesis, it’s that the information siloing that leads to Ben’s radicalization is unsustainable for democracy. Ben’s case, which has many <a href="https://www.theatlantic.com/ideas/archive/2020/05/shadowland-introduction/610840/"><span>depressing real-life analogues</span></a>, is portrayed as an extreme version of what has happened to all of us: recommendation algorithms create echo chambers that erode our shared reality and turn us against one another.</p><p>In the popular imagination, echo chambers act as <a href="https://www.youtube.com/watch?v=VAGnAl9s6OA&amp;list=PLhM_FlxNBM3rzVC0v6ih9P8vSS-tvXxdE&amp;index=7"><span>hermetically sealed</span></a> ideological bubbles that prevent exposure to the other side. On this account, polarization and radicalization occur because we simply don’t know the other side’s positions. In the case of the political left and right, this is <a href="https://5harad.com/papers/bubbles.pdf"><span>not generally true</span></a>. Most politically engaged people <em>do</em> get exposed to the other side; it’s just that this exposure happens in a context that incentivizes <a href="https://static1.squarespace.com/static/538ca3ade4b090f9ef331978/t/5a53c0d49140b7212c35b20e/1515438295247/Crockett_2017_NHB_Outrage.pdf"><span>outrage</span></a> and moral grandstanding rather than mutual understanding. In fact, <a href="https://www.pnas.org/content/115/37/9216"><span>a 2018 study</span></a> showed that more exposure to opposing views online actually <em>increases</em> polarization.</p><p>As we wrote in a prior newsletter, the philosopher C. Thi Nguyen <a href="https://www.cambridge.org/core/journals/episteme/article/echo-chambers-and-epistemic-bubbles/5D4AC3A808C538E17C50A7C09EC706F0"><span>introduces some helpful distinctions here</span></a>. Nguyen distinguishes <em>epistemic bubbles</em> from <em>echo chambers</em>. The former function by excluding opposing views; the latter actively discredit opposing views in advance. Nguyen calls this discrediting “evidential pre-emption.” Because opposing evidence is preemptively dismissed as untrustworthy, echo chambers survive and even strengthen in the face of counter-arguments. This makes them exceedingly difficult to combat. Evidential pre-emption can be seen everywhere from cults to partisan cable news.</p><p>As portrayed in the film, this process interacts in an especially pernicious way with recommendation algorithms. These algorithms do not have infinite capacities; rather, they excel at identifying particular rabbit holes to which they can then pattern-match our interests. As PTI advisor Stuart Russell points out in <a href="https://www.youtube.com/watch?index=3&amp;list=PLhM_FlxNBM3qcXMiZcTxdsFParh_6viiF&amp;v=80M9q1tWN1o"><span>our interview with him</span></a>, one way for a recommendation algorithm to meet its objective of predicting your interests is to <em>make your interests more predictable</em>. And since a political ideologue will be much easier for a recommendation algorithm to satisfy than someone with nuanced views, these algorithms tend to serve us information that makes us more partisan.</p><h3><strong>Polarization</strong></h3><p>As Harris explains in <a href="https://samharris.org/podcasts/218-welcome-cult-factory/"><span>an interview on the Making Sense podcast</span></a>, “we’re about ten years into this mass psychology experiment…[and] actually all of us are kind of running malware and bad code. It’s not just that the other side is wrong; it’s that all of us have been living in such narrow views of reality that we can no longer empathize with each other.” The tricky thing about addressing polarization in a polarized world is that we all tend to see the other side as the problem. Though we can observe the <a href="https://www.pewresearch.org/politics/interactives/political-polarization-1994-2017/"><span>trend of overall polarization</span></a> over time, this does little to moderate our views. Your echo chamber is my oasis of truth …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say">https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say</a></em></p>]]>
            </description>
            <link>https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630893</guid>
            <pubDate>Tue, 29 Sep 2020 17:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A gentle intro to Laplace transform]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630882">thread link</a>) | @R3G1R
<br/>
September 29, 2020 | https://mathvault.ca/laplace-transform/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/laplace-transform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><p>Let us take a moment to ponder how truly bizarre the <strong><a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Key_Transforms" target="_blank" aria-label="Laplace transform (opens in a new tab)" rel="noreferrer noopener">Laplace transform</a></strong> is.</p><p>You put in a sine and get an oddly simple, <strong>arbitrary-looking fraction</strong>. Why do we suddenly have squares?</p><p>You look at the table of <strong>common Laplace transforms</strong> to find a pattern and you see no rhyme, no reason, no obvious link between different functions and their different, very different, results.</p><p>What’s going on here?</p><p>Or so we thought when we first encountered the cursive $\mathcal{L}$ in school.</p><div><figure><img loading="lazy" width="888" height="367" src="https://mathvault.ca/wp-content/uploads/Laplace-Transform.png" alt="Laplace transform of function f" title="Laplace Transform"></figure></div><h2><span id="What_does_the_Laplace_transform_do,_really"></span><a href="#toc">What does the Laplace transform do, really?</a><span></span></h2><p>At a high level, Laplace transform is an <strong><a aria-label="integral transform (opens in a new tab)" href="https://en.wikipedia.org/wiki/Integral_transform#:~:text=In%20mathematics%2C%20an%20integral%20transform,in%20the%20original%20function%20space." target="_blank" rel="noreferrer noopener">integral transform</a></strong> mostly encountered in differential equations — in electrical engineering for instance — where electric circuits are represented as differential equations.</p><p>In fact, it takes a <strong>time-domain function</strong>, where $t$ is the variable, and outputs a <strong>frequency-domain function</strong>, where $s$ is the variable. Definition-wise, Laplace transform takes a function of real variable $f(t)$ (defined for all $t \ge 0$) to a function of complex variable $F(s)$ as follows:</p>\[\mathcal{L}\{f(t)\} = \int_0^{\infty} f(t) e^{-st} \, dt = F(s) \]<h2><span id="Some_Preliminary_Examples"></span><a href="#toc">Some Preliminary Examples</a><span></span></h2><p>What fate awaits <strong>simple functions</strong> as they enter the Laplace transform?</p><p>Take the simplest function: the <strong>constant function</strong> $f(t)=1$. In this case, putting $1$ in the transform yields $1/s$, which means that we went from a constant to a variable-dependent function.</p><iframe src="https://www.youtube.com/embed/OiNh2DswFt4?start=174" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>(Odd but not too worrying. After all, we’ve seen $1/x$ integrating to $\ln x$ in calculus. Not a constant-to-variable situation of course, but an unexpected transformation nonetheless.)</p><p>Let us take it up a notch, with the <strong>linear function</strong> $f(t) = t$. After the transformation, it is turned into $1/s^2$, which means that we went from $1 \to 1/s$ to $t \to 1/s^2$. A pattern begins to emerge.</p><p>Now what about $f(t)=t^n$? With this simple <strong>power function</strong>, we end up with: \[ \mathcal{L}\{ t^n \} = \frac{n!}{s^{n+1}}\] So there was a factorial in $\mathcal{L}\{t\}$ all along, hidden by the fact that $1! = 1$. What else is the transform hiding?</p><p>Here, a glance at a table of <strong><a aria-label="common Laplace transforms (opens in a new tab)" rel="noreferrer noopener" href="https://tutorial.math.lamar.edu/pdf/Laplace_Table.pdf" target="_blank">common Laplace transforms</a></strong> would show that the emerging pattern cannot explain other functions easily. Things get weird, and the weirdness escalates quickly — which brings us back to the sine function.</p><h2><span id="Looking_Inside_the_Laplace_Transform_of_Sine"></span><a href="#toc">Looking Inside the Laplace Transform of Sine</a><span></span></h2><p>Let us unpack what happens to our sine function as we Laplace-transform it. We begin by noticing that a sine function can be expressed as a <strong>complex exponential</strong> — an indirect result of the celebrated <a href="https://mathvault.ca/euler-formula/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Euler’s formula</a>:\[e^{it} = \cos t + i \sin t\]In fact, a sine is often expressed in terms of exponentials for <strong>ease of calculation</strong>, so if we apply that to the function $f(t) = \sin (at)$, we would get: \[ \sin(at) = \frac{e^{iat}-e^{-iat}}{2i} \]Thus the <strong>Laplace transform</strong> of $\sin(at)$ then becomes:<br>\[ \mathcal{L}\{\sin(at)\} = \frac{1}{2i} \int\limits_0^{\infty} (e^{iat}-e^{-iat}) e^{-st} \, dt \]which means that we have a <strong>product of exponentials</strong>. Distributing the terms, we get:<br>\[ \mathcal{L}\{\sin(at)\} = \frac{1}{2i} \int\limits_0^{\infty} e^{iat-st}-e^{-iat-st} \, dt \]</p><p>Here, <strong>factoring</strong> the $t$ in the exponents yields:<br>\[ \mathcal{L}\{\sin(at)\} = \frac{1}{2i} \int\limits_0^{\infty} e^{(ia-s)t}-e^{(-ia-s)t} \, dt \]and since $\mathrm{Re}(s) \gt 0$ by assumption, we can proceed with the integration from $0$ to $\infty$ as usual:<br>\[ \mathcal{L}\{\sin(at)\} = \left.\frac{e^{(ia-s)t}}{2i (ia-s)}\right|_0^{\infty}-\left.\frac{e^{(-ia-s)t}}{2i (-ia-s)}\right|_0^{\infty} \]</p><p>Let us simplify further. <strong>Distributing</strong> the $i$ inside the parentheses, we get:<br>\[ \mathcal{L}\{\sin(at)\} = \left.\frac{e^{(ia-s)t}}{2(-a-is)}\right|_0^{\infty}-\left.\frac{e^{(-ia-s)t}}{2(a-is)}\right|_0^{\infty} \]By evaluating the $t$ at the <strong>boundaries</strong>, we get:<br>\[ \mathcal{L}\{\sin(at)\} = \left( \frac{e^{(ia-s) \cdot \infty}}{2(-a-is)}-\frac{e^{(ia-s) \cdot 0}}{2 (-a-is)}\right)-\left(\frac{e^{(-ia-s)\cdot\infty}}{2(a-is)}-\frac{e^{(-ia-s)\cdot 0}}{2(a-is)}\right) \]And because $\mathrm{Re}(s) &gt; 0$ by assumption, both $e^{(ia-s) \cdot \infty}$ and $e^{(-ia-s)\cdot\infty}$ oscillate to $0$ (i.e., <strong><a aria-label="vanish at infinity (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/math-glossary/#vanish" target="_blank">vanish at infinity</a></strong>), after which we are then left with:\[ \mathcal{L}\{\sin(at)\} = \frac{1}{-2(-a-is)} + \frac{1}{2(a-is)} \]Once there, merging the <strong>fractions</strong> together would yield:\begin{align*} \mathcal{L}\{\sin(at)\} &amp; = \frac{2(a-is)-2(-a-is)}{-4 (a-is)(-a-is)} \\ &amp; = \frac{2a-2is + 2a+2is}{4 (a^2 + isa-isa + s^2)} \\ &amp; = \frac{4a}{4(a^2 + s^2)} \\ &amp; = \frac{a}{a^2 + s^2} \end{align*}which shows that after Laplace transform, a sine is turned into a more tractable <strong>geometric function</strong>. By following similar reasoning, the Laplace transform of cosine can be shown to be equal to the following expression as well: \[ \mathcal{L}\{\cos (at)\} = \frac{s}{a^2 + s^2} \qquad (\mathrm{Re}(s) &gt; 0) \] But then, one might argue “Why do we need to transform trigonometric functions like this when we can just <strong>integrate</strong> them?”</p><h2><span id="Diverging_Functions_What_the_Laplace_Transform_is_for"></span><a href="#toc">Diverging Functions: What the Laplace Transform is for</a><span></span></h2><p>What if we throw a wrench in there by introducing a <strong>diverging function</strong>, say, $f(t)=e^{at}$? As it turns out, the Laplace transform of the exponential $e^{at}$ is actually deceptively simple: \begin{align*} \mathcal{L}\{e^{at}\} &amp; = \int_0^{\infty} e^{at}e^{-st} \, dt \\ &amp; = \int_0^{\infty} e^{(a-s)t} \, dt \end{align*}Here, we see that so long as $\mathrm{Re}(s) \gt a$, we would get that: \begin{align*} \int_0^{\infty} e^{(a-s)t} \, dt &amp; = \left. \frac{e^{(a-s)t}}{a-s} \right|_0^{\infty} \\ &amp; = 0-\frac{1}{a-s}  \\ &amp; = \frac{1}{s-a} \end{align*} That is, as long as $\mathrm{Re}(s) &gt; a$, the Laplace transform of $e^{at}$ is a simple $1/(s-a)$. Here’s a <strong>video version</strong> of the derivation for the record.</p><iframe src="https://www.youtube.com/embed/33TYoybjqPg?start=50" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>On the other hand, if we mix the exponential $e^{at}$ with the <strong>power function</strong> $t^n$, we would then have: \[ \mathcal{L}\{t^n e^{at}\} = \int\limits_0^{\infty} t^n e^{at} e^{-st} \, dt \] which, after a bit of <a aria-label="recursion (opens in a new tab)" href="https://mathvault.ca/math-glossary/#recursion" target="_blank" rel="noreferrer noopener">recursion</a> and <a aria-label="integration by parts (opens in a new tab)" href="https://mathvault.ca/integration-overshooting-method/#Integration_By_Parts" target="_blank" rel="noreferrer noopener">integration by parts</a>, would become:\[ \frac{n!}{(s-a)^{n+1}} \]Here, notice how the transforms of exponential and power function are both <strong>represented</strong> in the expression, with the factorial $n!$, the $1/(s-a)$ fraction, and the $n + 1$ exponent.</p><p>In fact, it turns out that we can integrate <em>any</em> function with the Laplace transform, as long as it does not <strong>diverge</strong> faster than the $e^{at}$ exponential. In the tables of Laplace transforms, you might have noticed the $\mathrm{Re}(s) \gt a$ condition. That is what the condition is alluding to.</p><h2><span id="A_Transform_of_Unfathomable_Power"></span><a href="#toc">A Transform of Unfathomable Power</a><span></span></h2><p>However, what we have seen is only the tip of the iceberg, since we can also use Laplace transform to transform the <strong>derivatives</strong> as well. In goes $f^{(n)}(t)$. Something happens. Then out goes:\[ s^n \mathcal{L}\{f(t)\}-\sum_{r=0}^{n-1} s^{n-1-r} f^{(r)}(0) \]For example, when $n=2$, we have that:\[ \mathcal{L}\{f^{\prime\prime}(t)\} = s^2 \mathcal{L}\{f(t)\}-sf(0)-f'(0) \]In addition to the derivatives, the $\mathcal{L}$ can also process some <strong>integrals</strong>: the integral sine, cosine and exponential, as well as the <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Continuous_Probability_Distributions_and_Associated_Functions" target="_blank" aria-label="error function (opens in a new tab)" rel="noreferrer noopener">error function</a> — to name a few.</p><p>But that’s not all. There is also the <strong><a aria-label="inverse Laplace transform (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Key_Transforms" target="_blank">inverse Laplace transform</a></strong>, which takes a frequency-domain function and renders a time-domain function.</p><p>In fact, performing the transform from time to frequency and back once introduces a factor of $1/2\pi$. Sometimes, you’ll see the whole fraction in front of the inverse function, while other times, the transform and its inverse share a factor of $1/\sqrt{2\pi}$.</p><p>This is as if the Kraken could restitute the boat intact — but only for a factor of $1/2\pi$.</p><p>The Laplace transform, even after all those years, never ceases to bring us awe with its power. Here’s a <strong>table</strong> summarizing the transforms we’ve discussed thus far:</p><figure><table><thead><tr><th data-align="center">Function</th><th data-align="center">Laplace Transform</th></tr></thead><tbody><tr><td data-align="center">$1$</td><td data-align="center">$\dfrac{1}{s}$</td></tr><tr><td data-align="center">$t$</td><td data-align="center">$\dfrac{1}{s^2}$</td></tr><tr><td data-align="center">$t^n$</td><td data-align="center">$\dfrac{n!}{s^{n+1}}$</td></tr><tr><td data-align="center">$e^{at}$</td><td data-align="center">$\dfrac{1}{s-a}$</td></tr><tr><td data-align="center">$\sin(at)$</td><td data-align="center">$\dfrac{a}{a^2+s^2}$</td></tr><tr><td data-align="center">$\cos(at)$</td><td data-align="center">$\dfrac{s}{a^2+s^2}$</td></tr><tr><td data-align="center">$t^n e^{at}$</td><td data-align="center">$\dfrac{n!}{(s-a)^{n+1}}$</td></tr><tr><td data-align="center">$f^{(2)}(t)$</td><td data-align="center">$\displaystyle s^2 \mathcal{L}\{f(t)\}-sf(0)-f'(0)$</td></tr><tr><td data-align="center">$f^{(n)}(t)$</td><td data-align="center">$\displaystyle s^n \mathcal{L}\{f(t)\}-\sum_{r=0}^{n-1} s^{n-1-r} f^{(r)}(0)$</td></tr></tbody></table></figure> <span id="tve_leads_end_content"></span></section><div data-ct="thrive_author_box" data-ct-name="About the Author" data-shortcode="thrive_author_box" data-css="tve-u-16e8d3838e9"><div data-css="tve-u-17362c8dffa"><div data-css="tve-u-17362c8dffb"><div data-css="tve-u-17362c8dffc"><div data-css="tve-u-17362c8dffd"><p><span><img alt="Math Vault Standard Post" src="https://secure.gravatar.com/avatar/3e6005b4ba6abd9cef0c322ce2905523?s=256&amp;r=g" srcset="https://secure.gravatar.com/avatar/3e6005b4ba6abd9cef0c322ce2905523?s=512&amp;r=g 2x" loading="lazy" data-d-f="author" title="Math Vault Standard Post" data-css=""></span></p><p data-css="tve-u-17362c8dfff"><span data-css="tve-u-1739c03d42c" data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_author_name" data-shortcode-name="Author Name">Kim Thibault</span></p></div></div><div data-css="tve-u-17362c8e001"><div data-css="tve-u-17362c8e002"><p data-css="tve-u-17362c8e003"><h4 data-css="tve-u-17362cd5fcd">About the author</h4></p><p data-css="tve-u-17362c8e006"><span data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_author_bio" data-shortcode-name="Author Bio" data-css="tve-u-1736301163e">Kim Thibault is an incorrigible polymath. After a Ph.D. in Physics, she did applied research in machine learning for audio, then a stint in programming, to finally become an author and scientific translator. She occasionally solves differential equations as a hobby. Her blog can be found at <a href="http://kimthibault.mystrikingly.com/blog"><strong>kimthibault.mystrikingly.com/blog</strong></a> and her professional profile at <a href="https://linkedin.com/in/kimthibaultphd">linkedin.com/in/kimthibaultphd</a>.</span></p></div></div></div></div></div><p data-css="tve-u-17358ffc154"><h4 data-css="tve-u-170199ce799">You may also like</h4></p><div data-type="grid" data-pagination-type="none" data-pages_near_current="2" data-css="tve-u-17355fb4c5e" data-total_post_count="16" data-total_sticky_count="0" data-disabled-links="1" data-no_posts_text=""><article id="post-31923" tcb_hover_state_parent="" data-selector=".post-wrapper" data-permalink="https://mathvault.ca/euler-formula/"><a href="https://mathvault.ca/euler-formula/" title="Euler’s Formula: A Complete Guide" data-css=""><img width="900" height="572" src="https://mathvault.ca/wp-content/uploads/Euler-formula-diagram.png" alt="Diagram illustrating Euler's formula for complex numbers" loading="lazy" title="Euler formula diagram"></a><div><p data-css="tve-u-17356046414">		<span data-attr-link="0" data-attr-rel="0" data-attr-target="0" data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_title" data-shortcode-name="Post title" data-css="tve-u-17391b16085">Euler’s Formula: A Complete Guide</span></p> 	<br></div></article><article id="post-9087" tcb_hover_state_parent="" data-selector=".post-wrapper" data-permalink="https://mathvault.ca/statistical-significance/"><a href="https://mathvault.ca/statistical-significance/" title="A First Introduction to Statistical Significance — Through Dice Rolling and Other Uncanny Examples" data-css=""><img width="1000" height="600" src="https://mathvault.ca/wp-content/uploads/Statistical-Significance.jpg" alt="Header image of Math Vault's A Primer on Statistical Significance" loading="lazy" title="Statistical Significance"></a><div><p data-css="tve-u-17356046414">		<span data-attr-link="0" data-attr-rel="0" data-attr-target="0" data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_title" data-shortcode-name="Post title" data-css="tve-u-17391b16085">A First Introduction to Statistical Significance — Through Dice Rolling and Other Uncanny Examples</span></p> 	<br></div></article></div></div></div></div></div></div>]]>
            </description>
            <link>https://mathvault.ca/laplace-transform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630882</guid>
            <pubDate>Tue, 29 Sep 2020 17:53:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kaleidoscopic Rainbow Pattern Generator]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24630724">thread link</a>) | @newcoders
<br/>
September 29, 2020 | https://www.csh.bz/line/05xp.html?play | <a href="https://web.archive.org/web/*/https://www.csh.bz/line/05xp.html?play">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.csh.bz/line/05xp.html?play</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630724</guid>
            <pubDate>Tue, 29 Sep 2020 17:41:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effective Shell – Fly on the Command Line]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630268">thread link</a>) | @dwmkerr
<br/>
September 29, 2020 | https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is my favourite chapter of the book! The tricks I picked up on rapidly moving around in the command line have saved me an enormous amount of time over the years.</p><p>In this chapter, we'll look at the ways you can rapidly move your cursor around on the command line, as well as how to easily open up the current command in an editor (which is <em>incredibly</em> useful if you realise you are building a more complex sequence of commands).</p><p>Below is a quick reference which you can use - we'll see each operation in more detail as we go through the chapter!</p><p><a href="https://github.com/dwmkerr/effective-shell"><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/command-line.png" alt="command line"></a></p><ul><li><a href="#basic-navigation">Basic Navigation</a><ul><li><a href="#go-to-beginning--end">Go to beginning / end</a></li><li><a href="#move-backwards--forwards-one-word">Move backwards / forwards one word</a></li><li><a href="#delete-a-word-or-undo-a-mistake">Delete a word or undo a mistake</a></li><li><a href="#delete-the-next-word">Delete the next word</a></li><li><a href="#delete-to-beginning--clear-line">Delete to beginning / clear line</a></li><li><a href="#delete-to-end">Delete to end</a></li></ul></li><li><a href="#searching">Searching</a><ul><li><a href="#search-backwards--forwards">Search Backwards / Forwards</a></li><li><a href="#run-the-command-found-in-a-search">Run the command found in a search</a></li><li><a href="#edit-the-command-found">Edit the command found</a></li><li><a href="#stop-searching">Stop Searching</a></li></ul></li><li><a href="#editing-in-place">Editing In-Place</a></li><li><a href="#clear-the-screen">Clear the Screen</a></li><li><a href="#see-the-history-and-execute-a-recent-command">See the History and Execute a Recent Command</a></li><li><a href="#pro-tip-all-the-keys">Pro Tip: All The Keys!</a></li><li><a href="#pro-tip-transposing">Pro Tip: Transposing!</a></li><li><a href="#the-power-of-readline">The Power of Readline</a></li></ul><p>Let's assume we have a very simple command we are writing, which is going to write a quote to a text file:</p><div><pre><code data-lang="bash">echo <span>"The trouble with writing fiction is that it has to make sense,
</span><span>whereas real life doesn't. -- Iain M. Banks"</span> &gt;&gt; quote.txt
</code></pre></div><p>Navigating around long lines of text is a slow process if you are only relying on the arrow keys.</p><p>Let's see how we can quickly move around and manipulate text!</p><h2 id="go-to-beginning--end">Go to beginning / end</h2><p>Quickly jump to the beginning or end of the text:</p><ul><li><code>Ctrl + a</code> - Go to beginning</li><li><code>Ctrl + e</code> - Go to end</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/begin-end.gif" alt="begin / end"></p><h2 id="move-backwards--forwards-one-word">Move backwards / forwards one word</h2><p>For a little more fine-grained movement, you can jump backwards or forwards one word at a time:</p><ul><li><code>Alt + b</code> - Go back one word</li><li><code>Alt + f</code> - Go forward one word</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/forward-backwards.gif" alt="backward / forward"></p><h2 id="delete-a-word-or-undo-a-mistake">Delete a word or undo a mistake</h2><p>As this is the first operation we're seeing which <em>changes</em> the text, it is useful to remember how to <em>undo</em> any changes you make!</p><ul><li><code>Ctrl + w</code> - Delete a word</li><li><code>Ctrl + -</code> - Undo most recent change</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/delete-undo.gif" alt="delete / undo"></p><h2 id="delete-the-next-word">Delete the next word</h2><p>We've seen how to delete the word on or behind the cursor, now let's see how to delete the <em>next</em> word:</p><ul><li><code>Alt + d</code> - Delete next word</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/delete-next-word.gif" alt="delete next word"></p><p>Remember, just like any edit you can undo these changes with the <code>Ctrl + -</code> command.</p><h2 id="delete-to-beginning--clear-line">Delete to beginning / clear line</h2><p>In the Bash shell, you can delete all the way to the beginning of the line with <code>Ctrl + u</code>. However - if you are using the Z-Shell this will delete the entire line!</p><ul><li><code>Ctrl + u</code> - Delete to beginning of line OR delete line</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/delete-to-beginning.gif" alt="delete to beginning"></p><h2 id="delete-to-end">Delete to end</h2><p>You can also delete all of the way to the end of the line.</p><ul><li><code>Ctrl + k</code> - Delete to end</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/delete-to-end.gif" alt="delete to end"></p><p>When you find yourself repeatedly using the arrow or delete keys, refer back to this section to remind yourself of the shortcut - it will save a lot of time in the long run!</p><p>Once you have the basic navigation commands down, the next essential is <em>searching</em>. Let's assume we've run the following three commands:</p><div><pre><code data-lang="bash">$ command1 param1 param2 param3
$ command2 param4 param5 param6
$ command3 param7 param8 param9
</code></pre></div><p>You can search backwards or forwards with <code>Ctrl + r</code> and <code>Ctrl + s</code>. This will search in the current line and then iteratively through previous lines:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-backwards-and-forwards.gif" alt="search backwards and forwards"></p><p>People often remember this as searching through the history - but remember that it actually searches the <em>current line</em> as well. So this is often the fastest way to move to the desired location in the current line.</p><p>This is useful for searching in the current command, but can be also used to quickly search backwards and forwards through the command history:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-commands-backwards-and-forwards.gif" alt="search commands backwards and forwards"></p><p>As you type, your command history is searched, the most recent commands coming first. Use the arrow keys to edit the command, press enter to execute it, or <code>Ctrl + g</code> to cancel the search.</p><p>I think it's a little easier to see these commands in action with a more realistic example, so here's how they look with the text we used earlier.</p><h2 id="search-backwards--forwards">Search Backwards / Forwards</h2><p>Search backwards or forwards through the current line and also the history:</p><ul><li><code>Ctrl + r</code> - Search backwards (<em>reverse</em> search)</li><li><code>Ctrl + s</code> - Search forwards</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-history-next.gif" alt="find next occurrence"></p><h2 id="run-the-command-found-in-a-search">Run the command found in a search</h2><p>This one is easy! Just hit <code>Enter</code>:
<img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-history-execute.gif" alt="execute"></p><h2 id="edit-the-command-found">Edit the command found</h2><p>When you have found the command or positioned the cursor where you want it, use the Left or Right arrow keys to stop searching and to go back into the normal editing mode:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-history-edit.gif" alt="edit command"></p><h2 id="stop-searching">Stop Searching</h2><p>Cancel the search and return back to the text as it was before you started with the <code>Ctrl + g</code> command:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-history-cancel.gif" alt="cancel search"></p><p>These tips and tricks are helpful, but if you are working with a really long or complex command, you might find it useful just to jump into your favourite editor. This is one of those tricks that when you know it, you'll wonder how you lived without it!</p><p>Use <code>Ctrl + x , Ctrl + e</code> to edit-in place, opening the current command line in your default editor:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/edit-in-place.gif" alt="edit in place"></p><p>Now it's important to explain that this is the <em>shell's</em> default editor. This might not be the same as the default editor for your operating system. You can see what the shell is using as its default editor by printing the contents of the <code>EDITOR</code> environment variable. For example, my shell will show this:</p><pre><code>$ echo $EDITOR
vim
</code></pre><p>This means <code>vim</code> will be used to edit the command line. Your shell might use <code>emacs</code> or <code>nano</code> as a default editor. Unless you are familiar with <code>vim</code> or <code>emacs</code>, you might not find them particularly user friendly as an editor. You can change your default editor by setting the <code>EDITOR</code> variable. For example, below I set the editor to <code>code</code> (with the <code>-w</code> flag which tells the <code>code</code> program not to return control immediately back to the shell but instead wait until I've finished editing the file):</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/editor-vs-code.gif" alt="Screen Capture: Edit in Place with Visual Studio Code"></p><p>Now this works (just about), but I wouldn't recommend using a Graphical Editor like Visual Studio Code for this. The reason is that because the editor runs in a separate window, it is actually easy to lose track of it (or the shell). You pause to take a short break, come back, close the editor and the contents are either lost or written to the shell (and if you see in the example above, the shell actually <em>executed</em> the command, rather than just putting it in the command line ready for me to execute).</p><p>The other reason to avoid a graphical editor is that if you are using a shell on another user's machine, the editor might not be present (or might be configured differently). In general however, the main reason to avoid a graphical editor is that it moves the <em>context</em> of the command away from where you are in the shell to another place, which can be confusing. If you see the screenshot below, I have <em>two</em> editors open:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/multiple-editors.png" alt="Screenshot: Two shell editors"></p><p>The top right pane has my <code>git commit</code> command running (which is asking me to write a description of my changes) and the bottom right pane has the command line editor running (where I am testing out the commands for this chapter).</p><p>In this example, each editor has taken the place of the contents of the shell, so there's no ambiguity about <em>which</em> command I am editing. If I was to open a graphical editor, it would open multiple tabs for this operation and I'd have to track which tab was which.</p><p>It can be daunting to learn an editor like <code>vim</code> or <code>emacs</code>. Chapter 27 goes into more detail on the terminal based text editors - for now if you are not familiar with these programs I recommend you use the <code>nano</code> editor. Nano is small, simple and shows the shortcuts in a convenient menu at the bottom of the screen:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/screenshot-nano.png" alt="Screenshot: The Nano Editor"></p><p>In Chapter 18 we'll see how to make permanent customisations to the shell, configuring things like the default editor.</p><p>Probably the shortcut I use the most is <code>Ctrl + l</code>, which clears the screen without trashing your current command. Here's how it looks:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/clear-screen.gif" alt="clear screen"></p><p>This is very helpful if you have a lot of noise and output on the screen and are ready to start with a fresh command.</p><p>Just a few days ago a friend showed me a fantastic trick. If you run the <code>history</code> command, the shell will print the recent history of commands you have entered. But as an added bonus, you can <em>execute</em> any of these commands by entering an exclamation mark and the number next to the command:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/screenshot-history.png" alt="Screenshot History and Execute Recent Command"></p><p>The number is actually just the <em>line number</em> in the <em>history file</em>. Most shells maintain a history of commands which have been entered (to allow for things like searching through old commands). Where this history file is kept will depend on your shell, configuration and operating system, but in most cases you can find the file by running:</p><p>There are many configuration options for the shell history. But the main thing to remember is that you can see recent history with the <code>history</code> command and quickly execute the command at line <code>n</code> by running <code>!n</code>.</p><p>You can use the <code>bindkey</code> command to see a list of all keyboard shortcuts:</p><pre><code>$ bindkeys
"^@" set-mark-command
"^A" beginning-of-line
"^B" backward-char
"^D" delete-char-or-list
"^E" end-of-line
"^F" forward-char
"^G" send-break
"^H" backward-delete-char
"^I" expand-or-complete
"^J" accept-line
"^K" kill-line
"^L" clear-screen
...
</code></pre><p>This is an extremely useful command to use if you forget the specific keyboard shortcuts, or just want to see the shortcuts which are available.</p><p>If you've mastered all of the commands here and feel like adding something else to your repertoire, try this:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/transpose-word.gif" alt="transpose-word"></p><p>The <code>Alt + t</code> shortcut will transpose the last two words. Use <code>Ctrl + t</code> to transpose the last two letters:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/transpose-letters.gif" alt="transpose-letters"></p><p>These two commands were new to me when I was researching this chapter. I can't see myself ever being able to remember the commands more quickly than just deleting the last two words (<code>Ctrl+w</code> twice!) or characters and re-typing them, but perhaps you'll find them useful!</p><p>All of the movement commands you've learned in this chapter apply to:</p><ol><li>Bash</li><li>zsh</li><li>The Python REPL</li><li>The Node.js REPL</li></ol><p>And many more! The reason is that all of these programs use the same library under the hood to control reading command line input. This library is called <em>GNU Readline</em>.</p><p>If you are ever looking to go deeper on this topic then search the web for <em>GNU Readline</em>. You can actually configure lower level details of how all programs which use readline work, with the <a href="https://www.gnu.org/software/bash/manual/html_node/Readline-Init-File.html"><code>.inputrc</code></a> configuration file.</p><p>This configuration file can be used to configure things like the shortcuts used to move around. All of these shortcuts should be familiar to Emacs users. There is in fact also ‘Vi Mode’ option for readline, which …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/">https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/</a></em></p>]]>
            </description>
            <link>https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630268</guid>
            <pubDate>Tue, 29 Sep 2020 17:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I've become obsessed with networked thought]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630175">thread link</a>) | @scotthtaylor
<br/>
September 29, 2020 | https://st.im/ive-become-obsessed-with-networked-thought/ | <a href="https://web.archive.org/web/*/https://st.im/ive-become-obsessed-with-networked-thought/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<div>
  <main>
      <article>
  
  <div>
        <p>Imagine opening a note on your computer and within it you link to, and create, another note by writing [[<em><strong>something</strong></em>]] in square brackets. You now have a link from one note to another, and two notes.</p><p>Sounds simple, right? Nothing groundbreaking here, surely? </p><p>Upon first glance, yes. But hear me out, I believe this seemingly minor feature has fundamentally changed note-taking. I would even go as far to say it will change how our brains use and rely upon computers —as it pertains to supporting knowledge retention and plasticity.</p><p>With this new networked connection, note-taking has become an active, bi-directional relationship —rather than just a one-way dumping ground. </p><p>This is the basic premise of <strong>networked thought</strong>. </p><p>You might have seen some of the hype around apps such as <a href="https://roamresearch.com/">Roam Research</a>, <a href="https://obsidian.md/">Obsidian.md</a> or <a href="https://walling.app/">Walling</a>. The foundations of these apps are built upon networked thought. Billing themselves as your second brain.</p><figure><img src="https://st.im/content/images/2020/09/image-1.png" alt="" srcset="https://st.im/content/images/size/w600/2020/09/image-1.png 600w, https://st.im/content/images/2020/09/image-1.png 954w" sizes="(min-width: 720px) 720px"><figcaption>Screenshot of Roam Research</figcaption></figure><p>Over the past few years I've developed a pretty good habit of writing daily. Sometimes just for as little as twenty minutes. Building this cornerstone habit of journalling and note-taking has had a huge impact on my productivity —I'd highly recommend it. It reduced the strain on my brain's short term memory, as well as my dependency upon it. </p><p>With my daily habit established, I wanted to level up.</p><p>I wanted to evolve my journalling and note-taking habit to a higher level of reflection and connection. Just dumping my thoughts into a note wasn't enough.</p><p>I discovered the idea of <strong>Index, Maps of Content, and other fluid Frameworks</strong> (IMF). Basically some frameworks, structures, modules and approaches that note-taking pros had come up with, to use in apps such as Obsidian and Roam. By using this IMF foundation, I was able to build a network of thoughts on top of which I could be creative, innovative and strengthen and codify my knowledge.</p><p>One of the core aspects of IMF are Maps of Content. </p><h2 id="maps-of-content-mocs-">Maps of Content (MOCs)</h2><p>MOCs help us get past 'mental squeeze points'. They encourage thinking, create favourable conditions for flow, and allow us to create meaningful spatial constellations of thought. They have limitless interpretations, are non-destructive and non-limiting because they act as fluid, augmented layers.</p><p>MOCs have three basic stages in a full lifecycle:</p><ol><li><strong>Collect, curate, incubate</strong> - put related stuff on a new digital workbench</li><li><strong>Battle, collide, dismember, combine, craft, discover</strong> - have your ideas battle for relational positioning. This is the most joyous and valuable stage</li><li><strong>Enjoy and use </strong>- enjoy the spatial constellation you created out of concepts. It will be meaningful to <em>you</em>. Use it for different purposes: for final products (content creation), as a reference point in the future, or for the inherent joy the ideas provide.</li></ol><p>So what is an MOC? Simply put: let's say you read something interesting on a topic - for example '<em>habits</em>', and you make a note. Later on, you make a couple more notes on the same topic. You start to think you might lose some of the ideas. So to pass this 'mental squeeze point' you go ahead and make a special note. You call it '<strong>Habits MOC</strong>'</p><p>A 'mental squeeze point' is when your unsorted knowledge becomes so messy it overwhelms and discourages you. Either you are equipped with frameworks to overcome the squeeze point, or you are discouraged and possibly abandon your project. This is usually followed by yet another search for the next app that will make all the difference.</p><h3 id="habits-moc-stage-1">Habits MOC - Stage 1</h3><p><strong>Collect, curate, incubate</strong> - put related stuff on a new digital workbench.</p><p>To continue the example, I decided to compile old notes I collected on the topic of 'habits'. They aren't organised yet within Obsidian:</p><pre><code>201303102051 Habit Planning
201502201031 Habit Formation Research Article
201502201713 Habit Concepts and Theory
201910011142 Atomic Habits
201901250999 Resiliency Routines
</code></pre><h3 id="habits-moc-stage-2">Habits MOC - Stage 2</h3><p><strong>Battle, collide, dismember, combine, craft, discover</strong> - have your ideas battle for relational positioning. This is the most joyful and valuable stage.</p><p>Excitedly, without a task manager telling me what to do - I open the first note and I craft it into an evergreen note (something in my own words). But when I try to name it, I realise it's too big, so I split it up into two evergreen notes:</p><pre><code>The neural formation of habits are additive 
The truest habit metaphors are additive 
</code></pre><p>And the others I leave alone for now. I'm done for the night. I'm comforted by this MOC; the other notes have a digital workbench to rest upon. I'm satisfied with creating two evergreen notes. They have value to me.</p><p>The next day, I continue where I left off.</p><p>Looking at the collected notes —questions just arrive, unforced: What are they trying to say? What is redundant? What note needs to be split into two? What outside concepts relate to this? You naturally work yourself into a state of Flow and time becomes timeless; effort effortless.</p><h3 id="habits-moc-stage-3">Habits MOC - Stage 3</h3><p><strong>Enjoy and use </strong>- enjoy the spatial constellation you created out of concepts. It most likely is meaningful to you. My 'Habits MOC' now looks like this:</p><pre><code>**Understanding Habits**
Defining a habit
Habit formation provides an evolutionary advantage
Habits carry a ton of hidden inertia
The neural formation of habits is additive
	The truest habit metaphors are additive
        
**Designing Habits**
Understanding the habit cycle and habitual cues
	How Atomic Habits fit into the conversation on habits
	Resiliency Routines are my most important habits to regain a sense of control
An asymptotic curve models the development of skills, strength, habits, and more
	The mechanism for breaking through development plateaus

**Example of Habit Design**
Charting out habit cycles in my life circa 2013

**Related Concepts**
Positive Feedback Loop, Like begets like
Cobwebs into Cables, Reps
Natural Selection, Selfish Gene, Survival of the Fittest</code></pre><p>Within this example, we've only touched upon one MOC. Imagine combining everything in your brain —creating a knowledge graph. Below I've shown a snippet of my '<strong>000 Index</strong>'. I'd recommend visiting some of the <a href="https://forum.obsidian.md/c/knowledge-management/6">discussion forums</a>, download a template, and start moulding it to best suit your needs. </p><h2 id="screenshot-of-my-obsidian-imf-structure">Screenshot of my Obsidian IMF Structure </h2><figure><img src="https://st.im/content/images/2020/09/Screenshot-2020-09-29-at-15.40.18.png" alt="" srcset="https://st.im/content/images/size/w600/2020/09/Screenshot-2020-09-29-at-15.40.18.png 600w, https://st.im/content/images/size/w1000/2020/09/Screenshot-2020-09-29-at-15.40.18.png 1000w, https://st.im/content/images/size/w1600/2020/09/Screenshot-2020-09-29-at-15.40.18.png 1600w, https://st.im/content/images/2020/09/Screenshot-2020-09-29-at-15.40.18.png 2232w" sizes="(min-width: 720px) 720px"></figure><h2 id="final-note">Final note</h2><p>The three stages of MOCs are not distinct like these examples. They overlap. Don't get hung up on the stages, and don't view the process as linear.</p><p>The process is overlapping and cyclical. An MOC is rarely a finalised concrete statue. Instead, it should be able to free evolve with the times. Or you can just create a new one.</p>
              <section>
                <h2>Enjoying these posts? Subscribe for more</h2>
                <a href="https://st.im/subscribe/">Subscribe now</a>
                <br>
                <a href="https://st.im/signin/">Already have an account? Sign in</a>
              </section>
  </div>
    
</article>          
          


  </main>
</div>
      </div><p>
  You've successfully subscribed to Scott Taylor.
  
</p><p>
  Great! Next, complete checkout for full access to Scott Taylor.
  
</p><p>
  Welcome back! You've successfully signed in.
  
</p><p>
  Success! Your account is fully activated, you now have access to all content.
  
</p><p>
  Success! Your billing info is updated.
  
</p></div>]]>
            </description>
            <link>https://st.im/ive-become-obsessed-with-networked-thought/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630175</guid>
            <pubDate>Tue, 29 Sep 2020 16:56:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY IoT door monitor with ESP8266]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630168">thread link</a>) | @gk1
<br/>
September 29, 2020 | https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Using an ESP8266 for IoT projects makes me go fast while prototyping.</p><p>The compact format is perfect for small DIY devices.</p><p>Wi-Fi connectivity is built-in, and it's super affordable.</p><blockquote><p>The ESP8266 is a low-cost Wi-Fi microchip, with a full TCP/IP stack and microcontroller capability (<a href="https://en.wikipedia.org/wiki/ESP8266">wikipedia</a>)</p></blockquote><hr><h2>Table of Contents</h2><ul><li><a href="#tldr">tldr;</a></li><li><a href="#requirements">Requirements</a></li><li><a href="#circuit-explanation">Circuit explanation</a></li><li><a href="#coding">Coding</a><ul><li><a href="#install-libraries-for-esp8266">Install libraries for ESP8266</a><ul><li><a href="#adding-the-esp8266-board">Adding the ESP8266 Board</a></li><li><a href="#additional-libraries">Additional libraries</a></li></ul></li><li><a href="#flash-it">Flash it</a></li></ul></li><li><a href="#try-it-out">Try it out!</a></li><li><a href="#next-steps">Next steps</a></li><li><a href="#rest-api">REST API</a></li><li><a href="#web-ui">Web UI</a></li><li><a href="#demo">Demo</a></li></ul><h2>tldr;</h2><p>The door monitor running in my home activates a buzzer when the proximity sensor detects that the door is opened.</p><p>Additionally, it creates an AP for Wi-Fi configuration using a Web interface, and can connect to a desired Wi-Fi network afterwards. <a href="#web-ui">Read more about this below</a></p><p>Source code can be found on <a href="https://github.com/christian-fei/door-monitor-esp8266">GitHub christian-fei/door-monitor-esp8266</a></p><pre><code>git clone https://github.com/christian-fei/door-monitor-esp8266.git
</code></pre><p>The worst photo I could take of the "Gate keeper" in action:</p><p><a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.svg"><img src="https://cri.dev/assets/images/posts/door-monitor/project.jpg" alt="project photo"></a></p><p>Now I added a case! (<strong>update 2020-09-10</strong>)</p><p><a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.svg"><img src="https://cri.dev/assets/images/posts/door-monitor/project-update.jpg" alt="project photo"></a></p><p>The Web UI that this thing has (see home-assistant integration <a href="#next-steps">at the end</a>)</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-ui.png" alt="gate-keeper-ui"></p><h2>Requirements</h2><p>To build your own, this is what you need:</p><ul><li>Microcontroller ESP8266 (LoLin)</li><li>Active Piezo Buzzer</li><li>Proximity Sensor FC-51</li><li>optionally a breadboard</li></ul><p>Arduino IDE or the Arduino Plug-in for VSCode will work fine for flashing the ESP8266.</p><h2>Circuit explanation</h2><p>Here the schematics for the circuit</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/schematics.svg" alt="schematics door monitor"></p><p>The piezo buzzer is connected to GPIO D6, as an <code>OUTPUT</code> pin.</p><p>The proximity sensor is connected to GPIO D5, as an <code>INPUT</code> pin.</p><p>When the proximity sensor detects that the door is open, the GPIO D5 pin will read <code>HIGH</code>.</p><p>This is when the piezo buzzer is activated, and a simple alarm sound is played.</p><h2>Coding</h2><p>Clone the repository</p><pre><code>git clone https://github.com/christian-fei/door-monitor-esp8266.git
</code></pre><p>Open the project with Arduino IDE by clicking on the <a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.ino"><code>Gatekeeper.ino</code></a> file.</p><p>There is no need to change the code.</p><h3>Install libraries for ESP8266</h3><h4>Adding the ESP8266 Board</h4><p>Using the "Library Manager" in the Arduino IDE, you need to install support for ESP8266.</p><p>Here you can find <a href="https://arduino-esp8266.readthedocs.io/en/latest/installing.html#instructions">the official installation guide</a></p><h4>Additional libraries</h4><p>The project uses <a href="https://github.com/me-no-dev/ESPAsyncTCP/archive/master.zip"><code>ESPAsyncTCP</code></a> and <a href="https://github.com/me-no-dev/ESPAsyncWebServer/archive/master.zip"><code>ESPAsyncWebServer</code></a>.</p><p>Download both ZIP files, and add them either to your Arduino IDE installation libraries or via <code>Add .ZIP Library</code>.</p><h3>Flash it</h3><p>Connect your ESP8266 via USB to your PC.</p><p>Select the <code>usbserial</code> port and <code>NodeMCU 1.0 (ESP - 12 E Module)</code> board in the Arduino IDE.</p><p>Click <code>Upload</code> and flash the ESP8266.</p><h2>Try it out!</h2><p>Now you're ready to apply the board near a door you want to monitor.</p><p>The proximity sensor can both be placed on the door itself or on a wall near the door.</p><p>You'll need to calibrate the sensitivity of the sensor by rotating the potentiometer on the FC-51 chip.</p><h2>Next steps</h2><p>From here I went the following route:</p><p>Made the Gatekeeper available as an iframe element in my <a href="https://www.home-assistant.io/">homeassistant</a> installation. The URL I used was <code>http://gatekeeper.fritz.box</code> (after I connected it to my Wi-Fi network using <a href="#web-ui">the Web UI</a>)</p><p>On the Web UI of the Gatekeeper I can "disarm" the alarm sound and check whether the door is open or closed.</p><p>It looks like this:</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-homeassistant.png" alt="gate-keeper-homeassistant"></p><p>The next challenge is to register the door monitor as a "sensor" (or "entity" I think it's called in homeassistant lingo).</p><h2>REST API</h2><p>The Gatekeeper can already be called via HTTP on its REST API:</p><pre><code>  HTTP GET /
    -&gt; replies with the client html
  HTTP GET /door
    -&gt; returns the status of the door, whether it's "open" or "closed"
  HTTP GET /alarm
    -&gt; returns the status of the alarm, whether it's "on" or "off"
  HTTP POST /toggle-alarm
    -&gt; toggles the alarm and returns the current status of it
  HTTP POST /setup
    -&gt; to save the Wi-Fi credentials and connect to the desired access point
</code></pre><h2>Web UI</h2><p>The Web UI give you the current status of the door.</p><p>It also features a form where you can input the Wi-Fi credentials to connect to your home network.</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-ui.png" alt="gate-keeper-ui"></p><p>This means that once the door monitor is connected to Wi-Fi, it's accessible via the hostname <code>gatekeeper</code>.</p><p>E.g. with my FritzBox setup, it's available under <code>gatekeeper.fritz.box:80</code></p><h2>Demo</h2></div></div>]]>
            </description>
            <link>https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630168</guid>
            <pubDate>Tue, 29 Sep 2020 16:56:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Slack Dashboard Using Meltano and Superset]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629894">thread link</a>) | @skadamat
<br/>
September 29, 2020 | https://preset.io/blog/2020-09-22-slack-dashboard/ | <a href="https://web.archive.org/web/*/https://preset.io/blog/2020-09-22-slack-dashboard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome! This is the <strong>first of a three part blog series</strong> on Building A Slack Community Dashboard</p>
<p>Slack is one of the most popular community tools out there. Even though it was originally conceived as a tool for teams to communicate and coordinate, Slack embraced a <a href="https://slack.com/pricing/free">free tier</a> that lets community organizers create workspaces with unlimited members and unlimited channels.</p>
<div><p><span>
      <a href="https://preset.io/static/534d68c200f57c43aaced69238eb94e4/555cf/slack_free_tier.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Slack Free Tier" title="Slack Free Tier" src="https://preset.io/static/534d68c200f57c43aaced69238eb94e4/442cb/slack_free_tier.png" srcset="https://preset.io/static/534d68c200f57c43aaced69238eb94e4/4dcb9/slack_free_tier.png 188w,
https://preset.io/static/534d68c200f57c43aaced69238eb94e4/d38a6/slack_free_tier.png 376w,
https://preset.io/static/534d68c200f57c43aaced69238eb94e4/442cb/slack_free_tier.png 752w,
https://preset.io/static/534d68c200f57c43aaced69238eb94e4/7bf07/slack_free_tier.png 1128w,
https://preset.io/static/534d68c200f57c43aaced69238eb94e4/66632/slack_free_tier.png 1504w,
https://preset.io/static/534d68c200f57c43aaced69238eb94e4/555cf/slack_free_tier.png 1960w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
<p>This lead to the meteoric rise of thousands of Slack communities across the world. You can find Slack communities for many of your professional interests, personal interests, social causes, and many more. In fact, the website <a href="https://preset.io/blog/2020-09-22-slack-dashboard/www.slofile.com">Slofile</a> will even help you discover new Slack communities to join.</p>
<p><strong>Slack and Open Source</strong></p>
<p>Here at Preset, we're the experts of <a href="https://superset.apache.org/">Apache Superset (incubating)</a> and we invest a lot in the Superset Community. The Superset community is spread across <a href="https://superset.apache.org/community">many channels</a>, but a lot of discussions and conversations happen in the <a href="https://apache-superset.slack.com/join/shared_invite/zt-g8lpruog-HeqpgYrwdfrD5OYhlU7hPQ#/">community Slack</a>.</p>
<p>As an organization focused on enabling insights through data exploration, visualizations, and dashboards, we're always interested in finding <em>productive</em> ways to use data to help us understand the growth of the Superset project and the health of the Superset community.</p>
<p><strong>Wouldn't you love to have a dashboard like this for your community?</strong></p>
<div><p><span>
      <a href="https://preset.io/static/94eef0015acd21e3044a2ec22d55f8e4/4faaa/dashboard_3.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Slack dashboard" title="Slack dashboard" src="https://preset.io/static/94eef0015acd21e3044a2ec22d55f8e4/442cb/dashboard_3.png" srcset="https://preset.io/static/94eef0015acd21e3044a2ec22d55f8e4/4dcb9/dashboard_3.png 188w,
https://preset.io/static/94eef0015acd21e3044a2ec22d55f8e4/d38a6/dashboard_3.png 376w,
https://preset.io/static/94eef0015acd21e3044a2ec22d55f8e4/442cb/dashboard_3.png 752w,
https://preset.io/static/94eef0015acd21e3044a2ec22d55f8e4/7bf07/dashboard_3.png 1128w,
https://preset.io/static/94eef0015acd21e3044a2ec22d55f8e4/66632/dashboard_3.png 1504w,
https://preset.io/static/94eef0015acd21e3044a2ec22d55f8e4/4faaa/dashboard_3.png 2308w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
<p>In this blog post series, we'll explore how we can leverage a few different open source tools to build an awesome dashboard for a Slack community:</p>
<ul>
<li>Meltano for ELT (or extract-load-transform)</li>
<li>Postgres for data storage</li>
<li>Superset for creating views, visualizations, and dashboards</li>
</ul>
<div><p>Dbt stands for data build tool and is the key workflow for writing data transformation scripts using SQL. We'll focus on Singer taps and targets in this blog post.
</p></div>
<p><span>
      <a href="https://preset.io/static/d60cdf5636769e103111f40b37b51d2d/d67ca/slack_pipeline.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Pipeline" title="Pipeline" src="https://preset.io/static/d60cdf5636769e103111f40b37b51d2d/d67ca/slack_pipeline.png" srcset="https://preset.io/static/d60cdf5636769e103111f40b37b51d2d/4dcb9/slack_pipeline.png 188w,
https://preset.io/static/d60cdf5636769e103111f40b37b51d2d/d38a6/slack_pipeline.png 376w,
https://preset.io/static/d60cdf5636769e103111f40b37b51d2d/d67ca/slack_pipeline.png 714w" sizes="(max-width: 714px) 100vw, 714px" loading="lazy">
  </a>
    </span></p>
<h2 id="meltano--singer--dbt"><a href="#meltano--singer--dbt" aria-label="meltano  singer  dbt permalink"></a>Meltano = Singer + dbt</h2>
<p><a href="https://meltano.com/">Meltano</a> is an open source ELT platform for data integration that facilitates:</p>
<ul>
<li>the <strong>extraction</strong> of data from 3rd party SaaS services</li>
<li>the <strong>loading</strong> of data into data stores</li>
<li>the <strong>transformation</strong> of the data</li>
</ul>
<p>Under the hood, Meltano elegantly combines two open source projects -- <a href="http://singer.io/">Singer</a> and <a href="https://www.getdbt.com/">dbt</a>.</p>
<p>Singer is open source and the community has created <a href="https://www.singer.io/">hundreds of data extractors</a>, called <strong>Singer taps</strong>, to easily pull out data from 3rd party SaaS tools like Gitlab, Google Analytics, Hubspot, and Slack. Using <strong>Singer targets</strong>, Meltano can load data to destinations like Google BigQuery, Google Sheets, PostgreSQL, and Amazon S3.</p>
<p>Meltano packages both of these tools into a single platform and provides a command line interface and a graphical user interface to interact with everything very easily. </p>
<p><strong>Once you have everything setup, you only need to run a single command to sync your data incrementally from your community Slack into a Postgres database</strong>:</p>
<div data-language="text"><pre><code>meltano elt tap-slack target-postgres --job_id=daily_update</code></pre></div>
<p>But we're getting ahead of ourselves 😃</p>
<h2 id="slack-api-access"><a href="#slack-api-access" aria-label="slack api access permalink"></a>Slack API Access</h2>
<p>Slack provides an API that's accessible even for workspaces on the free tier (albeit with more limitations). Unfortunately, it's not as simple as getting access to the API. You actually have to create a Slack app, set up permissions, and add the app to the channels you want to extract data out of. </p>
<p>In the following steps, we'll walkthrough how to get the access you need.</p>
<ol>
<li>If you're not a <a href="https://slack.com/help/articles/201912948-Owners-and-Administrators">Workspace Admin</a>, I recommend getting permission from a Workspace Owner first for this project. Then, ask them to elevate your permissions to the Admin level.</li>
<li>
<p>Open the Slack workspace and navigate to <strong>[Workspace name]</strong> &gt; <strong>Setting &amp; administration</strong> &gt; <strong>Customize [Workspace name]</strong>.</p>
<div><p><span>
      <a href="https://preset.io/static/8f296aed9a5575b4e58c54c7b8531d6e/9b1e2/slack_customize.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Slack Customize" title="image_tooltip" src="https://preset.io/static/8f296aed9a5575b4e58c54c7b8531d6e/442cb/slack_customize.png" srcset="https://preset.io/static/8f296aed9a5575b4e58c54c7b8531d6e/4dcb9/slack_customize.png 188w,
https://preset.io/static/8f296aed9a5575b4e58c54c7b8531d6e/d38a6/slack_customize.png 376w,
https://preset.io/static/8f296aed9a5575b4e58c54c7b8531d6e/442cb/slack_customize.png 752w,
https://preset.io/static/8f296aed9a5575b4e58c54c7b8531d6e/7bf07/slack_customize.png 1128w,
https://preset.io/static/8f296aed9a5575b4e58c54c7b8531d6e/66632/slack_customize.png 1504w,
https://preset.io/static/8f296aed9a5575b4e58c54c7b8531d6e/9b1e2/slack_customize.png 1880w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
</li>
<li>
<p>In the new browser page that opens, navigate to <strong>Menu</strong> &gt; <strong>Configure apps</strong>.</p>
<div><p><span>
      <a href="https://preset.io/static/dbc82f72f91ec1bc5e602710e96455e6/05244/configure_apps.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Configure Apps" title="Configure Apps" src="https://preset.io/static/dbc82f72f91ec1bc5e602710e96455e6/442cb/configure_apps.png" srcset="https://preset.io/static/dbc82f72f91ec1bc5e602710e96455e6/4dcb9/configure_apps.png 188w,
https://preset.io/static/dbc82f72f91ec1bc5e602710e96455e6/d38a6/configure_apps.png 376w,
https://preset.io/static/dbc82f72f91ec1bc5e602710e96455e6/442cb/configure_apps.png 752w,
https://preset.io/static/dbc82f72f91ec1bc5e602710e96455e6/7bf07/configure_apps.png 1128w,
https://preset.io/static/dbc82f72f91ec1bc5e602710e96455e6/66632/configure_apps.png 1504w,
https://preset.io/static/dbc82f72f91ec1bc5e602710e96455e6/05244/configure_apps.png 1752w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
</li>
<li>
<p>Select <strong>Build</strong> in the top right corner.</p>
<div><p> <span>
      <a href="https://preset.io/static/c7481cd3e0b10d2ebdfab61354ec12fb/48ca3/build_slack_app.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Build Slack App" title="Build Slack App" src="https://preset.io/static/c7481cd3e0b10d2ebdfab61354ec12fb/442cb/build_slack_app.png" srcset="https://preset.io/static/c7481cd3e0b10d2ebdfab61354ec12fb/4dcb9/build_slack_app.png 188w,
https://preset.io/static/c7481cd3e0b10d2ebdfab61354ec12fb/d38a6/build_slack_app.png 376w,
https://preset.io/static/c7481cd3e0b10d2ebdfab61354ec12fb/442cb/build_slack_app.png 752w,
https://preset.io/static/c7481cd3e0b10d2ebdfab61354ec12fb/48ca3/build_slack_app.png 1084w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
</li>
<li>
<p>Read the Terms of Service agreement and select <strong>I agree</strong> (if you agree!). Then select <strong>Create new app</strong>, give your app a memorable name, and select the workspace you want the app to have access to.</p>
<div><p><span>
      <a href="https://preset.io/static/fffe0acb86336ab350f3265635f87cba/ea64c/create_app.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Create Slack App" title="Create Slack App" src="https://preset.io/static/fffe0acb86336ab350f3265635f87cba/442cb/create_app.png" srcset="https://preset.io/static/fffe0acb86336ab350f3265635f87cba/4dcb9/create_app.png 188w,
https://preset.io/static/fffe0acb86336ab350f3265635f87cba/d38a6/create_app.png 376w,
https://preset.io/static/fffe0acb86336ab350f3265635f87cba/442cb/create_app.png 752w,
https://preset.io/static/fffe0acb86336ab350f3265635f87cba/ea64c/create_app.png 1116w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
</li>
<li>
<p>Let's now give this app some permissions. Under <strong>Add features and functionality</strong>, select <strong>Permissions</strong>.</p>
<div><p><span>
      <a href="https://preset.io/static/0bb23c88983ab352c2bd4194be793848/6569d/permissions.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Permissions" title="Permissions" src="https://preset.io/static/0bb23c88983ab352c2bd4194be793848/442cb/permissions.png" srcset="https://preset.io/static/0bb23c88983ab352c2bd4194be793848/4dcb9/permissions.png 188w,
https://preset.io/static/0bb23c88983ab352c2bd4194be793848/d38a6/permissions.png 376w,
https://preset.io/static/0bb23c88983ab352c2bd4194be793848/442cb/permissions.png 752w,
https://preset.io/static/0bb23c88983ab352c2bd4194be793848/7bf07/permissions.png 1128w,
https://preset.io/static/0bb23c88983ab352c2bd4194be793848/6569d/permissions.png 1328w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
</li>
<li>
<p>We recommend giving the following permissions to this app.</p>
<div><p><span>
      <a href="https://preset.io/static/39e935c197cfa2bab0c17ad49d4deabd/6c2de/recommended_permissions.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Recomended permissions" title="Recomended permissions" src="https://preset.io/static/39e935c197cfa2bab0c17ad49d4deabd/442cb/recommended_permissions.png" srcset="https://preset.io/static/39e935c197cfa2bab0c17ad49d4deabd/4dcb9/recommended_permissions.png 188w,
https://preset.io/static/39e935c197cfa2bab0c17ad49d4deabd/d38a6/recommended_permissions.png 376w,
https://preset.io/static/39e935c197cfa2bab0c17ad49d4deabd/442cb/recommended_permissions.png 752w,
https://preset.io/static/39e935c197cfa2bab0c17ad49d4deabd/7bf07/recommended_permissions.png 1128w,
https://preset.io/static/39e935c197cfa2bab0c17ad49d4deabd/6c2de/recommended_permissions.png 1334w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
</li>
<li>
<p>Then, let's add the app to the workspace by clicking <strong>Install App to Workspace</strong>.</p>
<div><p><span>
      <a href="https://preset.io/static/67e2d2d99e472a5a36168c290d126840/07a9c/install_app.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Install App" title="Install App" src="https://preset.io/static/67e2d2d99e472a5a36168c290d126840/442cb/install_app.png" srcset="https://preset.io/static/67e2d2d99e472a5a36168c290d126840/4dcb9/install_app.png 188w,
https://preset.io/static/67e2d2d99e472a5a36168c290d126840/d38a6/install_app.png 376w,
https://preset.io/static/67e2d2d99e472a5a36168c290d126840/442cb/install_app.png 752w,
https://preset.io/static/67e2d2d99e472a5a36168c290d126840/7bf07/install_app.png 1128w,
https://preset.io/static/67e2d2d99e472a5a36168c290d126840/07a9c/install_app.png 1440w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
</li>
</ol>
<p>Once it's installed, you'll see a <strong>Bot User OAuth Access Token</strong>. This is what we need for the Meltano system to be able to extract data from our workspace. Before Meltano can extract useful data from the Slack workspace, we need to add our app to all of the public channels we want to pull data from.</p>
<p>Open each public channel in your community Slack and run the following command:</p>

<p>If your app was named meltano, you would type the following to add the app to the channel:</p>

<p>To wrap up this section, save your <strong>OAuth Access Token</strong> in a safe place. We'll need this later in this tutorial.</p>
<h2 id="installing-and-initializing-meltano"><a href="#installing-and-initializing-meltano" aria-label="installing and initializing meltano permalink"></a>Installing and Initializing Meltano</h2>
<p>Meltano's website has the full instructions on <a href="https://meltano.com/docs/getting-started.html#install-meltano">how to install Meltano</a> and their documentation is amazing! We'll cover the abridged version here!</p>
<ol>
<li>
<p>Meltano is a Python 3 library that can be installed using <code>pip</code> (or <code>pip3</code> based on your setup):</p>

</li>
<li>
<p>Create a directory for your Meltano projects and <code>cd</code> into it.</p>
<div data-language="text"><pre><code>mkdir meltano-projects
cd meltano-projects</code></pre></div>
</li>
<li>
<p>Using a Python virtual environment <strong>local to this project folder</strong> is highly recommended (use <code>python3</code> instead if that's linked to your Python 3 version).</p>
<div data-language="text"><pre><code>python -m venv .venv
source .venv/bin/activate</code></pre></div>
</li>
<li>
<p>Install the Meltano library.</p>

</li>
<li>
<p>You now should have the <code>meltano</code> command available in your command line now. We're now ready to initialize a Meltano project.</p>

<p>You should see a flurry of output. Take a look at the files Meltano created.</p>
<div data-language="sh"><pre><code>Created slack
Creating project files...
Created slack/meltano.yml
Created slack/README.md
Created slack/requirements.txt
Created slack/.gitignore
Created slack/model/.gitkeep
Created slack/extract/.gitkeep
Created slack/load/.gitkeep
Created slack/transform/.gitkeep
Created slack/analyze/.gitkeep
Created slack/notebook/.gitkeep
Created slack/orchestrate/.gitkeep
Creating system database...</code></pre></div>
</li>
</ol>
<p>This is one of the reasons Meltano works really well with version control, CI/CD, and other common web development workflows.</p>

<p>To extract data from a 3rd party API, Meltano needs <strong>extractor</strong> libraries. These are Python libraries that target the <a href="https://github.com/singer-io/getting-started#:~:text=The%20Singer%20spec%20describes%20how,any%20source%20to%20any%20destination.">Singer spec</a> and can usually be installed using <code>pip</code>.</p>
<p>Meltano comes with a few extractors out of the box, but not one for extracting data from Slack.</p>
<ol>
<li>
<p>First things first, open the folder that Meltano created for our project.</p>

</li>
<li>
<p>We'll need to install the community extractor library for Slack, called <a href="https://github.com/singer-io/tap-slack">tap-slack</a>. Adding any library or capabilities to a Meltano project is done using the <code>meltano add</code> command:</p>
<div data-language="text"><pre><code>meltano add --custom extractor tap-slack</code></pre></div>
<p>Meltano will launch a step-by-step wizard that lets us provide the necessary context (upto date <a href="https://meltano.com/docs/command-line-interface.html#how-to-use-custom-plugins">Meltano documentation here</a>).</p>
<p>We recommend the following options: </p>
<ul>
<li>(namespace): <code>tap_slack</code></li>
<li>(pip_url): <code>git+https://github.com/singer-io/tap-slack.git</code></li>
<li>(executable): <code>tap-slack</code></li>
<li>(capabilities): <code>catalog,discover,state</code></li>
<li>(settings): <code>token,start_date</code></li>
</ul>
<p>Here's a summary screenshot for your convenience:</p>
<div><p><span>
      <a href="https://preset.io/static/3457f6dac4e6770d7a706614519d165a/58354/tap_slack_settings.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tap Slack Settings" title="Tap Slack Settings" src="https://preset.io/static/3457f6dac4e6770d7a706614519d165a/442cb/tap_slack_settings.png" srcset="https://preset.io/static/3457f6dac4e6770d7a706614519d165a/4dcb9/tap_slack_settings.png 188w,
https://preset.io/static/3457f6dac4e6770d7a706614519d165a/d38a6/tap_slack_settings.png 376w,
https://preset.io/static/3457f6dac4e6770d7a706614519d165a/442cb/tap_slack_settings.png 752w,
https://preset.io/static/3457f6dac4e6770d7a706614519d165a/7bf07/tap_slack_settings.png 1128w,
https://preset.io/static/3457f6dac4e6770d7a706614519d165a/58354/tap_slack_settings.png 1396w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
</li>
<li>
<p>For a visual confirmation, you can inspect the <code>meltano.yml</code> file.</p>
<div><p><span>
      <a href="https://preset.io/static/de703953407d812018cc4ab3e707746c/5b481/cat_meltano_yml.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Cat Meltano YML" title="Cat Meltano YML" src="https://preset.io/static/de703953407d812018cc4ab3e707746c/442cb/cat_meltano_yml.png" srcset="https://preset.io/static/de703953407d812018cc4ab3e707746c/4dcb9/cat_meltano_yml.png 188w,
https://preset.io/static/de703953407d812018cc4ab3e707746c/d38a6/cat_meltano_yml.png 376w,
https://preset.io/static/de703953407d812018cc4ab3e707746c/442cb/cat_meltano_yml.png 752w,
https://preset.io/static/de703953407d812018cc4ab3e707746c/5b481/cat_meltano_yml.png 846w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
</li>
<li>
<div><p>By default, Meltano will instruct extractors like <code>tap-slack</code> to extract all of the entities and attributes specified in the extractor's catalog. </p><p>  You can run the following command to list all of the attributes Meltano will extract by default:</p></div>
<div data-language="text"><pre><code>meltano select --list --all tap-slack</code></pre></div>
<div><p><span>
      <a href="https://preset.io/static/dadb76e7f52577f0e5892671095f3861/91f10/meltano_schema.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Meltano Schema" title="Meltano Schema" src="https://preset.io/static/dadb76e7f52577f0e5892671095f3861/442cb/meltano_schema.png" srcset="https://preset.io/static/dadb76e7f52577f0e5892671095f3861/4dcb9/meltano_schema.png 188w,
https://preset.io/static/dadb76e7f52577f0e5892671095f3861/d38a6/meltano_schema.png 376w,
https://preset.io/static/dadb76e7f52577f0e5892671095f3861/442cb/meltano_schema.png 752w,
https://preset.io/static/dadb76e7f52577f0e5892671095f3861/91f10/meltano_schema.png 992w" sizes="(max-width: 752px) 100vw, 752px" loading="lazy">
  </a>
    </span></p></div>
<p>You can exclude specific entities and attributes if you'd like using:</p>
<div data-language="text"><pre><code>meltano select tap-slack &lt;entity&gt; &lt;attribute&gt;</code></pre></div>
<p>For example, the following commands will instruct Meltnao to not extract <code>teams.plan</code>:</p>
<div data-language="text"><pre><code>meltano select tap-slack --exclude teams plan</code></pre></div>
</li>
<li>
<p>To finish up configuration, we need to set the <code>token</code> and <code>start_date</code> parameters that we specified to Meltano during the extractor setup wizard.
If you run <code>meltano config tap-slack</code>, you'll notice that these values are set to <code>null</code>:</p>
<div data-language="text"><pre><code>{
"token": null,
"start_date": null
}</code></pre></div>
<p>Before configuring the <code>token</code> value, we recommend instructing Meltano to save this OAuth token in <code>.env</code> instead of as plain-text in <code>meltano.yml</code> (which is <a href="https://meltano.com/docs/command-line-interface.html#config">recommended practice</a>). This can be accomplished by opening <code>meltano.yml</code> and editing the <code>settings</code> section to match the following:</p>
<div data-language="text"><pre><code>plugins:
extractors:
- name: tap-slack
namespace: tap_slack
pip_url: git+https://github.com/singer-io/tap-slack.git
executable: tap-slack
capabilities:
- catalog
- discover
- state
settings:
    - name: token
      kind: password
    - name: start_date</code></pre></div>
</li>
<li>
<p>Now, let's set the <code>token</code> value, use the following command:</p>
<div data-language="text"><pre><code>meltano config tap-slack set token xoxb-22342-oauth1-token2-etc</code></pre></div>
<div><p><strong>Recall that the OAuth token comes from the Slack App page from earlier in this post.</strong></p></div>
</li>
<li>
<p>Finally, you need to set the <code>start_date</code> value. This represents the earliest datetime value you want for data like messages and channels synced (all users will be synced regardless of this value).</p>
<div data-language="text"><pre><code>meltano config tap-slack set start_date 2020-09-01</code></pre></div>
<p>We recommend picking a recent start date (<code>2020-09-01</code> at the time of writing is the start of the current month) to test the pipeline.</p>
</li>
</ol>
<h2 id="syncing-slack-data"><a href="#syncing-slack-data" aria-label="syncing slack data permalink"></a>Syncing Slack Data</h2>
<p>Now that we have all of the pieces setup, we just need to configure the destination for the data extracted from Slack. To test the extraction, let's load the data as JSON to a local folder. </p>
<p>To recap on Singer and Meltano vocabulary:</p>
<ul>
<li>data extraction from an API: Singer <code>taps</code> or Meltano <code>extractors</code></li>
<li>data loading to a destination: Singer <code>targets</code> or Meltano <code>loaders</code></li>
</ul>
<p>Meltano comes with <code>target-jsonl</code> out of the box, which stands for <a href="https://jsonlines.org/">JSON lines</a>. Let's use this for testing our pipeline.</p>
<ol>
<li>
<p>You can add <code>target-jsonl</code> using a single command:</p>
<div data-language="text"><pre><code>meltano add loader target-jsonl</code></pre></div>
</li>
<li>
<p>Create a director called <code>output</code> for <code>target-jsonl</code> to dump to.</p>

<p>To test our pipeline we can run the following, beautiful command and watch as Meltano coordinates the orchestra of commands needed for this pipeline.</p>
<div data-language="text"><pre><code>meltano elt tap-slack target-jsonl …</code></pre></div></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://preset.io/blog/2020-09-22-slack-dashboard/">https://preset.io/blog/2020-09-22-slack-dashboard/</a></em></p>]]>
            </description>
            <link>https://preset.io/blog/2020-09-22-slack-dashboard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629894</guid>
            <pubDate>Tue, 29 Sep 2020 16:33:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Technology Actually Making Things Better?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629844">thread link</a>) | @elorant
<br/>
September 29, 2020 | https://www.pairagraph.com/dialogue/354c72095d2f42dab92bf42726d785ff | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/354c72095d2f42dab92bf42726d785ff">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/354c72095d2f42dab92bf42726d785ff</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629844</guid>
            <pubDate>Tue, 29 Sep 2020 16:29:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Coinbase Got It Wrong and Tech Leaders Need to Speak Out]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629685">thread link</a>) | @geoffroberts
<br/>
September 29, 2020 | https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening | <a href="https://web.archive.org/web/*/https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5e5ab77cbd974c787316c1ca" id="sections">
  
    <section data-section-id="5e5ab77cbd974c787316c1cc" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
                &quot;imageOverlayOpacity&quot;: 0.15,
                &quot;video&quot;: {
                  &quot;playbackSpeed&quot;: 0.5,
                  &quot;filter&quot;: 1,
                  &quot;filterStrength&quot;: 0,
                  &quot;zoom&quot;: 0
                },
                &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
                &quot;customSectionHeight&quot;: 10,
                &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                &quot;customContentWidth&quot;: 50,
                &quot;sectionTheme&quot;: &quot;&quot;,
                &quot;sectionAnimation&quot;: &quot;none&quot;,
                &quot;backgroundMode&quot;: &quot;image&quot;
              }" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f7351eccb435d65f7911f6d"><div><div><div data-block-type="2" id="block-f7fa6d006ae58f15a59b"><div><p>Why Coinbase got it wrong and tech leaders need to speak out about an election that runs much deeper than politics</p><p>By <a href="https://twitter.com/GeoffTRoberts">Geoff Roberts</a> · 10 min read</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601394878123_12103"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601395351980-VXU2GJP2G2FE39NL02UK/ke17ZwdGBToddI8pDm48kPVZ5JZEC-owcWMIQ2jhW4FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpz0f89Yb3Pubh4TAiMtJKLZ57c4HEOU3qcz1kuI8OxB6YUDP7-Ncnym616I1rvTmUE/CoinbaseMissionFocused.png" data-image="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601395351980-VXU2GJP2G2FE39NL02UK/ke17ZwdGBToddI8pDm48kPVZ5JZEC-owcWMIQ2jhW4FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpz0f89Yb3Pubh4TAiMtJKLZ57c4HEOU3qcz1kuI8OxB6YUDP7-Ncnym616I1rvTmUE/CoinbaseMissionFocused.png" data-image-dimensions="575x411" data-image-focal-point="0.5,0.5" alt="CoinbaseMissionFocused.png" data-load="false" data-image-id="5f735a9626ac6c47a4e12e49" data-type="image" src="https://www.outseta.com/posts/CoinbaseMissionFocused.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601394878123_12394"><div><p>Jerry McGuire had his late night memo. This may very well prove to be mine.</p><p>Yesterday I opened up Twitter and came across <a href="https://blog.coinbase.com/coinbase-is-a-mission-focused-company-af882df8804">this post from Brian Armstrong, the CEO of Coinbase</a>. I read it and was severely disappointed. Then I came across this endorsement of the article from Y-combinator founder Paul Graham. I was nothing short of mortified.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601394878123_14960"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601395425248-4E8SW1WEH8NZBKKXQV0T/ke17ZwdGBToddI8pDm48kMOpxdSxSGrNDrvMgwlDLLpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxX9hRL0dftBSPVvkhsJfoiCGBA6CkuD9n85DoWEf5iLvRwwlYokq_d0zgwshhFUSs/PaulGrahamCoinbase" data-image="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601395425248-4E8SW1WEH8NZBKKXQV0T/ke17ZwdGBToddI8pDm48kMOpxdSxSGrNDrvMgwlDLLpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxX9hRL0dftBSPVvkhsJfoiCGBA6CkuD9n85DoWEf5iLvRwwlYokq_d0zgwshhFUSs/PaulGrahamCoinbase" data-image-dimensions="608x206" data-image-focal-point="0.5,0.5" alt="PaulGrahamCoinbase" data-load="false" data-image-id="5f735ae003ee376ca2c77eba" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601394878123_17587"><div><p><em>If only because those who don’t are less likely to succeed</em>…. Are you kidding me?</p><p>If you don’t live in the tech world, Coinbase is a tech company that allows you to buy and sell cryptocurrency. The company does billions of dollars in revenue and may soon become publicly traded. Paul Graham is an investor and founder of arguably the most well known start-up accelerator in the world. Few people better embody the idea of “tech leaders” than these two.&nbsp;</p><p>Now I don’t know Brian or Paul, and for all I know they are good people. I appreciate the tone of Brian’s post and I genuinely think he’s trying to do what he believes is the right thing. But as I read his thoughts, I couldn’t help but think to myself…</p><p><em>“Well if this isn’t the walking embodiment of all that’s wrong with the United States right now, I’m not sure what is.”&nbsp;</em></p><p>This article isn’t meant to be an attack on Brian or Paul—far from it. But I am going to use their example to illustrate why they got this oh-so-wrong. And let me begin by saying I write this with no political agenda—I don’t identify with any political party—which leads me to the crux of my argument…</p></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601393386670_18556"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>This election is NOT about politics. It’s about basic human rights, decency, ethics, and the behavior that we expect and accept from our leaders.&nbsp;<span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_18620"><div><p>Brian likely wanted his post to communicate…</p><p><em>”We’re focused on our mission as a company, and aren’t going to be taking a political or social stance.”</em></p><p>Unfortunately all he effectively communicated was…</p><p><em>&nbsp;“We don’t care enough to speak up about basic human rights, decency, and ethics if it’s going to impact our company’s balance sheet.”</em></p><p>And no matter your politics, that’s a massive failure of leadership. That’s turning a blind eye.</p><h2>It’s OK to separate business and politics</h2><p>If you haven’t read Brian’s post, I think it can very fairly be summed up as follows:</p><p><em>Coinbase is a “mission driven” company. Building a company is damn hard, and taking sides politically or in terms of social activism isn’t part of that mission. We have employees with diverse views and don’t want to divide our own company by sharing perspectives that could distract the company from the mission that unites it.</em></p><p>On the surface, that may sound fine—I 100% understand and respect wanting to keep business and politics separate. I personally believe that’s any person’s or company’s right, as much as I wish more businesses would take a stand for what they believe in.&nbsp;</p><p>Likewise, not all businesses need to be altruistic. Fine by me. In all honestly I’ve spent the first 33 years of my life never once intentionally mixing business and politics. And up until this year I’ve always identified as “non-political.” But 2020 has made me realize how much <em>that description of myself</em> came from a position of great privilege. And as I said, the upcoming election in the US is about something so much fundamentally bigger than politics. If you’re truly a leader, you can’t just say “I’m not going there” to something as big as this.</p><h2>Why I’ve started to speak up as a “non-political” person</h2><p>At the subtle prompting of people like Rand Fishkin and Peter Caputa, I’ve started <a href="https://www.outseta.com/posts/leadership-hope-and-minimalism">to speak up</a>. My <a href="https://twitter.com/GeoffTRoberts/status/1307096268703969280">tonality and the topics of my tweets have changed</a>. And none of it has been to show support for any political party—it’s all been in recognition that this election is different.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601393386670_21622"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601394137547-FK6BE4M3LCYRUUFDATCC/ke17ZwdGBToddI8pDm48kLaroNP0RQ9jWQ5AgMRuSbxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyh6qQVTa5d6aWizGl61QgfQsimZojEZtf2Vf89u0m5VPIytlZ9YjucZs5QDZUMtdU/PeterCaputaElection.png" data-image="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601394137547-FK6BE4M3LCYRUUFDATCC/ke17ZwdGBToddI8pDm48kLaroNP0RQ9jWQ5AgMRuSbxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyh6qQVTa5d6aWizGl61QgfQsimZojEZtf2Vf89u0m5VPIytlZ9YjucZs5QDZUMtdU/PeterCaputaElection.png" data-image-dimensions="609x256" data-image-focal-point="0.5,0.5" alt="PeterCaputaElection.png" data-load="false" data-image-id="5f7355d98b9cde1a2962745d" data-type="image" src="https://www.outseta.com/posts/PeterCaputaElection.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_26382"><div><p>Ethics and decency and human rights shouldn’t be construed as “political” or “Democratic” or “Republican”—they should be viewed as ideals that make up the very fabric of America with bi-partisan support, yet somehow we’ve landed here. This election <em>is</em> about showing that we care about having leaders who lead by example.</p><p>At the heart of Brian and Paul’s comments are two devastating ideas:</p><ul data-rte-list="default"><li><p>First, that building a company is hard enough as it is. So hard, that it’s not worth taking a stand on issues that could rock the boat financially.&nbsp;</p></li><li><p>Second, that in some way this is “leadership”—putting the financial interests of your company first and foremost.&nbsp;</p></li></ul><p>I fully recognize that we live in a capitalistic society, and I think that’s mostly a good thing. I want my own start-up to be a roaring financial success. But the perils of capitalism could not be illuminated more than by this interaction—we’re essentially saying “anything goes” because our most important obligations are to our financial constituents? We’re going to turn a blind eye to blatant and rampant ethical violations by the highest elected leader in our country because we need to improve outcomes for our financial stakeholders quarter over quarter?&nbsp;</p><p>I have a hard time calling that anything but having no soul.&nbsp;&nbsp;</p><h2>Tech leaders, no one is asking you to take a political stance</h2><p>What’s altogether missing from this perspective is the very reason people are calling on leaders to take a stand right now. </p></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601393386670_33129"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>No one is asking you, tech leaders, to identify your company as being supportive of Republican or Democatic ideals. <span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_33193"><div><p>The call to arms is simple—the US is being led by a person right now who undeniably:</p><ul data-rte-list="default"><li><p>Acts in his own financial interests and hasn’t paid his fair share</p></li><li><p>Has intentionally and consistently divided the country for his own political agenda</p></li><li><p>Has denied science, from Coronavirus to climate change</p></li><li><p>Is a pathological liar</p></li></ul><p>Tech leaders, you’re not being asked to take a stand on politics! You’re being asked to take a stand on basic human decency and the type of behavior we expect from our leaders. If you’re not comfortable saying, “We expect the truth, we expect a leader who tries to unite us, we expect a leader who leads by example,” then you are unfit to be a leader yourself.&nbsp;</p><p>After all, we all work in technology, right? Isn’t the mission of the tech industry to better the human condition? To advance our abilities as a species? To create a better and more promising future for the next generation?</p><p>If you’re not comfortable denouncing the behaviors that Donald Trump has demonstrated over the past 4 years, you’re either complicit or cowardly. Cowardly? Fine. But true leaders don’t stay silent when the going gets tough. Complicit? OK. But at least be ready to openly admit it.</p><p>If you’re hiding behind being a “mission driven” company so you don’t have to stand up for basic human decency or hold our leaders accountable in any way, at least have fortitude to say, “I’m choosing to act in my company’s best financial interests over anything else.” If you come out and say that I’ll at least respect your honesty. If you won’t my message for you is—<em>have some guts. </em></p><p>Edmund Burke’s quote sums up the election in front of the US perfectly:</p></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601393386670_36155"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>The only thing necessary for the triumph of evil is for good men to do nothing.<span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_36219"><div><h2>Stand for something greater than your balance sheet</h2><p>Taking a stand against obviously absurd and unethical behavior might be hard. It might be polarizing. It might impact your business’ bottom line.&nbsp;</p><p>Boo-hoo-hoo. Get over it.&nbsp;</p><p>It’s still absolutely the right thing to do if you care at all about the next generation, if you care at all about the world your kids will grow up in, if you care at all about what your actions truly say about you and your company. There’s more to life than term sheets, growth rates, and shareholder value.</p><p>I’m becoming increasingly disenfranchised with the tech industry on behalf of the complete and utter silence I’ve heard from the vast majority of tech leaders here in the US. The one thing the silence has made clear is this:</p></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601393386670_38316"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>Most tech leaders are willing to turn a blind eye to protect their own financial interests.<span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_40783"><div><p><em>﻿</em>Perhaps the biggest kicker here is that in taking a stand for what you believe is right, you might lose some business, sure. But I’d guess that more than anything you would be applauded and rewarded by people who actually give a shit who they do business with. Brands are built on opinions, not by using your brand’s “mission” as in invisibility cloak.</p><h2>Easy for you to say—you don’t have the same responsibilities</h2><p>I can hear the criticism of this article already—but Geoff, you’re not running a billion dollar company with thousands of employees and investors as constituents. That’s true. But nobody said leadership at that scale was going to be easy. You’re the person charged with making the tough calls—have the spine to make one. And I am running a business where publishing posts like this directly impacts my ability to put dinner on the table so my kids can eat, so reconsider your assessment of my own personal stakes. If I’ve learned anything in my lifetime it’s this—at the end of the day the only constituent that matters is the person you see looking back at you in the mirror.</p><p>So if you’re out there and you’ve been silent, don’t speak out to take a stand on behalf of the Democrats or the Republicans. Speak out on behalf of being a decent, ethical person. …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening">https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening</a></em></p>]]>
            </description>
            <link>https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629685</guid>
            <pubDate>Tue, 29 Sep 2020 16:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What it feels like when you've found product-market fit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629624">thread link</a>) | @amrrs
<br/>
September 29, 2020 | https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>👋 Hello, I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a> and welcome to a ✨ <strong>once-a-month-free-edition </strong>✨ of my newsletter. Each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing you out at the office.</p><p>If you’re not a paid subscriber, here’s what you missed this month:</p><ol><li><p><a href="https://www.lennyrachitsky.com/p/getting-better-at-product-strategy">Getting better at product strategy</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/fostering-a-culture-of-experimentation">Fostering a culture of experimentation</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/when-to-hire-your-first-product-manager">When to hire your first product manager</a></p></li></ol><p><em>“When we hit PMF, we started feeling pull for the first time”</em></p><p><em>“Like getting pressed into the back of your seat by a fast car or a plane taking off”</em></p><p><em>“Word of mouth was uncontrollable”</em></p><p><em>“Why won't you take my money???”</em></p><p><em>“Yeah, you really can't miss it”</em></p><p>This is what you hear from successful founders when you ask them what product-market fit felt like. But is this always what it feels like? I wanted to find out.</p><p><strong>Over the past few months I reached out to founders of the twenty five most iconic companies I could get a hold of and asked them one question</strong>: </p><blockquote><p><em><strong>When did you first know you found product-market fit?</strong> Whatever that point means to you – was there something you noticed, felt, or experienced where you were like “Damn, I think we got something here!”</em></p></blockquote><p>After collecting and reviewing their stories (all of which you’ll find below), one thing became clear: every company <em>did</em> have a clear moment of PMF, and many <em>did</em>  experience a sudden hard-to-miss pull from the market, BUT many companies <em>did not</em>. For many companies PMF became clear over time through a series of compounding wins or milestones. Here’s how it broke down across the companies I looked at:</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fddea5493-43b6-4017-93b5-47a3b37e38b6_1766x994.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fddea5493-43b6-4017-93b5-47a3b37e38b6_1766x994.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ddea5493-43b6-4017-93b5-47a3b37e38b6_1766x994.png&quot;,&quot;height&quot;:820,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:390110,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><h4><strong>Some of my biggest takeaways from these stories:</strong></h4><p><strong>1. Market “pull” comes in many forms:</strong></p><ul><li><p>An inflection in organic growth</p></li><li><p>Customers asking to pay for the product before you ask</p></li><li><p>Users flip from being excited about what you <em>have</em> to mad about what you <em>don’t have</em></p></li><li><p>Customers complaining when your site goes down</p></li><li><p>People using the product even when it’s broken</p></li></ul><p><strong>2. About half of these companies found PMF immediately after launch, but half spent months or years iterating to get there</strong>:</p><ul><li><p>Netflix: 18 months</p></li><li><p>Segment: 1.5 years</p></li><li><p>Airbnb: 2 years</p></li><li><p>PagerDuty: 2 years</p></li><li><p>Superhuman: 3 years</p></li><li><p>Amplitude: 4 years</p></li></ul><p>Once they got there though, it became obvious.</p><p><strong>3. The intensity of the pull is a factor of the </strong><em><strong>fit</strong></em><strong> (how good your product is at solving the user’s problem) AND </strong><em><strong>initial market size</strong></em><strong> (is it niche or broad)</strong>. Dropbox, Netflix, and Tinder were 10x better products within a huge market —&gt; sudden and broad pull. Instacart, Superhuman, and Substack were 10x better products but for a narrow set of initial customers —&gt; steady and compounding pull.</p><h4>What is Product-Market fit anyway?</h4><p>I covered this in <a href="https://www.lennyrachitsky.com/p/how-to-know-if-youve-got-productmarket">a previous post</a>, and I want to make clear that getting to a feeling of PMF does not mean you’ll automatically be able to build a successful business. There are three things you have to get right to find <strong>True Product-Market Fit</strong>:</p><ol><li><p><strong>Make a product that people want</strong> — that’s what this post is all about. </p></li><li><p><strong>Make a profit delivering this product to people at scale</strong> — companies like <a href="https://techcrunch.com/2012/12/23/cherry-car-wash-shut-down/">Cherry</a>, <a href="https://www.bizjournals.com/sanfrancisco/news/2017/04/27/valet-startup-luxe-shuts-down-its-door-to-door.html">Luxe</a>, and <a href="https://techcrunch.com/2013/09/10/rip-lazy-times/">Exec</a> are valuable cautionary tales.</p></li><li><p><strong>Find and keep these people, sustainably</strong> — <a href="https://www.lennyrachitsky.com/p/how-to-know-if-youve-got-productmarket">check out this previous post</a> that covers the quantitative side of PMF, like retention and sales yield.</p></li></ol><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8975379-7419-4366-b1f5-5f074a3a9c21_2400x1350.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8975379-7419-4366-b1f5-5f074a3a9c21_2400x1350.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d8975379-7419-4366-b1f5-5f074a3a9c21_2400x1350.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:140575,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Of these three milestones though, the most likely to kill your business is the first: not building something people want. And that what this post focuses on — <strong>how do you know when you’ve built something people want</strong>? Below you’ll find stories from twenty-five companies — many of which have never been shared before — revealing the moment they realized they had something special.</p><p>Let’s dive in!</p><p><em>❤️ A HUGE thank you to these generous humans who helped make this post possible: Alex Solomon, Brianne Kimmel, Calvin French-Owen, Chris Best, Cliff Obrecht, Dan Hockenmaier, Drew Houston, Henry Ward, James Beshara, Jason Wang, Jeff Morris Jr., Jeffrey Queisser, Joe Gebbia, Jonathan Badeen, Katie Dill, Keenan Rice, Li Jin, Marc Randolph, Matthias Wagner, Max Mullen, Nikhil Basu Trivedi, Nina Achadjian, Olivier Pomel, Patrick Lightbody, Rahul Vohra, Ryan Graves, Ryan Hoover, Samuel Yam, Sarah Leary, Scott Gorlick, Tai Rattigan, Todd Goldberg, Tom Preston-Werner, and Tomer London ❤️</em></p><h2>Sign 1: 🔥 Sudden and significant pull from the market</h2><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F616f359c-2191-4289-a42d-80adf532482b_1474x412.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F616f359c-2191-4289-a42d-80adf532482b_1474x412.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/616f359c-2191-4289-a42d-80adf532482b_1474x412.jpeg&quot;,&quot;height&quot;:407,&quot;width&quot;:1456,&quot;resizeWidth&quot;:218,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Dropbox for Business is Coming to Salesforce World Tour! - Salesforce  Australia &amp; NZ Blog&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Dropbox for Business is Coming to Salesforce World Tour! - Salesforce  Australia &amp; NZ Blog"></a></p><blockquote><p>“For me there was a visceral sense of your thing taking on a life of its own and lurching forward, <strong>like getting pressed into the back of your seat by a fast car or a plane taking off</strong>. The most standout moment for me was our demo video hitting the top of Digg (and then Reddit).”</p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4a553e07-1eb0-4466-9806-e3bec9802a27_646x413.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4a553e07-1eb0-4466-9806-e3bec9802a27_646x413.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/4a553e07-1eb0-4466-9806-e3bec9802a27_646x413.png&quot;,&quot;height&quot;:413,&quot;width&quot;:646,&quot;resizeWidth&quot;:596,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;image.png&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="image.png"></a><p>ー Drew Houston, CEO and co-founder</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8ee5dc69-f6f8-444e-aeb6-74de26e48cc5_418x135.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8ee5dc69-f6f8-444e-aeb6-74de26e48cc5_418x135.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8ee5dc69-f6f8-444e-aeb6-74de26e48cc5_418x135.png&quot;,&quot;height&quot;:135,&quot;width&quot;:418,&quot;resizeWidth&quot;:212,&quot;bytes&quot;:13721,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><blockquote><p>“With apologies to Justice Potter Stewart, I’ve often felt that Product Market Fit is not unlike hard core pornography: hard to define, but you know it when you see it. <strong>It took us at Netflix 18 months to finally find the repeatable scalable business model that worked</strong>.</p><p>As you know, I called my book "That Will Never Work" because everyone I pitched that original idea had that reaction.&nbsp;(Including my wife!). But they were right. The original idea didn’t work. But hundreds of failed experiments later, and and after many a sleepless night of worrying, we finally tested the unlikely combination of No Due Dates, No Late Fees, and Subscription that ultimately was the thing that ended up working. And boy did it work. <strong>Within days of testing it we knew we had a winner. </strong></p><p><strong>Where before we were struggling to get traffic, all of sudden we couldn’t keep up.  Our previously prodigious amounts of inventory were suddenly not enough.  Engagement soared, churn went dramatically down. Everything started working!</strong></p><p>If there was a moment when Netflix stopped being a start up and became a real company, it was then.”</p><p>ー Marc Randolph, first CEO and co-founder</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9e84f3c5-f8b3-43c4-913b-19172788cd3b_278x132.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9e84f3c5-f8b3-43c4-913b-19172788cd3b_278x132.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9e84f3c5-f8b3-43c4-913b-19172788cd3b_278x132.png&quot;,&quot;height&quot;:132,&quot;width&quot;:278,&quot;resizeWidth&quot;:154,&quot;bytes&quot;:6353,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><blockquote><p>“Uber never really had a product market fit problem — <strong>zero marketing budget and we were growing like a weed. Word of mouth was uncontrollable</strong>, and especially as regulatory heat started it's all anyone could talk about (is how it felt). Marketing was free because media loved the story.”</p><p>— Ryan Graves, first CEO, founding team</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9d3925d8-6349-4063-802a-3ed038ca3e69_3600x1200.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9d3925d8-6349-4063-802a-3ed038ca3e69_3600x1200.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9d3925d8-6349-4063-802a-3ed038ca3e69_3600x1200.jpeg&quot;,&quot;height&quot;:485,&quot;width&quot;:1456,&quot;resizeWidth&quot;:236,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Tinder Review September 2020: Are You Ready to Swipe? - DatingScout.com.au&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Tinder Review September 2020: Are You Ready to Swipe? - DatingScout.com.au"></a></p><blockquote><p>“Besides any gut feeling or friend input, I’d say we knew <strong>we had PMF towards the end of December 2012 when downloads started to pick up. By early to mid January 2013 those downloads started to skyrocket</strong>.</p><p>The rise of Tinder was really fast and there were very, very few changes to the product before it had already taken off. The swipe had been added within weeks of launching in August or September 2012. I think we were working on the 2.0 of the app already before we rose but it wasn’t finished or released until we were already spreading like wildfire.”</p><p>ー Jonathan Badeen, co-founder and CSO</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5f9b73a-d940-4976-b653-bfb9f40474d2_900x280.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5f9b73a-d940-4976-b653-bfb9f40474d2_900x280.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d5f9b73a-d940-4976-b653-bfb9f40474d2_900x280.png&quot;,&quot;height&quot;:280,&quot;width&quot;:900,&quot;resizeWidth&quot;:294,&quot;bytes&quot;:18299,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><blockquote><p>“The biggest difference between our ideas pre-PMF vs. when we found <strong>it was this feeling of </strong><em><strong>pull</strong></em>. Before we had any sort of fit, it always felt like we had to push our ideas on other people. We had to nag people to use the product. </p><p><strong>When we hit PMF, we started feeling 'pull' for the first time</strong>. We solved one problem for people... so they started asking us to solve a second, third, fourth, and fifth. Most of our early product iteration was just responding to customer requests.”</p><p>ー Calvin French-Owen, co-founder</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3f7bc07f-00ad-4cd0-b100-bfbca3677b29_640x343.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3f7bc07f-00ad-4cd0-b100-bfbca3677b29_640x343.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3f7bc07f-00ad-4cd0-b100-bfbca3677b29_640x343.png&quot;,&quot;height&quot;:343,&quot;width&quot;:640,&quot;resizeWidth&quot;:122,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;File:Box, Inc. logo.svg - Wikimedia Commons&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="File:Box, Inc. logo.svg - Wikimedia Commons"></a></p><blockquote><p>“For us it really felt like Geoffrey Moore's <strong>Inside the Tornado</strong>. Nearly 100% inbound sales because there was sufficient demand to keep the phones ringing.”</p><p>ー Jeffrey Queisser, co-founder and SVP of Engineering</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F20e15927-d2af-4707-a238-3eb81068f9a2_1280x537.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F20e15927-d2af-4707-a238-3eb81068f9a2_1280x537.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/20e15927-d2af-4707-a238-3eb81068f9a2_1280x537.png&quot;,&quot;height&quot;:537,&quot;width&quot;:1280,&quot;resizeWidth&quot;:170,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;File:Stripe Logo, revised 2016.svg - Wikimedia Commons&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="File:Stripe Logo, revised 2016.svg - Wikimedia Commons"></a></p><blockquote><p>“What indicated to us that there was something interesting here was that our friends who were using it asked if they could invite their friends, and those people invited their friends, and it <strong>spread through word of mouth process</strong>.</p><p><strong>We just put up a wait list on our site and demand took off, over a couple months we had a huge wait list. We weren’t expecting it.</strong>”</p><p>— Patrick Collison, CEO and co-founder (<a href="https://medium.com/notes-essays-cs183c-technology-enabled-blitzscalin/class-11-notes-essay-reid-hoffman-john-lilly-chris-yeh-and-allen-blue-s-cs183c-technology-ebf34cebae26">source</a>, <a href="http://techzinglive.com/page/939/168-tz-interview-patrick-collison-stripe">source</a>)</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F72fca2d4-c92e-419e-aad1-724e9a19c3b0_992x394.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F72fca2d4-c92e-419e-aad1-724e9a19c3b0_992x394.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/72fca2d4-c92e-419e-aad1-724e9a19c3b0_992x394.png&quot;,&quot;height&quot;:394,&quot;width&quot;:992,&quot;resizeWidth&quot;:224,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Patreon Png ,HD PNG . (+) Pictures - vhv.rs&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Patreon Png ,HD PNG . (+) Pictures - vhv.rs"></a></p><blockquote><p>“For Patreon, it was actually right after we launched with Jack's music video on YouTube video and patrons and creators started writing in.</p><p id="youtube2-mZ02alEkbLw" data-attrs="{&quot;videoId&quot;:&quot;mZ02alEkbLw&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><iframe src="https://www.youtube-nocookie.com/embed/mZ02alEkbLw?rel=0&amp;autoplay=0&amp;showinfo=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><p><strong>I'd never seen that level of passion and immediate resonance</strong>,&nbsp;and our launch was particularly fraught with stress since weeks before all the creators that were asked to launch rejected&nbsp;us. I actually emailed investors right after this, with a now cringey-esque note: ‘If you recall anything about me, I'm not one to exaggerate or overstate things, but based on the results and response thus far, I really think this company is going to be the one.’”&nbsp;</p><p>— Samuel Yam, co-funder and CTO</p></blockquote><blockquote></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F86d436a8-3910-4aba-8fc4-bdbe282dc481_320x158.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F86d436a8-3910-4aba-8fc4-bdbe282dc481_320x158.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/86d436a8-3910-4aba-8fc4-bdbe282dc481_320x158.png&quot;,&quot;height&quot;:158,&quot;width&quot;:320,&quot;resizeWidth&quot;:178,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Carta | Equity Management Solutions - Equity Plans, Cap Tables &amp; 409A&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Carta | Equity Management Solutions - Equity Plans, Cap Tables &amp; 409A"></a></p><blockquote><p>“About six months after we launched we changed our phone provider I think to DialPad or RingCentral. We misconfigured the system and for some reason after it prompted the user to "Press #1 for Sales" and the user pressed the button, it would just hang up on the caller. We didn't know about it for three weeks because we were just trying to fill the non-phone orders. </p><p>The way we found out was a prospect was able to contact us through chat support and wrote <strong>"I've been trying to get to your sales people for weeks and you keep hanging up on me!!! Why won't you take my money???" That's what product market fit feels like.</strong>”</p><p>ー Henry Ward, CEO and co-founder</p></blockquote><blockquote></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F222d8da0-614d-492f-96f3-ea18f955dc65_2000x665.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F222d8da0-614d-492f-96f3-ea18f955dc65_2000x665.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/222d8da0-614d-492f-96f3-ea18f955dc65_2000x665.png&quot;,&quot;height&quot;:484,&quot;width&quot;:1456,&quot;resizeWidth&quot;:286,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Github Logo Png&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Github Logo Png"></a></p><blockquote><p><strong>“</strong>When we launched our private beta (mostly enthusiasts from the Ruby community) we were offering it for free.<strong> To our surprise, users started writing to us asking ‘Can we pay for this??’ They liked it so much they wanted to pay for it. That was the first sign this was going to work.</strong></p><p>Our early users were individuals from the Ruby community. These people already demonstrated they were willing to operate on the cutting edge, Ruby was really new still in 2009. It was critical that we were embedded in that community before then, I don’t think we’d be able to convince people to try GitHub otherwise.</p><p><strong>After we got traction with individuals we were able to expand into SMBs, and then enterprises.”</strong></p><p>— Tom Preston-Werner, first CEO and co-founder</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F284047ac-81c2-41c5-b751-8e3cc5665165_611x180.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F284047ac-81c2-41c5-b751-8e3cc5665165_611x180.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/284047ac-81c2-41c5-b751-8e3cc5665165_611x180.png&quot;,&quot;height&quot;:180,&quot;width&quot;:611,&quot;resizeWidth&quot;:321,&quot;bytes&quot;:22984,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><blockquote><p>“I remember distinctly it was a Friday night. We had been working on the wait list in preparation for our press launch, which would have been, I think, the following Wednesday or Thursday. Everyone goes home, and I wake up Saturday …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found">https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629624</guid>
            <pubDate>Tue, 29 Sep 2020 16:13:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self hosted GitHub Actions runners in Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24629532">thread link</a>) | @SkyLinx
<br/>
September 29, 2020 | https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/ | <a href="https://web.archive.org/web/*/https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <article>
          <header>
  <span>
    
  </span>

  
  
  
    
	
  
  
    <div>
      
      <p>
        , &nbsp;published <time>Tuesday, Sep 29 2020</time>
      </p>
    </div>

    <p>
      Published &nbsp; <time>Tuesday, Sep 29 2020</time>
    </p>
 	
  
  
</header>

          <!--<div class="mt-8 sharethis-inline-share-buttons"></div>-->
          <section>
            
<div>
<p>Since August last year,<b>&nbsp;<a href="https://github.com/features/actions" target="_blank">Github Actions</a></b>&nbsp;has evolved into a complete solution to build pipelines for CI/CD, as well as a wide variety of other automation tasks. It's not always been the most reliable CI/CD&nbsp;solution available, but the service has improved a lot over time and it's a reasonably good option now. Writing YAML&nbsp;<i>﻿workflows</i>﻿ for Github Actions is pretty easy, and you get 2000 minutes of usage of Github's hosted runners included with the free Github plan, which is plenty for small teams. After that, pricing is affordable and competitive compared to that of other solutions in the market.</p>
<p>Besides the ease of use and the overall good design, one thing I particularly like is that you can also self host Github Actions runners in your own infrastructure for absolutely no cost. It's totally free, and you can use as beefy servers for this as you like, which can translate in better performance when executing workflows compared to Github's own runners which only have 2 cores and 7 GB of memory. Self hosted runners allow for greater control, making workflows more flexible. Also, if your workflows build Docker images, you need some workarounds to benefit from layer caching with Github's own runners since each time a workflow runs a brand new environment is spun up, so images built with previous runs are not cached out of the box. By using a self hosted runner instead, you can choose to use the same Docker instance across workflow runs, so new workflow runs can leverage layers cached in previous builds, which can dramatically speed up the execution.</p>
<p>I have been using a self hosted runner for Github Actions for a little while now, but while until recently I was using a VPS dedicated to the job, I am now leveraging some spare capacity in my Kubernetes cluster for this purpose to build, test and deploy <b>﻿<a href="https://www.dynablogger.com/" target="_blank">DynaBlogger</a></b>; this post is about how to set up self hosted runners for Github Actions in Kubernetes for workflows that require building Docker images. I'll assume you are already familiar with how Github Actions work.</p>
<p>There are various ways to build Docker images inside a Kubernetes cluster, but perhaps the easiest is with the&nbsp;<b>﻿"Docker in Docker</b>﻿" approach available with the <a href="https://hub.docker.com/_/docker" target="_blank">official Docker image</a>&nbsp;- it's basically the ability to run a Docker daemon inside a container and you can run the usual build commands as if you ran these commands directly on the actual host. We'll need a deployment of&nbsp;Docker in Docker ("dind") as well as a deployment of an image containing all the required dependencies to run self hosted runners for Github Actions which will leverage the dind deployment. This has a couple of important benefits:</p>
<ul>
<li>we can use a persistent volume for dind, so to benefit from layer caching across multiple workflow runs</li>
<li>we can easily scale runners by just scaling the deployment, allowing for multiple workflows to be executed in parallel.</li>
</ul>
<h2>Setting up the Docker in Docker deployment</h2>
<p>For dind we'll use a regular Kubernetes deployment and the&nbsp;<i>﻿dind</i>﻿ version of the official Docker image. First things first, you'll need to create a namespace - I name this namespace as&nbsp;<i>﻿docker-in-docker</i>﻿:<i></i><i></i></p>
<pre><code>kubectl create ns docker-in-docker</code></pre>
<p>Next, we need to create a persistent volume claim (pvc) in this namespace that dind will use to persist the Docker layers even if the pod is rescheduled for any reason:</p>
<pre><code>apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: dind
  namespace: docker-in-docker
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi

</code></pre>
<p>I am creating a volume of 50GB&nbsp;here since that should be enough for me (I can just exec into the container and prune images if needed every now and then), but you are free to create a larger or smaller volume.</p>
<p>Like I said for dind we'll need a regular deployment, so create&nbsp;<i>﻿deployment-dind.yml</i>﻿ with<i></i>&nbsp;the following:</p>
<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: dind
  namespace: docker-in-docker
spec:
  replicas: 1
  selector:
    matchLabels:
      workload: deployment-docker-in-docker-dind
  template:
    metadata:
      labels:
        workload: deployment-docker-in-docker-dind
    spec:
      containers:
      - command:
        - dockerd
        - --host=unix:///var/run/docker.sock
        - --host=tcp://0.0.0.0:2376
        env:
        - name: DOCKER_TLS_CERTDIR
        image: docker:19.03.12-dind
        imagePullPolicy: IfNotPresent
        name: dind
        resources: {}
        securityContext:
          privileged: true
          readOnlyRootFilesystem: false
        stdin: true
        tty: true
        volumeMounts:
        - mountPath: /var/lib/docker
          name: dind-storage
      volumes:
      - name: dind-storage
        persistentVolumeClaim:
          claimName: dind</code></pre>
<p>A few things to note here:</p>
<ul>
<li>we are setting the command explicitly because by default dind will run with TLS for the connections between the daemon and the clients. You can either leave the command unset to use TLS or override it to ignore TLS to make things a bit easier, it's up to you. I choose to disable TLS for this. Besides specifying a command without the default TLS arguments, we also need to set the&nbsp;<i>﻿DOCKER_TLS_CERTDIR</i>﻿ environment variable to an empty string;&nbsp;</li>
<li>the image we are using is the latest docker image with the&nbsp;<i>﻿dind</i>﻿ tag, so to be able to make the Docker daemon available to remote clients;</li>
<li>I am leaving the resources unset in this cluster, but since CPU-intensive workflows might use a lot of CPU, you may want to set some limits here;</li>
<li>finally, we are making sure that the pod can use the persistent volume claim we created earlier.<br>
</li>
</ul>
<p>To deploy, run:</p>
<pre><code>kubectl apply -f deployment-dind.yml</code></pre>

<h2>Setting up the Github Actions runners' deployment</h2>
<p>The next thing we need to do, is set up the deployment for the actual runners. I found a few different ways to do this, but the easiest for me was using&nbsp;<a href="https://github.com/SanderKnape/github-runner" target="_blank">this repo</a>&nbsp;since it already includes a useful Dockerfile as well as a sample deployment manifest for kubernetes. So go ahead and clone the repository, then open the&nbsp;<i>﻿Dockerfile</i>﻿ in your editor.&nbsp;</p>
<p>The Dockerfile installs the dependencies required by Github Actions to connect the runner to the Github Actions service, so that the runner can listen for jobs and report progress to Github. We can build a custom image using this Dockerfile and that's what we'll do in order to make using the dind instance possible. In particular we need to add the following to the&nbsp;<i>﻿apt install</i>﻿ command:</p>
<pre><code>    &amp;&amp; curl https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgz --output docker-19.03.9.tgz \
    &amp;&amp; tar xvfz docker-19.03.9.tgz \
    &amp;&amp; cp docker/* /usr/bin/</code></pre>
<p>The final Dockerfile will look something like the following:</p>
<pre><code>FROM debian:buster-slim

ARG GITHUB_RUNNER_VERSION="2.273.4"

ENV RUNNER_NAME "runner"
ENV GITHUB_PAT ""
ENV GITHUB_OWNER ""
ENV GITHUB_REPOSITORY ""
ENV RUNNER_WORKDIR "_work"
ENV RUNNER_LABELS ""
ENV DOCKER_HOST="tcp://docker-in-docker.dind:2376"

RUN apt-get update \
    &amp;&amp; apt-get install -y \
        curl \
        sudo \
        git \
        jq \
        iputils-ping \
    &amp;&amp; apt-get clean \
    &amp;&amp; rm -rf /var/lib/apt/lists/* \
    &amp;&amp; useradd -m github \
    &amp;&amp; usermod -aG sudo github \
    &amp;&amp; echo "%sudo ALL=(ALL) NOPASSWD:ALL" &gt;&gt; /etc/sudoers \\
    &amp;&amp; curl https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgz --output docker-19.03.9.tgz \
    &amp;&amp; tar xvfz docker-19.03.9.tgz \
    &amp;&amp; cp docker/* /usr/bin/

USER github
WORKDIR /home/github

RUN curl -Ls https://github.com/actions/runner/releases/download/v${GITHUB_RUNNER_VERSION}/actions-runner-linux-x64-${GITHUB_RUNNER_VERSION}.tar.gz | tar xz \
    &amp;&amp; sudo ./bin/installdependencies.sh

COPY --chown=github:github entrypoint.sh ./entrypoint.sh
RUN sudo chmod u+x ./entrypoint.sh

ENTRYPOINT ["/home/github/entrypoint.sh"]
</code></pre>
<p>One important thing to note here is that whenever there is a new release of the runner's software, we'll need to rebuild our image and update the deployment. The reason is that the runner itself will listen not only to jobs for workflows to run, but also to notifications whenever a new version of its software is available, which triggers a download of the new software followed by a restart of the runner. Of course, in Kubernetes this will cause the pod to restart, and then the runner will download the new software and restart again, causing a crash loop. To prevent that, I recommend you watch <a href="https://github.com/actions/runner" target="_blank">the runner's code repo</a>&nbsp;so you get notified when a new version is available, and can rebuild the image.</p>
<p>Next, go ahead and build the image, then push it to your registry of choice. If you don't need to change anything in the Dockerfile, you can just use the image I prebuilt and published on Docker Hub,&nbsp;<i>vitobotta/github-actions-runner:0.0.4</i>.<i>﻿</i></p>
<p>You don't need to change anything in the <i>entrypoint.sh</i> script, which simply installs the runner's software. However you need to make a few small changes to the deployment manifest <i>deployment.yml&nbsp;</i>﻿so that it looks like the following:</p>
<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: github-runner
  namespace: github-actions
  labels:
    app: github-runner
spec:
  replicas: 1
  selector:
    matchLabels:
      app: github-runner
  template:
    metadata:
      labels:
        app: github-runner
    spec:
      containers:
      - name: github-runner
        image: vitobotta/github-actions-runner:0.0.4
        env:
        - name: DOCKER_HOST
          value: tcp://dind.docker-in-docker:2376
        - name: GITHUB_OWNER
          value: &lt;your github username&gt;
        - name: GITHUB_REPOSITORY
          value: &lt;your repository&gt;
        - name: GITHUB_PAT
          valueFrom:
            secretKeyRef:
              name: github-actions-token
              key: pat
</code></pre>
<p>As you can see we set the&nbsp;<i>﻿DOCKER_HOST</i>﻿ to our dind pod. …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/">https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/</a></em></p>]]>
            </description>
            <link>https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629532</guid>
            <pubDate>Tue, 29 Sep 2020 16:07:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redis TLS was a big hit to performance – a look at how KeyDB addressed it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629370">thread link</a>) | @benschermel
<br/>
September 29, 2020 | https://docs.keydb.dev/blog/2020/09/29/blog-post/ | <a href="https://web.archive.org/web/*/https://docs.keydb.dev/blog/2020/09/29/blog-post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><div id="blog_body">
<p>We were extremely excited about TLS (Transport Layer Security) support which arrived in the ‘6.0’ versions of Redis and KeyDB. TLS database connections are part of a continuing trend towards defense in depth which has been a long time in the making, first starting with <a href="https://arstechnica.com/information-technology/2013/11/googlers-say-f-you-to-nsa-company-encrypts-internal-network/">google encrypting links</a> between their datacenters in 2013.</p>
<p>Unfortunately with Redis, TLS came with a big hit to performance ranging from 36-61%. While security is important, making a trade-off with performance may not always be a viable compromise. We thought carefully about the TLS implementation in KeyDB to try and prevent our users from experiencing this. By taking advantage of KeyDB’s multithreaded architecture we were able to maintain performance achieving nearly 1M ops/sec which was over 7X faster than the Redis TLS implementation.</p>
<!--truncate-->
<p>For those who may not be aware, <a href="https://github.com/JohnSully/KeyDB">KeyDB</a> is an open source project and compatible with Redis API, protocol and clients.</p>
<h2>An Analysis of TLS Perf by Redis</h2>
<p>I was recently looking through a detailed <a href="https://github.com/redis/redis/issues/7595">github issue response</a> by a RedisLabs performance engineer . He did a great job analyzing CPU holdup &amp; performance degradation when using TLS.</p>
<p>Here he suggests there is approximately a 36% drop in ops/sec with single threaded performance. In his analysis he states “TLS involves another layer in the stack, that brings additional overhead. The added SSL/TLS stack implies 28% CPU time devoted to it ( writing/reading bytes from ssl connetion, encrypt/decrypt and integrity check” … “Based on the flame graphs they moved from spending 17% on the handler to spending 45% of the CPU time with tls.”</p>
<p>Redis currently does not support using io-threads per their <a href="https://github.com/redis/redis/blob/unstable/TLS.md#connections">docs</a>.
RedisLabs <a href="https://docs.redislabs.com/latest/rs/administering/designing-production/security/client-connections/">documentation</a> also warns that  “TLS encryption can significantly impact database throughput and latency”</p>
<h2>A Comparison of Redis, TLS and Multithreaded KeyDB</h2>
<h3>Benchmarking Ops/sec</h3>
<p>Running tests of our own, we saw the same results (36% decline) to those stated by Redis for a single node. We will also include a comparison with Redis io-threads and how KeyDB performs with TLS enabled. This test looks at performance of a single node. Tests were done on AWS m5 instances of adequate size to ensure the machines were not a bottleneck.</p>
<p>The tests below were performed using memtier on a m5.8xlarge with the following command:</p>
<pre><code>$ memtier_benchmark --hide-histogram --tls <span>--cert</span>=/path/to/redis.crt <span>--key</span>=/path/to/tls/redis.key <span>--cacert</span>=/path/to/tls/ca.crt -s 172.31.56.132 <span>--threads</span>=32
</code></pre>
<p>KeyDB and Redis were operated on a m5.4xlarge. To see more details on setup for reproducing benchmarks please see the end of this blog.</p>
<p><img src="https://docs.keydb.dev/img/blog/2020-09-15/ops_comparison.png" alt="image"></p>
<p>You will see that our testing shows the same measured decline of 36%  with TLS enabled on Redis6 (single threaded). However if you were previously using the io-thread feature, you could see a 61% drop in performance as io-threads is not supported using TLS. This is stated in  <a href="https://github.com/redis/redis/blob/unstable/TLS.md#connections">TLS.md</a></p>
<h3>Why KeyDB perf does not decline</h3>
<p>With KeyDB there is almost no decline using TLS as multithreading is supported and it can scale vertically. The performance remains considerably higher in general due to architectural difference between the projects. There are considerably more CPU resources used with TLS, but that is something KeyDB is great at accounting for.</p>
<p>With 8 threads allocated, we were hitting closer to 800K ops/sec vs 1M ops/sec without TLS. However increasing threadcount as high as 16 threads enabled us to get back up to near the 1M ops/sec mark.</p>
<p>This enables us to compensate to the load and still offer the security without the penalty to performance for our users who rely on the perf.</p>
<h3>Latency Benchmark (lower is better)</h3>
<p>Similar trends can be seen in the latency measurements of the same test performed above. You can see that latency is significantly higher at these loads when using TLS. KeyDB not only serves at very high volumes, but the latency is also up to 7x lower that Redis with TLS. It can be noted latencies measured with memtier are pushing peak loads and when not heavily loaded will achieve much lower latencies. This should be taken as a relative comparison under load.</p>
<p><img src="https://docs.keydb.dev/img/blog/2020-09-15/latency_comparison.png" alt="image"></p>
<h3>Flamegraphs</h3>
<p>In the RedisLabs analysis they provided flamegraphs for context. For those interested we ran flame graphs on Redis 6, Redis 6 with io-threads, Redis 6 + TLS, KeyDB and KeyDB + TLS. Full expandable breakdowns can be seen by following the links below the charts.</p>
<p><img src="https://docs.keydb.dev/img/blog/2020-09-15/flamegraphs.PNG" alt="image"></p>
<p>Links to complete expandable flamegraphs:</p>
<ul>
<li><a href="https://download.keydb.dev/blog-2020-09-15/redis-fg.svg">Redis (single-threaded)  </a></li>
<li><a href="https://download.keydb.dev/blog-2020-09-15/redis-iothreads8-fg.svg">Redis with io-threads</a></li>
<li><a href="https://download.keydb.dev/blog-2020-09-15/redis-tls-fg.svg">Redis with TLS enabled</a></li>
<li><a href="https://download.keydb.dev/blog-2020-09-15/keydb-fg.svg">KeyDB (Multithreaded)    </a></li>
<li><a href="https://download.keydb.dev/blog-2020-09-15/keydb-tls-fg.svg">KeyDB with TLS enabled (multithreaded)</a></li>
</ul>
<h2>Conclusion</h2>
<p>TLS encryption is a great option when it comes to security, however if you are currently using Redis this may come with a performance penalty. If you are not heavily loading Redis you may be able to handle the additional overhead, but its something that should be taken into account.</p>
<p>To summarize performance:</p>
<ul>
<li>Redis with TLS experienced a 36% drop from single threaded Redis, and a 61% drop compared to using Redis with io-threads enabled.</li>
<li>KeyDB achieved close to 1 million ops/sec with little to no performance drop after adding additional threads</li>
<li>KeyDB got close to 1 million ops/sec with TLS enabled, while Redis got ~130k ops/sec</li>
</ul>
<p>Options for Redis users to increase performance would come in the form of sharding or increasing cluster size. KeyDB can also be used as a drop in replacement for the Redis binary.</p>
<p>KeyDB comes in at over 7X faster than Redis when using TLS. It may be a viable alternative when using this feature if performance is an issue for you.</p>
<h2>Find out More:</h2>
<ul>
<li><a href="https://github.com/JohnSully/KeyDB">KeyDB open source project on github</a></li>
<li><a href="https://keydb.dev/">Website</a></li>
<li><a href="https://eqalpha.us20.list-manage.com/subscribe/post?u=978f486c2f95589b24591a9cc&amp;id=4ab9220500">Subscribe to Mailing List</a>
<i></i></li><i>
</i></ul><p><i>
<h2>Reproducing benchmarks:</h2>
<p>For benchmark testing, an aws m5.8xlarge was needed as the benchmarking machine which used memtier as the benchmark tool. For the Redis/KeyDB instance a m5.4xlarge was used. Machine size selection was based off terminal performance ensuring the machine was not the bottleneck. A larger machine size would not make a difference in results, however a smaller machine may result in lower throughput.</p>
<p>If you are using TLS for the first time you can generate certificates simply cloning the github project and running <code>./utils/gen-test-certs.sh</code> to create the certificates for Redis or KeyDB.</p>
<p>You can now run keydb-server with the following command:</p>
<pre><code>$ keydb-server <span>--tls-port</span> 6379 <span>--port</span> 0 <span>--tls-cert-file</span> <span>./tests/tls/redis.crt</span> <span>--tls-key-file</span> <span>./tests/tls/redis.key</span> <span>--tls-ca-cert-file</span> <span>./tests/tls/ca.crt</span> <span>--server-threads</span> 16 <span>--server-thread-affinity</span> <span>true</span> <span>--protected-mode</span> no
</code></pre>
<p>For Redis we ran the following command:</p>
<pre><code>$ redis-server <span>--tls-port</span> 6379 <span>--port</span> 0 <span>--tls-cert-file</span> <span>./tests/tls/redis.crt</span> <span>--tls-key-file</span> <span>./tests/tls/redis.key</span> <span>--tls-ca-cert-file</span> <span>./tests/tls/ca.crt</span> <span>--protected-mode</span> no
</code></pre>
<p>In order to use memtier to connect via TLS ensure you transfer the ./test/tls/* files over to the benchmarking machine. You can the run the following command:</p>
<pre><code>$ memtier_benchmark --hide-histogram --tls <span>--cert</span>=/path/to/redis.crt <span>--key</span>=/path/to/tls/redis.key <span>--cacert</span>=/path/to/tls/ca.crt -s 172.31.56.132 <span>--threads</span>=32
</code></pre>
<p>For tests without TLS, the following commands were used:
KeyDB:</p>
<pre><code>$ keydb-<span>server</span> –-<span>server</span>-threads <span>10</span> –-<span>server</span>-thread-affinity <span>true</span> –-<span>protected</span>-mode no 
</code></pre>
<p>Redis:</p>
<pre><code>$ redis-server -–io-threads <span>8</span> –-<span>protected</span>-mode no
</code></pre>
<p>Memtier:</p>
<pre><code>$ memtier_benchmark -s <span>172.31</span><span>.56</span><span>.132</span> --hide-histogram  –-threads=<span>32</span> 
</code></pre>
<h3>Avoid bottlenecks</h3>
</i></p><ul><i>
<li>Because of KeyDB’s multithreading and performance gains, we typically need a much larger benchmark machine than the one KeyDB is running on. We have found that a 32 core m5.8xlarge is needed to produce enough throughput with memtier. This supports throughput for up to a 16 core KeyDB instance (medium to 4xlarge)</li>
<li>When using Memtier run 32 threads.</li>
<li>Run tests over the same network. If comparing instances, make sure your instances are in the same area zone (AZ). Ie both instances in us-east-2a</li>
<li>Run with private IP addresses. If you are using AWS public IPs there can be more variance associated with the network</li>
<li>Beware running through a proxy or VPC. When using such methods, firewalls, and additional layers it can be difficult to know for sure what might be the bottleneck. Best to benchmark in a simple environment (within same vpc) and add the layers afterwards to make sure you are optimized.</li>
<li>When comparing different machine instances ensure they are in the same AZ and tested as closely as possible in time. Network throughput throughout the day does change so performing tests close to eachother provides the most representative relative comparison.</li>
</i><li><i>KeyDB is multithreaded. Ensure you specify multiple threads when running
</i></li>
</ul>
</div>
</span></p></div></div></div>]]>
            </description>
            <link>https://docs.keydb.dev/blog/2020/09/29/blog-post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629370</guid>
            <pubDate>Tue, 29 Sep 2020 15:56:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Music Is Helpful for Concentration]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24629356">thread link</a>) | @pavelegorkin
<br/>
September 29, 2020 | https://tinnire.app/blog/why-music-is-helpful-for-concentration/ | <a href="https://web.archive.org/web/*/https://tinnire.app/blog/why-music-is-helpful-for-concentration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Discover the best music for focusing. Read the article to learn how to improve the efficiency of your work.</p>
    <h2>Content</h2>
    <ol>
        <li>What is concentration?</li>
        <li>Ways to improve focus and concentration</li>
        <li>What kind of music disrupts focusing</li>
        <li>Flow state music</li>
    </ol>

    <h2>What is Concentration?</h2>

    <p>There are several meanings of the word concentration. If we talk about focusing attention, then this is keeping the interest on one aspect while ignoring other things.</p>
    <p>In English language, this word came in the 1630s <a href="https://www.etymonline.com/word/concentrate?ref=etymonline_crossreference#etymonline_v_17305" target="_blank">from Italian</a> <i>concentrare</i>. Its origin is Latin: <i>com</i> ‘with, together’ + <i>centrum</i> ‘center’. This literally means ‘action of bringing to a central point’.</p>
    <p>Our ability to concentrate is important because the human body has limited resources. If we work being constantly distracted, then we will not be able to complete the task.</p>
    <p>Since ancient times, people have developed various techniques to stay focused. Let's dwell on the most popular methods.</p>

    <h2>Ways to Improve Focus and Concentration</h2>
    <ul>
        <li>
            <b>Choose the most productive working hours.</b> The early birds and late rasers have their peaks of activity at completely different times of the day. So, for the top-priority tasks, choose the time according to your individual characteristics.
        </li>
        <li>
            <b>Minimize the number of simultaneous tasks.</b> Scientists at <a href="https://news.stanford.edu/news/2009/august24/multitask-research-study-082409.html" target="_blank">Stanford University</a> have found that multitasking lowers human performance. Therefore, you should reduce the number of tasks and focus on one or two.
        </li>
        <li>
            <b>Make a clear plan and stick to it.</b> Until you complete one of the items, do not pay attention to anything else. Between plan items, you can take small breaks and change in the type of activity. If you are a computer worker, look out of the window or do a few push-ups.
        </li>
        <li>
            <b>Avoid checking your email and phone at work.</b> According to the
            <a href="http://www.fieldworksmarketing.co.uk/wellness/how-to-reduce-stress-for-international-stress-awareness-week/" target="_blank">International Journal of Information Management</a>, it takes us approximately 64 seconds to come back to the working process after checking email. If your job is not directly related to making calls and writing letters, put the phone away. Adopt a rule to check email and messengers before work and after work. Mute all notifications the rest of the time.
        </li>
        <li>
            <b>Use background music for concentration or white noise.</b> If you can't find a quiet place to work, you can use background sounds to drown out any distracting noises and keep your attention on the main thing.
        </li>
    </ul>
    <p>However, it happens that music does not help to focus. Let's find out why.</p>

    <h2>What Kind of Music Disrupts Focusing</h2>

    <p>Loud or fast-paced music. In general, any soundtrack that grabs your attention distracts you from your work. Dance music is created with the intention of fascinating you, creating a sense of celebration and encouraging you to dance.</p>
    <p>At the same time, if you put a song that you actively dislike, it will also not help your concentration, because you will think about your feelings.</p>
    <p>Songs with lyrics or commercials are also a bad choice for focusing. The brain will try to understand and process the text it hears.</p>

    <h2>Flow State Music</h2>
    <p>There is a particular type of music that is specifically designed to help you focus as much as possible. It calls flow state music.</p>
    <p>The term <i>flow state</i> was coined by the American psychologist <a href="https://en.wikipedia.org/wiki/Mihaly_Csikszentmihalyi" target="_blank">Mihaly Csikszentmihalyi</a>. He described this state as a maximum motivation and focusing on completing work. A person in the flow state feels freedom, joy and total satisfaction.</p>
    <p>Probably anyone who has been doing what they love has experienced the flow state. The Tinnire App offers an endless amount of music tracks that will help you stay in this state all day long. This AI-assisted music has been created specifically for concentrating. Visit
        the <a href="https://tinnire.app/">Tinnire website</a> and try it for free.</p>

</div></div>]]>
            </description>
            <link>https://tinnire.app/blog/why-music-is-helpful-for-concentration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629356</guid>
            <pubDate>Tue, 29 Sep 2020 15:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud-Native Security has Two R’s, not Three]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629352">thread link</a>) | @hobbiton
<br/>
September 29, 2020 | https://dr-knz.net/cloud-native-security-containers.html | <a href="https://web.archive.org/web/*/https://dr-knz.net/cloud-native-security-containers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <p>This article explains how I stopped a software vendor and at least one of its
customers from hemorraging $50K+ yearly due to unnecessary&nbsp;costs.</p>
<p>❦❦❦</p>
<p>A recommended best practice in Enterprise security is the “three R’s”:
Repair, Repave and Rotate <a href="https://builttoadapt.io/the-three-r-s-of-enterprise-security-rotate-repave-and-repair-f64f6d6ba29d?gi=428524632f99">[1]</a> <a href="https://thenewstack.io/why-wells-fargo-repaves-its-entire-platform-every-day/">[2]</a> <a href="https://tanzu.vmware.com/cloud-native-security">[3]</a>.</p>
<p>Repair means applying security patches as soon as available. Rotate
means rotating credentials often. Those two are useful and, at this
stage of our industry, necessary for good security&nbsp;hygiene.</p>
<p>The third R, “Repave,” meaning “bring back the software image to a
known state” is popular but, it is my argument today, <em>useless</em>—in a
truly cloud-native world, it is not&nbsp;needed.</p>
<p>That’s it!  Save money, use <em>immutable containers</em>, don’t&nbsp;repave.</p>
<p>End of&nbsp;story.</p>
<p>(<em>Repair,</em> on the other hand, remains absolutely relevant: container
images do contain <em>outdated</em> software, especially the base
image—libraries, run-time systems, etc. Folk who use containers should
regularly rebuild their container images to include the latest
security patches. But that is a story for another&nbsp;time.)</p>
<p>❦❦❦</p>
<p>I could be writing an article about the technicalities of <em>why</em>
repaving is not&nbsp;needed.</p>
<p>I could be explaining how repaving was invented for a world where
software was <em>installed</em> anew upon every new deployment by mutating an
<span>OS</span> image using an installation program, how the system image remained
mutable afterwards, and therefore how a risk remained for hackers to
install malware on top of&nbsp;it.</p>
<p>I could be explaining how FreeBSD <a href="https://en.wikipedia.org/wiki/FreeBSD_jail">Jails</a> (2000), Solaris <a href="https://en.wikipedia.org/wiki/Solaris_Containers">Zones</a>
(2004), and <a href="https://en.wikipedia.org/wiki/Docker_(software)">Docker</a> (2013) have been <em>specifically</em> designed and
implemented to support immutable filesystem mounts, with all
executable code and configuration “baked in” so that no amount of
bugs, mistakes or hackers can ever <em>change</em> the software within the
container and make it diverge from a known-good&nbsp;state.</p>
<p>I could also glaringly point out that software deployed <em>today</em> in
clouds comes most often as immutable containers, and thus that this form of
<em>cloud-native software</em>, once deployed, can never change—<em>by
construction</em>.</p>
<p>I could then conclude that requests from enterprise-y customers for
<em>procedures</em> and/or <em>processes</em> to “repave” a container-based software
deployment are, at best, <em>meaningless</em>; and in truth, <em>just a way to
throw good money after bad</em>.</p>
<p>The Enterprise mindset is to continue to do something long after it is not
needed any more. News at 11! <em>How is that even an interesting story to write&nbsp;about?</em></p>
<p>❦❦❦</p>
<p>The <em>real</em> story here is how a software vendor (who shall remain
nameless) got roped into spending significant effort over about a
year, and thus extremely significant $$$$, to entertain a
“repaving” story for container-based deployments, without anybody
realizing what was going&nbsp;on.</p>
<p>This story is not even very long, but it is <em>instructive</em>.</p>
<p>The story begins as follows: a customer says “I need a repaving
procedure.” Vendor assumes that the customer is installing on bare
metal or in a <span>VM</span>. Vendor obliges and start a year-long initiative to
ensure that the software behaves properly when reinstalled from
scratch. This was a complex project technically because the software
had to remain online while the repaving took&nbsp;place.</p>
<p>Then <em>someone</em> comes in and listens to a report about that customer’s
deployments and learns that the customer is really using <a href="https://en.wikipedia.org/wiki/Kubernetes">Kubernetes</a>
and deploys their software as immutable&nbsp;containers.</p>
<p><em>Huh</em>?</p>
<p>It turns out&nbsp;that:</p>
<ul>
<li>customer was saying “I need repaving” to one person,
and did not mention their use of containers to that
person. This first person did not <em>ask</em> about containers&nbsp;either.</li>
<li>Meanwhile, the customer was saying “I use containers” to <em>another</em> person.
The second person was not involved in the repaving&nbsp;story.</li>
</ul>
<p>And so two folk at the vendor did not connect the dots, and the
organization spent a minimum of $50k (I estimate $70k-$100k) in
combined hours from 4 departments to solve a problem that did not need
solving. Classic&nbsp;miscommunication.</p>
<p>(Also, did I mention that this vendor <em>recommends containers</em> as their
primary deployment mechanism, and their own <em>business strategy</em>
revolves around containers? That the repaving story even got traction
internally, given that business focus, astounds&nbsp;me.)</p>
<p>❦❦❦</p>
<p>To me personally, what is painful to admit is that I was listening on
both sides of the story for that entire year and it took me awfully
too long to connect the&nbsp;dots.</p>
<p>I would really like to be able to defend myself and say that the
customer was a large organization, and thus that I was <em>assuming</em> that
there were really two different groups of users, one using containers
and one using bare metal / VMs and repaving. But that was just that—an
<em>assumption</em>, and it was my job to check that assumption, and I did&nbsp;not.</p>
<p>❦❦❦</p>
<p>What is the lesson&nbsp;here?</p>
<ul>
<li><p>At a very minimum, when a customer says “I need something” a vendor
should probably ask&nbsp;“why”.</p>
</li>
<li><p>Then, if the reason given is security-related, the vendor should
probably ask a <em>security expert</em> to verify any&nbsp;assumptions.</p>
</li>
<li><p>Then, assuming a security expert is involved in the discussion, the
expert would ask about, then take into account, the entire customer’s
deployment practices to evaluate the problem to solve,
in a <em>holistic</em>&nbsp;manner.</p>
<p>This way, lateral knowledge about the customer’s practices would
surface, and could be used to point out that the “something” being
asked is&nbsp;redundant.</p>
</li>
</ul>
<p>And, of course, the obvious: security “best practices”
should not be implemented without understanding the <a href="https://dr-knz.net/stride-threat-model-with-examples.html">threat model</a>.</p>
<p>Repaving is not needed with immutable&nbsp;containers.</p>



             




 
                <hr>
    <p><a href="https://dr-knz.net/#about-the-author" target="_blank" rel="nofollow noopener noreferrer">
            <img src="https://dr-knz.net/images/avatars/cat.jpg" alt="Raphael ‘kena’ Poss Avatar" title="Raphael ‘kena’ Poss">
            
        </a>
        is a computer scientist and software engineer specialized in compiler construction, computer architecture, operating systems and databases.
    </p>

            







<section>
    
    

    
</section>

            <hr>
<section>
    <h2>Keep Reading</h2>

<hr>
</section>
            
        </div></div>]]>
            </description>
            <link>https://dr-knz.net/cloud-native-security-containers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629352</guid>
            <pubDate>Tue, 29 Sep 2020 15:55:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CockroachDB Code Commenting Guidelines]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629333">thread link</a>) | @knz42
<br/>
September 29, 2020 | https://wiki.crdb.io/wiki/spaces/CRDB/pages/914260289/Code+commenting+guidelines | <a href="https://web.archive.org/web/*/https://wiki.crdb.io/wiki/spaces/CRDB/pages/914260289/Code+commenting+guidelines">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wiki.crdb.io/wiki/spaces/CRDB/pages/914260289/Code+commenting+guidelines</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629333</guid>
            <pubDate>Tue, 29 Sep 2020 15:54:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[12 factors for successful Machine Learning in production]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629281">thread link</a>) | @benkoller
<br/>
September 29, 2020 | https://blog.maiot.io/12-factors-of-ml-in-production/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/12-factors-of-ml-in-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>The last two decades have yielded us some great understandings about Software Development. A big part of that is due to the emergence of DevOps and itâ€™s wide adoption throughout the industry.</p>

<p>Leading software companies follow identical patterns: Fast iterations in software development followed by Continuous Integration, Continuous Delivery, Continuous Deployment. Every artefact is tested on its ability to provide value, always has a state of readiness and is deployed through automation.</p>

<p>As a field, Machine Learning differs from traditional software development, but we can still borrow many learnings and adapt them to â€œourâ€� industry. For the last few years, weâ€™ve been doing Machine Learning projects in production, so beyond proof-of-concepts, and our goals where the same is in software development: reproducibility. So we built a pipeline orchestrator, strong automations and established a workflow to achieve exactly that.</p>

<p>Why not just Jupyter Notebooks? Well, how long does it take to construct a Notebook from scratch, with all processing steps, from scratch? And how easy is it to onboard new members to the team? Can you reproduce the results youâ€™ve had two months ago, now, fast? Can you compare todayâ€™s results against historic oneâ€™s? Can you give provenance over your data throughout training? And what happens if your model goes stale?</p>

<p>Weâ€™ve faced all of these issues, and more, and now took our experience to deduce 12 factors (as a nod to the <a href="https://12factor.net/">12 factor app</a>) that build the backbone of successful ML in production.</p>

<h2 id="1-versioning">1. Versioning</h2>

<p>While obvious to basically all Software Engineers, version control is not an universally accepted methodology among Data Scientists. Let me quote the folks at Gitlab as a quick primer:</p>

<blockquote>
  <p>Version control facilitates coordination, sharing, and collaboration across the entire software development team. Version control software enables teams to work in distributed and asynchronous environments, manage changes and versions of code and artifacts, and resolve merge conflicts and related anomalies.</p>
</blockquote>

<p>In short, versioning lets you safely manage the moving parts of Software Development.</p>

<p>As a special form of Software Development, Machine Learning has unique requirements. First, it has not one but two moving parts: Code and Data. Second, model trainings happen in (fast) iterations and introduce a high variance of code (e.g. splitting, preprocessing, models).</p>

<p>As soon as data can be subject to change it needs to be versioned to be able to reproducibly and repeatably conduct experiments and train models. Cruder forms of versioning (read: hard-copies) can go a long way, but especially in team scenarios shared, immutable version control becomes critical.</p>

<p>Version control of code is even more key. In addition to aboveâ€™s quote, preprocessing code is not just relevant at training but also at serving time and needs to be immutably correlatable with models. Serverless functions can provide an easy-access way to achieve a middle ground between the workflow of Data Scientists and production-ready requirements.</p>

<p><strong>TL;DR:</strong> You need to version your code, and you need to version your data.</p>

<h2 id="2-explicit-feature-dependencies">2. Explicit feature dependencies</h2>

<p>In a perfect world, whatever produces your input data will forever produce exactly the same data, at least structurally. But the world is not perfect, youâ€™re consuming data from an upstream service thatâ€™s built by humans and might be subject to change. Features will change, eventually. At best, your models fail outright, but at worst theyâ€™ll just silently start to produce garbage results.</p>

<p>Explicitly defined feature dependencies allow for transparent failure as early as possible. Well-designed systems will accommodate feature dependencies both in continuous training as well as at serving time.</p>

<p><strong>TL;DR:</strong> Make your feature dependencies explicit in your code.</p>

<h2 id="3-descriptive-training-and-preprocessing">3. Descriptive training and preprocessing</h2>

<p>Good software is descriptive - it can be read and understood easily without reading every line of code.</p>

<p>And while Machine Learning is a unique flavor of Software Development it doesnâ€™t exempt practitioners from following established coding guidelines. Basic understanding of coding standard essentials can be picked up with very little effort and in a short amount of time.</p>

<p>Code for both preprocessing and models should follow <a href="https://www.python.org/dev/peps/pep-0008/">PEP8</a>. It should consist of meaningful object names and contain helpful comments. Following PEP8 will improve code legibility, reduce complexity and speed up debugging. Programming paradigms such as <a href="https://en.wikipedia.org/wiki/SOLID">SOLID</a> provide thought frameworks to make code more maintainable, understandable and flexible for future use cases.</p>

<p>Configuration should be separated from code. Donâ€™t hardcode your split ratios, provide them at runtime through configuration. As known from hyperparameter tuning, a well-separated configuration increases speed of iterations significantly and makes codebases reusable.</p>

<p><strong>TL;DR:</strong> Write readable code and separate code from configuration.</p>

<h2 id="4-reproducibility-of-trainings">4. Reproducibility of trainings</h2>

<p>If you canâ€™t reproduce training results you canâ€™t trust the results. While this is somewhat the overarching theme of this blogpost, there are nuances to reproducibility. Not just do you need to be able to reproduce a training yourself, the entire team should be able to do so. Obscuring trainings in Jupyter Notebooks on someones PC or on some VM on AWS is the literal inverse of a reproducible training.</p>

<p>By using pipelines to train models entire teams gain both access and transparency over conducted experiments and training runs. Bundled with a reusable codebase and a separation from configuration, everyone can successfully relaunch any training at any point in time.</p>

<p><strong>TL;DR:</strong> Use pipelines and automation.</p>

<h2 id="5-testing">5. Testing</h2>

<p>Testing comes in many shapes and forms. To give two examples:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Unit_testing">Unit testing</a> is testing on an atomic level - every function is tested individually on itâ€™s own specific criteria.</li>
  <li><a href="https://en.wikipedia.org/wiki/Integration_testing">Integration testing</a> is taking an inverse approach - all elements of a codebase are tested as a group, in conjunction and with clones/mocks of up- and downstream services.</li>
</ul>

<p>Both paradigms are good starting points for Machine Learning. Preprocessing code is predestined for unit testing - do transforms yield the right results given various inputs? Models are a great use case for integration tests - does your model produce comparable results to evaluation at serving time in a production environment?</p>

<p><strong>TL;DR:</strong> Test your code, test your models.</p>

<h2 id="6-drift--continuous-training">6. Drift / Continuous training</h2>

<p>Drift is a legit problem for production scenarios. You need to account for drift as soon as there is even a slight possibility that data might change (e.g. user input, upstream service volatility). Two measures can mitigate risk exposure:</p>

<ul>
  <li>Data monitoring for production systems. Establish automated reporting mechanisms to alert teams of changing data, even beyond explicitly defined feature dependencies.</li>
  <li>Continuous training on newly incoming data. Well-automated pipelines can be rerun on newly recorded data and offer comparability to historic training results to show performance degradation as well as offer a quick way to promote newly trained models into production, given better model performance.</li>
</ul>

<p><strong>TL;DR:</strong> If you data can change run a continuous training pipeline.</p>

<h2 id="7-tracking-of-results">7. Tracking of results</h2>

<p>Excel is not a good way to track experiment results. And not just Excel, any decentralized, manual form of tracking will yield non-authoritative and therefore untrustworthy information.</p>

<p>The right approach are automated methods to record training results in a centralized data store. Automation ensures the reliable tracking of every training run, and allows for a later comparability of training runs against each other. Centralized storage of results give transparency across teams and allows for continuous analysis.</p>

<p><strong>TL;DR:</strong> Track results via automation.</p>

<h2 id="8-experimentation-vs-production-models">8. Experimentation vs Production models</h2>

<p>Understanding datasets requires effort. Commonly, this understanding is gathered through experimentation, especially when operating in fields with a lot of hidden domain knowledge. Start a Jupyter Notebook, get some/all of the data into a Pandas Dataframe, do some hours of out-of-sequence magic, train a first model, evaluate results - Job done. Well, unfortunately not.</p>

<p>Experiments serve a purpose in the lifecycle of Machine Learning. The results of these Experiments are however not models, but understanding. Models from explorative Jupyter Notebooks are proof for understanding, not production-ready artefacts. Gained understanding will need more molding and fitting into production-ready training pipelines.</p>

<p>All understandings unrelated to domain-specific knowledge can however be automated. Generate statistics on each data version youâ€™re using to skip any one-time, ad-hoc exploratory work you might have had to do in Jupyter Notebooks, and move straight to the first pipelines. The earlier you experiment in pipelines, the earlier you can collaborate on intermediate results and the earlier youâ€™ll receive production-ready models.</p>

<p><strong>TL;DR:</strong> Notebooks are not production-ready, so experiment in pipelines early on.</p>

<h2 id="9-training-serving-skew">9. Training-Serving-Skew</h2>

<p>The avoidance of skewed training and serving environments is often reduced to correctly embedding all data preprocessing into the model serving environments. This is absolutely correct, and you need to adhere to this rule. However, it is also a too narrow interpretation of Training-Serving-Skew.</p>

<p>A little detour to ancient DevOps history: In 2006 the CTO of Amazon, Werner Vogels, coined the term â€œYou build it, you run itâ€�. Itâ€™s a descriptive phrase for extending the responsibility of Developers to not only writing but also running the software they build.</p>

<p>A similar dynamic is required for Machine Learning projects - an understanding of both the upstream generation of data and the downstream usage of generated Models is within the responsibility of Data Scientists. What system generates your data for …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.maiot.io/12-factors-of-ml-in-production/">https://blog.maiot.io/12-factors-of-ml-in-production/</a></em></p>]]>
            </description>
            <link>https://blog.maiot.io/12-factors-of-ml-in-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629281</guid>
            <pubDate>Tue, 29 Sep 2020 15:49:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5 Things to look for in a Computer Vision startup job]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629259">thread link</a>) | @pat-jay
<br/>
September 29, 2020 | https://insights.ai-jobs.net/5-things-to-look-for-in-a-computer-vision-startup-job/ | <a href="https://web.archive.org/web/*/https://insights.ai-jobs.net/5-things-to-look-for-in-a-computer-vision-startup-job/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-21057">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>So you’re looking to join an ML startup in computer vision. At <a href="https://v7labs.com/">V7</a>, we partner with hundreds of the most ambitious AI and ML startups bringing sight to machines. Here are the common traits that the highest-achieving ones share:</p>



<h2>1. Do they have data?</h2>



<figure><img loading="lazy" width="1200" height="698" src="https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_sets_images.jpg" alt="" srcset="https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_sets_images.jpg 1200w, https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_sets_images-300x175.jpg 300w, https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_sets_images-1024x596.jpg 1024w, https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_sets_images-768x447.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"></figure>



<p>This should be your starting point. An ML startup without data for you to use will make your job harder and no fun. During a job interview, make sure you understand the data you’ll be working with very well. This doesn’t mean revealing its content, but you should know in general abstraction about:</p>



<ul><li>Where it’s coming from <em>(is it exclusive?)</em></li><li>What it’s captured by <em>(is the device relevant?)</em></li><li>What visual characteristics is the startup looking for <em>(can it be labelled?)</em></li></ul>



<p>Don’t be rude – AI companies are protective of their data, so rather than asking “Where is your data coming from” consider asking “are the sources of the data your users? What kind of profile do they have?” Exclusivity of data is a huge moat for AI startups, so if the data being used comes from an open dataset, consider that a red flag.</p>



<p>Sometimes the device capturing the data may be the product – a robot, camera system, or appliance. In this case, make sure that you’re able to work with that hardware configuration before jumping in. Consider asking whether the hardware is fixed in place, or if they’d like you to experiment with it.</p>



<p>Finally, whatever they wish to identify must be supervised in some way, else you’ll never know if your model is working. Make sure the data can be labelled within reason. If the objects can be enclosed in a polygon, that’s great. If temporal understanding is needed, that’s ok, but may not be elegantly solvable today. If the data comes from multiple cameras across large spans of time, with occlusions, appearance changes, or other obstacles, consider that this may be a research problem only solvable with a human-in-the-loop today.</p>



<h2>2. In what state will you find the data when starting</h2>



<figure><img loading="lazy" width="899" height="484" src="https://insights.ai-jobs.net/wp-content/uploads/2020/09/bad_data_with_dogs-1.jpg" alt="" srcset="https://insights.ai-jobs.net/wp-content/uploads/2020/09/bad_data_with_dogs-1.jpg 899w, https://insights.ai-jobs.net/wp-content/uploads/2020/09/bad_data_with_dogs-1-300x162.jpg 300w, https://insights.ai-jobs.net/wp-content/uploads/2020/09/bad_data_with_dogs-1-768x413.jpg 768w" sizes="(max-width: 899px) 100vw, 899px"><figcaption>Hopefully not like this</figcaption></figure>



<p>There may be none, there may be raw images, there may be poorly placed labels or a combination of the three. Rarely is computer vision talent hired once a dataset is ready to go. In fact, this probably never happens, you will have to give your input on how its labelled, organized, and optimized once your product launched and racks up failure cases.</p>



<p><a href="http://v7labs.com/">V7</a> was built to help you with this stage. You can automate labelling, organize and manage huge datasets, version control your work, and load it straight into Pytorch or Tensorflow.</p>



<p><strong>If your data is raw</strong>: The good news is that labelling data is very quick now. You can use something like <a href="https://www.v7labs.com/automated-annotation">Auto Annotate</a> to apply labels rapidly on objects of interest, or load pre-existing labels from a model output.</p>



<p><strong>If your data is labelled:</strong> This isn’t always good news. Ask yourself who labelled this, and for whom? Was someone dropped from the project who was supposed to use the data?</p>



<p><strong>If there is no data</strong>: You might be twirling your thumbs for a while, or working on proxy datasets while it is collected. Encourage the team to capture some as quickly as possible for validation purposes.</p>



<h2>3. Figure out if you’re in research or engineering</h2>



<figure><img loading="lazy" width="1200" height="483" src="https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_scientist_ml_engineer_salaries-1.jpg" alt="" srcset="https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_scientist_ml_engineer_salaries-1.jpg 1200w, https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_scientist_ml_engineer_salaries-1-300x121.jpg 300w, https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_scientist_ml_engineer_salaries-1-1024x412.jpg 1024w, https://insights.ai-jobs.net/wp-content/uploads/2020/09/data_scientist_ml_engineer_salaries-1-768x309.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>Source: Experfy via SalaryNinja (<a href="https://www.experfy.com/blog/machine-learning-engineer-vs-data-scientist-is-data-science-over/" target="_blank" rel="noreferrer noopener">https://www.experfy.com/blog/machine-learning-engineer-vs-data-scientist-is-data-science-over/</a>)</figcaption></figure>



<p>There are no “research engineers”. There are engineers asked to implement papers, or researchers asked to develop something for the user – neither of these tend to be happy folks.</p>



<p>Most talent in computer vision likes the idea of research because it sounds more noble, and less prone to deadlines. Commercial research also has a dark side – it is a more volatile job: your research topic moves quickly, and you might not be needed next year. If the company has a team of researchers that cannot be counted on 1 hand, make sure that they have a killer revenue stream, or flush with capital. Researchers are expensive and distant from directly generating revenue; when 💩 hits the fan, they are often the first to go.</p>



<p>Engineers are more loved when times are tough, and in most industries they have more career opportunities. Startups hiring “computer vision engineers” or “deep learning engineers” at the very most expect you to implement the cutting edge (whatever that means for them), but not iterate on it.</p>



<p>You know already if you are one or the other – make sure you apply to a position that suits that profile. If the team you are joining is less than 14, it is inevitable that you will have to do a bit of the other.</p>



<h2>4. Is the problem in a space you care about?</h2>



<figure><img loading="lazy" width="600" height="300" src="https://insights.ai-jobs.net/wp-content/uploads/2020/09/good_tomatobot.jpg" alt="" srcset="https://insights.ai-jobs.net/wp-content/uploads/2020/09/good_tomatobot.jpg 600w, https://insights.ai-jobs.net/wp-content/uploads/2020/09/good_tomatobot-300x150.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>



<p>If the tech is applied, make sure the area is something you find interesting, because it will define how you will introduce yourself at parties. If it’s fundamental research, ensure that the vision that it leads you is one that excites you.</p>



<p>Be wary of startups that sell you the idea of an idyllic product that changes the world effortlessly – you will have to work hard, on hard problems, against fierce competition of other motivated fellow ML engineers. Seek instead those that give you a glimpse of what a hard day on the job might look like.</p>



<p>Even if your problem appears very fundamental, it will become applied one day. Your mom and dad will recognize the application of your AI product more so than the tech behind it, and that will likely be the first use-case to hit the market or the press. If your groundbreaking hand tracker will primarily be used to make dance videos on apps, would that excite you? If not you are doing yourself and your employer a disfavor by entertaining that role.</p>



<h2>5. Do they have a chance of becoming N1?</h2>



<p>More importantly, do <em>you</em> have a chance of making that team the best in their field?</p>



<p>Your employer will likely be part of a niche problem space that they aim to dominate – something like identifying hand signs, unusual defects, triangulate a location via camera, signs of climate change, the wake of ships, picking ripe strawberries, car’s dents… there are hundreds of huge problems to solve that require sight. Vision AI is an exciting field where new use cases appear every day, and hundreds of startups emerge to resolve them. Does the team you are about to join have a plan to be the best, or the largest of a handful of players in a space? Have they implemented the right tools, engineering practices, and data flow to help you help them succeed? Are you going to help them make a dent in their market so big that people will notice?</p>



<p>You aren’t looking for clear “yes” answers here – nobody is proclaimed a winner at the starting line. However make sure that the questions above aren’t clear “no”s. Most important of all, don’t go to the team asking for answers – do your own research, and come to them with a hypothesis. For example, rather than asking “what are your thoughts on Competitor A?”, say “I’ve looked at Competitor A’s product and it looks like they’re missing out on using this approach, is the goal to use it as a differentiator and become better than them?” This will grant you some brownie points and a less defensive answer, and if you’re wrong, you’ll learn more about your interviewer by the way they correct you. Remember, you’re there to be helpful, take that opportunity to see what that feels like in return!</p>



<p>Good luck!</p>



<hr>



<p>WRITTEN BY <a href="https://www.v7labs.com/" target="_blank" rel="noreferrer noopener">V7</a> | <a href="https://twitter.com/V7Labs" target="_blank" rel="noreferrer noopener">@V7Labs</a></p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://insights.ai-jobs.net/5-things-to-look-for-in-a-computer-vision-startup-job/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629259</guid>
            <pubDate>Tue, 29 Sep 2020 15:48:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New homeowner 'freaked out' when stranger took control of her security system]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629254">thread link</a>) | @joeyespo
<br/>
September 29, 2020 | https://www.cbc.ca/news/business/security-system-app-homeowner-stranger-1.5733444 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/security-system-app-homeowner-stranger-1.5733444">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A new homeowner discovers a stranger can disarm the alarm, unlock windows and doors and track when she comes and goes from her new house. Security and privacy experts say the situation is the result of weak laws and cancellation policies written to benefit companies instead of protecting customers.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5733519.1600744704!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/taylor-fornell.jpg"></p></div><figcaption>Taylor Fornell had been living in her new home in Stony Plain, Alta., for several weeks before discovering someone she'd never met could control her home security system.<!-- --> <!-- -->(Art Raham/CBC)</figcaption></figure><p><span><p>The message came out of the blue for Taylor Fornell. A stranger told her he had complete control over the home security system in her new house in Stony Plain, Alta., and could prove it.</p>  <p>As she stood alone in her front hall, she watched in disbelief as the man unarmed the system, unlocked doors and windows and&nbsp;told her he could track&nbsp;when she left the house&nbsp;— all with a few clicks on the security company's app.</p>  <p>"I felt a little sick to my stomach … It's just really creepy and a breach of trust," Fornell told Go Public, referring to Vivint, the security company that installed and ran the system.</p>  <p>Fornell was lucky. The stranger who connected&nbsp;with her on Facebook was the former owner of the house.</p>  <p>Rob Hall wanted to warn her he still had control over the security system, despite asking the company to cancel the service weeks before Fornell moved in.</p>  <p>Security and privacy experts say the situation is the result of weak laws and cancellation policies that are written to boost companies' bottom lines instead of protecting customers.</p>  <p>"It's so frustrating that consumers should have to be the ones to pick up the slack on how to protect their privacy. It's outrageous," said&nbsp;privacy advocate and former Ontario privacy commissioner Ann Cavoukian.</p>  <p>She said security companies should be required to cancel their services as soon as "you depart from the home, should you sell it or something."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/ann-cavoukian.jpg 300w,https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/ann-cavoukian.jpg 460w,https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/ann-cavoukian.jpg 620w,https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ann-cavoukian.jpg 780w,https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/ann-cavoukian.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ann-cavoukian.jpg"></p></div><figcaption>Ontario's former privacy commissioner Ann Cavoukian says privacy protection rules ought to be written into contracts for home security systems.<!-- --> <!-- -->(Onnig Cavoukian)</figcaption></figure></span></p>  <h2>'She kind of freaked out'</h2>  <p>When Hall moved out, the security equipment was left behind. He had no idea he would still be able to control it after he handed over the keys.</p>  <p>He said Fornell&nbsp;"kind of freaked out because she was literally standing in her new house watching all the doors unlocking."</p>  <p>Hall's contract with Vivint had already expired when he called on May 21, requesting the service be cut off.&nbsp;He also sent an email that same day confirming his request.</p>  <p>On June 17, he realized&nbsp;he could still control the security system and contacted Fornell.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/rob-hall.jpg 300w,https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/rob-hall.jpg 460w,https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/rob-hall.jpg 620w,https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rob-hall.jpg 780w,https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rob-hall.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rob-hall.jpg"></p></div><figcaption>Rob Hall shows Go Public's Rosa Marchitelli the app he used to control Fornell's security system. <!-- --> <!-- -->(Art Raham/CBC)</figcaption></figure></span></p>  <p>Go Public spoke with three others&nbsp;who say they had the same experience with Vivint after selling or buying a home. All posted&nbsp;their&nbsp;stories on a private community Facebook page after reading what happened to Hall.<strong><strong> </strong></strong></p>  <p>"I just thought that was absolutely crazy," Hall said.</p>  <p>Hall says he called the company again the day he showed Fornell he still had access,&nbsp;and was told he'd have to wait a few more days before it would be cut off.</p>  <p>"I said, 'So you're going to give me access to somebody else's house? I literally could go on the app, I could watch them leave the house, then I could walk up to the front door, unlock it, disarm the system, walk and steal everything in the&nbsp;place because an alarm company gave me access.'"&nbsp;</p>  <p>Hall&nbsp;says that's when Vivint deactivated the app, a process which took less than 30 seconds.</p>  <p>Vivint says its policy requires 30 days' notice for cancellation but says it&nbsp;can cut off access right away if needed. The company says Hall&nbsp;didn't provide a move-out date when he cancelled the service and the company representative&nbsp;didn't ask.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/facebook-post.jpg 300w,https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/facebook-post.jpg 460w,https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/facebook-post.jpg 620w,https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/facebook-post.jpg 780w,https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/facebook-post.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/facebook-post.jpg"></p></div><figcaption>Several people, including this Edmonton woman, responded with similar stories when Hall posted his experience with Vivint on Facebook.<!-- --> <!-- -->(Facebook)</figcaption></figure></span></p>  <p>The company said "that step was overlooked" by its representatives in all the cases Go Public asked about.</p>  <p>"Our company policy is to confirm this&nbsp;timing but that step was overlooked in the cases you have shared … We have reviewed our process to ensure these situations are handled per our policies moving forward," spokesperson Liz Tanner told Go Public in an email</p>  <p>She added that the company honoured the terms of the customer agreement in all the cases.</p>  <p>Home security systems are big business in Canada,&nbsp;$2.6-billion a year according to IBISWorld, a private company that provides statistics and research on Canadian industries.&nbsp; That same report found&nbsp;Vivint&nbsp;is on track to have the second&nbsp;largest share of the&nbsp;national security system market by the end of 2020, after&nbsp;ADT.&nbsp;</p>  <p>It's also an industry with a lot of privacy and security issues, according to Kevvie Fowler from the&nbsp;consultancy firm&nbsp;Deloitte, who has 25 years' experience as a software developer and a security expert and who works with companies to prevent and recover from security breaches.</p>  <p>For example, Fowler says cancellation policies — which can range from 30 days to six months or more depending on the company — aren't written with privacy and security in mind, but to increase sales.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/kevvie-fowler.jpg 300w,https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/kevvie-fowler.jpg 460w,https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/kevvie-fowler.jpg 620w,https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/kevvie-fowler.jpg 780w,https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/kevvie-fowler.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/kevvie-fowler.jpg"></p></div><figcaption>Security expert Kevvie Fowler says security companies delay cancellations, hoping new homeowners will sign up for the service.<!-- --> <!-- -->(Submitted by Kevvie Fowler)</figcaption></figure></span></p>  <p>"It's advantageous for the monitoring companies not to cancel your service with the hopes that the new homeowner will actually come on board and sign up to the service … that's why they focus on the contract and having that extended period of time to actually cancel the service," he said.</p>  <p>Vivint says that's not the case with its contracts, saying it requires 30 days to cancel so customers can find another provider&nbsp;or&nbsp;move out of the house&nbsp;or continue to protect a vacant property during a sale.</p>  <p>None of those reasons apply to Hall or the other Vivint customers Go Public spoke with.</p>  <p>Fowler says he's seen a lot of situations when people have had access to home security systems who shouldn't — including access to cameras and microphones in and outside a house.</p>  <h2>Couple taunted by hacker</h2>  <p>Problems with security systems have been well documented. <a href="https://www.youtube.com/watch?reload=9&amp;v=-P0rSnt2HSU">CBC Marketplace</a> exposed problems with some security devices.&nbsp;</p>  <p>Arjun and Jessica Sud learned that firsthand. In January 2019, a stranger was able to hack into the Lake Barrington, Ill.,&nbsp;couple's Google Nest security system, verbally taunting them through their security cameras, after cranking up the heat in their seven-month old son's bedroom to 32 C as a prank, the couple told Go Public.</p>  <p><em><strong>WATCH | Homeowners confront digital intruder (Warning: graphic language):</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="WATCH | Home owners confront digital intruder  (Warning: graphic language)"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/976/323/GPSUD_2500kbps_1280x720_1793105475866.jpg" alt=""></p></div></div></div><span>Arjun and Jessie Sud of Barrington Lake, Illinois heard a voice in their baby's bedroom in January 2019 and discovered a hacker watching them via their home security system.<!-- --> <!-- -->1:18</span></span></span></p>  <p>"The camera that was up on the wall in the living room lights up and a man's voice starts talking to me. I was horrified. My hair still stands up when I talk about it," Sud said.</p>  <p>He says he and his wife immediately disconnected all the cameras and complained to the company.</p>  <h2>Privacy laws out of date</h2>  <p>Cavoukian, the former privacy commissioner, says Canada's weak privacy laws, which were passed&nbsp;20 years ago,&nbsp;are a troubling part of the problem.&nbsp;</p>  <p>She&nbsp;says the law should require&nbsp;privacy protection rules to be written into every aspect of business, including contracts and policies, a <a href="http://www.ipc.on.ca/wp-content/uploads/resources/7foundationalprinciples.pdf">concept she developed</a> called&nbsp;"privacy by design."&nbsp;</p>  <p>Without that, she says Canadians are often left with a false sense of security.</p>  <p>"Our&nbsp;privacy law, [<a href="http://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/">the&nbsp;Personal Information Protection and Electronic Documents Act</a>]&nbsp;is so outdated. Our federal privacy commissioner has been trying to get the federal government to upgrade it and modernize it for years," she said.</p>  <p>Taylor Fornell and Rob Hall&nbsp;would also like to see stronger laws and see companies be upfront about how they protect customers' safety and privacy.</p>  <p>Fornell says she was considering signing up with Vivint before Hall let her know what was happening.</p>  <p>"It was crazy that someone who didn't have keys to my front door could unlock my house without even being on my street," she said.</p>  <p>"If [Hall] was somebody else, if he wasn't an honest person, he could have come in and done who knows what."</p>  <hr>  <p><strong>Submit your story ideas</strong></p>  <p>Go Public is an investigative news segment on CBC-TV, radio and the web.</p>  <p>We tell your stories, shed light on wrongdoing, and hold the powers that be accountable.</p>  <p>If you have a story in the public interest, or if you're an insider with information, contact&nbsp;<a href="https://www.cbc.ca/news/gopublic">GoPublic@cbc.ca</a>&nbsp;with your name, contact information and a brief summary. All emails are confidential until you decide to Go Public.</p>  <p>Follow&nbsp;<a href="https://twitter.com/cbcgopublic" target="_blank">@CBCGoPublic</a>&nbsp;on Twitter.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/security-system-app-homeowner-stranger-1.5733444</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629254</guid>
            <pubDate>Tue, 29 Sep 2020 15:48:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Is Never a Compiler Bug Until It Is]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629234">thread link</a>) | @haakon
<br/>
September 29, 2020 | http://r6.ca/blog/20200929T023701Z.html | <a href="https://web.archive.org/web/*/http://r6.ca/blog/20200929T023701Z.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Last week I was trying to add some <a href="https://github.com/bitcoin-core/secp256k1/pull/822/commits/aa833603a6b4c947c21da04aeac40d80444ebcc1#diff-b04459e37839cd223176618536295715R425">testing code to libsecp256k1</a> and I was pulling out my hair trying to get it to work.
No amount of <code>printf</code> was working to illuminate what I was doing wrong.
Finally, out of desperation, I thought I would do a quick check to see if there are any compiler bugs related to <code>memcmp</code>, and lo and behold, I found <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95189">GCC bug #95189: memcmp being wrongly stripped like strcmp</a>.</p><p>Honestly this was a pretty horrifying bug to read about.
Under some circumstances GCC 9 and 10 will cause <code>memcmp</code> to return an incorrect value when one of the inputs is statically known array that contains <code>NULL</code> bytes.
As I rushed to <a href="https://gist.githubusercontent.com/roconnor/2b8e22e829ed80088ed6690cc3c7f3a8/raw/455571a6d9053c597c1585debe6f9dbd6af85071/gistfile1.txt">recompile my computer system using GCC 8</a>, I contemplated the vast consequences of such a bug could be, and pondered how it was possible that computers could function at all.</p><p>However over the week, with the help of my colleagues, we managed to get a better understanding of the scope of the bug.
The bug can only convert non-zero values to zero values.
The static array needs to have a <code>NULL</code> byte within the first 4 bytes.
Most importantly, the <code>memcmp</code> result must not immediately be compared to <code>0</code> for equality or inequality, or any equivalent test.
A different code path is taken in the compiler in that case.
That explained why computers were still functioning.
I expect the vast majority of the uses of <code>memcmp</code> does an immediate test for equality with <code>0</code>.</p><p>I still wondered though, how much code was being affected. My colleague Tim suggested that it would be possible to instrument GCC to emit a message when it was about to miscompile a program.
Together we came up with <a href="https://gcc.gnu.org/bugzilla/attachment.cgi?id=49276&amp;action=diff">a patch</a> to GCC 9 and 10 that would print a debugging message.
Once again, I recompiled my entire system, to see what GCC was miscompiling.
This is what I found:</p><ul>
<li><a href="https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709">https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709</a></li>
<li><a href="https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310">https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310</a></li>
<li><a href="https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172">https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172</a></li>
<li><a href="https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425">https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425</a></li>
<li><a href="https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70">https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70</a></li>
<li><a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279</a></li>
<li><a href="https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203">https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203</a></li>
<li><a href="https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412">https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412</a></li>
</ul>
<p>On my entire system I only found 10 lines of code that were miscompiled.
Three lines are tests.
All of the lines could be rewritten as a comparison to 0.
None of the lines looked that serious.
I am not sure which one is the worse: the reduced message integrity code(?) from some ARCFOUR implementation or the something something from an ATM driver?</p><p>The mplayer miscompilation is the most mysterious.
The code surrounding that function all appears to be immediately compare <code>memcmp</code> with <code>0</code>.
And given that my debug message refused to point to exactly what line is being miscompiled in that function, I fear some set of optimizations has happened to allow this code to be miscompiled in some way.</p><p>With more hardware I could do <a href="https://hydra.nixos.org/jobset/nixpkgs/trunk#tabs-jobs">a more thorough investigation</a> of the consequences of this GCC bug.
Until then I am going to stick with GCC 8 until GCC 9 and 10 have a new point releases.

</p></div></div>]]>
            </description>
            <link>http://r6.ca/blog/20200929T023701Z.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629234</guid>
            <pubDate>Tue, 29 Sep 2020 15:46:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fourier Filtering]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24629172">thread link</a>) | @gus_massa
<br/>
September 29, 2020 | http://bigwww.epfl.ch/demo/ip/demos/FFT-filtering/ | <a href="https://web.archive.org/web/*/http://bigwww.epfl.ch/demo/ip/demos/FFT-filtering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Running ...</p><div id="main">
    
    <p>
        Your browser does not support the HTML5 canvas element. Please, try with a newer browser.<br>
    </p>
    

    <div id="imageChooser">
        <div id="imagesContainer">
            <p><img src="http://bigwww.epfl.ch/demo/ip/demos/icons/open_file.png">
                <span>from disk</span>
            </p>

            <p><img src="http://bigwww.epfl.ch/demo/ip/demos/icons/open_url.png">
                <span>from url</span>
            </p>
            
        </div>
        </div>

    
    

     <p id="animationBlock">Steps<br>
         <progress id="animationSteps" min="0" value="1" max="10"></progress> <span>0/5</span>
    </p>

    <div>
        

        <div title="SNR">
            <div>
                <p>SNR:</p>
                <p>0.0</p>
            </div>
        </div>

        <!-- <div class="container-item" title="save a screenshot">
            <a id="export1">
                <div id="export_container">
                    <img id="export_img" src="http://bigwww.epfl.ch/demo/ip/demos/icons/screenshot.png"/>
                </div>
            </a>
        </div>

        <div class="container-item" title="save a screenshot">
            <a id="export2">
                <div id="export_container">
                    <img id="export_img" src="http://bigwww.epfl.ch/demo/ip/demos/icons/screenshot.png"/>
                </div>
            </a>
        </div> -->
    </div>

</div><p>
	© 2018 Image Processing Online Demonstration, Biomedical Imaging Group, EPFL.
	<br>
	The Javascript/HTML5/ImageAccess library (<a href="http://bigwww.epfl.ch/publications/sage0303.html">Reference</a>) 
	was written by <b>Cyril Favre</b>, <b>Robin Lang</b>, and <a href="mailto:daniel.sage@epfl.ch">Daniel Sage</a>.
	</p></div>]]>
            </description>
            <link>http://bigwww.epfl.ch/demo/ip/demos/FFT-filtering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629172</guid>
            <pubDate>Tue, 29 Sep 2020 15:42:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Following ransomware attack, Tyler Tech advises clients to change passwords]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629164">thread link</a>) | @rhinoh
<br/>
September 29, 2020 | https://www.route-fifty.com/tech-data/2020/09/tyler-tech-ransomware-password-change-clients/168837/ | <a href="https://web.archive.org/web/*/https://www.route-fifty.com/tech-data/2020/09/tyler-tech-ransomware-password-change-clients/168837/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <div>

      <div>
        

        
          
        

        
  
    <div>
      


<div>
  
  <p>Connecting state and local government leaders</p>
</div>

    </div>
  


        
          

          
        

      </div>

      
      <div>

        <div>
          
          <p>
            
              
                
                  



  By


<span><span><a href="https://www.route-fifty.com/voices/bill-lucia/10687/?oref=rf-post-author?oref=rf-post-author">Bill Lucia</a></span></span>

                
              
            
          </p>

          
            <p><span>|</span>
          

          
            <time datetime="2020-09-28T21:09:00+00:00">
             September 28, 2020
            </time>
          
        </p></div>

        
          <h2>The company is a leading provider of software to state and local governments. So far, it says it looks like the security breach has affected only its internal computer systems. </h2>
        

        
  <ul>
    
      <li>
        <a href="https://www.route-fifty.com/topic/cybersecurity/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Cybersecurity
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/information-technology/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Information Technology
              </span>
            </span>
          </span>
        </a>
      </li>
    
  </ul>


        





        

      </div>
      

    </div>
  </div><div>
<div>

<div>
<p>Tyler Technologies, a vendor that provides software to states and localities, has advised clients to change passwords after reports of suspicious login attempts, a warning that comes as the company is dealing with a ransomware attack on its own internal network.</p><p>The company said over the weekend that it was aware&nbsp;of&nbsp;“several suspicious logins to client systems” and strongly recommended that clients reset remote network access passwords&nbsp;for Tyler staff, as well as credentials the company’s staff would use to access applications.</p><p>A statement posted on Tyler’s website says that the company learned of a cybersecurity breach to its internal systems—including phone and IT systems—last Wednesday and has since confirmed that the situation involves a ransomware attack.</p><p>The company declined to comment on Monday about how many clients reported suspicious login attempts, where those clients are located, or if any of the login attempts had succeeded and resulted in nefarious activity of any kind.</p><p>In its <a href="https://www.tylertech.com/about-us" target="_blank">online statement</a>, Tyler says that because the company’s investigation into the incident is still active it would not provide additional specifics.</p><p>But the company emphasized over the weekend that evidence so far seemed to indicate that the digital attack was directed at its own internal corporate network and phone systems, which are separate from where the company hosts software for clients.</p><p>The company says it has been in contact with the FBI about the breach.</p><p>While the situation is unfolding during the runup to the November election, Tyler has noted that it does not make election software.&nbsp;</p><p>There is heightened concern about cybersecurity around the election after&nbsp;efforts by Russia to interfere in the 2016 presidential contest.&nbsp;</p><p>But, in a statement issued Monday, the FBI and the Cybersecurity and Infrastructure Security Agency suggested that bad actors may be fanning the flames around these worries to raise doubts about the integrity of the upcoming election.</p><p>“Foreign actors and cyber criminals,” the agencies said, are spreading false and inconsistent information through online platforms in an attempt to manipulate public opinion, discredit the electoral process and undermine confidence in U.S. democratic institutions.</p><p>“These malicious actors could use these forums to also spread disinformation suggesting successful cyber operations have compromised election infrastructure and facilitated the ‘hacking’ and ‘leaking’ of U.S. voter registration data,” the agencies added.</p><p>They pointed out that a lot of U.S. voter information can be purchased or acquired through publicly available sources, and said that while “cyber actors” have in recent years obtained voter registration information this did not affect the integrity of election results.&nbsp;</p><p>“The FBI and CISA have no information suggesting any cyberattack on U.S. election infrastructure has prevented an election from occurring, compromised the accuracy of voter registration information, prevented a registered voter from casting a ballot, or compromised the integrity of any ballots cast,” the agencies also said.</p><p>The situation with Tyler is unfolding as Washington state has faced a cyberattack in recent days. State officials there <a href="https://apnews.com/article/technology-phishing-washington-jay-inslee-bf63ccf1f0e4709efc8871bb7457ef1c" target="_blank">said last week</a> that hackers were targeting the state. <a href="https://www.bloomberg.com/news/articles/2020-09-27/hackers-have-infiltrated-many-of-washington-state-s-agencies" target="_blank"><em>Bloomberg</em> reported</a> on Sunday that the attack had infected computer systems used by many state agencies.</p><p>Washington’s secretary of state’s office said in a tweet last week that it was aware of “an active cyber threat” facing government entities throughout the country, but that the office had “no reason at this time to believe this is targeted at elections.”<svg>
<use xlink:href="/static/b/base/svg/spritesheet.svg#icon-rf-shield-alt"></use>
</svg></p></div></div>
</div></div>]]>
            </description>
            <link>https://www.route-fifty.com/tech-data/2020/09/tyler-tech-ransomware-password-change-clients/168837/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629164</guid>
            <pubDate>Tue, 29 Sep 2020 15:41:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breakthrough Listen Makes the Case for a SETI Telescope on the Moon]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629161">thread link</a>) | @n0pe_p0pe
<br/>
September 29, 2020 | https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon | <a href="https://web.archive.org/web/*/https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>On Monday, a group of researchers sponsored by Breakthrough Listen, the world’s largest SETI program, </span><a href="http://seti.berkeley.edu/lunarseti/" rel="noopener noreferrer" target="_blank">submitted a paper</a><span> to National Academy of Sciences’ Planetary Science and Astrobiology Decadal Survey that makes the case for establishing a SETI radio observatory on the farside of the moon. The decadal survey establishes scientific priorities for the next ten years and the new paper addresses one of the biggest problems facing the search for extraterrestrial intelligence today: The overwhelming amount of radio interference.&nbsp;</span></p></div><div><p><span>Our planet has become so “loud” in the part of the radio spectrum observed by SETI that it threatens to drown out any signal sent from an intelligent civilization. Not only would a lunar radio telescope not have to deal with terrestrial radio interference, it could also significantly increase our chances of hearing from ET by opening up parts of the radio spectrum that are blocked by Earth's atmosphere. While the idea of using the moon for radio astronomy is decades old, the researchers make the case that technological advancements have finally made a lunar SETI observatory truly feasible.</span></p></div><div><div><p><span>
says Eric Michaud, an intern at the SETI Berkeley Research Center and the first author of the paper. “Maybe not today, but I think it’s going to get more and more feasible as time goes on.”&nbsp;</span></p></div></div><div><p><span>Radio interference has been a problem for SETI from the very beginning. In the spring of 1960, the planetary scientist Frank Drake trained the massive radio telescope at Green Bank Observatory in West Virginia on Tau Ceti and Epsilon Eridani, two stars a mere 12 light years from Earth. That summer, Drake spent his days studying the signals picked up by Green Bank’s giant mechanical ear in the hopes of receiving a message broadcast by an alien civilization orbiting those stars. Known as Project Ozma, Drake’s experiment marked the beginning of SETI, the scientific search for extraterrestrial intelligence.&nbsp;</span></p></div><div><p><span>Shortly after Drake started his observations, he was surprised to find what appeared to be a signal of intelligent origin. After days of watching a needle drift lazily over a spool of paper recording the random undulations of cosmic static, Drake and his colleagues were jolted awake when the machine started recording the frantic pulses of a strong radio signal picked up by the telescope. The timing and magnitude of the pulses clearly marked them as artificial; there was nothing in the natural world that could produce such a frenetic radio profile. It would have been an astounding stroke of luck to pick up an alien message after only a few hours of observation, but it was hard to argue with the data.&nbsp;</span></p></div><div><p><span>“None of us had ever seen anything like it,” Drake recalled in </span><em>Is Anyone Out There?</em><span>, his autobiographical book about the early days of SETI. “We looked at each other wide-eyed. Could discovery be this easy?”</span></p></div><div><div><p><span>

It was a letdown, but the false detection turned out to be a portent for the future of SETI. In the 60 years since Drake’s pioneering experiment, researchers have conducted dozens of SETI searches across thousands of stars and turned up empty-handed. At the same time, the sources of radio interference on Earth—military radars, TV towers, cell phones, and satellites—have exponentially increased, which greatly increases the chances that an extraterrestrial signal will be lost among the noise.&nbsp;</span></p></div></div><div><p><span>Earth was never a particularly great place to do any kind of radio astronomy due to our thick atmosphere blocking a large portion of the radio spectrum. The proliferation of radio communication technologies has only made things harder. The moon, by comparison, has no atmosphere and its nights last for weeks on end, which limits radio noise from the sun. And as&nbsp;NASA discovered through a spate of lunar orbiter missions in the late 1960s, the moon also acts as a natural shield that blocks radio signals emanating from Earth. As the planetary astronomer Phillipe Zarka has put it, “the farside of the moon during the lunar night is the most radio-quiet place in our local universe.” It’s exactly the sort of peace and quiet you want if you’re searching for faint radio signals from solar systems that might be hundreds of light years away.&nbsp;</span></p></div><div><p><span>The new Breakthrough Listen paper proposed two main approaches to a lunar SETI observatory: an orbiter and a telescope on the surface. The basic idea behind a SETI lunar orbiter would be to scan for signals as it passed over the lunar farside and relay data back to Earth as it passed over the near side. One of the main advantages of an orbiter is cost. The proliferation of small satellites that are capable of accurate tracking combined with low-cost small launch providers like Rocket Lab means that a SETI orbiter could conceivably be sent to the moon </span><a href="https://www.nasa.gov/press-release/nasa-awards-contract-to-launch-cubesat-to-moon-from-virginia/#:~:text=The%20firm%2Dfixed%2Dprice%20launch,Tyvak%20Nano%2DSatellite%20Systems%20Inc." rel="noopener noreferrer" target="_blank">for less than $20 million</a><span>. This would be a valuable pathfinder mission that could pave the way for a more ambitious observatory on the surface, but without the risk and cost.&nbsp; As the </span><a href="https://www.supercluster.com/editorial/the-supercluster-podcast-water-bears-might-now-occupy-the-moon" rel="noopener noreferrer" target="_blank">ill-fated Israeli Beresheet lander mission</a><span> reminded us, landing on the moon is extremely challenging even when the mission is backed by $100 million.&nbsp;</span></p></div><div><p><span>But a SETI lunar orbiter would also come with a lot of compromises. It would only be able to conduct observations during the brief stretches when it was on the lunar farside, which would make a sustained observation campaign more challenging. The upshot is that an orbiter would have access to the full sky, whereas a telescope on the surface would be constrained by the moon’s rotation. The biggest downside of an orbiter is that it might lose a lot of the shielding benefits of the moon and be more vulnerable to radio interference from Earth since it would be orbiting high above the lunar surface.&nbsp;</span></p></div><div><p><span>“The first SETI observations that are done from the lunar farside will be done from orbit, there’s no question about that,” says Andrew Siemion, the director of the Berkeley SETI Research Center and the second author on the paper. “I think eventually we absolutely want to do something on the surface because we want to build a very large aperture telescope, but even when we’re at that point I don’t think that would negate the utility of doing things from orbit as well.”&nbsp;</span></p></div><div><p><span>So what would a SETI observatory on the moon look like? One idea is to use the naturally parabolic lunar crater as a radio dish, much like the Arecibo telescope in Puerto Rico and </span><a href="https://www.supercluster.com/editorial/chinas-massive-telescope-is-the-next-great-seti-hope" rel="noopener noreferrer" target="_blank">the FAST telescope in China</a><span>, which are built into natural depressions in the land. This idea was </span><a href="https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/RS012i005p00845" rel="noopener noreferrer" target="_blank">first considered</a><span> back in the late 1970s by a group of scientists at the radio physics lab at the Stanford Research Institute. Their idea was to recreate Arecibo on the moon by suspending an antenna from the lip of a crater and using the basin as a reflector. The reduced gravity on the moon would allow for a radio telescope far larger than any on Earth, which could significantly enhance the sensitivity of SETI searches. Ultimately the researchers concluded that a lunar radio observatory was too expensive compared to SETI telescopes that could be built on Earth.&nbsp;</span></p></div><div><p><span>But 40 years later, Michaud says that building a radio dish in a lunar crater may finally be cheap enough to pull off. One of the main drivers of this cost reduction is the advent of commercial launch providers like SpaceX and Rocket Lab, which have </span><a href="https://www.supercluster.com/editorial/cheaper-rockets-growing-the-human-family-in-space" rel="noopener noreferrer" target="_blank">dramatically lowered the cost of space access</a><span>. Another driver is NASA’s push to establish a permanent human presence on the moon, which has subsidized the development of a fleet of commercial lunar exploration vehicles. “There’s so much interest in going back to the moon,” says Michaud, who cited Blue Origin’s lunar lander and Rocket Lab’s Photon Lunar satellite as examples of technologies enabled by </span><a href="https://www.supercluster.com/editorial/nasas-first-puerto-rican-born-director-aims-for-a-moonshot" rel="noopener noreferrer" target="_blank">NASA’s Artemis program</a><span>.&nbsp;</span></p></div><div><p><span>A crux of the original vision for lunar SETI observatories was that it would require a human settlement on the moon to build and operate the radio dish. But robotic systems have improved enough that it may be possible to take humans out of the equation. This was clearly demonstrated in 2019 when China’s Chang’e 4 rover landed autonomously on the farside of the moon. These advancements in autonomous navigation have laid the foundation for a lunar radio observatory that is built entirely by robots.&nbsp;</span></p></div><div><p><span>It sounds like science fiction, but earlier this year NASA’s Advanced Innovative Concepts program </span><a href="https://www.nasa.gov/directorates/spacetech/niac/2020_Phase_I_Phase_II/lunar_crater_radio_telescope/" rel="noopener noreferrer" target="_blank">awarded one of it’s prestigious grants to Saptarshi Bandyopadhyay, a researcher at the Jet Propulsion Laboratory, to figure out a way to make it happen</a><span>. His idea is to use rovers to deploy wire mesh in a crater on the lunar farside and suspend a receiver over the dish. NIAC is all about funding high risk, high reward missions, and there’s no guarantee that Bandyopadhyay’s proposal will ever come to fruition. Still, addressing the technical problems associated with building a radio receiver on the farside of the moon is an important first step.</span></p></div><div><p><span>And Bandyopadhyay isn’t the only NASA-backed researcher contemplating a lunar radio observatory. Jack Burns, a radio astronomer at the University of Colorado, has also received a grant to study a mission concept for a radio telescope array called </span><a href="https://www.colorado.edu/project/lunar-farside/dr-jack-burns" rel="noopener noreferrer" target="_blank">FARSIDE</a><span>. Instead of using a crater as a dish, FARSIDE would deploy several smaller antennas across the lunar surface that would collectively form a large radio telescope. Both NASA studies are focused on radio astronomy rather than SETI, but Siemion sees the two disciplines as natural allies in the quest to establish an observatory on the lunar farside. SETI has piggybacked on other radio astronomy projects in the past—SERENDIP, for instance, opportunistically searched for ET signals during radio observation campaigns at a variety of telescopes—and it seems plausible that a similar arrangement could be made with an observatory on the moon.&nbsp;</span></p></div><div><p><span>Siemion acknowledged that there were certain technical challenges that would arise in a collaboration on a lunar radio observatory. The biggest issue, he says, is that a lot of radio astronomy is done at frequencies that don’t really require an observatory on the moon. “Radio …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</a></em></p>]]>
            </description>
            <link>https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629161</guid>
            <pubDate>Tue, 29 Sep 2020 15:41:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Digit Decline in Infectious Disease Research During Coronavirus Pandemic]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628957">thread link</a>) | @KaiserSanchez
<br/>
September 29, 2020 | https://www.medifind.com/news/post/double-digit-decline-in-infectious-disease-research-during-coronavirus-pandemic | <a href="https://web.archive.org/web/*/https://www.medifind.com/news/post/double-digit-decline-in-infectious-disease-research-during-coronavirus-pandemic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><div>
<p>As featured on <a rel="noreferrer noopener" href="https://www.contagionlive.com/news/double-digit-decline-infectious-disease-research-coronavirus-pandemic" target="_blank">Contagion Live</a></p>



<p>As resources have been poured into the COVID-19 response, other infectious disease priorities have been displaced. Patrick Howie, CEO of a firm which aggregates useful clinical data/analysis, explains.</p>



<figure><p>
<iframe title="Double Digit Decline in Infectious Disease Research During Coronavirus Pandemic" width="500" height="281" src="https://www.youtube.com/embed/fpZbcASIbYs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<div><p><em>“The areas of research most negatively affected by COVID-19 include other infectious diseases, many types of cancer&nbsp;and neurological diseases. The impact is potentially dire in all categories, but in somewhat different ways.”&nbsp;<p>&nbsp;“Failing to make advances against infectious diseases could have&nbsp;a&nbsp;global impact in the future,&nbsp;given their ability to spread quickly&nbsp;and&nbsp;indiscriminately. Slowdowns in research here may severely limit our ability to counteract outbreaks of&nbsp;both&nbsp;known infectious diseases and novel ones, given the fact that learnings are often relevant across different vectors of disease.&nbsp;</p></em></p><p><em>“Unfortunately, the way our medical research system is structured means there are limited resources, and thus clear winners and losers in the face of crisis. Progress against COVID-19 comes at the expense of many other important diseases, with implications that could last years. A researcher&nbsp;diverting&nbsp;their focus to COVID-19 may have a difficult time regaining funding, employees and resources when the time comes. Patients who were candidates for a clinical trial that was delayed due to&nbsp;the pandemic may&nbsp;have pursued&nbsp;other options that&nbsp;could&nbsp;later disqualify&nbsp;them, or&nbsp;faced even more dire consequences of these delays. With clinical trials unable to proceed as normal, and recruitment and retention becoming problematic, the delays in new research may be far-reaching and long-lasting.&nbsp;<br>&nbsp;</em><br><em>“COVID-19 was an unprecedented challenge and call-to-arms for the global medical research community. The speed and size of the response has been stunning, serving as evidence of our ability to scale up global collaboration in record time, across borders and boundaries. The response stands as a&nbsp;monument to the work we&nbsp;can&nbsp;do together when necessary. This reality offers hope not only for future pandemics, but also points to possibilities for more purposeful and progressive collaboration in the thousands of other diseases that rely on continued research. Disease isn’t limited by geopolitical boundaries, and our response can’t be either.&nbsp;&nbsp;<p>&nbsp;“COVID-19 has also put a new spotlight on the numerous issues in the healthcare system, including technological barriers like limited data interoperability. It’s become clear that no single&nbsp;person&nbsp;(or even group) can conduct research on the scale required for&nbsp;a&nbsp;challenge&nbsp;like&nbsp;COVID-19. To succeed, we desperately need to accelerate our ability to use tools like artificial intelligence and machine learning to amplify human effort.&nbsp;&nbsp;</p></em><br><em>“COVID-19, like SARS and MERS before it,&nbsp;has&nbsp;naturally relied heavily on the talents of infectious disease specialists. In all cases, these experts had to divert their attention, time, energy and perhaps even funding, given that they were best equipped to tackle these new threats. What’s different about COVID-19 is the scale of the impact. COVID-19 has impacted the entire world in dramatic numbers, leaving no country unscathed. The scale of increase in coronavirus research, and the related scale of decrease in all other research, is novel.”&nbsp;</em></p></div>
</div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.medifind.com/news/post/double-digit-decline-in-infectious-disease-research-during-coronavirus-pandemic</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628957</guid>
            <pubDate>Tue, 29 Sep 2020 15:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula Webinar: Managing your Kubernetes clusters with Rancher]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628837">thread link</a>) | @amarti
<br/>
September 29, 2020 | https://us02web.zoom.us/webinar/register/7916013795590/WN_3l49ozQMSgGGyY83RmsVHQ | <a href="https://web.archive.org/web/*/https://us02web.zoom.us/webinar/register/7916013795590/WN_3l49ozQMSgGGyY83RmsVHQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><label for="timezone">Time Zone:</label>&nbsp;&nbsp;

</p>
</div>
</div></div>]]>
            </description>
            <link>https://us02web.zoom.us/webinar/register/7916013795590/WN_3l49ozQMSgGGyY83RmsVHQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628837</guid>
            <pubDate>Tue, 29 Sep 2020 15:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graph Databases: TerminusDB vs. Neo4j]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628809">thread link</a>) | @vivek9209
<br/>
September 29, 2020 | https://terminusdb.com/blog/2020/09/24/graph-databases-terminusdb-vs-neo4j/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/09/24/graph-databases-terminusdb-vs-neo4j/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          <p>Are Graph Databases the future?  Structured and unstructured data coming from multiple sources can have immense value if you can find the relationships within it, Graph databases consider the relationships between data as first class citizens.</p>

<p>Inter-connected data are the future, and probably the easiest way to model interconnected data is using a Graph Database.</p>

<p>In this tutorial will see two different way to model and query data using native graph database technology - TerminusDB and Neo4j.</p>

<p>if you have never used TerminusDB before, this article includes everything you need to get started with TerminusDB.
<a href="https://terminusdb.com/2020/01/14/my-first-terminusdb-graph-visualisation-bike-share-data/">My First TerminusDB Graph Visualisation — Bike Share Data</a>.</p>

<p>Now let’s see how TerminusDB handles tasks compared to Neo4j in practice.</p>

<h2 id="graph-database-main-concepts">Graph Database Main Concepts</h2>

<p>Graph databases  are databases that use graph structures to organize data: nodes, edges (relationship), and properties to represent and store data. The relationships allow data in the store to be linked together.</p>

<h4 id="neo4j-main-concepts">Neo4J Main Concepts</h4>

<ul>
  <li>Node</li>
  <li>Label (:Person)</li>
  <li>Relationship :KNOWS</li>
  <li>Property {name}</li>
</ul>

<p><img src="https://terminusdb.com/blog/assets/images/neo4j-graph-know.png" alt=""></p>

<p>In Neo4j the main components of the property graph model are nodes and relationships, in our example, <strong>Maria</strong>, <strong>Anna</strong>, <strong>Tom</strong> and <strong>Jim</strong> are our nodes and <strong>KNOWS</strong> is our relationship between nodes.</p>

<p>Nodes and Relationships can have properties, properties are name-value pairs that provide additional details for nodes and relationships. You can group similar nodes together by assigning a node label (:Person). A node can have zero to many labels.</p>

<h4 id="terminusdb">TerminusDB</h4>

<ul>
  <li>OrdinaryClass</li>
  <li>DocumentClass (doc:Person)</li>
  <li>ObjectProperty (knows:doc:Person)</li>
  <li>DatatypeProperty (name:String)</li>
</ul>

<p><img src="https://terminusdb.com/blog/assets/images/terminusdb-graph-knows.png" alt=""></p>

<p>In TerminusDB everything is an object of a Class - objects can have properties and some of these properties may link to other objects. Document Classes are top-level classes, which allow the graph to be serialized into documents.  Our example <strong>Maria</strong>, <strong>Anna</strong>, <strong>Tom</strong>, and <strong>Jim</strong> are our Document Objects. The <strong>knows</strong> property is an ObjectProperty with range being the <strong>Person</strong> document.</p>

<p>Classes can be subclasses of other classes, which means that they inherit all the parent’s properties (much like inheritance in object-oriented programming). Multiple inheritance is supported.</p>

<p>The type of data that the property points to can either be a simple datatype literal (e.g. an integer or string) (DatatypeProperty) or it can be a class (ObjectProperty).</p>

<h2 id="query-language">Query language</h2>

<p>Neo4j uses <strong>Cypher</strong> to store and retrieve data from the graph database. Cypher is 
a graph query language and the best way to interact with Neo4j.</p>

<p>TerminusDB uses <a href="https://terminusdb.com/docs/woql"><strong>WOQL</strong> (Web Object Query Language)</a> which allows queries to be written in either javascript, python or as JSON-LD documents. All these examples are written using woql.js a javascript layer that allows queries to be written in simple javascript.</p>

<h2 id="schema">Schema</h2>

<p>A schema in Neo4j refers to indexes and constraints that can be applied to nodes. Neo4j is often described as schema optional, meaning that it is not necessary to create indexes and constraints. Index and Constraint can be added at any time.</p>

<p><em>In our example we create the constraint <strong>person_unique</strong>, it specifies that the properties <strong>name</strong> and <strong>born</strong> have to exist on all nodes with label <strong>Person</strong> and the combination of the property values is unique.</em></p>

<div><div><pre><code><span>CREATE</span> <span>CONSTRAINT</span> <span>person_unique</span>
<span>ON</span> <span>(</span><span>n</span><span>:</span><span>Person</span><span>)</span> <span>ASSERT</span> <span>(</span><span>n</span><span>.</span><span>name</span><span>,</span> <span>n</span><span>.</span><span>born</span><span>)</span> <span>IS</span> <span>NODE</span> <span>KEY</span>
</code></pre></div></div>

<p>TerminusDB is schema optional, but to take advantage of schema checking, it is better to create a schema before inserting data. TerminusDB lets you change your schema at any time. 
TerminusDB is a graph database that stores data like Git. <strong>TerminusDB allows for the whole suite of revision control features: branch, merge, squash, rollback, blame, and time-travel.</strong></p>

<p><a href="https://terminusdb.com/docs/quickstart/"><strong>If you want to read more …</strong></a></p>

<div><div><pre><code><span>WOQL</span><span>.</span><span>doctype</span><span>(</span><span>"</span><span>Person</span><span>"</span><span>)</span>            
  <span>.</span><span>label</span><span>(</span><span>"</span><span>Person Name</span><span>"</span><span>)</span>            
  <span>.</span><span>description</span><span>(</span><span>"</span><span>A Person Document</span><span>"</span><span>)</span>
	<span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>string</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Name</span><span>"</span><span>).</span><span>cardinality</span><span>(</span><span>1</span><span>)</span>
	<span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>"</span><span>date</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Date Of Birth</span><span>"</span><span>).</span><span>cardinality</span><span>(</span><span>1</span><span>)</span>
	<span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Knows</span><span>"</span><span>)</span>
</code></pre></div></div>

<p>Using the WOQL.js api, we create the <strong>Person</strong> Document class. This object has 3 properties, with three different types. The data type range in <strong>knows</strong> property (ObjectProperty) is the <strong>Person</strong> document class. The cardinality 1 for <em>name</em> and <em>date_of_birth</em> specifies that both property values have a single value.</p>

<h2 id="insert-data">Insert Data</h2>

<p>Here is an example of Cypress syntax for inserting data</p>

<p>We add 4 nodes of type (label) <strong>Person</strong> and relationships <strong>KNOWS</strong> between the nodes.</p>

<div><div><pre><code>
<span>CREATE</span> <span>(</span><span>maria</span><span>:</span><span>Person</span> <span>{</span> <span>name</span><span>:</span><span>"Maria"</span><span>,</span><span>born</span><span>:</span><span>date</span><span>(</span><span>'1978-12-03'</span><span>)</span><span>}</span><span>)</span>
<span>CREATE</span> <span>(</span><span>anna</span><span>:</span><span>Person</span> <span>{</span> <span>name</span><span>:</span><span>"Anna"</span><span>,</span><span>born</span><span>:</span><span>date</span><span>(</span><span>'1974-02-10'</span><span>)</span><span>}</span><span>)</span>
<span>CREATE</span> <span>(</span><span>tom</span><span>:</span><span>Person</span> <span>{</span> <span>name</span><span>:</span><span>"Tom"</span><span>,</span><span>born</span><span>:</span><span>date</span><span>(</span><span>'1975-06-23'</span><span>)</span><span>}</span><span>)</span>
<span>CREATE</span> <span>(</span><span>jim</span><span>:</span><span>Person</span> <span>{</span> <span>name</span><span>:</span><span>"Jim"</span><span>,</span><span>born</span><span>:</span><span>date</span><span>(</span><span>'1974-07-20'</span><span>)</span><span>}</span><span>)</span>

<span>MERGE</span> <span>(</span><span>maria</span><span>)</span><span>-</span><span>[</span><span>r</span><span>:</span><span>KNOWS</span> <span>{</span> <span>label</span><span>:</span> <span>maria</span><span>.</span><span>name</span> <span>+</span> <span>' knows '</span> <span>+</span> <span>anna</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>anna</span><span>)</span>
<span>MERGE</span> <span>(</span><span>anna</span><span>)</span><span>-</span><span>[</span><span>r01</span><span>:</span><span>KNOWS</span> <span>{</span> <span>label</span><span>:</span> <span>anna</span><span>.</span><span>name</span> <span>+</span> <span>' knows '</span> <span>+</span> <span>tom</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>tom</span><span>)</span>
<span>MERGE</span> <span>(</span><span>tom</span><span>)</span><span>-</span><span>[</span><span>r02</span><span>:</span><span>KNOWS</span> <span>{</span> <span>label</span><span>:</span> <span>tom</span><span>.</span><span>name</span> <span>+</span> <span>' knows '</span> <span>+</span> <span>maria</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>maria</span><span>)</span>
<span>MERGE</span> <span>(</span><span>tom</span><span>)</span><span>-</span><span>[</span><span>r03</span><span>:</span><span>KNOWS</span> <span>{</span> <span>label</span><span>:</span> <span>tom</span><span>.</span><span>name</span> <span>+</span> <span>' knows '</span> <span>+</span> <span>jim</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>jim</span><span>)</span>

<span>RETURN</span> <span>maria</span><span>.</span><span>name</span><span>,</span> <span>anna</span><span>.</span><span>name</span><span>,</span> <span>tom</span><span>.</span><span>name</span><span>,</span> <span>jim</span><span>.</span><span>name</span>

</code></pre></div></div>

<p>Let’s see how we add documents and relationships with TerminusDB - queries are accessible in a very easy way with JavaScript using the woql.js layer.</p>

<p>We create <strong>Person</strong> documents and we link them using the <strong>“knows”</strong> property in <strong>Person</strong> document. Our relationships between documents have been created.</p>

<div><div><pre><code><span>and</span><span>(</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Person</span><span>"</span><span>,[</span><span>"</span><span>Maria</span><span>"</span><span>,</span><span>"</span><span>1978-12-03</span><span>"</span><span>],</span><span>"</span><span>v:Maria</span><span>"</span><span>),</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Person</span><span>"</span><span>,[</span><span>"</span><span>Anna</span><span>"</span><span>,</span><span>"</span><span>1974-02-10</span><span>"</span><span>],</span><span>"</span><span>v:Anna</span><span>"</span><span>),</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Person</span><span>"</span><span>,[</span><span>"</span><span>Tom</span><span>"</span><span>,</span><span>"</span><span>1975-06-23</span><span>"</span><span>],</span><span>"</span><span>v:Tom</span><span>"</span><span>),</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Person</span><span>"</span><span>,[</span><span>"</span><span>Jim</span><span>"</span><span>,</span><span>"</span><span>1974-07-20</span><span>"</span><span>],</span><span>"</span><span>v:Jim</span><span>"</span><span>),</span>
 	
  <span>insert</span><span>(</span><span>"</span><span>v:Maria</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Maria</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1978-12-03</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>))</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Maria</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>v:Anna</span><span>"</span><span>),</span>

  <span>insert</span><span>(</span><span>"</span><span>v:Anna</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Anna</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1974-02-10</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>))</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Anna</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>v:Tom</span><span>"</span><span>),</span>

  <span>insert</span><span>(</span><span>"</span><span>v:Tom</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Tom</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1975-06-23</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>))</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Tom</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>v:Maria</span><span>"</span><span>),</span>

  <span>insert</span><span>(</span><span>"</span><span>v:Jim</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Jim</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1974-07-20</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>))</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Jim</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>v:Tom</span><span>"</span><span>)</span>
<span>)</span>
</code></pre></div></div>

<h2 id="add-a-new-node-type-and-relationship">Add a new node type and relationship</h2>

<p>In Neo4j we add a node with the label <strong>City</strong>, a new constaint and we connect our nodes <strong>Person</strong> and <strong>City</strong> with <strong>CITY_OF_BIRTH</strong> relationship</p>

<div><div><pre><code><span>CREATE</span><span>(</span><span>dublin</span><span>:</span><span>City</span> <span>{</span> <span>name</span><span>:</span><span>"Dublin"</span><span>}</span><span>)</span>

<span>CREATE</span> <span>CONSTRAINT</span> <span>city_name</span> <span>ON</span> <span>(</span><span>city</span><span>:</span><span>City</span><span>)</span> <span>ASSERT</span> <span>city</span><span>.</span><span>name</span> <span>IS</span> <span>UNIQUE</span>

<span>MATCH</span> <span>(</span><span>a</span><span>:</span><span>Person</span><span>),(</span><span>b</span><span>:</span><span>City</span><span>)</span>
<span>WHERE</span> <span>b</span><span>.</span><span>name</span> <span>=</span> <span>'Dublin'</span>
<span>MERGE</span> <span>(</span><span>a</span><span>)</span><span>-</span><span>[</span><span>r</span><span>:</span><span>CITY_OF_BIRTH</span> <span>{</span> <span>label</span><span>:</span> <span>a</span><span>.</span><span>name</span> <span>+</span> <span>' born in '</span> <span>+</span> <span>b</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>b</span><span>)</span>
<span>RETURN</span> <span>type</span><span>(</span><span>r</span><span>),</span> <span>r</span><span>.</span><span>label</span>

</code></pre></div></div>

<p>In TerminusDB we create a new Document Object <strong>City</strong></p>

<div><div><pre><code><span>WOQL</span><span>.</span><span>doctype</span><span>(</span><span>"</span><span>City</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>City Name</span><span>"</span><span>).</span><span>description</span><span>(</span><span>"</span><span>A City name</span><span>"</span><span>)</span>
</code></pre></div></div>

<p>We add a new property <strong>city_of_birth</strong> in the Document <strong>Person</strong> with range type <strong>City</strong>.
Here our relationship between <strong>Person</strong>-&gt;<strong>City</strong></p>

<div><div><pre><code><span>add_property</span><span>(</span><span>"</span><span>city_of_birth</span><span>"</span><span>,</span><span>"</span><span>City</span><span>"</span><span>).</span><span>domain</span><span>(</span><span>"</span><span>Person</span><span>"</span><span>)</span>
</code></pre></div></div>

<p>Now update the data!!</p>

<div><div><pre><code><span>and</span><span>(</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:City</span><span>"</span><span>,[</span><span>"</span><span>Dublin</span><span>"</span><span>],</span><span>"</span><span>v:City_id</span><span>"</span><span>),</span>
  <span>insert</span><span>(</span><span>"</span><span>v:City_id</span><span>"</span><span>,</span> <span>"</span><span>City</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Dublin</span><span>"</span><span>),</span>
  <span>triple</span><span>(</span><span>'</span><span>v:Person</span><span>'</span><span>,</span><span>'</span><span>type</span><span>'</span><span>,</span><span>'</span><span>scm:Person</span><span>'</span><span>),</span>
  <span>add_triple</span><span>(</span><span>"</span><span>v:Person</span><span>"</span><span>,</span><span>"</span><span>city_of_birth</span><span>"</span><span>,</span><span>"</span><span>v:City_id</span><span>"</span><span>)</span>
<span>)</span>

</code></pre></div></div>

<h2 id="creating-hierarchies">Creating hierarchies</h2>

<p>In our graph we now add another type of Person called Doctor, this entity has all the Person properties plus it is connected to the other nodes by the <strong>patient</strong> relationship</p>

<p>In Neo4j we can add multi labels to a node so our node is Person and Doctor at the same time.</p>

<div><div><pre><code>
<span>create</span> <span>(</span><span>freud</span><span>:</span><span>Person</span><span>:</span><span>Doctor</span> <span>{</span><span>name</span><span>:</span><span>'Freud'</span><span>,</span> <span>born</span><span>:</span><span>'1976-08-25'</span><span>}</span><span>)</span>

<span>MATCH</span> <span>(</span><span>a</span><span>:</span><span>Person</span><span>),(</span><span>b</span><span>:</span><span>Doctor</span><span>)</span>
<span>WHERE</span> <span>a</span><span>.</span><span>name</span> <span>=</span> <span>'Maria'</span> <span>AND</span> <span>b</span><span>.</span><span>name</span><span>=</span><span>"Freud"</span>
<span>MERGE</span> <span>(</span><span>a</span><span>)</span><span>-</span><span>[</span><span>r</span><span>:</span><span>IS_PATIENT_OF</span> <span>{</span> <span>label</span><span>:</span> <span>a</span><span>.</span><span>name</span> <span>+</span> <span>' is patient of '</span> <span>+</span> <span>b</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>b</span><span>)</span>
<span>RETURN</span> <span>type</span><span>(</span><span>r</span><span>),</span> <span>r</span><span>.</span><span>label</span>

<span>MATCH</span> <span>(</span><span>a</span><span>:</span><span>Person</span><span>),(</span><span>b</span><span>:</span><span>Doctor</span><span>)</span>
<span>WHERE</span> <span>a</span><span>.</span><span>name</span> <span>=</span> <span>'Tom'</span> <span>AND</span> <span>b</span><span>.</span><span>name</span><span>=</span><span>"Freud"</span>
<span>MERGE</span> <span>(</span><span>a</span><span>)</span><span>-</span><span>[</span><span>r</span><span>:</span><span>IS_PATIENT_OF</span> <span>{</span> <span>label</span><span>:</span> <span>a</span><span>.</span><span>name</span> <span>+</span> <span>' is patient of '</span> <span>+</span> <span>b</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>b</span><span>)</span>
<span>RETURN</span> <span>type</span><span>(</span><span>r</span><span>),</span> <span>r</span><span>.</span><span>label</span>

</code></pre></div></div>

<p>In TerminusDB classes can be subclasses of other classes, so let’s add a subclass for <strong>scm:Person</strong> called <strong>scm:Doctor</strong>.</p>

<p>A Doctor shares all of the properties available to a Person, but it also has a <strong>patient</strong> (ObjectProperty).</p>

<div><div><pre><code>
<span>WOQL</span><span>.</span><span>doctype</span><span>(</span><span>"</span><span>Doctor</span><span>"</span><span>)</span>
  <span>.</span><span>parent</span><span>(</span><span>"</span><span>Person</span><span>"</span><span>)</span>
  <span>.</span><span>label</span><span>(</span><span>"</span><span>Doctor</span><span>"</span><span>)</span>
  <span>.</span><span>description</span><span>(</span><span>"</span><span>A Doctor is a person with patients</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>patient</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>)</span>

<span>WOQL</span><span>.</span><span>and</span><span>(</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Doctor</span><span>"</span><span>,[</span><span>"</span><span>Freud</span><span>"</span><span>,</span><span>"</span><span>1976-08-25</span><span>"</span><span>],</span><span>"</span><span>v:Freud</span><span>"</span><span>),</span>
  <span>insert</span><span>(</span><span>"</span><span>v:Freud</span><span>"</span><span>,</span> <span>"</span><span>Doctor</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Freud</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1976-08-25</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>})</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Freud</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>patient</span><span>"</span><span>,</span><span>"</span><span>doc:Person_Maria_1978-12-03</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>patient</span><span>"</span><span>,</span><span>"</span><span>doc:Person_Tom_1975-06-23</span><span>"</span><span>)</span>
       	
<span>)</span>

</code></pre></div></div>

<h2 id="query-the-data">Query the Data</h2>

<p>Now, how we write our query for getting how the <strong>Person</strong> <strong>knows</strong> each others</p>

<p>Here an Cypher example</p>

<div><div><pre><code>
<span>MATCH</span> <span>(</span><span>person</span><span>:</span><span>Person</span><span>)</span><span>-</span><span>[:</span><span>KNOWS</span><span>]</span><span>-</span><span>(</span><span>otherPerson</span><span>:</span><span>Person</span><span>)</span>
<span>RETURN</span> <span>person</span><span>.</span><span>name</span><span>,</span><span>otherPerson</span><span>.</span><span>name</span>

</code></pre></div></div>

<p>Let’s see the TerminusDB WOQL query using woql.js</p>

<div><div><pre><code>
<span>or</span><span>(</span><span>triple</span><span>(</span><span>'</span><span>v:Person</span><span>'</span><span>,</span> <span>'</span><span>knows</span><span>'</span><span>,</span> <span>'</span><span>v:OtherPerson</span><span>'</span><span>),</span>
   <span>triple</span><span>(</span><span>'</span><span>v:OtherPerson</span><span>'</span><span>,</span><span>'</span><span>knows</span><span>'</span><span>,</span><span>'</span><span>v:Person</span><span>'</span><span>)</span>
<span>)</span>

</code></pre></div></div>

<p>How do we get only people who knows each other and are patients of the doctor <strong>Freud</strong> ?</p>

<p>Neo4j Cypher query example</p>

<p><img src="https://terminusdb.com/blog/assets/images/neo4j-graph-knows-doc.png" alt=""></p>

<div><div><pre><code>
<span>MATCH</span> <span>(</span><span>doc</span><span>:</span><span>Doctor</span> <span>{</span> <span>name</span><span>:</span> <span>'Freud'</span> <span>}</span><span>)</span><span>&lt;-</span><span>[:</span><span>IS_PATIENT_OF</span><span>]</span><span>-</span><span>(</span><span>person</span><span>:</span><span>Person</span><span>),</span>
      <span>(</span><span>doc</span><span>:</span><span>Doctor</span> <span>{</span> <span>name</span><span>:</span> <span>'Freud'</span> <span>}</span><span>)</span><span>&lt;-</span><span>[:</span><span>IS_PATIENT_OF</span><span>]</span><span>-</span><span>(</span><span>otherPerson</span><span>:</span><span>Person</span><span>)</span>
<span>WHERE</span> <span>(</span><span>person</span><span>:</span><span>Person</span><span>)</span><span>-</span><span>[:</span><span>KNOWS</span><span>]</span><span>-</span><span>(</span><span>otherPerson</span><span>:</span><span>Person</span><span>)</span>
<span>RETURN</span> <span>person</span><span>.</span><span>name</span>

</code></pre></div></div>

<p>TerminusDB query example</p>

<p><img src="https://terminusdb.com/blog/assets/images/terminusdb-graph-know-doc.png" alt=""></p>

<div><div><pre><code><span>and</span><span>(</span>
  <span>triple</span><span>(</span><span>'</span><span>v:Person</span><span>'</span><span>,</span> <span>'</span><span>knows</span><span>'</span><span>,</span> <span>'</span><span>v:OtherPerson</span><span>'</span><span>),</span>
  <span>triple</span><span>(</span><span>"</span><span>v:Doc</span><span>"</span><span>,</span><span>'</span><span>patient</span><span>'</span><span>,</span><span>'</span><span>v:Person</span><span>'</span><span>),</span>
  <span>triple</span><span>(</span><span>"</span><span>v:Doc</span><span>"</span><span>,</span><span>'</span><span>patient</span><span>'</span><span>,</span><span>'</span><span>v:OtherPerson</span><span>'</span><span>),</span>
  <span>triple</span><span>(</span><span>"</span><span>v:Doc</span><span>"</span><span>,</span><span>'</span><span>name</span><span>'</span><span>,</span><span>'</span><span>v:Freud</span><span>'</span><span>)</span>
<span>)</span>

</code></pre></div></div>

<p>Let’s jump into another interesting tutorial and continue to build
<a href="https://terminusdb.com/blog/2020/07/27/taking-terminusdb-to-the-bank/">Bank Tutorial</a></p>


        </div>

        



      </div>
    </div></div>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/09/24/graph-databases-terminusdb-vs-neo4j/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628809</guid>
            <pubDate>Tue, 29 Sep 2020 15:15:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deprecate WebSockets: GraphQL Subscriptions Using SSE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628801">thread link</a>) | @ChrisArchitect
<br/>
September 29, 2020 | https://wundergraph.com/blog/deprecate_graphql_subscriptions_over_websockets | <a href="https://web.archive.org/web/*/https://wundergraph.com/blog/deprecate_graphql_subscriptions_over_websockets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>WebSockets are an outdated technology deemed dead thanks to the ietf not adding HTTP/2 support. Using Server Sent Events, we could simplify the implementation of GraphQL Subscriptions, reduce frontend code and increase performance as well as flexibility when writing modern frontend applications.</p><p>GraphQL subscriptions are a mechanism to stream updates from the GraphQL server to the GraphQL client. You can use subscriptions e.g to automatically update the UI once there's a new message available in a chat room. Here's an example Operation:</p><div><div><div tabindex="0"><div><p><span>subscription Chat </span><span>{</span><span></span></p><p><span>  messages</span><span>(</span><span>room</span><span>:</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    message </span><span>{</span><span></span></p><p><span>      id</span></p><p><span>      author</span></p><p><span>      text</span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>In order to stream messages from the server to the client, there needs to be a persisted connection between the two. The most used transport for GraphQL Subscriptions is using WebSockets based on the <a href="https://github.com/apollographql/subscriptions-transport-ws/blob/master/PROTOCOL.md" target="_blank" rel="noopener noreferrer">GraphQL over WebSockets Protocol</a> by Apollo.</p><p>I'd like to discuss various aspects of this approach and why I think we should deprecate it in favour of technology that is a much better fit, Server-Sent Events (SSE).</p><p>To initiate the protocol it's not enough to just open a WebSocket connection. The client needs to send a "connection init" message to which the server needs to respond with "ack". WebSockets operate over TCP so it's not obvious to me why you would need to ack receiving a message.</p><p>Once the initial message is acknowledged the client needs to send a GraphQL operation alongside the ID of the operation. Both the client and the server have to remember the ID of each individual Operation because all Operations/Subscriptions get multiplexed over a single WebSocket connection. This makes the implementation of both server and client overly complex. We will see how SSE will improve this because it takes care of the multiplexing for us.</p><p>If the client decides to unsubscribe a subscription it needs to send a "stop" message over the WebSocket connection. This gets once again acknowledged by the server sending a "done" message. Again, as this is still using TCP I'm not sure why this is required.</p><p>Multiplexing in terms of GraphQL means that multiple Subscriptions use the same connection. In case of the implementation over WebSockets multiplexing is implemented using Javascript. This code needs to be written and maintained. It needs to be transpiled and then must run in each and every browser. Ideally, we can remove as much code as possible to simplify development and keep the Javascript running in the browser as little as possible.</p><p>The Browser API to use Server-Sent Events is named EventSource. While WebSockets allow bidirectional communication, Server-Sent Events, as the name indicates only allow the server to stream events to the client and not in both directions. Luckily, we don't have to stream messages from the client to the server to implement GraphQL subscriptions. We simply open one EventSource for each Subscription. This simplifies both the client as well as the server implementation. There's no more custom code required to remember operations and their ID's to associate a message with the right Subscription. Multiplexing is done by the client &amp; server automatically.</p><p>The ietf decided to not add WebSocket support over HTTP/2. This means that for each WebSocket connection, the browser has to open a new TCP connection to the server because the initial Handshake is based on HTTP/1.1. Depending on the browser your users are using the number of allowed TCP connections per host varies between 2 and 8 averaging at around 5. Keep in mind that a user might open multiple tabs with the same website so you should try keeping open connections at a minimum.</p><p>With Server-Sent Events this is a different story. Server-Sent Events, when used with HTTP/2 multiplex automatically over a single TCP Connection. This means you can open more than 100 EventSources to the same host across multiple tabs and would still only use one single TCP connection.</p><p>These days, component-based single page applications get more and more popular. Frameworks like React, Vue, Flutter etc. all have some concept of Components that take data and render it.</p><p>Using a persisted WebSocket connection means we have to use dependency injection to make this connection available to all components.</p><p>With the EventSource API on the other hand we can simplify the code required to implement Subscriptions. Here's an example using React's Hooks API:</p><div><div><div tabindex="0"><div><p><span>const</span><span> </span><span>SubscriptionComponent</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> </span><span>[</span><span>data</span><span>,</span><span>setData</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>const</span><span> source </span><span>=</span><span> </span><span>new</span><span> </span><span>EventSource</span><span>(</span><span>"https://example.com/persisted/FooSubscription"</span><span>)</span><span>;</span><span></span></p><p><span>        source</span><span>.</span><span>onmessage</span><span> </span><span>=</span><span> </span><span>e</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>            </span><span>setData</span><span>(</span><span>e</span><span>.</span><span>data</span><span>)</span><span>;</span><span></span></p><p><span>        </span><span>}</span><span></span></p><p><span>        </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>            source</span><span>.</span><span>close</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>        </span><span>}</span><span></span></p><p><span>    </span><span>}</span><span>,</span><span>[</span><span>]</span><span>)</span><span></span></p><p><span>    </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>        </span><span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>data</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span></span></p><p><span>    </span><span>)</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>The implementation is rather simple. Once the component get's mounted we start the EventSource. New messages get pushed into setState() to trigger re-rendering the component. The <code>return () =&gt; </code> function at the end of useEffect can be used to clean up the EventSource to avoid memory leaks. No additional library is required to implement multiplexing.</p><p>What looks simple on the client is even simpler on the server. In comparison to WebSockets, Server-Sent Events can be implemented without any additional dependencies. Have a look at this <a href="https://gist.github.com/ismasan/3fb75381cd2deb6bfa9c" target="_blank" rel="noopener noreferrer">Example</a> written in Golang to see how simple the implementation is.</p><p>With all the positive aspects what might hold you back from adopting this?</p><h2>Internet Explorer</h2><p>First of all, the EventSource API is supported by 93.8% by all Browsers. The WebSocket API, on the other hand, is supported by 97.41%. That is because IE does not support the SSE API. Is this a blocker? No, but it contradicts with the idea of reducing complexity. If you want to support IE you have to add a polyfill for the missing API.</p><h2>HTTP/2</h2><p>The EventSource API makes a lot of sense when used together with HTTP/2 because only then you can multiplex all Subscriptions over a single TCP connection. So, if your server or clients don't support HTTP/2 you're in trouble. If you're not sure if your clients can use HTTP/2 you might want to stick with WebSockets.</p><h2>URL length limitations</h2><p>The non-polyfill Browser API to initiate an EventSource doesn't allow you to send a payload. That is, you have to send the Operation as well as the variables in the query string of the URL. Due to URL length limitations, you might not be able to send the Operation in its original format. This problem is best addressed using persisted queries. I've written another article on persisted queries if you want to get more details about the concept.</p><h2>Summary</h2><p>Server-Sent Events and the EventSource Browser API simplify both the client as well as the server implementation a lot. We can reduce the amount of code and are able to improve performance with HTTP/2 while reducing resource consumption because we're running less Javascript code.</p><p>At the same time, we're forced to use Persisted Queries and need to migrate from our WebSocket implementation to SSE, don't we? Not really, this is where WunderGraph comes into the picture.</p><p>We have done the migration already. WunderGraph takes your GraphQL Server with the WebSocket implementation and turns all Subscriptions into Server-Sent Events on the fly.</p><p>We also take care of persisting all GraphQL Operations for you and generate a client for any frontend framework you'd like to use.</p><p>This means you get all the benefits of SSE without any additional work to be done.</p><p>As a side effect your GraphQL server becomes a lot more secure because it's not directly exposed anymore to the public. It's hidden behind WunderGraph which only allows the persisted you previously registered.</p><h2>There's one more thing..</h2><p>Did you know that the Query Planner of WunderGraph allows you to join Subscriptions with other data sources?</p><div><div><div tabindex="0"><div><p><span>subscription RocketStatus </span><span>{</span><span></span></p><p><span>  rocketStatus </span><span>{</span><span></span></p><p><span>    speed</span></p><p><span>    altitude</span></p><p><span>    aboveCountryCode</span></p><p><span>    country </span><span>{</span><span></span></p><p><span>      name</span></p><p><span>      capital</span></p><p><span>      currency</span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>This feature allows you to join any type of different data sources together with very little configuration.</p><p>For the future we're planning to add support for GraphQL Federation. This means you will be able to have Subscriptions and many more features for your federated GraphQL implementations thanks to the WunderGraph Query Planner and Execution Engine.</p><p>If you're interested in this functionality, leave your email in the chat so we can inform you once we have implemented it.</p></section></div>]]>
            </description>
            <link>https://wundergraph.com/blog/deprecate_graphql_subscriptions_over_websockets</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628801</guid>
            <pubDate>Tue, 29 Sep 2020 15:15:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I regained control when my startup dream was crashing down]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628760">thread link</a>) | @robertorodes
<br/>
September 29, 2020 | https://freegrowth.co/blog/regain-control/ | <a href="https://web.archive.org/web/*/https://freegrowth.co/blog/regain-control/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#FFFFFF" data-fg="#f44813" data-width="5" data-mute="1" data-fgopacity="0.5" data-mutedopacity="0.5" data-placement="top" data-placement-offset="0" data-content-offset="0" data-placement-touch="top" data-placement-offset-touch="0" data-transparent="" data-touch="1" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#f44813" data-rtl="">
<p><em>“I feel useless. This is not our place.”</em></p>



<p>It all came out of my mouth while working with my brother.</p>



<p>That was a feeling we both had been sharing for long. This time I just said it out loud.</p>



<p>After having failed twice with our previous startups, we were trying one more time.&nbsp;</p>



<p>However, after looking for success for more than six years, this one looked like our last chance.</p>



<p>Little was the energy and money that remained on us. We were on the ropes.</p>



<p>One more time, we were desperately trying to come up with a new business idea out of thin air. And again, we’d just hit a wall. </p>



<p>The pieces were falling down.</p>



<p>It felt like we were always running in circles.&nbsp;</p>



<p>After all the energy and effort, nothing seemed to work. We felt we’d grown a lot. We’d learned many valuable skills. Yet, nothing appeared to make a difference.</p>



<p>And as if that wasn’t enough, we felt tremendously undervalued by people in our environment.</p>



<p>It was devastating.</p>



<p>“We need to move forward once and for all.” —that was the recurring thought for long.&nbsp;</p>



<p>Nonetheless, this time we’d reached a breaking point.</p>



<p>We’d always relied on the standard advice.&nbsp;</p>



<p>We followed Lean Startup, made customer discovery, interviewed people, did surveys, performed market experiments, and built MVPs.</p>



<p>We designed landing pages, run Facebook Ads campaigns, and used many of the usual tools and tactics.&nbsp;</p>



<p>We tried everything.&nbsp;</p>



<p>And still, nothing worked.</p>



<p>After lots of research and conversations, I’m sure this is more common than it seems.&nbsp;</p>



<p>It’s a real struggle for many. And if that’s your case, stay calm. You’re not alone.</p>



<p>Today I’m sharing what probably was the most crucial lesson we learned along more than six years of pain, suffering, and effort to get out of the blockade.&nbsp;</p>



<p>We hope it will serve you too as a first step to start making progress in the right direction once and for all.</p>



<h2><strong>Getting off track as soon as you start the race.</strong></h2>



<figure><img src="https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1024x690.jpg" alt="" srcset="https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1024x690.jpg 1024w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-300x202.jpg 300w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-768x517.jpg 768w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1536x1035.jpg 1536w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-2048x1380.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1024x690.jpg 1024w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-300x202.jpg 300w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-768x517.jpg 768w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1536x1035.jpg 1536w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-2048x1380.jpg 2048w" data-lazy-src="https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1024x690.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by <a href="https://unsplash.com/@jamie452?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jamie Street</a> on <a href="https://unsplash.com/collections/11722728/article%3Ahow-to-start-moving-forward-when-you-are-starting-up/14b4d886248c3fd5d964d5507a1b57fb?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>I jumped into my first independent startup venture more than eight years ago.</p>



<p>At that time, I’d just left Facephi, the startup I joined as its first employee and CTO.&nbsp;</p>



<p>After more than four years, a pretty nice salary, a remarkably promising product out into the market, and 2+ million in investor funding, I felt the time for a change had come.</p>



<p>I wanted to keep growing.</p>



<p>I was trying to run away from things I didn’t want in my life and desired to create my own business.</p>



<p>I wanted to become happier and more fulfilled, but my idea of what all that meant was pretty fuzzy by then.&nbsp;</p>



<p>Obviously, starting a path without knowing what I was seeking was a ticket for disaster.</p>



<figure><blockquote><p>Would you tell me, please, which way I ought to go from here? —said Alice.<br>That depends a good deal on where you want to get to. —said the Cat.<br>I don’t much care where. —said Alice.<br>Then it doesn’t matter which way you go. —said the Cat.</p><cite>Lewis Carrol, Alice in Wonderland.</cite></blockquote></figure>



<p>I got captive and became a slave of my business and all the stakeholders around.</p>



<p>I had little time for what I enjoyed doing. I was dragged by meetings, external requests, recruiting, managing people, looking for funding, doing administrative tasks, putting out fires in general, and carrying out other unfulfilling stuff.</p>



<p>As a consequence, everything I did was useless. I couldn’t focus on the important, and couldn’t make any meaningful progress.</p>



<p>To top it all, it affected my personal life as well.</p>



<p>I didn’t have much time for family and friends anymore. I started doing far less physical exercise, began eating and sleeping worse, and had to renounce other goals in my life.</p>



<p>In every way, I neglected my health and well-being.</p>



<p>The case of my brother was no different.</p>



<p>It was evident that we’d made many unfitting choices.</p>



<h2><strong>The exit is inward.</strong>..</h2>



<blockquote><p>The least obvious part of the system, its function or purpose, is often the most crucial determinant of the system’s behavior.</p><cite><em>Daniella Meadows, Thinking in Systems</em></cite></blockquote>



<p>Where was I trying to get to? That’s the question I started asking myself following our last failure.</p>



<p>I had an intuition, but I’d never taken the time to reflect deep enough on it. I must admit that, up to that point, and to some extent, I’d looked outside for answers.</p>



<p>I needed to find the reasons why I was doing what I was doing. So, after a profound exercise of introspection and 6+ years of hustling, I finally found out what I was searching for.</p>



<p>In essence, I wanted to be freer to do what intrinsically moves me.&nbsp;</p>



<p>I wanted to feel useful and, what’s more important, live ethically. I felt a deep desire to do the right thing.</p>



<p>That was the purpose I expected entrepreneurship to fulfill in my life. That’s what success looked like to me.</p>



<p>This level of clarity caused a radical shift in our way of thinking.</p>



<p>It was like finding a light in the middle of darkness.&nbsp;</p>



<p>Everything became pretty more evident than before. Without knowing where we wanted to get to, it was barely impossible to get to our right place.</p>



<p>The question is that, when everything started, I didn’t know that I didn’t know it —even though I thought I did.&nbsp;</p>



<p>It’s easy not to notice it. Society bombards you with deceptive images of success and demands you to follow them.&nbsp;</p>



<p>You know, the dream of the billion-dollar companies and the hypergrowth VC path.</p>



<p>But this is a dangerous trap to fall into.</p>



<p>We fell dragged into those fake ideals and made life-changing decisions when what we wanted for our future was still blurred in our minds.</p>



<p>And inadvertently, we started being driven by others’ goals.</p>



<p>Now, one thing was neat. Whatever new system we followed, it should deliver on what we value.</p>



<p>It should be meant to get more freedom to explore, learn, and create on our own terms.&nbsp;</p>



<p>It should aim to gain more room to pursue other goals and grow in other areas of our lives.</p>



<p>And last but not least, it should help to contribute to this world, for good.</p>



<p>Did I need to build a macro-business overnight for that? Of course not. There was a more sustainable path.</p>



<p>Now, we wouldn’t focus on developing a high-growth business. Instead, we’d make it all about growing ourselves successfully as creators.&nbsp;</p>



<p>We turned our approach inside out and pressed a key that would change the rules of the game forever.</p>



<p>This new mindset suddenly made many vital decisions to become evident.</p>



<h2>Getting more freedom.</h2>



<p>This time, <strong>we decided to grow our new venture by ourselves</strong>. Unlike previous projects, we chose to avoid toxic relationships and commitments with investors and other stakeholders that could get us off track again.</p>



<p>Now, with Freegrowth, we’ve come to follow the bootstrapping route.</p>



<p>Second, <strong>we chose to work remotely and pick our work hours</strong>. We did it about a year ago and haven’t regretted ever since.&nbsp;</p>



<p>Now, no particular physical location or schedule ties us.&nbsp;</p>



<p>We toil at whatever time that better works for us, from whatever place that better fits our lives —something that, especially in the face of the current times, has proven invaluable.</p>



<p>Last, <strong>we chose to diversify and avoid long-term lock-in by the projects we get into</strong>. It’s our way to control risk and bring optionality into our path.</p>



<p>As in the stock market, these days, we strive to keep our risk portfolio balanced by combining high-risk investments with other safer options.&nbsp;</p>



<p>Here, we are the resource to invest, so we better do it wisely.</p>



<figure><blockquote><p>Common sense suggests that creative accomplishments can’t flourish without big windows of time and energy, and companies can’t thrive without intensive effort. Those assumptions overlook the central benefit of a balanced risk portfolio: Having a sense of security in one realm gives us the freedom to be original in another. By covering our bases financially, we escape the pressure to publish half-baked books, sell shoddy art, or launch untested businesses.</p><cite>Adam Grant, Originals.</cite></blockquote></figure>



<p>In the same fashion, we turned our attention toward the concept of liquidity.</p>



<p>Now, we approach our growth through small bets. We explore the terrain before anything else and make sure of the way to go before committing further.</p>



<p>Before getting ourselves tied to any particular commitment, we explore and try first.&nbsp;</p>



<p>We focus on experiencing what it takes and feels like to go through a given route. We try to uncover what we don’t know before moving on. That way, we cap the risk of getting into a place we don’t want to be.</p>



<p>There are many implications related to this.&nbsp;</p>



<p>To cite an example, consider that different types of products involve different levels of commitment. A SaaS app implies a dependency of customers on us. Among other things, it carries with it the need to deliver customer support for the long-haul.&nbsp;</p>



<p>As such, it entails a life-long responsibility.&nbsp;</p>



<p>Today, before building a product, we assess the level of commitment we want to assume.</p>



<p>If we consider building a software product, we ask ourselves, “Is this something we want to commit our time, money, energy, and knowledge for years?”</p>



<p>If the answer is no, we move on to another thing.</p>



<p>If we are not sure yet, maybe we’ll work on removing the uncertainty through smaller bets.</p>



<p>If the answer is “<a href="https://sive.rs/hellyeah">Hell yeah!</a>” then well…still, in the early stages, we’ll approach it through small bets to give us room to change course if necessary —we don’t know what we don’t know yet.</p>



<h2>Learning and creating.</h2>



<p>We focused on learning and creating regularly.&nbsp;</p>



<p><strong>We made study a part of our routine</strong>. It was already there, but now we made it more prominent.</p>



<p>Acquiring <a href="https://marker.medium.com/the-case-for-generalists-29f9af19c8da">range</a> and depth in and out of our fields has become a habit for satisfying our curiosity and overcoming upcoming challenges.&nbsp;</p>



<p>That has proven to be game-changing as it’s giving us a more holistic vision to find and approach problems and shape better solutions. While we previously operated from the ground, now we work from a 10000-feet perspective.</p>



<p>On the other hand, <strong>we chose to release …</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://freegrowth.co/blog/regain-control/">https://freegrowth.co/blog/regain-control/</a></em></p>]]>
            </description>
            <link>https://freegrowth.co/blog/regain-control/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628760</guid>
            <pubDate>Tue, 29 Sep 2020 15:11:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breaking down the complexity of notification system design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628595">thread link</a>) | @JaneKCall
<br/>
September 29, 2020 | https://magicbell.io/blog/building-a-user-notification-system/ | <a href="https://web.archive.org/web/*/https://magicbell.io/blog/building-a-user-notification-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://magicbell.io/blog/content/images/size/w300/2020/09/MagicBell.gif 300w,
                            https://magicbell.io/blog/content/images/size/w600/2020/09/MagicBell.gif 600w,
                            https://magicbell.io/blog/content/images/size/w1000/2020/09/MagicBell.gif 1000w,
                            https://magicbell.io/blog/content/images/size/w2000/2020/09/MagicBell.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://magicbell.io/blog/content/images/size/w2000/2020/09/MagicBell.gif" alt="Can you build a complete notification system without breaking a sweat?">
            </figure>

            <section>
                <div>
                    <p>User notifications significantly increase engagement in social apps and productivity in business apps. Today, email notifications, web notifications, and cross-platform mobile push notifications have become the standard in user expectations. While some savvy customers want notifications sent to their Slack channels, others might want SMS notifications. Keeping customers in the loop through all the channels is a monumental task--and not one your development team’s core competency or interest.</p><p>Before <a href="https://www.mailgun.com/" rel="noopener nofollow">Mailgun</a> and <a href="https://postmarkapp.com/" rel="noopener nofollow">Postmark</a> were on the map, companies struggled with reliably delivering emails. Before Facebook Connect or Google Auth, everyone built their own authentication systems. </p><p>Not anymore. With <a href="https://magicbell.io/">MagicBell</a>, nobody has to worry about building a bespoke notification system ever again.</p><h2 id="the-complexity-of-notifications">The Complexity of Notifications</h2><p>Let’s consider the most basic, cross-platform notifications setup. A system event requires a user notification(for example, if they were tagged in a comment). If you provide a web app, you’ll first need to verify the user is online before you can send them a notification in-app. If they are offline, you’ll need to push the notification via email. (You can push the notification through both channels, but we believe this practice to be less effective). </p><p>If you also offer a mobile app, you may send them a push notification, but then you should remember to remove it if your user sees it on another channel. To get an idea of just how complex notification systems can get, take a look at this flow chart that Slack, which offers a visual of heir notifications logic:</p><figure><img src="https://magicbell.io/blog/content/images/2020/01/0GXxzU9.jpg"><figcaption>Slack’s notifications logic, thanks to Slack</figcaption></figure><p>And that’s just the very basic notifications. What if you would like your users to act on notifications, send them a digest version, or offer other channels like Slack or SMS? Then things get even more complex. And you want to split test your notification, or analytics on the effectiveness of your notifications on user engagement, you’re going to have to build out even more pathways.</p><h2 id="the-secret-world-of-notification-mismanagement">The Secret World of Notification Mismanagement</h2><p>A lot of companies build a notification system but barely have time to maintain or improve it. Notifications are not just fired and forgotten. You need to worry about deliverability and giving your users subscription options and troubleshooting help. &nbsp;An additional concern is the management of notification preferences; you’ll need to build a screen where they can select how and when they want to be notified and about what. Finally, there’s security. Most don’t have any debugging or customer support infrastructure around notifications and end up just hoping for the best. </p><h2 id="introducing-magicbell">Introducing MagicBell</h2><p>There’s a silver lining. These implementation patterns are highly similar across products and companies and render themselves well to a SaaS service. </p><p>We have been thinking about this problem for many years in SupportBee and finally decided we were the ones to solve it. </p><p>We introduce our solution: MagicBell.</p><h2 id="your-email-notifications-supercharged-">Your Email Notifications, Supercharged!</h2><p>One more thing. Apps and services almost always offer email notifications. MagicBell re-uses your email notifications to give your users a notification center, automagically. All you have to do is BCC: your email notifications to a project-specific magic email address, and we do the rest! MagicBell sorts emails and understands who the notification is for, what the title of the notification is, and where it should direct the user.</p><p>All of this behavior is customizable in under than 5 mins: <a href="https://magicbell.supportbee.com/149-magicbell-s-help-docs/269-email-setup/381-configure-postfix-to-bcc-emails">BCC emails in postfix</a> with just one line of config change, and embed our widget in your site. To <a href="https://magicbell.supportbee.com/149-magicbell-s-help-docs/269-email-setup/341-customizing-notifications-using-email-headers">customize the notifications</a>, simply send us some custom email headers.</p><p>For more intelligent delivery, send us the email notifications via SMTP and let us worry about notification preferences, and smart delivery to the right channels, including email. </p><figure><img src="https://magicbell.io/blog/content/images/2020/01/image.png"></figure><p><a href="https://magicbell.io/" rel="noopener nofollow">MagicBell</a> is currently delivering over a million notifications a month for some great products. I invite you to give it a try for your app or service. <a href="https://magicbell.typeform.com/to/RNKqWW">P</a>lease <a href="https://app.magicbell.io/">signup for an account</a> or <a href="https://calendly.com/hana_mohan/30min">book a demo</a>.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://magicbell.io/blog/building-a-user-notification-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628595</guid>
            <pubDate>Tue, 29 Sep 2020 14:58:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doing discourse better: Stuff I wish I knew]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628593">thread link</a>) | @dyno-might
<br/>
September 29, 2020 | https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        

<div>
    <div>
        <div>
            <p><strong>Sep 29, 2020</strong></p>
            





<p>Nick and Maria want to talk about sugar. Does it reduce lifespan? They disagree, but are honest and principled. They want to find the truth and agree on it.</p>

<p>How should they talk? Take turns? Try hard to be polite and respectful? Allow interruptions? Search for origins of disagreement? Areas of agreement? Make bets? Get a moderator?</p>

<p>Or maybe Nick and Maria want to talk about tax-exemption for churches. It might be hard to get consensus, since this is a matter of opinion. Still, they’d like to reduce their disagreement to different underlying values. What should they do? Repeat the other’s argument? Tell personal stories? Run ideological Turing tests?</p>

<p>Do conversations have known best practices? How much do they improve the odds of landing on the truth?</p>



<p>In East Africa 70,000 years ago, humans made their first steps towards language. This didn’t happen for <em>truth</em>, it happened to <em>increase reproductive fitness</em>. Overly open-minded people were probably easy to manipulate. Scrupulously honest people were probably bad at manipulating. Many false beliefs still <em>enhanced reproductive fitness</em> (typically by <a href="https://dynomight.home.blog/2020/05/27/sapiens-part-1-the-cognitive-revolution/">improving cooperation</a>).</p>

<p>So, one might argue, <em>of course</em> we are terrible at finding truth via conversation! Why are we surprised that our instincts are bad at something we never evolved to be good at?</p>



<p>Doing some research, Maria finds the work of Robert Cialdini, who says we are persuaded by reciprocity, scarcity, authority, consistency, liking, and consensus. But these don’t seems useful to Maria. They are mostly “dark patterns” of persuasion, that work for anything regardless of its truth.</p>

<p>Instead, are there “non-dark” patterns of persuasion, that work well <em>for true stuff</em> but not for false stuff?</p>



<p>Over a few months, Nick and Maria have a dozen of these conversations. The results are exactly what you’d expect: No one ever changes their mind about anything. Maria has a feeling she can’t be right about <em>everything</em>. But try as she might, she can’t find a case where Nick’s arguments convince her.</p>

<p>Eventually, she has a strange idea. Maybe she should fight fire with fire, cognitive-bias wise. She decides that in each discussion they should both <em>intentionally</em> subject themselves to as much dark-pattern manipulation as possible. Her theory is that there is an “energy barrier” that prevents them from getting into a mind-space where it’s even possible to appreciate the other position fairly.</p>

<p>By temporarily brainwashing themselves a little bit, can they can actually give the other position a fair chance?</p>



<p>It’s reasonable to be skeptical about the above ideas. Humans have been talking for 70,000 years. If there was a trick to talking better, wouldn’t we have found it already? I showed some of the above thoughts to a friend, who responded, “LOLOLOLOLOL, dynomight, you sweet wide-eyed gazelle. The rare Nicks and Marias of the world do great already. The problem is <em>dishonest</em>, <em>unprincipled</em> people.”</p>

<p>So perhaps better conversation can’t save the world. Still, I think a different type of discourse has much more room for improvement: That in <em>online forums</em>. It sounds hyperbolic, but I genuinely believe this could move the needle on the future of humanity.</p>

<p>Just think about it. The world is a complex place. Want to understand the effects of the minimum wage? The long-term trajectory of population growth? The effects of vitamin C? No one human brain can process all the relevant information for such questions. But shouldn’t <em>groups</em> of brains, if we could “network” them properly, have much greater capabilities?</p>



<p><img src="https://dyno-might.github.io/img/discourse/conversational_graphs.png">
</p>

<p>Online forums have various design dimensions.</p>

<ul>
  <li><strong>Conversational graphs.</strong> An old-school message board is a chronological list. Modern forums (Reddit, LessWrong) represent comments in a reply tree. On 4chan, a directed acyclic graph of replies is overlaid on the chronological list: Someone can reply to multiple messages, and pointers are provided at both ends to move around the graph that way. In Stack Overflow, <em>answers</em> are ordered by votes, but <em>comments on answers</em> are chronological.</li>
  <li><strong>Voting.</strong> Some don’t use it at all (old-school boards). Some order everything by votes (Reddit). Some use votes to order some levels but not others (Stack Overflow).</li>
  <li><strong>Who can put content where?</strong> On Twitter, anyone can throw their replies up on anyone else’s content. It would be a very different place if you could only do this if that person followed you.</li>
  <li><strong>Moderation.</strong> This varies from <em>Moderate to Crush the Human Spirit</em> (Stack Overflow) to <em>Moderate When Alternative is Prison</em> (4chan).</li>
</ul>

<p>It’s hard to understand the influence of most of these choices, since popular forums vary along many dimensions at the same time. Most forums today are optimized for the goal of “make forum owners rich.” We don’t know the decision-making process, or what tradeoffs would be made with different goals.</p>

<p>I don’t think it’s possible to sit around and figure out what effects a given forum design will have. Human beings and social behavior are too complex. We need to systematically test the different designs, and see what actually happens empirically. Is anyone doing that?</p>



<p>Here are some ideas:</p>

<ul>
  <li>Sometimes people have useful ideas, but give them in a long, boring, hard to read form. Can we allow users to edit each others’ content?</li>
  <li>“Flattening” comments into a linear order is always a distortion. Why not learn-in to the idea of a full conversational graph, with some kind of visualization that allows people to elegantly navigate it?</li>
  <li>Inside a conversation are many interesting sub-conversations. Can users create “curated views” to highlight the best comments in one sub-conversation?</li>
  <li>We <em>say</em> we want beauty and truth and to be better people. But we can’t resist cat videos and the latest political outrage. Can we allow users to “Ulysses nudge” themselves, by choosing the kind of content they <em>wish</em> they enjoyed? Let the algorithm find a way to try to manipulate the user into doing what the user’s “better self” wants.</li>
  <li>Forums are great ways to share knowledge. Prediction markets are also a great way to combine knowledge. Can we find an effective way to combine the two?</li>
</ul>

<p>These ideas are all probably terrible. I’m just trying to say that there’s a <em>lot</em> of possibilities, and some of them are surely good.</p>

<p>Suppose we could look 30 years into the future. Forums will no doubt look very different. Probably some of the differences rely on exogenous technological innovation. But surely <em>some</em> differences could be “back-ported” to today, if only we knew what they were. What are they, and why is the pace of innovation in online forums so slow right now?</p>



<p>If we want a historical example of “public forum with rules and norms carefully derived to find truth” I think the best we can do is the system of journal publications. For all their imperfections, these have done a decent job of uncovering truth for several hundred years. What lessons do these offer?</p>

<p>I think for our purposes, the three biggest differences vs. online forums today are:</p>

<p>First, journals have a <em>crazy</em> focus on <strong>credit attribution</strong>. There is a formalized system of citations. Reviewers check that the claimed new ideas in papers really are new, and that credit (citations) have been provided to all (most? some?) related work. One paper can reply (cite) to many other papers. (Journals share this with 4chan!)</p>

<p>Second, journals provide strong <strong>quality signals</strong> coupled to <strong>heavy “moderation”</strong>. In most fields there is a fairly clear status hierarchy. The moderators (reviewers/editors) at top journals spend a lot of effort moderating, and are very picky about what they accept. This provides strong signaling for the papers that are accepted.</p>

<p>Third, there are extremely strong <strong>external incentives</strong> for people to appear in the top journals. (Ultimately, jobs and money are on the line.)</p>

<p>There other differences (e.g. journals are slow and cost money) but I think the three above are the most significant. What would happen if we added these to online forums today? Unfortunately, it’s a bit hard to say. These wouldn’t be easy to copy. The first is laborious, and the others are as much properties of the society the journal is embedded in as the journal system itself.</p>



<p>Maybe figuring out how to improve forums is hard. As a first step, maybe we can at least understand where things go wrong? Here’s some proposed failure modes.</p>

<p><strong>The user death spiral.</strong> Some cool people start a forum and have cool conversations. Random trolls show up sometimes, but they are easily banned. Eventually, some not-quite-as-cool people find their way to the forum. They aren’t misbehaving and make some good points sometime. It feels tyrannical to ban them so no one does. Still, the coolest people become slightly more likely to drift away. New very-cool people become slightly less likely to join. Eventually the median shifts enough that barely-cool-at-all people are joining. Gradually, the average coolness of people in the forum decreases to zero.</p>

<p><strong>The tyranny of the minority.</strong> Human experience is vast. There are people out there who truly, passionately believe that bestiality should be legal and accepted. Some are smart and compelling writers. Almost all forums block these people. You don’t, figuring that you believe in free speech, these people are a tiny minority, and the truth will emerge as they argue with the majority. Suddenly, in every thread people are findings connections to the “injustice” of the current prohibition on bestiality. Why? Because every other high-status place on the internet prohibited these people, and they’ve all been funneled to you.</p>

<p><strong>The village becomes anonymous.</strong> In small forums, you see the same person repeatedly. This has two advantages: A) You know people will remember you, and you want them to be nice to you, so you try not to act like a jerk. B) After seeing the same people for a while, you have some <em>context</em> for their comments. The conversation can actually evolve and grow over time. After …</p></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/">https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/</a></em></p>]]>
            </description>
            <link>https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628593</guid>
            <pubDate>Tue, 29 Sep 2020 14:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTML Canvas Art in TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628489">thread link</a>) | @xvzq
<br/>
September 29, 2020 | https://www.chrismytton.com/2020/06/06/canvas-art-in-typescript/ | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/2020/06/06/canvas-art-in-typescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>I ported a JavaScript “random art generator” I created a few years ago over to TypeScript. This post contains some notes from the process.</p>

<ul>
  <li>See the project: <a href="https://www.chrismytton.com/art/">www.chrismytton.com/art</a></li>
  <li>Check out the code: <a href="https://github.com/chrismytton/art/blob/1f34e99d121f2c7dd698eb8c9d45da1e9b7f450c/src/random.ts">chrismytton/art on GitHub</a></li>
</ul>

<hr>

<p>I’ve been learning TypeScript recently. As part of that I wanted to dig out some of my old JavaScript projects and port them to TypeScript. I find porting code to a new language is a good way to learn.</p>

<p>I found an old project that I created in 2014 which uses JavaScript and the Canvas API to create random pieces of art which change on every page load. The code itself is fairly straightforward, so it seemed like a good candidate for porting to TypeScript.</p>

<h2 id="classes-in-typescript">Classes in TypeScript</h2>

<p>TypeScript classes build on <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes">ES6 classes</a>. The major difference is that in TypeScript you need to explicitly declare the types of properties you’re expecting on the class.</p>

<div><div><pre><code><span>class</span> <span>CanvasPainting</span> <span>{</span>
  <span>viewport</span><span>:</span> <span>HTMLCanvasElement</span><span>;</span>
  <span>ctx</span><span>:</span> <span>CanvasRenderingContext2D</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>If you try to use <code>this.viewport</code> without declaring the property TypeScript will tell you:</p>

<blockquote>
  <p>Property ‘viewport’ does not exist on type ‘CanvasPainting’.</p>
</blockquote>

<p>I find having these properties explicitly defined actually makes it easier to figure out what the class might be doing internally. They provide useful documentation about what kind of data you can expect to find in each property.</p>

<h2 id="index-signatures">Index signatures</h2>

<p>This is something I struggled with for a while. I was trying to dynamically call methods on my <code>Shapes</code> class using <code>this[shape]</code>, but TypeScript was giving this warning:</p>

<blockquote>
  <p>Element implicitly has an ‘any’ type because expression of type ‘string’ can’t be used to index type ‘Shapes’.</p>

  <p>No index signature with a parameter of type ‘string’ was found on type ‘Shapes’.</p>
</blockquote>

<p>After reading various bits of the TypeScript documentation and some Stack Overflow answers I eventually figured out that I needed to define an index signature on my shapes class. This tells TypeScript what can be used to index this class, and what the indexing might return.</p>

<div><div><pre><code><span>class</span> <span>Shapes</span> <span>extends</span> <span>CanvasPainting</span> <span>{</span>
  <span>[</span><span>key</span><span>:</span> <span>string</span><span>]:</span> <span>any</span><span>;</span>

  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>This tells TypeScript that you can index this class with a string, and it will return <em>something</em>. There might be a way to avoid using <code>any</code> here, but I haven’t figured that out yet.</p>

<h2 id="dealing-with-null-values">Dealing with null values</h2>

<p>TypeScript knows which methods can return <code>null</code> and will make you deal with those cases. If you try to call a method on a value that might be null then TypeScript will give you a warning.</p>

<p>You can avoid this warning by explicitly checking for <code>null</code> before using the value.</p>

<div><div><pre><code><span>class</span> <span>CanvasPainting</span> <span>{</span>
  <span>viewport</span><span>:</span> <span>HTMLCanvasElement</span><span>;</span>
  <span>ctx</span><span>:</span> <span>CanvasRenderingContext2D</span><span>;</span>

  <span>constructor</span><span>(</span><span>viewport</span><span>:</span> <span>HTMLCanvasElement</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>viewport</span> <span>=</span> <span>viewport</span><span>;</span>
    <span>const</span> <span>ctx</span> <span>=</span> <span>viewport</span><span>.</span><span>getContext</span><span>(</span><span>'</span><span>2d</span><span>'</span><span>);</span>

    <span>// getContext can return null, so check for that case.</span>
    <span>if</span> <span>(</span><span>!</span><span>ctx</span><span>)</span> <span>{</span>
      <span>throw</span> <span>new</span> <span>Error</span><span>(</span><span>"</span><span>getContext('2d') failed</span><span>"</span><span>);</span>
    <span>}</span>
    <span>this</span><span>.</span><span>ctx</span> <span>=</span> <span>ctx</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Without this check for <code>null</code> TypeScript warns you that <code>Type 'null' is not assignable to type 'CanvasRenderingContext2D'.</code>.</p>

<p>It’s easy to forget to check for <code>null</code> when writing JavaScript. TypeScript protects you from this class of error at the compile stage.</p>

<h2 id="summary">Summary</h2>

<p>I really like what I’ve seen so far with TypeScript. Working on little projects like this is a great way to get some experience with new tools.</p>

<p>I’d forgotten all about this fun little art project. It’s nice to have given it a bit of polish and released it into the world, rather than it gathering dust on my hard drive.</p>

<p>See the project: <a href="https://www.chrismytton.com/art/">www.chrismytton.com/art</a>.</p>

<p>Check out the code: <a href="https://github.com/chrismytton/art/blob/1f34e99d121f2c7dd698eb8c9d45da1e9b7f450c/src/random.ts">chrismytton/art on GitHub</a>.</p>


  </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/2020/06/06/canvas-art-in-typescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628489</guid>
            <pubDate>Tue, 29 Sep 2020 14:50:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Stop the Wildfires]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628394">thread link</a>) | @Reedx
<br/>
September 29, 2020 | https://www.persuasion.community/p/how-to-stop-the-wildfires?r=222a5 | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/how-to-stop-the-wildfires?r=222a5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb40d974-20f0-44d1-8873-0773c651aa72_6583x4389.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb40d974-20f0-44d1-8873-0773c651aa72_6583x4389.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/cb40d974-20f0-44d1-8873-0773c651aa72_6583x4389.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:13915552,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Two weeks ago, San Francisco residents awoke to an apocalyptic scene. The sky was blood red. A thick shroud of smoke blocked the sun. Toxic ash fell from the sky.</p><p><a href="https://www.sfchronicle.com/california-wildfires/article/The-day-the-sun-didn-t-come-up-People-in-15554470.php">“The day the sun didn’t rise”</a> marked a low point in the ongoing battle with the California wildfires that have killed dozens and displaced thousands. In some heavily populated regions, the air quality index has exceeded 400, far worse than recent measurements in Beijing or New Delhi. Residents have taken to sealing windows, vents and door jambs with masking tape and plastic. Air filters are out of stock and people already struggling to avoid exposure to a deadly microbe suddenly need to avoid exposure to deadly particulates as well. </p><p>Headlines have been quick to declare that <a href="https://www.youtube.com/watch?v=UW1MYQqvED4">“This Is Climate Change.”</a> Just as quickly, climate skeptics have <a href="https://dailycaller.com/2020/09/13/california-oregon-wildfires-land-management-climate-change/">challenged</a> the claim. Decades of poor forest management at the behest of environmentalists who oppose logging, they argue, is the real culprit. </p><p>Both are partly right. Climate change <em>is</em> making California’s wildfires worse. But California’s forestry policies have massively contributed to the problem. </p><p>Climate change has changed how fires burn in California. Tinder dry conditions make forests burn explosively. And because wildfire season is now fifty percent longer than in the past, it increasingly overlaps with the windiest time of year. For these reasons, small fires are much more likely to turn into big fires very quickly. </p><p>Yet climate change alone can’t explain the onslaught of catastrophic fires the state has faced in recent years. California’s forest and grassland ecosystems are naturally adapted to fire. But a century of fire suppression has turned the state’s forests into a gigantic fuel bunker. When forests like these don’t burn for decades, they become choked with small trees and dense underbrush. When fires do start, there is much more fuel to burn. </p><p>The alternative to burning in many areas is to thin forests, taking out the smaller trees and undergrowth so that there is less fuel and the trees that remain are more resistant to fire. But the state’s powerful environmental lobby has long opposed proposals to thin forests, criticizing them as a lifeline for the state’s failing timber industry.</p><p>Finally, suburban and exurban sprawl into the fire zone has exacerbated the problem. Millions of people now live in the middle of California’s forests, making efforts to limit fire risk through thinning, controlled burns, and other methods more complicated and more controversial.&nbsp; </p><p>Ultimately, it is impossible to disentangle the contributions that climate change, forest management, and suburban and exurban sprawl have made to increasing the risk of catastrophic wildfires in California. But while the causes can’t be disentangled, the solutions can. </p><p>Ambitious efforts to cut carbon emissions, both in California and globally, have much to recommend them. But saving California from fiery apocalypse is not among them. Until fuel loads are dramatically reduced in California’s forests, catastrophic wildfires will continue to wreak havoc across the state. Solving that problem will require a totally different approach to forest management than what either environmentalists or their critics have long favored. </p><p>The environmental community has traditionally advocated letting forests burn, as they did before the arrival of Europeans. But in a state with 39 million residents, many of whom live in close proximity to the fire zone, this is simply unrealistic. Even fires that are far removed from population centers create enormous public health risks. The fire responsible for San Francisco’s red sky at morning, for example, burned in a largely uninhabited area several hundred miles away. Until fuel loads are reduced sufficiently to transition forests back to less intense natural fire regimes, allowing remote fires to burn themselves out is likely to increase the choking smoke that now regularly settles over the state’s densely populated regions. </p><p>Meanwhile, conservatives who insist that the timber industry would, but for onerous environmental regulations, take care of the problem are completely out of touch with the state of the industry, the economics of logging California’s forests, and the reality of what is needed for effective long-term fuel reduction. The state’s remnant timber industry does not remotely have the capacity to thin the state’s forests at the necessary scale. Nor would doing so be economical in many forested regions of the state, as the big trees that pay the bills are largely gone. Even where logging is economically viable, removing mature trees is frequently counterproductive, since they tend to be replaced by more flammable undergrowth.</p><p>Ultimately, neither carbon caps nor subsidies for solar or wind energy will stop California’s wildfires. Resuscitating the timber industry won’t either. Limiting catastrophic wildfires in California will instead require intensive management of the state’s forests at an unprecedented scale. This will require a new, publicly funded forest management industry dedicated not to the extraction of valuable timber for private profit but rather to the removal of low-value underbrush and immature trees for public benefit.</p><p>In the rush to find convenient villains, both climate advocates and their opponents avoid harder policy choices. Conservatives insist that forest management, not climate change, is the cause of the problem—but are unwilling to support big spending to actively manage California forests. Environmentalists argue that climate change “changes everything”—but still insist that the solution to climate fueled megafires is to return to the state’s historic fire pattern. </p><p>Environmentalists are right that, over the long-term, we need to cut carbon emissions to something close to zero. And conservatives are also right that, without radical changes to both land use and forest management policy, catastrophic wildfires will continue to plague the state. To engage these issues in good faith, protagonists on both sides of the debate will need to follow their arguments through to their logical conclusions rather than refusing to accept any inference that contradicts their ideological priors. To succeed in addressing either climate change or California’s wildfires, we will need to stop debates about climate change from degenerating into a stale culture war rather than imagining that we might win them. </p><p><strong>Ted Nordhaus and Alex Trembath are executive director and deputy director, respectively, of the Breakthrough Institute.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/how-to-stop-the-wildfires?r=222a5</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628394</guid>
            <pubDate>Tue, 29 Sep 2020 14:42:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Bytecode Surgery to Create an Ouroboros]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628194">thread link</a>) | @underanalyzer
<br/>
September 29, 2020 | https://www.peterstefek.me/ouroboros.html | <a href="https://web.archive.org/web/*/https://www.peterstefek.me/ouroboros.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>28 September 2020</strong></label></p>
<p>The code associated with this article can be found <a href="https://github.com/Mr4k/ouroboros">here</a>.</p>
<p>Consider the following function in Python which sums up the first n numbers:</p>
<div><pre><span></span><span>def</span> <span>sum</span><span>(</span><span>n</span>, <span>acc</span><span>=</span><span>0</span><span>)</span>:
  <span>if</span> <span>n</span> <span>==</span> <span>0</span>:
    <span>return</span> <span>acc</span>
  <span>else</span>:
    <span>return</span> <span>sum</span><span>(</span><span>n</span> <span>-</span> <span>1</span>, <span>acc</span> <span>+</span> <span>n</span><span>)</span>
</pre></div>


<p>So sum(1) returns 1, sum(2) returns 3 and sum(3) returns 6. What about sum(10000000)?<br>
Most likely if you call sum(10000000) you will get the following error:  </p>
<p><code>Maximum recursion depth exceeded</code>  </p>
<p>A quick google shows that we have exceeded a limit that Python has on how deep recursion can go. Why don't we just increase it to 10000001? Let's try it! Now what happens?<br>
Most likely you will see a different error which looks like this:  </p>
<p><code>Segmentation fault: 11</code>  </p>
<p>What happened here? It turns out that we ran out of memory. This is because every recursive call pushes a new stack frame, containing new variables and function information, onto Python's call stack.  </p>
<p>But if you are incredibly observant or have taken a functional programming course, you might realize that the final result of this recursion is just the value returned by the base case. This value is then passed up a long chain back to the original call. It turns out in this case we don't need the chain. This observation is at the heart of so-called tail call optimization. The optimization eliminates unnecessary stack frames when calling functions from within functions. Most languages (even some js runtimes) implement tail call optimization, however Python's design committee has always been stubbornly against it.  </p>
<p>Since I was looking for small projects to do during my first week at the <a href="https://www.recurse.com/">Recurse Center</a>, I decided to try to implement a basic version of tail call optimization in Python. Note this is not an original idea and I had already seen some clever hacks which used exceptions to break out of sub calls. I decided to try something different, although after presenting my implementation to the greater RC community I learned that another Recurser had given a <a href="https://www.youtube.com/watch?v=Qk1I6ZxcceU&amp;feature=share">fantastic talk</a> which used the same idea back in 2015 (small world!)  </p>
<p>Before I dive into the details let's look at the prototype in action:<br>
sum.py is a file which contains the same sum calculation from the beginning of this post:  </p>
<div><pre><span></span><span>def</span> <span>sum</span><span>(</span><span>n</span>, <span>acc</span><span>=</span><span>0</span><span>)</span>:
  <span>if</span> <span>n</span> <span>==</span> <span>0</span>:
    <span>return</span> <span>acc</span>
  <span>else</span>:
    <span>return</span> <span>sum</span><span>(</span><span>n</span> <span>-</span> <span>1</span>, <span>acc</span> <span>+</span> <span>n</span><span>)</span>

<span>print</span><span>(</span><span>sum</span><span>(</span><span>1000000</span><span>))</span>
</pre></div>


<p>If type <code>python sum.py</code> we will get an error.<br>
Now let's try using my tool:  </p>
<div><pre><span></span><span>python</span> <span>optimize</span><span>-</span><span>tail</span><span>-</span><span>calls</span><span>.</span><span>py</span> <span>sum</span><span>.</span><span>py</span>
</pre></div>


<p>This prints <code>500000500000</code> as expected.  </p>
<p><strong>Identifying Tail Recursive Functions Calls</strong> <br>
The first thing I did was to come up with a way to identify which function calls can be optimized.   </p>
<p>Let's say we have a function <code>f</code> which calls a function <code>g</code> inside of it (<code>g</code> could be a recursive call to <code>f</code> but doesn't have to be). If <code>f</code> just returns the value of <code>g</code> without modifying it, then we do not need to remember <code>f</code> existed in the first place (it does not have to stay on the call stack).  </p>
<p>Let's see how we can translate that definition into something we can implement with Python.   </p>
<p><strong>A Byte Sized Definition</strong><br>
It turns out the Python VM does not evaluate python code directly but rather compiles it to an intermediate bytecode. Below is an example of the bytecode generated for our <code>sum</code> function from above,  </p>
<p>
    <img src="https://www.peterstefek.me/images/ouroboros/sum-bytecode.png" width="50%"> 
</p>

<p>This code may look familiar to anyone who has seen assembly language before. Basically it is a set of instructions which must be executed in roughly sequential order. As you can see here, the CALL_FUNCTION instruction comes right before the return statement. In theory, this gives us a pretty good heuristic to tell if a function call is a tail call. That is to say, a function call is tail call optimizable if it comes right before a return statement (or in some cases jumps to a return statement). Note this definition might not capture every case but does a pretty good job overall. It also should not have false positives.  </p>
<p>✂️ <strong>Bytecode Surgery</strong> ✂️<br>
Now that we know which calls are tail call optimizable, all we have to do is to remove the unnecessary stack frames right? Unfortunately this is where we hit our first big limitation of Python's VM. We do not have full access to the stack pointer like we do in some assembly languages. Therefore, we really don't have a lot of control over the call stack. This really limits our ability to optimize. Some Python tail call optimization implementations get around this by using the exception system to break out of the current call. I chose not to do this due to the complexity of exceptions.   </p>
<p>However if we focus our attention on tail recursive calls (where the tail call functions call the parent function) there is another way to hack around our problem. The simplified version is that we can replace the CALL_FUNCTION instruction with the JUMP_ABSOLUTE instruction, which we can use to take us back to the beginning of the current function.  </p>
<p>
    <img src="https://www.peterstefek.me/images/ouroboros/bytecode-surgery.png" width="99%"> 
</p>

<p>Of course, reality is a little more complex. We actually have to insert more than one instruction to do things like store the function arguments into the proper variables and pop the initial function reference off the stack. To make things more complicated, Python will sometimes have jump statements elsewhere in the call. If we simply replace one instruction in the middle of the function with several instructions, all the indexes get messed up and things will break in subtle ways. The way I dealt with this problem was to replace CALL_FUNCTION with a jump which goes to the end of the function where we can append the rest of our instructions without having to worry about messing up other indexes. Of course this breaks for enormous functions but that's outside of the scope of this prototype.   </p>
<p><strong>More Complications</strong><br>
Unfortunately, there's one more major problem with our clean bytecode definition of a tail recursive function call. The problem is that there is no reliable way to tell from the bytecode which function is being called without actually running the bytecode. This means that in order to really know whether a tail call is tail recursive or not we need more information. I chose to use the AST (Abstract Syntax Tree) form of the code to figure this out.  </p>
<p>To determine if a function call is tail recursive, I used another heuristic which consists of four criteria: </p>
<ul>
<li>the call is the sole direct child of the return statement</li>
<li>the call calls the parent function</li>
<li>the call and entire return statement must be on one line</li>
<li>nothing unrelated to the return statement can be on the same line</li>
</ul>
<p>This heuristic further narrows the number of calls we can mark as tail recursive. I think it can be improved but I chose it partially for simplicity of implementation. One other quirk about python's bytecode is that it gives us the line where each instruction is based but does not give us any more granular information. This is why I have the same line requirement. </p>
<p>We can now mark all the lines with tail recursive calls. Then when going through the bytecode, if we see a function call next to a return statement we can check if it is a tail recursive call or not based on the line number.  </p>
<p><strong>An Ouroboros</strong><br>
</p><p>
    <img src="https://www.peterstefek.me/images/ouroboros/ouroboros.jpg" width="40%"> 
</p> <p>
The Ouroboros is a snake which is eating its own tail. It symbolizes eternal cyclic renewal. In Python I consider this function to represent an Ouroboros,  </p>
<div><pre><span></span><span>def</span> <span>ouroboros</span><span>()</span>:
    <span>return</span> <span>ouroboros</span><span>()</span>
</pre></div>


<p>Now that we can optimize tail recursive function calls, this function will run forever (read as until we send SIGINT), eating it's own stack in an endless cycle.  </p>
<p><strong>Further Places to Improve</strong><br>
I think with a little work the AST based heuristic could be complete (it would not miss any tail call optimizable functions).   </p>
<p>When I started this project I was wondering about diving into the cpython VM code itself. I think it was neat that I didn't have to but I wonder if being able to make these tail call optimization decisions at runtime would be better. This would allow us to know which function was about to be called at runtime and we could decide whether or not to jump then. We would no longer need any AST based heuristics.  </p>
<p>Of course if I had full VM access, I could also potentially allow jumping between functions without having to resort to exceptions which would really allow full tail call optimization. That might be an undertaking though.</p>
<p>Have questions / comments / corrections?<br>
Get in touch: <a href="mailto:pstefek.dev@gmail.com">pstefek.dev@gmail.com</a>   </p>
 </div>
</div></div>]]>
            </description>
            <link>https://www.peterstefek.me/ouroboros.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628194</guid>
            <pubDate>Tue, 29 Sep 2020 14:24:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking TensorFlow on Nvidia GeForce RTX 3090]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24628189">thread link</a>) | @rkwasny
<br/>
September 29, 2020 | https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090 | <a href="https://web.archive.org/web/*/https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>NVIDIA recently released the much-anticipated GeForce RTX 30 Series of Graphics cards, with the largest and most powerful, the RTX 3090, boasting 24GB of memory and 10,500 CUDA cores. This is the natural upgrade to 2018’s 24GB RTX Titan and we were eager to benchmark the training performance performance of the latest GPU against the Titan with modern deep learning workloads.</p><p>Based on the specs alone, the 3090 RTX offers a great improvement in the number of CUDA cores, which should give us a nice speed up on FP32 tasks. However, NVIDIA decided to cut the number of tensor cores in GA102 (compared to GA100 found in A100 cards) which might impact FP16 performance.<br></p><p>‍<br></p><div>
<table>
  <tbody><tr>
    <th></th>
    <th>Titan RTX</th>
    <th>3090 RTX</th>
  </tr>
  <tr>
    <td><i>Architecture</i></td>
    <td>Turing TU102</td>
    <td>Ampere GA102</td>
  </tr>
  <tr>
    <td><i>Cuda cores</i></td>
    <td>4,609</td>
    <td>10,496</td>
  </tr>
  <tr>
    <td><i>Tensor cores</i></td>
    <td>576</td>
    <td>328</td>
  </tr>
  <tr>
    <td><i>Memory</i></td>
    <td>24GB</td>
    <td>24GB</td>
  </tr>
  <tr>
    <td><i>Memory bandwidth</i></td>
    <td>672 GB/sec</td>
    <td>936 GB/sec</td>
  </tr>
  <tr>
    <td><i>TDP (watts)</i></td>
    <td>285</td>
    <td>350</td>
  </tr>
</tbody></table></div><p>System:<br></p><p><em>Ubuntu 18.04.3</em></p><p><em>Driver Version: 455.23.05</em></p><p><em>CUDA Version: 11.1</em></p><p><em>Tensorflow: tf-nightly 2.4.0.dev20200928</em></p><p>It is very important to use the latest version of CUDA (11.1) and latest tensorflow, some features&nbsp;like TensorFloat are not yet available in a stable release at the time of writing.</p><p><br>We use our own fork of the <a href="https://github.com/lambdal/lambda-tensorflow-benchmark/tree/tf2">Lambda Tensorflow Benchmark</a> which measures the training performance for several deep learning models trained on ImageNet.</p><p>‍</p><div>


<table>
	<caption>Training performance in images processed per second</caption>
  <thead>
    <tr>
      <th></th>
      <th colspan="2">FP16</th>
      <th colspan="2">FP32</th>
    </tr>
    <tr>
      <th></th>
      <th>Titan RTX</th>
      <th>RTX 3090</th>
      <th>Titan RTX</th>
      <th>RTX 3090</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><i>AlexNet</i></td>
      <td>6634.31</td>
      <td>8255.43</td>
      <td>4448.46</td>
      <td>6493.16</td>
    </tr>
    <tr>
      <td><i>Inception3</i></td>
      <td>656.13</td>
      <td>616.25</td>
      <td>222.95</td>
      <td>337.31</td>
    </tr>
    <tr>
      <td><i>Inception4</i></td>
      <td>298.11</td>
      <td>132.73</td>
      <td>99.74</td>
      <td>143.65</td>
    </tr>
    <tr>
      <td><i>ResNet152</i></td>
      <td>423.92</td>
      <td>484.02</td>
      <td>134.47</td>
      <td>203.58</td>
    </tr>
    <tr>
      <td><i>ResNet150</i></td>
      <td>966.77</td>
      <td>1259.95</td>
      <td>335.96</td>
      <td>525.88</td>
    </tr>
    <tr>
      <td><i>VGG16</i></td>
      <td>339.73</td>
      <td>442.49</td>
      <td>212.06</td>
      <td>325.60</td>
    </tr>
  </tbody>
</table></div><p>‍</p><p>‍</p><p>‍</p><figure id="w-node-81c38bb21f8c-a8a0c0ce"><p><img src="https://assets.website-files.com/5f286b01a607cf5cd1531aa9/5f731993be0980f19dfb79a2_gpu_benchmark.svg" loading="lazy" alt=""></p><figcaption>Speedup of RTX 3090 over Titan RTX</figcaption></figure><p>‍</p><p>We're able to achieve a 1.4-1.6x training speed-up for all the models training with FP32! As expected, the FP16 is not quite as significant, with a 1.0-1.2x speed-up for most models and a drop for Inception.</p><p>‍</p><p>Please get in touch at <a href="mailto:hello@evolution.ai">hello@evolution.ai</a> with any questions or comments!</p></div></div></div></div>]]>
            </description>
            <link>https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628189</guid>
            <pubDate>Tue, 29 Sep 2020 14:24:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going from JavaScript to WebAssembly in Three Steps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627952">thread link</a>) | @jasperk
<br/>
September 29, 2020 | https://engineering.q42.nl/webassembly/ | <a href="https://web.archive.org/web/*/https://engineering.q42.nl/webassembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://engineering.q42.nl/content/images/size/w300/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 300w,
                            https://engineering.q42.nl/content/images/size/w600/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 600w,
                            https://engineering.q42.nl/content/images/size/w1000/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 1000w,
                            https://engineering.q42.nl/content/images/size/w2000/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://engineering.q42.nl/content/images/size/w2000/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png" alt="Going from JavaScript to WebAssembly in Three Steps">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>Hi! I'm Marcel, web developer at <a href="https://www.q42.com/">Q42</a> and creator of the <a href="https://micr.io/">Micrio storytelling platform</a>.</p>
<p>In 2015, I started developing a JavaScript viewer for ultra high resolution 2D and 360° images with added markers, tours, audio, and more. Since then, I've been pushing to find the best balance between hardware performance, minimal CPU and bandwidth use, and compatibility for older browsers to deliver a sharp and high quality viewing experience.</p>
<p>For Micrio, it is vital that the performance on the client's browser is as good as possible. The reason for this is very simple: when you are being told a story, or watching a movie, even <em>a single frameskip</em> immediately takes you out of your experience.</p>
<p>Since Micrio is being used for an <a href="https://micr.io/showcases">ever growing list</a> of awesome projects, the most important thing is that for whoever visits a Micrio project, it must work, and <em>work well</em>: delivering fast load times, and a butter smooth interactive experience.</p>
<p><a href="https://webassembly.org/">WebAssembly</a> (Wasm) is the ability for your browser to run <em>compiled</em> code at (near-) native speeds. It is now recognised by the W3C as the <a href="https://www.w3.org/2019/12/pressrelease-wasm-rec.html.en">4th official web programming language</a>, after HTML, CSS and JavaScript.</p>
<p>With it, you can run compiled code written in a variety of programming languages (C/C++, Rust, Go, AssemblyScript, <a href="https://github.com/appcypher/awesome-wasm-langs">and many more</a>) in your browser, without any need for plugins.</p>
<p>Finding out about Wasm in late 2019 really made me want to try it out. Could I use this tech to make the Micrio client run smoother than the current version does? Would I need to rewrite everything in C++, and if so, how would that work? Would the effort be worth the gains it would give me? And not in the least.. <em>how does it work!?</em></p>
<p>This article describes my journey from upgrading the Micrio <strong>JavaScript-only client to use WebAssembly</strong>, with the hopes of improving performance, and taking my code to the next level.</p>
<h3 id="thecurrentversion">The current version</h3>
<p>To give a rough idea about the tech stack of the current latest JS-only revision of Micrio (<a href="https://b.micr.io/micrio-2.9.min.js">version 2.9</a>): This library as a single JS file works on all semi-modern browsers, including even Internet Explorer 10 for 2D, and IE 11 for 360° images.</p>
<p>It uses Canvas2D for the rendering of 2D images, and <a href="https://threejs.org/">three.js</a>/WebGL rendering for 360° images. Written in <a href="https://caniuse.com/#search=es6">ES6 JavaScript</a> (or ECMAScript 6, the latest version of JavaScript), it still <a href="https://developers.google.com/closure/compiler">compiles</a> to ES5 to support Internet Explorer 11.</p>
<p>As you can imagine, displaying a <a href="https://micr.io/i/xCSYV/">231.250 x 193.750 pixel image</a> in your browser in a matter of milliseconds, allowing the user to freely zoom in and navigate, requires a little bit of processing power.</p>
<p>Now, Micrio 2.9 <em>isn't bad</em>. It runs pretty smoothly on all devices. But with WebAssembly around the corner, allowing all calculations to be done at native CPU speeds, this could potentially make a big difference in making Micrio's performance even better, and could improve the code architecture a lot.</p>
<p>And, perhaps, this could also mark the setup for a new major version, where I will draw a clear line and drop all compatibility and polyfills for older browsers: <strong>Micrio 3.0</strong>.</p>
<h2 id="firstrewritecandemscripten">First Rewrite: C++ and emscripten</h2>
<p>As a first step into the world of WebAssembly, getting to know the ecosystem, I started to play around with <a href="https://emscripten.org/">emscripten</a>. With it, you can take almost any project made in C or C++, and compile it to a binary <code>.wasm</code> file that your browser can natively run.</p>
<p>At this point, I didn't really have a clear image of where WebAssembly starts and ends, and how autonomously it could run inside your browser. So I started a new project from scratch to see if I could make a C++-implementation of the basic Micrio logic: a virtual <em>zoomable</em> and <em>pannable</em> image consisting of a lot of separate tiles, using a virtual camera for displaying only the tiles necessary for what the user is viewing inside your screen.</p>
<p>It turns out, emscripten already had great compatibility for <a href="https://www.libsdl.org/">libsdl</a>: a low-level audio, keyboard/mouse input, and OpenGL library. Which is awesome, because I could write my code using this very well documented library, even including mouse and key inputs and WebGL rendering. Since I was also working with downloading images, I also used the <a href="https://github.com/nothings/stb">stb_image.h</a> image library.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/cpp.png" alt="Setting up SDL and OpenGL" title="C++ in the 21st century"></p>
<p>The largest struggle of this was picking up C++ again, never having used it outside of hobby scope many years ago. But after a few days of cursing and second guessing myself, I had a working first version with all of the most important features written with help of the SDL library:</p>
<ul>
<li>A virtual camera and all necessary viewing logic;</li>
<li>Image tiles downloading;</li>
<li>Rendering using WebGL(/OpenGL) using a simple shader;</li>
<li>Mouse event handling for panning and zooming the image;</li>
<li>Resize event handling to fit Micrio to the desired <code>&lt;canvas&gt;</code> HTML element</li>
</ul>
<p>You can see this version running here: <a href="https://b.micr.io/_test/wasm/index.html">https://b.micr.io/_test/wasm/index.html</a> :</p>
<p><a href="https://b.micr.io/_test/wasm/index.html"><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/emscripten.png" alt="Micrio in native C++"></a></p>
<h3 id="firstresults">First Results</h3>
<p>As incredibly awesome it was to see Micrio in C++ running smoothly in my browser, and even handing all the user's input, there were a few reservations, which left me with an unsatisfied feeling.</p>
<h4 id="1codingcfeltoldfashioned">1. Coding C++ felt old-fashioned</h4>
<p>Writing C++ felt like going back in time. Incredibly powerful and fully proven, but also archaic, especially for me as a web developer. I spent more time fiddling with making an optimized <code>Makefile</code> than I care to admit.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/makefile.png" alt="The emscripten C++ Makefile" title="( ͡° ͜ʖ ͡°)"></p>
<h4 id="2thecompiledwasmbinarywasverylarge">2. The compiled <code>.wasm</code> binary was very large</h4>
<p>As great as the help of <code>libsdl</code> and <code>stb_image.h</code> were to let me use OpenGL and JPG image functions, as much did they add to the final compiled binary file. Even with all <code>emcc</code> compiler optimizations (which can even use the awesome <code>closure</code> JS compiler), the resulting WebAssembly binary file was 760KB. Compared to the JavaScript version of Micrio being around 240KB, this was a major setback. These libraries packed a lot of functionalities that were not necessary for Micrio, but were still included in the compiled version.</p>
<h4 id="3tilagluefile">3. TIL: A <em>glue</em> file</h4>
<p>This is the part where I learnt where the limits of WebAssembly start and finish. <strong>WebAssembly is not a magical self-contained binary that lets you run full applications out of the box</strong>. It actually needs to be <em>bound</em> to the browser using JavaScript.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/glued.png" alt="glue clipart"><br>
<small><a href="http://www.clker.com/clipart-13445.html">Image source</a></small></p>
<p>Where I thought that all the SDL OpenGL code in C++ would automagically be recognised by the browser: <em>wrong</em>. What <code>emscripten</code> does, is to take all OpenGL operations from C++, and <em>convert them</em> to WebGL operations your browser can understand.</p>
<p>Same with the <code>libsdl</code> mouse and keyboard-inputs: these were <strong>glued</strong> to the browser using an extra JavaScript file that would set event listeners for the specific cases, and send them to the WebAssembly binary. This separate JavaScript file was generated by the emscripten compiler, and had to be included in the HTML alongside the compiled binary <code>.wasm</code> file.</p>
<p>Everything added together, the new total of the <em>base engine</em> of Micrio was a whopping <strong>791KB</strong>; a bit too much for my liking.</p>
<h2 id="secondrewriteassemblyscript">Second Rewrite: AssemblyScript</h2>
<p>Fast forward a few months, to just after having attended the awesome <a href="https://webassembly-summit.org/">WebAssembly Summit</a> in Mountain View in February 2020. With a bundle of fresh energy and inspiration, I decided to see if I could use WebAssembly to improve the Micrio JavaScript client a second time.</p>
<p>During the WebAssembly conference, I was very impressed by a <a href="https://www.youtube.com/watch?v=C8j_ieOm4vE">synth demo</a> written in <strong><a href="https://www.assemblyscript.org/">AssemblyScript</a></strong>, a language created specifically for WebAssembly, using the TypeScript syntax. Basically you can write (near) TypeScript, which compiles to a <code>.wasm</code>-binary. So anyone familiar with either TypeScript or JavaScript ES6 will not have a lot of difficulties using it.</p>
<p>And the great thing-- it's all installed using <code>npm</code>, so <a href="https://www.assemblyscript.org/quick-start.html">getting it up and running</a> and compiling your program is super easy!</p>
<p>There are a few basic <a href="https://www.assemblyscript.org/types.html"><code>types</code> added in AssemblyScript</a>, which are required for compile-time optimizations:</p>
<ul>
<li><code>f64</code> / <code>f32</code> : For 64 or 32-bit floats;</li>
<li><code>i8</code> / <code>i16</code> / <code>i32</code> / <code>i64</code> : For signed <code>int</code>s, ranging in precision</li>
<li><code>u8</code> .. <code>u64</code> : For unsigned <code>int</code>s</li>
<li><a href="https://www.assemblyscript.org/types.html">And a few more</a></li>
</ul>
<h3 id="goingatomic">Going atomic</h3>
<p>This time, I wanted to see if it was possible to only let a small part of Micrio run inside WebAssembly, and still use most of the JavaScript that was already inside the client. <em>How small can we get it?</em> I decided to focus on a subset of camera functions, such as translating screen coordinates to image coordinates and vice versa. So this time no rendering, event handling, or writing shaders.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/assemblyscript.png" alt="Simple camera functions in AssemblyScript" title="My First AssemblyScript"><br>
<small><em>Simple camera functions in AssemblyScript</em></small></p>
<p>The result: a 3KB binary containing some basic math functions, that take an input and return an output. AssemblyScript offers some <em>glue-tooling</em> by providing its own <a href="https://www.assemblyscript.org/loader.html">Loader</a>, which will deal with importing the binary file and being able to call these functions.</p>
<p>However, this is optional and I ended up using the JavaScript <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/Using_the_JavaScript_API">WebAssembly API</a>, <em>neat</em>. And it turns out, this is super easy: simply use the <code>fetch</code> API to load your compiled <code>.wasm</code> file, cast it as an <code>ArrayBuffer</code>, and use the <code>WebAssembly.instantiate()</code> function to get it up and running.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/instantiate.png" alt="Loading a wasm file" title="Gluing it yourself"></p>
<p>The compiled binary will then offer an <code>exports</code> object, containing the functions that you have exported in the AssemblyScript file, which you can immediately call from JavaScript as if they were normal functions.</p>
<p>Wait.. "<em>which you can immediately call from JavaScript as if they were normal functions</em>"...</p>
<p><strong>WebAssembly is running synchronously to JavaScript!</strong> 🤯</p>
<p>Having worked with WebWorkers before, I honestly thought that WebAssembly would run inside its own CPU thread, and that any function calls would be <code>async</code>. Nope, the Wasm-functions you call will return immediately!</p>
<p><a href="https://www.assemblyscript.org/exports-and-imports.html#exports"><em>This is, like, powerful stuff</em>!</a></p>
<h3 id="bundlingthecompiledwasminsidethejsfile">Bundling the compiled Wasm inside the JS file</h3>
<p>Since I now had some extra performing hands on deck for Micrio that was very easy to integrate, I decided to include this minimal WebAssembly binary in the then-stable release of Micrio (2.9).</p>
<p>However, I didn't want an extra HTTP request for the Wasm binary every time someone loaded the Micrio JS. So I included a <code>base64</code> encoded version of the Wasm-file <em>inside</em> the Micrio JS, and for browsers that support it, auto-loaded that. As a …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.q42.nl/webassembly/">https://engineering.q42.nl/webassembly/</a></em></p>]]>
            </description>
            <link>https://engineering.q42.nl/webassembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627952</guid>
            <pubDate>Tue, 29 Sep 2020 14:06:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Saturated ASCII Text, the unknown markup language]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24627899">thread link</a>) | @oileurre
<br/>
September 29, 2020 | https://www.cs.ru.nl/~freek/books/sat.sat | <a href="https://web.archive.org/web/*/https://www.cs.ru.nl/~freek/books/sat.sat">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.cs.ru.nl/~freek/books/sat.sat</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627899</guid>
            <pubDate>Tue, 29 Sep 2020 14:01:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to convert more users when their trial expires]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627648">thread link</a>) | @pmuens
<br/>
September 29, 2020 | https://philippmuens.com/how-to-convert-more-users-when-their-trial-expires/ | <a href="https://web.archive.org/web/*/https://philippmuens.com/how-to-convert-more-users-when-their-trial-expires/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Your product offers a free trial but your users aren't converting when it expires?</p><p>Most of the time the worst part is that you don't have any data to figure out why users stopped using your product. Even if you reach out, feedback is usually sparse and often doesn't reveal any useful patterns you can look into.</p><p>In response to that, a lot of time and energy is usually spent tweaking the onboarding flow or marketing funnel.</p><p>But there's a simpler, better way to increase your conversion rates. Let's see how it works.</p><h2 id="why-a-free-trial-is-a-hard-sell">Why a free trial is a hard sell</h2><p>There's a lot of debate whether having a free trial is the best way to acquire new customers.</p><p>The clear upside of offering a free trial is that the barrier of entry is extremely low. An E-Mail address and a password is usually enough to get new users into the door. The more users you have onboarded, the more likely it is that they talk about your product in their peer groups and network (assuming it solves a real pain). Even better if your product has built-in functionalities which incentivize your users to invite others. This mix of Word-of-Mouth and network effects kick-starts the growth flywheel which will attract even more users. Rinse and repeat.</p><p>Eventually a small percentage of your overall user base converts and upgrades to a paid plan.</p><p>Hundreds of large-scale companies followed this exact playbook. Given their success it should be a no-brainer to follow this strategy as well, correct?</p><p>Despite the aforementioned upsides there are also clear downsides to this approach. Having more users usually translates into more customer support requests your support staff needs to handle. In addition to that it's tricky to get the math right such that you can use the revenue you generate via your paid plans to finance the resources and infrastructure necessary for your free trials.</p><p>There isn't a clear, definite answer whether you should offer a free trial or avoid it at all costs. At the end of the day it all comes down to the type of product you sell and the audience you're serving.</p><p>Regardless of the way you acquire new customers there's one metric you should monitor closely when onboarding new users: <strong>User engagement</strong>.</p><h2 id="the-core-problem-with-free-trials">The core problem with free trials</h2><p>Low user engagement is at the very core of problems related to free trials.</p><p>Given that one only needs an E-Mail address and a password to sign up for your product it's an easy decision to take the leap and give it a try. Testing it is free after all and who doesn't like getting something for free?</p><p>The issue is that finding the time to sit down and "work with it in the next couple of days" usually never materializes. Life gets in the way and sooner rather than later the trial expires and your users are locked-out, never to be seen again.</p><p>Sure, this isn't always the case but more often than not people just don't get around testing your product enough to uncover the benefits they'll experience when using it in their day-to-day to solve their problems.</p><h2 id="free-plans-and-asking-for-the-credit-card-upfront">Free plans and "asking for the credit card upfront"</h2><p>One solution to mitigate this problem is to offer a limited, "always free" plan. This way users will have enough time to tinker around and assess whether your product is worth its money. But this only kicks the can down the road as you'll likely face the same issue of low user engagement as before. In addition to that you open up a can of worms because now you have to deal with all the other challenges a free plan entails:</p><ul><li>Even more customer support</li><li>Figuring out what to offer in the free plan and what to put in the paid plans</li><li>Ways to incentivize powers users of your "always free" plan to upgrade</li><li>Increasing spent on infrastructure and other resources</li><li>...</li></ul><p>Another common strategy to solve the free trial dilemma is to "ask for the credit card upfront", meaning that users have to put in their credit card information when they sign up but they won't be charged after their trial expired. While asking for credit card information is a good way to filter out users who might never convert into paid customers it comes with the sames problems we just discussed.</p><p>Offering an "always free" plan or asking for the credit card upfront still doesn't solve the issue of low <strong>user engagement</strong>.</p><h2 id="how-to-solve-the-user-engagement-debacle">How to solve the user engagement debacle</h2><p>Now that we know why free trials and free plans are a tough sell it's time to tackle the underlying issue: <strong>Low user engagement</strong>.</p><p>Basic human psychology tells us that human beings value items more if they've spent money to acquire them. Think about the last time you got something for free vs. the time you spent money on a similar item. Chances are that you've used and valued the item you paid money for more.</p><p>This discovery can be used to inform the way how you can design your trial version to eventually convert more users into paying customers.</p><p>Rather than offering a free trial which expires in 30 days offer a paid version of that exact same trial.</p><p>Yes, you read that right. Turn your free trial into a <strong>paid trial</strong>.</p><h2 id="the-benefits-of-a-paid-trial">The benefits of a paid trial</h2><p>Offering a paid trial comes with a couple of major advantages:</p><ol><li>Only users who are seriously considering your product will sign up for the paid trial</li><li>It's more likely that your users will find the time to test your product because they paid for it</li><li>Your users value your product more compared to your competitors who offer a free plan / free trial</li><li>Your users are more committed to get the most value out of your product during the trial</li><li>Another huge point of friction is already removed from the conversion process (asking to put in the credit card information and subscribe to a paid plan)</li></ol><p>In fact, I learned about the power a paid plan can have from a personal experience. Given my growing interest in SEM, SEO and marketing in general I did some research to figure out what tools the market has to offer in that space.</p><p>In particular I was looking for a tool which would help me conducting Keyword Research, Backlink analysis and SEO monitoring. What I stumbled upon was the well-known tool Ahrefs.</p><p>However what struck me was that compared to their competitors their pricing structure was different. There was no "Free trial". I had to pay 7 USD to get access to the tool for 7 days. After some hesitation I decided to give it a shot and try it for the next 7 days. In fact, I spent a significant amount of time upfront, learning and researching everything I could about their toolings to figure out if their paid trial would be really worth it.</p><p>Needless to say that I used Ahrefs every single day during that week. The felt "pressure" to get the most out of the 7 days in combination with their excellent, educational E-Mail sequence helped me to explore all the values their tool has to offer. I'm absolutely certain that their conversion rates from paid trial to paying customer aren't too shabby.</p><figure><img src="https://philippmuens.com/content/images/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png" alt="" srcset="https://philippmuens.com/content/images/size/w600/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png 600w, https://philippmuens.com/content/images/size/w1000/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png 1000w, https://philippmuens.com/content/images/size/w1600/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png 1600w, https://philippmuens.com/content/images/size/w2400/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Ahrefs 7-day trial for $7</figcaption></figure><h2 id="your-challenge">Your challenge</h2><p>Do you have a free plan, free trial or are thinking about introducing such a plan in the near future?</p><p>I'd challenge you to take a step back and think about offering a paid trial instead. Your paid trial shouldn't be too expensive but it should be enough that your users are incentivized to explore your product in more depth. Combine your paid trial with a helpful, educational E-Mail onboarding sequence and check-in with your users every now and then to understand what their problems are and to help them succeed.</p><p>I'm certain that this will help you tackle any conversion-related problems you might be facing!</p><h2 id="conclusion">Conclusion</h2><p>Converting users you've attracted via a free trial or a free plan to become paying customers is hard. There are a couple of issues one has to be aware of. It's tough to get the math right and take the profits you made from your paid plans to offset the costs you'll introduce by offering a free plan / free trial. While it's highly likely that you'll get new users using your product you'll also experience an increase in customer support requests and an almost guaranteed low conversion rate.</p><p>One of the underlying core problem with all this is a lack of user engagement. Paid products are valued more than free ones.</p><p>You can use this fact and offer a paid trial which incentivizes your users to take action and explore the values your product has to offer. Having a more engaged user base helps you tackle the conversion-related problems you might be facing.</p><p>I hope that you enjoyed this article and I'd love to invite you to subscribe to my Newsletter if you're interested in more, action-oriented posts like this.</p><p>Do you have any questions, feedback or comments? Feel free to reach out via E-Mail or connect with me on <a href="https://twitter.com/pmmuens">Twitter</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://philippmuens.com/how-to-convert-more-users-when-their-trial-expires/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627648</guid>
            <pubDate>Tue, 29 Sep 2020 13:38:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microservices – architecture nihilism in minimalism's clothes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627616">thread link</a>) | @vlfig
<br/>
September 29, 2020 | https://vlfig.me/posts/microservices | <a href="https://web.archive.org/web/*/https://vlfig.me/posts/microservices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some recent <a href="https://twitter.com/gergelyorosz/status/1247132806041546754" target="_blank" rel="nofollow noopener noreferrer">backtracking</a> <a href="https://twitter.com/copyconstruct/status/1247130488667394049" target="_blank" rel="nofollow noopener noreferrer">from</a> what we have been calling “Microservices” has sparked anew the debate around that software architecture pattern. It turns out that for increasingly more software people, having a backend with (<a href="https://www.infoq.com/presentations/monzo-microservices/" target="_blank" rel="nofollow noopener noreferrer">sometimes several</a>) hundreds of services wasn’t that great an idea after all. The debate has <a href="https://riak.com/posts/technical/microservices-please-dont/" target="_blank" rel="nofollow noopener noreferrer">been going on for a while</a> and much has already been said, but there are still a couple of things I’d like to say.</p>
<p><strong>TL;DR</strong> “Microservices” was a good idea taken too far and applied too bluntly. The fix isn’t just to dial back the granularity knob but instead to 1) focus on the split-join criteria as opposed to size; and 2) differentiate between the project model and the deployment model when applying them.</p>
<p>I explain. Allow me to rant a bit first.</p>


<p>There were three main reasons for the initial success of <em>microservices</em> as an architectural pattern for software: 1) forced modularisation, 2) weakened dependencies, and 3) an excuse for having no architecture. In order:</p>
<ol>
<li>In the monoliths of old, you could in theory enforce module boundaries. You could say that your <code>acme-helpers</code> or <code>acme-data-tools</code> could not depend on <code>acme-domain</code>, say, and you even had some tooling to enforce that, but it was fallible. Especially in big companies where these monoliths spanned more than a team’s cognitive horizon, violations of those boundaries were often a simple <code>import</code> away, and of course rife. Angry architects saw in microservices the promise of making those a thing of the past: now the developer is forced to only deal with the API. Codebases parted ways and calls were made to go down the network stack and back.</li>
<li>
<p>So then, one wouldn’t depend on a fellow service at build time, only at runtime. Great. Method calls became http calls. “Now we don’t need to care about dependencies” — actual people said this, as if the dependency wasn’t fundamental and instead just an accidental artifact of the build setup. Everybody brushed up on their HTTP and different server and client implementations, read all about REST and Soap (and RPC, RMI and CORBA while at it) and merrily created a layer of indirection between modules — now <em>services</em> — that was <em>very</em> loose. Typed APIs, granular network policies and contract testing came much later.</p>
<p>It felt liberating until the complexities of API versioning, delivery semantics, error propagation, distributed transaction management and the sprawl of client code in all callers of a service began to show up. This was a gigantic <strong>shift right</strong>, but hey, the build process was simpler.</p>
</li>
<li>
<p>More insidious perhaps was the validation that “doing microservices” brought to organisations that lacked a thesis about how their architecture should be. There was now a sanctioned answer to most architectural dilemmas: another microservice. Another entry in the service catalog for any and all interested parties to call. This ecology of interacting parties, each acting in their own interest for the common good spoke to an underlying, tacit belief that the emergent mesh of services would approximate the latent natural architecture of the domain.</p>
<p>So soft and convenient was the lure of not having to draw hard architectural lines that we got lazy where we weren’t and accepted our lazyness where we already were. If you didn’t subscribe to that belief, the problem was you and your lack of understanding of complex systems, you objectivist cretin.</p>
</li>
</ol>
<p>Yes, there was real pain in managing monoliths and sure, many systems were too monolithic (i.e. had deployables too large) but the zealotry of a newfound purity swung the pendulum too far, as they always do. Not only do we not need to run so many services so small, we also don’t benefit from isolating their codebases so much. To summarise:</p>
<ol>
<li>having a big flat permissive build is no good reason to split deployables;</li>
<li>weakening dependencies between different parts of our systems is a “shift-right” loan with high interest; and</li>
<li>having a ready answer when the thinking gets tough is a soothing lie that just moves complexity about. There is no substitute to the effortful application of cognitive power to a problem.</li>
</ol>

<p>Two things: focus on the right criteria for splitting a service instead of on its size, and apply those criteria more thoughtfully.</p>
<h2 id="size-is-not-the-answer"><a href="#size-is-not-the-answer" aria-label="size is not the answer permalink"></a>Size is not the answer</h2>
<p>The <em>micro</em> in microservices ought to be at best a prediction, never a goal. We may predict services <em>will be</em> micro but they don’t <em>have to be</em>. <a href="https://kalele.io/microservices-and-microservices/" target="_blank" rel="nofollow noopener noreferrer">Vaugh Vernon is right</a> when he speaks about “cohesion for a reason”.</p>
<p>There should be no prescribed <em>a priori</em> granularity of services. There <em>is</em> no prescribed size of a service. There are instead <strong>good and bad reasons to split</strong> parts of a software system.</p>
<p>So the heuristic is:</p>
<div data-language="text"><pre><code>                      Start one, split with a reason.</code></pre></div>
<p>Conversely, if a reason ceases to exist, consider joining them.</p>
<h2 id="the-missing-hinge"><a href="#the-missing-hinge" aria-label="the missing hinge permalink"></a>The missing hinge</h2>
<p>There are however different realms in which “software systems” exist: they exist both as artifacts we interact with and as artifacts computers interact with. Code and binary. We organise them in different ways: the <strong>project model</strong> (repositories, projects, modules and their dependencies) and the <strong>deployment model</strong> (what production environments look like and how deployables run in them).</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A monolithic setup where one big repo builds one single big deployable." title="A monolithic setup where one big repo builds one single big deployable." src="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg" srcset="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/09b79/monolith.jpg 240w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/7cc5e/monolith.jpg 480w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg 960w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/644c5/monolith.jpg 1440w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg 1463w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A monolithic setup where one big repo builds one single big deployable.</p></figcaption>
  </figure>
<p>In the process of going from coarse to granular (i.e. from monolith to microservices) however, little attention was paid to the difference — and possible indirection — between those two models. The hammer hit both fairly indiscriminately and made us split codebases because of runtime concerns and split deployables due to project concerns.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A set of repositories each building their own self-contained independent service." title="Excessive mirroring between the project and deployment models." src="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg" srcset="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/09b79/stiff-1-1.jpg 240w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/7cc5e/stiff-1-1.jpg 480w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg 960w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg 1062w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Excessive mirroring between the project and deployment models.</p></figcaption>
  </figure>
<p>Much like stiffness in a part of the human spine can result in pain in another, <strong>stiffness in our build DAGs is causing excessive mirroring between our project and deployment models</strong>; between our repositories and our services; between the way we organise our code and the way our services run. That mirroring is on the one hand preventing us from shifting left concerns about the relationships between modules that have often been made weak and fragile runtime dependencies, while on the other hand encouraging us to have more services than what the runtime reality would call for. That brings pain.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The build DAG as a hinge between the project model and the deployment model." title="A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly." src="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg" srcset="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/09b79/hinge.jpg 240w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/7cc5e/hinge.jpg 480w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg 960w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg 1335w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly.</p></figcaption>
  </figure>
<p>Central to resolving this stiffness is the realisation that the build flow, at least conceptually, is a DAG – Directed Acyclic Graph – where the nodes are <em>jobs</em> and <em>versioned artifacts</em> and the edges connect either a job to a versioned artifact (“produces”) or a versioned artifact to a jobs (“dependency_of”). Deployables are by definition the versioned artifacts that are consumed by the deployment jobs.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." title="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." src="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg" srcset="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/09b79/dag.jpg 240w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/7cc5e/dag.jpg 480w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg 960w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg 1384w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A graph of two types of nodes, jobs and versioned artifacts, connected by edges ‘dependency_of’ and ‘produces’. Versioned artifacts can be further specialised.</p></figcaption>
  </figure>
<p>For too long we overlooked how much a flexible and frictionless build DAG allows us to improve our architecture on both sides. With moderately rich build patterns we can have our code where its intent is clearer and more constraints can be validated at build time and still have it deployed into its simplest viable form, running where its execution is cheaper, faster and safer.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Cheesy cisgender, neurotypical westernised image of a wedding altar with the build dag marrying developer effectiveness with mechanical sympathy." title="Sorry. I had to." src="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" srcset="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/09b79/wedding-altar.jpg 240w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/7cc5e/wedding-altar.jpg 480w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg 612w" sizes="(max-width: 612px) 100vw, 612px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Sorry. I had to.</p></figcaption>
  </figure><p>.</p>
<h3 id="why-so-stiff-bro"><a href="#why-so-stiff-bro" aria-label="why so stiff bro permalink"></a>Why so stiff, bro?</h3>
<p>I’m not sure what the historically accurate account is that would explain the excessive simplicity of build patterns across the industry. I do know from experience that too many practices make do with very simple and linear flows where one repository builds independently one and only one service. Regardless of the legitimate argument about code duplication and its tradeoffs, there seems to be an aversion to build-time internal dependencies, even when these bring in clearly desirable data or logic such as message format definitions.</p>
<p>I suspect it might have something to do with how very few CI tools support composition natively (i.e. the outputs of jobs being able to be the inputs of others), how fallible semantic versioning in practice is and the difficulty of automating deterministic version propagation.</p>
<p>By that I mean keeping local copies in sync with CI, builds repeatable, and new upstream versions automatically used by their downstream dependents. It isn’t trivial and requires some versioning and build-fu that, to my knowledge, most practices end up shortcutting to either sacrifice repeatability by using <code>latest</code> or stifling the flow by requiring repeated manual work. Hence the pressure to have a simple build setup.</p>
<p>The exact cause is unimportant though. What is important is that overcoming this is crucial.</p>

<p>Many criteria for splitting or joining software systems, ranging from the social (teams, bounded contexts) to the mechanical (cpu or io boundedness) have been put forth, and they all make some form of sense. However, most of them are either a good reason to split projects or modules, or a good reason to split deployables, rarely both. Keeping that in mind will help us apply them more effectively.</p>
<p>Below are a few possible criteria and some comments about their application. I’m not trying to be exhaustive, just illustrating the kind of reasoning makes sense to me.</p>
<h2 id="runtime-deployment-side-criteria"><a href="#runtime-deployment-side-criteria" aria-label="runtime deployment side criteria permalink"></a>Runtime, deployment side criteria</h2>
<ul>
<li><strong>Different Runtime</strong> – If a part of the codebase compiles to a different runtime it becomes a different deployable and we call it a different service.</li>
<li><strong>Elasticity Profile</strong> – Some parts of the system may have a spikier load profile. It might pay off to have them scale in and out separately from the rest.</li>
<li><strong>Load Type</strong> – Some parts of a generally latency-oriented io-bound system may generate occasional peaks of cpu-bound load which can hurt response times. It might be better to put them in a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vlfig.me/posts/microservices">https://vlfig.me/posts/microservices</a></em></p>]]>
            </description>
            <link>https://vlfig.me/posts/microservices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627616</guid>
            <pubDate>Tue, 29 Sep 2020 13:34:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Indian festival goes high-tech]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24627261">thread link</a>) | @mtmail
<br/>
September 29, 2020 | https://restofworld.org/2020/india-magh-mela/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/india-magh-mela/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>I</span>t’s 3:13 a.m., and Radio Inspector Ashok Kumar turns around to look at his computer. His face stiffens. He zooms in on the screen and squints at an unauthorized SUV crossing a pontoon bridge.</p>



<p>Kumar and his team are in the Integrated Command and Control Center (ICCC) overlooking operations for this year’s Magh Mela, an annual Hindu pilgrimage and festival that draws millions of people in a single day. Each year, devotees from all across the country congregate at the spot where the Ganges, Yamuna, and mythical Saraswati rivers converge at Prayagraj in the northern Indian state of Uttar Pradesh. There, devotees dip in the water, which they believe cleanses them of their sins.</p>



<p>It is here at the ICCC, a big white room with two rows of desks, that the police keep a vigil over the mela (the Hindi word for “fair”). At each terminal, policemen hunch over computer screens as they monitor feeds from around 700 closed-circuit TV cameras. A video wall dominates, with 55-inch screens arranged in a 10 by 2 matrix along the length of the room. Khaki jackets emblazoned with “Uttar Pradesh Police” hang on the backs of the chairs. Tapping their shoeless feet on the carpeted floor, the officers glance at each other regularly, followed by tentative nods implying that everything is fine.</p>



<p>The monitoring team is on high alert. Kumar and his team have been here since 8 p.m. last night, on a 12-hour shift, and the first bathing rituals began at 3 a.m. Today is February 9, and it is the full moon day of Maghi Purnima. Police are expecting a crowd of 7.5 million — down from a single-day peak of 11 million two weeks earlier. Millions of pilgrims will be leaving after today’s dip. Many are joined by their families, who have come to take them home.</p>



<p>Kumar’s job is to keep this massive crowd under control. Stampedes, terror attacks, and theft are on his mind. He places a call, and minutes after the SUV is vetted, a police officer appears on-screen to set up a barricade at the foot of the bridge.</p>



<p>Outside, as LED lights switch off, an easterly sunrise turns the sky several shades of crimson. On the water, the boats stand out in silhouette. The air contains a mix of piety and festivity.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela077-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela077-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela077-1-2800x1575.jpg 2800w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela077-1-1600x900.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela077-1-768x432.jpg 768w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>

    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela011-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela011-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela011-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela011-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela011-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela011-2800x1867.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela009-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela009-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela009-1-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela009-1-600x400.jpg 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>Police from the Integrated Command and Control Centre monitor the crowd of devotees with around 700 closed-circuit TV cameras.</figcaption>
    </figure>


<hr>



<p><strong>The Magh Mela</strong> is a smaller version of the<a href="https://en.wikipedia.org/wiki/Kumbh_Mela"> Kumbh Mela</a>, the<a href="https://en.wikipedia.org/wiki/List_of_largest_peaceful_gatherings"> largest human gathering</a> on earth. The Kumbh is held every six years, and the previous one was held in 2019. Over 49 days last year, more than 250 million people took a dip in the <em>sangam</em>, the point where the three rivers meet, with the biggest one-day crowd reaching 50 million. It was the second-largest <a href="https://en.wikipedia.org/wiki/List_of_largest_peaceful_gatherings">gathering</a> in history.</p>



<p>To prepare for the melas, tens of thousands of officials spend months setting up a massive temporary city on the banks of the Ganges. Viewed from above, it is a colorful patchwork divided by big and small bodies of water. Much of this — tents, floating bridges, and metal sheet roads — is built specifically for the festival. As the riverbed floods every year, the city lasts for only several months before the Ganges threatens to reclaim the land.</p>



<p>The physical structure of the mela changes each year, depending on the river. The groundwork usually starts in October, after monsoon season, when the Ganges retreats. Temporary roads are marked, and pontoon bridges are built to join land separated by water. Jetties are built on the banks; the roads are lined with metal sheets; pipelines and electricity cables are laid. Bathing stations are set up along a 3-mile floating jetty, with nets spread underneath to catch those who fall in.</p>



<p>This year, the Ganges’ water levels remained high later than usual. “We could reclaim land only by the end of November, but heavy rains kept hampering civil works until December,” says Rajneesh Mishra, a civil servant who oversees the Mela. This year’s mela was spread over 270 hectares (667 acres), about 30% bigger than Monaco, and divided into six sectors for administrative purposes. Setting up the infrastructure was — and is — an immense logistical feat. The mela has 13 police stations, 40 police outposts, and five thermal power stations. There are five hospitals with operation theaters and 25 beds each, as well as labs, testing facilities, and on-site ambulances.</p>



<p>All of this requires a substantial budget. For this year’s mela, the state<strong> </strong>government budgeted $77 million. Last year, for the Kumbh, it spent $558 million.</p>



<p>All IT operations for the festival are run by the ICCC, which is based in a three-story concrete building that was inaugurated a little over a year ago by Prime Minister Narendra Modi. It’s one of the few permanent structures in the mela area, besides a temple and a 16th-century fort. The center itself is divided up between the monitoring room, which uses a video surveillance system to keep a bird’s-eye view on the mela; the wireless grid room, which liaises between monitors and the ground staff; the war room, where personnel from the fire, water, and police departments as well as the military are on hand at all hours to deal with emergencies; and, finally, a call center.</p>



<p>The key tool in the ICCC’s arsenal is the crowd management application (CMA) system, which keeps an eye on crowd density across all 700 camera feeds. The system is taught how much ground area each CCTV camera covers, which then allows it to estimate, with 85% accuracy, the number of people in a space at any given time. If there are more than three people per square meter, the system issues a warning, and the ground police team is notified and instructed to stop, hold, or divert the crowd.</p>



<p>The Prayagraj Smart City Mission team, which oversees the ICCC, considered various methods for crowd management before settling on the CMA. One option was to estimate crowd size by measuring an area’s smartphone density. But this idea was quickly scrapped. Most devotees at Magh Mela are not smartphone users, says assistant manager Vipin Singh. Only <a href="https://www.news18.com/news/tech/smartphone-users-in-india-crossed-500-million-in-2019-states-report-2479529.html">500 million</a> people in India — roughly one-third of the population — own smartphones. Additionally, many families share one phone, and rural residents (who form as much as 95% of mela attendees, according to police estimates) often don’t use them at all. “If the system shows three people,” says Singh, “there might actually be 100, where 97 are carrying basic mobile phones or no phones at all.”</p>



<p>Last year, officials also experimented with a facial recognition system. The idea was that the technology would provide accurate headcounts, track patterns of movement, and measure time spent between distinct points. But that didn’t work either, as people often carry big bags on their heads as they navigate mela crowds. That meant that, for every face the system could see, a piece of luggage might conceal several more.</p>



<p>Cars have proven easier to track. The automated number plate recognition (ANPR) system records the license number of every vehicle entering or exiting the city, checking it against a database containing the license numbers of stolen vehicles and ones involved in crimes. If a match is found, an alert goes off. For this Magh Mela, says Singh, the administration installed ANPR-aided cameras at eight locations on the city’s periphery. But there are plans to ramp up. “For the next mela,” he says, “we’re looking to increase this to 28 locations.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela107-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela107-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela107-1-2800x1575.jpg 2800w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela107-1-1600x900.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela107-1-768x432.jpg 768w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>It’s 7:17 a.m.</strong> Mamta Sharma<strong> </strong>stands knee-deep in the river.</p>



<p>Facing east toward the Ganges, she presses her hands in a namaste. She bows her head several times and chants a prayer under her breath. And then she takes a dip in the river, repeating it four times.</p>



<p>Seagulls glide over the heads of bowing devotees, but neither seem to mind the other. When pilgrims toss bits of fruit into the river, the seagulls scoop them up before they land in the water.</p>



<p>Some devotees hire boats to get to the point believed to be the exact location where the three rivers meet. There, people offer their respects to the river, take dips, and fill plastic cans with sacred water. At the <em>sangam</em>, you can see colors mixing, says boatman Ajay Nishad. “The whitish water is that of the Ganges, and the black that of the Yamuna,” he says. Stare long enough and one might think that he is right.</p>



<p>People who can’t afford to hire a boat, which is most pilgrims, instead bathe close to the bank. The mela administration encourages this to avoid overcrowding.</p>



<p>Sharma comes out of the river. Still dripping, she makes a video call to her mother, who could not come with her. She pans her phone to show the <em>sangam</em> to her mother, who offers namaste multiple times, her eyes welling up.</p>



<p>While she dries off, Sharma keeps looking up expectantly. On some auspicious days, the mela administration showers flowers on bathing devotees from a helicopter. She has seen videos of it on social media. “We were all excited about it, but it hasn’t happened today,” she says.</p>



<p>“Still, the holy dip is quite an experience.”</p>



<p>Sharma, who lives in Kolkata in eastern India, has come to the Magh Mela with a group of 12. They live in different cities but come from the same family in Jaunpur, over 100 kilometers from here. Most are elderly. At 31, Sharma is the youngest.</p>



<p>Nishad, the boatman, has been ferrying visitors to the <em>sangam</em> for three years, and he says the melas are always very well organized. Police designate holding areas to keep people safe when crowds swell, and are good at managing foot traffic to prevent bottlenecks. While it can take several hours to find missing people — pilgrims getting separated is a common problem at melas — he says the administration always tracks them down.</p>



<p>But, lately, he has noticed something new. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/india-magh-mela/">https://restofworld.org/2020/india-magh-mela/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/india-magh-mela/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627261</guid>
            <pubDate>Tue, 29 Sep 2020 13:05:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audrey Tang on her “conservative-anarchist” vision for Taiwan’s future]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627208">thread link</a>) | @leoschwartz
<br/>
September 29, 2020 | https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>“Civil Rap Song,” a <a href="https://www.billboard.com/articles/news/international/9392471/japan-dos-monos-civil-rap-song-taiwan-digital-minister-audrey-tang-watch-new-video">track</a> by the Japanese hip-hop trio Dos Monos, begins not with an MC’s rhymes but a faraway voice speaking slow, bureaucratic English. The deconstructed audio is sampled over gloomy synth:<em> “If you overemphasize … amplifying the public and private sector … where is the civic sector? … where is the social sector?”</em> Made in less than a week during Japan’s state of emergency over Covid-19, the track was intended to be “culturally empowering,” according to a band member — a way to remind the public that it still had choices, even in the midst of a crisis.</p>



<p>The speaker in the song is 39-year-old Audrey Tang, a prodigy hacker turned activist turned digital minister in the Taiwanese government. Tang, who wears rimless glasses and dark, baggy clothes by Issey Miyake, does not fit the profile of a rapper’s muse. Yet over the course of the coronavirus pandemic, which her country has managed with singular, tech-enabled ease, she has become an international messenger of Taiwan’s “radically transparent” “digital democracy.” For Tang, the Taiwanese model offers an imitable middle ground: between the internet and personal privacy; between corporate interests and the welfare state.</p>



<p>Before Covid-19, you may have heard of Tang if you followed Taiwanese news, tech gossip, or transgender politics. She is considered one of Taiwan’s top coders, having taught herself the programming languages Haskell and Perl before developing software for Apple that would be used in Siri. In the spring of 2014, when news that Taiwan’s then-president Ma Ying-jeou had threatened the island nation’s independence by attempting to force through a trade deal with China, Tang quit a job at Socialtext, where she worked on Google Suite–like productivity software, to join a scrum of hackers gathered outside the main government building in Taipei. This was the beginning of the Sunflower Movement, a popular uprising against the prospect of national absorption, and Tang helped broadcast the protests and debates online. After a nearly monthlong occupation, Ma was forced to abandon the pact, and the Sunflower activists turned to political organizing. They successfully ran progressive candidates in the 2014 local elections and, in 2016, elected Tsai Ing-wen as president. Tsai’s administration recruited Tang to become the first out transgender person in Taiwan’s executive cabinet.</p>



<p>While Tang’s title is “digital minister,” she is a minister without a ministry. As one of nine <a href="http://www.politicseastasia.com/research/audrey_tang_interview/">“horizontal ministers,”</a> she advises other parts of the government on all things tech — and, because she happens to be obsessed with the U.N.’s Sustainable Development Goals — environmental overlaps. In 2017, for instance, she and her staff worked with the Ministry of the Interior and a risk-management agency to combine separate systems used to prevent and respond to natural disasters. Upon Tang’s recommendation, the government agreed to implement a new cloud-based interface to trim costs and give the public quick, easy access to information on floods, fires, and extreme weather. Last year, during the second <a href="https://www.roc-taiwan.org/uk_en/post/6295.html">“presidential hackathon,”</a> an annual event that invites startup-style ideas for governance, she helped facilitate the development of a solar-powered device that can measure and log water-pollution levels on an open-source blockchain. Soon, any citizen worried about downstream industrial waste will be able to buy a few of these monitors, drop them in a creek, and create a dataset to hold corporations and local officials accountable to environmental regulations.</p>



<p>This is clearly government work, but Tang, at her core a hacker iconoclast, bristles at the notion that she works <em>for </em>Taipei. She still prefers to see herself as a liaison, or, in her words, “a moderator or editor,” between the public and the state. This explains why Tang — though not a doctor or epidemiologist — found herself at the center of Taiwan’s response to Covid-19.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/ARX_ROW_AT_00054-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/ARX_ROW_AT_00054-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/ARX_ROW_AT_00054-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/ARX_ROW_AT_00054-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/09/ARX_ROW_AT_00054-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/09/ARX_ROW_AT_00054-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/09/ARX_ROW_AT_00054-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p>When rumors of a dangerous flu emerged from Wuhan, China, last December, the Taiwanese reacted fast. Carrying the memory of the 2003 SARS epidemic, they rushed to buy face masks, threatening to deplete local supplies. In the city of Tainan, an engineer named Howard Wu created a fix: a mapping system to track available masks, using Google GPS and Places API. The platform was an immediate hit. Tang reached out to Wu and secured funding from Google to support and extend the project, which eventually inspired a similar system in South Korea. By spring, the Taiwanese government was managing the supply and distribution of cheap N95-type masks through neighborhood pharmacies. All 24 million residents of Taiwan could buy a certain number per week, at any pharmacy, based on their national health insurance card. Long lines got shorter, and people went about social distancing with confidence. The success of this model — Taiwan has had fewer than 500 total cases and just seven deaths — was what attracted the Dos Monos rappers to Tang.</p>



<p>It helped that, in East Asia, masks were “already ‘natural’ before the pandemic; we didn’t have to invent new things,” Tang said. In response to the common, mostly Western critique that East Asian technocracy relies too much on digital surveillance, Tang explained that Taiwan’s containment method involved “a deep but very narrow and time-limited privacy infringement: You either, when flying back, go to the quarantine hotel for 14 days, or you can choose the digital fence,” that is, submit to strict tracking. “We do not collect new data,” she added. “It’s not a new app. It’s not GPS. People understand it’s proportional.” Taiwan also invested in fact-checking startups and enlisted comedians to craft lighthearted responses to Covid-19 disinformation and consumer misbehavior. In a public-service announcement intended to stem panic-buying of toilet paper, a cartoon version of Tang’s boss, Premier Su Tseng-chang, shimmies his rear end beneath the <a href="https://qz.com/1863931/taiwan-is-using-humor-to-quash-coronavirus-fake-news/">words</a>, “You only have one butt.”</p>



<p>When I spoke with Tang via Skype in July, she referred to Taiwan as “post-pandemic.” The country had never shut down completely, and its streets, markets, and schools were beginning to feel normal. She had just made her morning commute in downtown Taipei, a 15-minute walk from Da’an Park, past the Jianguo flower market, to a broad concrete complex surrounded by lush trees. There, in an open-air arcade that once belonged to the air force, is the Social Innovation Lab, the headquarters of Tang’s digital non-ministry. She dialed in from her office, which resembled the lounge of a coworking space. A vertical Chinese scroll hung over her right shoulder: “More and more graceful every day.”</p>



<p>Tang had been holding public “office hours” on Tuesdays and Wednesdays and was booked through September to chat with locals about tech and government policy, entrepreneurship, and sustainability. Nearly all her interactions, including media interviews and meetings with lobbyists, are subject to a “radical transparency” policy: They are recorded, transcribed, and posted online for all to see. Tang also holds regular virtual visits with communities all over Taiwan.</p>



<figure><blockquote><p>“<strong>Any top-down, coercion, whether it’s from the capitalists or from the state, is equally bad.”</strong></p></blockquote></figure>



<p>During a recent one, entrepreneurs from Taiwan’s indigenous community pressed for changes to the business code. Tang listened and recalled a solution she helped devise last year, when Taiwan became the first Asian country to legalize same-sex marriage. Many older, conservative Taiwanese could accept that gay people should have equal rights but felt reluctant to have their extended-family registries — official, patrilineal records stretching back to the early 20th century — reflect LGBT unions. The fix was a “hyperlink act” that, with a single click, would amend relevant sections of the civil code to give queer couples the same rights and duties as anyone else but would not, as with straight marriages, “hyperlink to the in-laws,” meaning that the families of the same-sex couple wouldn’t be permanently bonded in the eyes of the state. “Their families don’t wed. It’s the individuals that wed,” she told me. “It’s a social innovation that convinced both generations that the values that they cherish are not disrupted when we pass marriage equality. It’s marriage equality with intergenerational solidarity.”</p>



<p>It’s also a compromise. Tang, whose mother was active in Taiwan’s cooperative movement before the country transitioned to democracy, much prefers collaboration to battle. This might relate as well to another aspect of Tang’s childhood: she was born with a heart defect and often talks about the virtues of unhurried observation. “If you’re slow in your motion, you tend to notice other, nonhuman beings,” she told me — trees, rivers, computers. As digital minister, she invoked this cooperative ideal to implement Pol.is, an online discussion board where Taiwanese people can engage in a “rough-consensus process” about social issues, such as what sorts of rules should govern Uber or how best to combat the spread of revenge porn. To prevent trolling, the platform functions without a reply button.</p>



<p>Taiwan’s constitution prohibits private businesses from acting against “the balanced development of national wealth and people’s livelihood,” yet the country’s most famous corporation is high-tech Apple supplier Foxconn, which gained notoriety for driving its mainland Chinese factory workers to suicide. I asked whether the cruelties of big businesses hadn’t dimmed Tang’s faith in the possibility of social equilibrium. “The manufacturing companies, they learned, of course, not to do [things with] adverse effects within Taiwan proper,” she replied, referring to Foxconn’s compounds in mainland China. But the next generation of Taiwanese entrepreneurs, she said, will use robotics to reduce worker exploitation, embrace “worker associations,” and pursue …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/">https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627208</guid>
            <pubDate>Tue, 29 Sep 2020 13:00:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Rust the Open Source Way]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627068">thread link</a>) | @bradsherman
<br/>
September 29, 2020 | https://bitsbybrad.com/2020-09-29-learning-rust/ | <a href="https://web.archive.org/web/*/https://bitsbybrad.com/2020-09-29-learning-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>A few months ago I started learning Rust, and in the process I ended up contributing to an open source project for the first time. It turned out to be a great vehicle for learning Rust, so in this post I’d like to go over what I did and why I think it was a good learning experience. In particular I want to walk through my thought process as I navigated my first open source contribution in the hopes that others who face similar challenges are encouraged to overcome them. Throughout this post I’ll also explain more about how this helped me learn Rust.</p>

<h2 id="motivation">Motivation</h2>

<p>The main impetus for deciding to learn Rust was that I had read a lot of great reviews and Rust seemed to be growing in popularity, so I thought it would be a nice addition to my tool-belt. I also use C++ in my day job and saw that Rust was trying to improve on some of the drawbacks of C++ (like easily writing safe, concurrent code), so I wanted to start investigating for myself.</p>

<p>The first thing I did was read <a href="https://doc.rust-lang.org/book/">The Rust Programming Language</a> (which I highly recommend for anyone else new to Rust!). I breezed through it fairly quickly, dutifully completing all of the exercises. Once I finished, I still felt like I had the training wheels on and I wanted to learn more. I briefly thought about finding <em>another</em> guide or tutorial to go through, but luckily I realized that was a one-way ticket to <a href="https://www.freecodecamp.org/news/how-to-escape-tutorial-purgatory-as-a-new-developer-or-at-any-time-in-your-career-e3a4b2384a40/">tutorial purgatory</a>, before getting in too deep. To be clear, the book (and most language introduction texts in my opinion) was great for understanding the basics and acting as a reference as I got more experience with the language. It’s just that I wanted to get to the next level of understanding and be able to write new code from scratch (take off the training wheels). In order to do that, I needed a project to sink my teeth into and push myself towards that deeper level of understanding.</p>

<p>In general at this point I could have done one of two things: start my own project or help with someone else’s project. I spent a decent amount of time trying to think of an exciting project, but I didn’t have any great ideas off the top of my head. Plus I had already accumulated plenty of small, unfinished toy projects on Github, so I started investigating the open source route. That way I would get clear instructions on what needed to get done and I could simply focus on improving my Rust abilities.</p>

<p>This wasn’t the first time I’ve thought about contributing to open source. I’ve had a desire to start contributing to open source software ever since college, but I never felt like I was good enough to help out. It was a clear case of <a href="https://en.wikipedia.org/wiki/Impostor_syndrome">imposter syndrome</a>. I imagine there are many other developers who have run into this feeling. Certainly it’s much more common in an interview but the idea here is the same. There’s no fool proof way of shaking off imposter syndrome, but the fact that I didn’t personally know any of the project maintainers helped me at least decide to give it a shot!</p>

<p>Once I stopped focusing on all the things that could go wrong for a second, I started to realize how beneficial contributing to an open source project could be in my quest to learn Rust. There are multiple experienced developers reviewing your code who know way more about the language and tools you are using so they can quickly explain important concepts you might not understand or even know about. You get the chance to have discussions with people all over the world who have their own ideas for a solution. I think anywhere you can find a cross-pollination of ideas like this is a great place to learn. The trick is to not be afraid to admit you don’t know something, or that your idea is wrong. By no means is it easy to do this, but once you do it is quite liberating!</p>

<h2 id="clippy">Clippy</h2>

<p>The next step was to find a project to contribute to. After googling a couple variations of “rust open source projects for beginners”, I found <a href="https://github.com/rust-lang/rust-clippy">Clippy</a>. The best summary comes from their Github: “A collection of lints to catch common mistakes and improve your Rust code”. I am always a fan of developer productivity and encouraging good coding standards, so this project seemed perfect! Part of the reason I picked this project is because the maintainers do a great job of labeling issues that are easier with ‘good first issue’ so that I could quickly find potential issues to solve. I recommend finding a project like this as it makes the initial experience with open source much smoother. Being able to choose from multiple issues that were better suited for beginners reduced the overwhelming feeling of being new. I still had to do plenty of work to acclimate myself with the new code base and the issue I was trying to solve, but I was able to proceed knowing that I was not out of my league.</p>

<p>I ended up volunteering to add a new lint for the use of <code>.nth(0)</code> on any iterator. I’ll post a link to the issue at the end of this post, but the basic idea is that Rust developers should call <code>.next()</code> on the iterator instead of <code>.nth(0)</code> (if you’re curious, check out the docs for <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.nth">nth</a> and <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#tymethod.next">next</a> to see why this is desired). It was my job to make Clippy output a helpful suggestion anytime this situation is found. I forked and cloned the repository, and then spent some time building the code and running the tests. I think this is important to do, especially in a new language, so that you can get familiar with the build system first and focus on implementing your solution after. Another reason Clippy was a nice place to start was there are hundreds of lints and therefore hundreds of other examples of what I had to do. I searched for examples of similar lints to the one I was implementing so I could start to understand which parts of the code I needed to change. After a while I was able to cobble together some changes, but I was pretty confident they were not correct. I was stuck and didn’t really know what to do. I returned to the Clippy Github page to see if I could find any useful information and found this in <code>CONTRIBUTING.md</code>:</p>

<blockquote>
  <p>First: if you’re unsure or afraid of <strong>anything</strong>, just ask or submit the issue or pull request anyway. You won’t be yelled at for giving it your best effort. The worst that can happen is that you’ll be politely asked to change something. We appreciate any sort of contributions, and don’t want a wall of rules to get in the way of that.</p>
</blockquote>

<p>They know this is going to happen, and they welcome the pull requests anyway. Clearly my best course of action was to push it up, admit I’m stuck, and ask for help. It felt weird pushing up code I know did not work, but the reason I chose to do this in the first place was to learn so I pushed up the branch and asked for a review.</p>

<h3 id="feedback">Feedback</h3>

<p>As I suspected, there were more than a few problems with my initial implementation, but that’s okay! I received encouraging and helpful feedback from multiple users. I learned new macros in Rust like <a href="https://docs.rs/if_chain/1.0.0/if_chain/">if_chain</a>, and was guided towards more helpful examples in the code related to what I needed to do. After a bit more back and forth, my pull request was merged! It was a great feeling knowing that I contributed at least in a small way to software that is used by thousands of developers every day!</p>

<p>I think it’s important to make a special note about the initial round of feedback I received. It wasn’t condescending or mean, even though I missed some things that by now have become second nature to the maintainers. I received simple, encouraging, and timely feedback that allowed me to quickly make changes and not feel bad about getting it wrong the first time. If the feedback is too complex, disrespectful, or takes forever there’s a good chance I wouldn’t want to contribute to the project again. What’s worse, I may write off contributing to open source altogether! Creating a welcoming environment for new contributors is key to establishing a thriving open source project.</p>

<h2 id="takeaways">Takeaways</h2>

<p>So, what did I learn about Rust after this whole experience? Well, there’s still so much to learn but after reading <a href="https://doc.rust-lang.org/book/">The Rust Programming Language</a> I was particularly intrigued by Rust’s idea of <a href="https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html">ownership</a>. I was immediately able to make a connection to my professional work in C++, particularly with regards to <a href="https://www.internalpointers.com/post/c-rvalue-references-and-move-semantics-beginners">move semantics and rvalue references</a>. Rust makes it very explicit who can read and modify data, and the compiler will yell at you if you break the rules. These rules help prevent multiple threads from modifying the same piece of data at the same time, also known as a data race. C++’s rules around data ownership and mutability are less strict, so the compiler cannot protect you from data races as much as it can in Rust. Just by writing Rust code for Clippy and being exposed to the rules that the Rust compiler enforces made me a better C++ programmer in this aspect. Now I am explicitly thinking about ownership and mutability when I write C++ code even though there are no rules forcing me to do so.</p>

<p>Other concepts I found interesting were <a href="https://doc.rust-lang.org/book/ch06-00-enums.html">pattern matching</a> and <a href="https://doc.rust-lang.org/book/ch09-02-recoverable-errors-with-result.html">recoverable errors</a>, which I had no experience with before. Contributing to Clippy gave me valuable experience dealing with these ideas and helped solidify my understanding. These features of the language, among others, were my first significant exposure to functional programming language concepts. Having come from an almost exclusively procedural background, it was interesting to see the two worlds collide. I was excited to have discovered something new, and I look forward to learning more about functional programming languages in the future as well!</p>

<h2 id="conclusion">Conclusion</h2>

<p>To wrap things up I want to reiterate some key lessons I learned from contributing to an open source project for the first time. I think it’s really important to find the right project and have a positive mindset when trying to jump into the open source world. Specifically:</p>

<ul>
  <li>Find a project that has a label for beginners, such as ‘good first issue’. These labels reduce the burden of finding an issue to choose, which can be overwhelming on large projects.</li>
  <li>Take a look at some of the …</li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bitsbybrad.com/2020-09-29-learning-rust/">https://bitsbybrad.com/2020-09-29-learning-rust/</a></em></p>]]>
            </description>
            <link>https://bitsbybrad.com/2020-09-29-learning-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627068</guid>
            <pubDate>Tue, 29 Sep 2020 12:48:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abandoned Cart Recovery: Email vs. Messenger 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24627034">thread link</a>) | @JonasvdP
<br/>
September 29, 2020 | https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/ | <a href="https://web.archive.org/web/*/https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <h2 id="using-a-range-of-data-we-looked-into-some-of-the-most-recent-cart-abandonment-statistics-and-how-ecommerce-shops-can-minimize-this-issue-">Using a range of data, we looked into some of the most recent cart abandonment statistics, and how ecommerce shops can minimize this issue. </h2><p>Should you use email marketing, chat marketing or both to recover abandoned carts? And which sectors stand to win back most revenue in 2020? Here are some of the headline stats from the data we compiled:</p><h3 id="abandoned-cart-rates-across-sectors-">Abandoned cart rates across sectors:</h3><p>Average all sectors: <strong>88.05%</strong></p><div><p>Out of all industries, ecommerce fashion businesses can benefit most from running abandoned cart recovery campaigns. Using email marketing to recover abandoned carts works well, but its efficiency has been on the decline:</p><p>Fashion: <strong>90.68% </strong><br>Retail: <strong>84.51% </strong><br>Travel: <strong>79.95%</strong></p></div><p><em>Source: <a href="https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/[https://www.statista.com/statistics/457078/category-cart-abandonment-rate-worldwide/](https://www.statista.com/statistics/457078/category-cart-abandonment-rate-worldwide/)">Statista</a></em></p><p>Abandoned cart email open rates have dropped from <strong>46.1%</strong> in 2013 to <strong>40.76%</strong> in 2020. These open rates are still relatively high. Click rates for this type of email have also dropped from <strong>13.3%</strong> in 2013 to <strong>8.24%</strong> in 2020. </p><p><em>Source: <a href="https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/[https://www.statista.com/statistics/457078/category-cart-abandonment-rate-worldwide/](https://www.statista.com/statistics/457078/category-cart-abandonment-rate-worldwide/)">Barilliance</a></em></p><p>How about Messenger's abandoned cart recovery performance?</p><h3 id="messenger-open-and-click-through-rates-">Messenger open and click through rates:</h3><p>Messenger average open rates (<strong>80-90%</strong>) and click-through rates (<strong>56%</strong>) are significantly higher than email. At the same time, where abandoned cart email conversion rates lie at <strong>10.7%</strong>, Messenger performs around <strong>33%</strong> better. </p><p><em>Sources: <a href="https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/[https://moosend.com/blog/cart-abandonment-rate-infographic/](https://moosend.com/blog/cart-abandonment-rate-infographic/)">Moosend</a>, <a href="https://neilpatel.com/blog/open-rates-facebook-messenger/">Neil Patel</a>, <a href="https://upbeatagency.com/facebook-messenger-bring-customers-back/">Upbeat</a></em></p><p>Basically, while abandoned cart emails still perform relatively well in 2020, they are less efficient than a few years ago. At the same time, Messenger outperforms email for every benchmark. </p><h2 id="abandoned-cart-recovery-email-vs-messenger-2020">Abandoned Cart Recovery: Email vs. Messenger 2020</h2><!--kg-card-begin: markdown--><figure><img src="https://www.iampop.com/blog/content/images/2020/09/Infographic-Abandoned-Cart-Recovery-Statistics-Email-vs-Messenger-2020-2.png" alt="Infographic-Abandoned-Cart-Recovery-Statistics-Email-vs-Messenger-2020" title="Infographic-Abandoned-Cart-Recovery-Statistics-Email-vs-Messenger-2020"></figure><!--kg-card-end: markdown--><p>If you liked this infographic, show us some <strong><strong><strong><strong>â�¤ï¸�</strong></strong></strong></strong> and tweet about it by clicking <a href="https://ctt.ac/8_b9d">here</a> ðŸ‘ˆ</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: markdown--><div>
 <p>Hey there ðŸ‘‹</p>
 <p>
Use POP to set up an abandoned cart campaign.
 </p>
 <p><a href="https://www.iampop.com/dashboard/commerce/shopify" target="_blank">
  Get started
 </a>
</p></div>
<!--kg-card-end: markdown--><p><em>Or why don't you connect to POP directly through Messenger at <a href="https://m.me/bypophq">https://m.me/bypophq</a></em></p>
        </div></div>]]>
            </description>
            <link>https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627034</guid>
            <pubDate>Tue, 29 Sep 2020 12:45:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write Shorter Blog Posts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24626848">thread link</a>) | @HermanMartinus
<br/>
September 29, 2020 | https://jonathancai.bearblog.dev/shorter/ | <a href="https://web.archive.org/web/*/https://jonathancai.bearblog.dev/shorter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I realize a big hindrance to me writing more is thinking that every post has to be significant/long. This is wrong.</p>
</div></div>]]>
            </description>
            <link>https://jonathancai.bearblog.dev/shorter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626848</guid>
            <pubDate>Tue, 29 Sep 2020 12:26:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3 key RPA+ML insights from invoice process automation project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24626595">thread link</a>) | @arauhala
<br/>
September 29, 2020 | https://aito.ai/blog/top-3-insights-from-using-rpa-ml-to-automate-invoice-processing/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/top-3-insights-from-using-rpa-ml-to-automate-invoice-processing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This post appeared first on <a href="https://towardsdatascience.com/top-3-insights-from-using-query-based-ml-to-automate-invoice-processing-a3260c3b840d">Towards Data Science</a> in September 25th, 2020.</p></blockquote><p>The <a href="http://robotic_process_automation/">RPA</a> team of <a href="https://www.posti.fi/en">Posti</a>, the Finnish logistics giant, started to use machine learning to boost their invoice automation. These are the key insights from that project. A good read for whoever is leading or contributing when taking existing automation and making it intelligent using machine learning.</p><p>You can read more about the project <a href="https://aito.ai/blog/posti-boosts-their-rpa-with-aito/">here</a>. In short, the problem was that <a href="https://www.posti.fi/">Posti</a> receives ten thousand purchase invoices a month. For accounting, payment and taxation purposes, each invoice needs to be associated with 1) a reviewer 2) a budget/account 3) department and 4) value added tax code.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-purchase-invoice-form.png" alt=""></p></div><p><span>In the purchase invoice automation process the goal was to automatically fill the 4 missing fields based on 4 known invoice fields. Such forms get continuously filled by the countless senior employees, accountants, managers and executives in virtually all organizations. Image source: Aito </span></p></div><p>As a solution, UiPath was used to copy the historical invoices to the predictive database. Then the predictive database queries were used to predict the missing fields:</p><div data-language="json"><pre><code><span>{</span>
  “from” <span>:</span> “purchase_invoices”<span>,</span>
  “where”<span>:</span> <span>{</span>
    “purchase_number “<span>:</span> “XY<span>12345678</span>”<span>,</span>
    “company_id”<span>:</span> “<span>234234</span>–<span>3</span>”<span>,</span>
    “vendor_number”<span>:</span> “<span>0002948810</span>”<span>,</span>
    “currency” <span>:</span> “EUR"
  <span>}</span><span>,</span>
  “predict”<span>:</span> “reviewer”
<span>}</span></code></pre></div><p>The predictions with high confidence/probability estimates were then used to fill the missing fields in the invoices by the RPA machinery and automate different phases of the process.</p><p>This is what we learned.</p><p>Process automation is a very rewarding field for machine learning application, because:</p><ol><li>Companies tend to have high quality and complete records of their core business processes, because the business cannot operate without those records (e.g. orders or invoices) and in the worst case there may be juridical implications (as with invoices), if the business records are not well maintained.</li><li>Most processes have extremely strong patterns. For example, the invoices coming from ‘the Parking company’ tend to always go to the ‘parking budget’. Such patterns are very easy to harvest from data and utilize in process automation allowing for example 20%-99% automation rates in exchange for 1%-5% errors in the statistical process.</li><li>Large companies can have a very high volumes in their core processes. For example: Posti processes about ten thousand invoices a month.</li></ol><p>As consequence of good data, high automation rates and high volumes, the existing process data is often easy to untap and reuse in intelligent automation for a significant business gain.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-mantas-hesthaven.jpg" alt=""></p></div><p><span>There are huge opportunities in the RPA+ML space especially now, when the economics of machine learning fit better the limited RPA project budgets. Photo by Mantas Hesthaven on Unsplash</span></p></div><p>Also based on the discussions with the Posti project team:</p><ul><li>RPA+ML projects are not that expensive compared to the traditional ML projects if done with a predictive database. Posti RPA team estimated that the median RPA project may take e.g. 3 months on average (there is typically a lot of analysis, communication and organizing overhead involved), while an RPA+ML project might take 4 months (extra month for the ML part, the extra data integrations, extra communication and the extra steps to handle possible errors). Still, it’s good to reserve significantly more time to the first RPA+ML project done by your organization.</li><li>There are lot of use cases. It was estimated that 10%-20% of the Posti RPA use cases could benefit from the similar kind of machine learning. </li><li>The business benefits of RPA+ML applications can be high: possibly hundreds of thousands of euros, because of high automation rates in moderately complex high volume processes</li></ul><p>As a result of these discussions: the team did identify many rewarding business cases and opportunities and decided to expand the deployment of ML with the same setup of tools.</p><p>While in the traditional rule-based RPA you may have strong guarantees that the process is errorless, with the intelligent automation it’s difficult to create an entirely error-free solution. This applies because the machine learning component operates in a statistical fashion.</p><div><div><p><img src="https://source.unsplash.com/GikVY_KS9vQ" alt=""></p></div><p><span>Statistical systems introduce a controlled error rate. Photo by Michał Parzuchowski on Unsplash</span></p></div><p>But while you cannot have a perfectly error-free system, what you can have is:</p><ul><li><p>A controlled error rate. In the Posti case, the ML component was able to fill the missing tax code field in 99% of cases with less than 1% error and 63% of the cost center cases with less than 5% error rate. In the invoice automation case, the content is double-checked in accounting, so a small error rate is typically not an issue.</p></li><li><p>Radically higher automation rates for extremely complex systems. In the Posti case, you could see thousands or even tens of thousands of separate purchase invoice types &amp; special cases. Developing and maintaining thousands of different rules to implement a rule-based RPA with high coverage is simply not feasible in such a case. While complex rule-based automation may manage to handle e.g. 10% of the invoices, I have seen 80% or 90% automation rates with ML based solutions.</p></li></ul><p>In essence with RPA+ML: you accept a controlled error rate in exchange for a radically higher automation rate, lower maintenance cost and an ability to solve otherwise unsolvable problems.</p><p>In practice, this requires a change in the mindset and a straightforward discussion with the business owners about the statistical errors and the optimal error rate/automation rate trade-off. It may also require an additional step in the process to review and correct the statistical decisions with an error rate above 1%.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-you-x-ventures.jpg" alt=""></p></div><p><span>As a part of the Posti project, the RPA team and the accounting team meet to decide the automation rate vs error rate trade-off. Photo by You X Ventures on Unsplash</span></p></div><p>You can find more information about the topic in an TDS article about <a href="https://towardsdatascience.com/return-on-investment-for-machine-learning-1a0c431509e">ML return on investment</a></p><p>In the implemented invoice automation, the basic interaction was simplistic:</p><ol><li>First, the RPA robot scrapes the processed invoice forms from the accounting system into the predictive database.</li><li>Second, the robot reads the incoming invoices, makes 4 simple predictive queries to predict the missing fields</li><li>Third, the robot uses predictions to write the missing fields into the accounting system and changes the invoice process state.</li></ol><p>There are numerous RPA+ML problems that can be solved in a similar simple manner. In essence, whenever you see a process with a form it can likely be automated in the same way.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-customer-contact-form.png" alt=""></p></div><p><span>Any process that includes a form is a potential target for ML+RPA based automation. In this example: the customer can be statistically inferred based on the email, while the product, the issue category and the correct customer support person can be inferred from the title and the description. As such, an ML enabled robot may process most cases flawlessly. Image source: Aito</span></p></div><p>Still, while the RPA part can be relatively straightforward, the ML part can be the exact opposite. In a typical scenario, you’ll ask for the data science team time for fitting, deploying and integrating the 4 ML models, that do the predictions for the 4 different fields. The data science project can take a while, it can be expensive and in essence: the data science team will schedule the time according to their wider priorities and often RPA is not at the top of their list.</p><p>On the other hand, if you use a predictive database to query the unknown fields, the experience is similar to using an SQL database to query the known fields. This SQL-like experience is easy enough for most RPA developers and the related effort and the time investments fit better the tight RPA budgets and schedules. The inherent easiness of the approach was reflected by the Posti RPA developer comment: ‘What I most like in Aito is that it’s easy to use’. It was also observed that the database integrations were a rather small part of the project and that the approach allowed the RPA team to do RPA+ML autonomously. </p><p>So the right tools can make RPA+ML easy and let the RPA teams progress on their intelligent automation roadmap autonomously. Of the alternative ML tools available: the used predictive database seems especially promising, because <a href="https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models/">the fundamental easiness of doing machine learning with predictive queries</a>.</p><p>RPA+ML creates immediate business impact, it doesn't require a data scientist and it doesn't need to be hard.</p><p>Yet, we have found that most companies have difficulties in recognizing RPA+ML use cases. This is quite understandable, because RPA teams often lack machine learning experience and expertise in the level most of the solutions in the market require.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-markus-spiske.jpg" alt=""></p></div><p><span>While the RPA+ML opportunities are numerous, there are challenges in identifying use cases, because the lack of machine learning expertise in RPA teams. Photo by Markus Spiske on Unsplash </span></p></div><p>As a consequence: while a company can have an abundance of good use cases, these can go largely unrecognized. Now to solve the issues regarding use cases:</p><ol><li>A simple thought exercise can help here. Like mentioned before: any business process that can be thought of as a form is a potential RPA+ML automation target.</li><li>There are a lot of use case descriptions available online.</li><li>Also you can always consult intelligent automation experts or vendors like us for advice.</li></ol><p>If you have questions or comments about the topic, we are happy to help at <a href="https://aito.ai/contact-us/">https://aito.ai/contact-us/</a> or you can contact our RPA consultant friends at <a href="https://sisuadigital.com/">Sisua Digital</a>. Sisua has a strong expertise in ML-supported RPA automation and they held an advisory role in the Posti invoice automation project.</p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/top-3-insights-from-using-rpa-ml-to-automate-invoice-processing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626595</guid>
            <pubDate>Tue, 29 Sep 2020 11:58:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Almost no-JS solution: Real-time monitoring of Hacker News and Reddit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24626578">thread link</a>) | @stanislavb
<br/>
September 29, 2020 | https://alertcamp.com/live/Apple,Google,Microsoft,Amazon,Facebook | <a href="https://web.archive.org/web/*/https://alertcamp.com/live/Apple,Google,Microsoft,Amazon,Facebook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
<div data-phx-main="true" data-phx-session="SFMyNTY.g2gDaAJhBHQAAAAHZAACaWRtAAAAFHBoeC1GanBWOXF1ME9VWjdqY1dCZAAKcGFyZW50X3BpZGQAA25pbGQACHJvb3RfcGlkZAADbmlsZAAJcm9vdF92aWV3ZAAcRWxpeGlyLkFsZXJ0Y2FtcFdlYi5MaXZlTGl2ZWQABnJvdXRlcmQAGkVsaXhpci5BbGVydGNhbXBXZWIuUm91dGVyZAAHc2Vzc2lvbnQAAAAAZAAEdmlld2QAHEVsaXhpci5BbGVydGNhbXBXZWIuTGl2ZUxpdmVuBgC2JP7rdAFiAAFRgA.VrUPY5czkUnDK_Z7qeV-B5Q9Zz0TblcobFTt8ETziow" data-phx-static="SFMyNTY.g2gDaAJhBHQAAAADZAAKYXNzaWduX25ld2pkAAVmbGFzaHQAAAAAZAACaWRtAAAAFHBoeC1GanBWOXF1ME9VWjdqY1dCbgYAtiT-63QBYgABUYA.JZlLy41SvOF5byeV-wenv6D0PKdXTVOtjxcdPji7wTI" data-phx-view="LiveLive" id="phx-FjpV9qu0OUZ7jcWB">



<div>
  <div>
    <p>
      Live monitoring of everything that's being posted on <b>Reddit</b> &amp; <b>HackerNews</b>.<br>
      Sponsored by <a href="https://www.saashub.com/">SaaSHub</a>
    </p>

      <div>
        <div>
            <p><span>Monitoring</span>
            <a href="#" phx-click="toggle-play" phx-disable-with="pause...">pause</a>
        </p></div>
        <p><span>Online Users</span>
-        </p>
        <div>
<p><a data-phx-link="redirect" data-phx-link-state="push" href="https://alertcamp.com/live?placeholder=Apple%2CGoogle%2CMicrosoft%2CAmazon%2CFacebook">Change keywords</a>        </p></div>
      </div>
  </div>

  <div>
      <table>
        <thead>
          <tr>
            <th colspan="2">
              Matches count
            </th>
          </tr>
        </thead>
        <tbody>
            <tr>
              <td>Amazon</td>
              <td>0</td>
            </tr>
            <tr>
              <td>Apple</td>
              <td>0</td>
            </tr>
            <tr>
              <td>Facebook</td>
              <td>0</td>
            </tr>
            <tr>
              <td>Google</td>
              <td>0</td>
            </tr>
            <tr>
              <td>Microsoft</td>
              <td>0</td>
            </tr>
        </tbody>
      </table>
  </div>
</div>
<hr>

<ul id="matches" phx-hook="LiveMatchesUpdated">
</ul><p>

    Waiting for keyword matches...<br>
    This may take up to 30 seconds
</p></div>      </div>
    </div></div>]]>
            </description>
            <link>https://alertcamp.com/live/Apple,Google,Microsoft,Amazon,Facebook</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626578</guid>
            <pubDate>Tue, 29 Sep 2020 11:56:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Check downtime status of top websites like Gmail, linkedin]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24626391">thread link</a>) | @1hakr
<br/>
September 29, 2020 | https://simpleops.io/websites | <a href="https://web.archive.org/web/*/https://simpleops.io/websites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://simpleops.io/websites</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626391</guid>
            <pubDate>Tue, 29 Sep 2020 11:33:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identifying Airtel middleboxes that censor HTTPS traffic]]>
            </title>
            <description>
<![CDATA[
Score 391 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24626388">thread link</a>) | @justDankin
<br/>
September 29, 2020 | http://iamkush.me/sni-airtel/ | <a href="https://web.archive.org/web/*/http://iamkush.me/sni-airtel/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Back in November 2019, <a target="blank" href="https://cis-india.org/internet-governance/blog/reliance-jio-is-using-sni-inspection-to-block-websites">we reported</a> that Reliance Jio is able to block HTTPS internet traffic by means of a deep packet inspection (DPI) technique. In response, some readers messaged us saying that they ran our test and were able to reproduce similar behaviour on Airtel mobile networks. According to <a href="https://trai.gov.in/sites/default/files/PIR_08012020_0.pdf" target="_blank">TRAI's Performance Indicators report for Jul-Sep 2019</a>, Reliance Jio and Airtel serve roughly 52% and 23% of internet subscribers in India respectively. <strong>This essentially means that SNI inspection based censorship is now impacting every 3 out of 4 internet connections in India.</strong></p>

<p>Although the previous test was able to detect the presence of SNI inspection based censorship, it was not very insightful. In this post, we delve into a more informative test which not only confirms the presence of SNI inspection based censorship, but also helps us identify the exact mechanism. Furthermore, it also allows us to identify middleboxes which are actively inspecting SNI in TLS handshakes and censoring requests. <strong>Using this method, we were able to discover 25 different middleboxes registered to Airtel, which are actively censoring HTTPS traffic.</strong></p>

<p>Quick links to different sections of this post: <br>
1. <a href="#secTLS">Transport Layer Security</a> <br>
1.1 <a href="#secSNI">Server Name Indication</a> <br>
2. <a href="#secSNICensor">SNI Inspection based censorship</a> <br>
3. <a href="#secINT">Iterative Network Tracing</a> <br>
4. <a href="#secData">Data Preparation</a> <br>
5. <a href="#secMethod">Methodology</a> <br>
6. <a href="#secAirtel">Examining Airtel's behaviour</a> <br>
7. <a href="#secRef">References</a></p>

<p>All the code for replicating this experiment, as well as the logs from our test runs can be found in <a target="_blank" href="https://github.com/kush789/INT-SNI">this repository</a>. Big shout-out to <a href="https://ipinfo.io/" target="_blank">IPinfo</a> for giving us access to their IP address dataset, and <a href="https://gurshabad.github.io/" target="_blank">Gurshabad Grover</a> for his suggestions while ideating the methodology and for editing this post.</p>





<p>Transport Layer Security (TLS) is a cryptographic protocol for providing communication confidentiality and authenticity, commonly used for encrypting web traffic (as done in HTTPS). Normally TLS is used over TCP, as it requires a reliable in-order data stream. A <a href="https://www.cloudflare.com/learning/ssl/transport-layer-security-tls" target="_blank">quick refresher</a> on TLS by Cloudflare.</p>

<p><img src="https://i.imgur.com/OlMYujg.png" alt="img">
</p><center>A TCP handshake followed by a TLS Handshake. The ClientHello is a message sent by the client, which initiates the TLS handshake. This message can contain extensions such as SNI. Image credits - <a href="https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/">Cloudflare</a></center>



<h3 id="servernameindication">Server Name Indication</h3>

<p>Server Name Indication (SNI), defined first in <a href="https://tools.ietf.org/html/rfc4366" target="_blank">RFC4366</a> and then in <a href="https://tools.ietf.org/html/rfc6066" target="_blank">RFC6066</a>, is a TLS extension designed to facilitate the hosting of multiple HTTPS websites on the same IP address. While sending a <code>ClientHello</code> message (which initiates the establishment of a secure connection), the client is expected to fill in the SNI attribute with the hostname of the website it wishes to connect to. SNI, unfortunately, travels on the network in cleartext, i.e. <strong>network operators can not only see the websites you’re visiting, but also filter traffic based on this information.</strong></p>

<hr>





<p>Since the SNI present is in cleartext, anyone in the network can inspect and filter traffic based on its value. As seen in other countries, ISPs can leverage this to deny access to certain websites. We can observe the same by attempting a TLS connection using openssl and monitoring packets to the host.  </p>

<pre><code>openssl s_client -state -connect 103.224.212.222:443 -servername fullhd720.com  
</code></pre>

<p><img src="https://raw.githubusercontent.com/kush789/INT-SNI/master/images/airtel_103.224.212.222_fullhd720.com.png" alt="img">
</p><center>An attempted TLS connection to <code>103.224.212.222</code>, with SNI <code>fullhd720.com</code>. We observe a RST packet immediately after the ClientHello message containing the SNI is sent.</center>

<p>For instance, using Airtel, we can see that the client receives a TCP RST packet when it tries to connect to a blocked website "fullhd720.com". The RST packet seems to be originating from the actual host, and is received right after the ClientHello message containing the SNI is sent. <a href="https://github.com/kush789/INT-SNI/blob/master/pcaps/airtel_103.224.212.222_fullhd720.com.pcap" target="_blank">PCAP</a>.</p>

<p>To confirm that the connection termination was indeed due to the SNI, we can reattempt the connection with a different SNI which we don't expect to be blocked (in this case we use <code>facebook.com</code>).</p>

<pre><code>openssl s_client -state -connect 103.224.212.222:443 -servername facebook.com  
</code></pre>

<p><img src="https://raw.githubusercontent.com/kush789/INT-SNI/master/images/airtel_103.224.212.222_facebook.com.png" alt="img">
</p><center>An attempted TLS connection to <code>103.224.212.222</code> with a different SNI, <code>facebook.com</code>. In this case, we observe a successful TLS handshake</center>

<p>This time we notice a successful connection, indicating that the RST in the previous attempt was indeed due to the specified SNI. <a href="https://github.com/kush789/INT-SNI/blob/master/pcaps/airtel_103.224.212.222_facebook.com.pcap" target="_blank">PCAP</a>.</p>

<p>Although this test does demonstrate the presence of SNI inspection based censorship, the packet dumps are not sufficient to prove that the RST packet was actually forged by a middlebox belonging to the ISP.</p>

<hr>  





<p>For a given host, let's call the minimum Time to Live (<a href="https://packetpushers.net/ip-time-to-live-and-hop-limit-basics/" target="_blank">TTL</a>) required for a packet to reach from the client to the host, <code>min_ttl</code>. Any packet where the TTL set is less than <code>min_ttl</code> would expire in transit, and never reach the host. Ideally, the router at which the TTL of the packet expired should respond with an ICMP Time Exceeded (<a href="http://www.networksorcery.com/enp/protocol/icmp/msg11.htm" target="_blank">ICMP message type 11</a>) message. However, this is not guaranteed, and some routers are even configured to not send them (in order to hide the topology of the network).</p>

<p><img src="https://i.imgur.com/aSrR375.png" alt="img">
</p><center>Iterative Network Tracing; we send ClientHello messages with increasing TTL. In this particular case, the minimum TTL required is 9. A middlebox which censors requests would send back a censored response even when the TTL is less than 9. Image credits - <a href="#cite1">Yadav et al.</a></center>

<p>So if the RST received is forged by a middlebox, we should receive it even when we send the ClientHello message with TTL less than <code>min_ttl</code>. This approach, known as Iterative Network Tracing (INT), has been previously used to ascertain the presence of middleboxes which censor DNS and HTTP traffic in India [<a href="#cite1">Yadav et al.</a>] and China <a href="#cite2">Xu et al.</a> Similar to these studies, we use INT to detect censorship of TLS traffic (explained further in the <a href="#secMethod">methodology</a> section).</p>

<hr>  





<p>We run our tests using a list of potentially blocked websites (PBWs), curated from leaked court and government orders. The list and more information pertaining to it can be found <a href="https://github.com/kush789/How-India-Censors-The-Web-Data" target="_blank">here</a>.</p>

<p>Using Google's DNS over HTTPS (DoH) <a href="https://developers.google.com/speed/public-dns/docs/doh" target="_blank">service</a>, each hostname was resolved to its correct IP address. Using DoH here is important as it ensures that no DNS based censorship intervenes with the test. This resulted in roughly 5000 (hostname, ip) pairs. Next we selected a random subset and checked for TCP connectivity to port 443 to each of those ips (since not all would support HTTPS traffic), filtering our list down to 1370 pairs.</p>

<p>For each of these test points, we establish a TCP connection with the resolved_ip, and send a TLS ClientHello with the SNI set as the correct_hostname. We sniff and save these ClientHello packets (just the SSL layer) for use later. Similarly, we save the ClientHello packet with the SNI set as <code>facebook.com</code>. These sniffed packets can be found <a href="https://github.com/kush789/INT-SNI/tree/master/tls_client_hellos" target="_blank">here</a>.</p>

<hr>  





<p>The input to the test is a 2-tuple, (<code>correct_hostname</code>, <code>resolved_ip</code>). We would like to understand the behaviour of a middlebox when it observes a ClientHello message containing an SNI for a website it wishes to block.</p>

<p>First, we calculate the <code>min_ttl</code> for a given test point. We begin by establishing a TCP connection with <code>resolved_ip</code>.</p>

<pre><code>import socket  
import random  
from scapy.all import *

resolved_ip = "103.224.212.222"  
dport = 443 # TLS connection  
sport = random.randint(1024, 65535) # Random source port

def create_connection(resolved_ip):  
    s = socket.socket(socket.AF_PACKET, socket.SOCK_RAW)
    s.bind(("usb0", 0)) # Was using a tethered mobile connection for the experiment

    IP_PACKET = IP(dst = resolved_ip)

    seq = random.randint(12345, 67890) # Randomise initial seq number
    SYN = TCP(sport = sport, dport = dport, flags = "S", seq = seq)
    SYNACK = sr1(IP_PACKET / SYN)
    ACK = TCP(sport = sport, dport = dport, flags = "A", seq = seq + 1, ack = SYNACK.seq + 1)
    send(IP_PACKET / ACK)
    return IP_PACKET, ACK
</code></pre>

<p><strong>Note</strong>: When the linux kernel feature gets a TCP packet to an unknown socket, it sends a RST back to the originator. Since we'll be creating our own raw sockets, we need to suppress these outbound RSTs from the kernel using iptables before running experiments.</p>

<pre><code>sudo iptables -A OUTPUT -p tcp --tcp-flags RST RST -j DROP  
</code></pre>

<p>Once the TCP connection has been established, we send ClientHello messages (containing <code>facebook.com</code> in SNI) after updating the TTL (<code>probe_ttl</code>) in the underlying IP header. We specify <code>facebook.com</code> in the SNI so that the middlebox doesn't attempt to terminate the connection. <code>min_ttl</code> would be the minimum TTL at which we receive a TLS ServerHello or TLS Alert from the host.</p>

<pre><code># Load ClientHello with garbled hostname in SNI (sniffed earlier, read Data Preparation)
max_ttl = 35

def find_min_ttl(resolved_ip)

    with open("tls_client_hellos/facebook.com", 'rb') as fp:
        tls_client_hello_facebook_com_sni = fp.read()

    for probe_ttl in range(1, max_ttl):
        IP_PACKET, ACK = create_connection(resolved_ip)
        IP_PACKET.ttl = probe_ttl
        del IP_PACKET.chksum # Will force scapy to recalculate checksum after TTL update

        resp, _ = sr(IP_PACKET / ACK / tls_client_hello_facebook_com_sni, timeout = 2, retry = 0, multi = True)

        for _, ans_packet in resp:
            tls_alert = ans_packet.get(tls.TLS, {}).get(tls.TLSAlert)
            tls_server_hello = ans_packet.get(tls.TLS, {}).get(tls.TLSHandshakes, {}).get(tls.TLSServerHello)

            if tls_alert or tls_server_hello:
                return probe_ttl # min_ttl found!
</code></pre>

<p>Next, we send ClientHello messages containing the <code>correct_hostname</code> in the SNI with TTL increasing from 1 to <code>min_ttl</code> - 1. If there is no middlebox interfering with the connection, all such requests should receive either an ICMP Time Exceeded in response or no response at all. If at any point we receive an RST packet which seems to be originating from <code>resolved_ip</code>, we can say with certainty that the packet was forged by a middlebox.</p>

<pre><code>min_ttl = find_min_ttl(resolved_ip, tls_client_hello)

with open("tls_client_hellos/fullhd720.com", 'rb') as fp:  
    tls_client_hello_correct_sni = fp.read()

for probe_ttl in range(1, min_ttl):  
    IP_PACKET, ACK = create_connection(resolved_ip)
    IP_PACKET.ttl …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://iamkush.me/sni-airtel/">http://iamkush.me/sni-airtel/</a></em></p>]]>
            </description>
            <link>http://iamkush.me/sni-airtel/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626388</guid>
            <pubDate>Tue, 29 Sep 2020 11:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitemporality in Crux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24626358">thread link</a>) | @diggan
<br/>
September 29, 2020 | https://opencrux.com/about/bitemporality.html | <a href="https://web.archive.org/web/*/https://opencrux.com/about/bitemporality.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                
<div>
<h2 id="overview"><a href="#overview"></a>Overview</h2>
<div>
<p>Crux is optimised for efficient and globally consistent point-in-time queries
using a pair of <code>transaction-time</code> and <code>valid-time</code> timestamps.</p>
<p>Ad-hoc systems for bitemporal recordkeeping typically rely on explicitly
tracking either <code>valid-from</code> and <code>valid-to</code> timestamps or range types directly
within relations.  The bitemporal document model that Crux provides is very
simple to reason about and it is universal across the entire database,
therefore it does not require you to consider which historical information is
worth storing in special "bitemporal tables" upfront.</p>
<p>One or more documents may be inserted into Crux via a <code>put</code> transaction at a
specific <code>valid-time</code>, defaulting to the <code>transaction time</code> (i.e. <code>now</code>), and
each document remains valid until explicitly updated with a new version via
<code>put</code> or deleted via <code>delete</code>.</p>
</div>
</div>
<div>
<h2 id="why"><a href="#why"></a>Why?</h2>
<div>
<p>The rationale for bitemporality is also explained in this
<a href="https://juxt.pro/blog/posts/value-of-bitemporality.html">blog post</a>.</p>
<p>A baseline notion of time that is always available is
<code>transaction-time</code>; the point at which data is transacted into the
database.</p>
<p>Bitemporality is the addition of another time-axis: <code>valid-time</code>.</p>
<table id="table-conversion">
<caption>Table 1. Time Axes</caption>
<colgroup>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Time</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><p><code>transaction-time</code></p></td>
<td><p>Used for audit purposes, technical requirements such as event sourcing.</p></td>
</tr>
<tr>
<td><p><code>valid-time</code></p></td>
<td><p>Used for querying data across time, historical analysis.</p></td>
</tr>
</tbody>
</table>
<p><code>transaction-time</code> represents the point at which data arrives into the
database. This gives us an audit trail and we can see what the state
of the database was at a particular point in time. You cannot write a
new transaction with a <code>transaction-time</code> that is in the past.</p>
<p><strong>valid-time</strong> is an arbitrary time that can originate from an upstream
 system, or by default is set to transaction-time. Valid time is
 what users will typically use for query purposes.</p>

<div>
<table>
<tbody><tr>
<td>
<i title="Note"></i>
</td>
<td>
In Crux, when <code>transaction-time</code> isn’t specified, it is set to
<em>now</em>. When writing data, in case there isn’t any specific valid-time
available, valid-time and transaction-time take the same value.
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div>
<h2 id="valid"><a href="#valid"></a>Valid Time</h2>
<div>
<p>In situations where your database is not the ultimate owner of the data—where
corrections to data can flow in from various sources and at various times—use
of <strong>transaction-time</strong> is inappropriate for historical queries.</p>
<p>Imagine you have a financial trading system and you want to perform
calculations based on the official 'end of day', that occurs each day at 17:00
hours. Does all the data arrive into your database at exactly 17:00? Or does
the data arrive from an upstream source where we have to allow for data to
arrive out of order, and where some might always arrive after 17:00?</p>
<p>This can often be the case with high throughput systems where there
are clusters of processing nodes, enriching the data before it gets to
our store.</p>
<p>In this example, we want our queries to include the straggling bits of
data for our calculation purposes, and this is where <strong>valid-time</strong>
comes in. When data arrives into our database, it can come with an
arbitrary time-stamp that we can use for querying purposes.</p>
<p>We can tolerate data arriving out of order, as we’re not completely
dependent on transaction-time.</p>

</div>
</div>
<div>
<h2 id="transaction"><a href="#transaction"></a>Transaction Time</h2>
<div>
<p>For audit reasons, we might wish to know with certainty the value of a
given entity-attribute at a given <code>tx-instant</code>. In this case, we want to
exclude the possibility of the valid past being amended, so we need a
pre-correction view of the data, relying on <code>tx-instant</code>.</p>
<p>To achieve this you can use <code>as-of</code> using <code>ts</code> (<code>valid-time</code>) and <code>tx-ts</code>
(<code>transaction-time</code>).</p>

</div>
</div>
<div>
<h2 id="domain"><a href="#domain"></a>Domain Time</h2>
<div>
<p>Valid time is valuable for tracking a consistent view of the entire state of
the database, however, unless you explicitly include a timestamp or other
temporal component within your documents you cannot currently use this
information about valid time inside of your Datalog queries.</p>
<p>Domain time or "user-defined" time is simply the storing of any additional
time-related information within your documents, for instance <code>valid-time</code>,
<code>duration</code> or timestamps relating to additional temporal life-cycles (e.g.
decision, receipt, notification, availability).</p>
<p>Queries that use domain times do not automatically benefit from any
kind of native indexes to support efficient execution, however Crux
encourages you to build additional layers of functionality to do
so. See <a href="https://github.com/crux-labs/crux-decorators">decorators</a> for
examples.</p>
</div>
</div>
<div>
<h2 id="uses"><a href="#uses"></a>Known Uses</h2>
<div>
<p>Recording bitemporal information with your data is essential when dealing with
lag, corrections, and efficient auditability:</p>
<div>
<ul>
<li>
<p>Lag is found wherever there is risk of non-trivial delay until an event can
  be recorded. This is common between systems that communicate over unreliable
networks.</p>
</li>
<li>
<p>Corrections are needed as errors are uncovered and as facts are reconciled.</p>
</li>
<li>
<p>Ad-hoc auditing is an otherwise intensive and slow process requiring
significant operational complexity.</p>
</li>
</ul>
</div>
<p>With Crux you retain visibility of all historical changes whilst compensating
for lag, making corrections, and performing audit queries. By default, deleting
data only erases visibility of that data from the current perspective. You may
of course still evict data completely as the legal status of information
changes.</p>
<p>These capabilities are known to be useful for:</p>
<div>
<ul>
<li>
<p>Event Sourcing (e.g.
  <a href="https://fr.slideshare.net/ThomasPierrain/as-time-goes-by-episode-2">retroactive
and scheduled events</a> and <a href="https://oparu.uni-ulm.de/xmlui/bitstream/handle/123456789/4150/RetroactiveComputing_Mueller2016.pdf?sequence=5&amp;isAllowed=y">event-driven computing on evolving graphs</a>)</p>
</li>
<li>
<p>Ingesting out-of-order temporal data from upstream timestamping systems</p>
</li>
<li>
<p>Maintaining a slowly changing dimension for decision support applications</p>
</li>
<li>
<p>Recovering from accidental data changes and application errors (e.g. billing
systems)</p>
</li>
<li>
<p>Auditing all data changes and performing data forensics when necessary</p>
</li>
<li>
<p>Responding to new compliance regulations and audit requirements</p>
</li>
<li>
<p>Avoiding the need to set up additional databases for historical data and
improving end-to-end data governance</p>
</li>
<li>
<p>Building historical models that factor in all historical data (e.g. insurance
calculations)</p>
</li>
<li>
<p>Accounting and financial calculations (e.g payroll systems)</p>
</li>
<li>
<p>Development, simulation and testing</p>
</li>
<li>
<p>Live migrations from legacy systems using ad-hoc batches of backfilled
temporal data</p>
</li>
<li>
<p>Scheduling and previewing future states (e.g. publishing and content
management)</p>
</li>
<li>
<p>Reconciling temporal data across eventually consistent systems</p>
</li>
</ul>
</div>
<p>Applied industry-specific examples include:</p>
<div>
<ul>
<li>
<p>Legal Documentation – maintain visibility of all critical dates relating to
  legal documents, including what laws were known to be applicable at the time,
and any subsequent laws that may be relevant and applied retrospectively</p>
</li>
<li>
<p>Insurance Coverage – assess the level of coverage for a beneficiary across
the lifecycle of care and legislation changes</p>
</li>
<li>
<p>Reconstruction of Trades – readily comply with evolving financial regulations</p>
</li>
<li>
<p>Adverse Events in Healthcare – accurately record a patient’s records over
time and mitigate human error</p>
</li>
<li>
<p>Intelligence Gathering – build an accurate model of currently known
information to aid predictions and understanding of motives across time</p>
</li>
<li>
<p>Criminal Investigations – efficiently organise analysis and evidence whilst
enabling a simple retracing of investigative efforts</p>
</li>
</ul>
</div>
</div>
</div>
<div>
<h2 id="examples"><a href="#examples"></a>Example Queries</h2>
<div>
<div>
<h3 id="crime"><a href="#crime"></a>Crime Investigations</h3>
<p>This example is based on an academic paper.</p>

<p>During a criminal investigation it is critical to be able to refine a temporal
understanding of past events as new evidence is brought to light, errors in
documentation are accounted for, and speculation is corroborated. The paper
referenced above gives the following query example:</p>

<p>The paper then lists a sequence of entry and departure events at various United
States border checkpoints. We as the investigator will step through this
sequence to monitor a set of suspects. These events will arrive in an
undetermined chronological order based on how and when each checkpoint is able
to manually relay the information.</p>
<div>
<h4 id="_day_0"><a href="#_day_0"></a>Day 0</h4>
<p>Assuming Day 0 for the investigation period is <code>#inst "2018-12-31"</code>, the
initial documents are ingested using the Day 0 valid time:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p2
   :entry-pt :SFO
   :arrival-time #inst "2018-12-31"
   :departure-time :na}

  {:crux.db/id :p3
   :entry-pt :LA
   :arrival-time #inst "2018-12-31"
   :departure-time :na}
  #inst "2018-12-31"</code></pre>
</div>
</div>
<p>The first document shows that <code>Person 2</code> was recorded entering via <code>:SFO</code> and
the second document shows that <code>Person 3</code> was recorded entering <code>:LA</code>.</p>
</div>
<div>
<h4 id="_day_1"><a href="#_day_1"></a>Day 1</h4>
<p>No new recorded events arrive on Day 1 (<code>#inst "2019-01-01"</code>), so there are no
documents available to ingest.</p>
</div>
<div>
<h4 id="_day_2"><a href="#_day_2"></a>Day 2</h4>
<p>A single event arrives on Day 2 showing <code>Person 4</code> arriving at <code>:NY</code>:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p4
   :entry-pt :NY
   :arrival-time #inst "2019-01-02"
   :departure-time :na}
  #inst "2019-01-02"</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_day_3"><a href="#_day_3"></a>Day 3</h4>
<p>Next, we learn on Day 3 that <code>Person 4</code> departed from <code>:NY</code>, which is
represented as an update to the existing document using the Day 3 valid time:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p4
   :entry-pt :NY
   :arrival-time #inst "2019-01-02"
   :departure-time #inst "2019-01-03"}
  #inst "2019-01-03"</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_day_4"><a href="#_day_4"></a>Day 4</h4>
<p>On Day 4 we begin to receive events relating to the previous days of the
investigation.</p>
<p>First we receive an event showing that <code>Person 1</code> entered <code>:NY</code> on Day 0 which
must ingest using the Day 0 valid time <code>#inst "2018-12-31"</code>:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p1
   :entry-pt :NY
   :arrival-time #inst "2018-12-31"
   :departure-time :na}
  #inst "2018-12-31"</code></pre>
</div>
</div>
<p>We then receive an event showing that <code>Person 1</code> departed from <code>:NY</code> on Day 3,
so again we ingest this document using the corresponding Day 3 valid time:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p1
   :entry-pt :NY
   :arrival-time #inst "2018-12-31"
   :departure-time #inst "2019-01-03"}
  #inst "2019-01-03"</code></pre>
</div>
</div>
<p>Finally, we receive two events relating to Day 4, which can be ingested using
the current valid time:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p1
   :entry-pt :LA
   :arrival-time #inst "2019-01-04"
   :departure-time :na}

  {:crux.db/id :p3
   :entry-pt :LA
   :arrival-time #inst "2018-12-31"
   :departure-time #inst "2019-01-04"}
  #inst "2019-01-04"</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_day_5"><a href="#_day_5"></a>Day 5</h4>
<p>On Day 5 there is an event showing that <code>Person 2</code>, having arrived on Day 0
(which we already knew), departed from <code>:SFO</code> on Day 5.</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p2
   :entry-pt :SFO
   :arrival-time #inst "2018-12-31"
   :departure-time #inst …</code></pre></div></div></div></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opencrux.com/about/bitemporality.html">https://opencrux.com/about/bitemporality.html</a></em></p>]]>
            </description>
            <link>https://opencrux.com/about/bitemporality.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626358</guid>
            <pubDate>Tue, 29 Sep 2020 11:28:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My little articles about tool I'm creating]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24626272">thread link</a>) | @Puchaczov
<br/>
September 29, 2020 | https://puchaczov.github.io/Musoq/articles/ | <a href="https://web.archive.org/web/*/https://puchaczov.github.io/Musoq/articles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article>

  

  <div>
    <h3 id="generating-ranged-ip-addresses">Generating ranged IP addresses</h3>

<p>Recently I stumbled upon a necessity to generate IP ranged addresses. 
I was working on allowing developers to use a single self signed certificate across multiple environments we have.
To do so, while generating certificate, there must be a section <code>alt_names</code> that contains IP entries written in such manner</p>

<div><div><pre><code>IP.1 = 10.0.12.13
IP.2 = 10.0.12.14
...
IP.N = 10.0.X.Y
</code></pre></div></div>

<p>It’s necessary to add that asteriks (<code>*</code>) sign is not allowed in certificate so the only option is to propagate the range we have mentioned before.
The problem I had was that I couldn’t assume developers will have assigned static ip in the future so I had to use pregenerated ranges that I would include into certificate.
Based on that I introduce how to generate the range using <code>Musoq</code>.</p>

<p>Let’s look at the query:</p>

<div><div><pre><code>select 
	Replace(
		Replace(
			Replace('IP.{X}=10.0.{A}.{B}', '{A}', ToString(r1.Value)), 
			'{B}', 
			ToString(r2.Value)), 
		'{X}', 
		ToString(RowNumber())) 
	from 
		#system.range(0, 256) r1 inner join 
		#system.range(0, 256) r2 on 1 = 1
</code></pre></div></div>

<p>and the result it generates:</p>

<p><img src="https://puchaczov.github.io/Musoq/assets/images/ip_ranges.png" alt="image"></p>

<p>The way how this query works is pretty easy. We just do the cross join of two ranges and for each pair of <code>r1</code> and <code>r2</code> replace <code>{A}</code> and <code>{B}</code> from text. The last thing is to just replace <code>{X}</code> with the row number.
That way, we are also able to customize our range with <code>where</code> clause. For example we would mark isles that we are focused on <code>... where r1.Value &gt; 10 and r1.Value &lt;= 20 and r2.Value &gt; 40 and r2.Value &lt;= 50</code></p>

<h3 id="analyzing-space-consumption-on-partition-with-windows-and-sql">Analyzing space consumption on partition with Windows and SQL</h3>

<p>Once upon a time in my computer… I faced a problem that appears to all of us from time to time. 
I was rumming in the system settings and I suddenly realized that my primary partition is almost full. 
There were only 30 gigabytes left and I really don’t know where all of my empty space disappeared as I haven’t installed anything big lately. 
To be honest, it’s not that it just disappeared. 
It was long term process that I was just ignoring for a long period of time. 
I’m aware of how Windows loves to consume all space left so I decided to analyze it and figure out what those files are and can I delete them?</p>

<p>This is what we want to achieve:</p>

<p><img src="https://puchaczov.github.io/Musoq/assets/images/executed_query.png" alt="image"></p>

<p>Clear table with listed directories and the space they occupies (including sub directories!). 
As there is a tremendous amount of files in the file system we need something that does quick overview of where to look for lost space.</p>

<p>It’s my personal preference to continuously go deeper into tree only for that directories that have high level of used space. 
This way, I can visit only those directories that have something big inside (or aggregated size of files is big) as I don’t want to waste of time to look over lowly occupied folders. 
Let’s look a query then:</p>

<div><div><pre><code>select 
	::1 as RootDirectory, 
	Round(Sum(Length) / 1024 / 1024 / 1024, 1) 
from #os.files('C:/', true) 
group by RelativeSubPath(1)
</code></pre></div></div>

<p>Looks easy, huh? It is so simple because the query does only few things and you don’t see all the underlying operations that evaluator does for you. <br>
First of all, all files are visited on every nested directory of <code>C</code> with <code>C</code> included. 
We get the starting location from <code>#os.files('C:/', true)</code>. 
The literal value <code>true</code> is passed to instruct query evaluator to visit sub directories.
To be precise I have to say we don’t have to be scared that all the files as it visits, will be loaded into memory. 
Query evaluator will just read the metadata of the file.<br>
By going further, we would like to visit all of the files in partition and on every of that file apply grouping operator. 
In our example, it will work on the result of <code>RelativeSubPath(1)</code>.
If you asked me what this method does I would be obligated to say: it gives a relative sub path of the file that is processed. 
In fact, the whole method <code>string RelativeSubPath ([InjectSource] ExtendedFileInfo, int nesting)</code> is a shorthand for two different methods:</p>

<ul>
  <li><code>string SubPath(string directory, int nesting)</code></li>
  <li><code>string GetRelativePath(ExtendedFileInfo fileInfo, string basePath)</code></li>
</ul>

<p>Result of that method is string that contains the relative path to one of the main directories we started to traverse from so in our case it will be <code>C:/Some</code>. 
Let me explain it on a simple example, if your path is:</p>



<p>and you start from</p>



<p>then your relative path will be <code>Some\Very\Long\Path</code>. 
If your path is the same but you starts from</p>



<p>then your relative path will be <code>Very\Long\Path</code>.</p>

<p>Did you get it? There is still literal argument <code>1</code> passed to this method. 
With these argument, we can limit the depth of the relative path <code>Some\Very\Long\Path</code> by setting it some numeric. 
With argument value <code>1</code> we end up with <code>Some</code>, with <code>2</code> it’s gonna be <code>Some\Very</code>. 
Based on that, we are able to flattening the whole tree to small subset of main directories. 
We can match the file from nested directory with the top directory as if it would belong to him directly. 
Every single file will belong to a single group - group that describes one of main directories.</p>

<h4 id="conclusion">Conclusion</h4>

<p>I hope it will be usefull you. 
In the future I will probably write about something more advanced using Musoq. 
Primarily I will describe my peripeteia with the tool as it is my swiss army knife I use with combination of other tools. 
If you enjoyed the reading and wants to ask something, please contact me through email or just make an issue within the github project.</p>


  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://puchaczov.github.io/Musoq/articles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626272</guid>
            <pubDate>Tue, 29 Sep 2020 11:11:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“If you want a task done quickly, ask a busy person to do it.”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24626209">thread link</a>) | @mcrittenden
<br/>
September 29, 2020 | https://critter.blog/2020/09/29/if-you-want-a-task-done-quickly-ask-a-busy-person-to-do-it/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/29/if-you-want-a-task-done-quickly-ask-a-busy-person-to-do-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-968">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>That quote has been around <a href="https://quoteinvestigator.com/2018/01/30/busy/">since at least the 1850’s</a>. I heard it a while back and immediately rejected it as nonsense. Then it kept bugging me for another week or two, so I tweeted about it.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>"If you want something done ask a busy person to do it."</p><p>I don't get this quote. Is the assumption that busy people are productive people?</p></div>— Mike Crittenden (@mcrittenden) <a href="https://twitter.com/mcrittenden/status/1299764398844776450?ref_src=twsrc%5Etfw">August 29, 2020</a></blockquote></div>
</div></figure>



<p>I got exactly 3 responses, and they’re all fascinating:</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">At least in non-profit world, some people observe and some people do.  They do-ers volunteer for jobs big and small while others stay silent. That's where busy = productive.</p>— weitzman (@weitzman) <a href="https://twitter.com/weitzman/status/1299804752491012098?ref_src=twsrc%5Etfw">August 29, 2020</a></blockquote></div>
</div></figure>



<p>The assumption here is that busy people are do-ers, and non-busy people are watchers. And you’d trust a do-er with your task more than a watcher, even if the do-er is busier. Seems reasonable to me. </p>



<p>It’s not the busyness itself that makes a person a good choice for your task. It’s that busyness is usually a trait of a do-er. If you could somehow find a do-er who wasn’t busy, that would be ideal. But do-ers by definition tend to be doing stuff.</p>



<hr>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Presumably this quote is from a bygone era where busy people aren't uselessly shuffling between meetings, messages, and unfinished tasks all day every day</p>— Christiann MacAuley (@xiann) <a href="https://twitter.com/xiann/status/1299766512589377538?ref_src=twsrc%5Etfw">August 29, 2020</a></blockquote></div>
</div></figure>



<p>Ouch. Too real. The quote <em>is</em> from a bygone era, meaning it dates back at least 150 years. So that part is correct. But were people spending their time on more meaningful tasks back then? Did deep work vs. shallow work exist 100+ years ago like it exists today?</p>



<p>They didn’t have Slack, Zoom, email, or even telephones to fill up their days with shallow work. So it seems reasonable that “busy” back then meant something more than it means now. </p>



<p>Then again, they couldn’t use computers or robots to automate the monotonous parts of the job. Maybe “busy” 150+ years ago meant manual number crunching and hand writing and paper folding?</p>



<p>I’m not sure, and my Google searches about this have ended in frustration. Anyone have any insight?</p>



<hr>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>My take is about the efficiency that comes with constraints on time (which exist because you're busy).</p><p>A task will expand or contract to take up the amount of time available. So because busy people have shorter chunks of free time, they will get a thing done more quickly.</p></div>— Jess Rohloff (@metajess) <a href="https://twitter.com/metajess/status/1308985359070527497?ref_src=twsrc%5Etfw">September 24, 2020</a></blockquote></div>
</div></figure>



<p>I didn’t expect <a href="https://en.wikipedia.org/wiki/Parkinson%27s_law">Parkinson’s law</a> to make an appearance when I tweeted that. But that’s the thing about Parkinson’s law; it likes to sneak in when you don’t expect it. </p>



<p>The more time you have for a task, the longer it takes. If you want something done quickly, give it to someone who doesn’t have much time for it. I love that interpretation.</p>



<hr>



<p>What do you think? Is this quote a relic, or is there still some wisdom to be had here? <a href="https://twitter.com/mcrittenden">Tweet me</a> and let me know!</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/29/if-you-want-a-task-done-quickly-ask-a-busy-person-to-do-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626209</guid>
            <pubDate>Tue, 29 Sep 2020 11:01:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Best Python Blogs to Follow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625999">thread link</a>) | @karlhughes
<br/>
September 29, 2020 | https://learn.draft.dev/technical-blogs/python | <a href="https://web.archive.org/web/*/https://learn.draft.dev/technical-blogs/python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
<article>
  <div>
    
    <div>
      <p><img src="https://learn.draft.dev/assets/posts/python.png" alt="Background image for The Best Python Blogs"></p>
    </div>
    
    <p>
      By Matthew Warholak&nbsp;&nbsp;&nbsp;—&nbsp;
      14 minute read
    </p>

    
      <p>Python is one of <a href="https://pypl.github.io/PYPL.html">the most popular programming languages</a> in use today, so I went on a journey to find the best Python blogs on the internet. Each of these sites demonstrates technical expertise, is relatively easy to comprehend, publishes content consistently, and has stood the test of time.</p>

<p>During this process, I used the same approach for analyzing and comparing common qualities (or deficiencies) in each blog.</p>

<p>I looked at the depth of each blog’s technical content and the usefulness of that content. I read a few posts from start to finish to get a sense of the writing quality and comprehensibility. I looked at how consistently each blog publishes new content, and I did some digging to learn how long each site has been around.</p>

<p>Here are the top 29 Python blogs I found:</p>

<h3 id="1-effbot">1. <a href="http://effbot.org/">effbot</a></h3>

<p><em><a href="http://effbot.org/zone/rss.xml">RSS</a></em></p>

<p><img src="https://i.imgur.com/FK1a7lG.png" alt="effbot.org blog"></p>

<p>Effbot is a minimalist early 2000s blog that hosts hundreds of articles on Python and related technologies. You’ll be glad you discovered this expansive resource consisting of overviews, tutorials, repositories, and articles covering all proficiency levels and unique user applications. Effbot’s articles offer comprehensive details and cogent explanations of advanced technical problems and strategies. While the content is mostly technical, both summaries and examples alike are clean and organized.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  3</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.75</strong></p>


      


      
<h3 id="2-rpython">2. <a href="https://www.reddit.com/r/Python/">r/Python</a></h3>

<p><em><a href="https://www.reddit.com/r/Python.rss">RSS</a></em></p>

<p><img src="https://i.imgur.com/SkZRdFD.png" alt="Reddit r/Python"></p>

<p>Reddit is a massive crowd-sourced message board with a ‘subreddit’ specifically dedicated to Python, among other programming languages. “r/Python,” est. 2008, is composed of a large community of members (&gt;500K) with varying degrees of proficiency who share dozens of questions, solutions, and ideas everyday. As is the case with some message boards, there are no sub-categories or <em>sub</em>-subreddits, so all posts are centralized in one location. Writing is often clear and high quality, depending on the writer; however, all posts are subjective and contributed solely by other Reddit users, so readability, clarity, and even language fluency does not always meet expectations.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  5</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.6</strong></p>

<h3 id="3-real-python">3. <a href="https://realpython.com/">Real Python</a></h3>

<p><em><a href="https://realpython.com/atom.xml">RSS</a>, <a href="https://twitter.com/realpython">Twitter</a></em></p>

<p>Real Python is an educational platform with a large archive of blog posts, tutorials, books, and courses. The content ranges in difficulty level and technical objective. While some of the books and courses are purchase-only, there is an abundance of useful information from 2013 to present made freely available to developers of all backgrounds. Writing is clear, well-researched, aesthetically formatted, and readers can look forward to several new blog posts regularly every month.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  5</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.6</strong></p>

<h3 id="4-pyimagesearch">4. <a href="https://www.pyimagesearch.com/blog/">PyImageSearch</a></h3>
<p><em><a href="https://www.pyimagesearch.com/feed/">RSS</a></em>, <em><a href="https://twitter.com/pyimagesearch">Twitter</a></em></p>

<p><img src="https://i.imgur.com/IBQugNM.png" alt="PyImageSearch Python blog"></p>

<p>PyImageSearch is a niche community that revolves around development in Computer Vision, Deep Learning, and OpenCV. Live since 2014, you’ll be greeted with weekly blog posts offering expertise from beginner to expert proficiency. The writing is clean, sharp, and informative, with no filler text or useless gifs, but be prepared for ample promotional links.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  5</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.4</strong></p>

<h3 id="5-matt-layman">5. <a href="https://www.mattlayman.com/">Matt Layman</a></h3>
<p><em><a href="https://www.mattlayman.com/index.xml">RSS</a>, <a href="https://twitter.com/mblayman">Twitter</a></em></p>

<p>Matt Layman is a self-named personal blog, composed of text, audio, and video posts demonstrating useful techniques, strategies, tutorials, and tips. The writing quality is above average, clean, and simple, with few errors and well-organized examples that help the blog’s message without being overly promotional. Impressively active since 2008, followers can expect a few sporadic posts every month.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  4</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.4</strong></p>

<h3 id="6-python-programming">6. <a href="https://pythonprogramming.net/">Python Programming</a></h3>

<p><em><a href="https://twitter.com/sentdex">Twitter</a></em></p>

<p>Python Programming is a content hub featuring multi-level tutorials in varying difficulty levels across several popular Python use-cases, including Machine Learning, Web Dev, Bots &amp; AI, Finance, and Quantum Computing. The publishing strategy is tutorial-centric, but after you start a tutorial, you’ll find the technical subject to be excellently presented with ample detail and supporting evidence. The writing is not poor, just not great. Some necessary links are present, other times they are not where you’d expect to find them.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency -  N/A</li>
  <li>Longevity - N/A</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.3</strong></p>

<h3 id="7-the-mouse-vs-the-python">7. <a href="https://www.blog.pythonlibrary.org/">The Mouse vs. the Python</a></h3>

<p><em><a href="https://www.blog.pythonlibrary.org/feed/">RSS</a>, <a href="https://twitter.com/driscollis">Twitter</a></em></p>

<p><em>Mouse vs. Python</em> is a personal blog that shares content on a variety of topics in both written and video formats. A recurring post type seems to be one-on-one interviews with developers, which may be less useful to current programmers than tutorials and technical breakdowns. That’s not to say the technical depth is not above average, as both formats provide moderate expertise and value. The blog has been around since 2008 and has established itself as a reliable publisher of content, as readers can typically expect 5-15 new posts every month. <em>Mouse vs. Python’s</em> writing is simple and cogent enough to comprehend.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency -  5</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  4</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.2</strong></p>

<h3 id="8-finxter">8. <a href="https://blog.finxter.com/blog/">Finxter</a></h3>

<p><em><a href="https://blog.finxter.com/feed/">RSS</a>, <a href="https://twitter.com/finxterdotcom?lang=en">Twitter</a></em></p>

<p>Finxter is an educational Python blog that offers everything from newbie guides to intermediate puzzles to in-depth technical guides and challenges. Finxter has featured regular posts every month since 2012. The writing is good, not great, with marginal room for language improvement. Like many technical blogs, Finxter’s content quality is boosted by supportive links and applicable references.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  4</li>
  <li>Longevity - 5</li>
  <li>Technical Depth - 4</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.2</strong></p>

<h3 id="9-pyfound">9. <a href="https://pyfound.blogspot.com/">Pyfound</a></h3>

<p><em><a href="https://pyfound.blogspot.com/feeds/posts/default">RSS</a>, <a href="https://twitter.com/ThePSF">Twitter</a></em></p>

<p>PyFound is the Blog arm of the Python Foundation, which has published official development updates, industry conferences, and project timelines since 2011. While the blog is informative and provides useful links, it’s predicated on sharing the organization’s development progress and community events. If you sift through the event and fundraiser updates, you’ll find the technical subject matter is thoroughly researched, and the writing is clear, concise, and with few errors. New posts are sporadic but can be expected between one and five times per month.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  3</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 3</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="10-full-stack-python">10. <a href="https://www.fullstackpython.com/blog.html">Full Stack Python</a></h3>

<p><em><a href="https://www.fullstackpython.com/feed">RSS</a>, <a href="https://twitter.com/fullstackpython">Twitter</a></em></p>

<p><img src="https://i.imgur.com/U00VrJJ.png" alt="Full Stack Python blog"></p>

<p>Full Stack Python is a personally-managed blog for Python developers and devs to-be. Active since 2012, posts are a combination of original content and automatically aggregated posts from other publications. The articles are predominantly technical findings, explanations, tutorials, and the like. The blog’s content is in-depth, shows a range of technical expertise, and maintains a clear and concise voice with no major red flags. Unfortunately, new content is published unpredictably and in seemingly random batches.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  2</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="11-ned-batchelder">11. <a href="https://nedbatchelder.com/blog/tag/python.html">Ned Batchelder</a></h3>

<p><em><a href="https://nedbatchelder.com/blog/rss.xml">RSS</a>, <a href="https://twitter.com/nedbat">Twitter</a></em></p>

<p>Ned Batchelder is the personal blog of veteran Python developer Ned Batchelder, which is one of the original and oldest active Python blogs from the early 2000s. There’s plenty of content dating back nearly 20 years; some topics being detailed breakdowns, others simple one paragraph tips. Ned keeps his content simple with no frills. Blog posts are clear enough to get the point across while sacrificing some elegance. The only improvement I can recommend would be more frequent posts; you’d be lucky to get one per month. Fortunately, there’s a huge backlog of posts to study up on, and it comes directly from the mind of a programmer who’s experimented with and written Python longer than most.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency -  3</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="12-practical-business-python">12. <a href="https://pbpython.com/">Practical Business Python</a></h3>

<p><em><a href="https://pbpython.com/feeds/all.atom.xml">RSS</a>, <a href="https://twitter.com/chris1610">Twitter</a></em></p>

<p>Practical Business Python is a Python blog boasting a variety of applicable technical subjects, primarily around Python business use cases and operability versus podcasts or interviews. Articles demonstrate strong technical knowledge supported with pertinent screenshots. Most posts are more functional than fluid, but not without references or properly supportive links. Followers can expect 1-2 posts sporadically per month but should be entertained while they wait by perusing the trove of articles going back to 2014.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  3</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="13-python-tips--yasoobme">13. <a href="https://yasoob.me/">Python Tips / Yasoob.me</a></h3>

<p><em><a href="https://yasoob.me/index.xml">RSS</a>, <a href="https://twitter.com/yasoobkhalid">Twitter</a></em></p>

<p>Python Tips is a personal blog that explores technical applications and nuances of Python. You’ll find a large collection of articles, guides, explanations, and deep-dives, sure to be useful for most Python programmers. Yasoob, the blog’s sole writer since 2013, showcases a strong technical grasp of the whats, wheres, whens, whys, and hows to walk the reader through complex concepts with clarity and detail. Its usefulness is hamstrung by periods of sporadic posting, followed by 2-3 months of silence. Like many technical blogs, the articles are informative and packed with data and supporting links, but also reads like many technical blogs: substance over aesthetics.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency -  3</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="14-invent-with-python">14. <a href="http://inventwithpython.com/">Invent with Python</a></h3>

<p><em><a href="https://twitter.com/AlSweigart">Twitter</a></em></p>

<p>Invent with Python is an educational programming blog by Al Sweigart, a Python veteran, and teacher. The blog is predicated on providing free tools, guides, courses, and tutorials to help beginners learning to code. You’ll find technical …</p></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learn.draft.dev/technical-blogs/python">https://learn.draft.dev/technical-blogs/python</a></em></p>]]>
            </description>
            <link>https://learn.draft.dev/technical-blogs/python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625999</guid>
            <pubDate>Tue, 29 Sep 2020 10:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forgetting as a Form of Feedback]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24625674">thread link</a>) | @olalola
<br/>
September 29, 2020 | https://universeofmemory.com/forgetting-as-a-form-of-feedback/ | <a href="https://web.archive.org/web/*/https://universeofmemory.com/forgetting-as-a-form-of-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tve_flt"><div id="tve_editor" data-post-id="13036"><div><p>Forgetting is as integral to our lives as it is disliked. It takes many forms - from the nastiest ones, i.e. neurodegenerative diseases (e.g. Alzheimer's), to relatively innocent ones (why am I standing in front of the open refrigerator again?!)</p><p>No wonder <strong>we treat this phenomenon as our worst enemy</strong>. After all, it robs you of the fruits of your work. You have put so much work into acquiring a given skill, and after a couple of months not much is left in your head. As depressing as it all might seem, I would like to show you a different perspective.</p><p><strong>What if forgetting is not your opponent but your ally?</strong></p><p>Your brain is actively working to make you forget most of the things you've come into contact with. It is the most sophisticated spam filter in the world. This process allows you to focus on the most important information. In other words,</p></div><div><div><p data-css="tve-u-174c11f34ce"><strong>forgetting is one of the best forms of feedback.</strong></p></div></div><p>It took me many years to understand this simple truth. It was also a turning point for me, which completely changed the memory systems I created at that time. Since, as far as I know, this concept is not widely discussed, I hope this article will be a sort of "memory awakening" for you.</p><div><h2>What Is the Purpose of Memory?</h2><p>Many people believe that the purpose of memory is to store information as accurately as possible. I think this is an erroneous perspective.</p></div><div><div><p><strong>Memory serves to guide and optimize decision-making by sticking only to meaningful and valuable information.</strong></p></div></div><p>I could describe a lot of memory processes that take place during the stage of encoding or information retrieval. Still, I think it's better to focus on a very logical and practical example.</p><div><h3>Optimization of decision-making processes as exemplified by crossing the street</h3><p>Think for a moment how much information you need to safely walk from one side of the street to the other.</p><h5>While performing this activity, do you analyze:</h5></div><div data-icon-code="icon-check" data-css="tve-u-174c1228afc"><ul><li><span data-css="tve-u-174c1228aff">Wind speed?</span></li><li><span data-css="tve-u-174c1228b01">Type of surface?</span></li><li><span data-css="tve-u-174c1228b03">The number of people in front of you?</span></li><li><span data-css="tve-u-174c1228b05">The number of people on your sides?</span></li><li><span data-css="tve-u-174c1228b08">The distance you have to travel?</span></li><li><span data-css="tve-u-174c1228b0a">Air humidity?</span></li><li><span data-css="tve-u-174c1228b0c">Surface moisture?</span></li></ul></div><p>Of course not.</p><div><div><p data-css="tve-u-174c6a21c61"><strong>Too much irrelevant information is detrimental to a given decision-making process.</strong></p></div></div><div><p>If you really had to take into account all this information, it would take you forever to make any decision at all. In other words, the process would not be optimal, also energy-wise.</p><h5>Thus, it is much easier to focus on activities such as:</h5></div><div data-icon-code="icon-check" data-css="tve-u-174c1238c0a"><ul><li><span data-css="tve-u-174c1238c0c">checking if there are traffic lights at the crosswalk,</span></li><li><span data-css="tve-u-174c1238c0f">making sure the light is green,</span></li><li><span data-css="tve-u-174c1238c11">looking to your left and right (and left again).</span></li></ul></div><div><p>As you can see, <strong>a handful of relevant information can be more valuable to the brain than a ton of meaningless data</strong>. However, we shouldn't forget that it doesn't make sense to remember much—quite the contrary. The trick is to <a href="http://universeofmemory.com/biggest-problem-in-learning-effectively/" target="_blank" spellcheck="false" data-css="tve-u-174c6a391b8">combine the memorized information into meaningful scripts</a> that can be activated in a given situation.</p><p>In the example above, a type of surface is almost certainly a useless piece of information. Nevertheless, if our decision-making process required making sure that we can do a dangerous stunt on the said surface, it would be one of the first factors that should be taken into consideration.</p></div><div><h2>What Kind of Information Is Meaningful To Your Brain?</h2></div><p><span><a href="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg" target="_blank"><img alt="Forgetting" data-id="13043" width="642" data-init-width="1920" height="428" data-init-height="1280" title="Forgetting" loading="lazy" src="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg" data-width="642" data-height="428" data-link-wrap="true" data-css="tve-u-174c152fca7" srcset="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg 1920w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-300x200.jpg 300w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1024x683.jpg 1024w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-768x512.jpg 768w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-600x400.jpg 600w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1536x1024.jpg 1536w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1320x880.jpg 1320w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-272x182.jpg 272w" sizes="(max-width: 642px) 100vw, 642px" data-lazy-srcset="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg 1920w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-300x200.jpg 300w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1024x683.jpg 1024w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-768x512.jpg 768w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-600x400.jpg 600w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1536x1024.jpg 1536w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1320x880.jpg 1320w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-272x182.jpg 272w" data-lazy-src="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></span></p><div><p>Another question we have to answer is what information the brain perceives as valuable, and what information is the equivalent of food scraps at the bottom of the dishwasher.</p><h5>In simple terms, information must meet two main criteria to be considered valuable:</h5></div><div data-icon-code="icon-check" data-css="tve-u-174c12130a6"><ul><li data-css="tve-u-174c6a41120"><span data-css="tve-u-174c120bb0a">frequently appear in your immediate environment,</span></li><li data-css="tve-u-174c6a41120"><span data-css="tve-u-174c120bb0a">it must be related to your life, i.e. be relevant to you.</span></li></ul></div><p>I will discuss them in more detail later in this article. At the moment, it is worth looking at how slowly we forget information when the above two criteria are met.</p><div><h2>Almost Complete Elimination of Forgetting</h2></div><div><h3>Problems with research on memory</h3><p>One of the big problems that plague most of the memory studies is that<strong> they are often detached from reality</strong>. The overwhelming majority of them are carried out in laboratories. I know what you are thinking. Why would that be a disadvantage?</p><p>Laboratories are artificial creations which, according to the rules of the scientific method, try to limit the number of variables that affect the tested value as much as possible. It sounds nice until we realize that <strong>our memory does not work in a vacuum</strong>. <strong>Hundreds of stimuli and information constantly flood our minds</strong><strong>.</strong> One should not try to artificially separate them from the process of memorizing and retrieving data.</p><p>The effect is that most such studies come to conclusions that are as out of touch with reality as a team of Marvel superheroes from a nearby asylum.</p><p>What's even worse is that there are quite a few people who accept this nonsense uncritically. I often hear some strange websites or YT channels saying that "in this or that study, scientists proved (sic!) that if you imagine that you have an orange on the top of your head, your ability to remember and concentrate will increase by 15%".</p><p>I wish it were an anecdote, but the video had over 100k views and lots of positive comments at the time. In my mind's eye, I could almost see 20,000 people sitting with their eyes rolled over and the face of a constipated walrus wondering why memorizing books didn't get any easier.</p></div><div><h3>Forgetting names - Bahrick's and Wittlinger's research</h3><p>Bahrick is one of my favorite memory researchers. He was one of the first scientists to insist that research of this kind be carried out outside the laboratory, despite the difficulties it poses.</p><p>One of his groundbreaking works, which he did in 1975 with Wittlinger, is about remembering the names and faces of high school friends over many years. The study lasted 50 years (!!!), and it showed for many years<strong>&nbsp;after graduating from high school, the process of forgetting this information occurred only slightly.&nbsp;</strong>Although, as always, the active recall was the first to go.</p></div><p><span><a href="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png" target="_blank"><img alt="" data-id="13052" width="505" data-init-width="505" height="473" data-init-height="473" title="Bahrick - Names Forgetting" loading="lazy" src="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png" data-width="505" data-height="473" data-link-wrap="true" srcset="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png 505w, https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting-300x281.png 300w" sizes="(max-width: 505px) 100vw, 505px" data-lazy-srcset="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png 505w, https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting-300x281.png 300w" data-lazy-src="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></span></p><div><p>You can conduct this experiment virtually. Assuming a minimum of 10 years has passed since you have graduated from high school, check if you can still remember everyone in your class? I know I certainly didn't have almost any problems with it.</p></div><div><h3>How to explain the almost complete absence of forgetting over a long period?</h3><p>In one of my past articles,&nbsp;<a data-saferedirecturl="https://www.google.com/url?q=https://universeofmemory.com/optimize-your-repetitions/&amp;source=gmail&amp;ust=1601053411857000&amp;usg=AFQjCNGEsWrkDpiWu5XTxXC7R1uMEXDm_Q" href="https://universeofmemory.com/optimize-your-repetitions/" target="_blank" spellcheck="false" data-css="tve-u-174c125ee3c">I mentioned the Ebbinghaus curve</a>:</p></div><p><span><a href="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg" target="_blank"><img alt="the Ebbinghaus curve - Forgetting as a Form of Feedback" data-id="13040" width="767" data-init-width="767" height="434" data-init-height="434" title="the Ebbinghaus curve - Forgetting as a Form of Feedback" loading="lazy" src="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg" data-width="767" data-height="434" data-link-wrap="true" srcset="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg 767w, https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1-300x170.jpg 300w, https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1-600x340.jpg 600w" sizes="(max-width: 767px) 100vw, 767px" data-lazy-srcset="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg 767w, https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1-300x170.jpg 300w, https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1-600x340.jpg 600w" data-lazy-src="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></span></p><div><p>Notice how huge the difference in retention (i.e., keeping the information in your head) is between Bahrick's and Ebbinghaus's experiment. Even after 7 years, the retention of names was higher than the retention of meaningless knowledge presented by the Ebbinghaus curve after 20 minutes.</p><p>The explanation for this phenomenon is based on many elements.&nbsp;</p></div><div><h4>1. High frequency of repetitions</h4><p>Note that the contact with first and last names in high school is extremely common, be it during the roll call or the regular socialization with your peers. What's more, almost all children are forced continuously to retrieve this knowledge. It would be difficult to get through high school only by yelling, "Hey you!"</p></div><div><h4>2. Relevance of the information</h4><p>Ebbinghaus tested the information decay by memorizing nonsense letter clusters. Bahrick, on the other hand, demonstrated how we absorb vital information in the real world.</p><p>It is worth mentioning that the relevance of information automatically means one more thing -<strong> emotional load</strong>. It doesn't matter if it's positive or negative. <strong>It is an inherent factor modulating your ability to remember.</strong></p><p>The meaningfulness of the information is a very personal and individual thing. Two different people may perceive the same facts as useless or vital. It is reflected in another one of Bahrick's (1984) studies, that showed that college professors have difficulties with remembering their students' name.</p><p>Can you see that contrast? Of course, one might argue that the frequency of information, in this case, is much lower. However, in my opinion, the decisive factor here is the indifference of lecturers. Most students are as important to them as half-dried pigeon carrion on the side of the road.</p><p>Of course, we could name more factors that contributed to the almost complete absence of forgetting in the first study. However, I think that the ones mentioned above are the most important.</p></div><div><h2>Forgetting as a Form of Feedback, I.e. What Information Does It Provide You With?</h2><p>The example above does not seem to be fully related to subjects such as physics, foreign languages or medicine. Regardless, I hope it convinced you of one thing - <strong>the frequency and relevance of information are among the most critical factors affecting your ability to remember information.</strong></p><p>Thus, from now on, I would like you to change your mind about the phenomenon of forgetting. Don't see it as something negative.</p></div><div><div><p>Treat forgetting as the best possible form of feedback.</p></div></div><div><p>If you can't keep information in your head, your brain is trying to subtly say, "Hey buddy! Don't even try to make me remember this string of numbers. I don't know; I don't understand, I don't care. When are we going to do something exciting like tap dancing in banana peel shoes?&nbsp;</p><p>Whenever you cannot recall information, you should ask yourself, "How can I modify it so that it makes more sense to my brain?"</p></div><div><h2>Forgetting as a Form of Feedback - Three Main Takeaways</h2></div><div><h3>1. Too little interaction with the information</h3><p>Consider whether you should <strong>increase the frequency of a given element</strong>. If you use programs like <a href="https://apps.ankiweb.net/" target="_blank"><strong>ANKI</strong></a>, it happens organically to some degree.</p></div><div><h3>2. No connection between the element and your background knowledge</h3></div><p><span><a href="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg" target="_blank"><img alt="Forgetting as a Form of Feedback" data-id="13044" width="700" data-init-width="1602" height="1119" data-init-height="2560" title="Forgetting as a Form of Feedback" loading="lazy" src="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg" data-width="700" data-height="1119" data-link-wrap="true" data-css="tve-u-174c158a579" srcset="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg 1602w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-188x300.jpg 188w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-641x1024.jpg 641w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-768x1227.jpg 768w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-600x959.jpg 600w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-961x1536.jpg 961w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-1282x2048.jpg 1282w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-1320x2109.jpg 1320w" sizes="(max-width: 700px) 100vw, 700px" data-lazy-srcset="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg 1602w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-188x300.jpg 188w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-641x1024.jpg 641w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-768x1227.jpg 768w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-600x959.jpg 600w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-961x1536.jpg 961w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-1282x2048.jpg 1282w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-1320x2109.jpg 1320w" data-lazy-src="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></span></p><div><p>Your brain is a very practical sponge. If it finds no connection between an item and the rest of the information you have in mind, it considers that item to be irrelevant. Thus, this information is forgotten very quickly (see&nbsp;<a data-saferedirecturl="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Forgetting_curve&amp;source=gmail&amp;ust=1601053411857000&amp;usg=AFQjCNHwsdgc6CGBmdmZXERAk99urdfR5A" href="https://en.wikipedia.org/wiki/Forgetting_curve" target="_blank" spellcheck="false" data-css="tve-u-174c134a01a">Ebbinghaus forgetting curve</a>).</p><p><strong>If you want to remember a given piece of information, there is nothing to prevent more than one flashcard from encoding a given word or concept.</strong></p></div><div><h3>3. Lack of the relevance of the information</h3><p>The relevance of information always means one thing - emotional load. It is the basis of the so-called&nbsp;<a data-saferedirecturl="https://www.google.com/url?q=https://link.springer.com/chapter/10.1007/978-3-319-67615-9_1%23:~:text%3DAlthough%252520the%252520issues%252520around%252520emotions%252Cdriven%252520or%252520at%252520least%252520enhanced.&amp;source=gmail&amp;ust=1601053411857000&amp;usg=AFQjCNHjnV_mlGqfTGocZFiAHMhdHOqj9A" href="https://link.springer.com/chapter/10.1007/978-3-319-67615-9_1#:~:text=Although%2520the%2520issues%2520around%2520emotions%2Cdriven%2520or%2520at%2520least%2520enhanced." target="_blank" spellcheck="false" data-css="tve-u-174c134c638">affective learning</a> that is <strong>related to feelings and emotions</strong>.</p><p>If you …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://universeofmemory.com/forgetting-as-a-form-of-feedback/">https://universeofmemory.com/forgetting-as-a-form-of-feedback/</a></em></p>]]>
            </description>
            <link>https://universeofmemory.com/forgetting-as-a-form-of-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625674</guid>
            <pubDate>Tue, 29 Sep 2020 09:45:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Encrypted CRDTs for building privacy focused collaborative software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24625563">thread link</a>) | @kn8
<br/>
September 29, 2020 | https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/ | <a href="https://web.archive.org/web/*/https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="reach-skip-nav"><div><p>I want to be able to build privacy focused applications that are as powerful and as user friendly as the “traditional” web apps we’re so used to today.</p>
<p><strong>Privacy focused</strong> means the application developers never get to see the content their users are creating - your data is yours only. <strong>Powerful</strong> means real-time collaboration between multiple users, search, notifications. <strong>User friendly</strong> means it’s easy to access or recover your data on a new device and easy to invite collaborators.</p>
<p>And that’s really hard today. Really really hard.</p>
<h2>Why do it?</h2>
<p>Why should we even care about building privacy focused applications? Why does privacy matter? Privacy might sometimes feel like a philosophical topic, but it’s one with very real life altering and threatening implications (including <a href="https://time.com/5290043/nazi-history-eu-data-privacy-gdpr/" target="_blank" rel="noopener">the Holocaust</a>). I won’t be tackling this question in more depth here and if you want to learn more about the importance of privacy I recommend reading <a href="https://www.amazon.co.uk/Identity-Reboot-Reimagining-Privacy-Century/dp/1916314414" target="_blank" rel="noopener">Identity Reboot: Reimagining Data Privacy for the 21st Century</a> by Arwen Smit.</p>
<p>“Privacy focused” can mean many things and is a really broad topic. This article looks specifically at collaborative content creation tools such as Google Docs and Slack - tools that individuals, teams and communities use to create private digital content. End-to-end encryption or removal of centralised servers could offer a technical solution to enhanced privacy in such applications. Public digital content creation like Wikipedia and Twitter, ambient content collection such as Amazon Alexa and Tesla car recordings and many other digital privacy issues are not considered in this article.</p>
<h2>Misaligned incentives</h2>
<p>Building collaborative content creation applications such as Google Docs, Asana or Slack, but in a way where all the content is end-to-end encrypted and only accessible to the content creators is technically very difficult. We will look at some of the technical challenges in more depth in the remainder of the article, but here are a few:</p>
<ul>
<li>added UX challenges of handling encryption keys</li>
<li>handling real-time collaborations on encrypted data</li>
<li>search over encrypted data is difficult to impossible</li>
<li>debugging, optimizing and supporting customers all become more difficult</li>
</ul>
<p>Technical overhead alone removes a lot of the incentive for any company to even try. What’s more, having access to the raw data provides companies with extra value. Data can be used to power features (e.g. Gmail’s smart compose) and data is what created today’s most profitable businesses by fuelling Ad targeting.</p>
<p>There’s also the fact that end-to-end encryption is not applicable to every type of application. E.g. building a web search engine, wikipedia or a social network does not require all of the content to be encrypted end-to-end. The fact that this problem is not universal further reduces the incentive to tackle it.</p>
<p>And so we have a chicken and egg problem, where lack of incentives means progress on technological solutions is slow, mostly being pushed forward by decentralisation hackers and academic researchers, while many of the world’s engineers are being paid to do the opposite - extracting more value from the data.</p>
<p>To make matters worse, end-to-end encryption tech could become more and more government regulated at any point. Perhaps anecdotal, but COVID-19 created an incentive to build a <a href="https://twitter.com/romy/status/1303852660320215042" target="_blank" rel="noopener">privacy focused exposure notification system</a> (great!), but it’s also up to the governments to opt into it, and <a href="https://twitter.com/babynewt_/status/1304052101883064320" target="_blank" rel="noopener">not all of them are doing so</a>.</p>
<h2>Encryption trade offs</h2>
<p>To be clear, I’m not saying that encrypting all of the content is necessarily the best thing to do. Amassing data centrally can be of value not just to the companies, but to the users and society at large. While it might be possible to power a lot of innovative technology in a privacy focused manner, such as utilising on-device machine learning, it’s probably more efficient to develop say self driving cars if you can collect real video data from as many cars as possible.</p>
<p>And even if you’re not extracting value from data, storing unencrypted data is simpler and more efficient. It’s also more convenient for the users as the data is always backed up and easy to access from any device.</p>
<p>All that, coupled with the technical difficulty of creating end-to-end encrypted applications, it might well be the case that we will always have to lean on privacy policies, government regulations and put trust in companies when it comes to protecting our data.</p>
<h2>Privacy focused software landscape</h2>
<p>Nevertheless, high quality tools that are built in a privacy focused manner do exist. Perhaps most impressively - WhatsApp with its mass deployment of end-to-end encryption tech (Facebook ownership aside), as well as similar messaging apps, Signal and Wire. Then there’s ProtonMail providing the end-to-end encrypted email service. And 1Password, a cloud backed encrypted password manager.</p>
<p>Another, less known tool built on cutting edge tech is <a href="https://scuttlebutt.nz/" target="_blank" rel="noopener">Scuttlebutt</a> a fully decentralised (and fully functional) p2p social network. Scuttlebutt, which is similar to Twitter, does not utilise end-to-end encryption (for the social networking functionality), but it’s built in a way that means it works entirely without any servers (!). It’s completely p2p and it’s impressive that they made it work so well. BitTorrents are p2p and they work too, but that’s static file sharing, where Scuttlebutt is a living, breathing, dynamic social network with messages getting posted and propagated to the relevant peers all the time. I bring up Scuttlebutt, because as we see later it can inform the architecture of building privacy focused collaborative software.</p>
<p><em>Tangent: Speaking of privacy, election meddling and Scuttlebutt… Scuttlebutt can be viewed as an alternative to Facebook’s centralised approach. Facebook’s data is behind a login and access is monitored and limited (not always true as we’ve seen with the Cambridge Analytica). While Scuttlebutt’s data is completely open for anyone to mine, archive and analyse. But Scuttlebutt doesn’t have profit motives or server costs and so does not need to create targeted Ad tools or even algorithmic feeds that were used in election meddling. Which approach is better?</em></p>
<p>Finally, <a href="https://bear.app/" target="_blank" rel="noopener">Bear</a> or <a href="https://culturedcode.com/things/" target="_blank" rel="noopener">Things</a> take a different privacy focused approach. Even though these apps do not encrypt the data, they store it in your private iCloud account, which means the app developers never get to see it. However, these apps do not offer collaboration. They are meant for single user only (with the exception of having to sync data across all of your devices, which they don’t always handle gracefully).</p>
<h2>Building a Google Docs alternative</h2>
<p>Is it possible then to build a multi user, collaborative, end-to-end encrypted, privacy focused Google Docs alternative? I picked Google Docs, because it’s so familiar and features what to this date remains to be such an impressive piece of tech – the real-time collaborative editing with shared cursors and comments. I don’t think anybody has done collaborative text editing better than Google Docs since it’s launch, at least not in such a widely used tool or in such a useful way.</p>
<p>To be able to answer if this is possible, let’s make a list of requirements.</p>
<h4>1. End-to-end encrypted</h4>
<p>Nobody, but the content creators get to see the content.</p>
<h4>2. Collaborative</h4>
<p>It should be as close as possible to the real-time collaborative editing experience of Google Docs – shared cursors and commenting. Not only that, but documents, entire collections of documents and application state, such as document tags and folder structures, should be easily shareable between multiple people.</p>
<h4>3. Easy sharing</h4>
<p>Sharing a document, a collection of documents, or inviting other people into your workspace should be easy enough so that anyone can do it (e.g. invite by email address as opposed to copying and pasting public keys).</p>
<h4>4. Search</h4>
<p>I should be able to search through all of the documents I have access to.</p>
<h4>5. Offline capable</h4>
<p>I’d like to be able to access and edit documents offline, without internet connection and sync later. Including any text edits and comment interactions.</p>
<h4>6. Backups</h4>
<p>If you drop your phone in the mud with all the documents, you can restore them from an encrypted cloud backup.</p>
<h4>7. High availability</h4>
<p>If I make changes to a document on my phone, those changes should propagate to other collaborators reliably and quickly even if they were offline at the time of me typing those changes. That is, collaborators don’t have to be online at the same time to sync their changes. Similarly, if you invite a new member to your workspace with some documents shared, they should be able to retrieve and decrypt those documents without any other collaborator being online.</p>
<h4>8. Stretch goal: p2p mode</h4>
<p>Ideally, the software, accepting some limitations (i.e. no high availability), should be able to work completely peer to peer. That is you should be able to opt out of any server participation and still be able to use the application in full even if the service provider shuts down, a longevity oriented approach.</p>
<p>Not all of the above requirements are strictly necessary for building privacy focused software, but they do interconnect in unexpected ways. For example, since search can not be done server side on the encrypted data, that implies having to store all the data on the client, making offline capability a useful side effect. In addition to privacy, these requirements try to incorporate longevity, data ownership and other ideas of <a href="https://www.inkandswitch.com/local-first.html" target="_blank" rel="noopener">Local-first software</a>.</p>
<h2>Possible approaches</h2>
<p>I can think of at least three distinctly different approaches to building an application like this. Let’s see how each of the approaches holds against our requirements.</p>
<h4>Traditional server/client web app</h4>
<p>You can most definitely create Google Docs as a web app (it is already a web app, duh). But once you add the data privacy or end-to-end encryption requirement, that’s when things get tricky.</p>
<p>For starters, powering a feature like Search becomes nearly impossible with encrypted content on the server. To be able to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/">https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/</a></em></p>]]>
            </description>
            <link>https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625563</guid>
            <pubDate>Tue, 29 Sep 2020 09:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the C++ standard library?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625526">thread link</a>) | @bvaldivielso
<br/>
September 29, 2020 | https://cor3ntin.github.io/posts/std/ | <a href="https://web.archive.org/web/*/https://cor3ntin.github.io/posts/std/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><a href="https://xkcd.com/2347/">
<img src="https://imgs.xkcd.com/comics/dependency.png">
</a>
</p>
<hr>
<p><strong>DISCLAIMER</strong></p>
<p>The following represent my opinions, not that of the C++ committee (WG21), any of its members or any other person mentioned in this article.</p>
<hr>
<p>I think the most fundamental work done by WG21 is trying to answer meta-questions about itself.
What is C++, what is its essence, what should we focus on? How to evolve a language with a growing community,
a growing committee?
A language that is deployed on billions of devices, with an estimated 50 billions actively maintained lines of code.
During a CppCon panel last week I was asked about stability VS evolution. This is a hot topic,
one that may never stop being on people’s mind.</p>
<p>There are a lot of interesting meta-questions worth asking about the standard library too.
A question that comes over and over again, is what does it mean to deprecate something, why and when.
Another is what to put in there to begin with.</p>
<p>I wrote a few times on the subject <a href="https://cor3ntin.github.io/posts/what_should_go_in_stl/">before</a>,
hopefully, I will be self-consistent. Not promising anything!</p>
<p>Bryce Adelstein Lelbach, then chair of LEWGI coined the phrase</p>
<blockquote>
<p>Knowing that our resources are scarce and our time is limited, do we want to give more time to this proposal?</p>
</blockquote>
<p>This has become somewhat of a meme in the committee.
Since then, we shipped C++20, Bryce became chair of LEWG (which is a super difficult job that he does brilliantly),
and oh. There is this pandemic you might have heard about.</p>
<p>Never have the scarcity of our resources and the limitedness of our time be more apparent.</p>
<p>We try to make the best of the situation, but I think it’s fair to say that WG21’s output is
reduced. And frankly, we cannot ask of anyone to prioritize C++ standardization with all that’s going on right now.
But even at the best of times, C++ library design is a costly, lengthy process involving a lot of people.
Which is good, <a href="https://en.wikipedia.org/wiki/Linus%27s_law">Linus’s law</a>, plays a huge role in the quality of the standard library.</p>
<p>I don’t know that this used to be a question anyone asked. For a very long time, there were few enough proposals
that they virtually could accept all of those they liked.
At the beginning of the committee, there even was a single pipeline for both language and library.
We can argue whether the separation of rooms we have today is always sensible.
Most of the time library features can be added without new language proposal, but at the same time ADL, customization points,
overload sets etc have been growing pain point for the library, and no organization can escape Conway’s law.</p>
<p>Anyway, the influx of new proposal has grown enough in the past few years that LEWG has now the luxury
and the burden to chose which direction to go in and how to use its far too limited time.</p>
<h2 id="standardization-is-expensive">Standardization is expensive</h2>
<p>I think the life cycle of a library feature goes a bit like this:</p>
<ul>
<li>Someone floats an idea and write a paper</li>
<li>The paper is matured over 1-10 years</li>
<li>There is some latency for implementations (6 months - 5 years) - at least 3 or 4 implementations</li>
<li>There is a ton of latency in deploying toolchains where people can use them (this might be a story for another day)</li>
<li>There is a literal ton of people writing blog posts / textbooks / conference talks about that one feature</li>
<li>Then there is a slow adoption and debate about whether adopting the feature is good or not</li>
</ul>
<p>And every step is resources constrained. Deprecation and removal is also very slow.
People are still using components that were deprecated 10, 20 years ago.</p>
<p>Critical flight software at NASA is estimated at 1000$ per line.
I wouldn’t be surprised if the standard library costs more.
And so, one of the way to answer
“Should that piece of code be in the standard” can maybe be reformulated as “Would this benefit from the standardization process?”</p>
<p>Fundamentally, that makes the standard library a bad package manager.
If the only motivation for something to be in the standard is to palliate to the lack of good package managers,
then it’s probably not a good motivation.
(Especially as the standard library is super bad at availability. it will be years until <code>&lt;ranges&gt;</code> is everywhere.)</p>
<p>Of course, that argument falls flat if you consider <code>std::vector</code>. It doesn’t <em>need</em> to be there, but we are all sure glad it is.
So there is an <em>universality</em> argument to be made too.
If something is universally useful (for example, 90% of programs would use it), then it starts to be a very compelling
feature for the standard library.</p>
<p>Some features can’t live anywhere but in the STL:</p>
<p>Type traits, and everything that needs or benefits from compiler magic and intrinsics.
<a href="http://eel.is/c++draft/support.srcloc">source_location</a>, <a href="https://wg21.link/p0881r6">std::stacktrace</a>, <a href="https://wg21.link/p1885r2">encoding detection</a>,
Reflection support library and other introspection capabilities, <a href="https://wg21.link/p0627r3">std::unreachable</a>, <a href="https://wg21.link/p1773r0">std::assume</a>,
<a href="https://wg21.link/p1040r6">std::embed</a>.
All of these are magic and rely on the compiler. In other words they cannot be implemented portably outside of the standard library.
These are necessary for communicating between user code and compiler, and are the basis of higher-level components.
A logger would use <code>std::source_location</code> for example.</p>
<p>This is especially true of reflection: until C++ gets reflection, an entire class of program cannot be written.
Pattern matching make it possible to write cleaner code. Reflection make it possible to write… code.
Code that you cannot otherwise emulate in standard C++, regardless how much you try.
And that can be pretty expensive across the industry.</p>
<p>So library components that make new things possible are high on the list of the things I think should go in the standard library.</p>
<p>Then, even more obvious, come amelioration to what’s already there.
As standard types get deployed, the committee has to improve them. Both in response to usage experience and to increase synergy between types
or add obvious features that were missing, bug fix, support for new language features.
As such, this <a href="https://wg21.link/p1679r3">std::string::contains</a> proposal might not be the most exciting that will land in 23,
but it might be one of the most useful for many people.</p>
<p>This is the rationale for my own  <a href="https://wg21.link/p2019r0">thread name proposal</a>.
It is not possible to name threads created by <code>std::thread</code>,
and people who rely on that (for ex. the game industry) need to write an entire thread class to replace <code>std::thread</code>, just for this extra piece of functionality.
Other people might give a name to their threads if it’s easy, but might not bother if it implies reimplementing <code>std::thread</code> themselves.
The cost/benefit of using a feature decreases if that feature is present in the standard library. But that is mostly true for small quality-of-life features,
not larger features that are application critical.</p>
<p>There are also vocabulary types: types that are designed to be the glue between libraries, a universal language for interface boundaries.
These get used everywhere. We spend a lot of time getting them right because of this by-design pervasiveness. <code>std::span</code> might simultaneously
be the simplest type of C++20 and also the one that took the most work getting right.
One example of glaringly missing vocabulary type is <a href="https://wg21.link/p1059r0"><code>std::expected</code></a>:
A type that is a bit stuck in another super important meta-conversation: What are the error handlings mechanism that should be used and promoted in C++?
We still have to answer that question.</p>
<p>But… I am not sure types are the right kind of entities at interfaces boundary.
Concepts make for a better vocabulary because they prescribe interfaces, not implementations. (<code>span</code> is nothing if not ““template erasure”” over any <code>contiguous_range</code>).
So maybe the standard library should mainly provide concepts to tie all 3rd parties together? The <code>&lt;concept&gt;</code> header is a good start here.</p>
<p>There is however an issue with just trying to add concepts in the standard.
Concepts are informed by concrete types and how they are used, they cannot be pulled out of thin air. Not without making mistakes anyway, and <a href="https://www.youtube.com/watch?v=v_yzLe-wnfk">concepts are not amendable to mistakes</a>.</p>
<p>So, it would seem that if the STL is to have concepts, it need algorithms.</p>
<blockquote><p lang="en" dir="ltr">Generic Programming pro tip: Although Concepts are constraints on types, you don't find them by looking at the types in your system. You find them by studying the algorithms.<a href="https://twitter.com/hashtag/cpp?src=hash&amp;ref_src=twsrc%5Etfw">#cpp</a></p>— Eric Niebler (@ericniebler) <a href="https://twitter.com/ericniebler/status/990390059579789312?ref_src=twsrc%5Etfw">April 29, 2018</a></blockquote>


<p>Good algorithms are agnostic of domain-specific knowledge and can be used in the widest variety of situations.
Algorithms are not useful to people who write games, or people who make microcontrollers, they are useful to people who write C++.
I’d write better code if I was able to recognise more algorithms.</p>
<p>A focus of C++20 was concepts and ranges, and I hope this remains the case in future versions of C++. views in particular are one of these things people might not actively looked for if available by default.
I sure think <code>views::product</code> is more maintainable than nested loops, but I might not try to find a library that has it, if it’s not in the standard.</p>
<p>So, magic types, vocabulary types, concepts and improvements of existing facilities. A good list of what might be LEWG priorities.</p>
<p>But what about networking, Unicode, processes, 15D graphics, audio, a web engine, ML facilities, JSON parsing, crypto, blockchains, Http, event handling, regexes that don’t suck, etc?</p>
<p>These sure make a great front page cover.
But here is the thing:</p>
<p>WG21 is… kinda bad at design?
Not because we are inherently inept, but because library design is fundamentally hard.
And what we understand to be good library design is a somewhat fast-moving target.</p>
<p>The STL is the foundation of the entire C++ ecosystem. And often used to demonstrate how to use new features and write good code. And we try to cover as many use cases as possible.
Design is finding a path in the maze of the design space, and at each crossing, we go in the direction that we think is the most widely useful.
Problem is, the numbers of crossings grows exponentially with the number of abstraction layers or the complexity of the domain.
It soon becomes impossible to please everybody, or even a majority of people.</p>
<p><code>vector</code> has a few knobs: allocation strategies, growth strategies, error handling etc. It’s a manageable number of knobs that we can tweak …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cor3ntin.github.io/posts/std/">https://cor3ntin.github.io/posts/std/</a></em></p>]]>
            </description>
            <link>https://cor3ntin.github.io/posts/std/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625526</guid>
            <pubDate>Tue, 29 Sep 2020 09:18:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Fix PostgreSQL Performance Issues with PG Extras]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625471">thread link</a>) | @todsacerdoti
<br/>
September 29, 2020 | https://pawelurbanek.com/postgresql-fix-performance | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/postgresql-fix-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <p><img title="PostgreSQL performance checklist is represented by a notebook Photo by Aaron Burden on Unsplash" alt="PostgreSQL performance checklist is represented by a notebook Photo by Aaron Burden on Unsplash" data-src="https://pawelurbanek.com/assets/postgres-performance-notebook-223d1a2313851e07a649511f2ec7d7d7bbcf49c50cff6fbccf133f7a50a164f1.jpg" src="https://pawelurbanek.com/assets/postgres-performance-notebook-thumb-d32ee718054bdb4e0941997a0fef3c2040885ba2197dfc125668a82f6dea1a0b.jpg">
    </p>
  

  

  <p>PostgreSQL database queries are a common performance bottleneck for web apps. Before you resort to more complex optimization techniques like caching or read replicas, you should double-check if your database engine is correctly tuned and queries are not underperforming.</p>

<p>PG Extras is a tool that allows you to spot common PostgreSQL pitfalls. <a href="https://github.com/pawurb/ruby-pg-extras" rel="noopener noreferrer" target="_blank">Ruby</a>, <a href="https://github.com/pawurb/rails-pg-extras" rel="noopener noreferrer" target="_blank">Rails</a>, <a href="https://github.com/pawurb/ecto_psql_extras" rel="noopener noreferrer" target="_blank">Elixir</a>, and <a href="https://github.com/pawurb/node-postgres-extras" rel="noopener noreferrer" target="_blank">NodeJS</a> implementations are currently available.</p>

<p>In this blog post, I present a step by step guide on using PG Extras library to spot and resolve common PostgreSQL database performance issues.</p>



<p>Please refer to READMEs of respective implementations for installation details.  API is almost identical for all the versions. Let’s compare the invocation of the <code>cache_hit</code> method:</p>

<p><code>Ruby</code></p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>cache_hit</span></code></pre></figure>

<p><code>Rails</code></p>

<figure><pre><code data-lang="ruby"><span>RailsPGExtras</span><span>.</span><span>cache_hit</span></code></pre></figure>

<p><code>Elixir</code></p>

<figure><pre><code data-lang="elixir"><span>EctoPSQLExtras</span><span>.</span><span>query</span><span>(</span><span>:cache_hit</span><span>,</span> <span>YourApp</span><span>.</span><span>Repo</span><span>)</span></code></pre></figure>

<p><code>NodeJS</code></p>

<figure><pre><code data-lang="javascript"><span>PostgresExtras</span><span>.</span><span>cache_hit</span><span>()</span></code></pre></figure>

<p>In this blog post, I’ll be using examples from the pure Ruby version.</p>

<h3 id="enable-pg_stat_statements-extension">Enable <code>pg_stat_statements</code> extension</h3>

<p>Some of the PG Extras methods depend on the <code>pg_stat_statements</code> extension. If you are using a default Heroku PostgreSQL plugin or <a href="https://aws.amazon.com/rds/" rel="noopener noreferrer" target="_blank">AWS RDS</a>, you should be good to go without making any changes.</p>

<p>To check if the extension is already enabled you can use PG Extras itself:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>extensions</span>

<span>...</span>
<span>|</span> <span>pg_stat_statements</span> <span>|</span> <span>1.7</span> <span>|</span> <span>1.7</span> <span>|</span> <span>track</span> <span>execution</span> <span>statistics</span> <span>of</span> <span>all</span> <span>SQL</span> <span>statements</span> <span>executed</span>
<span>...</span></code></pre></figure>

<p>If <code>pg_stat_statements</code> is not listed you should check out <a href="https://www.postgresql.org/docs/current/pgstatstatements.html" target="_blank">these docs</a> for info on installing it.</p>

<p>Now that you’ve set up the library in the language of your choice let’s start checking our database’s health.</p>

<p><strong>[Important]</strong> <em>Make certain to run all the checks on a warmed up production database. Under the hood, PG Extras performs a lightweight queries on PostgreSQL metadata tables. It will not impact your production workload.</em></p>

<h2 id="1-validate-your-database-specs-with-cache-hit-ratios">1) Validate your database specs with cache hit ratios</h2>

<p>In theory, the simplest solution to optimize the underperforming database is to scale it up vertically. Before you start throwing money at your performance issues, it’s good to check if it will actually help.</p>

<p>PostgreSQL tracks access patterns of your data and keeps frequently read chunks in a memory cache. A reliable indicator that a database should be scaled up is an invalid cache hit ratio.</p>

<p>You can check index and table cache hit ratios using the following code:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>cache_hit</span>

      <span>name</span>      <span>|</span>         <span>ratio</span>
<span>----------------+------------------------</span>
 <span>index</span> <span>hit</span> <span>rate</span> <span>|</span>        <span>0.999577</span>
 <span>table</span> <span>hit</span> <span>rate</span> <span>|</span>        <span>0.988721</span></code></pre></figure>

<p>If you want to drill down into each individual’s table and index cache hit ratios, you can use <code>table_cache_hit</code> and <code>index_cache_hit</code> methods.</p>

<p>The rule of the thumb is that values should be above 99%. If your database cache hit ratios are lower, it’s either not correctly configured or should be scaled up to increase the performance.</p>

<p>Heroku PostgreSQL ships with already optimized settings and does not allow you to change them. If you see low cache hit ratios, your best bet is to provision a more powerful database instance.</p>

<p>Amazon RDS is notorious for shipping the database instances with incorrect default settings. If you’re using it, make sure to tweak them before deciding to scale up the instance. <a href="https://pgtune.leopard.in.ua/" rel="noopener noreferrer" target="_blank">PGTune</a> is the best tool to help you tweak the most important Postgres buttons and dials to the correct values.</p>

<h2 id="2-remove-unused-indexes">2) Remove unused indexes</h2>

<p>Overusing indexes is a recipe for a sluggish web app.</p>

<p>The more indexes you add, the more write operations have to be performed on each data update. Misconfigured indexes also tend to unecessarily bloat the size of a database, slowing down the backup/restore/upgrade operations.</p>

<p>It’s entirely possible that some of your indexes and not used and can be safely removed.</p>

<p>PG Extras <code>unused_indexes</code> method can help you spot them:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>unused_indexes</span>

          <span>table</span>      <span>|</span>                       <span>index</span>                <span>|</span> <span>index_size</span> <span>|</span> <span>index_scans</span>
<span>---------------------+--------------------------------------------+------------+-------------</span>
 <span>public</span><span>.</span><span>grade_levels</span> <span>|</span> <span>index_placement_attempts_on_grade_level_id</span> <span>|</span> <span>97</span> <span>MB</span>      <span>|</span>           <span>0</span>
 <span>public</span><span>.</span><span>observations</span> <span>|</span> <span>observations_attrs_grade_resources</span>         <span>|</span> <span>33</span> <span>MB</span>      <span>|</span>           <span>0</span>
 <span>public</span><span>.</span><span>messages</span>     <span>|</span> <span>user_resource_id_idx</span>                       <span>|</span> <span>12</span> <span>MB</span>      <span>|</span>           <span>0</span></code></pre></figure>

<p>Few <code>index_scans</code> on an index that has been around for a while means that it should be removed. If the index is large, remember to use the <a href="https://www.postgresql.org/docs/current/sql-dropindex.html" rel="noopener noreferrer" target="_blank"><code>CONCURRENTLY</code></a> option when dropping it, to avoid exclusively blocking the whole related table.</p>

<p><code>index_size</code> method can give you a quick overview of how much space your database indexes are taking:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>index_size</span>

     <span>name</span>            <span>|</span>  <span>size</span>
<span>-----------------------------------------------</span>
 <span>index_a_name</span>        <span>|</span> <span>5196</span> <span>MB</span>
 <span>index_b_name</span>        <span>|</span> <span>4045</span> <span>MB</span>
 <span>index_b_name</span>        <span>|</span> <span>2611</span> <span>MB</span></code></pre></figure>

<h2 id="3-add-missing-indexes">3) Add missing indexes</h2>

<p>Now that we’ve removed unused indexes, let’s add some new ones. We don’t want them to share the fate of their recently deprovisioned cousins. Let’s look at PG Extras <code>seq_scans</code> and <code>calls</code> methods before deciding on what should be indexed.</p>

<p>A <em>sequential scan</em> is an action that Postgres performs if it cannot find an index necessary to fulfill the query condition. For the following query:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>*</span> <span>FROM</span> <span>USERS</span> <span>WHERE</span> <span>AGE</span> <span>=</span> <span>18</span><span>;</span></code></pre></figure>

<p>the related <code>EXPLAIN ANALYZE</code> query output will show <code>Seq scan on users Filter: AGE = 18</code> or <code>Index Scan using users_age_index Index Cond: AGE = 18</code> depending on whether the index on <code>age</code> column is present or not.</p>

<p><code>seq_scans</code> method displays the number of <code>Seq Scan</code> operations for each table:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>seq_scans</span>

               <span>name</span>                <span>|</span>  <span>count</span>
<span>-----------------------------------+----------</span>
 <span>learning_coaches</span>                  <span>|</span> <span>44820063</span>
 <span>states</span>                            <span>|</span> <span>36794975</span>
 <span>grade_levels</span>                      <span>|</span> <span>13972293</span>
 <span>charities_customers</span>               <span>|</span>  <span>8615277</span></code></pre></figure>

<p>Now that we know which tables are often read inefficiently, we can use <code>calls</code> and <code>outliers</code> methods to list the most often executed and most time-consuming queries.</p>

<p>Both of those methods let you extract the raw query string. You can use it to perform <code>EXPLAIN ANALYZE</code> and check if the query planner does <code>Seq scan</code> on one of the tables.</p>

<p>By correlating all those sources of data, you should be able to spot queries that are consuming a lot of your database resources and are potentially missing an index.</p>

<p>Watch out to avoid premature optimization by adding unnecessary indexes. PostgreSQL will often fallback to <code>Seq Scan</code> instead of <code>Index Scan</code> on small tables, for which using the index would be less efficient than reading the whole table row by row.</p>

<h2 id="4-identify-deadlocks">4) Identify deadlocks</h2>

<p>PostgreSQL uses locks to ensure data consistency in multithreaded environments. There are different kinds of locks, but we’ll focus on <code>ExclusiveLock</code> and <code>RowExclusiveLock</code>. A healthy web app should never lock for more than a couple of hundred of miliseconds.</p>

<p>Deadlock is two more or database locks blocking each other and not able to continue execution. An implementation error that results in a deadlock might have disastrous consequences for your application. The queue of requests not able to proceed could start piling up and eventually crash your servers.</p>

<p>Common reasons for deadlocks and locks that are granted for too long:</p>

<ul>
  <li>too broad database transaction scope</li>
  <li>adding or removing index without using the <code>CONCURRENTLY</code> option</li>
  <li>updating lots of rows at once</li>
  <li>adding a new column with the default value (before PostgreSQL 12)</li>
</ul>

<h3 id="how-to-detect-locks-and-deadlocks">How to detect locks and deadlocks</h3>

<p>You can use <code>locks</code> method to see all the currently obtained locks together with the source query:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>locks</span>

 <span>procpid</span> <span>|</span> <span>relname</span> <span>|</span> <span>transactionid</span> <span>|</span> <span>granted</span> <span>|</span>     <span>query_snippet</span>     <span>|</span> <span>mode</span>             <span>|</span>       <span>age</span>
<span>---------+---------+---------------+---------+-----------------------+-------------------------------------</span>
   <span>31776</span> <span>|</span>         <span>|</span>               <span>|</span> <span>t</span>       <span>|</span> <span>&lt;</span><span>IDLE</span><span>&gt;</span> <span>in</span> <span>transaction</span> <span>|</span> <span>ExclusiveLock</span>    <span>|</span>  <span>00</span><span>:</span><span>19</span><span>:</span><span>29.837898</span>
   <span>31776</span> <span>|</span>         <span>|</span>          <span>1294</span> <span>|</span> <span>t</span>       <span>|</span> <span>&lt;</span><span>IDLE</span><span>&gt;</span> <span>in</span> <span>transaction</span> <span>|</span> <span>RowExclusiveLock</span> <span>|</span>  <span>00</span><span>:</span><span>19</span><span>:</span><span>29.837898</span>
   <span>31912</span> <span>|</span>         <span>|</span>               <span>|</span> <span>t</span>       <span>|</span> <span>select</span> <span>*</span> <span>from</span> <span>hello</span><span>;</span>  <span>|</span> <span>ExclusiveLock</span>    <span>|</span>  <span>00</span><span>:</span><span>19</span><span>:</span><span>17.94259</span>
    <span>3443</span> <span>|</span>         <span>|</span>               <span>|</span> <span>t</span>       <span>|</span>                      <span>+|</span> <span>ExclusiveLock</span>    <span>|</span>  <span>00</span><span>:</span><span>00</span><span>:</span><span>00</span></code></pre></figure>

<p>The mere presence of locks does not mean that something is wrong with your database. Only locks that are granted for too long are potentially problematic. You can use the following Ruby snippet integrated into the background job to alert you if this happens:</p>

<figure><pre><code data-lang="ruby"><span>TRESHOLD_SECONDS</span> <span>=</span> <span>1</span>

<span>long_locks</span> <span>=</span> <span>RubyPGExtras</span><span>.</span><span>locks</span><span>(</span><span>in_format: :hash</span><span>).</span><span>select</span> <span>do</span> <span>|</span><span>lock</span><span>|</span>
  <span>Time</span><span>.</span><span>parse</span><span>(</span><span>lock</span><span>.</span><span>fetch</span><span>(</span><span>"age"</span><span>)).</span><span>seconds_since_midnight</span> <span>&gt;</span> <span>TRESHOLD_SECONDS</span>
<span>end</span>

<span>raise</span> <span>"Long running locks: </span><span>#{</span><span>long_locks</span><span>}</span><span>"</span> <span>if</span> <span>long_locks</span><span>.</span><span>present?</span></code></pre></figure>

<p>If you notice extended locks, you can use the <code>blocking</code> method to check which SQL statements cannot continue execution because of a lock:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>blocking</span>

 <span>blocked_pid</span> <span>|</span>    <span>blocking_statement</span>    <span>|</span> <span>blocking_duration</span> <span>|</span> <span>blocking_pid</span> <span>|</span>                                        <span>blocked_statement</span>                           <span>|</span> <span>blocked_duration</span>
<span>-------------+--------------------------+-------------------+--------------+------------------------------------------------------------------------------------+------------------</span>
         <span>461</span> <span>|</span> <span>select</span> <span>count</span><span>(</span><span>*</span><span>)</span> <span>from</span> <span>app</span> <span>|</span> <span>00</span><span>:</span><span>00</span><span>:</span><span>03</span><span>.</span><span>838314</span>   <span>|</span>        <span>15682</span> <span>|</span> <span>UPDATE</span> <span>"app"</span> <span>SET</span> <span>"updated_at"</span> <span>=</span> <span>'2013-03-04 15:07:04.746688'</span> <span>WHERE</span> <span>"id"</span> <span>=</span> <span>12823149</span> <span>|</span> <span>00</span><span>:</span><span>00</span><span>:</span><span>03</span><span>.</span><span>821826</span></code></pre></figure>

<p>If your app is crashing because of deadlocks, you can use the <code>kill_all</code> to terminate all the database processes before you manage to resolve the underlying cause.</p>

<h2 id="5-get-rid-of-unnecessary-bloat">5) Get rid of unnecessary bloat</h2>

<p>The way PostgreSQL works is that it never updates or removes the data in place but instead marks each row as visible or not for transactions using two meta columns <code>xmin</code> and <code>xmax</code>. Rows no longer visible for any of the currently active transactions are called <em>dead rows</em> or <em>bloat</em>.</p>

<p>Dead rows are regularly <em>garbage collected</em> by a process called <em>AUTOVACUUM</em>, …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/postgresql-fix-performance">https://pawelurbanek.com/postgresql-fix-performance</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/postgresql-fix-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625471</guid>
            <pubDate>Tue, 29 Sep 2020 09:06:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp Chatbots – The Ultimate Guide (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24625400">thread link</a>) | @chatimize
<br/>
September 29, 2020 | https://chatimize.com/whatsapp-chatbots/ | <a href="https://web.archive.org/web/*/https://chatimize.com/whatsapp-chatbots/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			<div data-elementor-type="wp-post" data-elementor-id="4545" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="650a3768" data-element_type="section">
						<div>
				<div>
				<div data-id="cee7aa2" data-element_type="column">
			<div>
					<div>
				
				<div data-id="50106658" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><div><p><img alt="joren-wouters-avatar" src="https://chatimize.com/wp-content/themes/chatimize/images/joren-wouters.jpg" data-src="https://chatimize.com/wp-content/themes/chatimize/images/joren-wouters.jpg"></p><p>By Joren Wouters <span>•</span> Updated on <time datetime="2020-10-02T11:13:38+00:00">Oct 2, 2020</time></p></div>
				</div>
				</div>
				<section data-id="2bb6a39" data-element_type="section">
						<div>
				<div>
				
				<div data-id="457b65e" data-element_type="column">
			<div>
					<div>
				<div data-id="ec62486" data-element_type="widget" data-widget_type="html.default">
				<div>
			<div>
    <div>
        <p>This is the ultimate guide to WhatsApp Chatbots in 2020.</p>
        <p>And I will cover <strong><u>everything</u></strong>.</p>
        <p>What WhatsApp chatbots are. <br>
        What message rules apply on WhatsApp. <br>How you can build a WhatsApp Chatbot.</p>
        <p><strong>And even more.</strong></p>
        <p>So if you're looking to use WhatsApp chatbots in your marketing, you'll love this new guide.</p>
    </div>
    <p><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots.png" alt="whatsapp-chatbots" width="1000" height="1032" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots.png 1000w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-291x300.png 291w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-768x793.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-992x1024.png 992w" data-sizes="(max-width: 1000px) 100vw, 1000px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots.png 1000w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-291x300.png 291w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-768x793.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-992x1024.png 992w">
    </p>
</div>		</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</div></section>
				<section data-id="5f004b5e" data-element_type="section" id="winner" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						
		</section>
				<section data-id="5927f47" data-element_type="section" id="intro-whatsapp" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="40c8773" data-element_type="column">
			<div>
					<div>
				<div data-id="d9f2218" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2><strong>Chapter 1:</strong> Intro to WhatsApp Chatbots</h2>		</p>
				</div>
				<section data-id="53ee519" data-element_type="section">
						<div>
				<div>
				
				<div data-id="1f456ec" data-element_type="column">
			<div>
					<div>
				<div data-id="2cba36b" data-element_type="widget" data-widget_type="html.default">
				<div>
			<div>
    
    <p><img src="https://chatimize.com/wp-content/uploads/2020/09/basics-whatsapp-chatbots.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/basics-whatsapp-chatbots.png" alt="intro-whatsapp-chatbots">
    </p>
</div>		</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="a7978fb" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="0d19ce8" data-element_type="column">
			<div>
					<div>
				<div data-id="ac9bf20" data-element_type="widget" id="what-is" data-widget_type="heading.default">
				<p>
			<h2>What is a WhatsApp chatbot?</h2>		</p>
				</div>
				<section data-id="05e68f4" data-element_type="section">
						<div>
				<div>
				
				<div data-id="da3b036" data-element_type="column">
			<div>
					<div>
				<div data-id="690393b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>A WhatsApp <a href="https://chatimize.com/chatbot/">chatbot</a> is an automated conversation partner on WhatsApp.</p><p>It facilitates a conversation between a person and a computer.</p><p>Usually, you will have a conversation with another person on WhatsApp (for example, one of your friends), but with chatbots, you are talking to a computer, not a human.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3ed98d8" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="c6ac601" data-element_type="column">
			<div>
					<div>
				
				<section data-id="0b93cb5" data-element_type="section">
						<div>
				<div>
				
				<div data-id="17658ca" data-element_type="column">
			<div>
					<div>
				<div data-id="90ba18e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Now a real-life example: the KLM WhatsApp Chatbot.</p><p>KLM Royal Dutch Airlines is one of the biggest airlines in the world. They have over 30.000 employees and serve passengers and cargo to 145 destinations.&nbsp;</p><p>I’m originally from the Netherlands, so I really like the fact that <a href="https://news.klm.com/klm-first-airline-with-verified-whatsapp-business-account/" target="_blank" rel="noopener">KLM was the first airline with a WhatsApp chatbot</a>.</p><p>KLM used the chatbot to send booking information, check-in notifications, boarding passes and flight status updates. Besides that, users could ask KLM questions in 10 different languages:</p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="34a084c" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="3e63315" data-element_type="column">
			<div>
					<div>
				<div data-id="570966b" data-element_type="widget" id="why-whatsapp-chatbot" data-widget_type="heading.default">
				<p>
			<h2>Why use WhatsApp Chatbots?</h2>		</p>
				</div>
				<section data-id="26b0509" data-element_type="section">
						<div>
				<div>
				
				<div data-id="c437b41" data-element_type="column">
			<div>
					<div>
				<div data-id="be29912" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>WhatsApp is one of the biggest messaging apps in the world, with over <a href="https://www.oberlo.com/blog/whatsapp-statistics" target="_blank" rel="noopener">2 billion users</a> around the globe. It is available in more than 180 countries and 60 different languages.</p><p>Moreover, 1.6 billion WhatsApp users access the app on a monthly basis.</p><p><a href="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png"><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png" alt="whatsapp-users" width="1459" height="553" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png 1459w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-300x114.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-768x291.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-1024x388.png 1024w" data-sizes="(max-width: 1459px) 100vw, 1459px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png 1459w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-300x114.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-768x291.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-1024x388.png 1024w"></a></p><p>And this leads to 65 billion WhatsApp messages sent every day.</p><p><a href="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png"><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png" alt="whatsapp-messages" width="1459" height="553" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png 1459w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-300x114.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-768x291.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-1024x388.png 1024w" data-sizes="(max-width: 1459px) 100vw, 1459px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png 1459w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-300x114.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-768x291.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-1024x388.png 1024w"></a></p><p>Overwhelming, right?</p><p>So basically, you should use WhatsApp because your customers are already there, they are just waiting for you to send them a message. Besides that, you can reach any potential client on WhatsApp, because it is used by so many users all over the world.</p><p>Now I hear you thinking “Okay, I should use WhatsApp. But why use a chatbot?”</p><p>Good one.</p><p>In fact, I made a complete post about <a href="https://chatimize.com/why-chatbots/">why you should use chatbots</a>, but here are the ten most important reasons:</p><ol><li>Save time and money on customer service</li><li>Boost your sales</li><li>Get more leads</li><li>Reply in seconds, instead of days</li><li>24/7 available, everywhere</li><li>Send real-time, tailored messages to customers</li><li>Messenger apps (like WhatsApp) become more popular</li><li>People are open to using chatbots</li><li>You can use chatbots internally in your company</li><li>Stand out from the crowd (aka, not many businesses use chatbots yet)</li></ol></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2dd9403" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="953cb1c" data-element_type="column">
			<div>
					<div>
				<div data-id="f60f589" data-element_type="widget" id="how-whatsapp-chatbot" data-widget_type="heading.default">
				<p>
			<h2>How does a WhatsApp Chatbot work?</h2>		</p>
				</div>
				<section data-id="5ef3c27" data-element_type="section">
						<div>
				<div>
				
				<div data-id="0477877" data-element_type="column">
			<div>
					<div>
				<div data-id="392637b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>A WhatsApp chatbot works really simple.</p><p>Someone can just send a message to the WhatsApp number of a certain business and the chatbot will try to answer that message, just like any normal person would do.</p><p>I will illustrate this by giving an example:</p><ol><li>A user starts a conversation with a WhatsApp chatbot of a wine company. The user asks “What red wine do you recommend?”</li><li>The chatbot understands this message and recognizes the words “red wine” and “recommend”</li><li>Based on those recognized words, the chatbot will look in the wine database for “recommended red wines”</li><li>Finally, the chatbot will send a message back with all the recommended red wines in the wine database.</li></ol><p>Pretty simple, right?</p><p>“But what about KLM? Nobody sent them a message and they automatically send someone’s boarding pass?”</p><p>That’s right. It’s also possible that the chatbot starts the conversation with the user. But this is only allowed in certain situations. We will talk more about that in the next chapter 😉</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3dc9d56" data-element_type="section" id="whatsapp-message-rules" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="3fd8f10" data-element_type="column">
			<div>
					<div>
				<div data-id="6895a0d" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2><strong>Chapter 2:</strong> WhatsApp Message Rules</h2>		</p>
				</div>
				<section data-id="27cc5f9" data-element_type="section">
						<div>
				<div>
				
				<div data-id="c6e5c42" data-element_type="column">
			<div>
					<div>
				<div data-id="387e922" data-element_type="widget" data-widget_type="html.default">
				<div>
			<div>
    <div>
        <p>Unfortunately, you can't just send any message to anyone with your WhatsApp chatbot.</p>

<p>There are certain rules that you must follow.</p>

<p>Why is this? So that businesses don't spam everyone on WhatsApp (which is really anoying).</p>

<p>So, what are these rules?</p>

<p>Let's jump right in.</p>
    </div>
    <p><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules.png" alt="whatsapp-message-rules" width="1000" height="961" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules.png 1000w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules-300x288.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules-768x738.png 768w" data-sizes="(max-width: 1000px) 100vw, 1000px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules.png 1000w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules-300x288.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules-768x738.png 768w">
    </p>
</div>		</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2917218" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="07ab3ad" data-element_type="column">
			<div>
					<div>
				<div data-id="b47bff3" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Intro to WhatsApp Message Rules</h2>		</p>
				</div>
				<section data-id="ff4aea9" data-element_type="section">
						<div>
				<div>
				
				<div data-id="7ab42fb" data-element_type="column">
			<div>
					<div>
				<div data-id="c78367c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Basically, there are two kinds of conversations with WhatsApp Chatbots:</p><ol><li>The user starts the conversation with the chatbot – WhatsApp calls this “Customer Care”</li><li>The chatbot starts the conversation with the user – This is called WhatsApp Message Templates or WhatsApp Notifications</li></ol><p>If you are only planning to provide Customer Care to your users, then don’t worry, because you won’t break any rules.</p><p>But if you want to do more, I recommend to read on.</p><p>So, every time a user sends a message to your WhatsApp chatbot, a&nbsp;<strong>24-hour window</strong> will open. Within this 24-hour window, you can send any message to the user, with absolutely no constraints.</p><p>Please note that this 24-hour window will reopen,&nbsp;<strong>every time</strong> the user sends a message. Take this example:</p><ul><li>User sends message to chatbot&nbsp;<strong>*24-hour window will open*</strong></li><li>User says nothing for 8 hours <strong>*There are 16 hours left in the 24-hour window*</strong></li><li>After 8 hours, the user sends another message&nbsp;<strong>*24-hour window will re-open*</strong></li></ul><p><a href="https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg.png"><img src="https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg.png" data-src="https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg.png" alt="whatsapp-24-hour-window" width="1313" height="678" data-srcset="https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg.png 1313w, https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg-300x155.png 300w, https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg-768x397.png 768w, https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg-1024x529.png 1024w" data-sizes="(max-width: 1313px) 100vw, 1313px" srcset="https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg.png 1313w, https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg-300x155.png 300w, https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg-768x397.png 768w, https://chatimize.com/wp-content/uploads/2020/10/whatsapp-message-rules-whitebg-1024x529.png 1024w"></a></p><p><strong>By the way</strong>, these message inside the 24-hour window are also called&nbsp;<strong>“Session Messages”.</strong></p><p>But what about messages outside the 24-hour window?</p><p>WhatsApp uses Message Templates/Notifications for that.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="e6a99ca" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="b4ffd8c" data-element_type="column">
			<div>
					<div>
				<div data-id="d1a7810" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>WhatsApp Message Templates / Notifications</h2>		</p>
				</div>
				<section data-id="351a5aa" data-element_type="section">
						<div>
				<div>
				
				<div data-id="36bfbdc" data-element_type="column">
			<div>
					<div>
				<div data-id="8155c2a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>You can use WhatsApp Message Templates to send messages to users outside the 24-hour window.</p><p>But you can only send these message templates in really specific situations.</p><p>In total, there are 11 situations and I will go by them one-by-one.</p><h3>Account update</h3><p>You can use this category to send messages to users when their account is updated or changed. For example, you can inform customers when they have successfully created an account on your webshop.&nbsp;</p><h3>Alert update</h3><p>Send important updates or news to customers.</p><p>This category is more for general updates to users. For example, you can send an update to a user if he ordered a product at your webshop.</p><h3>Appointment Update</h3><p>The Appointment Update is used to send confirmations, reminders or other updates to users about their appointments:</p><figure id="attachment_4735" aria-describedby="caption-attachment-4735"><a href="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg"><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg" alt="whatsapp-reservation-message-template" width="1536" height="1289" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg 1536w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-300x252.jpg 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-768x645.jpg 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-1024x859.jpg 1024w" data-sizes="(max-width: 1536px) 100vw, 1536px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg 1536w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-300x252.jpg 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-768x645.jpg 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-1024x859.jpg 1024w"></a><figcaption id="caption-attachment-4735">Source: <a href="https://trengo.com/blog/communication/examples-of-whatsapp-business-templates-that-make-life-easier/">Trengo</a></figcaption></figure><h3>Auto-Reply</h3><p>You can use this category to send auto-replies to customers when your business isn’t online or available to respond right away.</p><p>To be honest, most business with WhatsApp chatbots don’t use this feature, because a chatbot is 24/7 available and can always respond.</p><h3>Issue Resolution</h3><p>With the Issue Resolution category, you can respond to questions or concerns from users about your business.</p><p>For example, when your website or service isn’t online at the moment, you can inform users that you are working on a resolution to solve the issue.</p><h3>Payment Update</h3><p>The Payment Update is meant to send messages to customers about their payment. For example, you can send a message when the payment has been succesfully received.</p><h3>Personal Finance Update</h3><p>You can use the Personal Finance Update to send messages to customers about their personal finances. This is especially useful for insurance organizations or financial institutions.</p><h3>Reservation Update</h3><p>This one is quite similar to the Appointment Update.</p><p>With the Reservation Update, you can send confirmations, reminders or other updates to users about their reservations.</p><h3>Shipping Update</h3><p>You can use the Shipping Update to send updates to customers about shipping their products. For example, you can send “You will receive your products within 24 hours.”</p><h3>Ticket Update</h3><p>This can be used to send ticketing information or updates to customers. It is especially useful if you solved a ticket outside the 24-hour window.</p><h3>Transportation Update</h3><p>This template is used for sending transportation information or updates to customers. For example, you could send a message when a flight has been delayed (Exactly what KLM used!)</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="7355590" data-element_type="section" id="create-whatsapp-chatbot" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="d9e8b5a" data-element_type="column">
			<div>
					<div>
				<div data-id="4495bfd" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2><strong>Chapter 3:</strong> How to create a chatbot on WhatsApp</h2>		</p>
				</div>
				<section data-id="2b8d936" data-element_type="section">
						<div>
				<div>
				
				<div data-id="b562a6c" data-element_type="column">
			<div>
					<div>
				<div data-id="a83979c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Now, we know the basics of WhatsApp Chatbots and the rules we need to follow in order to build one.</p><p>So, we got everything to build a WhatsApp chatbot ourselves.</p><p>Let’s dive in.</p><p><a href="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png"><img src="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png" alt="how-to-create-whatsapp-chatbot" width="1920" height="1106" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png 1920w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-300x173.png 300w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-768x442.png 768w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-1024x590.png 1024w" data-sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png 1920w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-300x173.png 300w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-768x442.png 768w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-1024x590.png 1024w"></a></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2c34759" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="7665f4e" data-element_type="column">
			<div>
					<div>
				<div data-id="af218be" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Choose your chatbot software</h2>		</p>
				</div>
				<section data-id="651a437" data-element_type="section">
						<div>
				<div>
				
				<div data-id="191b3c7" data-element_type="column">
			<div>
					<div>
				<div data-id="94c2439" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>The first thing you need to do, is choose the chatbot software you are going to use to build your WhatsApp chatbot.</p><p>There are basically two options:</p><ul><li>Choose a chatbot builder that has WhatsApp inside their platform (such as <a href="https://landbot.grsm.io/chatimize">Landbot</a>)</li><li>Go with a chatbot builder that has an integration with <a href="http://www.twilio.com/referral/TpDZL3" target="_blank" rel="noopener">Twilio</a> (like <a href="https://silferbots.io/">SilFer Bots</a>)</li></ul><p>The last option is the most common approach for chatbot builders that offer …</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chatimize.com/whatsapp-chatbots/">https://chatimize.com/whatsapp-chatbots/</a></em></p>]]>
            </description>
            <link>https://chatimize.com/whatsapp-chatbots/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625400</guid>
            <pubDate>Tue, 29 Sep 2020 08:50:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Single Machine Startup Company System]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625277">thread link</a>) | @blazeeboy
<br/>
September 29, 2020 | https://www.emadelsaid.com/single-machine-startup-company-system/ | <a href="https://web.archive.org/web/*/https://www.emadelsaid.com/single-machine-startup-company-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div dir="auto">
    <p>Technology is moving fast. This is true for the tools we developers are using to
build web applications. You wake up everyday on news about new library or
framework or a new feature in the language you’re already using. Tools are
getting more complex and layers of abstractions are added over each other faster
than I can keep up with. Marketing are getting stronger everyday. Reading
documentation for a framework/program recently triggers me with a lot of
marketing sentences that doesn’t deliver any concrete proof to their claims,
just shiny buzz words that should excite me to use this new tool.</p>

<p>With that I think it’s more sane for me to understand the existing software that
I have on my system before I add anything to it. I’m using Linux on all of my
work machines and servers. That means I should gain a deeper understanding to
the userland applications that comes with my work machine distribution
(Archlinux) and the one I use on my servers (Ubuntu). With a better
understanding to what the system can already do I would gain a more stable
knowledge that has a further expiration date than say a new components
JavaScript library.</p>

<p>This following will be my attempt to aggregate the knowledge I gained to build
an organized Linux system that can host multiple Web services for a small
company. I’ll try to use the system features as much as possible before adding
more software. Software choices will favor boring old software than new and
shiny ones. I’ll try to keep it simple. That doesn’t mean it’ll be an easy task
but a simpler one with less abstraction layers to understand and maintain. I’ll
try to keep what I do relevant to two Linux distributions (Archlinux and
Ubuntu).</p>

<p>At the end of this page we should have a Linux system that’s ready to
host several web applications with all it needs from HTTP servers, database
servers, caching server, logs and monitoring..etc.</p>

<h2 id="a-new-linux-server-where-should-i-start">A New Linux server, Where should I start?</h2>

<p>You can get a good VPS server for cheap price from many providers, Digital ocean
and Linode are famous choices, My favorite provider is Hetzner their prices are
way better and they are very reliable I’m have been a customer for 5 years now
with no issues.</p>

<h2 id="allow-ssh-key-login-and-disable-password-login">Allow SSH key login and disable password login</h2>

<p>The default login to your VPS server uses a username and password so lets
make that better.</p>

<p>We’ll create an RSA key pair for you, on your machine execute this command:</p>


<p>Then copy the generated public key to your server</p>
<div><div><pre><code>ssh-copy-id -i ~/.ssh/id_rsa.pub root@your-server-ip
</code></pre></div></div>

<p>Now SSHing to your server should work without a password, make sure of that
before disabling the password login.</p>

<p>Disable the password login in your server SSH by editing <code>/etc/ssh/sshd_config</code>
and set <code>ChallengeResponseAuthentication</code> and <code>PasswordAuthentication</code> to <code>no</code>.</p>

<p>After editing the file changes won’t apply to the current SSH server until you
reload it. SSH is running as systemd service, to reload it</p>



<p>Here is a bonus, If you already have systemd running on your system you can
execute the systemctl commands with <code>-H root@your-server-ip</code> to execute the
command on your server. You don’t need to login to execute it. the <code>-H</code>
argument will execute the command on the remote server.</p>

<p>For the previous couple commands we used the <code>ssh-keygen</code> and <code>ssh-copy-id</code> from
<code>openssh</code> package and <code>sshd</code> on the server and <code>systemctl</code> from systemd to
reload the service. I encourage you to read more about them. Try reading their
manual page on your machine with <code>man command-name</code>.</p>

<p>If you want to show your server SSH service logs you can use another program
from systemd package <code>journalctl</code> to do that.</p>



<h3 id="make-it-easier-to-ssh">Make it easier to SSH</h3>

<p>On your local machine SSH command reads <code>~/.ssh/config</code> to know about the
servers and their IP addresses and which keys to use and which user…etc so I
do a simple configuration for my SSH server in this file as follows:</p>

<div><div><pre><code>Host vps
     HostName server.ip.address.here
     User root
     IdentityFile ~/.ssh/id_rsa
</code></pre></div></div>

<p>This will allow you to ssh to your server with this</p>



<p>instead of this</p>
<div><div><pre><code>ssh root@server.ip.address.here
</code></pre></div></div>

<p>The <code>IdentityFile</code> line is not necessary if you’re using <code>~/.ssh/id_rsa</code> but if
you generated the VPS private key to another file use it here.</p>

<p>This simple configuration saved me a lot of time.</p>

<p>Many guides on the web recommend having SSHd listening on another port than the
default and disabling the root user login and using another user name. I fail to
see the benefit for that so far but feel free to do it if you wish.</p>

<h2 id="update-the-system-packages">Update the system packages</h2>

<p>Lets update the packages. The command will depend on your distribution.</p>

<div><div><pre><code>Ubuntu: apt update &amp;&amp; apt upgrade &amp;&amp; apt autoremove
Archlinux: pacman -Syu
</code></pre></div></div>

<h2 id="clean-the-system">Clean the system</h2>

<p>I also review the installed packages and uninstall the unnecessary ones, list
your installed packages with</p>

<div><div><pre><code>Ubuntu: apt list --installed
Archlinux: pacman -Qet
</code></pre></div></div>

<p>Then uninstall the ones you feel not useful to you.</p>
<div><div><pre><code>Ubuntu: apt remove &lt;package-name&gt;
Archlinux: pacman -Rs &lt;package-name&gt;
</code></pre></div></div>

<p>And review the running services and stop the ones you don’t need</p>

<div><div><pre><code>systemctl list-unit-files --state=enabled
</code></pre></div></div>

<p>Also the enabled timers</p>



<h2 id="enable-the-firewall">Enable the firewall</h2>

<p>Lets allow SSH only for now and enable the firewall, make sure you can login
with SSH after doing it</p>



<h2 id="setting-up-users-groups">Setting up users groups</h2>

<p>First concept we’ll map from our company is Teams. Each team in the company
we’ll correspond to a Linux group. Teams members will be Linux users in their
teams group. Simple and straight forward.</p>

<p>So for each team in the company we’ll create a user and a group. Initially I was
set to create only a group for each team, but I also need projects to work under
teams not team members. So As creating a new user will also create a group for
him I decided to create a user + group for each team. This way we can use the
user home for projects and for running services (we’ll get in to that later).</p>

<div><div><pre><code>useradd -m teamname
useradd -m membername
usermod -a -G teamname membername
</code></pre></div></div>

<p>So for every team member he’ll have his home directory for private files and
team home for projects and shared data.</p>

<div><div><pre><code>chmod 770 /home/teamname
chmod g+s /home/teamname
</code></pre></div></div>

<p>Each team directory will be readable and writable for each member of the team.</p>

<h2 id="give-access-to-each-team-member">Give access to each team member</h2>

<p>Each user should generate an SSH key and you should get their public key and add
it to their <code>.ssh/authorized_keys</code></p>

<h2 id="our-first-web-service">Our first web service</h2>

<p>Now we have our teams setup and team members on our system, they can login and
use the system existing software, they can download binaries and run it as they
wish.</p>

<p>This means if there is a program one of our teams wrote they can run it by login
and putting the project files in their team home directory and run the program
to listen on a port.</p>

<p>Having this application run as the team user instead of the team member user is
the first challenge we’ll tackle.</p>

<h2 id="running-web-service-as-a-systemd-service">Running web service as a systemd service</h2>

<p>This is the next concept we’ll map from our real world to the system. Each
project we’ll need to run on our system will be equivalent to a systemd service.</p>

<p>Systemd manages our system resources, background services like the http server,
database server, redis server, networking, and alot of things we’ll use some of
them in time.</p>

<p>Systemd allow us to define our own services and run it as a user on this system
as long as we’re logged into the system.</p>

<p>First lets define our service file. In your team home directory you need to
create file for your web service
<code>/home/teamname/.config/systemd/user/myservice.service</code> with similar content</p>

<div><div><pre><code>[<span>Unit</span>]
<span>Description</span>=<span>A</span> <span>useful</span> <span>web</span> <span>service</span>
<span>After</span>=<span>network</span>.<span>target</span>

[<span>Service</span>]
<span>ExecStart</span>=/<span>home</span>/<span>teamname</span>/<span>projects</span>/<span>myservice</span>/<span>program</span>/<span>binary</span>
<span>WorkingDirectory</span>=/<span>home</span>/<span>teamname</span>/<span>projects</span>/<span>myservice</span>
<span>User</span>=<span>teamname</span>
<span>Group</span>=<span>teamname</span>
<span>Restart</span>=<span>always</span>

[<span>Install</span>]
<span>WantedBy</span>=<span>multi</span>-<span>user</span>.<span>target</span>
</code></pre></div></div>

<p>Now reload systemd to discover this new service file</p>



<p>Listing systemd services with <code>systemctl list-unit-files</code> should have your new
service among them.</p>

<p>enabling it and starting it should run your service</p>

<div><div><pre><code>systemctl enable myservice --user
systemctl start myservice --user
</code></pre></div></div>

<p>And when you login to the system with any this team group account the service
will start automatically. When you logout it’ll be stopped.</p>

<p>To make the service run on boot we need to turn on the lingering for the team,
and as this is a common use case you’ll need to do it for all the teams</p>

<div><div><pre><code>loginctl enable-linger teamname
</code></pre></div></div>

<p>The only problem now is that we login as a team member and we want to run the
previous <code>enable</code> and <code>start</code> commands as this team user not our user so the
service runs for the team and any one in the team can control it. If you
executed the commands as you the service will run under the team member account
which will make it stop when he’s logged out.</p>

<p>So we need team member to switch to the group user when they want without
password, the command responsible about that is</p>



<p>But it asks for a password, so to allow team members for <code>teamname</code> to <code>sudo</code>
without password as <code>teamname</code> user. Add the following line to <code>/etc/sudoers</code>
for each team.</p>

<div><div><pre><code>%teamname ALL = (teamname) NOPASSWD: ALL
</code></pre></div></div>

<p>Now any team member can start/stop/enable/disable the service for the team.</p>

<div><div><pre><code>sudo -u teamname systemctl start myservice --user
</code></pre></div></div>

<p>And it’ll keep running after the team member logout, If necessary you can have a
CI user for each team that execute these commands as part of your continuous
integration steps.</p>

<p>So far our service will be used inside the system, so if the service listens on
port 8080 you can curl it with</p>

<div><div><pre><code>curl http://localhost:8080
</code></pre></div></div>

<p>so lets improve this <code>localhost</code> to our actual company name <code>companyname</code></p>



<p>And add your domain name to <code>/etc/hosts</code> to allow local services to resolve it
faster when using it to refer to other services</p>

<div><div><pre><code>127.0.0.1    companyname.tld
</code></pre></div></div>

<p>So now you can curl your service with <code>curl http://companyname.tld:8080</code>
instead.</p>

<h2 id="further-securing-your-web-service">Further securing your web service</h2>

<p>Systemd provides many features to isolate your service so in the case of
misbehaving it’ll do the least damage possible to the system.</p>

<p>Each of these features can be turned …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.emadelsaid.com/single-machine-startup-company-system/">https://www.emadelsaid.com/single-machine-startup-company-system/</a></em></p>]]>
            </description>
            <link>https://www.emadelsaid.com/single-machine-startup-company-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625277</guid>
            <pubDate>Tue, 29 Sep 2020 08:20:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Knowledge Organization (5 ways to capture everything your company knows)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625204">thread link</a>) | @xdze2
<br/>
September 29, 2020 | https://blog.fibery.io/the-knowledge-organization/ | <a href="https://web.archive.org/web/*/https://blog.fibery.io/the-knowledge-organization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In a creative organization — tech startup, management consultancy, law school&nbsp;—&nbsp;Henry Ford’s productivity is much less relevant than Douglas Engelbart’s collective intelligence.</p>
<p><small>Yeah, our objectives were set in <a href="https://www.dougengelbart.org/pubs/papers/scanned/Doug_Engelbart-AugmentingHumanIntellect.pdf" target="_blank" rel="noopener">1962</a>. So what? 🦕</small> 
</p>
<p>Instead of looking for ways to “boost productivity”, we wonder how we can “augment collective intelligence”. Here are our goals as Engelbart put it:</p>
<ul>
<li>more-rapid and better comprehension</li>
<li>gaining a useful degree of comprehension in a situation that previously was too complex</li>
<li>speedier and better solutions</li>
<li><em>finding solutions to problems that before seemed insoluble</em></li>
</ul>
<p><small><a href="https://fibery.io/connect?utm_source=blog.fibery.io&amp;utm_medium=referral&amp;utm_campaign=the-knowledge-organization" target="_blank" rel="noopener">Fibery</a> is a connected workspace for teams. Yes, yet another 🤦‍♀️</small> 
</p>
<p>In a series of joyfully boring essays we are going to explore ways of achieving these goals. Maybe, some ideas will even find their way into Fibery’s vision, who knows.</p>
<p>So where should we start?</p>
<h2>Knowledge Architecture</h2>
<p>At the basic level, it all comes down to capturing, sharing, and generating knowledge. So the first step is to get this knowledge out of bright heads and into a shared space.</p>
<p>How should this space look like? Good old files and folders? Powerful databases? Trendy networks?</p>
<p><small>We resisted the "5 ways to capture everything your company knows" clickbait title 💪</small> 
</p> 
<p>In this article we are going to explore five different approaches to knowledge architecture in an organization. We are looking for the most natural structure that encourages people to discover and share knowledge. The structure should help us to build on top of each other’s ideas. </p>
<p>Starting with…</p>
<h2>Vertical Hierarchy</h2>
<p><span>
      <span></span>
  <img alt="vertical hierarchy" title="Vertical hierarchies in popular tools: Google Drive, Asana, ClickUp, Confluence, and Trello" src="https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/99f37/vertical-hierarchy.png" srcset="https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/6b2ea/vertical-hierarchy.png 275w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/dd45a/vertical-hierarchy.png 550w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/99f37/vertical-hierarchy.png 1100w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/573d3/vertical-hierarchy.png 1650w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/821da/vertical-hierarchy.png 2200w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/97a96/vertical-hierarchy.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>The most ubiquitous structure is a strict vertical hierarchy.</p>
<p>Some bearded guys borrowed the file cabinet metaphor in 1960s, and it has become a standard since. From cloud drives to note taking and work management tools&nbsp;— it’s all folders and files in some shape or form.</p>
<p>💎 <strong>The onboarding is easy.</strong> With the ubiquity comes familiarity — you don’t need to explain to anyone how folders work.</p>
<p>Unfortunately, <a href="https://youtu.be/oAHbLRjF0vo?t=32" target="_blank" rel="noopener">popular ≠ the best</a>. The strict hierarchy made sense in the real world: a book can only be on a single shelf in a particular room. However, the restrictions of physical objects should not apply to abstract knowledge.</p>
<p>💩 <strong>Every entity has to be exactly in one place.</strong> Two teams collaborating on the same project? Let them decide where the project goes in a vicious pillow fight: </p>
<figure>
    <img src="https://blog.fibery.io/196cdba16c74313951ec270b27ba2a3e/entity-in-exactly-one-place.gif" alt="The same Project should be in two folders at the same time: for Product and Marketing teams">
    <figcaption><p>In our examples we will pretend that all organizations build digital products 🤷‍♀</p></figcaption> 
</figure>
<p>Alternatively, duplicate the data and hope that the intricate two-way sync won’t suprise you with a merge conflict any time soon. </p>
<p>💩 <strong>The organization has to agree on a single hierarchy for all purposes.</strong> Business folks want folders to be initiatives, engineering folks — product areas. Let them decide in a vicious pillow fight:</p>
<p><span>
      <span></span>
  <img alt="competing hierarchies" title="Competing hierarchies: folders as initiatives or product areas" src="https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/99f37/competing-hierarchies.png" srcset="https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/6b2ea/competing-hierarchies.png 275w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/dd45a/competing-hierarchies.png 550w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/99f37/competing-hierarchies.png 1100w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/573d3/competing-hierarchies.png 1650w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/821da/competing-hierarchies.png 2200w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/97a96/competing-hierarchies.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>And once they decide, there is no going back because…</p>
<p>💩 <strong>Evolution is near impossible.</strong> A company is transitioning from outsource (folders = clients) to product (folders = products) development? The next few months will be fun!</p>
<p>Speaking of fun — what about cross-team collaboration?</p>
<p>💩 <strong>Horizontal connections are lost.</strong> Try mapping this natural workflow into a vertical structure:</p>
<figure>
    <img src="https://blog.fibery.io/0c887eda53c96a94797af94f4886024f/horizontal-connections.gif" alt="Horizontal connections between Marketing, CRM, Software Development, and Dev Ops">
</figure>
<p>The vertical approach produces inflexible information silos. As Ted Nelson noted in the legendary <a href="https://www.goodreads.com/book/show/722414.Computer_Lib_Dream_Machines" target="_blank" rel="noopener">Computer Lib/Dream Machines</a>:</p>
<blockquote>
Hierarchical structures are usually forced and artificial. Interwingularity is not generally acknowledged —&nbsp;people think they can make things hierarchical, categorizable and sequential when they can't.
</blockquote>
<p>So let’s… acknowledge interwingularity?</p>
<h2>Flat Network</h2>
<p><span>
      <span></span>
  <img alt="flat network" title="Flat network: nodes representing thoughts and ideas connected to each other" src="https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/99f37/flat-network.png" srcset="https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/6b2ea/flat-network.png 275w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/dd45a/flat-network.png 550w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/99f37/flat-network.png 1100w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/573d3/flat-network.png 1650w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/821da/flat-network.png 2200w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/97a96/flat-network.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>In a flat network we are free to form arbitrary connections between nodes (pages).</p>
<p>In a good network, these connections are bi-directional: if two pages are related, we’ll always see the connection on both of them. Unfortunately, this is not how most networks work — yet 🤞.</p>
<p>Lately, we’ve seen a revival of the “networked thought”&nbsp;fueled by the idea that… </p>
<p>💎 <strong>Free associations are closer to how brain works.</strong> Thoughts are not neatly packed in file cabinets: rather one leads to another and yet another. In a flat network this means that the “campaign → lead →&nbsp;bug&nbsp;→&nbsp;version” workflow we mentioned above works like a charm.</p>
<p>💎 <strong>Knowledge naturally accumulates.</strong> There is no limit on the size of the network and no restrictions on how it should grow.</p>
<p>Just like our brains, flat networks are great at working with unstructured knowledge but suck when it comes to structured data.</p>
<p>💩 <strong>Querying data is hard.</strong> All pages have either the same or unpredictable attributes. Getting all high-priority features or all customers due to renew the next month is nearly impossible.</p>
<p>💩 <strong>Visualizations are limited.</strong> Most vizualizations rely on structured data — so forget about a Kanban board with swimlanes, an event calendar, a gantt chart, or a hierarchical list. </p>
<p>💩 <strong>Repeatable processes are undiscoverable.</strong> Since there are no required (or even desired) attributes and relations, there is nothing to nudge folks into a predictable workflow. You have to explain each newcomer that “we decompose Epic into Stories, estimate these Stories, and plan into Sprints” —&nbsp;a flat network cannot guide them.   </p>
<p>So we need both horizontal and vertical connections as well as the ability to handle structured data. Sounds pretty much like…</p>
<h2>Relational Databases</h2>
<p><span>
      <span></span>
  <img alt="relational databases" title="Relational databases: each standalone database stores multiple connected tables" src="https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/99f37/relational-databases.png" srcset="https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/6b2ea/relational-databases.png 275w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/dd45a/relational-databases.png 550w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/99f37/relational-databases.png 1100w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/573d3/relational-databases.png 1650w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/821da/relational-databases.png 2200w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/97a96/relational-databases.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>In a relational database, both vertical and horizontal connections are present through one-to-many and many-to-many relations. Each table has its own attributes making home for structured data.</p>
<p>💎 <strong>The structure is flexible.</strong> The knowledge architect is free to create as many or as few tables as needed and connect them in the way it makes sense to the particular organization. As organization evolves, she creates more tables and adds more relations.</p>
<p><small>A common pitfall is to design a database that doesn't satisfy at least <a href="https://en.wikipedia.org/wiki/Database_normalization" target="_blank" rel="noopener">3NF</a> and struggle with complicated queries and data duplication.  
 
  
 </small>
</p>
<p>💩 <strong>Building a database requires time and skill.</strong> This is the price your pay for the flexibility. While <a href="https://airtable.com/" target="_blank" rel="noopener">Airtable</a> has democratized online databases, the knowledge architect still has to understand how data normalization works —&nbsp;at least intuitively.</p>
<p>💩 <strong>It’s either one unmanageable, or many disconnected databases.</strong> When all teams share the same database, it quickly becomes huge and messy. When teams split into several bases, it’s “hello” to information silos and “bye” to cross-team collaboration. Instead of sharing data, it’s all back to pillow fights — where should the customers table go, in sales or marketing db.</p>
<p>On the bright side…</p>
<p>💎 <strong>Pretty much any visualization or query is possible.</strong> Tables, boards, charts, and even maps — with data filtered and sorted as you desire. If a database doesn’t have a visualization out of the box, you can usually build one.</p>
<p>While the structured data feels at home…</p>
<p>💩 <strong>Unstructured knowledge is not welcome.</strong> Collaborative documents, whiteboards, and multimedia are second-class citizens at best and are simply missing at worst.</p>
<p>Is there a way to combine structured and unstructured knowledge, vertical and horizontal connections?</p>
<h2>Single-Purpose Hierarchical Networks</h2>
<p><span>
      <span></span>
  <img alt="single purpose networks" title="Single-purpose hierarchical networks: Jira for software development, Hubspot&nbsp;for sales CRM" src="https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/99f37/single-purpose-networks.png" srcset="https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/6b2ea/single-purpose-networks.png 275w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/dd45a/single-purpose-networks.png 550w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/99f37/single-purpose-networks.png 1100w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/573d3/single-purpose-networks.png 1650w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/821da/single-purpose-networks.png 2200w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/97a96/single-purpose-networks.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>Most single-purpose work management tools are, basically, hierarchical networks. Tool vendors understand they need the best of all worlds to foster collaboration.</p>
<p>💎 <strong>Structured and unstructured knowledge is mixed.</strong> You set feature priority, but you also write specs. You advance deals through a pipeline, but also take meeting notes. Hopefully, digital whiteboards and interactive embeds will also be welcome —&nbsp;one day 🤞.</p>
<p>💎 <strong>Multiple parallel hierarchies coexist.</strong> A Task belongs to a Sprint, but also to a Version and a Component. A few pillows saved.</p>
<p> 💎 <strong>Visualizations are tailor-made to specific workflows.</strong> If a team adapts its behavior to the tool, it’s rewarded with a top-notch user experience.</p>
<p>Wait, but what if a team is happy with its habits and doesn’t want to kneel before the tool? That’s the catch.</p>
<p>💩 <strong>Single-purpose is synonymous with inflexible.</strong> A team has grown, and you need an extra level of hierarchy — 🤷‍♀️. You call it Deals, not Opportunities — 🤷‍♀️. Haven’t yet settled on a process and are experimenting with workflows —&nbsp;🤷‍♀️. Want to look at the data from a different angle&nbsp;— 🤷‍♀️.</p>
<p>Teams are diverse so each one gets its own purpose-built network.</p>
<p>💩 <strong>Networks are isolated.</strong> We are back to information silos, islands of knowledge, bubbles of data, please stop me, idea zoos, insight prisons. Because of the incompatible data models, cross-network integrations are always limited and clunky.</p>
<p><span>
      <span></span>
  <img alt="isolated networks" title="An isolated Jira network with feedback, ideas, campaign, and leads excluded" src="https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/99f37/isolated-networks.png" srcset="https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/6b2ea/isolated-networks.png 275w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/dd45a/isolated-networks.png 550w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/99f37/isolated-networks.png 1100w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/573d3/isolated-networks.png 1650w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/821da/isolated-networks.png 2200w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/97a96/isolated-networks.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>So what can we have instead of many single-purpose networks? A single generic…</p>
<h2>Hierarchical Network</h2>
<figure>
    <span>
      <span></span>
  <img alt="Wait, was it all just content marketing? 😱" title="Hierarchical network in a product company and a creative agency: multiple hierarchies coexist" src="https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/99f37/hierarchical-network.png" srcset="https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/6b2ea/hierarchical-network.png 275w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/dd45a/hierarchical-network.png 550w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/99f37/hierarchical-network.png 1100w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/573d3/hierarchical-network.png 1650w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/821da/hierarchical-network.png 2200w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/97a96/hierarchical-network.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span>
    <figcaption>Wait, was it all just content marketing? 😱</figcaption>
  </figure>
<p>Each node in the network is of a particular type (Objective, Customer). Types form hierarchies: Objective has several Key Results, Customer — many logged Chats and a few too many reported Bugs.</p>
<p>A single generic hierarchical network is capable of holding all the knowledge of an organization. So why aren’t these networks common?</p>
<p>First of all, the vertical hierarchy has become a no-brainer default, and we rarely stopped to ask if there might be a better generic storage architecture. This “things have already been figured out” effect has been common across computer science since 1980s. Bret Victor put it best: </p>
<p><small>Replace "programming" with "knowledge architecture" (29:52—31:17)
 </small>
</p>
<p> <iframe src="https://www.youtube-nocookie.com/embed/8pTEmbeENF4?start=1792" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </p>
<p>Second, there hasn’t been a platform to easily build such networks. Why hasn’t there been a platform? Well, as we have found out in the last 3 <a href="https://fibery.io/anxiety?utm_source=blog.fibery.io&amp;utm_medium=referral&amp;utm_campaign=the-knowledge-organization" target="_blank" rel="noopener">miserable</a> years, the platform is damn hard to build&nbsp;—&nbsp;interview what is left of our engineers.</p>
<p>What’s so special about the hierarchical network? </p>
<p>💎 <strong>Adapts and evolves with an organization.</strong> It’s easy to start with a simple network and create more hierarchies as the company grows and diversifies. Each team constructs its own subnetwork —&nbsp;connected to the wider pool of knowledge. </p>
<p>Here is Ted Nelson again:</p>
<p><small>The first chapters of …</small></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.fibery.io/the-knowledge-organization/">https://blog.fibery.io/the-knowledge-organization/</a></em></p>]]>
            </description>
            <link>https://blog.fibery.io/the-knowledge-organization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625204</guid>
            <pubDate>Tue, 29 Sep 2020 08:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When the Impact of Digital Tech on Our Mental Health Begins to Matter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625172">thread link</a>) | @Lima_Writes
<br/>
September 29, 2020 | https://lifebeyond.one/blogs/tech-impact/when-the-impact-of-digital-tech-on-our-mental-health-begins-to-matter | <a href="https://web.archive.org/web/*/https://lifebeyond.one/blogs/tech-impact/when-the-impact-of-digital-tech-on-our-mental-health-begins-to-matter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  <section name="9b04">

<div>
<div>
<h3 name="d56f">Seeing ourselves through the eyes of our children and our&nbsp;tech</h3>
<figure name="c560"><img data-image-id="1*vr4Rb1HI9B3nHj0E1snGoA.jpeg" data-width="1161" data-height="728" src="https://cdn-images-1.medium.com/max/1200/1*vr4Rb1HI9B3nHj0E1snGoA.jpeg"></figure>
<p name="2ab1"><strong>The above photo is from the </strong><a href="https://weconomics.org/events/congres2019/congresprogramma/" data-href="https://weconomics.org/events/congres2019/congresprogramma/" rel="noopener noreferrer" target="_blank"><strong>Weconomics convention</strong></a><strong> last year, where I had the opportunity to pre-present my book </strong><a href="https://lifebeyond.one/" data-href="https://lifebeyond.one/" rel="noopener noreferrer" target="_blank"><strong>Life Beyond the Touch Screen</strong></a><strong> before its official launch in 2020. Something really interesting happened during my session.</strong></p>
<p name="da59">I never presented my book as much as I simply told a story about my personal experience with technology and mental health.&nbsp;</p>
<p name="f245">In my presentation and workshop I mostly just shared the story about <a href="https://lifebeyond.one/blogs/tech-impact/smartphone-addiction-burnout-and-balance?_pos=2&amp;_sid=0e6e4570f&amp;_ss=r" data-href="https://lifebeyond.one/blogs/tech-impact/smartphone-addiction-burnout-and-balance?_pos=2&amp;_sid=0e6e4570f&amp;_ss=r" rel="noopener noreferrer" target="_blank">my own experience with digital dependency and with burnout</a>.&nbsp;</p>
<p name="5820">In that story I recount how for about two years I was simply asking far too much from myself; my body and my brain. And how looking back, I could easily retrace the steps that led to my inevitable collapse, more or less.</p>
<p name="f412">The fun part is that — though I do mention here and there that <a href="https://lifebeyond.one/blogs/tech-impact/smartphone-addiction-technology-dependency-science-and-statistics?_pos=1&amp;_sid=76458b6a6&amp;_ss=r" data-href="https://lifebeyond.one/blogs/tech-impact/smartphone-addiction-technology-dependency-science-and-statistics?_pos=1&amp;_sid=76458b6a6&amp;_ss=r" rel="noopener noreferrer" target="_blank">study after study is showing the possible heinous effects overuse of digital technology</a> can and probably does have on our mental health — </p>
<blockquote name="302e">Digital technology is not the root cause in my story.</blockquote>
<h4 name="dbf8">Digital tech is your black&nbsp;mirror</h4>
<p name="a727">Digital technology, in my personal experience, is simply a (black) mirror that shows us what we’re <em>actually</em> giving our focus and attention to — as compared to what we <em>think</em> our priorities and values are. If we let it, it can show us what’s really going on under the surface.</p>
<p name="2187">My talk at the Weconomics convention was by far the best received ‘performance’ I have ever given. The reactions from listeners were easily 10x those of my greatest and best performances in my time as a musician.</p>
<p name="969a">I think it had to do with relevance, vulnerability and authenticity.</p>
<p name="753a">But there was something else that absolutely stood out to me as well.</p>
<h4 name="c19b">When do things start to matter to&nbsp;humans?</h4>
<p name="e8ee">I saw faces in the crowd change, and I noticed the tone of the discussion become much, much more serious when we started talking about the impacts of tech on our younger generations. Our kids.</p>
<blockquote name="530f">What if our children are already, inevitably headed to digitally-induced mental health disaster, and there’s not much we can do now to stop the train?</blockquote>
<p name="7f01">Touching as it may have felt, it also had me worried. Why can we suddenly see how serious something can really be impacting our focus, energy, creativity, productivity — generally; our growth and wellbeing — when it’s about our children? Why can’t we see that when it’s about <em>ourselves</em>?</p>
<p name="e05c">You want my blunt, honest opinion? I think it’s a combination of an underdeveloped capacity to seriously self-reflect as human adults, with an underdeveloped degree of self-love.&nbsp;</p>
<p name="3499">And the funny thing is: if we want a better world and a better future for our children — it starts exactly there: with ourselves, our self-love and self-awareness.&nbsp;</p>
<p name="ff4e">Namasté, peoples.</p>
</div>
</div>
</section>
<section name="79ac">


</section>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://lifebeyond.one/blogs/tech-impact/when-the-impact-of-digital-tech-on-our-mental-health-begins-to-matter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625172</guid>
            <pubDate>Tue, 29 Sep 2020 07:57:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keep your GitHub forks up to date]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625051">thread link</a>) | @reconquestio
<br/>
September 29, 2020 | https://samizdat.dev/keep-your-github-forks-up-to-date/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/keep-your-github-forks-up-to-date/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>Sometimes I do fork repositories and do some tweaks here and there for my personal needs which ain’t
really going to be merged into the upstream repository.</p>
<p>One thing that used to concern me is that I needed to manually rebase my changes onto the upstream
to have new goods but keep my changes on top of them.</p>
<p>Fortunately, GitHub Actions supports the <code>schedule</code> trigger for workflows and this is what we are
going to use.</p>
<p>The CI plan is simple and straightforward:</p>
<ul>
<li>Tigger by a schedule or by a manual run.</li>
<li>Fetch &amp; checkout repository.</li>
<li>Specify an upstream Git URL. Unfortunately, GitHub doesn’t expose an environment variable of a
upstream repository (or I didn’t find it).</li>
<li>Rebase onto upstream.</li>
<li>Push changes.</li>
</ul>
<div><pre><code data-lang="yaml"><span>name</span><span>:</span><span> </span><span>'Rebase'</span><span>
</span><span>
</span><span></span><span>on</span><span>:</span><span>
</span><span>  </span><span>schedule</span><span>:</span><span>
</span><span>    </span>- <span>cron</span><span>:</span><span> </span><span>'*/15 * * * *'</span><span>
</span><span>  </span><span>workflow_dispatch</span><span>:</span><span>
</span><span>
</span><span>
</span><span></span><span>jobs</span><span>:</span><span>
</span><span>  </span><span>rebase</span><span>:</span><span>
</span><span>    </span><span>runs-on</span><span>:</span><span> </span>ubuntu-latest<span>
</span><span>    </span><span>steps</span><span>:</span><span>
</span><span>    </span>- <span>uses</span><span>:</span><span> </span>actions/checkout@v2<span>
</span><span>    </span>- <span>uses</span><span>:</span><span> </span>shitiomatic/forkbacon@master<span>
</span><span>      </span><span>with</span><span>:</span><span>
</span><span>        </span><span>upstream_url</span><span>:</span><span> </span><span>"upstream url here"</span><span>
</span><span>        </span><span>upstream_branch</span><span>:</span><span> </span><span>"master"</span><span>
</span><span>        </span><span>branch</span><span>:</span><span> </span><span>"master"</span><span>
</span><span>        </span><span>method</span><span>:</span><span> </span><span>"rebase"</span><span>
</span></code></pre></div><p>Almost there. GitHub doesn’t sync &amp; install schedules for forked repositoies without a manual run or
an additional push. Go to Actions, find Rebase workflow and click on the Run workflow button.</p>
<p>That’s it, really. If the rebase fails, GitHub will send you an email letting you know about it.</p>
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/keep-your-github-forks-up-to-date/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625051</guid>
            <pubDate>Tue, 29 Sep 2020 07:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing an accessible color palette with magic numbers]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24624914">thread link</a>) | @darekkay
<br/>
September 29, 2020 | https://darekkay.com/blog/accessible-color-palette/ | <a href="https://web.archive.org/web/*/https://darekkay.com/blog/accessible-color-palette/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>A low text contrast is the <a href="https://webaim.org/projects/million/" target="_blank" rel="noopener">most common accessibility issue</a>. 86% of the top 1,000,000 websites have at least one contrast ratio violation, which may lead to a bad user experience. Our favorite orange website isn’t leading by example, either. Some comments are almost unreadable:</p><figure><picture><img src="https://darekkay.com/blog/accessible-color-palette/hacker-news.png" srcset="https://darekkay.com/blog/accessible-color-palette/hacker-news.png, https://darekkay.com/blog/accessible-color-palette/hacker-news-2x.png 2x" alt="Insufficient contrast ratio on Hacker News"></picture><figcaption>Insufficient contrast ratio on Hacker News</figcaption></figure><p>There are various tools that help us <em>identify</em> and <em>fix</em> contrast ratio issues on our websites. This post presents an approach for designing and structuring color palettes so that we can prevent such issues <em>before</em> they arise: “magic numbers”.</p><h2 id="Which-contrast-ratio-is-accessible"><a href="#Which-contrast-ratio-is-accessible" title="Which contrast ratio is accessible?"></a>Which contrast ratio is accessible?</h2><p>How do we know whether the contrast ratio between a text and its background is sufficient? The <em>Web Content Accessibility Guidelines</em> (WCAG) <a href="https://www.w3.org/TR/WCAG20-TECHS/G18.html" target="_blank" rel="noopener">define</a> minimum required contrast ratios, based on colors, text properties (size, boldness) and conformance levels (AA vs. AAA):</p><figure><table><thead><tr><th></th><th>Level AA</th><th>Level AAA</th></tr></thead><tbody><tr><td><strong>small text</strong></td><td>4.5+</td><td>7+</td></tr><tr><td><strong>large text</strong></td><td>3+</td><td>4.5+</td></tr></tbody></table><figcaption>Minimum required contrast ratio values</figcaption></figure><p>Note: <em>large text</em> is defined as <em>19px+ bold</em> or <em>24px+ normal</em>.</p><p>As a rule of thumb, try to go for a <strong>4.5:1</strong> minimum contrast ratio, which will pass <strong>WCAG AA</strong> independent of the text size. This provides a good cost-value trade-off and is often the legal accessibility requirement.</p><p>Calculating the accessibility conformance manually is tedious. Instead, I suggest using a tool like <a href="https://contrast-ratio.com/" target="_blank" rel="noopener">contrast-ratio.com</a>. DevTools in <a href="https://developer.mozilla.org/en-US/docs/Tools/Accessibility_inspector#Color_contrast" target="_blank" rel="noopener">Firefox</a> and <a href="https://umaar.com/dev-tips/236-accessible-colour-suggestions/" target="_blank" rel="noopener">Chrome</a> provide great built-in browser support. Finally, <a href="https://github.com/dequelabs/axe-cli" target="_blank" rel="noopener">axe-core</a> will scan a website for all kinds of accessibility violations.</p><p>Those tools are a great way to find contrast ratio issues, but let me describe a technique to prevent them in the first place.</p><h2 id="Magic-numbers"><a href="#Magic-numbers" title="Magic numbers"></a>Magic numbers</h2><p>Most color palettes divide their colors into grades (e.g. <code>pink-10</code> … <code>pink-90</code>).</p><p>Let’s define a <em>difference between two color grades</em> as <strong>magic number</strong>, e.g.:</p><ul><li>Colors: <code>blue-80</code> and <code>orange-30</code></li><li>Magic number: <code>80 - 30</code> = <code>50</code></li></ul><p>What if we could find a magic number for the whole palette that ensures a sufficient color contrast between two colors? The first time I’ve heard about this concept was in a <a href="https://pspeter3.com/blog/2020/02/19/accessible-contrast-shades/" target="_blank" rel="noopener">blog post</a> from Phips Peter. I’ve learned about the <a href="https://designsystem.digital.gov/design-tokens/color/overview/" target="_blank" rel="noopener">U.S. Web Design System</a> and was immediately hooked. The color system provides the following magic numbers:</p><ul><li>A magic number of <strong>40+</strong> ensures a contrast ratio of <strong>3+</strong></li><li>A magic number of <strong>50+</strong> ensures a contrast ratio of <strong>4.5+</strong></li><li>A magic number of <strong>70+</strong> ensures a contrast ratio of <strong>7+</strong></li></ul><p>By looking at the color names, I know that <code>red-40</code> and <code>gray-90</code> (= <code>50</code>) will definitely pass <em>WCAG AA</em> (required contrast ratio <code>4.5+</code>), while <code>red-60</code> and <code>gray-90</code> (= <code>30</code>) will not. This leads to a <em>fantastic</em> designer/developer experience. I don’t have to use a contrast checker or look anything up to ensure a sufficient contrast ratio. A difference of 50 or more is all I care about.</p><h2 id="Calculating-magic-numbers-for-an-existing-color-palette"><a href="#Calculating-magic-numbers-for-an-existing-color-palette" title="Calculating magic numbers for an existing color palette"></a>Calculating magic numbers for an existing color palette</h2><p>Some libraries define their magic numbers in the documentation, but what about others?</p><p>I have written <a href="https://github.com/darekkay/a11y-contrast" target="_blank" rel="noopener">a11y-contrast</a> to calculate the magic numbers for any color palette that follows a grade naming pattern (e.g. <code>red-20</code>). This tool also finds all violations for any given magic number. This way you can prevent regression issues after adding or adjusting a color value.</p><figure><picture><img src="https://darekkay.com/blog/accessible-color-palette/a11y-contrast.png" srcset="https://darekkay.com/blog/accessible-color-palette/a11y-contrast.png, https://darekkay.com/blog/accessible-color-palette/a11y-contrast-2x.png 2x" alt="CLI output with magic numbers and a list of violations"></picture><figcaption>CLI output with magic numbers and a list of violations</figcaption></figure><p>I’ve calculated the magic numbers for some common color palettes:</p><table><thead><tr><th></th><th>3+</th><th>4.5+</th><th>7+</th></tr></thead><tbody><tr><td><a href="https://designsystem.digital.gov/design-tokens/color/system-tokens/" target="_blank" rel="noopener">USWDS</a></td><td>40</td><td>50</td><td>70</td></tr><tr><td><a href="https://www.ibm.com/design/v1/language/resources/color-library/" target="_blank" rel="noopener">IBM v1</a></td><td>50</td><td>60</td><td>70</td></tr><tr><td><a href="https://github.com/carbon-design-system/carbon/tree/master/packages/colors" target="_blank" rel="noopener">IBM Carbon v2.1</a></td><td>50</td><td>50</td><td>70</td></tr><tr><td><a href="https://tailwindcss.com/docs/customizing-colors/#default-color-palette" target="_blank" rel="noopener">Tailwind v1</a></td><td>60</td><td>70</td><td>80</td></tr><tr><td><a href="https://github.com/tailwindlabs/tailwindcss/pull/2132" target="_blank" rel="noopener">Tailwind v2</a> (proposal)</td><td>50</td><td>60</td><td>80</td></tr><tr><td><a href="https://yeun.github.io/open-color/" target="_blank" rel="noopener">Open Color</a></td><td>-</td><td>-</td><td>-</td></tr></tbody></table><p>Here are my takeaways:</p><ul><li><strong>USWDS</strong> defines <em>by far</em> the most colors (461!), and yet it uses the smallest magic numbers. This leads to a much wider spectrum of allowed color combinations than any of the other color palettes I’ve checked.</li><li><strong>Open color</strong> doesn’t have <em>any</em> magic numbers. This means I cannot reliably derive the contrast ratio from the color naming (e.g., <code>gray-90/red-20</code> is fine, but <code>red-90/red-20</code> is not).</li><li>Both <a href="https://github.com/uswds/uswds/issues/3329" target="_blank" rel="noopener">USWDS</a> and <a href="https://github.com/carbon-design-system/carbon/issues/6130" target="_blank" rel="noopener">IBM Carbon</a> previously contained minor violations, showing the importance of automatic tests.</li></ul><h2 id="Defining-luminance-bounds-with-fixed-magic-numbers"><a href="#Defining-luminance-bounds-with-fixed-magic-numbers" title="Defining luminance bounds with fixed magic numbers"></a>Defining luminance bounds with fixed magic numbers</h2><p>Predefined color palettes are great, but what if we want to change or add a color? What grade does a certain color map to?</p><p>Because the contrast ratio between two colors depends only on their <a href="https://www.w3.org/TR/WCAG20-TECHS/G17.html" target="_blank" rel="noopener">luminance values</a>, it is possible to create a mapping from a color to a grade between 0 and 100. For the USWDS color palette, here are the <a href="https://github.com/uswds/uswds/issues/3329#issuecomment-594762982" target="_blank" rel="noopener">luminance bounds</a>:</p><table><thead><tr><th>grade</th><th>min luminance (%)</th><th>max luminance (%)</th></tr></thead><tbody><tr><td>0</td><td>100</td><td>100</td></tr><tr><td>5</td><td>85</td><td>93</td></tr><tr><td>10</td><td>75</td><td>82</td></tr><tr><td>20</td><td>50</td><td>65</td></tr><tr><td>30</td><td>35</td><td>45</td></tr><tr><td>40</td><td>25</td><td>30</td></tr><tr><td>50</td><td>17.5</td><td>18.3</td></tr><tr><td>60</td><td>10</td><td>12.5</td></tr><tr><td>70</td><td>5</td><td>7</td></tr><tr><td>80</td><td>2</td><td>4</td></tr><tr><td>90</td><td>0.05</td><td>1.5</td></tr><tr><td>100</td><td>0</td><td>0</td></tr></tbody></table><p><a href="https://github.com/thisisdano" target="_blank" rel="noopener">Dan O. Williams</a> — a USWDS maintainer — optimized those values for <em>consistency</em> instead of <em>coverage</em>. This means there are more colors that don’t fit into <em>any</em> bound, even though they would technically pass the WCAG contrast ratio. While this setup is more constraining, I agree with the consistency benefits.</p><blockquote><p>It’s important that our color system be consistent and predictable, that users know what they’re getting when they choose a color of a certain grade. This makes us inclined to favor smaller, more equal ranges, and consistent spacing between ranges.</p></blockquote><p>If you want to calculate the luminance value and the potential USWDS grade of any color, check out my <a href="https://darekkay.com/dev/color-tools.html">Color Tools</a>.</p><picture><source type="image/webp" srcset="https://darekkay.com/blog/accessible-color-palette/color-palette.webp, https://darekkay.com/blog/accessible-color-palette/color-palette-2x.webp 2x"><img src="https://darekkay.com/blog/accessible-color-palette/color-palette.jpg" srcset="https://darekkay.com/blog/accessible-color-palette/color-palette.jpg, https://darekkay.com/blog/accessible-color-palette/color-palette-2x.jpg 2x" alt=""></picture><h2 id="Conclusion"><a href="#Conclusion" title="Conclusion"></a>Conclusion</h2><p>Let me summarize all the theory into some <strong>actionable advice</strong>. There are two ways to create an accessible color palette with <em>magic numbers</em>:</p><ol><li>Create a color palette first and calculate the magic numbers with <a href="https://github.com/darekkay/a11y-contrast" target="_blank" rel="noopener">a11y-contrast</a>. Depending on the colors, the magic numbers might be rather high or even non-existent (see Open Color).</li><li>Define luminance bounds with fixed magic numbers and use only colors that can be mapped. This approach is more constraining and requires more work, but the result is a future-proof and consistent color palette.</li></ol><p>If you don’t want to go through all the work, I suggest you try out the <a href="https://designsystem.digital.gov/design-tokens/color/system-tokens/" target="_blank" rel="noopener">USWDS color palette</a>.</p></div></div></div>]]>
            </description>
            <link>https://darekkay.com/blog/accessible-color-palette/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624914</guid>
            <pubDate>Tue, 29 Sep 2020 07:09:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security September: Still Early Days for ABAC]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624908">thread link</a>) | @boyter
<br/>
September 29, 2020 | https://onecloudplease.com/blog/security-september-still-early-days-for-abac | <a href="https://web.archive.org/web/*/https://onecloudplease.com/blog/security-september-still-early-days-for-abac">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

		<div data-page-title="Security September: Still Early Days for ABAC – One Cloud Please">

			<section>

	

</section>

<section>

	<p><img src="https://onecloudplease.com/images/posts/tag.jpg" alt=""></p>

<p><em>This is the final part of a 5-part series on AWS exploits and similar findings discovered over the course of 2020. All findings discussed in this series have been <a href="https://aws.amazon.com/security/vulnerability-reporting/">disclosed</a> to the AWS security team and had patches rolled out to all affected regions, where necessary. A big thanks to my friend and fellow Australian <a href="https://twitter.com/__steele">Aidan Steele</a> for co-authoring this series with me. Check out parts <a href="https://onecloudplease.com/blog/security-september-escaping-codebuild">2</a> and <a href="https://onecloudplease.com/blog/security-september-cataclysms-in-the-cloud-formations">4</a> for his work!</em></p>

<p>In the final part of this series we take a look at an exploit that let us tag S3 buckets without permission, even with an explicit deny, and what this means for attribute-based access control (ABAC).</p>

<h2 id="discovery">Discovery</h2>

<p>I recently embarked on a <a href="https://github.com/iann0036/aws-leastprivilege">project</a> that attempts to generate detailed IAM policy statements given a defined CloudFormation template. I admit this was a little too ambitious and this didn’t get too far, but the process required me to create valid CloudFormation templates which hit every possible field for a resource type so I could incrementally determine what permissions were needed on a field-by-field basis.</p>

<p>When performing this for the <code>AWS::S3::Bucket</code> type, I eventually had a template where I had to define the <code>Tags</code> field. To my surprise, the stack successfully updated without the <code>s3:PutBucketTagging</code> permission I expected to require (as referenced in the <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html">ARC</a> documentation).</p>

<p>After some testing, I determined that S3 buckets within a stack could have its tags modified without the presence of the tagging permission, or even if an explicit deny IAM permission is set. I could also bring existing S3 buckets into a stack using the CloudFormation import feature and adjust tags for the imported resource.</p>

<p>I never had the exact reason for this discrepancy explained to me, but my theory relates to the automatic application of <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html">stack tags</a> to supported resources within a stack. These stack tags are prefixed with <code>aws:</code>, which is a prefix that standard users are not permitted to use. I believe that the application of these stack tags are performed through an internal endpoint and that perhaps the S3 tag application was also occurring through this endpoint, which means that the usual <a href="https://aws.amazon.com/blogs/security/protect-sensitive-data-in-the-cloud-with-automated-reasoning-zelkova/">automated reasoning</a> was not being performed - however this is just a theory.</p>



<p>I <a href="https://aws.amazon.com/security/vulnerability-reporting/">raised</a> the issue directly with the AWS security team, who got back to me within a day.</p>

<p>This issue had some complications that led to a couple of delays with the rollout likely due to the fact that some in-depth analysis was occurring to determine which customers would be affected and, if necessary, reach out to them to ensure their workloads wouldn’t be affected by providing remediation steps. Per those communications, it seems RDS and ELB had similar issues.</p>

<p>If users attempt to perform the S3 action today, they’d receive the following stack event:</p>

<p><img src="https://onecloudplease.com/images/posts/s3-cfn-permission-1.png" alt=""></p>

<h2 id="on-attribute-based-access-control-abac">On Attribute-Based Access Control (ABAC)</h2>

<p>This incident did not change my view on <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_attribute-based-access-control.html">ABAC</a> and only strengthened my beliefs that it is a high risk approach for the security of your cloud resources. The AWS team <a href="https://aws.amazon.com/blogs/mt/simplifying-permissions-management-at-scale-using-tags-in-aws-organizations/">publish</a> <a href="https://aws.amazon.com/blogs/security/attribute-based-access-control-ad-fs-simplify-iam-permissions-management/">great</a> <a href="https://www.youtube.com/watch?v=7eC5eUVt_VI">content</a> on how the ABAC model improves agility however I strongly believe that at this point tags are a tool for auditing, billing and automation - not for access control.</p>

<p>With the amount of services utilizing tags for their own purposes and subsequently tagging permissions being seen as a low risk permission, I recommend cloud security practitioners stick to traditional resource-based access control. <a href="https://twitter.com/iann0036">@ me</a> if you disagree!</p>

<h2 id="closing-out">Closing out</h2>

<p>I was able to work with the teams to get this patched, however it is a good opportunity to revisit your security model if you’re using ABAC in your organization. Many services and methods have functionality that is built with an RBAC model in mind, and you should be vigilant that the assumptions within your environment continue to hold true.</p>

<p>Thanks to the AWS security, S3 and CloudFormation team members who worked with me to help remediate this issue, and thanks for those readers who took the time to read this series. Both Aidan and I enjoyed writing it and I hope you all enjoyed reading it!</p>

<p>✌️</p>


</section>

		</div>

	</div></div>]]>
            </description>
            <link>https://onecloudplease.com/blog/security-september-still-early-days-for-abac</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624908</guid>
            <pubDate>Tue, 29 Sep 2020 07:08:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun Yet Effective Meetings]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24624819">thread link</a>) | @thesnide
<br/>
September 28, 2020 | https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html | <a href="https://web.archive.org/web/*/https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <blockquote>
  <p>⚠️ This article is extreme &amp; satirical on the purpose of being thought-provoking. Therefore, please, do take it with some grain of salt.</p>

  <p>This is a followup of my <a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working is a paradigm shift</a>.</p>
</blockquote>



<p>My #1 advice about distributed teams is actually even the case in colocated teams:
<strong>Try as hard as possible to avoid meetings, use textual IM instead</strong> as <a href="https://blog.codinghorror.com/meetings-where-work-goes-to-die/">meetings are where work goes to die</a>.
I know it sounds pretty dull, but if you really think about it you’ll see that it’s usually wasted time.
The usual pattern of decision taking is:</p>

<div><div><pre><code>1. if you don’t have a clue, ask someone else.
2. to ask him, schedule a meeting
3. to schedule a meeting, you have to find a slot
4. that usually postpones the decision
</code></pre></div></div>

<p>Postponing the decision is usually what one really wants, even unknowingly: “<em>to be able to have an excuse not to decide at once</em>”.</p>

<p>It’s a very very fair humane reaction, I also fell myself into that trap.</p>

<p><img src="https://blog.pwkf.org/assets/images/out-of-window.jpg" alt="Thrown out of the fence for proposing an textual chat"></p>



<p>I end up having the following workflow:</p>

<ul>
  <li>Avoid email loops. Those have too much overhead, and will divide your audience pretty quickly.</li>
  <li>Create a slack channel instead of the email loop. This will retain the whole conversation in 1 central place.</li>
  <li>Systematically push back on any meetings. Accept them only if you have a clear statement of who will drive it.</li>
  <li>
    <p>Meetings should be a broadcast mode. All the Q&amp;A should go back to the slack channel.</p>

    <ul>
      <li>Having everything searchable makes it super easy for
        <ul>
          <li>newcomers that can simply scroll back</li>
          <li>old timers such as me that forget and can also simply scroll back</li>
        </ul>
      </li>
      <li>
        <p>Even recorded meetings are a vast of time if you need to find an information, as it’s not indexed.</p>
      </li>
      <li>If not recorded, sending the minutes afterwards are usually a loss of information.
        <ul>
          <li>It’s still very important to extract “executive summaries” from those meetings, even only textual. As can be posted on a public place for massive &amp; broad sharing.</li>
          <li>Yet, the real context on those summaries will be kept inside the whole meeting</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Context effectively fights Cargo Cult</strong></p>

  <p>Usually the why of decisions are not provided in a “<a href="https://english.stackexchange.com/questions/120739/a-peek-into-the-sausage-factory">build the sausage</a>” manner. But after a while, the hypothesis of the decision are not true anymore, and therefore another decision has to be taken.</p>

  <p>This is not possible when loss of information occurs and that’s when <a href="https://en.wikipedia.org/wiki/Cargo_cult_programming">Cargo cult</a> begins to creep in.</p>
</blockquote>

<p>In a record-everything scenario, context switch is just a matter of reading back some previous messages. Otherwise you’ll spend numerous times “explaining the context” in a meeting to everyone. And then everyone will just move to something else, and you’ll have pitiful engagement, while still spending time on it.</p>

<p><strong>A company that use its time effectively, is a company that moves much faster than its competitors</strong>, no matter the skillsets in that company. Even if you have the brightest minds, if you waste their talents in boring activities, you’ll dry them up. And either they’ll leave, or worse, they <a href="https://www.sbnonline.com/article/the-quit-and-stay-syndrome-a-business-epidemic-thats-a-silent-profit-killer/">quit &amp; stay</a>.</p>

<blockquote>
  <p>💡 This enabled me to scale to a reasonable multitasking ability while curbing its overhead to a manageable level</p>
</blockquote>

<p><strong>That’s why “startups” are so effective</strong> : they are small and therefore very fast. Being fast brings capacity to try &amp; fail, and therefore agility.</p>

<blockquote>
  <p>💡 <strong>time is the only really scarse resource in a company</strong> : you can’t buy it back, no matter the price.</p>
</blockquote>

<h2 id="why-you-should-only-have-fun-ones">Why you should only have fun ones</h2>

<p>That said, I do agree that travelling is necessary. But we should name the real usecase of travelling : having <em>fun</em> <strong>together</strong>.</p>

<p>The nicest part of that purpose is :</p>

<ul>
  <li>you can plan it far in advance</li>
  <li>you can also budget it in advance</li>
  <li>you can mentally map yourself in those fun times, and focus on actual work right now.</li>
</ul>



<p>The most used reason for meetings is “alignments”, but it is very usually wasted as :</p>

<ul>
  <li>There’s always someone missing for that meeting</li>
  <li>No-one really wants to write the minutes out of it</li>
  <li>If written nonetheless, those minutes are only seldom capturing the <em>why</em> the decision is reached. Which is the most important part!</li>
</ul>

<p>The “<em>there’s always someone missing from that meeting</em>” is the worst part, as usually, that is the one that says “what you decided cannot be done”. And you’ll end up with yet another round of thinking at best. At worst you’ll try to shoehorn your precious alignment (that did sink a huge travel budget) into the needs of that missing person.</p>

<blockquote>
  <p>💡 We can draw a parallel to the paradigm shift I mentioned earlier:</p>
</blockquote>

<ul>
  <li><strong>F2F</strong> Meetings are the <strong>monolith</strong> way.</li>
  <li>Informal, dedicated &amp; <strong>textual meetings</strong> are the <strong>micro-services</strong> way.</li>
</ul>

<p>Now, one immediately notices the following:</p>

<ul>
  <li><strong>People are very much at ease with monoliths</strong>. It takes a huge mental leap to go micro-services.</li>
  <li><strong>Micro-services have an overhead</strong>. But no-one will argue that they can scale way better.</li>
  <li>Monoliths can seldomly be distributed the way micro-services can : you’ll quickly end up with that infamous distributed monolith pattern.</li>
</ul>

<blockquote>
  <p>💡 Now, let’s travel only for “team building” purposes.</p>

  <p>You can plan them in advance, and you won’t have over-budget ones. As their outcome is predictable, and if there’s someone missing, it won’t jeopardy the whole travelling.</p>
</blockquote>

<p>A final word of caution, the reference to scaling is <strong>not about runtime performance</strong>. It’s more about <strong>organisation size</strong>. As Martin Fowler said : <em>don’t even consider microservices unless you have a system that’s too complex to manage as a monolith</em>.</p>

<p>So, it usually makes very much sense to start with a small, colocated team, that has traditional meetings. The trick is to recognize the need to change the paradigm when the team grows, as it always done smoothly over the months. Just don’t forget to have good meeting hygiene (written inputs &amp; outputs), as <strong>even monoliths should be nicely modular</strong>.</p>

<blockquote>
  <p>I posted those 2 articles (<a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working</a>, <a href="https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">Effective Meetings</a>) internally to my company some years ago, but I’m republishing those publicly to help others the same way it helped us.</p>
</blockquote>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624819</guid>
            <pubDate>Tue, 29 Sep 2020 06:54:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for the most immersive video calls]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624798">thread link</a>) | @telotortium
<br/>
September 28, 2020 | https://www.benkuhn.net/vc/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/vc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I spend a lot of my day on video calls. Wave is a distributed company, so they’re the main way we communicate. But compared to talking in person, they feel unnatural:</p><ul><li>Most people have low-quality microphones and webcams that make them look and sound bad.</li><li>There’s a lag between when you say something and when the other person hears it, making it hard to navigate conversational <a href="https://en.wikipedia.org/wiki/Turn-taking" target="_blank">turn-taking</a>.</li><li>If you’re using headphones, you can’t hear your own voice very well.</li><li>Because of <a href="https://en.wikipedia.org/wiki/Echo_suppression_and_cancellation" target="_blank">echo cancellation</a>, you often can’t talk when someone else is also talking, which makes the conversation flow less well.</li></ul><p>I started wondering how much nicer video calls would feel if I fixed these problems. So I spent way too much time fiddling with gear and software. This post summarizes what I’ve learned.</p><p>Collectively, these recommendations have had a pretty big impact: when talking one-on-one to friends with equally good setups, I’ve been able to go 4+ hours without feeling fatigued.</p><p><em><small>Epistemic status: best guess; not a professional; almost certainly contains wrong bits. Tell me which ones by comment or <a href="https://www.benkuhn.net/contact/">email</a>!</small></em></p><h2 id="omg-ben-dont-make-me-read-your-4500-word-doorstopper-just-tell-me-what-to-do">omg ben don’t make me read your 4500 word doorstopper, just tell me what to do</h2><p>Here’s how I would stack-rank my advice for my past self. (Of course, your personal ranking might be different depending on your situation.)</p><ol><li><p>($depends) Don’t work in a space where your noise can bother other people, or vice versa.</p></li><li><p>($10-30) If you ever have network issues, run <a href="https://amzn.to/3luTVdV" target="_blank">a cable</a> between your computer and router. You’ll probably need an <a href="https://amzn.to/2YOFis9" target="_blank">adapter</a>. (Contrary to popular belief that a bad connection is your ISP’s fault, it’s <a href="https://www.benkuhn.net/wireless/">more likely to be flaky wifi</a>.)</p></li><li><p>(~$100) Buy <a href="https://amzn.to/3bULynH" target="_blank">open-back headphones</a>, which let you hear your own voice normally and are extremely comfortable.</p></li><li><p>(~$30) Switch from your built-in computer mic to a <a href="https://www.sweetwater.com/store/detail/BoomProMic--v-moda-boompro-microphone-communication-mic-for-headphones" target="_blank">headset mic</a> (and <a href="https://amzn.to/3hOU5JU" target="_blank">pop filter</a>), which will sound much better and pick up less noise. Note this requires a headset with detachable cable, like the one I linked above.</p><p>You can now leave yourself unmuted! If the other person also has headphones, you can also talk at the same time. Both of these will make your conversations flow better.</p></li><li><p>($0) Prefer Zoom to most alternatives; it has higher sound quality, better echo cancellation, and fewer silly behaviors. If you have headphones and a good mic, enable “original sound” to turn off some unnecessary audio filtering.</p></li><li><p>(~$200) Get a second monitor for notes so that you can keep Zoom full-screen on your main monitor. It’s easier to stay present if you can always glance at people’s faces. (I use an iPad with <a href="https://support.apple.com/en-us/HT210380" target="_blank">Sidecar</a> for this; for a dedicated device, the right search term is <a href="https://amzn.to/3iZRUVz" target="_blank">“portable monitor”</a>. Also, if your meetings frequently involve presentations or screensharing, consider getting a third monitor too.)</p></li><li><p>($0?) Arrange your lighting to cast lots of diffuse light on your face, and move any lights that shine directly into your camera. Lighting makes a bigger difference to image quality than what hardware you use!</p></li><li><p>(~$20-80 if you have a nice camera) Use your camera as a webcam. There’s software for <a href="https://www.usa.canon.com/internet/portal/us/home/support/self-help-center/eos-webcam-utility" target="_blank">Canon</a>, <a href="https://fujifilm-x.com/en-us/support/download/software/x-webcam/" target="_blank">Fujifilm</a>, <a href="https://downloadcenter.nikonimglib.com/en/download/sw/176.html" target="_blank">Nikon</a>, and <a href="https://support.d-imaging.sony.co.jp/app/webcam/en/" target="_blank">Sony</a> cameras (Windows-only for Nikon and Sony); for others, if they can output clean HDMI (check <a href="https://www.elgato.com/en/gaming/cam-link/camera-check" target="_blank">this list</a>), you can buy an <a href="https://amzn.to/3kgunjj" target="_blank">HDMI capture card</a>. You will also want to be able to plug your camera into a power source, for which you may need a “dummy battery.”</p></li><li><p>(~$40 if you have a smartphone with a good camera) Use that as a webcam via <a href="https://reincubate.com/camo/" target="_blank">Camo</a>.</p></li><li><p>(~$350) If you don’t own a nice camera but want one, you can get a used entry-level mirrorless camera + lens + dummy battery + boom arm. See <a href="#a-note-on-camera-buying">buying tips below</a>.</p></li></ol><p>More detailed recommendations and justifications follow.</p><h2 id="network">Network</h2><p>Connection problems are the thing that makes video calls suck the most. They do this in three different ways:</p><ol><li><p>If your connection ever gets really bad, your audio will break up, which is exhausting to listen to and ruins the flow.</p></li><li><p>Even if it doesn’t get that bad, a poor connection will increase <em>latency</em>, or the time between when you speak and when the other person hears you. High latency is what causes the dreaded “you first, no <em>you</em> first” dance.</p></li><li><p>Finally (and least importantly), a bad connection limits the amount of data you can exchange, forcing you to use lower-quality video. This doesn’t really matter if you’re using a webcam, but by the end of this post, you might have a good enough camera that it matters.</p></li></ol><p>I wrote a whole post of its own on how to troubleshoot your home network for video calls, but realistically, most connection problems are because <a href="https://www.benkuhn.net/wireless/">wifi sucks</a> and you can avoid them by not using wifi. So, first try running an <a href="https://amzn.to/3luTVdV" target="_blank">Ethernet cable</a> between your computer and your router. If you still notice high latency or your connection dropping, or if you really can’t run a cable for some reason, <a href="https://www.benkuhn.net/vcnet/">check the guide</a> for more troubleshooting advice.</p><h2 id="audio">Audio</h2><p>Video improvements are flashy and noticeable, but audio is the reason you’re having the call, thus ultimately more important. So audio comes first.</p><h3 id="get-away-from-other-people">Get away from other people</h3><p>This is a basic prerequisite for everything below. Coworking spaces and cafés are nice if you plan to be silent all day, but will make natural-feeling meetings impossible due to your crippling self-consciousness about noise levels. If you’re going to be on a call for more than 5 minutes, get your own space.</p><p>(If you are committed to taking your meetings in a crowded and noisy space, ignore the rest of the audio section. You’re mostly just doomed to crappy calls in this case, though you might be able to limit the damage by getting <a href="https://www.sweetwater.com/store/detail/BoomProMic--v-moda-boompro-microphone-communication-mic-for-headphones" target="_blank">a nice headset mic</a> and installing <a href="https://krisp.ai/" target="_blank">krisp.ai</a>.)</p><p>If you’re talking to someone else who’s in a noisy environment, you can apparently also use krisp.ai to filter their audio yourself, though I haven’t tried this.</p><h3 id="get-full-duplex-audio-with-no-echo">Get full-duplex audio with no echo</h3><p>One key ingredient to making voice conversations feel “natural” is that both participants need be able to talk and hear the other person talking at the same time (“full-duplex audio”). Full-duplex audio is important because it allows you to talk simultaneously (“overlap”) with the other person.</p><p>You might think that overlap should be rare, because interrupting someone else is rude. While that’s true of large-scale overlaps, we often use small-scale overlaps to <a href="https://en.wikipedia.org/wiki/Turn-taking#Overlap" target="_blank">negotiate conversational turn-taking</a> (e.g. starting talking when the speaker is trailing off but hasn’t finished), or to signify that we’re paying attention (“uh-huh,” “yeah”).</p><p>The hard problem of full-duplex audio is that if someone else is talking, their voice is going to come out of your computer’s speakers and go back into your microphone. If your computer leaves the microphone on, in that case, it’ll end up playing back an “echo” of their own voice to them, which is extremely annoying. So video call tries to filter out feedback from your speakers into your microphone, which is called <a href="https://en.wikipedia.org/wiki/Echo_suppression_and_cancellation" target="_blank">echo cancellation</a>.</p><p>Unfortunately, removing <em>only</em> the speaker echo from your microphone stream is really hard to do. So instead, the software often ends up completely muting your mic if someone else is talking. If you’ve ever tried to micro-overlap with someone and noticed that their audio cut out briefly, that’s what’s going on.</p><p>If your listeners can’t overlap with you, it’s harder to tell whether they’re following along, and it’s harder to negotiate whose turn it is to speak. This makes the conversation feel less natural, especially in larger groups.</p><p>To get full-duplex audio, you need to (a) have an audio setup that doesn’t produce echoes, then (b) convince your video call app not to try to suppress echoes.</p><p>(a), “an audio setup that doesn’t produce echoes,” means that your microphone should not pick up any sound from your speakers. In practice this means that your “speakers” must be headphones.</p><p>(b), “convince your video call app not to try to suppress echoes,” seemed surprisingly tricky when I tried to research it, because each video call app has its own heuristics for when to engage echo-cancellation.</p><p>So I did my own tests of echo cancellation Zoom, Skype, and Hangouts in Chrome and Firefox. I started a chat between two computers, both with headphones attached—a setup that should have required no echo cancellation. I then played music into the microphone of one computer. On the other, I spoke into the microphone and listened for whether the music got quieter.</p><p>Zoom, Skype and Hangouts in Firefox all seemed to slightly decrease the audio volume when I spoke, indicating light echo cancellation. For Hangouts in Chrome, the audio cut out <em>completely</em> every time I said anything. In Zoom, I was able to eliminate all echo cancellation by selecting the “use original audio” option, which you can also permanently enable for particular audio devices—I’d recommend doing this.</p><h3 id="throw-your-wireless-headset-in-the-trash">Throw your wireless headset in the trash</h3><p>The gear I recommend in this guide is all wired, not Bluetooth. While Bluetooth seems like it should be great, in practice it has <a href="https://www.benkuhn.net/wireless/">horrible problems with audio latency, quality and reliability</a>. Also, I don’t think wireless open-back headphones (see below) exist.</p><p>If you finished the previous paragraph and still think you can get away with using wireless audio gear, read the post at the link :)</p><h3 id="hear-yourself-clearly-with-open-back-headphones">Hear yourself clearly with open-back headphones</h3><p>Most headphones are <em>closed-back</em>, which means they form an acoustic seal over your ear that attenuates outside sound. This is good for “noise isolation” when you’re listening to music. But it’s bad in calls because it also isolates you from your own voice, making you sound muffled and unnatural to yourself. (The same thing also happens with any earbuds that form a seal, i.e. pretty much everything except EarPods or non-Pro AirPods.)</p><p>Personally, without the feedback from hearing myself, I also tend to start speaking louder or shouting on calls. This tires out my voice, and can get stressful for whoever I’m <del>shouting at</del> talking to.</p><p>To avoid this, you can buy <em>open-back headphones</em>, which have mesh instead of a closed covering over your ears. I bought the <a href="https://amzn.to/3bULynH" target="_blank">Philips SHP9500</a>, which I like a lot; I haven’t tested any other pairs. (I chose a low-end pair because for …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.benkuhn.net/vc/">https://www.benkuhn.net/vc/</a></em></p>]]>
            </description>
            <link>https://www.benkuhn.net/vc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624798</guid>
            <pubDate>Tue, 29 Sep 2020 06:49:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Radio I/Q Data for Dummies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624796">thread link</a>) | @pabo
<br/>
September 28, 2020 | http://whiteboard.ping.se/SDR/IQ | <a href="https://web.archive.org/web/*/http://whiteboard.ping.se/SDR/IQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">
<p>This is a description of using I/Q Data (aka "analytic signal") representing a signal. Since the topic may be quite confusing, I've described the same thing here from different point of views. If you find the information somewhat redundant, it is because it is. Different views may appeal to different readers, and if something seems unclear, keep on reading and it may be more comprehensible later - hopefully.
</p>
<h2>Why I/Q Data?</h2>
<p>I/Q Data is a signal representation much more precise than just using a series of samples of the momentary amplitude of the signal. Have a look at the following signal below.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/cosample.png" alt="Plain signal" title="Plain signal"></p>
<p>This is what you may be used to work with. So why I/Q Data - isn't this good enough?
</p>
<p>Not really. We have a few problems here.
</p>
<ul><li>First, it is impossible to determine the frequency of this signal. Sure, it looks simple enough, just look at the period length? True, but you have no clue if it's a positive or negative frequency since they both generate the same curve. I.e. cos(x) = cos(-x). This becomes a problem working with the signal. Mixing (multiplying) two signals and it'll cause multiple solutions due to the uncertainty of the sign: f1 âŠ— f2 equals f1 + f2 as well as f1 - f2.
</li><li>Second, it's hard to determine the power (peak amplitude, envelope) of the signal. Basically you can only see the peak amplitude here at 0Â°, 180Â°, 360Â° etc, and how do you know the power is the same everywhere else as well? And did you sample the signal exactly at its peak? You really don't know.
</li></ul><p>I/Q Data solves this. Instead of looking at the signal as a flat curve as above, look at it as a corkscrew (helix, spiral, coil spring) in three dimensions.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkscrew.png" alt="Complex signal" title="Complex signal"></p>
<hr>
<p>Now if you look at this curve from the side, you'll actually get the same graph as the first one above. Your "real" signal actually is this 2D projection of this corkscrew signal. This is your "I" in I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkI.png" alt="Side view" title="Side view"></p>
<hr>
<p>Now have a look at the corkscrew from above. This looks quite similar, but as you see, it is out of phase 90Â°  starting at zero, not at one as the other. This this the Q part of your I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkQ.png" alt="Top view" title="Top view"></p>
<hr>
<p>Now looking at the corkscrew down the time axis you'll see it winds counter-clockwise. This means we know the frequency is positive. It could have wound clockwise as well, still generating the same I-signal (projection) but different Q-signal, representing a negative frequency.
</p>
<p>You also see that the radius of the corkscrew is constant at every sample, if small in I large in Q and vice versa. The radius is the peak amplitude of your signal. 
</p>
<p>The axes are of course 90Â°, so the radius must be equal to (IÂ²+QÂ²)<sup>1/2</sup>. This is the peak amplitude of your signal, and as you can see you know this for each and every sample.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkT.png" alt="Viewed down time axis" title="Viewed down time axis"></p>
<h2>What is I/Q Data?</h2>
<p>AS you now understand, the I/Q Data Sample is the coordinates of your signal as seen down the time axis of the corkscrew.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/onesample.png" alt="" title=""></p>
<p>You might object that your signal isn't a pure cosine function as the one we have shown here, and it might be very true. Still, every single sample of your signal can be described as such, i.e. with a peak amplitude times cosine of some phase angle.
</p>
<p>Every single point of your signal can be described as the function Aâ‹…cos(Ï•)
</p>
<p>Since you may freely chose any amplitude A and angle Ï• this must of course be true (as long as the signal is continuous). The value of Aâ‹…cos(Ï•) is the <strong>I</strong> component of the I/Q signal, i.e. your real signal. Note that this only describes your signal in one single point, i.e. one sample. Next sample gives you a new I and Q very likely resulting in another amplitude and/or phase angle, reflecting the modulation of the signal.
</p>
<h2>One sample I/Q Data</h2>
<p>Ok, lets take one sample of I/Q Data and see what it represents. This is also called a phase vector, or phasor.
</p>
<pre>I = 0.69
Q = 0.40
</pre>
<p>Lets draw this in the complex plane.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/iqdraw1.png" alt="" title=""></p>
<p>Lets see what this tells us about our data point.
</p>
<ul><li>The momentary amplitude of our real signal is by definition <strong>I</strong>, i.e. 0.69
</li><li>Pythagoras tells us the amplitude A of the cosine wave is <code>(0.69Â²+0.40Â²)<sup>1/2</sup> = 0.8</code>
</li><li>Trigonometry tells us our angle is +30Â° into our cosine wave.
</li></ul><p>- <em>Hold it</em>, you say, <em>what cosine wave?</em>
</p>
<p>Well, I/Q actually assumes your real signal (<strong>I</strong>, that is) can be described as the
function <strong>I</strong> = Aâ‹…cos(Ï•)
</p>
<p>Since you are free to chose A and Ï• this must of course be true, as long the function is continuous. Remember we are looking at one single sample now, i.e. one point in time.
</p>
<p>So by using IQ Data we not only get the momentary values of our signal, but the function generating it as well. If we put above together we get:
</p>
<p>The real signal I = 0.8â‹…cos(30Â°)
</p>
<hr>
<ul><li>I/Q Data is the representation (data type) of this cosine function.
</li></ul><p>I/Q Data is the rectangular representation of the polar notation we used above. There is a unique transformation between the two, and the different notations have different properties calculating with them. The rectangular form of I/Q Data is chosen due to the ease of hardware implementations of the most common operations.
</p>
<p>I/Q Data consists of I and Q represented as two separate variables, a vector of length two, or more often, the complex number  I + Q<em>i</em>  (yes, I is the real part).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/polrep.png" alt="" title=""></p>
<p>Note that the Amplitude above is the waves peak amplitude, not the momentary amplitude.
</p>
<ul><li>I is the current momentary amplitude of the signal (i.e. the Real signal)
</li><li>Q is the momentary amplitude of the signal phase shifted -90Â°.
</li></ul><p>For a simple function such as sine, the phase shift is what the signal was earlier in time, but for a signal with more than one sine component, Q reflects a -90Â° shift of the individual components, and not the composite signal as such. To convert a Real Signal to a I/Q Data Signal, discrete Fourier transformation is required (Hilberts transform).
</p>
<h2>Different ways of representing the same I/Q Data Sample</h2>
<p>There are at least three common ways to represent the I/Q Data Sample. Different representations gives you different pros and cons. Some are more easy to add, other are more easy to multiply etc. This may be important in the implementation, resulting in less complex hardware/software using the best representation.
</p>
<h3>The rectangular form</h3>
<p>The I/Q Data on the form Q and I is called "rectangular" (or "Cartesian") form as it can be viewed as positions in a coordinate system. I and Q are the x and y axis respectively. This is the most common representation you are used to. This form is most common due the ease of modulating/demodulating it in hardware. More about that later.
</p>
<ul><li>As a complex number: I + Q<em>i</em>
</li><li>As a vector [I,Q]
</li><li>Or just the two plain variables I and Q
</li></ul><h3>The polar form</h3>
<ul><li>Amplitude and angle
</li></ul><p>I = Amplitudeâ‹…cos(angle) <br>Q = Amplitudeâ‹…sin(angle)
</p>
<p>The Amplitude is the peak amplitude of the cos (and sin) function, and the angle is how far into the period from zero to 360Â° you are (or 0 to 2Ï€ if you prefers radians).
</p>
<h3>Eulers form</h3>
<p>Since cos(Ï•) + iâ‹…sin(Ï•) = e<sup>iÏ•</sup> we can write our IQ sample as
</p>
<p><span> Ae<sup>iÏ•</sup> </span>
</p>
<p>This might (not?) be the most intuitive representation of the sample. Ï• rotates the angle as seen in the polar representation, and A is of course the amplitude. Realizing this, Eulers identity becomes obvious. Because Ï• is the rotation of the vector in the complex plane, rotating it half a turn, 180Â° or Ï€ radians, results in a real part of -1 and no imaginary part, hence:
</p>
<p><span> e<sup>Ï€i</sup>+1 = 0 </span>
</p>
<p><em>"The student should find this to be immediately obvious,</em> <br><em>otherwise he'll never be a first rate mathematician"</em>
</p>
<p><em>-- Carl Friedrich Gauss </em>
</p>
<h2>Positive versus negative frequency</h2>
<p>It is now easy to see that using I/Q we can represent the signal frequency either as positive or negative. Have a look at the two I/Q signals red and blue below to the left and compare them with their corresponding real projections. It is as obvious they differ in signs in I/Q, as it's impossible to determine the signs using only the real signal component (neither the I nor the Q projection separately).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/freqsign.gif" alt="Positive versus negative frequencies" title="Positive versus negative frequencies"></p>
<p><span>(sidenote: I've put them slightly out of phase compared to each other since else they wouldn't be possible to distinguish at all in the real representation to the right. Also, please note I'm here, quiet unconventional, using the x axis in the phasor for the imaginary <strong>Q</strong>)</span>
</p>
<p>The same signal (well, more or less) in a 3D representation.
</p>
<p>The <strong>I</strong> components (side view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-i.png" alt="" title=""></p>
<p>The <strong>Q</strong> components (top view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-q.png" alt="" title=""></p>
<p>The I/Q signals in 3D:
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-3d.png" alt="" title=""></p>
<p><a name="twopriceone" id="twopriceone"></a>
As the Nyquistâ€“Shannon sampling theorem states you can only represent
frequencies up to <code>f/2</code> using a samplings rate of <code>f</code>. This is still true
using IQ Data, but since you now can represent negative frequencies
the signal spans <code>[-f/2..+f/2]</code> compared to <code>[0..+f/2]</code> using a â„�eal signal,
hence the range is in effect doubled. Using a
sampling rate of <code>f</code> and you now can represent a signal range of <code>f</code> as well.
Two to the price of one!
</p>
<h2>Mixing and multiplying signals</h2>
<p>Using real signals or IQ Signals gives different results when you multiply them. This is because using only the real component it's not possible to uniquely determine the phase angle of the signal, hence impossible to distinguish a positive frequency from a negative.
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-real.png" alt="Mixing 10 kHz with 3 kHz using real" title="Mixing 10 kHz with 3 kHz using real"></span></p>
<p>Multiplying two signals f1 and f2 in the real domain:
</p>
<p><span> Â±f1 âŠ— Â±f2 = (Â±)f1 Â± f2 </span>
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-iq.png" alt="Mixing 10 kHz with 3 kHz using I/Q" title="Mixing 10 kHz with 3 kHz using I/Q"></span></p>
<p>Using IQ Data the signs are now given, and the result is unambiguous:
</p>
<p><span> f1 âŠ— f2 = f1 + f2 </span>
</p>
<p><br>
A frequency spectrum in the real domain usually never show the negative side, since it always must be symmetric around zero due to the uncertainty of the sign of the frequency of the real signal -- hence the parentheses around the sign of <code>f1</code> in the first formula mixing the real signals. I've included the negative side here for illustrative purposes, despite of its redundancy.
</p>
<p>Multiplying two complex number is easiest understood in the polar representation. The amplitude is multiplied and the angle added.
</p>
<p><span> A<sub>1</sub>â‹…e<sup>iÏ•<sub>1</sub></sup>â‹…A<sub>2</sub> e<sup>iÏ•<sub>2</sub></sup> = A<sub>1</sub>A<sub>2</sub> e<sup>i(Ï•<sub>1</sub>+Ï•<sub>2</sub>)</sup> </span>
</p>
<p>Realizing the angle is added under multiplication makes it obvious that the frequencies are added as well.
</p>
<h3>And in time domain ...</h3>
<p>Now let us have a look at this in time domain. To make it easier (doable!) to calculate the DFT in our …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://whiteboard.ping.se/SDR/IQ">http://whiteboard.ping.se/SDR/IQ</a></em></p>]]>
            </description>
            <link>http://whiteboard.ping.se/SDR/IQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624796</guid>
            <pubDate>Tue, 29 Sep 2020 06:49:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know about running an A/B test. – Aanand Shekhar Roy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624555">thread link</a>) | @aanandshekhar
<br/>
September 28, 2020 | http://www.aanandshekharroy.com/articles/2020-09/intro-to-ab-tests | <a href="https://web.archive.org/web/*/http://www.aanandshekharroy.com/articles/2020-09/intro-to-ab-tests">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <article>
      <p>A/B test is a powerful tool that every product team can use to get insights from their customers. A/B tests or experiments provide us a controlled environment to understand why certain things happened. We all have heard ‘Correlation doesn’t imply causation’, meaning, just because two variables are correlated (sales of ice cream are increasing, and Amazon is expanding its ever-increasing empire), doesn’t mean one is causing another.
This, however, puts us in an uncomfortable place. How would we ever be able to confirm that our ingenious idea of adding a  little song and dance above the ‘Buy Now’ button is responsible for a 10x sale on our website? It could be due to the change we made, or it could just mean that discount code of 90% off went viral.</p>



<p>A/B tests help us to establish causality. How does it work? In short, we divide our users into two groups, one is called ‘control group’, and another is called ‘test group’. Then we show a design change only to users in the ‘test group’. Then we analyze the effects. Since the design change was the only difference between the control group and the test group, we can be certain to establish the causality that the design change is most likely the reason behind the observed effect. 
Note that in the above description I loosely used ‘design change’ as a catch-all term for any changes that you make, but it’s not just related to changes in design. You could use it for experimenting with different pricing points, subscription options, etc.
Here’s a little diagram I borrowed from a very good book on the topic which you should check out <a href="https://amzn.to/33ODbX7">Designing with Data: Improving the User Experience with A/B Testing</a>
<img src="http://www.aanandshekharroy.com/assets/img/abtestexperiment.png" alt="abtestdiagram"></p>

<p>People have been running experiments since the dawn of time. In the 18th century, a British captain ran an experiment where he gave citrus fruit to half of the sailors and observed that people who were not given citrus fruit had a higher rate of scurvy(which is caused by Vitamin C deficiency), so he concluded citrus fruit can prevent scurvy.
A/B tests in an online world today is experimentation on steroids. You can get feedback within hours from hundreds and thousands of people, cutting the time it takes to conclude radically. 
We’ll now look at important aspects of running an A/B test.</p>

<h2 id="sampling-the-users">Sampling the users</h2>

<p>This is the first and probably the most important step. In this step, you decide how to distribute your users under the control and test group. You have to be careful that you aren’t accidentally inducing bias in how the users are sampled. The best and the easiest way is to assign them randomly. This should certainly cancel out any unfair advantage one group may have over another.</p>

<h3 id="subdivision">Subdivision</h3>

<p>Another important consideration in an experiment is, which user group to get data about? 
One large user base is quite varied. If you subdivide your user base within cohorts and segments, you’d better understand the motivation and behavioral difference which might get unnoticed when considered as one big group.</p>

<h4 id="cohort-and-segment">Cohort and Segment</h4>

<p>A cohort is a group of users who have the same experience. It could be based on time (all 500 new users acquired during January because of a big sale on the e-commerce platform).
Or, you can segment your user base on a more stable characteristic like demographics, gender, etc.</p>

<p>If you focus on one single cohort/segment, you can better tap into their unique needs and motivations.</p>

<h3 id="new-users-vs-old-users">New users vs Old users</h3>

<p>Why it matters? Your existing users are accustomed to interactions with the app, so they might get a hang of your design changes easily (compared to new users). This learned behavior may influence the decision they make or experience your product.</p>

<p>“Learning effect” is a real thing. It takes time for users to get accustomed to your new UX. When you make a design change, if it is big, expect your metrics to go haywire initially.
One way to detect that a learning effect might be going on is to compare the metrics of new and old users. If old users are doing a lot better than new users, then probably you should let the experiment run a little bit longer. You might notice the metrics will become stable over time as they slowly get around the changes.</p>

<h2 id="metric-what-we-wish-to-influence">Metric: What we wish to influence</h2>

<p>We do an A/B experiment to test which approach might be better at improving a certain metric. There’s always a metric you have in mind that you want to influence, or else, why would you look for a better way to do a certain thing?
On a higher level, there are KPIs. They are key performance metrics that tell you the health of the company. They can be the number of new users, revenue generated by months, etc. But not all small A/B tests will reflect in a change in your KPIs, simply because KPIs are too big a target. To deal with this problem, you can create <em>proxy metrics</em>. They are basic metrics that correlate to the big KPIs. Let’s say you have ‘Revenue generated per month’ as a KPI, and you are testing a new design of the checkout button.
You can create the ‘Checkout button clicked’ metric and test which version of the test improved that metric. Clicking on the checkout button correlates highly to the ‘revenue generated’ metric so it’s a good proxy metric here.</p>

<p>The rationale here is simple. If you are observing an insensitive metric that takes longer time and effort to be changed meaningfully (like NPS score) you might not record any significant changes even after making significant changes in the user experience. For eg. Changing the copy in login form may result in a lot more people signing up, but may not have any effect on the NPS score.</p>

<h2 id="concluding-results">Concluding results</h2>

<p>So you’ve done all the pre-requisites, which means that you have a hypothesis that you want to test using the A/B test, You’ve decided which segment or cohort of users to run the tests on, and you’ve also picked up the metric you wish to influence. You run the test, and you get the results. How would you conclude that you’ve proved or disproved your hypothesis? Can we be sure of the tests and decide to invest resources based on these results? 
If we can say that we have statistically significant results, we can conclude the experiment and say confidently whether the hypothesis that we were testing is proved or disproved. To do that, we have to understand what a <strong>significance level</strong> is.</p>

<h3 id="significance-level">Significance level</h3>

<p>The significance level tells you the probability that a certain observation/result is caused by chance. For example, significance level, or in short <em>p-value</em> of 0.05 tells you that there is a 5% chance that the difference observed between the test and control group is due to pure chance. In other words, we are 95% confident that change in the test and control group is not caused by randomness/luck/chance.
Which <em>p-value</em> is the best? There is no right answer. In most social studies, p of 0.05 is commonly used. In experimental physics, a p-value of 0.0000003 can be used. As you can guess through intuition, to get a higher level of confidence, you’d need more data, more samples, which might make sense when you are making critical design based on the A/B tests, but it’s not always the case, and you might be ok with 10% chance of being wrong.
I’ve written more on <a href="http://www.aanandshekharroy.com/articles/2020-09/statistical-singificance-in-data">How to tell if you have ‘statistically significant’ results?</a> which goes into more detail.</p>

<p>Now you can conclude whether the results you have are statistically significant or not. Let’s say you can tell with 99% confidence that a little song and dance above the checkout button leads to more people buying stuff from you. Does that mean you should go ahead with the change? 
This a kind of question ‘statistical significance’ can’t tell you. There is a term called ‘Minimum detectable effect’, or MDE. This means, what’s the minimum change between the test and control group needs to be to call this A/B test a success and decide to further invest in this approach. Imagine in the above case we figured out that we need to observe a 10% improvement in people clicking on the ‘Checkout’ button to make a meaningful impact in our revenue, 10% would be our MDE. In that case, there needs to be a 10% improvement between the control and test group in our A/B test.
Note that it’s easier to detect bigger MDEs. As in, it’s easier to detect a 90% of a difference than a 0.9% difference. As a result, smaller MDEs require more powerful tests and large samples. Usually, you’d be running tests with smaller MDEs if you are working on optimizing experience, hence the changes will be subtle and small, but still may worth it. A 0.1% improvement in a billion-dollar revenue company is still huge :)</p>



<p>A/B tests are a great quantitative way of getting data to make a critical decision, but as with all quantitative methods, it’s difficult to know ‘why’ people make the decision that they made. To account for that lapse of data, you shouldn’t be afraid to club your A/B tests with their methods of data gathering, like surveys, etc to know why people made a certain decision.
Armed with that knowledge you’ll have a better picture of the problem.</p>

<h3 id="bias-in-the-data">Bias in the data</h3>
<ul>
  <li>It’s imperative that the data you have isn’t inherently biased. Either directly or indirectly.</li>
</ul>

<blockquote>
  <p>“Most statistics books assume that you are using good data, just as a cookbook assumes
that you are not buying rancid meat and rotten vegetables. But even the finest
recipe isn’t going to salvage a meal that begins with spoiled ingredients”</p>
</blockquote>

<p>I wrote a piece <a href="http://www.aanandshekharroy.com/articles/2020-09/hidden-bias-in-data">‘Garbage in, Garbage out: Hidden biases in data’</a> which goes in the detail of that issue.</p>

<hr>
<p>Resources:</p>

<p><a href="https://amzn.to/33ODbX7">Designing with Data: Improving the User Experience with A/B Testing</a></p>

<p><a href="https://amzn.to/2DE5tKJ">How to Lie with Statistics By D. Huff, I. Geis</a></p>

<p><a href="https://amzn.to/32872do">Naked Statistics: Stripping the Dread from the Data</a></p>

      <!-- <div class="center">
        <h4 >
          I am making a new course for you on Advanced Android Development and I’d love your input.
          Just click below to answer 5 very short questions. It only takes 1 minute.</h4>
          <div class="center">
            <a class="btn" href="https://goo.gl/forms/7sLk5CVAoYoP058u2">
              Click here
            </a>
          </div>
          <h4>  P.S. Check out the bonus question if you’d like an early access (It's already 25% complete!).
        </h4>
      </div> -->
      <!-- <iframe style="height:400px;width:100%;max-width:800px;margin:30px auto;" src="https://upscri.be/42a5c9?as_embed"></iframe> -->
      <!-- Begin Mailchimp Signup Form -->




<!--End mc_embed_signup-->
    </article>
  </div></div>]]>
            </description>
            <link>http://www.aanandshekharroy.com/articles/2020-09/intro-to-ab-tests</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624555</guid>
            <pubDate>Tue, 29 Sep 2020 06:00:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blur attacks bypass Bluetooth Classic and BLE security mechanisms CVE-2020-15802]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624206">thread link</a>) | @a5withtrrs
<br/>
September 28, 2020 | https://hexhive.epfl.ch/BLURtooth/ | <a href="https://web.archive.org/web/*/https://hexhive.epfl.ch/BLURtooth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      <h2 id="blur-attacks">BLUR attacks</h2>

<p>BLURtooth (the BLUR attacks) exploits the lack of cross-transport key
validation, allowing an attacker to bypass Bluetooth Classic and Bluetooth Low
Energy security mechanisms.</p>

<p>Bluetooth’s cross-transport key derivation (CTKD) is vulnerable to attacks
enabling to attack Bluetooth Classic from Bluetooth Low Energy and vice versa.
A remote attacker in Bluetooth range may impersonate, man-in-the-middle, and
establish malicious sessions with arbitrary devices.</p>

<ul>
  <li><strong><em>Security Impact:</em></strong> device impersonation, man-in-the-middle, malicious
session establishment with arbitrary devices</li>
  <li><strong><em>Affected Devices:</em></strong> the attack is standard compliant, so all BT/BLE
devices supporting CTKD are likely vulnerable; all our tested devices are
vulnerable</li>
  <li>BLURtooth is tracked under <a href="https://kb.cert.org/vuls/id/589825">CVE-2020-15802</a></li>
  <li><strong><em>Credit:</em></strong> Daniele Antonioli and Mathias Payer
from École Polytechnique Fédérale de Lausanne (EPFL),
Nils Ole Tippenhauer from Helmholtz Center for Information Security (CISPA),
and Kasper Rasmussen from University of Oxford.</li>
  <li><strong><em>Contacts at EPFL:</em></strong>
<a href="mailto:daniele.antonioli@epfl.ch,mathias.payer@nebelwelt.net">Daniele Antonioli and Mathias Payer</a></li>
</ul>

<h2 id="summary">Summary</h2>

<p>Here, we provide more details about a set of novel and standard-compliant
Bluetooth vulnerabilities affecting both Bluetooth Classic (BT) and Bluetooth
Low Energy (BLE).  The uncovered vulnerabilities affect a security mechanism
called cross-transport key derivation (CTKD). CTKD is used to improve the
usability of Bluetooth pairing by allowing to generate BT and BLE pairing keys
just by pairing two devices either on BT or BLE (rather than pairing them two
times).</p>

<p>However, we find that CTKD introduces cross-transport security issues and that
an attacker can abuse those issues to attack BT from BLE and vice versa.  In
particular, our attacks enable to impersonate, man-in-the-middle, and establish
malicious sessions with arbitrary devices by abusing CTKD, while defeating all
the security mechanisms put in place by BT and BLE.  Our work is named BLURtooth
and the related attacks are called BLUR attacks as they blur the security
boundary between BT and BLE.</p>

<p>The team behind this work consists of
<a href="https://francozappa.github.io/">Daniele Antonioli</a>
and
<a href="https://nebelwelt.net/">Mathias Payer</a>
from the <a href="https://hexhive.epfl.ch/">HexHive group</a> at
École Polytechnique Fédérale de Lausanne (EPFL),
<a href="https://tippenhauer.de/">Nils Ole Tippenhauer</a>
from Helmholtz Center for Information Security (CISPA), and
<a href="https://www.cs.ox.ac.uk/people/kasper.rasmussen/">Kasper Rasmussen</a>
from the University of Oxford.</p>

<p>In the remainder of this document, we provide information on
technical details, disclosure, impact, our proposed mitigation, the response
from the Bluetooth SIG.</p>

<h2 id="technical-details">Technical Details</h2>

<p>The Bluetooth standard includes two technologies <em>Bluetooth Classic (BT)</em> (also
known as Bluetooth BR/EDR) and <em>Bluetooth Low Energy (BLE)</em>. The majority of
mobile devices, including laptops, smartphones, tablets, headphones, and
smartwatches, support both and are defined as <em>dual-mode</em> Bluetooth devices. To
securely use dual-mode devices over BT and BLE a user has to pair her devices
two times, once for BT and once for BLE. As pairing the same device is
considered <em>user-unfriendly</em>, in 2014, with the release of Bluetooth version
4.2, the Bluetooth standard introduced a security mechanism that allows a user
to pair dual-mode Bluetooth devices once (either over BT or BLE) and then
securely use them both over BT and BLE. This security mechanism is called
<em>cross-transport key derivation (CTKD)</em>, and, as the name implies, it enables
deriving pairing keys across different transports (i.e.  derive a BT pairing key
from BLE and vice versa).</p>

<p>Despite being a security-critical mechanism, CTKD is not part of the Bluetooth
threat model and there are no security evaluations of CTKD. Those reasons
motivated us to perform a security analysis of CTKD, resulting in our findings.
In particular, CTKD is affected by 5 major issues (i.e.  vulnerabilities)
enabling an attacker to abuse Bluetooth roles, association, security modes,
keys, and pairing states across BT and BLE. Such issues derive from the <em>lack of
a cross-transport threat model</em> in the Bluetooth standard. The standard
considers BT and BLE with separate threat models and security architectures
while, through CTKD, opens avenues for cross-transport attacks (i.e., attacks
that exploit BT by taking advantage of a vulnerability in BLE or vice versa).</p>

<p>We demonstrate that the identified CTKD issues can be exploited by a remote
attacker in Bluetooth range with the victims. In particular, the attacker can
perform impersonation, man-in-the-middle, and malicious session establishment
attacks while bypassing all the security mechanisms provided by BT and BLE
(including Secure Connections or strong association).  Those are very serious
attacks that violate the security guarantees promised by Bluetooth.  We
confirmed the feasibility of our attacks by testing them on 13 common Bluetooth
devices using 10 unique Bluetooth chips. All of them were vulnerable.</p>

<p>You will find technical details about CTKD, our security analysis, a detailed
discussion of the threads, a discussion, and potential mitigations in our
<a href="https://arxiv.org/abs/2009.11776">BLURtooth preprint</a>.</p>

<h2 id="disclosure">Disclosure</h2>

<p>We discovered the vulnerability in March 2020 and responsibly disclosed our
findings along with suggested countermeasures to the Bluetooth SIG in May 2020.
We kept our findings private and the Bluetooth SIG publicly disclosed them,
without informing us, on the 10th of September of 2020.  Our work is assigned
<em><a href="https://kb.cert.org/vuls/id/589825">CVE-2020-15802</a></em>.</p>

<h2 id="impact">Impact</h2>

<p>The BLUR attacks are a <em>significant threat for all Bluetooth users and
the related vulnerabilities remain 0-days</em>. Our claim
is backed up by our experimental results where we successfully conducted
impersonation, man-in-the-middle, and malicious sessions establishment attacks
on 13 different devices. Our device sample include manufacturers such as
Dell, Google, Lenovo, Samsung, and Sony, operating systems, such as Windows
10, Linux, and Android, and Bluetooth chip manufacturers such as Cypress,
Qualcomm, Intel, Broadcom, and Cambridge Silicon Radio (CSR).</p>

<h2 id="our-mitigations">Our Mitigations</h2>

<p>As part of our disclosure, we provided <em>concrete fixes to combat the BLUR
attacks</em>. In particular, we recommended disabling the capability to overwrite
keys via CTKD in certain circumstances, enforce strong association and Secure
Connections and roles across BT and BLE, disable pairing over BT and/or BLE when
not needed, and add user notifications in case of odd behaviors. Our fixes can
be implemented at the standard level and do not require vendor-specific
features.</p>

<h2 id="response-from-the-bluetooth-sig">Response from the Bluetooth SIG</h2>

<p>At the time of writing, there are <em>no deployed patches</em> to address the BLUR
attacks on actual devices.  The Bluetooth SIG suggested that version 5.1 of the
standard will contain guidelines to mitigate the BLUR attacks (e.g., disable key
overwrites in certain circumstances as proposed in our countermeasures), but
such guidelines are not (yet) public and we cannot comment on them.  The
Bluetooth SIG provides a <a href="https://www.bluetooth.com/learn-about-bluetooth/bluetooth-technology/bluetooth-security/blurtooth/">public statement about BLURtooth and the BLUR
attacks</a>.</p>


      
    </div></div>]]>
            </description>
            <link>https://hexhive.epfl.ch/BLURtooth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624206</guid>
            <pubDate>Tue, 29 Sep 2020 04:43:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: GraphQL for Taskord is out now]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624057">thread link</a>) | @bigint
<br/>
September 28, 2020 | https://taskord.com/graphiql | <a href="https://web.archive.org/web/*/https://taskord.com/graphiql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://taskord.com/graphiql</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624057</guid>
            <pubDate>Tue, 29 Sep 2020 04:03:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XRHealth debuts new at-home VR therapy for ADHD]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624048">thread link</a>) | @vrfinal
<br/>
September 28, 2020 | https://www.vrfinal.com/xrhealth-debuts-new-at-home-vr-therapy-for-adhd/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/xrhealth-debuts-new-at-home-vr-therapy-for-adhd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <main>
            <article>
                            <p><time datetime="2020-09-28">
                  Sep 28, 2020
                </time>
                <span>1 min read</span>
              </p>
                <div>
    <p><a href="https://www.vrfinal.com/xrhealth-debuts-new-at-home-vr-therapy-for-adhd/">
        <img data-srcset="/content/images/size/w400/2020/09/XRHealth_1.png 400w, /content/images/size/w750/2020/09/XRHealth_1.png 750w, /content/images/size/w960/2020/09/XRHealth_1.png 960w" data-sizes="auto" alt="XRHealth debuts new at-home VR therapy for ADHD" srcset="https://www.vrfinal.com/content/images/size/w400/2020/09/XRHealth_1.png 400w, https://www.vrfinal.com/content/images/size/w750/2020/09/XRHealth_1.png 750w, https://www.vrfinal.com/content/images/size/w960/2020/09/XRHealth_1.png 960w">
      </a>
    </p>
  </div>
              <div>
                <div>
                  <p>XRHealth has developed a VR app for people suffering from ADHD. </p><p>ADHD affects millions of people; it causes issues around impulse control and attention. Medications are available to treat lack of focus, but concentration skills can also be instilled through personal instruction, this is what XRHealth’s new app aims to deal with.</p><p>The app was developed to improve the cognitive function of people with ADHD. It is based on the principle of “brain plasticity”, the ability of the brain to restructure itself in order to adapt to new environments and challenges.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/Ue3TgMKGq0E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>A new policy from the FDA allows US medical providers to prescribe VR therapy to patients during the Covid-19 pandemic, this is an attempt to modify the older in-person outpatient system. According to the<a href="https://www.xr.health/"> XRHealth website</a> they offer, <em>“The first-and-only VR treatment for children and adults with ADHD.”</em></p><p>The app works by presenting the patient with a visual, auditory, and physical experience similar to real life, the patient then works through several tasks and challenges designed to test and improve their cognitive functions. All of the data, eye movements and general performance, will be sent to the physician who prescribed the therapy, they can then adjust the difficulty and track daily improvements.</p><p>The XRHealth app is not meant to be a replacement for other treatments, instead, it is used to work with medications and in-person therapy. Due to the current pandemic, home solutions like the app are becoming more and more popular but they won’t replace traditional treatments.If you live in the US, you can apply for your insurance to cover the costs of their TeleHealth VR kit. The VR system provided is a heavily locked down version of the<a href="https://www.pico-interactive.com/us/neo2.html"> Pico Neo 2</a> but users who own the Oculus Quest or Oculus Go can install the app on their devices.</p>
                </div>
                  
                              </div>
            </article>
              <section>
    <p><img data-src="/content/images/size/w150/2020/09/IMG_20200812_155324.jpg" alt="Andrew Boggs" src="https://www.vrfinal.com/content/images/size/w150/2020/09/IMG_20200812_155324.jpg">
    </p>
    <div>
      
      <p>Andrew is a Northern Ireland based journalist with a passion for video games. His latest hobby is watching people speedrun Super Mario 64 and realising how bad he is at platformers.</p>
    </div>
  </section>
            <div>
      <div>
        <p><img data-srcset="/content/images/size/w400/2020/09/budget-1.jpg 400w, /content/images/size/w750/2020/09/budget-1.jpg 750w, /content/images/size/w960/2020/09/budget-1.jpg 960w" data-sizes="auto" alt="Budget Cuts FINALLY hits PSVR" srcset="https://www.vrfinal.com/content/images/size/w400/2020/09/budget-1.jpg 400w, https://www.vrfinal.com/content/images/size/w750/2020/09/budget-1.jpg 750w, https://www.vrfinal.com/content/images/size/w960/2020/09/budget-1.jpg 960w">
        <span>Previous Post</span></p><h4>Budget Cuts FINALLY hits PSVR</h4>
        </div>

    <div>
      <p><img data-srcset="/content/images/size/w400/2020/09/mortal-blitz3.jpg 400w, /content/images/size/w750/2020/09/mortal-blitz3.jpg 750w, /content/images/size/w960/2020/09/mortal-blitz3.jpg 960w" data-sizes="auto" alt="Mortal Blitz: Combat Arena gets PSVR Release Next Week" srcset="https://www.vrfinal.com/content/images/size/w400/2020/09/mortal-blitz3.jpg 400w, https://www.vrfinal.com/content/images/size/w750/2020/09/mortal-blitz3.jpg 750w, https://www.vrfinal.com/content/images/size/w960/2020/09/mortal-blitz3.jpg 960w">
      <span>Next Post</span></p><h4>Mortal Blitz: Combat Arena gets PSVR Release Next Week</h4>
      </div>
</div>            


        </main>
      </div>
    </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/xrhealth-debuts-new-at-home-vr-therapy-for-adhd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624048</guid>
            <pubDate>Tue, 29 Sep 2020 04:01:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Vision – Coalition for App Fairness]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624006">thread link</a>) | @tambourine_man
<br/>
September 28, 2020 | https://appfairness.org/our-vision/ | <a href="https://web.archive.org/web/*/https://appfairness.org/our-vision/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="primary"><main id="main"><article class="page" id="post-394" itemtype="https://schema.org/CreativeWork" itemscope="itemscope"><div itemprop="text"><div data-elementor-type="wp-page" data-elementor-id="394" data-elementor-settings="[]"><div><div><section data-id="e1785ac" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="29e5348" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="df3eaf0" data-element_type="column"><div><div><div data-id="9fdb9b1" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:300}" data-widget_type="text-editor.default"><div><p>The world’s most popular online platforms and the app stores that govern access to them have become a critical gateway to the consumers of digital products and services worldwide. While they can be beneficial when fairly operated, they can also be used by platform owners to hurt developers and consumers. As enforcers, regulators and legislators around the world seek to address these important issues, we, the Coalition for App Fairness, urge them to recognize that every app developer, regardless of size or the nature of the developer’s business, is entitled to fair treatment by these app stores and the platform owners who operate them, and should be afforded the following rights:</p></div></div></div></div></div></div></div></section><section data-id="e9c6c37" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;gradient&quot;,&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="537c477" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;animation&quot;:&quot;fadeInUp&quot;,&quot;animation_delay&quot;:300}"><div><div><section data-id="ec9b1aa" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="5b0d45c" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="a4f6862" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd3235671" data-id="info_box5f77cd3235671" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_1.png" alt="one"></p><div><p>No developer should be required to use an app store exclusively, or to use ancillary services of the app store owner, including payment systems, or to accept other supplementary obligations in order to have access to the app store.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="5eefa74" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="143ef27" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd3237f31" data-id="info_box5f77cd3237f31" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_2.png" alt="two"></p><div><p>No developer should be blocked from the platform or discriminated against based on a developer’s business model, how it delivers content and services, or whether it competes in any way with the app store owner.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="a36f301" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="c13739d" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="dd74397" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd323afa9" data-id="info_box5f77cd323afa9" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_3.png" alt="three"></p><div><p>Every developer should have timely access to the same interoperability interfaces and technical information as the app store owner makes available to its own developers.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="d7acc59" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="c8f0078" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd323d5f8" data-id="info_box5f77cd323d5f8" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_4.png" alt="four"></p><div><p>Every developer should always have access to app stores as long as its app meets fair, objective and nondiscriminatory standards for security, privacy, quality, content, and digital safety.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="c3f38e1" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="c29ef73" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="6d00f0d" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd324050a" data-id="info_box5f77cd324050a" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_5.png" alt="five"></p><div><p>A developer’s data should not be used to compete with the developer.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="7c1173a" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="aaac757" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd3242be9" data-id="info_box5f77cd3242be9" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_6.png" alt="six"></p><div><p>Every developer should always have the right to communicate directly with its users through its app for legitimate business purposes.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="00e085e" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="0931faa" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="be80356" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd3247203" data-id="info_box5f77cd3247203" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_7.png" alt="seven"></p><div><p>No app store owner or its platform should engage in self-preferencing its own apps or services, or interfere with users’ choice of preferences or defaults.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="c58956e" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="e726b73" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd3249987" data-id="info_box5f77cd3249987" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_8.png" alt="eight"></p><div><p>No developer should be required to pay unfair, unreasonable or discriminatory fees or revenue shares, nor be required to sell within its app anything it doesn’t wish to sell, as a condition to gain access to the app store.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="b79a45e" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="35127a4" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="669eafc" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd324c839" data-id="info_box5f77cd324c839" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_9.png" alt="nine"></p><div><p>No app store owner should prohibit third parties from offering competing app stores on the app store owner’s platform, or discourage developers or consumers from using them.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="e891f97" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="a8cb9a4" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f77cd324ef33" data-id="info_box5f77cd324ef33" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_10.png" alt="ten"></p><div><p>All app stores will be transparent about their rules and policies and opportunities for promotion and marketing, apply these consistently and objectively, provide notice of changes, and make available a quick, simple and fair process to resolve disputes.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section><section data-id="d605c57" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="1d8304b" data-element_type="column"><div><div><div data-id="15c3e7a" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:400}" data-widget_type="text-editor.default"><div><p>The Coalition for App Fairness was created by industry leading companies who want to see freedom of choice for consumers and a level playing field for businesses. This is an open call to all developers, big and small, to join us – and together we will fight back against the monopolist control of the app ecosystem by Apple.</p></div></div></div></div></div></div></div></section></div></div></div></div></article></main></div></div></div></div>]]>
            </description>
            <link>https://appfairness.org/our-vision/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624006</guid>
            <pubDate>Tue, 29 Sep 2020 03:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Possible reason for crashes of the Nvidia RTX 3080 and RTX 3090]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623963">thread link</a>) | @g42gregory
<br/>
September 28, 2020 | https://www.igorslab.de/en/what-real-what-can-be-investigative-within-the-crashes-and-instabilities-of-the-force-rtx-3080-andrtx-3090/ | <a href="https://web.archive.org/web/*/https://www.igorslab.de/en/what-real-what-can-be-investigative-within-the-crashes-and-instabilities-of-the-force-rtx-3080-andrtx-3090/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="post-149171"><div><div><div><div><div><p>Not only the editors and testers were surprised by sudden instabilities of the new GeForce RTX 3080 and RTX 3090, but also the first customers who were able to get board partner cards from the first wave. An interesting pattern of behavior emerged that did not affect all cards or manufacturers and the problems only occurred at certain boost clock rates above or just around 2 GHz. To make matters worse, NVIDIA has obviously also slightly undermined the quality management of the board partners (AIC) due to the secrecy – unconsciously, of course, but with plausible consequences. A chain of adverse circumstances? This could well be the case, because this explains the somewhat diffuse error pattern from the most diverse forums.</p><h3><span><strong>Start of production without real function control?</strong></span></h3><p>Let’s start with the latter, before I get lost in the technical analyses. You probably remember when I wrote that the board partners couldn’t use working drivers yet and only work with a very limited driver and NVPunish. Since the driver problem lasted until shortly before the launch, but the first wave of cards had to be produced already, the functional testing of the first models was obviously limited to power-on and thermal stability. Running, not running. However, this does not say much about the chip quality and the possible maximum frequencies that the respective chip can safely handle.</p><p>Thus, it would at least be plausible that cards could have been sold as OC cards, which wouldn’t have passed a real quality test at the manufacturer with the delivered settings. Real binning? Nothing. Subsequent selection of particularly overclocked cards? Impossible, in fact. And so it is by no means impossible that one or the other “Potato” chip could also have gotten lost on such an OC card. We know the consequences from the posts of the buyers in the relevant forums.</p><h3><span><strong>Wrong component selection? Plausible!</strong></span></h3><p>Now let’s come to the fact that even good chips have dropped out now and then. That they are good, you can see for yourself e.g. by the boost cycle and the temperatures. So it is quite easy to find out with a selected card. This brings us now to a point that I was actually very unconsciously haunting the back of my mind at first, and which then solidified into a realization when comparing the boards of different models So let’s go directly to the “reference board” PG132, which can also be understood as a so-called Base Design. Especially the backside and especially the area below the BGA is interesting. What is interesting about such drawings and the so-called BoM (Bill of Materials) is that you are offered different placement alternatives.</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC.jpg" alt="" width="980" height="765" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC-300x234.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC-768x600.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>I will (have to) simplify the following for better understanding. Below the BGA we see the six NECESSARY capacitors for filtering high frequencies on the voltage rails, i.e. NVVDD and MSVDD. Apart from the fact that there is still enough high-frequency “garbage” from the voltage converters, it is mainly the so-called GPU load including all jumps caused by boost, which leads to very broadband frequency mixtures, which become more extreme the higher the boost clock goes. The BoM and the drawing from June leave it open whether large-area POSCAPs (Conductive Polymer Tantalum Solid Capacitors) are used (marked in red), or rather the somewhat more expensive MLCCs (Multilayer Ceramic Chip Capacitor). The latter are smaller and have to be grouped for a higher capacity.</p><p>According to the list and specifications of Nvidia, both are possible. In terms of quality, however, good MLCCs are better able to filter the very high frequency components in particular. In the end, this is simple practical knowledge, which only often enough collides with the world view of a financial controller.&nbsp; If one searches the forums, it seems that the Zotac Trinity is particularly affected when it comes to instabilities starting at certain boost clock rates from around 2010 MHz. A feat, because Zotac is relying on a total of six cheaper POSCAPs.</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity.jpg" alt="" width="980" height="390" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity-300x119.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity-768x306.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>And what does NVIDIA do with its own Founders Editions? One does it obviously better, because I could not reproduce these stability problems with any FE even very clearly beyond 2 GHz (fan to 100%). If something went wrong, it was almost certainly a driver problem. If we take a look at the FE, we see only four SP-CAPs (red) and in the middle two MLCC groups of 10 individual capacitors each (green). This is definitely the better solution and the optimal compromise. because especially the middle areas should best be provided with suitable filters (short circuit of the high-frequency frequency mixtures).</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1.jpg" alt="" width="980" height="406" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1-300x124.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1-768x318.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>If it is only about NVVDD, a single MLCC block may be sufficient to solve the most serious problems. For example, MSI uses only one on the Gaming X Trio, which is theoretically enough, but could have been better solved if, for example, the 2.1 GHz were to be used with water. Whether this is still enough would of course have to be tested. PC Partner, Zotac’s mother company, seems to have recognised this and is obviously changing its cards. By the way, the following example is from a soldering experiment that was NOT made by Zotac, but which confirmed the effectiveness of MLCC smoothing very impressively. One can almost be envious of these soldering skills.</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC.jpg" alt="" width="980" height="497" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC-300x152.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC-768x389.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>By the way, you also have to praise a company here that recognized the whole thing from the start and didn’t even let it touch them, as the Asus TUF RTX 3080 Gaming consequently did without POSCAPs and only used MLCC groups. My compliments, it fits!</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1.jpg" alt="" width="980" height="439" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1-300x134.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1-768x344.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>Interestingly, all board partners are silent on this issue, no matter who you ask. No answer is also an answer, because this behaviour is the absolute exception and almost resembles a muzzle decree. This is because components are normally spoken freely when the launch has already taken place. But here comes nothing but meaningful silence. This also applies to the question of whether the BoM was subsequently changed again to completely exclude the exclusive use of POSCAPs/SP-CAPs.</p><p>Sometimes things are so obvious that you really have to look several times to see them. But once you have understood it, many things suddenly go from nebulous to plausible. NVIDIA, by the way, cannot be blamed directly, because the fact that MLCCs work better than POSCAPs is something that any board designer who hasn’t taken the wrong profession knows. Such a thing can even be simulated if necessary. I will of course stay on it, because my interest is naturally aroused.</p><p>Please read also the latest follow up to that sory:</p><h2><a href="https://www.igorslab.de/en/nvidia-geforce-rtx-3080-und-rtx-3090-and-the-crash-why-the-capacitors-are-so-important-and-what-are-the-object-behind/" target="_blank" rel="noopener noreferrer">NVIDIA GeForce RTX 3080 and RTX 3090 and the crashes – Why capacitors are so important and what’s behind them</a></h2><p><iframe title="Aufgedeckt: Gründe, warum eine NVIDIA GeForce RTX 3080 oder RTX 3090 oberhalb 2 GHz crashen könnten!" width="1320" height="743" src="https://www.youtube.com/embed/7YQ7rNgoqMA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p> </div></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.igorslab.de/en/what-real-what-can-be-investigative-within-the-crashes-and-instabilities-of-the-force-rtx-3080-andrtx-3090/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623963</guid>
            <pubDate>Tue, 29 Sep 2020 03:38:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[City of Amsterdam’s Algorithm Register]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24623639">thread link</a>) | @cpeterso
<br/>
September 28, 2020 | https://algoritmeregister.amsterdam.nl/en/ai-register/ | <a href="https://web.archive.org/web/*/https://algoritmeregister.amsterdam.nl/en/ai-register/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-pm="normal" data-desktopportraitmargin="5|*|0|*|65|*|0|*|px+" data-tabletportraitmargin="0|*|0|*|0|*|0|*|px+" data-mobileportraitmargin="-20|*|0|*|0|*|0|*|px+" data-desktopportraitheight="0" data-has-maxwidth="1" data-desktopportraitmaxwidth="520" data-tabletportraitmaxwidth="430" data-mobileportraitmaxwidth="295" data-cssselfalign="inherit" data-desktopportraitselfalign="inherit" data-sstype="layer" data-rotation="0" data-desktopportrait="1" data-desktoplandscape="1" data-tabletportrait="1" data-tabletlandscape="1" data-mobileportrait="1" data-mobilelandscape="1" data-adaptivefont="0" data-desktopportraitfontsize="100" data-tabletportraitfontsize="90" data-mobileportraitfontsize="120" data-plugin="rendered"><div><p><br>The Algorithm Register is an overview of the artificial intelligence systems and algorithms used by the City of Amsterdam. Through the register, you can get acquainted with the quick overviews of the city's algorithmic systems or examine their more detailed information based on your own interests. You can also give feedback and thus participate in building human-centered algorithms in Amsterdam. The register is still under development.</p></div></div></div>]]>
            </description>
            <link>https://algoritmeregister.amsterdam.nl/en/ai-register/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623639</guid>
            <pubDate>Tue, 29 Sep 2020 02:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keeping Large Mammals in Zoos and Aquariums Damages Their Brains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623399">thread link</a>) | @laurex
<br/>
September 28, 2020 | https://science.thewire.in/environment/mammals-captivity-zoos-aquariums-brain-damage/ | <a href="https://web.archive.org/web/*/https://science.thewire.in/environment/mammals-captivity-zoos-aquariums-brain-damage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
										                <p><em>Featured image: Lolita the Killer Whale is fed a fish by a trainer during a show at the Miami Seaquarium in Miami January 21, 2015. Photo: Reuters/Andrew Innerarity</em></p>
<p><a href="http://elephantsinjapan.com/worlds-loneliest-elephant-hanako/">Hanako</a>, a female Asian elephant, lived in a tiny concrete enclosure at Japan’s Inokashira Park Zoo for more than 60 years, often in chains, with no stimulation. In the wild, <a href="https://www.elephantvoices.org/elephant-sense-a-sociality-4/elephants-are-socially-complex.html">elephants live in herds</a>, with close family ties. Hanako was solitary for the last decade of her life.</p>
<p><a href="https://whalesanctuaryproject.org/whales/kiska-alone-again/">Kiska</a>, a young female orca, was captured in 1978 off the Iceland coast and taken to Marineland Canada, an aquarium and amusement park. Orcas are social animals that live in family <a href="https://www.nationalgeographic.com/animals/mammals/o/orca/">pods</a> with up to 40 members, but Kiska has lived alone in a small tank since 2011. Each of her five calves died. To combat stress and boredom, she swims in slow, endless circles and has gnawed her teeth to the pulp on her concrete pool.</p>


<p>Unfortunately, these are common conditions for many large, captive mammals in the “entertainment” industry. In decades of <a href="https://scholar.google.com/citations?user=KvCW9T0AAAAJ&amp;hl=en">studying the brains of humans, African elephants, humpback whales and other large mammals</a>, I’ve noted the organ’s great sensitivity to the environment, including serious impacts on its structure and function from living in captivity.</p>
<figure>
<figure><a href="https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img data-src="https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" data-sizes="auto" data-srcset="https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=560&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=560&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=560&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=704&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=704&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=704&amp;fit=crop&amp;dpr=3 2262w" alt="" width="600" height="560" src="https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>Hanako, an Asian elephant kept at Japan’s Inokashira Park Zoo; and Kiska, an orca that lives at Marineland Canada. One image depicts Kiska’s damaged teeth. Elephants in Japan (left image), Ontario Captive Animal Watch (right image), CC BY-ND</figcaption></figure></figure>
<p><strong>Affecting health and altering behaviour</strong></p>
<p>It is easy to observe the overall health and psychological consequences of life in captivity for these animals. Many captive elephants suffer from arthritis, obesity or skin problems. Both <a href="https://doi.org/10.11609/JoTT.o2620.1826-36">elephants</a> and orcas often have severe dental problems. Captive orcas are plagued by <a href="https://doi.org/10.1016/j.jveb.2019.05.005">pneumonia, kidney disease, gastrointestinal illnesses and infections</a>.</p>
<p>Many animals <a href="https://doi.org/10.1016/j.neubiorev.2017.09.010">try to cope</a> with captivity by adopting abnormal behaviors. Some develop “<a href="https://doi.org/10.1016/j.applanim.2017.05.003">stereotypies</a>,” which are repetitive, purposeless habits such as constantly bobbing their heads, swaying incessantly or chewing on the bars of their cages. Others, especially big cats, pace their enclosures. Elephants rub or break their tusks.</p>
<p><ins>Also read: <a href="https://science.thewire.in/environment/lockdown-elephants-starvation/">As Captive Elephants Starve, Lockdown Brings a Problem Practice to the Fore</a></ins></p>
<p><strong>Changing brain structure</strong></p>
<p>Neuroscientific research indicates that living in an impoverished, stressful captive environment <a href="https://doi.org/10.1016/j.jveb.2019.05.005">physically damages the brain</a>. These changes have been documented in many <a href="https://doi.org/10.1002/cne.903270108">species</a>, including rodents, rabbits, cats and <a href="https://doi.org/10.1006/nimg.2001.0917">humans</a>.</p>
<p>Although researchers have directly studied some animal brains, most of what we know comes from observing animal behavior, analyzing stress hormone levels in the blood and applying knowledge gained from a half-century of neuroscience research. Laboratory research also suggests that mammals in a zoo or aquarium have compromised brain function.</p>
<figure>
<figure><a href="https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img data-src="https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" data-sizes="auto" data-srcset="https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=803&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=803&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=803&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=1008&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=1008&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=1008&amp;fit=crop&amp;dpr=3 2262w" alt="" width="600" height="803" src="https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>This illustration shows differences in the brain’s cerebral cortex in animals held in impoverished (captive) and enriched (natural) environments. Impoverishment results in thinning of the cortex, a decreased blood supply, less support for neurons and decreased connectivity among neurons. Photo: Arnold B. Scheibel, CC BY-ND</figcaption></figure></figure>
<p>Subsisting in confined, barren quarters that lack intellectual stimulation or appropriate social contact seems to <a href="https://doi.org/10.1590/S0001-37652001000200006">thin the cerebral cortex</a> – the part of the brain involved in voluntary movement and higher cognitive function, including memory, planning and decision-making.</p>
<p>There are other consequences. Capillaries shrink, depriving the brain of the oxygen-rich blood it needs to survive. Neurons become smaller, and their dendrites – the branches that form connections with other neurons – become less complex, impairing communication within the brain. As a result, the cortical neurons in captive animals <a href="https://doi.org/10.1002/cne.901230110">process information less efficiently</a> than those living in <a href="https://doi.org/10.1002/dev.420020208">enriched, more natural environments</a>.</p>
<figure>
<figure><a href="https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img data-src="https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" data-sizes="auto" data-srcset="https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=398&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=398&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=398&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=500&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=500&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=500&amp;fit=crop&amp;dpr=3 2262w" alt="" width="600" height="398" src="https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>An actual cortical neuron in a wild African elephant living in its natural habitat compared with a hypothesized cortical neuron from a captive elephant. Photo: Bob Jacobs, CC BY-ND</figcaption></figure></figure>
<p>Brain health is also affected by living in small quarters that <a href="https://doi.org/10.3233/BPL-160040">don’t allow for needed exercise</a>. Physical activity increases the flow of blood to the brain, which requires large amounts of oxygen. Exercise increases the production of new connections and <a href="http://dx.doi.org/10.1126/science.aaw2622">enhances cognitive abilities</a>.</p>
<p>In their native habits these animals must move to survive, covering great distances to forage or find a mate. Elephants<br>
typically travel anywhere from <a href="https://www.elephantsforafrica.org/elephant-facts/#:%7E:text=How%20far%20do%20elephants%20walk,km%20on%20a%20daily%20basis.">15 to 120 miles per day</a>. In a zoo, they average <a href="https://doi.org/10.1371/journal.pone.0150331">three miles daily</a>, often walking back and forth in small enclosures. One free orca studied in Canada swam <a href="https://doi.org/10.1007/s00300-010-0958-x">up to 156 miles a day</a>; meanwhile, an average orca tank is about 10,000 times smaller than its <a href="https://www.cascadiaresearch.org/projects/killer-whales/using-dtags-study-acoustics-and-behavior-southern">natural home range</a>.</p>
<p><ins>Also read: <a href="https://science.thewire.in/the-sciences/animal-culture-meme-social-learning/">The Complex Social Lives of Animals</a></ins></p>
<p><strong>Disrupting brain chemistry and killing cells</strong></p>
<p>Living in enclosures that restrict or prevent normal behavior creates chronic frustration and boredom. In the wild, an animal’s stress-response system helps it escape from danger. But captivity traps animals with <a href="https://doi.org/10.1073/pnas.1215502109">almost no control</a> over their environment.</p>
<p>These situations foster <a href="https://doi.org/10.1037/rev0000033">learned helplessness</a>, negatively impacting the <a href="https://doi.org/10.1155/2016/6391686">hippocampus</a>, which handles memory functions, and the <a href="https://doi.org/10.1016/j.neuropharm.2011.02.024">amygdala</a>, which processes emotions. Prolonged stress <a href="https://doi.org/10.3109/10253899609001092">elevates stress hormones</a> and <a href="https://doi.org/10.1523/JNEUROSCI.10-09-02897.1990">damages or even kills neurons</a> in both brain regions. It also disrupts the <a href="https://doi.org/10.1016/j.neubiorev.2005.03.021">delicate balance of serotonin</a>, a neurotransmitter that stabilizes mood, among other functions.</p>
<p>In humans, <a href="https://doi.org/10.1006/nimg.2001.0917">deprivation</a> can trigger <a href="https://doi.org/10.3389/fnins.2018.00367">psychiatric issues</a>, including depression, anxiety, <a href="https://doi.org/10.3389/fnins.2018.00367">mood disorders</a> or <a href="https://doi.org/10.1177/1073858409333072">post-traumatic stress disorder</a>. <a href="https://doi.org/10.1007/s00429-010-0288-3">Elephants</a>, <a href="https://doi.org/10.1371/journal.pbio.0050139">orcas</a> and other animals with large brains are likely to react in similar ways to life in a severely stressful environment.</p>
<p><strong>Damaged wiring</strong></p>
<p>Captivity can damage the brain’s complex circuitry, including the basal ganglia. This group of neurons communicates with the cerebral cortex along two networks: a direct pathway that enhances movement and behavior, and an indirect pathway that inhibits them.</p>
<p>The repetitive, <a href="http://dx.doi.org/10.1016/j.bbr.2014.05.057">stereotypic behaviors</a> that many animals adopt in captivity are caused by an imbalance of two neurotransmitters, dopamine and <a href="https://doi.org/10.1016/j.neubiorev.2010.02.004">serotonin</a>. This impairs the indirect pathway’s ability to modulate movement, a condition documented in species from chickens, cows, sheep and horses to primates and big cats.</p>
<figure>
<figure><a href="https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img data-src="https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" data-sizes="auto" data-srcset="https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=375&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=375&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=375&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=471&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=471&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=471&amp;fit=crop&amp;dpr=3 2262w" alt="Image of brain showing areas affected by captivity" width="600" height="375" src="https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>The cerebral cortex, hippocampus and amygdala are physically altered by captivity, along with brain circuitry that involves the basal ganglia. PHoto: Bob Jacobs, CC BY-ND</figcaption></figure></figure>
<p>Evolution has constructed animal brains to be exquisitely responsive to their environment. Those reactions can affect neural function by <a href="https://www.penguinrandomhouse.com/books/311787/behave-by-robert-m-sapolsky/">turning different genes on or off</a>. Living in inappropriate or abusive circumstance alters biochemical processes: It disrupts the synthesis of proteins that build connections between brain cells and the neurotransmitters that facilitate communication among them.</p>
<p>There is strong evidence that <a href="https://doi.org/10.1523/JNEUROSCI.0577-11.2011">enrichment</a>, social contact and appropriate space in more natural habitats are <a href="https://doi.org/10.1111/j.1748-1090.2003.tb02071.x">necessary</a> for long-lived animals with large brains such as <a href="https://doi.org/10.1371/journal.pone.0152490">elephants</a> and <a href="https://doi.org/10.1080/13880292.2017.1309858">cetaceans</a>. Better conditions <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543669/">reduce disturbing sterotypical behaviors</a>, improve connections in the brain, and <a href="https://doi.org/10.1038/cdd.2009.193">trigger neurochemical changes</a> that enhance learning and memory.</p>
<p><ins>Also read:&nbsp;<a href="https://thewire.in/environment/elephants-bengal-deaths-kerala-drought">Giving Elephants the Space They Need, One SMS at a Time</a></ins></p>
<p><strong>The captivity question</strong></p>
<p>Some people defend keeping animals in captivity, arguing that it helps conserve endangered species or offers educational benefits for <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.574.3479&amp;rep=rep1&amp;type=pdf">visitors to zoos and aquariums</a>. These justifications are questionable, particularly for <a href="https://animalstudiesrepository.org/acwp_zoae/8/">large mammals</a>. As my own research and work by many other scientists shows, caging large mammals and putting them on display is undeniably cruel from a neural perspective. It causes brain damage.</p>
<p>Public perceptions of captivity are slowly changing, as shown by the reaction to the documentary <em><a href="https://en.wikipedia.org/wiki/Blackfish_(film)">Blackfish</a></em>. For animals that cannot be free, there are well-designed sanctuaries. Several already exist for elephants and other large mammals in <a href="https://www.elephants.com/">Tennessee</a>, <a href="https://globalelephants.org/overview/">Brazil</a> and Northern <a href="http://www.pawsweb.org/about_our_sanctuaries.html">California</a>. Others are being developed for large <a href="https://whalesanctuaryproject.org/">cetaceans</a>.</p>
<p>Perhaps it is not too late for Kiska.</p>
<p><em>Dr. Lori Marino, president of the Whale Sanctuary Project and a former senior lecturer at Emory University, contributed to this article.<br>
</em><!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. --><img src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-src="https://counter.theconversation.com/content/142240/count.gif?distributor=republish-lightbox-basic" alt="The Conversation" width="1" height="1"><!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines --><br>
<em>Bob Jacobs is a Professor of Neuroscience at Colorado College</em></p>
<p><em>This article is republished from </em><a href="https://theconversation.com/">The Conversation</a><em> under a Creative Commons license. Read the <a href="https://theconversation.com/the-neural-cruelty-of-captivity-keeping-large-mammals-in-zoos-and-aquariums-damages-their-brains-142240">original article</a>.</em></p>

<!-- AI CONTENT END 1 -->
																												              </div></div>]]>
            </description>
            <link>https://science.thewire.in/environment/mammals-captivity-zoos-aquariums-brain-damage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623399</guid>
            <pubDate>Tue, 29 Sep 2020 01:48:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using machine learning to create images to match Sufjan Stevens lyrics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623366">thread link</a>) | @no_bear_so_low
<br/>
September 28, 2020 | https://deponysum.com/2020/09/26/artificial-intelligence-dreams-images-to-accompany-sufjan-stevens-lyrics/ | <a href="https://web.archive.org/web/*/https://deponysum.com/2020/09/26/artificial-intelligence-dreams-images-to-accompany-sufjan-stevens-lyrics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><header id="masthead" role="banner">
		<div>
							<p><a href="https://deponysum.com/" rel="home">DePonySum</a></p>
							<p>Immanentize the eschaton but carefully. Check out our Twitter @sumdepony, and our subreddit at r/deponysum</p>
					</div>

		<nav id="site-navigation" role="navigation">
			
			<div><ul id="menu-primary"><li id="menu-item-6"><a href="https://deponysum.com/">Home</a></li>
<li id="menu-item-7"><a href="https://deponysum.com/contact/">Contact</a></li>
</ul></div>		</nav><!-- #site-navigation -->
	</header><!-- #masthead -->

	<div id="content">
		
	<div id="primary">
		<main id="main" role="main">

		
			
<article id="post-2524">
	<header>
				
		<div>
			<p><span><a href="https://deponysum.com/2020/09/26/artificial-intelligence-dreams-images-to-accompany-sufjan-stevens-lyrics/" rel="bookmark"><time datetime="2020-09-26T23:54:48+01:00">26th Sep 2020</time><time datetime="2020-09-27T03:38:36+01:00">27th Sep 2020</time></a></span><span><span><span> ~ </span><a href="https://deponysum.com/author/deponysum/">deponysum</a></span></span>					</p></div><!-- .entry-meta -->
	</header><!-- .entry-header -->

	<div>
		
<p>Continuing this blog’s project of creating Sufjan themed art using AI I’ve automatically generated a collection of images to accompany Sufjan lyrics. Using this <a href="https://vision-explorer.allenai.org/text_to_image_generation" rel="nofollow">https://vision-explorer.allenai.org/text_to_image_generation</a> I gave a computer program hundreds of Sufjan Steven lyrics and picked the best results.</p>



<figure><img data-attachment-id="2526" data-permalink="https://deponysum.com/i-was-dressed-in-white/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="i-was-dressed-in-white" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png 400w, https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>I was dressed in white</strong></figcaption></figure>



<figure><img data-attachment-id="2543" data-permalink="https://deponysum.com/you-stare-at-the-sun-to-see-the-sublime/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="you-stare-at-the-sun-to-see-the-sublime" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png 400w, https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>You stare at the sun to see the sublime</strong></figcaption></figure>



<figure><img data-attachment-id="2552" data-permalink="https://deponysum.com/the-lion-and-the-lamb-were-restored/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the-lion-and-the-lamb-were-restored" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png 400w, https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>The lion and the lamb were restored</strong></figcaption></figure>



<figure><img data-attachment-id="2527" data-permalink="https://deponysum.com/his-father-was-a-drinker/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="his-father-was-a-drinker" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png 400w, https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>His father was a drinker</strong></figcaption></figure>



<figure><img data-attachment-id="2529" data-permalink="https://deponysum.com/in-the-tower-above-the-earth/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="in-the-tower-above-the-earth" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png 400w, https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>In the tower above the earth</strong></figcaption></figure>



<figure><img data-attachment-id="2530" data-permalink="https://deponysum.com/all-things-grow/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="all-things-grow" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png 400w, https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>All things grow</strong></figcaption></figure>



<figure><img data-attachment-id="2532" data-permalink="https://deponysum.com/ill-find-sleep-ill-find-peace/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ill-find-sleep-ill-find-peace" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png 400w, https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>I’ll find sleep, I’ll find peace</strong></figcaption></figure>



<figure><img data-attachment-id="2534" data-permalink="https://deponysum.com/its-your-own-damn-head-on-that-plate/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="its-your-own-damn-head-on-that-plate" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png 400w, https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>It’s your own damn head on that plate</strong></figcaption></figure>



<figure><img data-attachment-id="2535" data-permalink="https://deponysum.com/justice-delivers-its-death/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="justice-delivers-its-death" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png 400w, https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>Justice delivers its death</strong></figcaption></figure>



<figure><img data-attachment-id="2537" data-permalink="https://deponysum.com/blackbird-on-my-shoulder/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blackbird-on-my-shoulder" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png 400w, https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>Blackbird on my shoulder</strong></figcaption></figure>



<figure><img data-attachment-id="2540" data-permalink="https://deponysum.com/i-built-your-walls-around-me/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="i-built-your-walls-around-me" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png 400w, https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>I built your walls around me</strong></figcaption></figure>



<figure><img data-attachment-id="2541" data-permalink="https://deponysum.com/all-of-me-wants-all-of-you/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="all-of-me-wants-all-of-you" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png 400w, https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>All of me wants all of you</strong></figcaption></figure>



<figure><img data-attachment-id="2547" data-permalink="https://deponysum.com/signs-and-wonders/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="signs-and-wonders" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png 400w, https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>Signs and wonders</strong></figcaption></figure>



<figure><img data-attachment-id="2549" data-permalink="https://deponysum.com/my-friend-ran-away/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="my-friend-ran-away" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png 400w, https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>My friend is gone, he ran away</strong></figcaption></figure>



<figure><img data-attachment-id="2555" data-permalink="https://deponysum.com/we-were-ashamed-of-her/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="we-were-ashamed-of-her" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png 400w, https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>We were ashamed of her</strong></figcaption></figure>



<figure><img data-attachment-id="2556" data-permalink="https://deponysum.com/were-all-going-to-die/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="were-all-going-to-die" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png 400w, https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>We’re all going to die</strong></figcaption></figure>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

		<div>
				<p><img alt="" src="https://2.gravatar.com/avatar/844c2b3fe77c2f3e30212fe26c1c30f2?s=60&amp;d=identicon&amp;r=G" height="60" width="60">		</p><!-- .author-avatar -->
		
		<p>
			<h2>Published by <span>deponysum</span></h2>
		</p><!-- .author-heading -->

		<p>
						<a href="https://deponysum.com/author/deponysum/" rel="author">
				View all posts by deponysum			</a>
		</p><!-- .author-bio -->
	</div><!-- .entry-auhtor -->
</article><!-- #post-## -->

			
	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		<div><div><p><a href="https://deponysum.com/2020/09/25/should-you-vote/" rel="prev"><span>‹ Previous</span>Should you vote?</a></p></div><div><p><a href="https://deponysum.com/2020/09/29/in-a-shocking-twist-reddit-protects-a-structurally-racist-judicial-system-from-criticism/" rel="next"><span>Next ›</span>In a shocking twist, Reddit protects a structurally racist judicial system from&nbsp;criticism</a></p></div></div>
	</nav>
			
<div id="comments">

	
	
	
		<div id="respond">
		<h3 id="reply-title">Leave a Reply <small></small></h3><form action="https://deponysum.com/wp-comments-post.php" method="post" id="commentform" novalidate="">


<div>
	<p><label for="comment">Enter your comment here...</label></p>
</div>

<div id="comment-form-identity">
	<div id="comment-form-nascar">
		<p>Fill in your details below or click an icon to log in:</p>
		<ul>
			
			<li>
				<a href="#comment-form-load-service:WordPress.com" id="postas-wordpress" title="Login via WordPress.com">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"></path></g></svg>				</a>
			</li>
			<li>
				<a href="#comment-form-load-service:Twitter" id="postas-twitter" title="Login via Twitter">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"></path></g></svg>				</a>
			</li>
			<li>
				<a href="#comment-form-load-service:Facebook" id="postas-facebook" title="Login via Facebook">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"></path></g></svg>				</a>
			</li>
		</ul>
	</div>

	<div id="comment-form-guest">
		<div>
			<p><a href="https://gravatar.com/site/signup/" target="_blank">				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Gravatar" width="25">
</a>			</p>

				<div>
				<div>
					<p><label for="email">Email <span>(required)</span> <span>(Address never made public)</span></label></p>
				</div>
				<div>
					<p><label for="author">Name <span>(required)</span></label></p>
				</div>
				<div>
					<p><label for="url">Website</label></p>
				</div>
			</div>
			
		</div>
	</div>

	<div id="comment-form-wordpress">
		<div>
			<p><img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="WordPress.com Logo" width="25">
			</p>

				<div>
				<p>
			<strong></strong>
			You are commenting using your WordPress.com account.			<span>
				(&nbsp;Log&nbsp;Out&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-googleplus">
		<div>
			<p><img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Google photo" width="25">
			</p>

				<div>
				<p>
			<strong></strong>
			You are commenting using your Google account.			<span>
				(&nbsp;Log&nbsp;Out&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span><svg xmlns="http://www.w3.org/2000/svg" role="presentation" x="0px" y="0px" viewBox="0 0 60 60"><path fill="#519bf7" d="M56.3,30c0,-1.6 -0.2,-3.4 -0.6,-5h-3.1H42.2H30v10.6h14.8C44,39.3 42,42 39.1,43.9l8.8,6.8C53,46 56.3,39 56.3,30z"></path><path fill="#3db366" d="M30,57.5c6.7,0 13.1,-2.4 17.9,-6.8l-8.8,-6.8c-2.5,1.6 -5.6,2.4 -9.1,2.4c-7.2,0 -13.3,-4.7 -15.4,-11.2l-9.3,7.1C9.8,51.3 19.1,57.5 30,57.5z"></path><path fill="#fdc600" d="M5.3,42.2l9.3,-7.1c-0.5,-1.6 -0.8,-3.3 -0.8,-5.1s0.3,-3.5 0.8,-5.1l-9.3,-7.1C3.5,21.5 2.5,25.6 2.5,30S3.5,38.5 5.3,42.2z"></path><path fill="#f15b44" d="M40.1,17.4l8,-8C43.3,5.1 37,2.5 30,2.5C19.1,2.5 9.8,8.7 5.3,17.8l9.3,7.1c2.1,-6.5 8.2,-11.1 15.4,-11.1C33.9,13.7 37.4,15.1 40.1,17.4z"></path></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-twitter">
		<div>
			<p><img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Twitter picture" width="25">
			</p>

				<div>
				<p>
			<strong></strong>
			You are commenting using your Twitter account.			<span>
				(&nbsp;Log&nbsp;Out&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-facebook">
		<div>
			<p><img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Facebook photo" width="25">
			</p>

				<div>
				<p>
			<strong></strong>
			You are commenting using your Facebook account.			<span>
				(&nbsp;Log&nbsp;Out&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>


	<div id="comment-form-load-service">
		<div><p>Cancel</p></div>
		<p>Connecting to %s</p>
	</div>

</div>



<div id="comment-form-subscribe">
	<p> <label id="subscribe-label" for="subscribe">Notify me of new comments via email.</label></p><p> <label id="subscribe-blog-label" for="subscribe_blog">Notify me of new posts via email.</label></p></div>






</form>	</div><!-- #respond -->
	
</div><!-- #comments -->

		
		</main><!-- #main -->
	</div><!-- #primary -->

	<div id="secondary" role="complementary">
			</div><!-- #secondary -->

	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://deponysum.com/2020/09/26/artificial-intelligence-dreams-images-to-accompany-sufjan-stevens-lyrics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623366</guid>
            <pubDate>Tue, 29 Sep 2020 01:42:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CMake: Public vs Private vs Interface]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623282">thread link</a>) | @keyboardman
<br/>
September 28, 2020 | https://leimao.github.io/blog/CMake-Public-Private-Interface/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/CMake-Public-Private-Interface/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>CMake is one of the most convenient building tools for C/C++ projects. When it comes to <a href="https://cmake.org/cmake/help/latest/command/target_include_directories.html"><code>target_include_directories</code></a> and <a href="https://cmake.org/cmake/help/latest/command/target_link_libraries.html"><code>target_link_libraries</code></a>, there are several keywords, <code>PUBLIC</code>, <code>PRIVATE</code>, and <code>INTERFACE</code>, that I got confused about from time to time even if I have read the related official documentations. So When I was building my C/C++ projects using CMake, I often just use <code>PUBLIC</code> everywhere or leave the keyword blank (CMake will then use <code>PUBLIC</code> by default), the libraries and executables built from the projects would work in most of the scenarios. However, it is certainly not best practice.</p>



<p>Today, I read Kuba Sejdak’s blog post <a href="https://kubasejdak.com/modern-cmake-is-like-inheritance">“Modern CMake is Like Inheritance”</a> and I found his interpretation on the CMake keywords <code>PUBLIC</code>, <code>PRIVATE</code>, and <code>INTERFACE</code> inspiring. So in this blog post, I would like to discuss some of my thoughts on these CMake keywords from the perspective of “inheritance”.</p>

<h3 id="c-inheritance">C++ Inheritance</h3>

<h4 id="access-specifiers">Access Specifiers</h4>

<p>In C++ object oriented programming, there are three types of access specifiers for classes.</p>



<table>
<thead>
  <tr>
    <th>Access Specifier</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>public</td>
    <td>Members are accessible from outside the class.</td>
  </tr>
  <tr>
    <td>protected</td>
    <td>Members cannot be accessed from outside the class. However, they can be accessed in inherited classes.</td>
  </tr>
  <tr>
    <td>private</td>
    <td>Members cannot be accessed (or viewed) from outside the class.</td>
  </tr>
</tbody>
</table>

<p>Alternatively, this could be described using the following simplified table.</p>



<table>
<thead>
  <tr>
    <th>Access Specifier</th>
    <th>Same Class</th>
    <th>Derived Class</th>
    <th>Outside Class</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>public</td>
    <td>Yes</td>
    <td>Yes</td>
    <td>Yes</td>
  </tr>
  <tr>
    <td>protected</td>
    <td>Yes</td>
    <td>Yes</td>
    <td>No</td>
  </tr>
  <tr>
    <td><span>private</span></td>
    <td>Yes</td>
    <td>No</td>
    <td>No</td>
  </tr>
</tbody>
</table>

<h4 id="inheritance-types">Inheritance Types</h4>

<p>When it comes to class inheritance, there are also three types of inheritances.</p>



<table>
<thead>
  <tr>
    <th>Inheritance Type</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>public</td>
    <td>Public members of the base class become public members of the derived class and protected members of the base class become protected members of the derived class. A base class's private members are never accessible directly from a derived class, but can be accessed through calls to the public and protected members of the base class.</td>
  </tr>
  <tr>
    <td><span>protected</span></td>
    <td>Public and protected members of the base class become protected members of the derived class.</td>
  </tr>
  <tr>
    <td>private</td>
    <td>Public and protected members of the base class become private members of the derived class.<br></td>
  </tr>
</tbody>
</table>

<p>Alternatively, this could be described using the following simplified table.</p>



<table>
<thead>
  <tr>
    <th>Inheritance Type</th>
    <th>base: public member</th>
    <th><span>base: </span>protected <span>member</span></th>
    <th><span>base: </span>private <span>member</span></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>public</td>
    <td>derived: public member</td>
    <td><span>derived: </span>protected member</td>
    <td>-</td>
  </tr>
  <tr>
    <td>protected</td>
    <td><span>derived: </span>protected <span>member</span></td>
    <td><span>derived:</span> protected <span>member</span></td>
    <td>-</td>
  </tr>
  <tr>
    <td>private</td>
    <td><span>derived:</span> private <span>member</span></td>
    <td><span>derived:</span> private <span>member</span></td>
    <td>-</td>
  </tr>
</tbody>
</table>

<h3 id="cmake-inheritance">CMake Inheritance</h3>

<p>CMake uses somewhat similar inheritance concepts to C++, especially for the C++ <code>public</code> and <code>private</code> access specifiers and inheritance types. The CMake keywords <code>PUBLIC</code>, <code>PRIVATE</code>, and <code>INTERFACE</code> used in <code>target_include_directories</code> and <code>target_link_libraries</code>, in my opinion, are mixtures of access specifier and inheritance type from C++.</p>

<h4 id="include-inheritance">Include Inheritance</h4>

<p>In CMake, for any <code>target</code>, in the preprocessing stage, it comes with a <code>INCLUDE_DIRECTORIES</code> and a <code>INTERFACE_INCLUDE_DIRECTORIES</code> for searching the header files building. <code>target_include_directories</code> will populate all the directories to <code>INCLUDE_DIRECTORIES</code> and/or <code>INTERFACE_INCLUDE_DIRECTORIES</code> depending on the keyword <code>&lt;PRIVATE|PUBLIC|INTERFACE&gt;</code> we specified. The <code>INCLUDE_DIRECTORIES</code> will be used for the current <code>target</code> only and the <code>INTERFACE_INCLUDE_DIRECTORIES</code> will be appended to the <code>INCLUDE_DIRECTORIES</code> of any other <code>target</code> which has dependencies on the current <code>target</code>. With such settings, the configurations of <code>INCLUDE_DIRECTORIES</code> and <code>INTERFACE_INCLUDE_DIRECTORIES</code> for all building targets are easy to compute and scale up even for multiple hierarchical layers of building dependencies and many building targets.</p>



<table>
<thead>
  <tr>
    <th>Include Inheritance</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>PUBLIC</td>
    <td>All the directories following PUBLIC will be used for the current target and <span>the other targets that have dependencies on the current target, i.e., appending the directories to </span>INCLUDE_DIRECTORIES and INTERFACE_INCLUDE_DIRECTORIES.</td>
  </tr>
  <tr>
    <td>PRIVATE</td>
    <td><span>All the include directories following PRIVATE will be used for the current target only</span>, i.e., appending the directories to <span>INCLUDE_DIRECTORIES.</span></td>
  </tr>
  <tr>
    <td>INTERFACE</td>
    <td><span>All the include directories following INTERFACE</span> will NOT be used for the current target but will be accessible for the other targets that have dependencies on the current target<span>, i.e., appending the directories to </span>INTERFACE_INCLUDE_DIRECTORIES.</td>
  </tr>
</tbody>
</table>

<p>Note that when we do <code>target_link_libraries(&lt;target&gt; &lt;PRIVATE|PUBLIC|INTERFACE&gt; &lt;item&gt;)</code>, the dependent <code>&lt;item&gt;</code>, if built in the same CMake project, would append the <code>INTERFACE_INCLUDE_DIRECTORIES</code> of <code>&lt;item&gt;</code> to the <code>INCLUDE_DIRECTORIES</code> of <code>&lt;target&gt;</code>. By controlling the <code>INTERFACE_INCLUDE_DIRECTORIES</code>, we could eliminate some unwanted or conflicting declarations from <code>&lt;item&gt;</code> to the <code>&lt;target&gt;</code>.</p>



<p>For example, the <code>fruit</code> library has <code>INCLUDE_DIRECTORIES</code> of <code>fruit_h</code>, <code>tree_h</code>, and <code>INTERFACE_INCLUDE_DIRECTORIES</code> of <code>fruit_h</code>. If there is a <code>apple</code> library that is linked with the <code>fruit</code> library, the <code>apple</code> library would also have the <code>fruit_h</code> in its <code>INCLUDE_DIRECTORIES</code> as well. We could equivalently say, the <code>apple</code> library’s include directory inherited the <code>fruit_h</code> of the  <code>fruit</code> library.</p>

<h4 id="link-inheritance">Link Inheritance</h4>

<p>Similarly, for any <code>target</code>, in the linking stage, we would need to decide, given the <code>item</code> to be linked, whether we have to put the <code>item</code> in the link dependencies, or the link interface, or both, in the compiled <code>target</code>. Here the link dependencies means the <code>item</code> has some implementations that the <code>target</code> would use, and it is linked to the <code>item</code>, so that whenever we call the functions or methods corresponding to those implementations it will always be mapped correctly to the implementations in <code>item</code> via the link, whereas the link interface means the <code>target</code> becomes an interface for linking the <code>item</code> for other targets which have dependencies on the <code>target</code>, and the <code>target</code> does not have to use <code>item</code> at all.</p>



<table>
<thead>
  <tr>
    <th>Link Type</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>PUBLIC</td>
    <td>All the objects following PUBLIC will be used for linking to the current target and providing the interface to the other targets that have dependencies on the current target.</td>
  </tr>
  <tr>
    <td>PRIVATE</td>
    <td><span>All the objects following </span>PRIVATE will only be used for linking to the current target.</td>
  </tr>
  <tr>
    <td>INTERFACE</td>
    <td><span>All the objects following </span>INTERFACE will only be used for providing the interface to the other targets that have dependencies on the current target.</td>
  </tr>
</tbody>
</table>

<p>For example, if the <code>fruit</code> library has the implementation of functions, such as <code>size</code> and <code>color</code>, and the <code>apple</code> library has a function <code>apple_size</code> which called the <code>size</code> from the <code>fruit</code> library and was <code>PRIVATE</code> linked with the <code>fruit</code> library. We could create an executable <code>eat_apple</code> that calls <code>apple_size</code> by <code>PUBLIC</code> or <code>PRIVATE</code> linking with the <code>apple</code> library. However, if we want to create an executable <code>eat_apple</code> that calls the <code>size</code> and <code>color</code> from the <code>fruit</code> library, only linking with the <code>apple</code> library will cause building error, since the <code>fruit</code> library was not part of the interface in the <code>apple</code> library, and is thus inaccessible to <code>eat_apple</code>. To make the <code>apple</code> library to inherit the <code>size</code> and <code>color</code> from the <code>fruit</code> library, we have to make the linking of the <code>apple</code> library to the the <code>fruit</code> library <code>PUBLIC</code> instead of <code>PRIVATE</code>.</p>

<h3 id="conclusions">Conclusions</h3>

<p>The CMake builds a hierarchical project via the include interface or link interface. The “inheritance” mechanism in C++ is built upon the include interface or link interface.</p>

<h3 id="faq">FAQ</h3>

<h4 id="how-to-understand-cmake-interface">How to Understand CMake Interface?</h4>

<p>In my understanding, CMake interface is just like a telephone switch station in old times.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-08-08-CMake-Public-Private-Interface/medienwandel-chicago-union-station-telegraph-switchboard.jpg">
    <figcaption>Telephone Switch Station</figcaption>
</figure>
</div>

<p>If <code>A</code> wants to call <code>B</code> and there is no direct telephone cable connection between <code>A</code> and <code>B</code>, <code>A</code> has to call a telephone switch station that has connection to <code>B</code> and the personal in the telephone switch station will connect <code>A</code> and <code>B</code> by jointing the cable of <code>A</code> and the cable of <code>B</code> together. If the telephone switch station does not know there is a <code>B</code>, it is impossible to get <code>A</code> and <code>B</code> connected. So CMake interface is simply a registration in the telephone switch station. When there is a dependency in CMake targets, targets from different levels of hierarchy are connected via interfaces, for both <code>include</code> and <code>link</code>.</p>

<h4 id="what-are-the-key-points-for-this-blog-post">What are the Key Points for This Blog Post?</h4>

<p><code>PRIVATE</code> only cares about himself and does not allow inheritance. <code>INTERFACE</code> only cares about others and allows inheritance. <code>PUBLIC</code> cares about everyone and allows inheritance.</p>

<h4 id="is-public-private-interface-part-of-the-gccg-compiler">Is PUBLIC, PRIVATE, INTERFACE Part of the GCC/G++ Compiler?</h4>

<p>No. Compilers, such as <code>gcc</code> and <code>g++</code>, do not have such mechanism. CMake invented those keywords for user to create a building graph that has very clear and explicit dependencies. The building graph translates to normal building commands using <code>gcc</code> and <code>g++</code>.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://kubasejdak.com/modern-cmake-is-like-inheritance">Modern CMake is Like Inheritance</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/CMake-Public-Private-Interface/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623282</guid>
            <pubDate>Tue, 29 Sep 2020 01:27:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenStreetMap State of the Map conf 2020 – a few thoughts on the experiment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623160">thread link</a>) | @pabs3
<br/>
September 28, 2020 | http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/ | <a href="https://web.archive.org/web/*/http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Last weekend has been the <a href="https://2020.stateofthemap.org/">2020 State of the Map conference</a> – which did not take place like it was originally planned and as it has been conducted in the past years at a specific physical place (in this case Capetown, South Africa) but was done in a purely virtual distributed form across the internet.</p>
<p>I regard this change – forced by the pandemic situation we all struggle with these days in some form – as in a way a welcome disruption.  Due to an outside event the powers-that-be have been forced to try something they would not have tried probably in many years to come otherwise.</p>
<p>The implementation of the virtual distributed conference as an afterthought on an originally planned physical single place event led of course to some flaws and inconsistencies in the practical setup and to not using the full potential of the virtual setting in all of its aspects.  This is obviously owed a lot to the desire not to throw away work already done.  The most obvious issue resulting from that approach is that the main conference program contained almost exclusively program items submitted by people under the original premise of a physical conference – or in other words:  The chance to hold a talk at the virtual conference still depended on the willingness and ability of people to travel to South Africa and be there for the talk in person.</p>
<p>This means the conference in its program was not even remotely as diverse as it could have been it it had been set up as a distributed remote conference in the first place.  This should IMO be kept in mind by everyone evaluating how SotM 2020 turned out.</p>
<p>I regard the whole event mostly as an experiment to test various techniques and methods and means of communication to have a virtual conference in the OSM context.  This applies both to behind-the-scene infrastructure and the public interfaces.  If the SotM WG documents and shares their findings publicly that could have use far beyond SotM for the OSM community.</p>
<h3>Practical observations from the conference</h3>
<p>The pads for collecting questions and comments on talks worked great.  This is definitely a concept that could play a central role in future distributed conferences.  Initially the questions were asked anonymously which has led in particular in case of Frederik’s talk to quite a lot of people making vile comments under the disguise of anonymity.  It was later established that questions and comments should be signed.  I also think that the use of pads could be extended to non-talk program items like self organized sessions.</p>
<div id="attachment_9119"><p><a href="https://pad.sotm.bitcast.co.za/p/general-feedback"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_pad.png" alt="" width="512" height="429" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_pad.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_pad-320x268.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>general feedback pad of the conference – there was a similar pad for questions and comments on each of the talks</p></div>
<p>The attractiveness of the pads to a large extent comes from the real time capability (which is essential for a real time conference obviously) combined with the non-linear free form structure of the text (which contrasts pleasantly with most other real time communication channels that tend to have a strictly linear structure).</p>
<p>There are quite a few things that could be improved about the audio.  This starts with the levels of the pause music relative to the talk audio levels and continues with reverberations in poorly dampened rooms of some presenters and feedback noise in some people’s audio setup.  That is mostly a matter of sufficient testing and experience with setting up and adjusting equipment in a way that works well.  That takes time from everyone involved obviously.  This is the hardest the first time but gets easier once you gain experience.  And i am confident with the corona virus crisis incentivizing many people to gain more practice in remote communication knowledge and experience in this field is much improving every day.  More communication about how to ensure good audio recording and communication quality within the community, sharing experiences and techniques used, would definitely be helpful.</p>
<p>None the less what also became clear to me during the conference is that the willingness of people to engage in communication was very clearly in the order written conversation &gt; audio communication &gt; video.  I think this is an observation to consider for any audio or video conversation in the OSM context.  Video meetings might be very convenient for heavily engaged extroverted community members with a pre-existing prominence but for many people this can be a source of discomfort.  And cultural and language barriers can be strongly emphasized by use of real time audio and especially video communication.</p>
<h3>Comments on the talks</h3>
<p>I have not watched all the talks of the conference so this is more a list of anecdotal observations than a complete review.  All the talks of the main conference program were pre-recorded while the Q&amp;A after the talks were live.  The pre-recorded talks offered a lot of options for presenters which would not be available in a live conference talk and which were used very differently by the presenters.  Ilya in his talk <em><a href="https://2020.stateofthemap.org/sessions/CKYTVS">Send me a Postcard</a></em> IMO showed the most innovative approach to this.  Watching this talk is recommended to anyone who in the future might be in the position to pre-record a conference talk as a positive example.</p>
<p>Some of the talks i watched so far that i consider particularly interesting:</p>
<div id="attachment_9121"><p><a href="https://2020.stateofthemap.org/sessions/RRVNAM"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_allan2.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_allan2.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_allan2-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Allan’s American perspective on the political spectrum of OSM</p></div>
<p>Allan’s keynote <em><a href="https://2020.stateofthemap.org/sessions/RRVNAM">Winds of Change in OpenStreetMap</a></em> – While this did not provide much new information of substance to those following OSMF politics in general and who have read past statements from Allan on that subject, it seems to provide a valuable glimpse into the current mentality of the OSMF board regarding their work.  Although Allan had a prominent disclaimer that these are his personal views and do not represent those of the board, it is quite clear from statements and actions of other board members that they see many of these things similarly.  There is quite a lot of accurate analysis in the talk but also quite a few highly questionable selective perceptions, assumptions and conclusions.  I might comment about some of those separately although it is not clear at this time if the board is currently willing to openly discuss the merits of their views and opinions on the OSM community and the future of the OSM project and on the OSMFs role and defend their views and conclusions on these matters in a public setting.</p>
<div id="attachment_9122"><p><a href="https://2020.stateofthemap.org/sessions/DYXWDC"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_fred.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_fred.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_fred-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Frederik explaining OpenStreetMap</p></div>
<p>Frederik’s talk <em><a href="https://2020.stateofthemap.org/sessions/DYXWDC">There might have been a misunderstanding…</a></em> – As usual Frederik explains in a well understandable way many of the central aspects of the OpenStreetMap project which new contributors as well as data users often struggle with because they differ from what people are used to, either in other internet communities or in the world of geodata.  Naturally, a lot of these frequently misunderstood aspects of OSM are also fairly controversial and this has – as hinted above – led to a lot of critical and in parts insulting comments on the talk by people who would like these things to change and for OSM to become more compatible with their expectations.  What Frederik presents however is for the most part not wishful thinking – presenting how he would like OSM to be – but how OpenStreetMap actually works and functions based on knowledge derived from many years of practical involvement in the project.  Other long term participants will largely be able to confirm that.  So whether you like these aspects of OSM or not and in what direction you might want OSM to develop in the future this is a very useful talk to watch to understand how OpenStreetMap ticks.  </p>
<div id="attachment_9123"><p><a href="https://2020.stateofthemap.org/sessions/RHDUV9"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_mikel.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_mikel.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_mikel-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Mikel mocking concerns about conflicts of interest of corporate employees in the OSMF</p></div>
<p>Mikel’s talk <em><a href="https://2020.stateofthemap.org/sessions/RHDUV9">An Incomplete History of Companies and Professionals in OpenStreetMap</a></em> – Essentially Mikel is painting corporate activities in OSM and their history in rosy colors while saying: just pay no attention to all the skeletons lying around here.  A lot could be criticized about selective presentations of facts as well as factual and logical errors or about the technique of jokingly dismissing and ridiculing differentiated philosophical critique of the influence of corporate interests in OSM.  Anyway – I think this is a valuable talk to watch to get a glimpse into the mindset of many corporate employees involved in OSM as part of or in relation to their job.  </p>
<div id="attachment_9124"><p><a href="https://2020.stateofthemap.org/sessions/DZ8PWQ"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_janet.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_janet.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_janet-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Janet explaining aid work in rural Tanzania</p></div>
<p>Janet’s talk <em><a href="https://2020.stateofthemap.org/sessions/DZ8PWQ">Building mapping communities in rural Tanzania – challenges, successes and lessons learnt</a></em> – I found this interesting because of a certain observation.  In the beginning a number of specific non mapping related examples are shown of aid being given to people in rural areas of Tanzania for everyday life problems.  And emphasis is admirably given to helping locals solving these problems themselves in a sustainable and independent fashion using locally available means.  Yet when it comes to mapping and digital technology the same initiative (and from what i know also many other humanitarian mapping projects) critiquelessly rely on commercial services and proprietary tools and encourage locals to use and rely on those services and tools that increase and perpetuate dependence of local people on non-local corporations for their local mapping work instead of educating people in using open source technology and tools they can manage and control themselves.</p>
<p>To be clear, i am not at all saying that this talk in any way constitutes an example for particularly bad practice in that regard, on the contrary the examples shown illustrate a principal awareness of the issue that is missing elsewhere.  But to me it demonstrates quite well how fundamentally different measures are applied to the goal of supplying aid in a way that enables locals to solve serious problems in a sustainable fashion outside the digital world and within it.  </p>
<div id="attachment_9125"><p><a href="https://2020.stateofthemap.org/sessions/CKYTVS"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_ilya.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_ilya.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_ilya-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Ilya making a case for sending postcards in an innovative style video</p></div>
<p>Ilya’s talk <em><a href="https://2020.stateofthemap.org/sessions/CKYTVS">Send me a Postcard</a></em> – I mentioned his talk already above as an example for making innovative use of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/">http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/</a></em></p>]]>
            </description>
            <link>http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623160</guid>
            <pubDate>Tue, 29 Sep 2020 01:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julia mixed precision GEMM codegen meets and exceeds CUBLAS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623153">thread link</a>) | @amkkma
<br/>
September 28, 2020 | https://juliagpu.org/2020-09-28-gemmkernels/ | <a href="https://web.archive.org/web/*/https://juliagpu.org/2020-09-28-gemmkernels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        





<i data-feather="calendar"></i> <time datetime="2020-09-28">Sep 28, 2020</time>




  <br>
  <i data-feather="edit-2"></i> Thomas Faingnaert, Tim Besard, Bjorn De Sutter


<p>General Matrix Multiplication or GEMM kernels take center place in high performance
computing and machine learning. Recent NVIDIA GPUs include GEMM accelerators, such as
NVIDIA’s Tensor Cores. In this paper we show how it is possible to program these
accelerators from Julia, and present abstractions and interfaces that allow to do so
efficiently without sacrificing performance.</p>
<p>A pre-print of the paper has been published on arXiv:
<a href="https://arxiv.org/abs/2009.12263">arXiv:2009.12263</a>. <br> The source code can be found on
GitHub:
<a href="https://github.com/thomasfaingnaert/GemmKernels.jl">thomasfaingnaert/GemmKernels.jl</a>.</p>
<p>With the APIs from GemmKernels.jl, it is possible to instantiate GEMM kernels that perform
in the same ball park as, and sometimes even outperform state-of-the-art libraries like
CUBLAS and CUTLASS. For example, performing a mixed-precision multiplication of two 16-bit
matrixes into a 32-bit accumulator (on different combinations of layouts):</p>


<figure>
	<img src="https://juliagpu.org/2020-09-28-gemmkernels/mixed_precision.png" alt="Performance of mixed-precision GEMM">
</figure>

<p>The APIs are also highly flexible and allow customization of each step, e.g., to apply the
activation function <code>max(x, 0)</code> for implementing a rectified linear unit (ReLU):</p>
<div><pre><code data-lang="julia">a <span>=</span> CuArray(rand(<span>Float16</span>, (M, K)))
b <span>=</span> CuArray(rand(<span>Float16</span>, (K, N)))
c <span>=</span> CuArray(rand(<span>Float32</span>, (M, N)))
d <span>=</span> similar(c)

conf <span>=</span> GemmKernels<span>.</span>get_config(
    gemm_shape <span>=</span> (M <span>=</span> M, N <span>=</span> N, K <span>=</span> K),
    operator <span>=</span> Operator<span>.</span>WMMAOp{<span>16</span>, <span>16</span>, <span>16</span>},
    global_a_layout <span>=</span> Layout<span>.</span>AlignedColMajor{<span>Float16</span>},
    global_c_layout <span>=</span> Layout<span>.</span>AlignedColMajor{<span>Float32</span>})

GemmKernels<span>.</span>matmul(
    a, b, c, d, conf;
    transform_regs_to_shared_d <span>=</span> Transform<span>.</span>Elementwise(x <span>-&gt;</span> max(x, <span>0</span>)))
</code></pre></div><p>The GemmKernels.jl framework is written entirely in Julia, demonstrating the
high-performance GPU programming capabilities of this language, but at the same time keeping
the research accessible and easy to modify or repurpose by other Julia developers.</p>



      </main>
    </div></div>]]>
            </description>
            <link>https://juliagpu.org/2020-09-28-gemmkernels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623153</guid>
            <pubDate>Tue, 29 Sep 2020 01:08:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD on the Desktop (Part I)]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24622788">thread link</a>) | @upofadown
<br/>
September 28, 2020 | https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Let's install OpenBSD on a Lenovo Thinkpad X270. I used this computer for my
computer science studies. It has both Arch Linux and Windows 10 installed as
dual boot. Now that I'm no longer required to run Windows, I can ditch the dual
boot and install an operating system of my choice.</p>

<p>First, I grab my work Thinkpad running Arch Linux and some USB dongle big enough
for the <a href="https://cdn.openbsd.org/pub/OpenBSD/6.7/amd64/miniroot67.fs">amd64 miniroot
image</a> (roughly
five megabytes, that is). This small image does not include the file sets, which
will be downloaded during installation instead. I also download the <a href="https://mirror.ungleich.ch/pub/OpenBSD/6.7/amd64/SHA256">SHA256
checksums</a> from the
Swiss mirror, and verify the downloaded image, before I copy it on my dongle:</p>
<pre><code>$ sha256sum -c --ignore-missing SHA256 
miniroot67.fs: OK
$ sudo dd if=miniroot67.fs of=/dev/sda bs=1M
</code></pre>

<p>The Thinkpad X270 is connected to my network through Ethernet. The WiFi firmware
usually needs to be installed separately, so only Ethernet will work out of the
box. The BIOS has UEFI activated. OpenBSD and UEFI has issues on older hardware
(at least on a 2014 Dell laptop I have), but let's try it on this laptop,
anyway.</p>
<p>I plug in the dongle prepared before, and start the computer. I interrupt
the regular boot with Enter and pick an alternative boot method by pressing F12.
Now I pick my USB dongle. After roughly a minute, the installer has been
started. Now I follow these steps:</p>
<ul>
<li>I choose the option <code>I</code> to install OpenBSD.</li>
<li>For the keyboard layout, I pick <code>sg</code>, for Swiss German.</li>
<li>As a hostname, I simply pick <code>x270</code>, because it's a Thinkpad X270, and I'm not
  very creative when it comes to naming things.</li>
<li>From the available network options (<code>iwm0</code>: WiFi, <code>em0</code>: Ethernet, and
  <code>vlan0</code>: Virtual LAN), I pick <code>em0</code>.</li>
<li>I try to get an IPv4 address over DHCP, which seems to work very quickly.</li>
<li>Next, I type in my very secret root password twice.</li>
<li>I do <em>not</em> start <code>sshd</code> by default, because I don't need to connect to this
  machine through SSH. It's supposed to be a workstation, not a server.</li>
<li>The X Window System should not be started by <code>xnodm(1)</code>, so I leave it to
  <code>no</code>.</li>
<li>Neither do I want to change the default to <code>com0</code>.</li>
<li>I set up my user <code>patrick</code> with my proper name <code>Patrick Bucher</code>, and a decent
  password.</li>
<li>The time zone has been detected properly as <code>Europe/Zurich</code>, which I just
  leave the way it is.</li>
<li>The installer detected two disks: <code>sd0</code> and <code>sd1</code>. Since <code>sd0</code> is the detected
  SSD in my laptop, the UEFI issue from my Dell laptop doesn't exist on this
  computer. I pick <code>sd0</code> for the root disk, since <code>sd1</code> is my USB dongle.</li>
<li>I choose to use the whole disk with a GPT partitioning schema, because it's
  2020.</li>
<li>An auto-allocated layout for <code>sd0</code> is presented. It looks decent to me, so I
  just go with that auto layout.</li>
<li>I don't want to initialize another disk, so I just press Enter (<code>done</code>).</li>
<li>Since the miniroot image does not come with the file sets, I pick <code>http</code> as
  the location for the sets.</li>
<li>I don't use a proxy, and use the mirror <code>mirrog.ungleich.ch</code> and the server
  directory <code>pub/OpenBSD/6.7/amd64</code> as proposed.</li>
<li>Next, I unselect the game sets by entering <code>-game*</code>. (I heard that they're not
  much fun to play.) I leave all the other sets activated, including the <code>x</code>
  sets, which will be required for the GUI later on.</li>
<li>After those sets are installed, I press Enter (<code>done</code>). Now the installer
  performs various tasks, after which I choose to <code>halt</code> the computer. This
  gives me time to remove the USB dongle.</li>
</ul>

<p>I now restart my laptop, and OpenBSD boots. This takes more time than booting
Arch Linux, which uses <code>systemd</code>, whereas OpenBSD uses <code>rc</code>, which performs the
startup tasks sequentially.</p>
<p>There's a message showing up that various firmware (<code>intel-firmware</code>,
<code>iwm-firmware</code>, <code>inteldrm-firmware</code>, <code>uvideo-firmware</code>, and <code>vmm-firmware</code>) has
been installed automatically. Very nice, indeed.</p>
<h2>WiFi Connection</h2>
<p>Now that the <code>iwm-firmware</code> has been installed, I can connect right away to my
WiFi network <code>frzbxpdb5</code>. I create a file called <code>/etc/hostname.iwm0</code>, wich
<code>hostname</code> being a literal string, and <code>iwm0</code> being the WiFi network card. The
connection to my WiFi network consists of a single line:</p>
<pre><code>dhcp nwid frzbxpdb5 wpakey [my-wpakey]
</code></pre>
<p>Whereas <code>frzbxpdb5</code> is my WiFi network's ESSID, and <code>[my-wpakey]</code> needs to be
replaced by the actual WPA key.</p>
<p>Then the networking can be restarted for that device:</p>
<pre><code># sh /etc/netstart iwm0
</code></pre>
<p>This script is kind enough to set the file permissions of <code>/etc/hostname.iwm0</code>
to <code>640</code>, and then connects to my WiFi network.</p>
<p>I unplug the Ethernet cable and <code>ping openbsd.org</code>, which works fine, even after
a restart.</p>

<p>My GUI on Unix-like systems is based on the Dynamic Window Manager (<code>dwm</code>) and a
couple of other tools, such as <code>dmenu</code>, <code>st</code>, <code>slstatus</code>, <code>slock</code>, all created and
maintained by the <a href="http://suckless.org/">Suckless</a> community.</p>
<p>This software doesn't come with configuration facilities, but needs to be
configured in the respective C header file <code>config.h</code>, and then re-compiled.
Even though OpenBSD offers <code>dwm</code> as a package, customizing and configuring that
window manager requires to build it from source.</p>
<h2>Building <code>dwm</code> and Friends</h2>
<p>First, I need to install <code>git</code> to fetch the source code:</p>
<pre><code># pkg_add git
</code></pre>
<p>Then I fetch the source code for <code>dwm</code>, <code>dmenu</code>, <code>st</code>, and <code>slstatus</code> from <a href="http://suckless.org/">Suckless</a>:</p>
<pre><code>$ git clone https://git.suckless.org/dwm
$ git clone https://git.suckless.org/dmenu
$ git clone https://git.suckless.org/st
$ git clone https://git.suckless.org/slstatus
</code></pre>
<h3>Building <code>dwm</code></h3>
<p>Next, I try to build <code>dwm</code>:</p>
<pre><code>$ cd dwm
$ make
</code></pre>
<p>This fails with an error message (<code>'ft2build.h' file not found</code>), which reminds
me of building <code>dwm</code> on FreeBSD roughly a month before. Since I can finde the
header file at another location:</p>
<pre><code># find / -type f -name ft2build.h
/usr/X11R6/include/freetype2/ft2build.h
</code></pre>
<p>I simply can modify the <code>config.mk</code> accordingly by changing</p>
<pre><code>FREETYPEINC = /usr/include/freetype2
</code></pre>
<p>to</p>
<pre><code>FREETYPEINC = $(X11INC}/freetype2
</code></pre>
<p>Actually, I only need to comment the above line, and uncomment the line below</p>
<pre><code># OpenBSD (uncomment)
</code></pre>
<p>The Suckless folks obviously are friendly towards OpenBSD, which is also
noticable in other places (more evidence to be shown further below).</p>
<p>The next compilation attempt succeeds:</p>
<pre><code>$ make
</code></pre>
<p>So let's install <code>dwm</code>, too:</p>
<pre><code># make install
</code></pre>
<p>By default, and as to be seen in <code>config.h</code>, the keyboard combination
<code>[Alt]+[Shift]+[Enter]</code> (deeply engraved into the muscle memories of many <code>dwm</code>
users) starts the <code>st</code> terminal. This will be built in a while. However, I
prefer to use the <em>Super</em> or <em>Windows</em> key instead of <code>Alt</code>, since the former
is of no use in OpenBSD, and the latter still comes in handy when working with
the emacs readline mode. Therefore, I change the <code>MODKEY</code> from</p>
<pre><code>#define MODKEY Mod1Mask
</code></pre>
<p>to</p>
<pre><code>#define MODKEY Mod4Mask
</code></pre>
<p>Then I rebuild and reinstall <code>dwm</code>:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>st</code></h3>
<p>Let's switch over to the <code>st</code> source directory and just try to compile it:</p>
<pre><code>$ cd ../st
$ make
</code></pre>
<p>Here, we get a warning that the function <code>pledge</code> (an OpenBSD mitigation, which
is built into the <code>master</code> branch, but surrounded by an <code>ifdef</code> preprocessor
statement, so that it will only be compiled for OpenBSD) is imported implicitly.
Let's just ignore this warning for now.</p>
<p>What's worse, the compilation fails with the error message:</p>
<pre><code>ld: error: unable to find library -lrt
</code></pre>
<p>Here, the FAQ comes in handy, stating that</p>
<pre><code>If you want to compile st for OpenBSD you have to remove -lrt from
config.mk, ...
</code></pre>
<p>Having done so in <code>config.mk</code>, <code>st</code> compiles without any further issues, and,
thus, can be rebuilt and installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>dmenu</code></h3>
<p>Even OpenBSD users with Suckless tools have to open another GUI application than
a terminal emulator once in a while. For this purpose, Suckless offers <code>dmenu</code>.
Let's switch over to it and compile it:</p>
<pre><code>$ cd ../dmenu
$ make
</code></pre>
<p>Again, we have the issue with <code>ft2build.h</code>, which can be resolved as above with
<code>dwm</code>: by using the proper path for <code>FREETYPEINC</code> in <code>config.mk</code>. Afterwards,
the build succeeds, and <code>dmenu</code> can be installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>slstatus</code></h3>
<p><code>dwm</code> has a status bar on the top right, which can be used to show various
information. I used to write some shell commands in <code>.xinitrc</code> to compose such a
status line, and then set it by <code>xset -b</code> once every five seconds or so. This
approach generates a multitude of processes every couple of seconds.</p>
<p><code>slstatus</code> is a C programm that is capable of showing various kinds of more or
less useful information. Let's switch over to <code>slstatus</code> and see, what is
available in <code>config.def.h</code>:</p>
<pre><code>$ cd ../slstatus
$ less config.def.h
</code></pre>
<p>The comments section lists different functions (<code>battery_perc</code> for the battery
percentage, <code>datetime</code> for date and time information, <code>temp</code> for thermal
information, etc.). I usually display the CPU load, the battery percentage, the
memory usage, the current keyboard layout, and the current date and time.</p>
<p>Before configuring those, let's try to compile <code>slstatus</code>:</p>
<pre><code>$ make
</code></pre>
<p>This worked fine, so let's configure the information to be displayed in
<code>config.h</code>:</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    "%s",     "%F %T" },
};
</code></pre>
<p>This renders the current date as follows:</p>
<pre><code>$ date +"%F %T"
2020-09-05 19:26:38
</code></pre>
<p>I also like to have the weekday included, but not the seconds, so I define a
different argument string:</p>
<pre><code>$ date +"%a %Y-%m-%d %H:%M"
Sat 2020-09-05 19:27
</code></pre>
<p>That's better, so let's use it in <code>config.h</code> (surrounded with some spaces in the
format string):</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    " %s ",   "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>The other settings I like to have do not require any arguments, at least not on
OpenBSD, so I only need to define a decent format string (with <code>|</code> as a
seperator) for those:</p>
<pre><code>static const struct arg args[] = {
    /* function    format           argument */
    { cpu_perc,     " cpu: %s%% |", NULL },
    { battery_perc, " bat: %s%% |", NULL },
    { ram_used,     " mem: %s |",   NULL },
    { keymap,       " %s |"         NULL },
    { datetime,     " %s ",         "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>This actually compiles, so let's install it:</p>
<pre><code># make install
</code></pre>
<h2>Configuring X Startup</h2>
<p>Now that all software is compiled and installed, let's run X. To do so, a file
<code>.xinitrc</code> in the user's directory is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</a></em></p>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24622788</guid>
            <pubDate>Tue, 29 Sep 2020 00:23:20 GMT</pubDate>
        </item>
    </channel>
</rss>
