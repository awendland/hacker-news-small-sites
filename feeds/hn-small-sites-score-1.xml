<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 03 Aug 2020 12:23:27 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 03 Aug 2020 12:23:27 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[No, the Woke Won’t Debate You. Here’s Why]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24019257">thread link</a>) | @wcerfgba
<br/>
August 1, 2020 | https://newdiscourses.com/2020/07/woke-wont-debate-you-heres-why/ | <a href="https://web.archive.org/web/*/https://newdiscourses.com/2020/07/woke-wont-debate-you-heres-why/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	
	<div>

		
		
		

				
		
		
		<div>

			
			<div>

				
				<div id="content">

					
	<div id="primary">

		
		<main id="main" role="main">

			
			
				
				<article data-scroll="" id="post-3420">

					
					<div>

						
						<div>

										<section>
						
				</section>
			
							<section>

								<p>I can’t tell you how many times I’ve been asked why it is that the <a href="https://newdiscourses.com/tftw-woke-wokeness/">Woke</a> won’t seem to have a debate or discussion about their views, and I’ve been meaning to write something about it for ages, probably a year at this point. Surely you’ll have noticed that they don’t tend to engage in debates or conversation?</p>
<p>It is not, as many think, a fear of being exposed as fraudulent or illegitimate—or otherwise of losing the debate or looking bad in the challenging conversation—that prevents those who have internalized a significant amount of the Critical Social Justice <a href="https://newdiscourses.com/tftw-theory/">Theory</a> mindset that prevents these sorts of things from happening. There’s a mountain of Theoretical reasons that they would avoid all such activities, and even if those are mere rationalizations of a more straightforward fear of being exposed as fraudulent or losing, they are shockingly well-developed and consistent rationalizations that deserve proper consideration and full explanation.</p>
<p>I often get asked specifically if there’s some <a href="https://newdiscourses.com/2020/06/beginners-curriculum-critical-race-theory/">paper or book</a> out there in the <a href="https://newdiscourses.com/2020/02/naming-enemy-critical-social-justice/">Critical Social Justice</a> literature that prohibits or discourages debate and conversation with people who don’t already agree with them. I honestly don’t know. I’ve looked in a cursory fashion and haven’t found one, but, then, Critical Social Justice scholars are also rather incredibly prolific (an undeniable benefit of having <a href="https://newdiscourses.com/2020/01/academic-grievance-studies-and-the-corruption-of-scholarship/">no rigorous standards</a> to meet and a surplus of ideological zeal, as it happens). That is to say, there’s a lot of Woke literature out there, and maybe someone has explained it very clearly and at length with a lot of specificity, but if so, I haven’t seen it. So far as I know, there’s not some specific piece of scholarship that closes the Woke off to debate, like a single paper or book explaining why they don’t do it. It’s just part of the Woke mindset not to do it, and the view of the world that informs that mindset can be read throughout their scholarship.</p>
<p>There are a number of points within Critical Social Justice Theory that would see having a debate or conversation with people of opposing views as unacceptable, and they all combine to create a mindset where that wouldn’t be something that adherents to the Theory are likely or even willing to do in general. This reticence, if not unwillingness, to converse with anyone who disagrees actually has a few pretty deep reasons behind it, and they’re interrelated but not quite the same. They combine, however, to produce the first thing everyone needs to understand about this ideology: it is a complete worldview with its own ethics, epistemology, and morality, and theirs is not the same worldview the rest of us use. Theirs is, very much in particular, <em>not liberal</em>. In fact, theirs advances itself rather parasitically or <a href="https://newdiscourses.com/2020/03/critical-theories-virus-liberal-body-politic/">virally</a> by depending upon us to play the liberal game while <a href="https://newdiscourses.com/2020/04/woke-virus-infects-academia-covid-19-response/">taking advantage</a> of its openings. That’s not the same thing as being willing to play the liberal game themselves, however, including to have thoughtful dialogue with people who oppose them and their view of the world. Conversation and debate are part of <em>our</em> game, and they are <em>not</em> part of <a href="https://newdiscourses.com/2020/05/stealing-motte-critical-social-justice-principle-charity/"><em>their</em> game</a>.</p>
<h3 id="1-they-think-the-system-is-rigged-against-them">1. They Think the System Is Rigged Against Them</h3>
<p>The first thing to understand about the way adherents to Critical Social Justice view the world is just how deeply they have accepted the belief that we operate within a wholly systemically <a href="https://newdiscourses.com/tftw-oppression/">oppressive</a> system. That system extends to <a href="https://newdiscourses.com/2020/07/nobody-systemically-racist/">literally everything</a>, not just material structures, institutions, law, policies, and so on, but also into cultures, mindsets, ways of thinking, and how we determine what is and isn’t true about the world. In their view, the broadly liberal approach to knowledge and society is, in fact, rotted through with “white, Western, male (and so on) <a href="https://newdiscourses.com/tftw-bias/">biases</a>,” and this is such a profound departure from how the rest of us—broadly, liberals—think about the world that it is almost impossible to understand just how deeply and profoundly they mean this.</p>
<p>In a <a href="https://www.tandfonline.com/doi/abs/10.1080/02691728.2013.782585" target="_blank" rel="noopener noreferrer">2014 paper</a> by the black feminist epistemology heavyweight Kristie Dotson, she explains that our entire <a href="https://newdiscourses.com/tftw-epistemic-injustice/">epistemic landscape</a> is itself profoundly unequal. Indeed, she argues that it is intrinsically and “irreducibly” so, meaning that it is not possible from within the prevailing system of knowledge and understanding to understand or know that the system itself is unfairly biased toward certain ways of knowing (white, Western, Eurocentric, male, etc.) and thus exclusionary of other ways of knowing (be those what they may). That is, Dotson explains that when we look across <a href="https://newdiscourses.com/tftw-identity/">identity groups</a>, not only do we find a profound lack of “shared epistemic resources” by which people can come to understand things in the same way as one another, but also that the lack extends to the ability to know that that dismal state of affairs is the case at all. This, she refers to as “irreducible” <a href="https://newdiscourses.com/tftw-epistemic-oppression/">epistemic oppression</a>, which she assigns to the third and most severe order of forms of epistemic oppression, and says that it requires a “third-order change” to the “organizational schemata” of society (i.e., a complete epistemic revolution that removes the old epistemologies and replaces them with new ones) in order to find repair.</p>
<p>This view is then echoed and amplified, for example, in a lesser-read <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/hypa.12354" target="_blank" rel="noopener noreferrer">2017 paper</a> by the Theorist Alison Bailey. Therein she invokes explicitly that in the neo-Marxist “critical” tradition, which is not to be mistaken for the “critical thinking” tradition of the Western canon, critical thinking itself and that which is seen to produce and legitimize it are part of the “<a href="https://newdiscourses.com/tftw-masters-tools/">master’s tools</a>” that black feminist Audre Lorde wrote “will never dismantle the master’s house.” Since nobody ever believes me that she really writes this, here’s the quote:</p>
<p>The critical-thinking tradition is concerned primarily with epistemic adequacy. To be critical is to show good judgment in recognizing when arguments are faulty, assertions lack evidence, truth claims appeal to unreliable sources, or concepts are sloppily crafted and applied. For critical thinkers, the problem is that people fail to “examine the assumptions, commitments, and logic of daily life… the basic problem is irrational, illogical, and unexamined living.” In this tradition sloppy claims can be identified and fixed by learning to apply the tools of formal and informal logic correctly.</p>
<p>Critical pedagogy begins from a different set of assumptions rooted in the neo-Marxian literature on critical theory commonly associated with the Frankfurt School. Here, the critical learner is someone who is empowered and motivated to seek justice and emancipation. Critical pedagogy regards the claims that students make in response to social-justice issues not as propositions to be assessed for their truth value, but as expressions of power that function to re-inscribe and perpetuate social inequalities. Its mission is to teach students ways of identifying and mapping how power shapes our understandings of the world. This is the first step toward resisting and transforming social injustices. By interrogating the politics of knowledge-production, this tradition also calls into question the uses of the accepted critical-thinking toolkit to determine epistemic adequacy. To extend Audre Lorde’s classic metaphor, the tools of the critical-thinking tradition (for example, validity, soundness, conceptual clarity) cannot dismantle the master’s house: they can temporarily beat the master at his own game, but they can never bring about any enduring structural change. They fail because the critical thinker’s toolkit is commonly invoked in particular settings, at particular times to reassert power: those adept with the tools often use them to restore an order that assures their comfort. They can be habitually invoked to defend our epistemic home terrains. (pp. 881–882)</p>
<p>Here, the “master’s tools” are explicitly named by Bailey as including soundness and validity of argument, conceptual clarity, and epistemic adequacy (i.e., knowing what you’re talking about) and can easily be extended to science, reason, and rationality, and thus also to conversation and debate. The “master’s house” is the “organizational schemata” laid out by Kristie Dotson as the prevailing knowing system. Her claim is that these tools—essentially all of the liberal ones—cannot dismantle liberal societies from within, which is their goal, because they are the very tools that build and keep building it.</p>
<p>Bailey’s point is clear: the usual tools by which we identify provisional truths and settle scholarly disagreements are part of the hegemonically dominant system that, by definition, cannot be sufficiently radical to create real revolutionary change (a “third-order” change, as Dotson has it). That is, they can’t <a href="https://newdiscourses.com/2020/07/complex-relationship-between-marxism-wokeness/">reorder society</a> in the radical way they deem necessary. The belief, as both scholars explain in different ways, is that to play by the existing rules (like conversation and debate as a means to better understand society and advance truth) is to automatically be co-opted by those rules and to support their legitimacy, beside one deeper problem that’s even more significant.</p>
<p>The deeper, more significant aspect of this problem is that by participating in something like conversation or debate about scholarly, ethical, or other disagreements, not only do the radical Critical Social Justice scholars have to tacitly endorse the existing system, they also have to be willing to agree to participate in a system in which they truly believe they <em>cannot</em> win. This isn’t the same as saying they know they’d lose the debate because they know their methods are weak. It’s saying that they believe their tools are extremely good but not welcome in the currently dominant system, which is a different belief based on different assumptions. Again, their game <a href="https://newdiscourses.com/2020/04/narratives-postmodern-democratic-political-regime/">is not</a> our game, and they <em>don’t want to play</em> our game at all; they want to <a href="https://newdiscourses.com/tftw-dismantle/"><em>disrup…</em></a></p></section></div></div></article></main></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newdiscourses.com/2020/07/woke-wont-debate-you-heres-why/">https://newdiscourses.com/2020/07/woke-wont-debate-you-heres-why/</a></em></p>]]>
            </description>
            <link>https://newdiscourses.com/2020/07/woke-wont-debate-you-heres-why/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24019257</guid>
            <pubDate>Sat, 01 Aug 2020 10:07:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Projecting Bitcoin’s Price with Popularity (Google Trends)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24019023">thread link</a>) | @hackernewsreadr
<br/>
August 1, 2020 | https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong><span>A Tale of Two Charts</span></strong></p>



<p>The chart below shows the monthly average <a href="https://www.coindesk.com/price/bitcoin">price of bitcoin</a> since October 2013.</p>



<figure><img data-attachment-id="1238" data-permalink="https://blogofjake.com/image-26/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png" data-orig-size="782,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-26" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" src="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-26.png 782w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=768 768w" sizes="(max-width: 782px) 100vw, 782px"></figure>



<p>This second chart shows the <a href="https://trends.google.com/trends/explore?date=all&amp;q=bitcoin">Google Trends Score</a> by month for the search term “bitcoin”, also since October 2013.</p>



<figure><img data-attachment-id="1239" data-permalink="https://blogofjake.com/image-27/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-27" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-27.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>When I first saw the second chart, I thought it looked remarkably similar to the first. Sure enough, it does. Below are the two charts together. The darker line shows the price according to the left-side axis and the lighter line shows the Google Trends Score according to the right-side axis.</p>



<figure><img data-attachment-id="1240" data-permalink="https://blogofjake.com/image-28/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-28" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-28.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>It turns out that bitcoin’s price and its Google Trends Score are quite correlated.</p>



<p>Specifically, they have had a 72% positive correlation since October 2013. This compares favorably to bitcoin’s <a href="https://cointelegraph.com/news/bitcoins-correlation-with-gold-is-weakening-says-new-kraken-report">26% correlation with the stock market and 24% correlation with gold</a> over the last year.</p>



<p>I should note that the correlation between bitcoin’s price and its Google Trends Score was much stronger up until both price and score peaked in December 2017 (98%) than it has been since (59%).</p>



<p>Nonetheless, the purpose of this analysis is not to argue about the level of correlation nor to assert causation one way or another (though it seems logical that the price and popularity feed off of each other). Rather, the purpose of this analysis is to make a speculative projection regarding what bitcoin’s price could be if and when its popularity (as measured by its Google Trends Score) returns to and surpasses its previous all-time high.</p>



<p>In order to make this projection, we first must consider the historical ratio between bitcoin’s average price and its Google Trends Score on a monthly basis. Let us refer to this as the <em><strong>price:score ratio</strong></em><strong> </strong>for short.</p>



<p><strong><span>Bitcoin’s Price:Score Ratio</span></strong></p>



<p>The chart below shows how bitcoin’s price:score ratio has increased over the last several years.</p>



<figure><img data-attachment-id="1241" data-permalink="https://blogofjake.com/image-29/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-29" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-29.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>For a ratio that has been relatively volatile historically, it has remained unusually consistent for the last two months (June &amp; July) at 729, just 4% short of its all-time high of 758 in November 2019.</p>



<p>Bitcoin’s price:score ratio has been above 645 for 9 of the last 12 months after having only reached such a level once before, and barely (646 in October 2018).</p>



<p>The 3 months in the last year during which the ratio was lower than 645 can be fairly easily explained. They took place this past March, April, and May as hype grew in anticipation of bitcoin’s once every four years halving event on May 11, 2020. Additionally, people perhaps were searching more than usual for information about alternative assets (including bitcoin) when the stock market crashed ~30% in the early days of the lockdown resulting from the pandemic. Those two factors together seem sufficient to explain the uptick in bitcoin’s Google Trends Score over that period. On the other side of the price:score ratio, bitcoin’s price fell along with the market, and so with the price going down and the score going up, the decreased price:score ratio over those few months makes sense.</p>



<p>Since the stock market substantially recovered and the halving event came and went without materially moving bitcoin’s price, the Google Trends Score has returned to the pre-pandemic, pre-halving-hype range. For the last two months (June &amp; July), bitcoin’s monthly Google Trends Score has stayed steady at 13, which is equal to its average from April 2018 (after the peak) through February 2020 (before the halving hype and market crash).</p>



<p>For some additional context, it should be noted that bitcoin’s Google Trends Score has only been equal to or greater than 21 in 7 months since bitcoin’s inception and they all took place consecutively surrounding bitcoin’s last major surge from September 2017 through March 2018 (with scores chronologically of 21, 22, 44, 100, 55, 39, and 23).</p>



<p><strong><span>Flying Under The Radar</span></strong></p>



<p>Sufficed to say, bitcoin’s average score of 13 since the last surge, excluding the three aforementioned months from earlier this year (14 if we include them), shows objectively that bitcoin is flying under the radar (in terms of its popularity as a search term at least). Of course, it may not seem this way to people who follow crypto closely and daily but the algorithmic and mass-data collecting Google Trends Score should be trusted over any single person’s speculative and subjective observation about the current level of hype and attention.</p>



<p>If you, like me, believe that bitcoin is and has been flying under the radar for more than two years now, the natural question to ask is this. What do we expect to happen when that is no longer the case? In other words, what happens to bitcoin’s price if and when it reaches the pinnacle of its next hype cycle? How high might bitcoin fly the next time we see a situation similar to that of December 2017?</p>



<p><strong><span>Projecting Bitcoin’s Price</span></strong></p>



<p>I believe a reasonable response to this question can be made by applying bitcoin’s average price:score ratio over the last twelve months (643) to a Google Trends Score of 100 to estimate what bitcoin’s price would be if the price:score ratio stays about constant and bitcoin’s popularity in terms of search returns to its all-time high. The price implied by this projection is about $65,000 as is demonstrated by the maximum value in the top right corner of the chart below. Basically, if one believes that bitcoin will at least at some point return to the level of popularity it attained in December 2017, this methodology would lead that person to expect bitcoin to attain a price of at least $60,000 at that time.</p>



<figure><img data-attachment-id="1242" data-permalink="https://blogofjake.com/image-30/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png" data-orig-size="783,308" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-30" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-30.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>This estimate can be made less conservative in two ways. The first is to assume that the price:score ratio will continue to increase as it has all along (6% month-over-month), rather than calculating the price using the LTM average of the ratio. The second is to assume that bitcoin’s popularity as a search term will well surpass its previous all-time high set in December 2017 just as that all-time was more than twice as great as any high before it and more than 8 times greater than the all-time high before May 2017 (which was set in December 2013, perhaps not coincidentally exactly 4 years or one halving period prior to the latest all-time high). I hesitate to call either of these two less conservative assumptions aggressive because they are not only reasonable but actually probable if one is to simply assume that the historical trends will continue in terms of the score and the ratio.</p>



<p>As such, I will close by presenting a chart which one can use to approximate the price implied by their own inputs for the Google Trends Score and the price:score ratio. In this chart, I show the ratio for the last 12 months, 2 years, 3 years, and so on, and use the average year-over-year growth rate between those figures (16%) to project the next twelve months (“NTM”), next two years (“N2Y”), and next three years (“N3Y”) ratios.</p>



<p>The highest price projected on the chart is right around $300,000 based on a Google Trends Score of 3 times the previous all-time high (300) and a projected N3Y price:score ratio of 996 (the LTM average of 643 increased 16% 3 times for 3 years). Of course, this maximum price projection is limited only arbitrarily by the maximums I have decided to present on this chart for both the score and the ratio.</p>



<figure><img data-attachment-id="1243" data-permalink="https://blogofjake.com/image-31/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-31" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-31.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p><strong><span>To Be Continued…</span></strong></p>



<p>Many people have employed many methodologies in attempting to accurately project bitcoin’s price. For example, <a href="https://medium.com/@100trillionUSD">PlanB</a>‘s stock to flow ratio looks at scarcity to make one of the more convincing price projections I’ve seen. My price:score ratio looks at popularity in endeavoring to do the same. This analysis was not intended to be totally comprehensive. My intention was merely to introduce this methodology for others to critique. As such, my hope is that this becomes widely enough read so that I may receive ample critical feedback for further consideration and refinement of the methodology.</p>



<p><em>As always, I welcome all outreach to jake@blogofjake.com and any comments on Twitter <a href="https://twitter.com/blogofjake">@blogofjake</a></em></p>
	</div></div>]]>
            </description>
            <link>https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24019023</guid>
            <pubDate>Sat, 01 Aug 2020 09:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you see everything, you'll get nothing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24018973">thread link</a>) | @kiyanwang
<br/>
August 1, 2020 | https://www.jjude.com/focus-to-win | <a href="https://web.archive.org/web/*/https://www.jjude.com/focus-to-win">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Every day, we carry burdens of family, job, and community. We manage the load by breaking them into pieces and put them into a to-do list. The agony of life is that the more tasks we tick off the list, the more added. Running faster seems to be the only way out, so we run faster aided by tools, only to discover at the end of a period that we have been running on a treadmill with ever-increasing speed, going nowhere.</p><p>I have run on the treadmill of tasks with panting of disappointment for more weeks than I can count. For reasons I can't explain, enlightenment in life strikes only at the trough of despair. I was reminded of a story in the great Indian epic, <a href="https://en.wikipedia.org/wiki/Mahabharata">Mahabharata</a>, during one of the downcast days. The story goes like this.</p><p><em>I'm paraphrasing the story here, so if you know the story, allow me some latitude.</em></p><blockquote><p>One day, Drona, the teacher, lines up his students to teach archery. He commands them to focus on a bird on a near-by tree. Every student raised their bow and was ready to shoot. <br>
Before they shoot, he walks over to each student and asks them what they see. <br>
“I see the tree, the branch, and the bird” answers the first student. Drona asks him to put the bow down and stand aside. He moves to the next student. <br>
“Tree, branch, and the bird …” The second student repeats the same answer. And the next, and the next. Finally, Drona approaches Arjuna. “What do you see, my favorite boy?” <br>
“The tip of the arrow and the eye of the bird,” Arjuna replied. <br>
“Do you see the tree and the leaves?” Asked Drona. <br>
“No, just the tip of the arrow and the eye of the bird.” <br>
“Shoot,” commands Drona. <br>
Arjuna releases the arrow and hits the target.</p></blockquote><blockquote><p>Moral of the story: When you want to achieve something, your attention should be on what you have and what you target. Everything else is noise, and you should shut them out.</p></blockquote><p>I'm no archer, but I can transfer the fundamentals to any domain of interest. I started building a system that embodies the principles of the above story. I have used and fine-tuned the system for long, so I feel sure to share it with you. Here are the fundamental principles behind this system:</p><ul><li>Know the outcomes that you want to achieve</li><li>See the outcomes often</li><li>Create projects to reach the outcomes</li><li>Divide each project into weekly wins</li><li>Win a day</li><li>Review to learn, pat, and adjust</li><li>Iterate this cycle to win the outcomes</li></ul><h2 id="know-the-outcomes">Know the outcomes</h2><blockquote><p>It's hard to do a really good job on anything you don't think about in the shower - Paul Graham, <a href="http://www.paulgraham.com/top.html">The top idea in your mind</a></p></blockquote><p><img src="https://cdn.olai.in/jjude/wins-plan.png" alt=""></p><p>We don't stop thinking about our personal life when we enter the office, and we don't stop thinking of our job when we play with our kids. Thus it is futile to try for a balance; rather, we should integrate all areas of our lives to have a fulfilling life.</p><p>After many iterations, I have found <strong>four areas that encompass all of life</strong>, and if I do well in those areas, I would have a fulfilling life. They are <strong>w</strong>ealth, <strong>i</strong>nsights, <strong>n</strong>etwork, and <strong>s</strong>elf-control.</p><p>For each area, I think of one or two outcomes I want to achieve in three years. The outcomes I want to accomplish in each area in the coming three years looks like this:</p><p><strong>Wealth</strong></p><ul><li>Launch Gravitas WINS course</li></ul><p><strong>Insights</strong></p><ul><li>Learn to run a digital business (Gravitas WINS course)</li></ul><p><strong>Network</strong></p><ul><li>Five mentors &amp; Five Thousand Students</li></ul><p><strong>Self-control</strong></p><ul><li>Stay fit and healthy</li></ul><p>All the projects are related, hence it is easier to remember and think about them cohesively. Because they are cohesive, ideas pop into my head during showers or when I take a walk.</p><p>Once I know the outcomes, I divide them further into quarterly projects and weekly milestones. At any quarter, I run only one or two projects. In this quarter, JAS 2020, I am focusing only on two projects:</p><ul><li>Completing the material for the Gravitas WINS course</li><li>Double the subscribers for this newsletter</li></ul><h2 id="win-the-day">Win the day</h2><blockquote><p>Slow is smooth, smooth is fast - Navy SEALs</p></blockquote><p><img src="https://cdn.olai.in/jjude/daily-wins.png" alt=""></p><p>WINS sheet is not a glorified to-do list; it is not even a to-do list by another name. It is a WINS sheet. I enter only those activities that will move me towards the outcome.</p><p>There are always other tasks that I need to do. I do one of the three with those tasks:</p><ul><li>avoid them</li><li>delegate them</li><li>do a good enough job to move on</li></ul><h2 id="reflect-daily--review-weekly">Reflect daily &amp; Review weekly</h2><p>Every day, I reflect on the day that went by.</p><ul><li>Did something catch my attention?</li><li>Did I do something beyond expectation?</li><li>Was I distracted?</li><li>Did I spend too much on movies or YouTube?</li></ul><p><img src="https://cdn.olai.in/jjude/weekly-reflection.png" alt=""></p><p>Every Sunday night, I sit with the sheet and review the previous week.</p><p>There is always a surprise every week. New things pop up; I completed more than I planned; but most weeks, I completed only 80% of what I intended.</p><p>Since the outcome is clear, I am not disappointed even if I have not completed everything I planned. Eighty percent progress every week towards the outcome is a great move forward.</p><p>When I review every week, I get 54 chances to review and amend my ways.</p><h2 id="adjust-as-you-go-along">Adjust as you go along</h2><p>After the Sunday review, I take a print-out for the next week. I write down the three-year outcome and the quarterly projects again. Repeatedly writing the expected results gives me a moment to consider the outcomes and projects in light of what I know.</p><ul><li>Do these outcomes still make sense?</li><li>Are these projects the best way to achieve the outcomes?</li><li>Is there a way to achieve the outcome differently?</li><li>Can I partner with someone to reach the milestone in half the time?</li><li>Can I use any tool to amplify my efforts?</li></ul><p>I go through these questions, and I adjust the outcomes, projects, and weekly wins. Usually, I don't make any changes to outcomes and projects. But there are always changes to weekly wins.</p><h2 id="drown-out-the-noise">Drown out the noise</h2><p>Going through such routine cement the outcomes in my mind. My unconscious mind reflects these outcomes all the time - when I sleep, work out, or take a shower. My mind doesn't think of anything else. So there is clarity when I sit down to do the work.</p><p>That is how I drown out the noise and win the day.</p><h2 id="wins-productivity-system-is-yours-to-have">WINS productivity system is yours to have</h2><blockquote><p>Move forward three things a mile, not hundred things an inch - Alan Weiss</p></blockquote><p>This system has aided me to publish a <a href="https://www.jjude.com/subscribe/">weekly newsletter</a>, write for <a href="https://www.jjude.com/published-articles/">reputed magazines and newspapers</a>, <a href="https://www.jjude.com/talks/">speak</a> in conferences, amidst consulting as a <a href="https://www.jjude.com/cto/">CTO</a> and <a href="https://www.jjude.com/tags/parenting/">being a dad</a> to two amazing boys.</p><p>If this interests you, subscribe using the below form, and you will get the Weekly WINS sheet for free.</p><h3 id="how-did-you-feel-about-this-essay">How did you feel about this essay?</h3><p><a href="https://docs.google.com/forms/d/e/1FAIpQLSfJssJLsZXicJA2tlxPVgVvQswNGOftftRLnySkrZsMNNhO7Q/viewform?usp=pp_url&amp;entry.13661847=Amazing">Amazing</a> • <a href="https://docs.google.com/forms/d/e/1FAIpQLSfJssJLsZXicJA2tlxPVgVvQswNGOftftRLnySkrZsMNNhO7Q/viewform?usp=pp_url&amp;entry.13661847=Good">Good</a> • <a href="https://docs.google.com/forms/d/e/1FAIpQLSfJssJLsZXicJA2tlxPVgVvQswNGOftftRLnySkrZsMNNhO7Q/viewform?usp=pp_url&amp;entry.13661847=Meh">Meh</a> • <a href="https://docs.google.com/forms/d/e/1FAIpQLSfJssJLsZXicJA2tlxPVgVvQswNGOftftRLnySkrZsMNNhO7Q/viewform?usp=pp_url&amp;entry.13661847=Bad">Bad</a></p></div></div>]]>
            </description>
            <link>https://www.jjude.com/focus-to-win</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018973</guid>
            <pubDate>Sat, 01 Aug 2020 09:10:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design System UI Kit for Busy Designers – Available for Sketch, Figma and XD]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24018965">thread link</a>) | @nitishkmrk
<br/>
August 1, 2020 | https://rev.webkul.design/kit/ | <a href="https://web.archive.org/web/*/https://rev.webkul.design/kit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>Ready to fit your existing design workflow.</h2>
            <p>Fully organized components which are available right inside your favorite prototyping tools. Insert,
                edit, and use - it’s that easy.</p>
        </div></div>]]>
            </description>
            <link>https://rev.webkul.design/kit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018965</guid>
            <pubDate>Sat, 01 Aug 2020 09:09:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Engineering != Coding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24018826">thread link</a>) | @FailMore
<br/>
August 1, 2020 | https://taaalk.co/t/software-engineering-coding#q | <a href="https://web.archive.org/web/*/https://taaalk.co/t/software-engineering-coding#q">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <div id="tlk-section-read">
    



<div>

    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I'm a recently trained full stack developer who want's to understand the FULL stack. Right now I think of that as backend + frontend code, but I hear there is more to it than that...</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <div>
  <p>I am the founder of multiple bootstrapped companies. They include web, mobile and infrastructure development agency <a href="https://www.solidstategroup.com/">Solid State Group</a>, virtual office business <a href="https://www.hoxtonmix.com/">The Hoxton Mix</a> and, most recently, developer friendly feature flag tool <a href="https://bullet-train.io/">Bullet Train</a>. I've been involved with many more than that, watching some succeed and others fail.</p>
</div>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

</div>

  </div>







  <div>

      <div id="1">
        <div>
          
          <p>Joshua Summers</p>
          <p>15:58, 26 Jun 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Why did you ask for this?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="2">
        <div>
          
          <p>Ben Rometsch</p>
          <p>12:36, 03 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Right so yes I've spent over 25 years writing software for people in a professional capacity. As time has gone by, and I've learnt more about the process, I've slowly realised that actually writing code is actually quite a small part of the process. When I was a junior developer I probably spent 90% of my working day sat in front of an editor writing code. And I thought that was the job. Turns out it really isn't!Â&nbsp;</p></div><div><p>I think people both inside and outside of the industry fixate on coding for a number of reasons, and it's quite interesting to ruminate on those, but building software is so much more than writing code. Talking to users, agreeing on features, designing the interface, setting up the infrastructure, testing the platform for bugs, testing it for performance, providing support for it. These are all messy, imprecise things that have very human factors.Â&nbsp;</p></div><div><p>If you are a software engineer you can often seek solace in the code itself. Code is truth. You can't really argue with it. You can't argue with your compiler. It's really easy to fall into the trap of avoiding all work other than coding for these very reasons. But I would suggest that this makes you a really bad engineer! Engineering means getting your hands dirty, either literally in the case of Brunel, or from a human interaction point of view where software is concerned.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="3">
        <div>
          
          <p>Joshua Summers</p>
          <p>14:15, 10 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So you are sort of saying that an engineer solves problems, and problems are experienced (mostly) by people, so to solve problems effectively you a) have to deal with people and b) have to really know how to solve the problem (e.g. dealing with infrastructure, performance, etc.) instead of only the parts you are comfortable with. Is that correct?</p></div><div><p>How much of this comes down to the attitude of the engineer? And how much of this comes down to actively studying?Â&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="4">
        <div>
          
          <p>Ben Rometsch</p>
          <p>10:22, 13 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>In my experience, almost 100% of that learning comes from hard won experience.Â&nbsp;</p></div><div><p>When I studied at university, I was really surprised to discover that the "Computing" courses that I was interested in were labelled as "Software Engineering". I thought it was odd at the time; I never really had thought it about it before, and I was even a bit worried that I might have been signing up for the wrong course!Â&nbsp;</p></div><div><p>I don't think many universities at the time offered "Computer Science" as an undergrad course; it's a very different discipline.Â&nbsp;</p></div><div><p>It took me a LONG time to get my head around the fact that one of the words in the job was "engineering". And really the only way I realised that was after years of working building software. At some point the penny dropped that I was an engineer, and that writing code was only 1 aspect of that job.Â&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="5">
        <div>
          
          <p>Joshua Summers</p>
          <p>12:00, 15 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So based on your experience, where do you feel the greatest value lies in the spectrum of what it means to be an engineer? Or is it person dependent?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="6">
        <div>
          
          <p>Ben Rometsch</p>
          <p>12:21, 17 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>There are a number of things that people starting off in a career of Software Engineering should try and keep in mind.</p></div><div><div><ol>
<li>Never stop learning. Software development is still a very immature discipline. I like to think about it like building jet aeroplanes. After the jet engine was invented, flying on a jet passenger plane was pretty dangerous! Google "the de Havilland Comet". There was so much new engineering that needed to be learnt to get to the point where now it is pretty much the safest mode of transport in the world. The software industry is still building de Havilland Comets to a certain degree. So much is being learnt in terms of best practices, what works and what doesn't. If you don't constantly learn new things, you will be left behind.</li>
<li>You know less than you think. You can wield great power writing software and it can go to your head! Good engineers are humble and never think they either know it all or know better than others.</li>
<li>Stretch yourself. If you know an OOP language, learn a functional one like Elixir or Haskell. If you have spent a lot of time with a very high level language like Python, try Rust. Think of it like a gym. The machine you cant stand the site of is probably the one doing you the most good.</li>
<li>It is an art as well as a science. There is room for beauty and elegance in software.</li>
</ol></div></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="7">
        <div>
          
          <p>Joshua Summers</p>
          <p>16:43, 27 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>I sort of feel swamped by things that I don't know, almost to the point of paralysis.</p></div><div><p>I'm new to Ruby on Rails and know that there is a huge ocean of knowledge that I could keep swimming in, but then again I'm competent enough to build this reasonably functioning Taaalk website. I look at React, which might help me get a job, and unlike with Rails, I know none of that currently. And then there are tangential things, for example improving my git skills.</p></div><div><p>It feels confusing, especially without a job where problems to solve aren't put in your plate. And it feels confusing because I can doÂ&nbsp;<em>enough to create</em>. I could probably build most things in my mind with Rails and a standard html.erb + scss front end... but while I would learn something, I wouldn't be learning in leaps and bounds in the same way I was when I was learning Ruby/Rails for the first time. I guess what I'm saying is that, in some ways, my ability to create is separated from my need to make drastic educational strides - so it is confusing to know what to focus on.</p></div><div><p>If you were in my shoes what would you be optimising for? Does it seem obvious from where you're sitting?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="8">
        <div>
          
          <p>Ben Rometsch</p>
          <p>15:36, 30 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>A good rule of thumb for things like personal projects. If you want to learn something new, build the project with new tools, languages and frameworks. If you want to actually build a project, use what you know. So it depends what the point of the project is. I guess if you want to do both you have to just accept that it will take longer using whatever new shiny stuff youâ€™re using.Â&nbsp;</p></div><div><p>Tech and software engineering has always been obsessed with the new thing. People just canâ€™t help themselves! Itâ€™s fine if youâ€™re just working by yourself and playing around with a new language or framework, but if you are making those decisions on behalf of an employer with a large team, you can easily burn millions of pounds by making the wrong choice. The hard part of all this is making consistently right choices given varying contexts and requirements.Â&nbsp;</p></div><div><p>This goes back to what I was saying about engineering. It is not just coding. Itâ€™s the ability to understand a new technology, digest what is good and bad about it, consider it subjectively and then make a decision based on all that information. Good engineers will be good at that, and will be opinionanted about it as well. Being careful and conservative when they need to be, and working on the cutting edge when it makes sense.Â&nbsp;</p></div><div><p>I would recommend not trying to do 4 new things at once. So if you want to learn Flutter or React Native, donâ€™t then something totally foreign for the backend API. Just take it one step at a time. That way you will strike a balance between the fear and excitement of learning something new, and without the admitted drudgery of knocking out features that have no interesting aspects.Â&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>

  </div>








  

  





    </div></div>]]>
            </description>
            <link>https://taaalk.co/t/software-engineering-coding#q</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018826</guid>
            <pubDate>Sat, 01 Aug 2020 08:41:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ASK HN : Please teardown my Landing Page before the LAUNCH in 2 days.]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24018822">thread link</a>) | @pauljeba
<br/>
August 1, 2020 | https://www.gox.ai/two-minute-reports/ | <a href="https://web.archive.org/web/*/https://www.gox.ai/two-minute-reports/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div> <div><p>Monitoring business metrics is a pain in the ***.</p><p>We all would like a “Crystal ball” that helps us see through our product, operations, customers and sales performance. One, that continuously adapts to our business – sends us beautiful reports, tracks business health, all while pointing out what’s working and what’s not working for our success. </p><p>So for many years, we believed tools like Tableau, Tibco Spotfire, Microsoft BI would bless us with such wizardry.</p><p>But they didn’t.<br>They wasted MASSIVE amounts of our time and resources. Not just that – they slowed us down, frustrated the developers and required constant maintenance. </p><p>Now, tracking business metrics feels like a chore, rather than a joy. Something we don’t prioritise enough and fall behind on. </p><p>So good news, <br>Introducing Two-Minute-Reports, a simple and flexible, no-headache business analytics software. </p><p>It’s a redo, a rethink, a simplified, potent reintroduction that makes data tracking beautiful and an effortless one. A fresh start, the way it should be. </p><p>It’s so simple that it runs inside your Google Sheets with no developer or infrastructure dependency. </p><p>Try us – 15 days for free and get 30 days money back guarantee on all paid plans.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.gox.ai/two-minute-reports/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018822</guid>
            <pubDate>Sat, 01 Aug 2020 08:40:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing vs. Quality Assurance vs. Quality Control What’s the Difference?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24018653">thread link</a>) | @AnuGeorge
<br/>
August 1, 2020 | https://testsigma.com/blog/testing-vs-quality-assurance-vs-quality-control-whats-the-difference/ | <a href="https://web.archive.org/web/*/https://testsigma.com/blog/testing-vs-quality-assurance-vs-quality-control-whats-the-difference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>A product, an application, a website, the success of all these do depend on the functionalities built into them. But answer to some questions like “How easy they were to use? How easy were they to understand? Did they do the job without any errors?”, ‘quality’ becomes the most important factor of it all.</p>



<p>A developer may build the functionality but a tester determines the quality of the software and how well they were built.</p>



<p>Google defines Quality as “the standard of something as measured against other things of a similar kind; the degree of excellence of something”.&nbsp;</p>



<p>Thus, quality for obvious reasons is a very important aspect of any product or service. It, clearly, can be highly subjective. To remove the ambiguity around quality, it becomes essential to set up methods and processes to define or verify the quality of a product for the people involved in making the product and for the people who use the product.</p>



<p>When we talk about quality in terms of a software application, we also hear the term ‘Testing’&nbsp; a lot. They seem to be used interchangeably.&nbsp;</p>



<p>But it is not just about Testing or just about Quality, is it? There are more terms like Quality Assurance and Quality Control which again are quite often confused with Testing.&nbsp;</p>



<p>In reality, these three are supposed to be different yet related to each other and form different parts of the quality management cycle. In this blog, we will take a look at these 3, their importance and how they can be used to make the product better.</p>



<h2><strong>What is Quality Assurance?</strong></h2>



<p><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.yourdictionary.com/quality-assurance" target="_blank">Yourdictionary.com</a> defines quality assurance as “A system for evaluating performance, as in the delivery of services or the quality of products provided to consumers, customers, or patients.”</p>



<p>Quality Assurance(QA) is a standard process set up by an organization to meet quality standards. This process helps to avoid mistakes and defects in the end delivered product and services to customers. </p>



<p>QA is the foundation pillar for quality management as it focuses on the integrity of the product. It also provides confidence to stakeholders that desired and mentioned requirements are fulfilled.&nbsp;</p>



<h2><strong>What is Quality Control?</strong></h2>



<p>Quality Control is defined as “the process of setting standards and testing to make sure something, like a product or service, is done correctly.”</p>



<p>The goal of quality control is to check whether the prescribed model was followed or not. It can be achieved by performing audits and determining whether the team followed the defined model to attain quality.</p>



<h2><strong>Origin</strong></h2>



<p>Both Quality Assurance and Quality control are interrelated. They are essential parts of quality management protocols followed by an organization. Initially, Quality control started to be followed in the 1920s by the manufacturing industry. </p>



<p>The Quality control guidelines need to be put in place as the manufacturing industry demands the same replicas of the original product in bulk without any variations. The Quality control process helps them check if the desired requirements were met without committing any mistakes.</p>



<p>With passing years, more research work and Growing technology made the manufacturing process more complex.&nbsp; This made the Quality control process even more complex. </p>



<p>This made the organization define a proper quality control process and ensure it is being followed throughout the development of that particular unit.</p>



<p>In the 1950’s, The process of&nbsp; Quality Control was further extended in the manufacturing unit by performing&nbsp; Quality Assurance checks and Audits. The major areas of focus were the sectors related to public health and safety.&nbsp;</p>



<p>The idea behind “Assurance” was to randomly select any manufactured piece from the batch and check if it meets the desired requirement. If the piece is found to meet the requirement it is passed. </p>



<p>If the piece did not match the exact requirement but was within defined range it may be passed. If it is found out of defined range, it has to be rejected and can lead to immediate stopping of the manufacturing process and starting it all over again from scratch leading to loss of money and time.</p>



<p>Quality control focuses on auditing the project and checking if defined guidelines and protocols were followed while manufacturing or not.</p>



<h2><strong>Quality Control: What role quality audits and inspection play in product development?</strong></h2>



<p>Quality Audits are the onsite evaluation of a process to ensure their compliance with the requirements. They are performed under the supervision of an auditor who checks whether set guidelines were practised during the making of the product.</p>



<p> Audits are not about checking the product quality but to inspect the type of work done in making a product. It evaluates how closely the prescribed model was followed. Are there any variations? If yes, then the reason behind variations?</p>



<p>The objective of audits is to continuously improve the quality of the work henceforth increasing product quality. Inspection can be one of the aspects of Audit.&nbsp;</p>



<p>The inspection examines the traits of a product. It checks how well the product fits requirements, are there any variation between developed product and desired product. If yes, it will fit the requirement or not. How many load/stress products can handle? Which adverse situation can make it crash?</p>



<p>In short, the audit is all about examining the quality of the process used while making a product. Inspection is about examining how well the product fits the requirement provided by stakeholders.</p>



<p>Quality and inspection are being practised in a wide variety of industries such as software, manufacturing, automobile, retail, etc. to ensure a standard procedure and practice is being followed by all. </p>



<p>As in bulk manufacturing, any deviation from the standard procedure might lead to mistakes which can result in loss of a huge amount of money and time.</p>



<h2><strong>What is Testing?</strong></h2>



<p><a href="https://testsigma.com/automated-testing" target="_blank" rel="noopener noreferrer">Testing</a> is the process to check if the designed product behaves as required when subjected to various conditions.&nbsp;</p>



<p>The requirements are documented in the form of test cases. The tester verifies and validates the product. If the product requirement under test behaves as expected, the test case is marked as pass or else fail. </p>



<p>The defect is raised by the tester for the failed scenarios and assigned to the developer. Once the defect is fixed by the developer again the requirement is tested to verify the fix and the corresponding case is passed. It is important to have these feedback loops at every stage of the product delivery lifecycle.</p>



<p>By documenting requirements and corresponding testing results, we get a clear picture of how testing is progressing, what procedures are being followed, what is pending, what is the current success rate. Some of the pointers which are&nbsp; defined by testing are:</p>



<p>1. Code and function coverage</p><p>2. The traceability matrix helps define each requirement and has at least one case mapped to it.&nbsp;</p><p>3. percentage of automation vs. manual testing&nbsp;</p><p>4. number of test case executed</p><p>5. Total number of cases passed</p><p>6. Total number of cases failed</p><p>7. The number of defects raised and fixed.</p>



<p>The testing process cannot be subjected to one model as they are various kinds of tests that a product undergoes. Each type of testing has different goals to fulfil. For example, <a href="https://testsigma.com/regression-testing/functional-regression-testing" target="_blank">Functional testing</a> will only check for the conformance to requirement. </p>



<p>Whereas, non-functional testing will check other aspects of requirements such as how an application would behave when subjected to heavy load. </p>



<p>Hence, it is almost impossible to follow one model throughout testing and achieve the desired result. If you try following one model throughout testing scope they are high chances of missing on some essential requirements.</p>



<h2><strong>How testing can help make your product better?</strong></h2>



<p>Testing is documenting each requirement in the form of scenarios and verifying it. Good testing requires a lot of thoughtful work and experience. </p>



<p>Experience makes you understand the requirement better and helps design crisp and clear test cases without missing on any requirement. A good test case should include both positive and negative scenarios.</p>



<p>Each documented requirement is tested. The first step to good testing activity is proper communication. Communication should not be limited to documents being mailed back and forth. </p>



<p>It should involve an open conversation. Each member of the team can speak to anybody and clear their doubts. This helps ensure all team members are on the same page.</p>



<p>Healthy team environment also assures good testing.&nbsp; If coordination is lagging between teammates the problem needs to be addressed and fixed. </p>



<p>Good testing checks what impact any newly introduced or suggested way of working can bring to the existing system and how it can help the team and users in a better way.</p>



<p>Good testing challenges assurance. It checks for all possibilities and their outcomes. The testing activity should be incorporated from the requirement phase as it helps provide better feasibility of requirements, what assumptions to be made, how products can be tested effectively, what cannot be tested, etc.&nbsp;</p>



<p>Good testing provides an excellent end product that in turn yields high customer satisfaction. Thus, fulfilling the goal of Quality management system. </p>



<p>Hence, to deliver an apt end product testing plays a key role in the development of the product. Without testing, it would be difficult to say that a developed product is bug-free and right.</p>



<p>Early testing, often testing and performing as much as possible is the only key for a high customer satisfaction rate and application to be a success. Continuously working on customer feedback, testing and delivering the product as per their need is the only way to thrive in a competitive market.</p>



<h2><strong>Finally, what is the relationship between QA, QC and Testing</strong>?</h2>



<p>To sum up, Quality assurance makes sure that correct processes are set up to get a quality product as a result. This also …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://testsigma.com/blog/testing-vs-quality-assurance-vs-quality-control-whats-the-difference/">https://testsigma.com/blog/testing-vs-quality-assurance-vs-quality-control-whats-the-difference/</a></em></p>]]>
            </description>
            <link>https://testsigma.com/blog/testing-vs-quality-assurance-vs-quality-control-whats-the-difference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018653</guid>
            <pubDate>Sat, 01 Aug 2020 08:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gall’s Law]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24018317">thread link</a>) | @MindGods
<br/>
August 1, 2020 | https://matthiasott.com/notes/galls-law | <a href="https://web.archive.org/web/*/https://matthiasott.com/notes/galls-law">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
			<!--  -->


<article>
		<header>

		

		
	</header>

	<section itemprop="articleBody">

		
		
	    	    				    		      	    	<p>In 1963, the people at NASA needed a building. And not just any building. It had to be large enough to be able to assemble the enormous space vehicles NASA designed as part of their massive effort to send astronauts to the Moon. The building that was completed in 1966 allowed for the <em>vertical</em> assembly of rockets like the Saturn V, and it is to this date the largest single-story building in the world. Located at Kennedy Space Center in Florida, the “Vehicle Assembly Building” (VAB) is <a href="https://www.nasa.gov/centers/kennedy/pdf/718659main_VAB.pdf">160 meters tall, 218 meters long, and 160 meters wide</a>, with a volume 3.75 times that of the Empire State Building, and built to withstand hurricanes. The building is a vast and complex system that includes five overhead cranes used to pick up the heaviest elements of rockets and to place them carefully into position ahead of launch. It also has the largest doors in the world, through which the rockets roll to the launch pads.</p>

<p>Yet, after the Vehicle Assembly Building was completed, it had a surprise in store: It creates its own weather. The building is so vast that, on very humid days, rain clouds form below the ceiling and about 10,000 tons of air conditioning equipment are needed to control the moisture inside. And so it only takes one hour to completely replace the air in the building. Although, rumor has it that the folks at NASA often just leave the doors open…</p>

														
	    	    																    		    						
				            <section>
        
					<figure>
													<div>
																<picture>
										<!--[if IE 9]><video style="display: none;"><![endif]-->
										<source data-srcset="/assets/pictures/_standardImage1536/NASA-VAB-Saturn-V-rollout.jpg 1536w, /assets/pictures/_standardImage768/NASA-VAB-Saturn-V-rollout.jpg 768w" data-sizes="auto">
										<!--[if IE 9]></video><![endif]-->
										<img data-src="/assets/pictures/_standardImage768/NASA-VAB-Saturn-V-rollout.jpg" alt="Nasa Vab Saturn V Rollout" src="https://matthiasott.com/assets/pictures/_standardImage768/NASA-VAB-Saturn-V-rollout.jpg">
								</picture>
															</div>
			      			      						<figcaption>
			    	<p>Aerial view of the Apollo 11 Saturn V rollout from the Vehicle Assembly Building. 20 May 1969. <em>Image: NASA, research by J. L. Pickering.</em></p>

			    	</figcaption>
			    			    	</figure>
				
				            </section>
        	    	
					
	    	    				    		      	    	<p>That a building can have its own weather is not only a good story to start a blog post with, but it also teaches us something about the nature of complex systems: They come with unintended consequences and unexpected behavior. “The larger the system, the greater the probability of unexpected failure,” <a href="https://en.wikipedia.org/wiki/John_Gall_(author)">John Gall</a> wrote in <em>General Systemantics</em>, his seminal book about how systems work – and how they fail. In the book, <a href="https://archive.org/details/systemantics00john/">which can be borrowed from the Internet Archive</a>, Gall offered many principles of systems design, especially with regards to complex systems. One of those principles has become known as Gall’s Law:</p>

														
	    	    												<figure>
				<blockquote><p>A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple&nbsp;system.</p>
</blockquote>
					      <figcaption>John Gall, <cite>General Systemantics</cite> </figcaption>
	      	    </figure>
								
	    	    				    		      	    	<p>He might have a point here: Many of the complex systems around us that work, weren’t designed from scratch. They evolved from a simpler system, a basic set of rules and conventions. Nation-states, companies, the World Wide Web – it would have been impossible to design them in all their complexity without failing miserably. And history has seen countless failed attempts at designing complex systems, from <a href="https://urbanutopias.net/2019/06/01/le-corbusier/">Le Corbusier’s radically geometric ideas for urban planning</a> to <a href="https://www.curbed.com/2019/6/7/18657121/brasilia-brazil-urban-planning-architecture-design">the utopia that is Brasilia</a> to the sinking of the Titanic.</p>

<p>So when you set out to design a system, whether it is a business, a team, its workflows, a website, or a design system, it is good to remember Gall’s Law. A complex system designed from scratch never works. Start with the simplest system you can come up with and enhance it incrementally. Don’t overspecify, but leave enough room so that connections and structures can evolve and grow over time. Loose systems last longer and work better. Lastly, be aware that your system might fail at any time. At least, <a href="https://en.wikipedia.org/wiki/Murphy%27s_law">anything that can go wrong will go wrong</a>, right? So also ask yourself: <a href="https://vimeo.com/217697727">How well does it fail?</a> </p>

<p>Designing a simple system is much harder than designing a complex system. But at least you might end up with a system that actually works.</p>

<p>-</p>

<p><em>This is the 49th post of my 100 days of writing series. <a href="https://matthiasott.com/notes/100-days-of-writing">You can find a list of all posts here</a>.</em></p>

																<p>~</p>
		
	</section>
	
	    
	    			
	    <section>
						<h2>4 Webmentions</h2>
				  		  		  									
  
  		  		  							<h3>Likes</h3>
							<article>
			<figure>
								<a href="https://twitter.com/mattosurf" title="Matt O'Leary">
					<img src="https://matthiasott.com/assets/pictures/avatars/93fc2c2be3e9af8ebe0b36c93d1ecc23625a3c1e.jpg" alt="Photo of Matt O'Leary">
				</a>
								<figcaption><a href="https://twitter.com/mattosurf">Matt O'Leary</a><a href="https://twitter.com/m_ott/status/1289350784593858560#favorited-by-122052466"><time datetime="2020-08-03 02:54:00"></time></a></figcaption>
				
			</figure>
					</article>
		  		    
  							<h3>Reposts</h3>
							<article>
			<figure>
								<a href="https://matthiasott.com/" title="apple-touch-icon-120x120.pngMatthias Ott">
					<img src="https://matthiasott.com/assets/pictures/avatars/bbf492161ad1be44b0c7d85228de63fc387f3c76.png" alt="Photo of apple-touch-icon-120x120.pngMatthias Ott">
				</a>
								<figcaption><a href="https://matthiasott.com/">apple-touch-icon-120x120.pngMatthias Ott</a><a href="https://matthiasott.com/notes/100-days-of-writing"><time datetime="2020-08-03 02:54:00"></time></a></figcaption>
				
			</figure>
			
					</article>
		  						<article>
			<figure>
								<a href="https://matthiasott.com/" title="apple-touch-icon-120x120.pngMatthias Ott">
					<img src="https://matthiasott.com/assets/pictures/avatars/bbf492161ad1be44b0c7d85228de63fc387f3c76.png" alt="Photo of apple-touch-icon-120x120.pngMatthias Ott">
				</a>
								<figcaption><a href="https://matthiasott.com/">apple-touch-icon-120x120.pngMatthias Ott</a><a href="https://matthiasott.com/notes/100-days-of-writing"><time datetime="2020-08-03 02:54:00"></time></a></figcaption>
				
			</figure>
			
					</article>
		  		  		  	</section>
	    
						
			
							
	

 


</article>
	</div></div>]]>
            </description>
            <link>https://matthiasott.com/notes/galls-law</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018317</guid>
            <pubDate>Sat, 01 Aug 2020 07:01:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to correctly ask a customer how much they are willing to pay]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24018272">thread link</a>) | @alfahad
<br/>
July 31, 2020 | https://theunconventional.blog/how-to-survey-product-pricing/ | <a href="https://web.archive.org/web/*/https://theunconventional.blog/how-to-survey-product-pricing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://theunconventional.blog/content/images/size/w300/2020/07/pricing1.jpg 300w,
                            https://theunconventional.blog/content/images/size/w600/2020/07/pricing1.jpg 600w,
                            https://theunconventional.blog/content/images/size/w1000/2020/07/pricing1.jpg 1000w,
                            https://theunconventional.blog/content/images/size/w2000/2020/07/pricing1.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://theunconventional.blog/content/images/size/w2000/2020/07/pricing1.jpg" alt="How to correctly ask a customer how much they are willing to pay">
            </figure>

            <section>
                <div>
                    <p><strong><em>We can take advantage of the way humans think about value.</em></strong></p><p>We know that the computer you are using is <strong>worth more</strong> than the water bottle that is on the table. That is just something we inherently know. <strong>Why?</strong> Because we probably purchased water in the past, we recognize the price of a computer. We understand that we get more value out of the computer than the bottle of water. Every human has a built-in value meter in which we value products (or services!) comparatively.</p><p>Now, assume I put you in the middle of the desert and don't give you water for two days. Suddenly the value of the water bottle climbs to the top of your value meter.</p><hr><p>When you ask a person directly what they are willing to pay for a bottle of water, they refer to their value meter. They give you an answer based on expectation and comparison rather than on how much they may potentially value it. This happening makes it hard for a person to admit the real value of your product.</p><p>This phenomenon occurs when your product is an innovation, without valid comparisons, or if the value your product provides is much higher than any substitutes available on the market. The customer suddenly does not have an accurate thermometer to measure your product against, and will often give you a much lower price point when asked directly.</p><p>Economists and psychologists have studied this phenomenon for a long time. There are many techniques to gather information on the world-famous question for any startup: <strong>How much should I price my product?</strong></p><p>We can take advantage of this phenomenon by asking the customer indirect questions on a range.</p><hr><p>One of my favorite techniques, which I believe works very well, is the <strong><a href="https://en.wikipedia.org/wiki/Van_Westendorp%27s_Price_Sensitivity_Meter">Van Westerndorp method</a></strong>, also known as the Price Sensitivity Meter technique. Its a series of 4 simple questions you can ask your customers to determine a price range at which your product pricing matches your offering's real value. </p><p>What better way then to put those questions on a survey and ask enough people. If you survey, say, 150 potential customers, you will discover a pretty accurate price range determined by consumer value. Simple enough? Let's get started.</p><p>The first step is to <strong>make sure that customers understand your product</strong>. Consider giving customers a demo, sharing a video, or showing them detailed pictures of your product. You could include this at the top of your survey. For our purposes, let us take a picture of this yummy Gyro. Since a picture is worth a thousand words, I think it would do quite well to price this Gyro.</p><figure><img src="https://theunconventional.blog/content/images/2020/07/gyro.jpg" alt="" srcset="https://theunconventional.blog/content/images/size/w600/2020/07/gyro.jpg 600w, https://theunconventional.blog/content/images/2020/07/gyro.jpg 700w"><figcaption>Let's price this Gyro.</figcaption></figure><!--kg-card-begin: markdown--><blockquote>
<ol>
<li>The first question you would ask is, at what particular price point is this Gyro way <strong>too expensive</strong> that you would never consider purchasing it?</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>Then you would ask at what specific price point is this Gyro <strong>getting expensive, but you would still consider</strong> buying it?</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>At what price point is this Gyro a really <strong>good deal</strong>?</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>And, At what point is this Gyro <strong>too cheap</strong> that you'd question its quality?</li>
</ol>
</blockquote>
<!--kg-card-end: markdown--><p>Notice the answers would give us a range of prices rather than one fixed price. By answering in ranges, people tend to let go of their value spectrum and instead determine the boundaries of how valuable the product is to them. This technique is, by far, one of the most accurate ways of determining your products true value-based price through a survey.</p><p>Looking at the data for 30+ users, we would get a cumulative graph as shown below.</p><figure><img src="https://theunconventional.blog/content/images/2020/07/PSM-graph-ready.png" alt="" srcset="https://theunconventional.blog/content/images/size/w600/2020/07/PSM-graph-ready.png 600w, https://theunconventional.blog/content/images/2020/07/PSM-graph-ready.png 933w" sizes="(min-width: 720px) 720px"><figcaption>Gyro Survey Results</figcaption></figure><p>From the results of the survey above, (about 30 entries at the time of this article.) We notice that the optimal value-based price range is between $2.5 and $3.5. At $2.5, the Gyro has approximately 15% of people who think its both expensive and too cheap. The optimal price would be the intersection of "too expensive" and "too cheap" at $3. Of course, this is just an indication of pricing and based purely on the people you have surveyed!</p><p>For anyone interested, I have created the Gyro survey <a href="https://forms.gle/EML2DwbiaEgFQWoe8">here</a> &nbsp;(feel free to take it!). I have set up a live updating-pricing <a href="https://bit.ly/2X0wQoZ">worksheet</a> to go along with it.</p><p><strong>Feel free to make a copy for your own product pricing journey, and good luck with your product pricing adventures.</strong></p>
                </div>
            </section>

                <section>
    <h3>Subscribe to The Unconventional Blog</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://theunconventional.blog/how-to-survey-product-pricing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018272</guid>
            <pubDate>Sat, 01 Aug 2020 06:50:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gimp is working on its own version of “smart objects”]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24018269">thread link</a>) | @pmoriarty
<br/>
July 31, 2020 | https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/ | <a href="https://web.archive.org/web/*/https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>The GIMP team recently informed me that the next upcoming version of GIMP will be GIMP 2.10.22 (no GIMP 3.0 just yet – womp). Though there has been no official announcements of specific features to come in this next version, there has been one feature announcement in particular that has caught my eye – the “<strong>linked layers</strong>” feature.</p>



<h2>Linked Layers – GIMP’s Answer to Photoshop’s Smart Objects?</h2>



<p><a href="https://twitter.com/zemarmot/status/1286952087558004738?s=20" target="_blank" rel="noreferrer noopener">GIMP quietly announced (via a retweet)</a> that the <a href="https://patreon.com/zemarmot?utm_medium=social&amp;utm_source=twitter&amp;utm_campaign=creatorshare" target="_blank" rel="noreferrer noopener">ZeMarmot team</a> was working on a new feature they are calling the “Linked Layers” feature (note: this has nothing to do with the “transform link” feature already found in GIMP).</p>



<p>In fact, work for this feature actually began in July 2019 (about a year ago) but, due to limited developers working on GIMP, this feature was shelved until recently.&nbsp;</p>



<p>Jehan from ZeMarmot, who recently revisited development on this feature, described the application of Linked Layers in this way: “What if you wanted to use the same background in several images? Instead of duplicating it, you could just link it from all images using it. And if you edit a bit your common background, it would automatically update the render of all images.”</p>



<p>Sound familiar?&nbsp;</p>



<p>To me, this sounds like GIMP’s version of “Smart Objects” – the popular Photoshop feature that allows you to “link” a different file to your composition, then have that file live update in your current composition any time you make changes to it. This has many applications – especially in the world of creating universal templates that can be updated with your own design (by simply replacing the “linked image” with your own design, then re-saving that image). <strong>This is huge.&nbsp;</strong></p>



<figure><img data-attachment-id="13511" data-permalink="https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/linked-layers-test-gimp-smart-objects-2/" data-orig-file="https://i0.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg?fit=820%2C511&amp;ssl=1" data-orig-size="820,511" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Linked-Layers-Test-GIMP-Smart-Objects-2" data-image-description="" data-medium-file="https://i0.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg?fit=300%2C187&amp;ssl=1" data-large-file="https://i0.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg?fit=820%2C511&amp;ssl=1" src="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg" alt="" srcset="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg 820w, https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2-480x299.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 820px, 100vw" data-recalc-dims="1" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg" data-srcset="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg 820w, https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2-480x299.jpg 480w"><figcaption><em>How linked layers would work (image from <a href="https://youtu.be/N5oyqbD7zyQ">ZeMarmot test video</a>)</em></figcaption></figure>



<p>It would work like this in GIMP: you would create a new layer, and under “Fill With” you choose “Image Link” (red arrow in the image above). Choosing this option would bring up an option to select an image to link the layer to on your computer (blue arrow). You then select your image, and click “OK” to create your new layer. The layer is now linked to the image on your computer. If you were to then open that image in GIMP and make edits to it, the edits would automatically update in the linked layer inside your other composition.</p>



<h2>Why GIMP’s Linked Layers Will Be Just As Good As Photoshop’s Smart Objects</h2>



<figure><img data-attachment-id="13510" data-permalink="https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/linked-layers-test-gimp-smart-objects/" data-orig-file="https://i2.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg?fit=850%2C346&amp;ssl=1" data-orig-size="850,346" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Linked-Layers-Test-GIMP-Smart-Objects" data-image-description="" data-medium-file="https://i2.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg?fit=300%2C122&amp;ssl=1" data-large-file="https://i2.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg?fit=850%2C346&amp;ssl=1" src="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg" alt="" srcset="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg 850w, https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-480x195.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 850px, 100vw" data-recalc-dims="1" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg" data-srcset="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg 850w, https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-480x195.jpg 480w"><figcaption><em>In this photo, which is from <a href="https://youtu.be/N5oyqbD7zyQ">ZeMarmot’s video demo-ing the linked layers feature</a>, you can see a new layer thumbnail/icon (red arrow) indicating that the layer is linked to another image.</em></figcaption></figure>



<p>Some of you are wondering how this feature would keep pace with Photoshop’s well-established “Smart Objects” feature. In Photoshop, not only can you link a layer from one composition to a layer or image from another composition, but you can also link vector objects from Adobe Illustrator as a layer in Photoshop, and edit that vector object essentially in real-time in either program and have the quality of the vector object remain intact.</p>



<p>Well, GIMP’s “linked layers” will do the exact same thing – using Open Source alternatives, of course. This feature will be integrated with Inkscape so that, for example, you can link a vector composition to a GIMP layer, and have the GIMP layer scale up without quality loss the way any vector object would in Inskcape. <strong>This is mind-blowing.</strong> You could also make updates to the vector file in Inkscape, and those changes would then refresh inside of the linked layer in GIMP. It would essentially create a dynamic link between the two programs.</p>



<p>Here is a <a href="https://youtu.be/N5oyqbD7zyQ">video ZeMarmot released showing this new “linked layers” feature in action.</a> This isn’t just a pipe-dream or concept yet to be implemented – it’s a feature they’ve demonstrated to work in a test-version of GIMP. </p>



<p>If GIMP can successfully get linked layers to work in a stable release version of GIMP, the internet, myself included, will lose its mind. And, once again, GIMP will have successfully taken a bite out of Adobe’s photo editing software lead (still without charging its users a dime).</p>



<p>In my opinion, some form of “smart object” functionality is one of the top 3 features missing in GIMP (and one of the top 3 things I get comments about on my videos – especially when doing PS vs. GIMP comparisons). Stay tuned – I will provide more information on this feature as it comes out (hopefully via a video tutorial if they get the feature implemented in one of the new release-versions of GIMP).</p>



<p>If you want to help speed up the development of this and other cool new features in GIMP, I recommend supporting the <a href="https://patreon.com/zemarmot?utm_medium=social&amp;utm_source=twitter&amp;utm_campaign=creatorshare">ZeMarmot team on Patreon</a> so they can spend more time on GIMP development and less time on other jobs to pay their bills.</p>




</div></div>]]>
            </description>
            <link>https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018269</guid>
            <pubDate>Sat, 01 Aug 2020 06:49:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Notification Timeline Using React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24017852">thread link</a>) | @atapas
<br/>
July 31, 2020 | https://blog.greenroots.info/a-notification-timeline-using-react-ckdb6o0yp00wy59s16les9bjn | <a href="https://web.archive.org/web/*/https://blog.greenroots.info/a-notification-timeline-using-react-ckdb6o0yp00wy59s16les9bjn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>It's been a while I have done much with <a target="_blank" rel="noopener noreferrer" href="https://reactjs.org/">React</a>. When I was trying it out with simple state management, in-built hooks, basic styling and managing events, I thought, why not to build something useful? That's when the idea of building a simple, light-weight <code>notification-timeline</code> came into my mind.</p>
<p>So what is notification-timeline? </p>
<ul>
<li>As the name indicates, it notifies you sooner a notification arrives.</li>
<li>It helps you in reading through your notifications in timed sorted manner. That's where the timeline comes from.</li>
<li>You can mark the notifications as read.</li>
<li>You can identify what notification was received and when. </li>
<li>Few more customization capabilities that we will discuss bit later.</li>
</ul>
<p>How does it look?</p>
<ul>
<li><p>The basic look and feel contains a bell icon along with a number of unread notifications for you to look into.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1596200894152/IAyZ5bz-i.png?auto=format&amp;q=60" alt="1.png"></p>
</li>
<li><p>You click on the bell icon to open up a pop-over to read the notifications and mark them as read, if required.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1596196428932/MY3VUo_vo.png?auto=format&amp;q=60" alt="2.png"></p>
</li>
</ul>

<p>In this article, I am going to explain some source code at the high level. Please stick to it. I am sure, you will have some take-away from it. </p>
<p>In case, you want to get to the code or the demo early, here are the details:</p>
<h2 id="demo">Demo</h2>
<p>You can access the demo from here: <a target="_blank" rel="noopener noreferrer" href="https://notify-timeline.netlify.app/">https://notify-timeline.netlify.app/</a></p>
<h2 id="source-code">Source Code</h2>
<p>All the Source Code are here in the git repo.  If you like the work, please show your support with a star for the repo.</p>


<p>Did you know, this component is also <a target="_blank" rel="noopener noreferrer" href="https://www.npmjs.com/package/react-notification-timeline">available as a npm</a>? Yeah! you can download and install it using,</p>
<pre><code>npm i react-notification-timeline
</code></pre>
<p>or</p>
<pre><code>yarn add react-notification-timeline
</code></pre>
<p>Once installed, it can be imported into your React project as,</p>
<pre><code><span>import</span> NotifyMe <span>from</span> <span>'react-notification-timeline'</span>;
</code></pre>
<p>Use the component as,</p>
<pre><code>&lt;NotifyMe
  data={data}
  storageKey=<span>'notific_key'</span>
  notific_key=<span>'timestamp'</span>
  notific_value=<span>'update'</span>
  heading=<span>'Notification Alerts'</span>
  sortedByKey={<span>false</span>}
  showDate={<span>true</span>}
  size={<span>64</span>}
  color=<span>"yellow"</span>
/&gt;
</code></pre>
<p>For more details about the properties and customizations, please <a target="_blank" rel="noopener noreferrer" href="https://github.com/atapas/notifyme#properties">read it from here</a>.</p>
<p>Please give it a try and let me know how it goes. Almost nothing is bug free! Feel free to be a contributor if you would like to find-try-fix bugs or add features to it. You are most welcome.</p>

<p>Thank you for reading through so far! This section of the article is going to explain few important parts of the source code and the basic logic around it. <a target="_blank" rel="noopener noreferrer" href="https://github.com/atapas/notifyme/blob/master/NotifyMe.js">Here</a> is the direct link to the component file.</p>
<h2 id="first-is-the-data">First is the data</h2>
<p>The <code>notification-timeline</code> component expects data in the following format,</p>
<pre><code> [
     {
       <span>"update"</span>:<span>"70 new employees are shifted"</span>,
       <span>"timestamp"</span>:<span>1596119688264</span>
     },
     {
       <span>"update"</span>:<span>"Time to take a Break, TADA!!!"</span>,
       <span>"timestamp"</span>:<span>1596119686811</span>
     }
  ]
</code></pre>
<p>The object must have two properties.</p>
<ul>
<li>timestamp: The timestamp of the time a message was generated. This must be of type long that represent a timestamp value.</li>
<li>update: The message to show as notification.</li>
</ul>
<p>Note: The key names, <code>timestamp</code> and <code>update</code> can be customized as explained in the <a target="_blank" rel="noopener noreferrer" href="https://github.com/atapas/notifyme#properties">properties section</a>.</p>
<h2 id="states-to-manage">States to manage</h2>
<p>The hook <code>useState</code> returns a pair. First is the current state and second is an updater function. We usually take advantage of  <code>array destructuring</code> to assign the values. The initial state value can be passed using the argument. </p>
<p>The notification component manages few states using <code>useState</code>,</p>
<ul>
<li>To show the unread message count<pre><code> <span>const</span> [showCount, setShowCount] = useState(<span>false</span>);
</code></pre>
</li>
<li>How many unread messages<pre><code> <span>const</span> [messageCount, setMessageCount] = useState(<span>0</span>);
</code></pre>
</li>
<li>To show the message panel on click of the bell icon<pre><code> <span>const</span> [show, setShow] = useState(<span>false</span>);
</code></pre>
</li>
<li>To set the click target of the message panel<pre><code> <span>const</span> [target, setTarget] = useState(<span>null</span>);
</code></pre>
</li>
<li>To maintain a read index. This is to determine, how far the messages were read so that the unread messages can be shown with a different style.<pre><code> <span>const</span> [raedIndex, setReadIndex] = useState(<span>0</span>);
</code></pre>
</li>
</ul>
<h2 id="handle-the-side-effects">Handle the side effects</h2>
<p>The hook <code>useEffect</code> is used for handling any sort of side effects like, state value changes, any kind of subscriptions, network requests etc. It takes two arguments, first a function that will be invoked on the run and, an array of the values that will run the hook. </p>
<p>It runs by default after every render completes. However we can make it run whenever a particular value changes by passing it as the second parameter. We can also make it run just once by passing an empty array as the second parameter.</p>
<p>Notification component handles the side effect of the data changes. Whenever a new notification arrives, the data gets muted and we need to handle this side effect.</p>
<pre><code>useEffect(() =&gt; {
        <span>if</span> (!sortedByKey) {
            data.sort((a, b) =&gt; b[key] - a[key]);
        }

        <span>let</span> readItemLs = reactLocalStorage.getObject(storageKey);
        <span>let</span> readMsgId = <span>Object</span>.keys(readItemLs).length &gt; <span>0</span> ? readItemLs[<span>'id'</span>] : <span>''</span>;

        <span>let</span> readIndex = (readMsgId === <span>''</span>) ? data.length : 
                           data.findIndex(
                               elem =&gt; 
                                   elem[key] === readMsgId);


        readIndex === <span>-1</span> ? readIndex = data.length : readIndex;
        setReadIndex(readIndex);

        (data.length &amp;&amp; readIndex) &gt; <span>0</span> ? 
            setShowCount(<span>true</span>) : setShowCount(<span>false</span>);
        setMessageCount(readIndex);

    }, [data]);
</code></pre>
<p>On data change,</p>
<ul>
<li>Check and sort by timestamp, if required.</li>
<li>We track the last read message by adding the timestamp of it into the local storage. We check if any last read item id is in the local storage.</li>
<li>We set the message count, last read index accordingly.</li>
</ul>
<h2 id="the-render-part">The render part</h2>
<p>Last, the render part. We have a bell icon that shows the unread message count and method to handle the click event.</p>
<pre><code>&lt;div className=<span>"notification-container"</span>&gt;
    <span><span>&lt;<span>div</span> <span>className</span> = 
              {
                 <span>showCount</span> ? 
                   '<span>notification</span> <span>notify</span> <span>show-count</span>' <span>:</span> 
                       '<span>notification</span> <span>notify</span>'
               }
           <span>data-count</span>=<span>{messageCount}</span>
            <span>onClick</span>=<span>{event</span> =&gt;</span> handleClick(event)}&gt;
                    <span>&lt;<span>Bell</span> <span>color</span>=<span>{bellColor}</span> <span>size</span>=<span>{bellSize}</span> /&gt;</span>
     <span>&lt;/<span>div</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span></span>
</code></pre>
<p>Important to note here, we use the <code>data-*</code> attribute to embed custom data. In this case it is the unread message count using the <code>data-count</code> attribute. Read more about HTML data-* attribute <a target="_blank" rel="noopener noreferrer" href="https://www.w3schools.com/tags/att_global_data.asp">from here</a>.</p>
<p>Next, the <code>handleClick()</code> method handles to show the pop-over with the notification messages. To do that, we just need to update couple of states,</p>
<pre><code>
<span>const</span> handleClick = (event) =&gt; {
    setShow(!show);
    setTarget(event.target);
}
</code></pre>
<p>That's all for covering all the important parts here. I have used <a target="_blank" rel="noopener noreferrer" href="https://feathericons.com/">feather icons</a> for the bell icon and <a target="_blank" rel="noopener noreferrer" href="http://react-bootstrap.github.io/">react bootstrap</a> for the message pop-over component.</p>

<p>I would like to enhance the code better as in, I can make it more precise and short. There are lots of scope to improve this component with additional features like,</p>
<ul>
<li>Showing total message count.</li>
<li>Mark as unread.</li>
<li>Limiting the total number of notifications and flush out.</li>
<li>Read/Unread Selected notification messages.</li>
<li>Delete all the notification messages.</li>
<li>Better persistence hook, other than the browser local storage.</li>
<li>Better look-and-feel.</li>
</ul>
<p>That's all for now. I am happy to share my learning with you and that's motivates me further to learn more.</p>

<p>If it was useful to you, please Like/Share so that, it reaches others as well. To get e-mail notification on my latest posts, please subscribe to my blog by hitting the <strong><em>Subscribe</em></strong> button at the top of the page. You can also follow me on twitter <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/tapasadhikary">@tapasadhikary</a>.</p>
<p>The cover photo is an improvisation on top of the awesome work by <a target="_blank" rel="noopener noreferrer" href="https://www.freepik.com/vectors/background">freepik</a>.</p>
</div></div>]]>
            </description>
            <link>https://blog.greenroots.info/a-notification-timeline-using-react-ckdb6o0yp00wy59s16les9bjn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017852</guid>
            <pubDate>Sat, 01 Aug 2020 05:14:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Default to tabs instead of spaces for an 'accessible first' environment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24017590">thread link</a>) | @edent
<br/>
July 31, 2020 | https://alexandersandberg.com/tabs-for-accessibility/ | <a href="https://web.archive.org/web/*/https://alexandersandberg.com/tabs-for-accessibility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  
    
  

  <span>
  
    #<a href="https://alexandersandberg.com/dev/">dev</a> / 
  

  
    published july 11th, 2019
  
</span>

  
    
    <p>I’m sure you’ve come across the age-old, opinion-based debate of ‘Tabs vs. Spaces’ for <em>indentation</em> before. It has been going since forever, and there seem to be valid reasons for both sides:</p>
<p><strong>Tabs…</strong></p>
<ul>
<li>smaller files because it’s just 1 character</li>
<li>that’s what they’re used for</li>
<li>you can customize your own indentation width (👈 keep this one in mind)</li>
</ul>
<p><strong>Spaces…</strong></p>
<ul>
<li>to avoid problems in whitespace-sensitive environments</li>
<li>because you know what you’ll get, and consistency is key</li>
</ul>
<p>But, there’s more to this than just personal preferences. <a href="https://www.reddit.com/user/ChaseMoskal">u/ChaseMoskal</a> recently posted a very insightful and eye-opening post on Reddit with the title <a href="https://www.reddit.com/r/javascript/comments/c8drjo/nobody_talks_about_the_real_reason_to_use_tabs/">“Nobody talks about the real reason to use Tabs over Spaces”</a>.</p>
<h2 id="the-one-real-reason-to-use-tabs-over-spaces">The one real reason to use tabs over spaces</h2>
<p>In his post, Chase explains his own experience of using spaces at his workplace, and the negative effects it had on co-workers with visual impairment.</p>
<p>One of his co-workers uses a tab-width of <code>1</code>, to avoid huge indentations when using a large font-size.</p>
<p>Another co-worked of his is using a tab-width of <code>8</code> because that works best for his situation with a wide monitor.</p>
<blockquote>
<p>I see people saying “tabs lets us customize our tab-width”, as though we do this “for fun” — Chase</p>
</blockquote>
<p>By using tabs in our projects, we allow these kinds of customizations that are <em>essential</em> for people with visual impairment. Custom tab-widths might seem like an unnecessary thing to most, but some people rely on it—and we <em>can not</em> ignore that.</p>
<h2 id="accessible-first">Accessible first</h2>
<p>We simply can’t “convert” everyone to one side or the other, there’s no question about it. Everyone has their own preferences, and we should celebrate that freedom—that we have the ability to make our own choices.</p>
<p>But with that said, we should also make sure to include <em>everyone</em>, and that means respecting and using accessible tools like the Tab-character.</p>
<p>Much like designing for ‘mobile first’—making sure everyone, no matter what device, has a great experience with your product—we should create an ‘<strong>accessible first</strong>’ environment, by making sure that everyone has the same ability to work, whether it’s at the workplace or on an open-source project.</p>
<p>I thought Chase put it perfectly when he said in his post that <em>"…there’s just no counter-argument that even comes close to outweighing the accessibility needs of valued coworkers”</em>.</p>
<h2 id="conclusion--accessible-first-personal-preference-second">Conclusion — Accessible first, personal preference second</h2>
<p>By defaulting to tabs, we make sure that everyone has a great experience working together with others, no matter their own abilities.</p>
<p>And if you prefer spaces, feel free to use an auto-formatting tool that converts tabs to spaces when opening a file (all modern editors have these). Just make sure that the spaces get converted back to tabs before anyone else has to work on your code.</p>
<blockquote>
<p>Only by making sure everyone has the same capability can we maximize our combined potential ❤️</p>
</blockquote>
  
</article></div>]]>
            </description>
            <link>https://alexandersandberg.com/tabs-for-accessibility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017590</guid>
            <pubDate>Sat, 01 Aug 2020 04:24:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned from doing over 60 technical interviews in 30 days]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24017555">thread link</a>) | @bolajiayodeji
<br/>
July 31, 2020 | https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky | <a href="https://web.archive.org/web/*/https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this article, I’ll share my motivation for doing 60+ technical interviews in 30 days. More importantly, I’ll share 13 lessons I learned from my failures and my successes.</p>
<p>I’ve grouped the lessons into three categories to match the phases of a typical recruitment process.</p>
<p>While most of the lessons apply directly to software engineers and technical professionals, the principles behind these lessons can be applied to all careers. I hope you find something useful that you can apply to your professional lives.</p>
<h2 id="how-did-i-get-started-">How did I get started?</h2>
<blockquote>
<p> “If you’re going to fail, do it fast.” — Unknown</p>
</blockquote>
<p>Like any other software engineer, I’ve had different types of technical interviews - from the dreaded whiteboard coding interview to the unreal 45-minute coding challenge on platforms like HackerRank. While some of my experiences in these interviews were great, others were bad. Really bad.</p>
<p>But I wanted to get really good at interviewing. I wanted to learn to overcome the interviewing phobia and exude confidence at interviews. Like a skilled surfer, I wanted to learn to ride the high pressure waves that came with interviews. I was also looking to change jobs at the time.</p>
<p>So from January through early March 2020, I applied to and was contacted by companies based in the US and Europe. From early-stage startups like Coda to later stage startups like Crunchbase, from mid-size companies like Affirm, to bigger companies like Amazon and even remote companies like Webflow.</p>
<p>109+ applications later, I landed myself more than 60 interviews. These comprised more than 60 introductory phone interviews, 50+ technical phone screen interviews, 18 take-home coding projects, 11 coding challenges and 8 on-site interviews including 3 virtual ones.</p>
<h2 id="what-did-i-learn-">What did I learn?</h2>
<p>For better appreciation, I have grouped the lessons into three categories to match the different phases of a typical recruitment process.</p>
<h3 id="pre-interview-phase">Pre-Interview Phase</h3>
<p>This covers everything from the initial contact with a company to the point where the first interview happens.</p>
<h4 id="1-what-i-learned-about-applications">1. What I learned about applications</h4>
<p>When I started applying to companies, I imagined that the more applications I submitted, the higher my chances of getting an interview would be. Seems logical, huh? So I set a target of 5 applications a day, aiming for 1 interview for every 5 applications.</p>
<p>But my strategy didn’t work as I hoped it would. The number of interview requests I got often fell short of my target. It was almost a 1:12 ratio - 1 interview for every 12 applications.</p>
<p>I was faced with the question: do I need to increase my daily target to, say, 10 companies? Or was there something else I needed to change?</p>
<p>With every unsuccessful application, I saw that something needed to change.</p>
<p>That change came when I took a break from meeting my daily numbers and began to think of my applications differently. I began to see each application as a sales pitch to the hiring manager or whoever was going to be reading my application, but here the product being sold was me.</p>
<p>If a company needed to fill a talent gap and I say I had the skills, I needed to find a way to convince them that I did.</p>
<p>My new task then became to find a way to effectively pitch my unique skills, experience and personality in a way that convinced the hiring manager that I was the right fit for the job.</p>
<p>Here is an example of one of such <em>pitches</em> I came up with:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1596030331456/A8nDIn-ih.png?auto=format&amp;q=60" alt="body image.png"></p>
<p>Backed with my resume, this cover letter had a 95% success rate. The one time this didn’t work, the hiring manager still replied to let me know that the position was no longer available but he would like to connect in the future.</p>
<p>The lesson here is, be very intentional about the application you put forward – quality over quantity. Better still do both. Know your unique competencies and experience and present them in a way that matches the company’s needs without sacrificing your personality.</p>
<p>It is also important to understand the peculiarity of the company you are applying to and its specific needs. A startup or a smaller-sized company may have different needs from a bigger company, thus requiring a different skill-set.</p>
<p>Sell yourself and be sure to back your sales pitch during the interview.</p>
<h4 id="2-what-i-learned-about-recruiter-in-mails">2. What I learned about recruiter in-mails</h4>
<p>During this period, I received a number of in-mails from recruiters (mostly unsolicited) for open roles, the majority of which were roles I wasn’t interested in.</p>
<p>Granted, it was sometimes a lot given my busy schedule but I learned to be empathetic, understanding that these recruiters were only trying to do their jobs.</p>
<p>I stopped seeing these in-mails as noise in my inbox and started making the effort to reply to all recruiter in-mails, even for positions I was not interested in. By doing this, I succeeded in building a network of recruiters that have become a rich resource if I have to switch roles in the future.</p>
<p>Now I don’t expect you may want to start replying to every in-mail you receive. But it might interest you to know that some of the interview requests I got were from recruiters I had replied to before for roles I wasn’t interested in. It never hurts to reply.</p>
<h3 id="the-interview-phase">The Interview Phase</h3>
<p>This covers everything about the interview itself, cutting across the different interview types.</p>
<h4 id="3-how-to-handle-introductory-phone-calls">3. How to handle introductory phone calls</h4>
<p>Yes I get it, you’re busy and many things are competing for your time. But hey, you are also an excellent professional, and that means you never get on a phone call without knowing at least these two things:</p>
<ul>
<li>the first name of your interviewer, and</li>
<li>at least one tangible thing about the company — what they do, where they are located, any recent news, something, anything!</li>
</ul>
<p>I noticed that for interviews where I put in the effort to make these findings, I always came across as being genuinely interested in the company. That’s something recruiters typically look for in these kinds of interviews.</p>
<h4 id="4-how-to-handle-technical-phone-screens">4. How to handle technical phone screens</h4>
<p>The one thing that can almost single-handedly decide how well you do in a technical phone screen interview is your ability to communicate your thoughts clearly.</p>
<p>You may have heard stuff like this before:
“<em>The interviewers care about your thought process. Yes they can see your code but importantly, they want to know why you are doing what you’re doing</em>.”</p>
<p>The interviewer isn’t there with you and so does not have the luxury of seeing other non-verbal cues like your hand gestures or nuances. All the interviewer has is your voice as a means of understanding your thought process.</p>
<p>Now you know how you should lead this conversation, the next question is how do you become good at this? Because the truth is, while expressing your thoughts may come naturally to some people, it doesn’t to others – including me.</p>
<p>So – Practice! Practice!! Practice!!!</p>
<p>Practice doing a lot of mock interviews. Doing these mock interviews with friends made me better and more confident in explaining my thought process. But more interestingly, it helped me develop a new mindset about interviews.</p>
<p>I began to see interviews as a conversation with a friend or a team member. I visualized the interviewer on the other end as one of my friends (I sometimes gave the interviewer a name in my head). So what would have been a high-pressure interview I now saw as a friendly ‘chat’ about a technical problem.</p>
<p>This new mindset, aided by the many practice interviews, helped me grow in confidence so much so that I started enjoying interviews, sorry, technical chats.
How to get started on a problem</p>
<p>Never start solving a problem without fully understanding the problem statement. You are almost never wrong if you start by asking clarifying questions. It’s also a good sign to your interviewer when you ask those questions rather than run with your assumptions.</p>
<h4 id="5-how-to-solve-the-problem">5. How to solve the problem</h4>
<p>Good candidates know how to solve a problem (e.g. a sorting problem), but the best candidates know multiple solutions to a problem and understand the trade-offs of one solution versus the other.</p>
<p>The interviews where I performed the best (Cruise comes to mind) are the ones where I didn’t just solve the algorithmic challenge – I was also able to provide alternative solutions and discuss the trade-offs.</p>
<p>Aim to provide multiple solutions to a problem, be willing to discuss the trade-offs, and be able to implement at least one of them.</p>
<p>For technical interviews, write clean code. Most interviewers care about your code quality as well as the correctness of your solution. Aim for modular code, separate reusable logic into utility functions, name variables and methods properly, and just be a boss!</p>
<h4 id="6-what-to-do-when-you-re-stuck-on-a-problem">6. What to do when you’re stuck on a problem</h4>
<p>There will be times when you’re stuck. And this could be caused by a number of reasons: you don’t have the requisite knowledge, incorrect assumptions, missing details, and so on.</p>
<p>I used to think that at such times I was being judged by how fast I could come up with a solution. So I would be quiet, thinking, not communicating with the interviewer, just thinking.</p>
<p>And this is where a lot of us get it wrong. I get it, you need some alone time to think. But sorry to burst your bubble, that alone time is not when you’re being interviewed by a person.</p>
<p>Yes, your interviewer wants to see that you can come up with a solution, but one thing you must not forget is that they also want to see that <strong>you can collaborate with other team-mates to come up with a solution</strong>. While companies want rock-stars, they also want team-players.</p>
<p>Since your interviewer is a friend, a buddy, a team member who’s on your side and means well for you (Refer to 4), talk to them while you're figuring it out.</p>
<p>Share your thought process up till the point you got stuck and do it confidently, not like some cry for help. By doing so you just may uncover the solution, as was the case during my interview with Coda.</p>
<h4 id="7-how-to-handle-coding-challenges">7. How to handle coding challenges</h4>
<p>The lessons here apply to interviews that take the form of coding challenges on platforms like Hackerrank, Codility, and so on. Typically these are timed challenges, say 45 minutes or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky">https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky</a></em></p>]]>
            </description>
            <link>https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017555</guid>
            <pubDate>Sat, 01 Aug 2020 04:19:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get started on Flipped classroom in the digital space]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24017079">thread link</a>) | @xueyongg
<br/>
July 31, 2020 | https://blog.phuaxueyong.com/post/2020-08-01-benefits-challenges-of-flipped-classroom/ | <a href="https://web.archive.org/web/*/https://blog.phuaxueyong.com/post/2020-08-01-benefits-challenges-of-flipped-classroom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><span><p>Are you a teacher seek to be more effective on the virtual space as COVID forces us onto the internet? As I was looking for other educational tools, I found the flipped classroom concept really interesting or even kinda radical. As technology evolves and become more integrated with our lives, we have to find ways to leverage on the strengths of technology to enable us to do more with less. For example, to reach out to more students with less time. Teach more concepts with less classroom time. Have you heard of flipped classroom and what does it mean? We will find out today!</p>

<p>Here’s a video I find really descriptive to help you kickstart your understanding of this pedagogical approach:</p>

<p>
<iframe src="https://www.youtube.com/embed/qdKzSq_t8k8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p>In this article, we will be going through the following sections:</p>
<br>
<ol>
<li>What is Flipped classroom?</li>
<li>What is technology’s role?</li>
<li>Benefits of Flipped classroom</li>
<li>How to get started?</li>
<li>Challenges of flipped classroom</li>
<li>Alternatives - What are you solving?</li>
</ol>

<p>Before we begin, I would like to give a shout out to <a ref="nofollow" target="_blank" href="http://exploreily.wordpress.com/">exploreily</a> for putting together insightful and meaningful articles across many blogs across the world. I’m also featured in their blog as well, so check them out!</p>

<p>Lets dive in first to understand what is Flipped classroom.</p>
<br>
<hr>
<br>
<h2>#1. What is Flipped classroom?</h2>

<p>The flipped classroom pedagogical approach has two key spaces: the group space which we know as the classroom, and the individual learning space which is student’s personal time outside of classroom.</p>

<p>Flipped classroom essentially moves the group learning such as content teaching from classrooms to their own individual learning space aka outside of classroom. Once that content teaching is done outside of the classroom, your classroom time can now be transformed into a dynamic, interactive learning environment which students can engage these learnt concepts creatively.</p>

<p><img src="https://blog.phuaxueyong.com/img/2020-08-01-benefits-challenges-of-flipped-classroom/flipped-classroom-overview.jpg" alt="flipped classroom overview"> <em>The flipped purpose of group and individual time</em></p>
<br>
<blockquote>
<p>Flipped classroom is a “pedagogical approach in which direct instruction moves from the group learning space to the individual learning space, and the resulting group space is transformed into a dynamic, interactive learning environment where the educator guides students as they apply concepts and engage creatively in the subject matter" (The Flipped Learning Network, 2014)</p>
</blockquote>
<br>
<hr>
<br>
<h2>#2. What is technology’s role?</h2>

<p>Before we delve right into the benefits of flipped classroom, one has to ask herself:</p>
<br>
<blockquote>
<p>“What is the role of technology in this radical teaching pedagogy?”</p>
</blockquote>

<p>While flipped classrooms are possible without the use of digital content, we want to leverage on the ability to “create once, used a million times”. Create a good content that follows your own curriculum and many teachers can leverage of the digital resource; freeing up their classroom time for other forms of teacher-student engagements.</p>

<p>Some of the key benefits includes Scalability &amp; Flexibility. Your content and your teaching can reach many more students on-demand. It can be repeated if students needs to revisit the explanation. It can be streamed and played at their own time outside of class when they feel most productive. There is flexibility in the pace students can now take to learn. There is scalability on these contents being reused.</p>
<br>
<hr>
<br>
<h2>#3. Benefits of Flipped classroom</h2>
<br>
<ol>
<li>Students can now learn at their own pace as videos can be watched again</li>
</ol>

<p>The lecture contents, in forms of manageable length videos, can be provided for outside of classrooms. We allow the traditional passive learning to take place outside of the classroom. This will free up time to have more meaningful engagement with the students - clarifying learning points, additional learning objectives can be accomplished through active learning.</p>
<br>
<ol start="2">
<li>its more efficient, as students are more prepared to contribute in the classroom</li>
</ol>

<p>As students are more prepared for classrooms, so are their accountability for learning. Students are charged to come for class prepared. Thus their own responsibility and accountability for their own learning is increased.</p>
<br>
<ol start="3">
<li>It enriches the classroom as more time can be spent on group work and projects</li>
</ol>

<p>When the traditional learning takes place outside of classroom time, the classroom now has the potential to turn into a workshop that incorporates and focuses on active hands on learning. With flipped classroom, active learning approach becomes the core component rather than a supplementary to the lectures.</p>
<br>
<ol start="4">
<li>Doing homework in class allows students to help each other. Helping the advance and less advance learners</li>
</ol>

<p>As the class becomes more interactive and bi-directional, suddenly we find space for students to step up. As students are now charged to help their weaker students, the classroom can starts to function like a family -  or even a small society. Each with a common goal, but having different interactions and forms to teach different needs; Each students now play a responsibility of adding onto the educational experience of their peers. It feels safe, and it feels like the ideal we would like to impart</p>
<br>
<blockquote>
<p>The classroom can serve as an example of what the world should look like—all&nbsp;students with equal power, regardless of their culture or background—rather than a replication of what it is.</p>
</blockquote>
<br>
<ol start="5">
<li>Flipped classroom allows teachers to target students who really needs help instead of those who are just confident</li>
</ol>
<br>
<ol start="6">
<li>Flipped classroom allows teachers to guide by the side instead of teaching at the front.</li>
</ol>
<br>
<ol start="7">
<li>Teachers who are not good presenters can use third-party videos to explain concepts and focus on teaching styles that best suit them such as project work or experiments. Once presented and recorded, teachers don’t have to teach the concept over and over again. They gain more time to focus on the needs of the class.</li>
</ol>
<br>
<ol start="8">
<li>It promotes equal learning opportunities as all kids get the same attention when doing their homework; either through the teacher or their more advanced classmates.</li>
</ol>

<p>This includes the support for diversity in student learning styles. For example, in addition to lecture students may reflect on materials through questions and discussions with the classroom facilitators. If they are more comfortable with their peers, they can also learn by working with their classmates to solve problems, demonstrating and arguing their own solutions to class experiments and work.</p>
<br>
<hr>
<br>
<h2>#4. How to get started?</h2>

<p>There are many tools out there for one to leverage on. You can also reference my post of the educational tools that are available for us</p>
<br>
<h3>1. Decide what technology you will use</h3>

<p>I’ve also taken the time to curate a list of highly useful technology to facilitate discussions and flipped classroom’s content sharing. It can be the use of videos to do your digital lecture or it could be through the use of games. These are merely tools that allows you to put up your own content based on your own curriculum and syllabus for students. Whichever the tool, find one that is best for your use case; straight forward and easy with lowest barrier to entry.</p>

<p>Check out the <a ref="nofollow" target="_blank" href="https://blog.phuaxueyong.com/post/2020-07-25-top-10-educational-tools/">Educational tools</a>!</p>
<br>
<h3>2. What video service are you going to use?</h3>

<p>Now once you consider your technology, you have to then decide if you want to utilize a low technology or high technology approach. Low technology could mean simply just a 5mins video of you teaching the content from a particular topic. You can just upload your video on Youtube and then reference that using the video’s URL.</p>

<p>High technology approach will use an application that will capture both your audio and also your computer screen. This allows you to reference visual resources while you walk through the content. You can use powerpoint or basically any form of visuals that will aid your teaching.</p>

<p>Once you have considered this approach and have created your own video. Now you have to figure out which video service do your students have access to? Do you want your videos to be public or private.</p>

<p>Ultimately, the most common choice will <strong>Youtube</strong>. It is highly accessibly across devices, they have friendly UX that even toddlers are able to navigate the application even before they can talk</p>
<br>
<h3>3. Set up your virtual class!</h3>

<p>From the educational tools, one of the effective tool to create your class workflow is “eduflow”. It allows you to create your own segments of your class. First we will watch videos, then we will have a forum to answer a question “what have you learnt about algebra”. Now you can review your peer’s answers and check if they are correct or wrong.</p>

<p>Below is a screen record of my own personal trying of eduflow to create a class curriculum on space exploration!</p>
<br>

<br>
<h3>4. Find out more information on educational technology forums</h3>

<p>As the world evolves to embrace technology in the educational space, communities of people coming together to put together great ideas, experiences, and expertises on remote learning and flipped classroom concepts.</p>

<p>Listed below are some of the ed-tech forums with active communal discussions:</p>
<br>
<ul>
<li><a ref="nofollow" target="_blank" href="https://twitter.com/edtechforum?lang=en">Twitter edtechforum</a> is one such platform for teachers to come together to share</li>
<li><a ref="nofollow" target="_blank" href="https://www.reddit.com/r/edtech/">Reddit edtech</a> <em>There are discussions about the educational space</em></li>
</ul>

<p>Below is a small guide on how to get started on your remote teaching experience for each of your class.</p>

<p><img src="https://blog.phuaxueyong.com/img/2020-08-01-benefits-challenges-of-flipped-classroom/1.jpg" alt=""></p>

<p>Here’s also an interesting Youtube video on how to get started on flipped learning as well:</p>

<p>
<iframe src="https://www.youtube.com/embed/ma_aCjs_pzE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<br>
<hr>
<br>
<h2>#4. Challenges of Flipped classroom</h2>

<p>Not all implementations come without its challenges. As we are showered with the benefits of flipped classroom and the amount of classroom time freed up from rogue learning and transformed into interactive discussion and application of concepts, there are still challenges that may create inertia or even stiffen teacher’s adoption of flipped classroom.</p>
<br>
<blockquote>
<p>No, you’re not the only one facing these problems</p>
</blockquote>
<br>
<h3>1. Faculty buy-in</h3>

<p>Since facilitators are the ones to persuade or require students to watch the online videos or complete class readings before the class. If the faculty members are not onboard to share and work upon this expectation on students, theres a good chance that students will not come prepared.</p>

<p>As …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.phuaxueyong.com/post/2020-08-01-benefits-challenges-of-flipped-classroom/">https://blog.phuaxueyong.com/post/2020-08-01-benefits-challenges-of-flipped-classroom/</a></em></p>]]>
            </description>
            <link>https://blog.phuaxueyong.com/post/2020-08-01-benefits-challenges-of-flipped-classroom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017079</guid>
            <pubDate>Sat, 01 Aug 2020 03:16:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple iCloud – please stop bugging me]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24017071">thread link</a>) | @cjlovett
<br/>
July 31, 2020 | https://lovettchris.github.io/posts/apple_upsell/ | <a href="https://web.archive.org/web/*/https://lovettchris.github.io/posts/apple_upsell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<article>
			<div>
				<div>
					<div>
						

<p>Anyone else tired of these annoying popups?</p>

<p><img src="https://lovettchris.github.io/posts/apple_upsell/icloud_installer.png" alt=""></p>

<p>I’m getting pretty tired of all this… I actually tried to find customer support for the PC
installer popup, but no luck. Anyone know who owns this ugly little Windows app? I find it
particularly devious that Apple uses language here that sounds like something is broken until I
“Install” their fix. This is not a fix, this is an upsell to get iCloud on my PC.</p>

<p>The iPhone backup message is also annoying. I tried to tell my iPhone to stop backing up my photos,
and yet I still get this backup failed warning every day. Perhaps Apple should find a more creative
way to upsell my on iCloud because this is driving me nuts, and making it much less likely I’ll
ever checkout the benefits of paying Apple for cloud storage on stuff I’ve backed up my self lots
of other ways.</p>

<p>Apple is world class on user experiences of everything else, so why are they so bad at this
experience? I’m guessing the part of the company that expertly squeezes every dime out of consumers
is not so connected to the user experience gods at Apple… Here’s hoping I can wake up some of
those gods to go slap the accountants on the wrist for this naughty behavior.</p>

<p>-Chris.</p>

					</div>
				</div>
			</div>
		</article>
	</div></div>]]>
            </description>
            <link>https://lovettchris.github.io/posts/apple_upsell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017071</guid>
            <pubDate>Sat, 01 Aug 2020 03:14:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking the Pleroma: Elixir, Phoenix and a Bit of ActivityPub]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24017031">thread link</a>) | @todsacerdoti
<br/>
July 31, 2020 | https://wimvanderbauwhede.github.io/articles/hacking-pleroma/ | <a href="https://web.archive.org/web/*/https://wimvanderbauwhede.github.io/articles/hacking-pleroma/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" itemprop="articleBody">
				<p><a href="https://pleroma.social/">Pleroma</a> "is a microblogging server software that can federate (= exchange messages with) other servers that support the same federation standards (OStatus and ActivityPub). What that means is that you can host a server for yourself or your friends and stay in control of your online identity, but still exchange messages with people on larger servers. Pleroma will federate with all servers that implement either OStatus or ActivityPub, like GNU Social, Friendica, Hubzilla and Mastodon." <a href="https://blog.soykaf.com/post/what-is-pleroma/">(stolen from Lain's blog post)</a>.</p>

<p>Recently I modified my Pleroma instance to support bot services: parse a posted message, take an action, post the result. To get there I had to learn <a href="https://elixir-lang.org/">Elixir</a>, the language in which Pleroma is written, as well as <a href="https://hexdocs.pm/phoenix/overview.html">Phoenix</a>, the web framework Elixir uses, and a little bit about ActivityPub, the protocol for exchanging messages. What I want to explain here in particular is the architecture of Pleroma, so that you can hack it more easily, for fun or if you want to participate in the development.</p>

<h2>Elixir</h2>

<p>As Pleroma is written in <a href="https://elixir-lang.org/">Elixir</a> you'll need to learn that language to some extent. If you are familiar with Ruby (or Perl, for that matter) and with the idea of functional programming (everything is a function), then it is quite easy to learn and understand. The <a href="https://hexdocs.pm/elixir/">documentation</a> and <a href="https://elixir-lang.org/getting-started/introduction.html">guides</a> are very good. </p>

<p>If you've never hear of functional programming, the main difference with e.g. Ruby or Java is that Elixir does not use an object-oriented programming model. Instead, there are functions that manipulate data structures and other functions. A particular consequence of the functional model is that there are no for- or while-loops. Instead, there are what is called higher-order functions which e.g. apply another function to a list. Elixir programs also make a lot more use of recursion. </p>

<p>Another point about Elixir as a web programming language is that it is built on a system where processes communicate by passing messages to one another, and it is  built in such a way that if a process dies it will normally be restarted automatically. This approach makes it very easy to offload work to separate worker processes etc. </p>

<p>All this comes courtesy of <a href="https://www.erlang.org/">Erlang</a>, the language on which Elixir is built, with its powerfull OTP framework for building applications and its BEAM virtual machine, which manages the processes. </p>

<h2>Phoenix</h2>

<p>A lot of the groundwork of Pleroma is done by <a href="https://hexdocs.pm/phoenix/overview.html">Phoenix</a>, a very easy-to-use web server framework. Essentially, what happens is that the end user accesses the application using a specific url, typically via a web browser, and based on this url the application performs a number of actions, which in the end result in a change in the state of the application and usually in what is shown in the browser window.</p>

<p>In Phoenix, there are five stages or components  between the connection and the resulting action by the application:</p>

<h3>Endpoint</h3>

<p>The <a href="https://hexdocs.pm/phoenix/Phoenix.Endpoint.html">endpoint</a> is the boundary where all requests to your web application start. It is also the interface your application provides to the underlying web servers.</p>

<p>Pleroma's endpoint is <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/endpoint.ex"><code>web/endpoint.ex</code></a>. If you look at the source you see several occurrences of <code>plug(Plug...)</code>. <a href="https://hexdocs.pm/phoenix/plug.html">Plug</a> is a specification for composable modules in between web applications, and it is very heavily used in Pleroma.  For example, to serve only specific static files/folders from <code>priv/static</code>:</p>
<div><pre><code data-lang="elixir"><span></span><span>plug</span><span>(</span>
  <span>Plug.Static</span><span>,</span>
  <span>at</span><span>:</span> <span>"/"</span><span>,</span>
  <span>from</span><span>:</span> <span>:pleroma</span><span>,</span>
  <span>only</span><span>:</span> <span>~w(index.html static finmoji emoji packs sounds images instance sw.js)</span>
<span>)</span>
</code></pre></div>
<p>Another very nice feature of Phoenis is that you can edit your code while your server is running. It gets automatically recompiled and the affected processes are automatically restarted, courtesy of the <a href="https://hexdocs.pm/phoenix/Phoenix.CodeReloader.html">Phoenix.CodeReloader</a>:</p>
<div><pre><code data-lang="elixir"><span></span>  <span># Code reloading can be explicitly enabled under the</span>
  <span># :code_reloader configuration of your endpoint.</span>
  <span>if</span> <span>code_reloading?</span> <span>do</span>
    <span>plug</span><span>(</span><span>Phoenix.CodeReloader</span><span>)</span>
  <span>end</span>
</code></pre></div>
<h3>Router</h3>

<p><a href="https://hexdocs.pm/phoenix/Phoenix.Router.html">Routers</a> are the main hubs of Phoenix applications. They match HTTP requests to controller actions, wire up real-time channel handlers, and define a series of pipeline transformations for scoping middleware to sets of routes.</p>

<p>Pleroma's router is <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/router.ex"><code>web/router.ex</code></a>. The key function in the router is the <code>pipeline</code> which lets you create pipelines of plugs. Other functions are <code>scope</code>, <code>get</code>, <code>post</code>, <code>pipe_through</code>, all of these let you match on the url and whether you are dealing with a get or post request, and define appropriate pipelines of actions. For example, federated ActivityPub requests handled as follows:</p>
<div><pre><code data-lang="elixir"><span></span><span>scope</span> <span>"/"</span><span>,</span> <span>Pleroma.Web.ActivityPub</span> <span>do</span>
  <span>pipe_through</span><span>(</span><span>:activitypub</span><span>)</span>
  <span>post</span><span>(</span><span>"/users/:nickname/inbox"</span><span>,</span> <span>ActivityPubController</span><span>,</span> <span>:inbox</span><span>)</span>
  <span>post</span><span>(</span><span>"/inbox"</span><span>,</span> <span>ActivityPubController</span><span>,</span> <span>:inbox</span><span>)</span>
<span>end</span>
</code></pre></div>
<p>where the <code>pipe_through(:activitypub)</code> call is used to insert a custom pipeline:</p>
<div><pre><code data-lang="elixir"><span></span><span>pipeline</span> <span>:activitypub</span> <span>do</span>
  <span>plug</span><span>(</span><span>:accepts</span><span>,</span> <span>[</span><span>"activity+json"</span><span>])</span>
  <span>plug</span><span>(</span><span>Pleroma.Web.Plugs.HTTPSignaturePlug</span><span>)</span>
<span>end</span>
</code></pre></div>
<h3>Controllers</h3>

<p><a href="https://hexdocs.pm/phoenix/Phoenix.Controller.htm">Controllers</a> are used to group common functionality in the same (pluggable) module.  </p>

<p>Pleroma makes heavy use of controllers: almost every request is handled by a specific controller for any given protocol, e.g. <code>MastodonAPIController</code> or <code>ActivityPubController</code>. This makes it easy to identify the files to work on if you need to make a change to the code for a given protocol. For example, the ActivityPub post requests in the Router are handled by <code>inbox</code> function in the <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/activity_pub/activity_pub_controller.ex">ActivityPubController</a>:</p>
<div><pre><code data-lang="elixir"><span></span><span>def</span> <span>inbox</span><span>(%{</span><span>assigns</span><span>:</span> <span>%{</span><span>valid_signature</span><span>:</span> <span>true</span><span>}}</span> <span>=</span> <span>conn</span><span>,</span> <span>params</span><span>)</span> <span>do</span>
  <span>Federator</span><span>.</span><span>enqueue</span><span>(</span><span>:incoming_ap_doc</span><span>,</span> <span>params</span><span>)</span>
  <span>json</span><span>(</span><span>conn</span><span>,</span> <span>"ok"</span><span>)</span>
<span>end</span>
</code></pre></div>
<h3>Views</h3>

<p><a href="https://hexdocs.pm/phoenix/Phoenix.View.html">Views</a> are used to control the rendering of templates. You create a view module, a template and a set of assigns, which are basically key-value pairs.</p>

<p>Pleroma uses views for "rendering" JSON objects. For example in <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/activity_pub/activity_pub_controller.ex"><code>web/activity_pub/activity_pub_controller.ex</code></a> there are lines like</p>
<div><pre><code data-lang="elixir"><span></span><span>json</span><span>(</span><span>UserView</span><span>.</span><span>render</span><span>(</span><span>"user.json"</span><span>,</span> <span>%{</span><span>user</span><span>:</span> <span>user</span><span>}))</span>
</code></pre></div>
<p>Here, <code>UserView.render</code> is defined in <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/activity_pub/views/user_view.ex"><code>web/activity_pub/views/user_view.ex</code></a> for a number of different "*.json" strings. These are not really templates, they are simply used to pattern match on the function definitions.</p>

<p>The more conventional usage to create HTML is also used, e.g. the template <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/templates/mastodon_api/mastodon/index.html.eex"><code>web/templates/mastodon_api/mastodon/index.html.eex</code></a>
is used in <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/mastodon_api/mastodon_api_controller.ex"><code>web/mastodon_api/mastodon_api_controller.ex</code></a> via the view
<a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/mastodon_api/views/mastodon_view.ex"><code>web/mastodon_api/views/mastodon_view.ex</code></a>:</p>
<div><pre><code data-lang="elixir"><span></span><span>render</span><span>(</span><span>MastodonView</span><span>,</span> <span>"index.html"</span><span>,</span> <span>%{</span><span>initial_state</span><span>:</span> <span>initial_state</span><span>})</span>
</code></pre></div>
<h3>Templates</h3>

<p><a href="https://hexdocs.pm/phoenix/Phoenix.Template.html">Templates</a> are text files (typically html pages) with Elixir code to generate the specific values based on the assigns, included in <code>&lt;%= ... %&gt;</code>.</p>

<p>For example, in Pleroma, the Mastodon front-end uses a template for the <code>index.html</code> file which has the code</p>
<div><pre><code data-lang="elixir"><span></span><span>&lt;</span><span>%</span><span>=</span> <span>Application</span><span>.</span><span>get_env</span><span>(</span><span>:pleroma</span><span>,</span> <span>:instance</span><span>)[</span><span>:name</span><span>]</span> <span>%</span><span>&gt;</span>
</code></pre></div>
<p>to show the name of the instance.</p>

<h2>Ecto</h2>

<p><a href="https://hexdocs.pm/ecto/Ecto.html">Ecto</a> is not a part of Phoenix, but it is an integral part of most web applications: Ecto is Elixir's main library for working with databases. It provides the tools to interact with databases under a common API.</p>

<p>Ecto is split into 4 main components:</p>

<p>Ecto.Repo - repositories are wrappers around the data store. Via the repository, we can create, update, destroy and query existing entries. A repository needs an adapter and credentials to communicate to the database</p>

<p>Pleroma uses the PostgresQL database.</p>

<p>Ecto.Schema - schemas are used mainly to map tables into Elixir data (there are other use cases too).</p>

<p>Ecto.Changeset - changesets provide a way for developers to filter and cast external parameters, as well as a mechanism to track and validate changes before they are applied to your data</p>

<p>Ecto.Query - written in Elixir syntax, queries are used to retrieve information from the database.</p>

<h2>GenServer</h2>

<p>Because Elixir, like Erlang, uses a processes-with-message-passing paradigm, client-server relationships are so common that they have been abstracted as a <em>behaviour</em>, which in Elixir is a specification for composable modules which have to implement specified public functions (a bit like an interface in Java or typeclass in Haskell).</p>

<p>If we look at the <code>Federator.enqueue</code> function, its implementation actually reduces to a single line:</p>
<div><pre><code data-lang="elixir"><span></span><span>GenServer</span><span>.</span><span>cast</span><span>(</span><span>__MODULE__</span><span>,</span> <span>{</span><span>:enqueue</span><span>,</span> <span>type</span><span>,</span> <span>payload</span><span>,</span> <span>priority</span><span>})</span>
</code></pre></div>
<p><a href="https://hexdocs.pm/elixir/GenServer.html">GenServer</a> is an Elixir behaviour module for implementing the server of a client-server relation. The <code>cast</code> call sends an asynchronous request to the server (synchronous requests use <code>call</code>). The server behaviour is implemented using the <code>handle_cast</code> callback, which handles <code>cast</code> calls. </p>

<p>In <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/federator/federator.ex"><code>Pleroma.Federator</code></a>, these are implemented in the same module as the <code>enqueue</code> function, hence the use of <code>__MODULE__</code> rather than the hardcoded module name.</p>

<h2>Applications, Workers and Supervisors</h2>

<p>Elixir borrows the concept of a "supervision tree" from Erlang/OTP. AN application consists of a tree of processes than can either be <em>supervisors</em> or <em>workers</em>. The task of a supervisors is to ensure that the worker processes do their work, including distributing the work and restarting the worker processes when they die. Supervisors can supervise either worker or other supervisors, so you can build a <em>supervision tree</em>.</p>

<p>Elixir provides an <a href="http://elixir-lang.org/docs/stable/elixir/Application.html">Application</a> behaviour module and a <a href="https://hexdocs.pm/elixir/Supervisor.html">Supervisor</a> module to make this easy. The Application module requires a <code>start()</code> function as entry point. Typical code to create a supervision tree is</p>
<div><pre><code data-lang="elixir"><span></span><span>Supervisor</span><span>.</span><span>start_link</span><span>(</span><span>children</span><span>,</span> <span>opts</span><span>)</span>
</code></pre></div>
<p>where <code>start_link()</code> spawns the top process of the tree, and it spawns all the child processes in the list <code>children</code>. </p>

<p>Pleroma uses a convenient but deprecated module called <a href="https://hexdocs.pm/elixir/Supervisor.Spec.html">Supervisor.Spec</a> which provides <code>worker()</code> and <code>supervisor()</code> functions, for example:</p>
<div><pre><code data-lang="elixir"><span></span><span>children</span> <span>=</span> <span>[</span>
  <span>supervisor</span><span>(</span><span>Pleroma.Repo</span><span>,</span> <span>[]),</span>
  <span>supervisor</span><span>(</span><span>Pleroma.Web.Endpoint</span><span>,</span> <span>[]),</span>
  <span># ...</span>
  <span>worker</span><span>(</span><span>Pleroma.Web.Federator</span><span>,</span> <span>[]),</span>
  <span># ...</span>
<span>]</span>  
</code></pre></div>
<p>Every worker has this own <code>start_link</code> function,  e.g.  in <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/federator/federator.ex"><code>web/federator/federator.ex</code></a> we find: </p>
<div><pre><code data-lang="elixir"><span></span><span>def</span> <span>start_link</span> <span>do</span>
  <span># ...</span>
  <span>GenServer</span><span>.</span><span>start_link</span><span>(</span><span>__MODULE__</span><span>,</span> <span>...</span><span>)</span>
<span>end</span>
</code></pre></div>
<p>This means that the Federator module borrows the <code>start_link</code> from the GenServer module. This is a very common way to create a worker.</p>

<h2>Mix</h2>

<p><a href="https://hexdocs.pm/mix/Mix.html">Mix</a> is the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wimvanderbauwhede.github.io/articles/hacking-pleroma/">https://wimvanderbauwhede.github.io/articles/hacking-pleroma/</a></em></p>]]>
            </description>
            <link>https://wimvanderbauwhede.github.io/articles/hacking-pleroma/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017031</guid>
            <pubDate>Sat, 01 Aug 2020 03:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Sizle.io – React Presentation Builder]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24016998">thread link</a>) | @sizleio
<br/>
July 31, 2020 | https://sizle.io/presentations/ | <a href="https://web.archive.org/web/*/https://sizle.io/presentations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="home" data-column-margin="default" data-midnight="dark" data-top-percent="6%" data-bottom-percent="7%" data-bg-mobile-hidden="true" data-using-ctc="true"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="right" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div id="fws_5f2801c634664" data-midnight="" data-column-margin="default"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h3>Make your content shine on all devices with presentations and proposals that convert more leads</h3></p></div></div></div></div></div></div></div></div></div></div></div><div id="fws_5f2801c6391b2" data-column-margin="default" data-midnight="dark" data-top-percent="5%" data-bottom-percent="5%"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="none" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="775" width="933" data-animation="none" src="https://sizle.io/wp-content/uploads/2020/04/Mobile-friendly-online-presentations-min-2.png" alt="Mobile friendly online presentations" srcset="https://sizle.io/wp-content/uploads/2020/04/Mobile-friendly-online-presentations-min-2.png 933w, https://sizle.io/wp-content/uploads/2020/04/Mobile-friendly-online-presentations-min-2-300x249.png 300w, https://sizle.io/wp-content/uploads/2020/04/Mobile-friendly-online-presentations-min-2-768x638.png 768w" sizes="(min-width: 1450px) 75vw, (min-width: 1000px) 85vw, 100vw"></p></div></div></div></div></div></div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><h2>Mobile friendly</h2><div><p>Give your viewer the best experience no matter what device they’re using.</p></div><h2>Distraction-free</h2><div><p>Display your presentations in a minimal interface that makes your content shine.</p></div><h2>Viewer analytics</h2><div><p>Measure the performance of your presentations across multiple devices.</p></div></div></div></div></div></div><div id="fws_5f2801c6404de" data-column-margin="default" data-midnight="dark" data-top-percent="5%" data-bottom-percent="4%" data-using-ctc="true"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p>Ensure that your presentations remain commercial in confidence. Share securely with password protection.</p></div></div></div></div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="none" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="964" width="1634" data-animation="none" src="https://sizle.io/wp-content/uploads/2020/02/Sizle-Presentation-Password-Protection.svg" alt="Sizle Presentation Password Protection"></p></div></div></div></div></div></div></div></div><div id="howitworks" data-column-margin="default" data-midnight="dark" data-top-percent="3%" data-bottom-percent="3%" data-using-ctc="true"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="left" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h2>Viewer insights<br> and alerts</h2></p></div><div><p>See how people engage with your<br> presentation slide-by-slide.</p></div></div></div></div></div></div><div id="fws_5f2801c6494df" data-column-margin="default" data-midnight="dark" data-top-percent="8%" data-bottom-percent="8%" data-using-ctc="true"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p>Create a or upload a presentation to explore a suite of dynamic features.</p></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://sizle.io/presentations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016998</guid>
            <pubDate>Sat, 01 Aug 2020 03:02:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alacritty Version 0.5.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24016977">thread link</a>) | @sbt567
<br/>
July 31, 2020 | https://blog.christianduerr.com/alacritty_0_5_0_announcement.html | <a href="https://web.archive.org/web/*/https://blog.christianduerr.com/alacritty_0_5_0_announcement.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <p>
        
        <h4>July 31, 2020</h4>
    </p>

    <h2>Table of Contents</h2>

    <ul>
      <li><a href="#about">About</a></li>
      <li><a href="#added">Added</a></li>
      <li><a href="#changed">Changed</a></li>
      <li><a href="#fixed">Fixed</a></li>
      <li><a href="#removed">Removed</a></li>
      <li><a href="#additional-information">Additional Information</a></li>
    </ul>

    <h2><a name="about" href="#about">About</a></h2>

    <p>
      <a href="https://github.com/alacritty/alacritty" target="_blank">Alacritty</a>
      is a terminal emulator with a strong focus on simplicity and performance.
      With such a strong focus on performance, included features are carefully
      considered and you can always expect Alacritty to be blazingly fast. By
      making sane choices for defaults, Alacritty requires no additional setup.
      However, it does allow configuration of many aspects of the terminal.
    </p>

    <h2>
      <a name="added" href="#added">Added</a>
    </h2>
    <ul>
      <li>Default Command+N keybinding for SpawnNewInstance on macOS</li>
      <li>Vi mode for regex search, copying text, and opening links</li>
        
        
      <li><code>CopySelection</code> action which copies into selection buffer on Linux/BSD</li>
      <li>Option <code>cursor.thickness</code> to set terminal cursor thickness</li>
        <p><img src="https://blog.christianduerr.com/img/cursor_thickness.png">
        </p>
      <li>Font fallback on Windows</li>
      <li>Support for Fontconfig embolden and matrix options</li>
      <li>Opt-out compilation flag <code>winpty</code> to disable WinPTY support</li>
      <li>Scrolling during selection when mouse is at top/bottom of window</li>
        
      <li>Expanding existing selections using single, double and triple click with the right mouse button</li>
        
      <li>Support for <code>gopher</code> and <code>gemini</code> URLs</li>
      <li>Unicode 13 support</li>
      <li>Option to run command on bell which can be set in <code>bell.command</code></li>
      <li>Fallback to program specified in <code>$SHELL</code> variable on Linux/BSD if it is present</li>
    </ul>

    <h2>
      <a name="changed" href="#changed">Changed</a>
    </h2>
    <ul>
      <li>Block cursor is no longer inverted at the start/end of a selection</li>
      <li>Preserve selection on non-LMB or mouse mode clicks</li>
      <li>Wayland client side decorations are now based on config colorscheme</li>
      <li>Low resolution window decoration icon on Windows</li>
      <li>Mouse bindings for additional buttons need to be specified as a number not a string</li>
      <li>Don't hide cursor on modifier press with <code>mouse.hide_when_typing</code> enabled</li>
      <li><code>Shift + Backspace</code> now sends <code>^?</code> instead of <code>^H</code></li>
      <li>Default color scheme is now <code>Tomorrow Night</code> with the bright colors of <code>Tomorrow Night Bright</code></li>
        <p><img src="https://blog.christianduerr.com/img/new_colorscheme.png">
        </p>
      <li>Set IUTF8 termios flag for improved UTF8 input support</li>
      <li>Dragging files into terminal now adds a space after each path</li>
      <li>Default binding replacement conditions</li>
      <li>Adjusted selection clearing granularity to more accurately match content</li>
      <li>To use the cell's text color for selection with a modified background, the <code>color.selection.text</code>
      variable must now be set to <code>CellForeground</code> instead of omitting it</li>
      <li>URLs are no longer highlighted without a clearly delimited scheme</li>
      <li>Renamed config option <code>visual_bell</code> to <code>bell</code></li>
      <li>Moved config option <code>dynamic_title</code> to <code>window.dynamic_title</code></li>
    </ul>

    <h2>
      <a name="fixed" href="#fixed">Fixed</a>
    </h2>
    <ul>
      <li>Selection not cleared when switching between main and alt grid</li>
      <li>Freeze when application is invisible on Wayland</li>
      <li>Paste from some apps on Wayland</li>
      <li>Slow startup with Nvidia binary drivers on some X11 systems</li>
      <li>Display not scrolling when printing new lines while scrolled in history</li>
      <li>Regression in font rendering on macOS</li>
      <li>Scroll down escape (<code>CSI Ps T</code>) incorrectly pulling lines from history</li>
      <li>Dim escape (<code>CSI 2 m</code>) support for truecolor text</li>
      <li>Incorrectly deleted lines when increasing width with a prompt wrapped using spaces</li>
      <li>Documentation for class in <code>--help</code> missing information on setting general class</li>
      <li>Linewrap tracking when switching between primary and alternate screen buffer</li>
      <li>Preservation of the alternate screen's saved cursor when swapping to primary screen and back</li>
      <li>Reflow of cursor during resize</li>
      <li>Cursor color escape ignored when its color is set to inverted in the config</li>
      <li>Fontconfig's <code>autohint</code> and <code>hinting</code> options being ignored</li>
      <li>Ingoring of default FreeType properties</li>
      <li>Alacritty crashing at startup when the configured font does not exist</li>
      <li>Font size rounding error</li>
    </ul>

    <h2>
      <a name="removed" href="#removed">Removed</a>
    </h2>
    <ul>
      <li>Environment variable <code>RUST_LOG</code> for selecting the log level</li>
      <li>Deprecated <code>window.start_maximized</code> config field</li>
      <li>Deprecated <code>render_timer</code> config field</li>
      <li>Deprecated <code>persistent_logging</code> config field</li>
    </ul>

    <h2><a name="additional-information" href="#additional-information">Additional Information</a></h2>

    <p>
      Detailed installation instructions can be found in
      <a href="https://github.com/alacritty/alacritty#installation">
        Alacritty's GitHub README.
      </a>
    </p>

    <p>
      The full changelog including all previous versions can be found
      <a href="https://github.com/alacritty/alacritty/blob/v0.5.0/CHANGELOG.md">here</a>.
    </p>
  

</div>]]>
            </description>
            <link>https://blog.christianduerr.com/alacritty_0_5_0_announcement.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016977</guid>
            <pubDate>Sat, 01 Aug 2020 02:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build and Deploy a Discord Bot with Node and Discord.js in 5 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24016740">thread link</a>) | @xtrp
<br/>
July 31, 2020 | https://xtrp.io/blog/2020/07/31/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/ | <a href="https://web.archive.org/web/*/https://xtrp.io/blog/2020/07/31/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Title assumes 265 words per minute reading time, as used by Medium and others.</em></p>
<p>Discord bots can be useful in doing a variety of things like playing music in a voice chat, or sending automated announcements when a Youtuber releases a new video.</p>
<p>I'm active on several Discord servers myself and have always wanted to build my own Discord bot. After building, deploying, and using my own bot for over a month now, I've written this article as a starting point in building a basic bot and moving from there.</p>
<p>We'll be building a bot that does something pretty simple: solves math equations. Users will be able to send a message on any channel that looks like <code>!solve [math equation]</code> and receive a response with the calculated result. For example:</p>
<p><img src="https://xtrp.io/api/content/static_files/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/botexamplefunctionality.png" alt="Bot Functionality Graphic"></p>
<h3>Before Reading, You Should:</h3>
<ul>
<li>Know basic JavaScript and Node.js (with Node and NPM installed)</li>
<li>Have a Discord account (create one <a href="https://discord.com/">here</a>)</li>
</ul>
<h2>1. Create a Discord API Application and Bot</h2>
<p>Go to <a href="https://discord.com/developers/applications">discord.com/developers/applications</a> and click 'New Application' on the top right. Let's call the app 'Solver Bot'.</p>
<p><img src="https://xtrp.io/api/content/static_files/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/newapp.png" alt="New Application Button Screenshot"></p>
<p>By creating an app, you'll be able to get a unique API key to connect to the Discord API, create a bot, and do things like send and receive messages with that bot.</p>
<p>Now click on the 'Bot' tab on the right sidebar and click 'Add Bot'.</p>
<p><img src="https://xtrp.io/api/content/static_files/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/addbot.png" alt="Bot Tab and Add Bot Screenshot"></p>
<p>Add a profile picture to the bot by importing a file from your local machine.</p>
<p>I'll be using an icon which you can <a href="https://github.com/xtrp/tutorials/blob/master/discord-solver-bot/icon.png">download here</a> (this icon is CC0 Licensed, and you can use it without attribution).</p>
<p><img src="https://xtrp.io/api/content/static_files/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/boticon.png" alt="Bot Icon and Name Screenshot"></p>
<h2>2. Add Your Bot to a Server!</h2>
<p>Now that we've created a Discord API App with a bot account, we can add the bot to a server. I recommend making your own server to test your bots.</p>
<p>To add a bot to a server, all we need is an Discord OAuth2 URL. Upon opening this URL, any Discord user can add your bot to a server they own, and grant it permissions.</p>
<p>To generate the URL, open up the OAuth2 tab.</p>
<p>You'll see a grid of checkboxes, and here, select the 'bot' option. Another grid should appear, and here is where you'll select bot permissions. For this basic bot, we'll just need to manage and read messages.</p>
<p><img src="https://xtrp.io/api/content/static_files/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/botselection.png" alt="App and Bot Scopes and Permissions Screenshot"></p>
<p>Given these selected options, Discord automatically generates an OAuth2 URL, which you can see in the input box under the first grid. The URL should look something like <code>https://discord.com/oauth2/...</code>.</p>
<p>Try copying and opening the URL! You should be able to add the bot to any servers you own.</p>
<p><img src="https://xtrp.io/api/content/static_files/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/copyoauthurl.png" alt="Discord OAuth2 URL"></p>
<h2>3. Create the Functionality of Your Bot With Node and Discord.js</h2>
<p>Let's start building the functionality of the bot in Node.</p>
<p>Make a new folder (or Git repository if that's what you prefer) on your machine called <code>discord-solver-bot</code>.</p>
<p>On your Terminal or Command Line, navigate to the folder and run <code>npm init</code>, adding any the necessary details when you see fit.</p>
<p>Now, let's add our dependencies. We'll be using <a href="https://discord.js.org/">Discord.js</a>, a package which simplifies connecting and using the Discord API. For solving math equations, we'll use the useful <a href="https://www.npmjs.com/package/equations">Equations</a> module.</p>
<p>Run <code>npm install discord.js equations --save</code> to install these packages.</p>
<p>Okay, now we can create an <code>index.js</code> file in the folder and start writing some code.</p>
<p><img src="https://xtrp.io/api/content/static_files/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/commandline.png" alt="Command Line Example of Creating a Node Project and Adding Packages"></p>
<p>We can start by importing any necessary packages.</p>
<pre><code>const Discord = require('discord.js');
const Equation = require('equations').default; // .default to fix a problem I encountered while importing without it</code></pre>
<h3>Connect to Your Bot With Your Bot Token and Login to Discord</h3>
<p>To connect to your bot with Discord.js, we initialize Discord.js Client object to connect to the Discord API.</p>
<p>To login with our bot with the client, we need the bot token. Copy the token by going to your app in the developer portal &gt; bot &gt; token &gt; copy.</p>
<p>Now we can login to our bot by calling the Client <code>login</code> function and passing the copied token.</p>
<pre><code>const client = new Discord.Client();
client.login("[your bot token here]");</code></pre>
<blockquote>
<p><strong>Don't share your bot token with anyone else. It can be used to take complete control over your bot.</strong></p>
</blockquote>
<h3>Check if Your Bot is Logged In</h3>
<p>To check if your bot is logged in and ready to do things on Discord, use the Client <code>ready</code> event:</p>
<pre><code>client.on('ready', async () =&gt; {
  console.log(`Logged in successfully as bot!`);
});</code></pre>
<p>Try running the bot by running <code>node index.js</code>. You should see that your bot is logged in. In Discord, you should also be able to see that the bot is marked as online.</p>
<p><img src="https://xtrp.io/api/content/static_files/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/loggedin.png" alt="Bot Logged In Screenshot"></p>
<h3>Listen for a Message and Respond</h3>
<p>Use the client <code>message</code> event to listen any time a user sends a message anywhere on any server the bot is on. The event comes with a message object which contains the <code>content</code> (text content of the message) property among others.</p>
<p>The object also has a <code>.reply</code> method, for your bot to reply to the message directly to the user that sent it.</p>
<p>Typically a message we're looking for looks like <code>!solve [equation here]</code>.</p>
<p>So, all we have to do is check if the message starts with '!solve ', and then solve the equation written afterwards. We can do this with the JavaScript string <code>.startsWith</code> and <code>.slice</code> functions respectively.</p>
<p>For solving the equation the <code>equations</code> package has a <code>.solve</code> function to solve any given equation. <code>.solve</code> throws an error if the equation is not valid, and we can catch that error to reply saying the equation could not be solved.</p>
<p>Here's what this code looks like:</p>
<pre><code>client.on('message', (msg) =&gt; {
    msg.content = msg.content.trim(); // remove extra whitespace
    const flag = '!solve ';
    if (msg.content.startsWith(flag)) {
        const toSolve = msg.content.slice(flag.length, msg.content.length);
        try {
            const solved = Equation.solve(toSolve);

            msg.reply(`${toSolve} = ${solved}`); // backticks (TLs) are used to embed variables in strings like `${var}`
        } catch (err) {
            msg.reply(`Could not solve the equation '${toSolve}'.`);
        }
    }
});</code></pre>
<h2>4. We're Done! Let's Test the Bot</h2>
<p>After running <code>node index</code>, go to a server with the bot (in my case my bot testing server), and try sending a message like <code>!solve 2 + 2</code>. You should see a response like <code>2 + 2 = 4</code>. You can additionally try more complex equations, and test the error checking with a malformed equation.</p>
<p><img src="https://xtrp.io/api/content/static_files/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/bottest.png" alt="Bot Functionality Screenshot"></p>
<p>If you'd like, you can <a href="https://discord.com/api/oauth2/authorize?client_id=738260543479218217&amp;permissions=10240&amp;scope=bot">click here</a> to add <strong>my version</strong> of this bot to your own server(s).</p>
<h2>5. Deploying Your Bot and Next Steps</h2>
<p>Deploying your bot is pretty simple. All you have to do is keep the index file (in this case <code>node index</code>) running whenever you want your bot to be online, typically 24/7. You can choose to run it on an old computer or Raspberry Pi, your own server, or you can choose to deploy on a platform like <a href="http://heroku.com/">Heroku</a>.</p>
<p>In terms of next steps in building a more complex bot, the <a href="https://discord.js.org/#/docs/main/stable/general/welcome">Discord.js documentation</a> can be really useful in using the Discord API to perform functions on text and voice channels, multiple servers, direct messages, and more.</p>
<p>In sharing your bot, there are many websites dedicated to listing Discord bots, including <a href="https://bots.ondiscord.xyz/">bots.ondiscord.xyz</a>, <a href="https://discord.bots.gg/">discord.bots.gg</a>, and <a href="https://top.gg/">top.gg</a>. Building a website for your bot can be useful in showcasing its features and linking the URL to add the bot to a server. Sharing the bot among servers you own are know the owner of can also be useful.</p>
<h2>Thanks for Reading</h2>
<p><strong>View the source code and assets <a href="https://github.com/xtrp/tutorials">here, at my tutorials repo</a></strong>.</p>
<p>I hope you enjoyed this post and found it useful in creating your own Discord bots with Node and Discord.js.</p>
<p>Thanks for scrolling.</p>
<p><em>— Fred Adams, July 31, 2020</em></p></div></div>]]>
            </description>
            <link>https://xtrp.io/blog/2020/07/31/build-and-deploy-a-discord-bot-with-node-and-discordjs-in-5-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016740</guid>
            <pubDate>Sat, 01 Aug 2020 02:11:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a Physics Engine]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24016718">thread link</a>) | @todsacerdoti
<br/>
July 31, 2020 | https://blog.winter.dev/2020/designing-a-physics-engine/ | <a href="https://web.archive.org/web/*/https://blog.winter.dev/2020/designing-a-physics-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>By coincidence, right when <a href="https://www.youtube.com/c/TheChernoProject/videos" target="_blank" rel="noreferrer noopener">The Cherno</a> announced his game engine series I was just starting to get going on my own engine. I couldn’t wait to finally have a professional opinion on how to make one. With self-taught programming it’s hard to not doubt yourself constantly, wondering if you are doing things right or just think you are.</p>



<p>Recently, he has been posting videos about huge aspects of his engine like physics and entity systems, which were what I really wanted to learn about by making myself, but he ended up using libraries instead of going through the internals! I am not against using libraries, but to use them for the fun stuff? I felt like it defeated the point of making a <em>custom</em> engine series.</p>



<p>There is an argument to be made about saving time, but this was the first C++ project that I was making and the goal from the start was to go through all the major pillars of an engine: input, graphics, physics, entities, and audio. I wanted to learn how those things worked along with C++ and code design in general.</p>



<p>I bet that some other people are interested in the details of how these systems work, and I want to learn how to explain code better, so I am going to try and make some videos going over the internals of these systems. They end up being much simpler than at first glance.</p>



<p><strong>Let’s start with the physics engine…</strong></p>



<p>Physics engines are responsible for figuring out where each object in a scene is over time. Objects can collide with one another, then choose to respond in several ways. It’s a generic problem that the user can configure at several different levels. Do they want a collider? Do they want to respond to collisions? Do they want to simulate dynamics? They could want dynamics, but not gravity. It’s a problem that calls for good planning and robust design.</p>



<p>I looked at how <a href="https://github.com/bulletphysics/bullet3" target="_blank" rel="noreferrer noopener">bullet</a> and <a href="https://github.com/erincatto/box2d" target="_blank" rel="noreferrer noopener">box2d</a> went about sorting their engines and concluded that the way bullet went about it was solid. I boiled it down to just what was needed, and based my design around that. There are already some <a href="https://www.toptal.com/game/video-game-physics-part-i-an-introduction-to-rigid-body-dynamics" target="_blank" rel="noreferrer noopener">great articles</a> going over the hard math involved, so I am going to focus on the design aspect instead because I haven’t seen anyone do that, and it’s also a real headache.</p>



<p>At the current moment, this physics engine is not fully featured, but in future articles I plan to build it out further. This article will not cover rotation, multiple contact point collisions, or constrained simulation. I think it will work out for the best as it’s easy to get overwhelmed, and I want to ease into those topics. With that out of the way, let’s dive into the different parts of a physics engine.</p>



<p>The problem can be split into 2 or 3 pieces, dynamics, collision detection, and collision response. I’ll start with dynamics because it is by far the simplest.</p>



<p><strong>Dynamics</strong></p>



<p>Dynamics is all about calculating where the new positions of objects are based on their velocity and acceleration. In high school you learn about the four kinematic equations along with Newton's three laws which describe the motion of objects. We’ll only be using the first and third kinematic equations, the others are more useful for analysis of situations, not simulation. That leaves us with:</p>



<p><span data-katex-display="true">v = v_0+at</span>



<span data-katex-display="true">\Delta x = v_0t + \frac{1}{2}at^2</span></p><p>We can give ourselves more control by using Newtons 2<sup>nd</sup> law, subbing out acceleration giving us:</p>



<p><span data-katex-display="true">v = v_0+\frac{F}{m}t</span>



<span data-katex-display="true">x = x_0+vt</span></p><p>Each object needs to store these three properties: velocity, mass, and net force. Here we find the first decision we can make towards the design, net force could either be a list or a single vector. In school you make force diagrams and sum up the forces, implying that we should store a list. This would make it so you could set a force, but you would need to remove it later which could get annoying for the user. If we think about it further, net force is really the total force applied in a <em>single</em> frame, so we can use a vector and clear it at the end of each update. This allows the user to apply a force by adding it, but removing it is automatic. This shortens our code and gives a performance bump because there is no summation of forces, it’s a running total.</p>



<p>We’ll use this struct to store the object info for now.</p>



<pre><span>struct</span>&nbsp;<span>Object</span>&nbsp;<span>{</span>
	<span>vector3</span>&nbsp;<span>Position</span><span>;</span>&nbsp;<span>//&nbsp;struct&nbsp;with&nbsp;3&nbsp;floats&nbsp;for&nbsp;x,&nbsp;y,&nbsp;z&nbsp;or&nbsp;i&nbsp;+&nbsp;j&nbsp;+&nbsp;k</span>
	<span>vector3</span>&nbsp;<span>Velocity</span><span>;</span>
	<span>vector3</span>&nbsp;<span>Force</span><span>;</span>
	<span>float</span>&nbsp;<span>Mass</span><span>;</span>
<span>};</span>
</pre>



<p>We need a way to keep track of the objects we want to update. A classic approach is to have a <em>physics world</em> that has list of objects and a <em>step</em> function that loops over each one. Let’s see how that might look; I’ll omit header/cpp files for brevity.</p>



<pre><span>class</span>&nbsp;<span>PhysicsWorld</span>&nbsp;<span>{</span>
<span>private</span><span>:</span>
	<span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>Object</span><span>*&gt;</span>&nbsp;<span>m_objects</span><span>;</span>
	<span>vector3</span>&nbsp;<span>m_gravity</span>&nbsp;<span>=</span>&nbsp;<span>vector3</span><span>(</span><span>0</span><span>,</span>&nbsp;<span>-</span><span>9.81f</span><span>,</span>&nbsp;<span>0</span><span>);</span>
 
<span>public</span><span>:</span>
	<span>void</span>&nbsp;<span>AddObject</span>&nbsp;&nbsp;&nbsp;<span>(</span><span>Object</span><span>*</span>&nbsp;<span>object</span><span>)</span>&nbsp;<span>{</span>&nbsp;<span>/*&nbsp;...&nbsp;*/</span>&nbsp;<span>}</span>
	<span>void</span>&nbsp;<span>RemoveObject</span><span>(</span><span>Object</span><span>*</span>&nbsp;<span>object</span><span>)</span>&nbsp;<span>{</span>&nbsp;<span>/*&nbsp;...&nbsp;*/</span>&nbsp;<span>}</span>
 
	<span>void</span>&nbsp;<span>Step</span><span>(</span>
		<span>float</span>&nbsp;<span>dt</span><span>)</span>
	<span>{</span>
		<span>for</span>&nbsp;<span>(</span><span>Object</span><span>*</span>&nbsp;<span>obj</span>&nbsp;<span>:</span>&nbsp;<span>m_objects</span><span>)</span>&nbsp;<span>{</span>
			<span>obj</span><span>-&gt;</span><span>Force</span>&nbsp;<span>+=</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Mass</span>&nbsp;<span>*</span>&nbsp;<span>m_gravity</span><span>;</span>&nbsp;<span>//&nbsp;apply&nbsp;a&nbsp;force</span>
 
			<span>obj</span><span>-&gt;</span><span>Velocity</span>&nbsp;<span>+=</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Force</span>&nbsp;<span>/</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Mass</span>&nbsp;<span>*</span>&nbsp;<span>dt</span><span>;</span>
			<span>obj</span><span>-&gt;</span><span>Position</span>&nbsp;<span>+=</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Velocity</span>&nbsp;<span>*</span>&nbsp;<span>dt</span><span>;</span>
 
			<span>obj</span><span>-&gt;</span><span>Force</span>&nbsp;<span>=</span>&nbsp;<span>vector3</span><span>(</span><span>0</span><span>,</span>&nbsp;<span>0</span><span>,</span>&nbsp;<span>0</span><span>);</span>&nbsp;<span>//&nbsp;reset&nbsp;net&nbsp;force&nbsp;at&nbsp;the&nbsp;end</span>
		<span>}</span>
	<span>}</span>
<span>};</span>
</pre>



<p>Note the use of pointers, this forces other systems to take care of the actual storing of objects, leaving the physics engine to worry about physics, not memory allocation.</p>



<p>With this you can simulate all sorts of stuff from objects flying through the sky to solar systems.</p>



<iframe src="https://www.youtube.com/embed/crKrkn-RIOU?rel=0" allowfullscreen=""></iframe>



<iframe src="https://www.youtube.com/embed/sHZEs-oQTI4?rel=0" allowfullscreen=""></iframe>



<p>You can do a lot with this, but it’s the easy part to be honest, and that’s not what you came for…</p>



<p><strong>Collision detection</strong></p>



<p>Collision detection is more involved, but we can lighten the load by using some clever tricks. Let’s think about what needs to be found first. If we look at some examples of objects colliding, we notice that in most cases there is a point on each shape that is furthest inside the other.</p>



<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 364.19 219.82"><defs></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><path id="a7vJywMoip" d="M250.74,108.59A108.34,108.34,0,1,1,142.4.25,108.39,108.39,0,0,1,250.74,108.59Z"></path><path id="aojGvlR1o" d="M364.19,149.47H0"></path><path id="b13RQfe45N" d="M145,216.93a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,145,216.93Z"></path><path id="a3jwpJe9bd" d="M145,149.47a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,145,149.47Z"></path><g id="epQfmNKBq"><text transform="translate(147.06 211.83)">A</text></g><g id="g3JoLaPokP"><text transform="translate(147.06 143.56)">B</text></g><path id="bnhzn14P" d="M145,157.62l-2.64-3.82-2.64,3.82h1.68v54.21h1.93V157.62Z"></path><g id="a5EIiwgkw"><g id="aeJzDwQJn"><text transform="translate(269.3 140.4)">Plane B</text></g></g><g id="lWR9tvULn"><g id="giK7zCiBZ"><text transform="translate(209.6 209.41)">Sphere A</text></g></g></g></g></svg>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 319.48 293.52"><defs></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><path id="circleB" d="M216.92,108.58A108.34,108.34,0,1,1,108.58.25,108.38,108.38,0,0,1,216.92,108.58Z"></path><path id="pointA" d="M201.59,169.27a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,201.59,169.27Z"></path><path id="bvujLY3Pv" d="M319.23,184.93A108.34,108.34,0,1,1,210.89,76.59,108.4,108.4,0,0,1,319.23,184.93Z"></path><path id="b2sM6mmV3Y" d="M138.53,105.94a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,138.53,105.94Z"></path><g id="g7IjQmpjFM"><g id="a5ffFLN0Lk"><text transform="translate(206.96 169.27)">A</text></g></g><g id="f5t39XVL9"><g id="a3HVPWIRk6"><text transform="translate(125.66 100.13)">B</text></g></g><path id="a6B9Ro3d2Q" d="M145.73,112.32l-5.51-1.77,1.78,5.5,1.18-1.18,51.76,51.76,1.37-1.37L144.55,113.5Z"></path><g id="b34R6jrlf6"><g id="azoQGzEb0"><text transform="translate(254.28 162.37)">Sphere B</text></g></g><g id="c1Pseh1RfC"><g id="j1Q686eol"><text transform="translate(10.62 84.31)">Sphere A</text></g></g></g></g></svg>



<p>This turns out to be all we need to respond to a collision. From those two points we can find the normal, and how deep the objects are inside one another. This is huge because it means that we can abstract the idea of different shapes away, and only worry about the points in the response.</p>



<p>Let’s jump into the code, we’ll need some helper structs that I’ll note first.</p>



<pre><span>struct</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>{</span>
	<span>vector3</span>&nbsp;<span>A</span><span>;</span>&nbsp;<span>//&nbsp;Furthest&nbsp;point&nbsp;of&nbsp;A&nbsp;into&nbsp;B</span>
	<span>vector3</span>&nbsp;<span>B</span><span>;</span>&nbsp;<span>//&nbsp;Furthest&nbsp;point&nbsp;of&nbsp;B&nbsp;into&nbsp;A</span>
	<span>vector3</span>&nbsp;<span>Normal</span><span>;</span>&nbsp;<span>//&nbsp;B&nbsp;–&nbsp;A&nbsp;normalized</span>
	<span>float</span>&nbsp;<span>Depth</span><span>;</span>&nbsp;&nbsp;&nbsp;&nbsp;<span>//&nbsp;Length&nbsp;of&nbsp;B&nbsp;–&nbsp;A</span>
	<span>bool</span>&nbsp;<span>HasCollision</span><span>;</span>
<span>};</span>
 
<span>struct</span>&nbsp;<span>Transform</span>&nbsp;<span>{</span>&nbsp;<span>//&nbsp;Describes&nbsp;an&nbsp;objects&nbsp;location</span>
	<span>vector3</span>&nbsp;<span>Position</span><span>;</span>
	<span>vector3</span>&nbsp;<span>Scale</span><span>;</span>
	<span>quaternion</span>&nbsp;<span>Rotation</span><span>;</span>
<span>};</span>
</pre>



<p>Each shape will have a different type of collider to hold its properties and a base to allow them to be stored. Any type of collider should be able to test for a collision with any other type, so we’ll add functions in the base for each one. These functions will take <em>Transforms</em>, so the colliders can use relative coordinates. I’ll only demonstrate spheres and planes, but the code is repeatable for any number of colliders.</p>



<pre><span>struct</span>&nbsp;<span>Collider</span>&nbsp;<span>{</span>
	<span>virtual</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>Collider</span><span>*</span>&nbsp;<span>collider</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>colliderTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>=</span>&nbsp;<span>0</span><span>;</span>
 
	<span>virtual</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>SphereCollider</span><span>*</span>&nbsp;<span>sphere</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>sphereTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>=</span>&nbsp;<span>0</span><span>;</span>
 
	<span>virtual</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>PlaneCollider</span><span>*</span>&nbsp;<span>plane</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>planeTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>=</span>&nbsp;<span>0</span><span>;</span>
<span>};</span>
</pre>



<p>Let’s make both types of colliders at the same time too see how they interact. A sphere is defined as a point and a radius, and a plane is defined as a vector and a distance. We’ll override the functions from <em>Collider</em>, but won’t worry about the work for now.</p>



<p>We can choose per collider which other colliders it will detect by filling, or not filling, in these functions. In this case, we don’t want Plane v Plane collisions, so we return an empty <em>CollisionPoints</em>.</p>



<pre><span>struct</span>&nbsp;<span>SphereCollider</span>
	<span>:</span>&nbsp;<span>Collider</span>
<span>{</span>
	<span>vector3</span>&nbsp;<span>Center</span><span>;</span>
	<span>float</span>&nbsp;<span>Radius</span><span>;</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>Collider</span><span>*</span>&nbsp;<span>collider</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>colliderTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>collider</span><span>-&gt;</span><span>TestCollision</span><span>(</span><span>colliderTransform</span><span>,</span>&nbsp;<span>this</span><span>,</span>&nbsp;<span>transform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>SphereCollider</span><span>*</span>&nbsp;<span>sphere</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>sphereTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>algo</span><span>::</span><span>FindSphereSphereCollisionPoints</span><span>(</span>
			<span>this</span><span>,</span>&nbsp;<span>transform</span><span>,</span>&nbsp;<span>sphere</span><span>,</span>&nbsp;<span>sphereTransform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>PlaneCollider</span><span>*</span>&nbsp;<span>plane</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>planeTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>algo</span><span>::</span><span>FindSpherePlaneCollisionPoints</span><span>(</span>
			<span>this</span><span>,</span>&nbsp;<span>transform</span><span>,</span>&nbsp;<span>plane</span><span>,</span>&nbsp;<span>planeTransform</span><span>);</span>
	<span>}</span>
<span>};</span></pre>



<p>We can add a function for testing the base and use a technique called <a href="https://en.wikipedia.org/wiki/Double_dispatch" target="_blank" rel="noreferrer noopener">double dispatch</a>. This takes advantage of the type system to determine both types of colliders for us by swapping the arguments, determining the first, then the second type through two calls of TestCollision. This saves us needing to know what type of colliders we are checking, which means we’ve fully abstracted away the notion of different shapes outside the collision detection.</p>



<pre><span>struct</span>&nbsp;<span>PlaneCollider</span>
	<span>:</span>&nbsp;<span>Collider</span>
<span>{</span>
	<span>vector3</span>&nbsp;<span>Plane</span><span>;</span>
	<span>float</span>&nbsp;<span>Distance</span><span>;</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>Collider</span><span>*</span>&nbsp;<span>collider</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>colliderTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>collider</span><span>-&gt;</span><span>TestCollision</span><span>(</span><span>colliderTransform</span><span>,</span>&nbsp;<span>this</span><span>,</span>&nbsp;<span>transform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>SphereCollider</span><span>*</span>&nbsp;<span>sphere</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>sphereTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>//&nbsp;reuse&nbsp;sphere&nbsp;code</span>
		<span>return</span>&nbsp;<span>sphere</span><span>-&gt;</span><span>TestCollision</span><span>(</span><span>sphereTransform</span><span>,</span>&nbsp;<span>this</span><span>,</span>&nbsp;<span>transform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>PlaneCollider</span><span>*</span>&nbsp;<span>plane</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>planeTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>{};</span>&nbsp;<span>//&nbsp;No&nbsp;plane&nbsp;v&nbsp;plane</span>
	<span>}</span>
<span>};</span>
</pre>



<p>In cases like this, where there are many classes with a web of similar functions, it can be confusing as to where the actual code is located. <em>Sphere</em> v …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.winter.dev/2020/designing-a-physics-engine/">https://blog.winter.dev/2020/designing-a-physics-engine/</a></em></p>]]>
            </description>
            <link>https://blog.winter.dev/2020/designing-a-physics-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016718</guid>
            <pubDate>Sat, 01 Aug 2020 02:07:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for White-Collar Apprenticeships]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24016655">thread link</a>) | @kolchinski
<br/>
July 31, 2020 | https://alexkolchinski.com/2020/08/01/the-case-for-white-collar-apprenticeships/ | <a href="https://web.archive.org/web/*/https://alexkolchinski.com/2020/08/01/the-case-for-white-collar-apprenticeships/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-207">

	

	
	<div>
		
<p>Over the past century, the labor market in America has seen a dramatic shift from blue-collar to white-collar work. According to the Bureau of Census Data, white-collar work in the US grew from 17.6% of total employment in 1900 to 59.9% in 2003 [1]. The “white-collar” categorization was then discontinued for lack of specificity, but the fact remains that the majority of the American workforce is now employed in work where brainpower is more relevant than muscle power, a situation opposite to the way things were a century ago.</p>



<p>As knowledge work was displacing manual labor as the most common form of employment in America, the amount of formal education completed by Americans also grew rapidly. Before World War 2, only a quarter of American adults had graduated high school, and a vanishingly small percent had gone to college. Americans like George Washington, Cornelius Vanderbilt and Thomas Edison rose to the heights of politics, business and science with little to no formal education. But that state of affairs changed quickly after the end of World War 2 with the introduction of the GI bill, which paid for postsecondary education for millions of veterans. 75 years later, a large majority of American adults now hold high school degrees, and over a third hold bachelor’s degrees.</p>



<figure><img src="https://lh5.googleusercontent.com/LtNpx8ZHyaIn1-_Wu6ns-jOZTpztV-j1gWgCKcjTOQ-AIGQrv9Uhi97QiNop4AnqVYlwvvIaUjiTd45BtDbJP5RKm1dUMs522WYQIOf6raUZt15cQv9E_ftsck5bPJ8mSCh-awCF" alt=""></figure>







<p>As Americans have begun to attain higher levels of formal educational credentials, so too have jobs begun to demand higher levels of credentials as a prerequisite. Some of this is because some jobs really do require extensive formal education: patients might not want to be operated on by a neurosurgeon who had learned exclusively on-the-job! But many white-collar jobs, like sales and clerical roles, which do not require extensive theoretical training and traditionally were not filled by college graduates, are starting to require higher degrees in a phenomenon often referred to as degree inflation [2].&nbsp;</p>



<p>Some of this is rational from the point of view of the employer, as college graduates can be expected to have higher levels of skills applicable to office work than high school graduates or dropouts, if only due to their four extra years of experience performing a type of knowledge work in college. But spending four years writing papers on art history with the goal of landing a sales job is not efficient from the point of view of either the prospective employer, who limits their labor pool and ends up paying a premium for entry-level labor, or the prospective employee, who incurs often-heavy tuition fees and four years of opportunity cost before starting a career.&nbsp;</p>



<p>A better model exists in the form of apprenticeships. For centuries, teenagers have learned skilled blue-collar trades in collaboration with more experienced mentors, and have emerged into young adulthood as full-fledged professionals in their chosen field. As an added benefit, apprentices can be productive in the lower-skilled parts of a job almost from the get-go, implicitly paying for their own training and earning a wage as their counterparts in college instead pay tuition.</p>



<p>This model has occasionally been applied to white-collar professions in countries like Germany and the UK, in which formal apprenticeships in the traditional mold exist for higher-skilled jobs like IT system administration and CNC machining. Those programs, where they exist, are generally coordinated to some degree by the relevant government, but America’s culture would likely pair better with a privatized apprenticeship model, which could fill niches unseen by a government administrator.</p>



<p>In such a model, companies large enough to sustain internal apprenticeship programs would designate appropriate roles for which they would hire apprentices, like sales or web development. For those roles, they would hire recent high school graduates or even dropouts, who would commit to the apprenticeship program for several years.</p>



<p>The apprentices would be assigned to a team and mentor, just like a typical intern or co-op student worker, with the key difference being that they would stay on each team for one to several years, rotating as appropriate to learn different aspects of their chosen profession.&nbsp;</p>



<p>This on-the-job training would be paired with classroom training, where each cohort of apprentices would be instructed in relevant skills alongside their day job. This might include things like written and oral communication for sales apprentices, psychology and anthropology for marketers, and computer science and graphic design for web developers. Some of these courses could be conducted internally by the company’s more-senior employees; others could be outsourced to local colleges in a reverse co-op arrangement.</p>



<p>The expectation would be that after completion of the apprenticeship program, some of its alumni would keep working in their new profession, while others would then go to college to pursue a broader and deeper formal education. Those that kept working would have the advantage of a four-year head start in their career trajectory and a much better financial situation than a recent college graduate; those that went to college after all would have a very compelling college admissions packet, transfer credits to the extent their employer could negotiate for them with universities, and a much better idea of what is worth studying in college than someone right out of high school. Talented students from poor families and poor schools might benefit to an especial degree from this sort of program, which would let them gain a stable financial footing and a better understanding than that provided by their high school of how to navigate a future college education. In this way, an apprenticeship program would play a similar role to that which the military plays for many teenagers today, but would prepare them for a rather different sort of work.</p>



<p>Of course, some apprentices would probably flounder partway through the program, or conversely be tempted to leave for a competitor. Employers could protect their investment by a similar mechanism to what West Point does for cadets: apprentices could leave at any point during the first year with no strings attached, but those that left later on would have to pay back the expenses incurred in training them. The apprenticeship program could also have a contractual requirement to work for the employer for a certain number of years after completing the program, with the alternative option of paying a financial penalty. Employers could also protect their investments in their apprentices by paying the college tuition of apprenticeship alumni who wished to go to college afterwards, under the condition that they return for a certain number of years after completing their degrees – much like many employers pay for business school for their employees under the condition that they come back afterwards.</p>



<p>This system of white-collar apprenticeships would have significant advantages for both the employer and the apprentice.&nbsp;</p>



<p>The employer would be able to attract some of the most talented and driven teenagers with a unique value proposition and thereby gain a recruiting advantage over competitors that wait to hire much competed-over college graduates. The apprentices, once recruited, would also have the value of being able to perform necessary but less-skilled work that must currently be done by older employees for whom it is tremendously boring. Once done with their contractual term, a number of apprentices could be expected to stick around and keep working for the employer and delivering value for years to come, assuming the employer did a good enough job to keep offering opportunities for advancement and a good work culture.</p>



<p>For high school students, the apprenticeship program would represent a unique opportunity to&nbsp;learn a profession with great career opportunities while earning a living straight out of high school, while keeping options open for a college education and even improving them. Right now, many high school graduates go off to college to study things which they will never use again, and make friends there with people who all too often end up moving to different cities and drifting apart over time. Instead, a well-run apprenticeship program would let students learn a gainful profession and the theoretical knowledge behind it while earning money from day one, and to use some of the most social years of their lives to form bonds with friends who would be far more likely to stay in the same industry and city and remain close social and professional contacts for decades.&nbsp;</p>



<p>Starting a program like this would surely lead to howls of disapproval from those who see the one-size-fits-all track of formal education as the right way for everyone, but the company that started it would be more than compensated for that negative attention by the newfound stream of talent it would be able to access. Done right, an apprenticeship program would prove its worth in a matter of years, and would surely spawn numerous competitors – exactly what our economy needs in this era of degree inflation.</p>



<p>The only question is, which company will seize the opportunity to go first? [3]</p>



<hr>



<p>[1] <a href="https://www.encyclopedia.com/social-sciences/applied-and-social-sciences-magazines/employment-white-collar">https://www.encyclopedia.com/social-sciences/applied-and-social-sciences-magazines/employment-white-collar</a></p>



<p>[2] <a href="https://www.burning-glass.com/wp-content/uploads/Moving_the_Goalposts.pdf">https://www.burning-glass.com/wp-content/uploads/Moving_the_Goalposts.pdf</a></p>



<p>[3] Thanks to Ani Mohan for <a href="https://blog.google/outreach-initiatives/grow-with-google/digital-jobs-program-help-americas-economic-recovery/">this link</a>: a recent Google press release mentions an apprenticeship program! Maybe my former employer will be the one to blaze this trail.</p>



<hr>



<p><em>Thanks to Allie Cavallaro, Ani Mohan, Alex Gruebele, Sal Calvo, Josh Pickering, and Anthony Buzzanco for helping edit drafts of this essay.</em></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://alexkolchinski.com/2020/08/01/the-case-for-white-collar-apprenticeships/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016655</guid>
            <pubDate>Sat, 01 Aug 2020 01:57:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A macroaccounting of the August 2020 financial crisis (pt 1: debt)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24016408">thread link</a>) | @natural219
<br/>
July 31, 2020 | https://clutchofthedeadhand.us/macro/debt | <a href="https://web.archive.org/web/*/https://clutchofthedeadhand.us/macro/debt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <h4>A macroaccounting of the August 2020 financial crisis.</h4>
        <p><em>Part 1: Debt</em>
          <span>Fri July 31</span>
        </p>
      </div>

      <div>
        <p>"Will there be water,</p>
        <p>When my ship comes in?</p>
        <p>And when I set sail...</p>
        <p>Will there be enough wind?"</p>
      </div>
      

      <p>In my <a href="https://cjohnson.io/civics/america-in-2020">State of America 2020</a> post, we went over the many layers of existential crisis America is currently facing. The most pressing one is the economic issue. I wrote:</p>
      <p><em>The next big area of concern is the economy. I actually studied economics in college, and I'll be the first to tell you that most of it is over-wrought academic mumbo-jumbo. What ultimately matters is that the job-money-rent-food cycle continues "working" for most* citizens. Very serious threats like hyperinflation / devaluation of currency, or mass defaults of households and businesses are now on the horizon. When James Carville said "it's the economy, stupid", he was referring to this; if most* people cannot sustain their livelihoods through the economic system, and order cannot be kept through the judicial / military system, that's when the zombie apocalypse starts. Nobody wants the zombie apocalypse to start.</em></p>
      <p>Well, it's been about a full month. I am unhappy to report that the zombie apocalypse unfortunately seems closer than ever. Alex Jones is probably wondering what seasoning <a href="https://www.youtube.com/watch?v=rfZcKCIcug8">goes best on his neighbors</a>.</p>
      <p>I'm joking, of course. Kind of. Here's a brief recap of our economic situation, as of July 31:</p>
      <ul>
      <li>Only ~43% of Americans have some kind of job<ul>
      <li>~18 million Americans remain officially unemployed (U3)</li>
      <li>Another 100 million Americans are categorized as Not In Labor Force</li>
      <li>Another 71 million Americans are not "Officially Employed"</li>
      </ul>
      </li>
      <li>Among those 43%, it is unclear how much income they're actually making. You are counted as "Officially Employed" if you:<ul>
      <li>Work 1 hour / week</li>
      <li>Are temporarily absent from your job, whether or not you are paid for time off</li>
      <li>Worked a minimum of 15 hours without pay for your family's business</li>
      </ul>
      </li>
      <li>According to some surveys, as many as 69% (nice) of Americans have less than $1,000 in savings. (And those are 2019 numbers; it seems safe to assume the % is substantially higher in July 2020)</li>
      <li>The Paycheck Protection Program (extra money for workers) ended on June 30, and the CARES act (additional unemployment benefits) will end today. It seems overwhelmingly likely that additional major stimulus will have to be passed to keep Americans afloat.</li>
      <li>In <strong>April</strong>, the CBO projected the year-total US deficit for 2020 will be <strong>$3.7 trillion dollars</strong> (larger than the entire US debt in 1991) -- <em>before</em> we pass any new stimulus.</li>
      <li>GDP shrank ~10% in the first half of 2020 (from $21.43 trillion in 2019, to an annualized $19.41 trillion now), and although it's expected to bounce back substantially, everything is up in the air due to coronavirus uncertainty.</li>
      <li>Current US debt, before any new stimulus gets passed, is $26.48 trillion.</li>
      <li>This puts us at <strong>136% debt-to-GDP</strong> (123.6%, if you want to be super fair and use 2019 numbers). This is highest in American history, well surpassing the WWII peak at ~122%</li>
      <li>According to <a href="https://www.pgpf.org/blog/2020/06/how-much-is-the-national-debt-what-are-the-different-measures-used#:~:text=The%20United%20States'%20debt%2Dto,is%20the%20highest%20since%201948.">pgpf.org</a>, a whopping 39% of current US debt is held by foreign creditors.</li>
      </ul>
      <p>Everyone seems pretty fine with additional major stimulus (me included). But why should we care about the debt?</p>
      <p>A very common refrain from many pundits, especially post-2008, is that public debt just doesn't matter anymore. The fed can print* as much money as it wants, and as long as there's no detectable inflation, we shouldn't run into any issues. There's a pseudointellectual theory of economics called <a href="https://en.wikipedia.org/wiki/Modern_Monetary_Theory">Modern Monetary Theory</a> which makes a garbled academic case for this point, and there's been a lot of handwringing about it. To save you the trouble; the whole thing is hot philosophical garbage.</p>
      <p>I actually think there's value in it, though, from an absurdist, <em>Modest Proposal</em>-esque troll on the establishment of fiscal politics. As stated in my <em>civics</em> series, the 2008 bailouts basically shattered any sense of justice or reason that legitimized our economic system. If we can just print* trillions of dollars to save big banks and corporations, why can't we just print* trillions of more dollars to fix healthcare, education, and alleviate economic inequality?</p>
      <p>The 20th century macroeconomic models fail us here. While the classical views on macro were mostly debunked by 1973, it really took until 2008 for the entire system to stop making sense completely. And by 2020, we're fully swimming in the theater of the absurd, as this domain of financial sophistry comes head-to-head with the real livelihoods and raw survival decisions of millions of American families.</p>
      <p>I still think there's hope for us to make it through; avoiding a dark age, civil war, zombie apocalypse, military dictatorship, or some other kind of terrible calamity. Mostly, we just need to agree about basic facts and ideas about how the economy works, and then collectively reckon with how out-of-sync our financial system is with the material needs (and wants) of US citizens. Then, we need to elect leaders and agree on policy proposals that both clearly outline a shared future vision for the American economy, and then take whatever necessary steps to get us there safely. All while unifying around rising foreign adversaries that want to divide us, like Russia and China, and -- preferably -- taking meaningful steps to actually address centuries-long racial and economic disparities that have plagued the American populace since its inception.</p>
      <p>Should be easy, right? ðŸ˜…</p>
      <p>I offer nothing in the way of specific answers, platforms, or policy proposals; I am not an economist, historian, or policy guy, and I'm not technically an academic of any kind. I formed most of my perspective on the economy from watching documentaries like <a href="https://www.youtube.com/watch?v=O_TjBNjc9Bo"><em>I.O.U.S.A.</em></a><em>,</em> movies like <a href="https://www.youtube.com/watch?v=1GfqispPMes"><em>The Big Short</em></a>, and reading books like <a href="https://www.amazon.com/Ascent-Money-Financial-History-World/dp/0143116177"><em>The Ascent of Money</em></a>, <a href="https://www.amazon.com/Age-Turbulence-Adventures-New-World/dp/0143114166"><em>The Age of Turbulence</em></a>, and <a href="https://www.penguinrandomhouse.com/books/103996/when-genius-failed-by-roger-lowenstein/"><em>When Genius Failed</em></a>. I disliked most of my own college curriculum (I did study economics for a year or two, before switching to computer science, before dropping out). So take all of this with a grain of salt, and cross-reference my claims with people who actually know wtf they're talking about.</p>
      <p><strong>If you feel like you're totally and completely lost on the subject of economics</strong>, and you've been persuaded to <a href="https://cjohnson.io/civics">take civics seriously</a>, I highly recommend jumping into the history and contemporary debates about it. Trust me; the water is fine. I think a lot of young people lack the confidence to understand or participate in this discussion, because they think it sounds complicated, involves a lot of complex math, or is probably best left to "experts". While it might not be for everyone, I assure you that these concepts are truly not that hard to understand. You don't need any math beyond basic arithmetic, and there are many accessible entry points into the history and politics stuff (the aforementioned I.O.U.S.A. documentary is a great place to start; there's even an <a href="https://www.pbs.org/video/the-ascent-of-money-part-1-from-bullion-to-bubbles/"><em>Ascent of Money</em> TV show</a>). If anything we discuss doesn't make sense initially, just go slow and Google things.</p>
      <p>The outline of this essay series is simple. I only keep track of two metrics regarding the US financial system: the <strong>debt-to-GDP ratio</strong> and the <strong>PPP / exchange rates</strong> of the US dollar. To break this down further, we'll look at three topics in total, split into three different essays:</p>
      <ol>
      <li>Not all debt is created equal</li>
      <li>Not all GDP is created equal</li>
      <li>The power of the USD</li>
      </ol>
      <p>This first essay is about debt.</p>
      <p>===</p>
      <p><strong>Debt</strong></p>
      <p>Everyone understands the basic idea of debt; you borrow money from someone, and you incur a financial obligation to pay them back eventually. That's the most we can say about it definitively. Debt is a truly fascinating subject; there are multitudes of different theories about it, types of it, and personal experiences with it. I can't hope to do the concept itself justice, but I'll certainly offer an abridged take. The way I frame it is like this:</p>
      <p>Debt is a financial relationship (between humans, business entities, governments), which is mediated by both other types of relationships (personal, familial, commercial, civic) and is enforced by specific systems (the legal system, international agreements, physical force). The nature of this relationship is inherently contextual; the interpretation of what a debt <em>means</em> depends highly on the specific parties involved, the surrounding cultural / legal environment, and even the global background setting of world affairs. Debt itself is mostly neutral; it can be used positively, it can be used harmfully, it can be used for growth, and it can be used for control.</p>
      <p>A useful way to break down different types of debt is to examine expectations around repayment, interest, and consequences for defaulting. Let's look at some toy examples, just to get a feel for the different varieties here:</p>
      <ul>
      <li><p>You owe thousands of dollars to a 1920s mafia gangster (maybe you took on a gambling debt, or you owe money for "protection"). You better have his money by next Thursday, or "it'd be a shame if somethin' happened to ya'" (he's going to break your legs, burn down your business, hurt your family, etc.)</p>
      </li>
      <li><p>Your dad loans you $3000 to buy a used car upon graduating high school. Most dads probably don't care when you pay it back, or even if you ever do. Maybe, if he's a jerk, he'll tease you about it often at family gatherings.</p>
      </li>
      <li><p>You recently lost one of your three jobs. To buy food / diapers for your kids, pay rent, and cover your costs for the next month, you take out a payday loan at 350% APR. If you're very lucky, a family member / local church organization chips in to pay it back quickly. In the dismally common case, you just can't pay it back for a while, so your principal balloons to unpayable proportions. You just live in a debt trap; your credit score tumbles, monthly payments rise, and your assets / wages are at risk of …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://clutchofthedeadhand.us/macro/debt">https://clutchofthedeadhand.us/macro/debt</a></em></p>]]>
            </description>
            <link>https://clutchofthedeadhand.us/macro/debt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016408</guid>
            <pubDate>Sat, 01 Aug 2020 01:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retail millennials are now in charge]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24016249">thread link</a>) | @shdc
<br/>
July 31, 2020 | https://shyal.com/blog/retail-millennials-are-now-in-charge | <a href="https://web.archive.org/web/*/https://shyal.com/blog/retail-millennials-are-now-in-charge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
     

    
    â†�
    <a href="https://shyal.com/">ðŸ�&nbsp;</a>
     
    <!-- if has_fences -->
    <!-- <div><a href='/black'><img src='/Attachments/black.svg'/></a></div> -->
    <!--  end  -->
    <p>2020 has flipped the investment scene upside down: retail investors are now in charge. It first struck me when i picked the <a href="https://shyal.com/blog/tesla-stock-bottom-date">tesla stock bottom date</a> while professional financial advisors, professional investors, and economics professors missed the entire 800% move.</p>
<h2 id="millenials-hold-the-reins">Millenials hold the reins</h2>
<p>Don't want to take my word for it? Then in the words of billionaire investor Chamath Paliphpitiya:</p>
<blockquote>
<blockquote>
<p>"Retail investors now have access to so much information that it's almost on parity with people that work in traditional investment organisations" -- Chamath Palihapitiya</p>
</blockquote>
</blockquote>
<p><img alt="Pasted image 48.png" src="https://shyal.com/Attachments/Pasted%20image%2048.png"></p>
<h2 id="the-importance-of-retail-flows">The importance of retail flows</h2>
<p><a href="https://www.biancoresearch.com/about-us/">Jim Bianco</a>, a macro strategist who recently featured on <a href="https://realvision.com/">RealVision</a> also agrees: </p>
<blockquote>
<blockquote>
<p>"Well, that seems to be what's going on with a lot of this money, even though a traditional AAII account might have half a million dollars in it, and a Robinhood account might have 10,000 just to use a number, that 10,000 will turn over every day or two, that half a million might do three trades a year. That Robinhood account will have a bigger influence on the flow of money in and out of the markets than those other accounts. Citadel says that about 25% of all trading in the markets, they said this to Bloomberg a few weeks ago, is retail investors on peak days, 20% on normal days. Now the third group" -- Jim Bianco @ RealVision</p>
</blockquote>
</blockquote>
<p>This means:</p>
<ul>
<li>on peak days, people trading on their apps are actually driving the price action.</li>
<li>the rest of the time (non peak days) they still dictate about a third of the price action.</li>
</ul>
<p>The average Robinhood investor is <a href="https://techcrunch.com/2020/02/20/robinhood-profiles-morgan-stanley-etrade">30 years old</a>. </p>
<p><img alt="Pasted image 51.png" src="https://shyal.com/Attachments/Pasted%20image%2051.png"></p>
<h2 id="listen-to-the-millennials-who-have-savings">Listen to the Millennials (who have savings)</h2>
<p><a href="https://www.youtube.com/watch?v=GGberGnxiJk">Thomas Lee</a> also agrees, and has been warning us that Millennials are now entering into their peak income years. It turns out Millennials love <a href="https://www.investopedia.com/terms/g/growthstock.asp">"growth stocks"</a> (companies which re-invest in themselves and focus on exponential growth).</p>
<p>If TSLA teaches us anything, it is that big disruptive growth stock companies have become too complex for traditional finance to analyze under their existing lense. They'll often blend AI, SAAS, economies of scale, etc. and require a more technologically versed group of analysts to properly price.</p>
<p>Maybe this is something Millenials can do, natively, especially when not pressured by their boomer CEOs while working in the traditional fin jobs? After all, Millenials grew up programming their parents' VCRs.</p>
<p>Another thesis is that <strong>it doesn't matter whether millennials are right or wrong</strong>. They are now calling the shots. If they say it's right, then it's right.</p>
<p><img alt="Pasted image 50.png" src="https://shyal.com/Attachments/Pasted%20image%2050.png"></p>
<h2 id="ditch-your-hedge-fund">Ditch your hedge fund</h2>
<p>We now know that hedge funds are basically a money-making myth:</p>
<blockquote>
<blockquote>
<p>"Hedge funds lost 3.8% of assets globally in 2019, the most since 2009" --<a href="https://www.marketwatch.com/story/clients-withdrew-nearly-1-of-all-hedge-fund-assets-in-december-2020-02-18">market watch</a></p>
</blockquote>
</blockquote>
<p>You can also ditch your financial advisor if they missed all the important trends of 2020. They'll tell you that you cannot live without them; they'll enter self-preservation mode, but remember they make money from you; and the data is showing they should start paying you for advice, not vice versa.</p>
<h2 id="to-sum-up">To sum up</h2>
<ul>
<li>Do your own research, you have access to as much information as investment firms.</li>
<li>Listen to 30 year olds. What companies do they like? <strong>30 year olds dictate the trends</strong>.</li>
<li>Research <strong>good</strong> investment apps: apps that let you directly buy:<ul>
<li>Stocks</li>
<li>Commodities</li>
<li>Bitcoin</li>
</ul>
</li>
<li>Start <strong>small</strong>, while you learn.</li>
</ul>
<p>You are now in charge.</p>
    </div></div>]]>
            </description>
            <link>https://shyal.com/blog/retail-millennials-are-now-in-charge</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016249</guid>
            <pubDate>Sat, 01 Aug 2020 00:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport Energy Use and Greenhouse Gases in Urban Passenger Transport Systems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24016216">thread link</a>) | @simonebrunozzi
<br/>
July 31, 2020 | http://winnspace.uwinnipeg.ca/bitstream/handle/10680/365/Transport_Greenhouse.pdf?sequence=1&isAllowed=y | <a href="https://web.archive.org/web/*/http://winnspace.uwinnipeg.ca/bitstream/handle/10680/365/Transport_Greenhouse.pdf?sequence=1&isAllowed=y">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://winnspace.uwinnipeg.ca/bitstream/handle/10680/365/Transport_Greenhouse.pdf?sequence=1&amp;isAllowed=y</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016216</guid>
            <pubDate>Sat, 01 Aug 2020 00:50:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National Defense Authorization Act: Implications for Design Engineers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24016173">thread link</a>) | @stn8188
<br/>
July 31, 2020 | https://shielddigitaldesign.com/posts/2020_001_ndaa/ndaa/ | <a href="https://web.archive.org/web/*/https://shielddigitaldesign.com/posts/2020_001_ndaa/ndaa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://shielddigitaldesign.com/posts/2020_001_ndaa/ndaa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016173</guid>
            <pubDate>Sat, 01 Aug 2020 00:43:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great Products Aren’t Always Successful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24016147">thread link</a>) | @gk1
<br/>
July 31, 2020 | https://ganotnoa.com/why-great-products-arent-always-successful/ | <a href="https://web.archive.org/web/*/https://ganotnoa.com/why-great-products-arent-always-successful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="35880673" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>As product managers, we are taught to build great products, products that customers really love. Our product management books talk about it loud and clear:</p>



<div>
<div>
<figure><img src="https://ganotnoa.com/wp-content/uploads/2020/07/Book-Cover-678x1024.jpg" alt="" srcset="https://ganotnoa.com/wp-content/uploads/2020/07/Book-Cover-678x1024.jpg 678w, https://ganotnoa.com/wp-content/uploads/2020/07/Book-Cover-199x300.jpg 199w, https://ganotnoa.com/wp-content/uploads/2020/07/Book-Cover-768x1160.jpg 768w, https://ganotnoa.com/wp-content/uploads/2020/07/Book-Cover.jpg 918w" sizes="(max-width: 678px) 100vw, 678px"></figure>




</div>



<div>
<figure><img src="https://ganotnoa.com/wp-content/uploads/2020/07/41q7gZyFigL-resize.jpg" alt="" srcset="https://ganotnoa.com/wp-content/uploads/2020/07/41q7gZyFigL-resize.jpg 324w, https://ganotnoa.com/wp-content/uploads/2020/07/41q7gZyFigL-resize-199x300.jpg 199w" sizes="(max-width: 324px) 100vw, 324px"></figure>




</div>
</div>







<p>but as you become a product leader – CPO, VP Product, Head of Product – you have an extended responsibility. Creating products that customers love is no longer enough. You have to create products that are business successful. And while it may seem that one leads to the other, this is usually not the case.</p>



<p>It’s true that having a product that customers love is necessary in order to demonstrate business success, but that alone does not guarantee the success you are looking for. It’s a necessary but insufficient condition.</p>



<h2>Kevin Costner Was Wrong</h2>



<p>If you are like me, you probably ask “why” a lot, <a href="https://ganotnoa.com/how-to-translate-ceo-product-ideas-into-actual-products/">and when the CEO asks you to do something</a>, you try to find the reasoning behind it and make sure it makes sense.</p>



<p>If you have tried it long enough, and couldn’t find answers, people might have used the old saying “build it and they will come*” to urge you into action. In other words, if you believe in something, go for it, and the rest will align around it.</p>



<p>Unfortunately, in tech products, this is rarely the case. Even if you create a tighter condition here – “build a great product and business will come” – it still doesn’t hold.</p>



<p>I’m not talking about the fact that you need to market and sell the product (you need it at any point in time, with any product, especially before you have product-market fit). I’m talking about products that even with proper sales and marketing still can’t succeed.</p>



<p>How come? Here are a few examples.</p>



<figure><img src="https://lh3.googleusercontent.com/WYLjp8RnairgeyIUDDgeM-4RbrFEZZDhbwknpkHZjET7cc1yegsT54bebBB0a0xeYPEGKRRbq5-pNt1gd-pf-Kubeh9LfCLuU00UfpsEehrYO2vcfQ1_5ZcxuCV3s2-TSoUsZApB" alt=""></figure>



<p><em>* the original quote from the 1989 Kevin Costner movie Field of Dreams is “if you build it, he will come”. But nonetheless, the misquote “build it and they will come” has become widely used in business. You can’t trust misquotes 😉</em></p>



<h2>They Love the Product, but Won’t Pay</h2>



<p>The simplest example of why a great product isn’t enough to bring you business success is the following: your customers love the product. They use it, a lot. They recommend it to their friends. They don’t want it to go away. But that’s only true as long as the product is free. They love it, but not enough to pay for it.&nbsp;</p>



<p>Of course, other business models exist. If you have a wide customer base of people who love your product and use it all the time, <a href="https://www.investopedia.com/articles/investing/032515/whatsapp-best-facebook-purchase-ever.asp#:~:text=When%20Facebook%20announced%20its%20plans,billion%2C%20or%20%2455%20per%20user.">Facebook might acquire you for $16B</a>. But for us, the mere mortals who are not Google or Facebook, monetization strategy should be a core part of our path to success.&nbsp;</p>



<p>Another version of this issue is when your customers are willing to pay, but not enough to justify your CAC, or otherwise not enough to build a successful business. Do the math – <strong>what do you need the numbers to be in order to succeed?</strong> Think about short term goals – meeting this year’s revenue goals for example, and long term ones – like keeping a viable, growing business.</p>



<h2>They Love the Product, but Can’t Pay</h2>



<p>Another issue, relevant mostly to B2B products, is when your users love the product, but they are not the ones who make the purchase decision. They also don’t have a budget to allocate for this, and usually can’t justify why this is a good purchase to the decision-makers within their company.&nbsp;</p>



<p>Here is an important rule for building successful B2B products: <strong>you must solve a problem for the buyer, not only for the user</strong>. Even if the buyer is the manager of the users (for example you are selling to the accounting department, and the department manager is the one who makes the decision), they might not see the problem the same way or not feel it is justifying purchasing the product.&nbsp;</p>



<p>In your product strategy, you should have a detailed description of the user persona as well as the buyer persona, and make sure you solve the problem that each of them cares about. <strong>Even if that means solving two different problems simultaneously.</strong></p>



<h2>They Love the Product, but They Are the Only Ones</h2>



<p>Tech products require a heavy investment in development. That’s why most startups need VC funding in order to grow. Becoming profitable (even without considering that any revenue is then invested back into development) is a very late stage for startups.&nbsp;</p>



<p>The reason VCs are willing to invest huge amounts of money in the risky business of tech startups is the assumption that once the product is built, it can be sold in masses to return the heavy initial investment. Simply put, this means that you should address a huge market from the get-go, otherwise you won’t be able to raise money – no matter how great your product really is.</p>



<p>That is not the only problem with a total addressable market that is too small. If you don’t have a large potential market, most likely you won’t be able to even build a product that your customers love (since you won’t be able to iterate and explore freely). And of course, since you will be nowhere near owning 100% of the market, the overall revenue might be too small.</p>



<p><strong>The business world measures growth, and even worse for you – sustainable growth</strong>. That is, not only you have to show that your business is growing, you have to convince the market that you can maintain and expand this growth rate. If the customers who love your product are not too many, it will be impossible for you to demonstrate the required growth rates.</p>



<h2>Is It a Product Problem?</h2>



<p>Usually when I start working with a new company, one of the first questions that come up is where is the problem exactly. If your product isn’t selling well enough, is it a product issue? Maybe the product is fine, but the sales team isn’t good enough? Or perhaps it’s a marketing problem?</p>



<p>The thing is, that if you look at everything I listed above, these are fundamental issues in the product definition. Not the features definition, not the experience, but still – definitely product.&nbsp;</p>



<p>Even if you have the most talented sales and marketing teams, if you define a product that only speaks to a very small market, they won’t be able to bring more sales. And <a href="https://ganotnoa.com/before-you-deem-your-product-a-failure-check-your-target-audience/">if you define a product that doesn’t work for the buyer and only for the user</a>, guess what – the buyers won’t be convinced and sales won’t happen.</p>



<p><strong>Defining the right product starts with choosing the right problem to solve</strong>. One that is worth paying money for, that is important enough to both the user and the buyer, and that is wide enough for you to build a successful tech company.</p>



<p>Rate your product according to the criteria I just mentioned. How are you doing in each? Start owning the business success of your product by making sure you choose the right problem. Haven’t got a perfect score? It’s never too late to refine the product strategy and pivot. Every successful company you can think of has done it. Maybe you should too.</p>



<hr>
		</div>
				</div></div>]]>
            </description>
            <link>https://ganotnoa.com/why-great-products-arent-always-successful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016147</guid>
            <pubDate>Sat, 01 Aug 2020 00:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defragmenting DNS: determining the optimal maximum UDP response size for DNS [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24015927">thread link</a>) | @fanf2
<br/>
July 31, 2020 | https://rp.delaat.net/2019-2020/p78/report.pdf | <a href="https://web.archive.org/web/*/https://rp.delaat.net/2019-2020/p78/report.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://rp.delaat.net/2019-2020/p78/report.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015927</guid>
            <pubDate>Sat, 01 Aug 2020 00:09:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TODO Zero: Write more robust code by treating TODOs like sticky notes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24015723">thread link</a>) | @countermeasure
<br/>
July 31, 2020 | https://redandblack.io/blog/2020/todo-zero/ | <a href="https://web.archive.org/web/*/https://redandblack.io/blog/2020/todo-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <p>When used well, TODOs can help you write more robust code and minimise
unhandled edge cases. When used badly, they disappear into your codebase and
are forgotten, marking problems which will never be fixed.</p>
<p>Here’s what I think of as a best-practice system for using TODOs. It treats
them like sticky notes and is made up of two rules and four actions. I call it
“TODO Zero”.</p>
<h2 id="the-two-rules">The two rules</h2>
<p>There are only two rules, and everything flows from them.</p>
<p>They are:</p>
<ol>
<li>
<p>Capture every useful thought in a TODO.</p>
</li>
<li>
<p>Leave no TODOs in shipped code.</p>
</li>
</ol>
<h2 id="the-four-actions">The four actions</h2>
<p>Something must be done with a TODO which was created because of Rule 1 before
it is deleted because of Rule 2, so the rules give rise to the four actions.</p>
<p>They are:</p>
<ol>
<li>
<p>Disregard it.</p>
</li>
<li>
<p>Do it.</p>
</li>
<li>
<p>Create an issue (or ticket) from it.</p>
</li>
<li>
<p>Convert it to a note.</p>
</li>
</ol>
<h2 id="the-system">The system</h2>
<p>These rules and actions combine to create a simple system which works like
this.</p>
<p>When you’re writing code and you have a useful idea or thought which isn’t
directly relevant to the code you’re writing at that instant, record it as a
TODO. Then as soon as you’ve done that forget about it and go back to the
code you were writing.</p>
<p>Treat a TODO as a temporary reminder, like a sticky note. It serves two
purposes. The first is to make sure that ideas and insights which you can’t act
on straight away aren’t forgotten. The second is to clear your mind of thoughts
that aren’t relevant to what you’re doing right at that instant.</p>
<p>Over your work session, review the TODOs you’ve written. Your aim for each one
is to use one of the four actions to deal with it, and then delete it. Just
like sticky notes, TODOs are thrown out as soon as they’ve served their purpose
as a reminder, and just like sticky notes, they don’t make it into the final
product.</p>
<p>Before your code reaches the branch from which you ship (i.e. release or
deploy), all the TODOs you’ve created should be deleted. No TODOs should
survive in your finished code, which is where the name <em>TODO Zero</em> comes from.</p>
<h2 id="lets-dive-in">Let’s dive in</h2>
<p>That was the high-level summary, now stay with me as I explain how it works,
why it works and how to best make it work for you.</p>
<p>First, let’s start with a look at the most common problem <em>TODO Zero</em> saves you
from – The Forgotten TODO.</p>
<h2 id="the-forgotten-todo">The Forgotten TODO</h2>
<p>A TODO usually marks something that the person who left it didn’t have the
time, energy or knowledge to take care of.</p>
<p>Let’s say you’re coding productively and you don’t want to slow down to handle
an unlikely edge case, so you quickly throw in a comment like this and move on:</p>
<div><pre><code data-lang="python"><span># TODO: Handle an empty list.</span></code></pre></div>
<p>Or you’re racing the clock on a deadline. The function you’ve just finished is
unpleasantly complicated <em>but it works</em>, and so you add a note like this above
it:</p>
<div><pre><code data-lang="python"><span># TODO: Clean this function up.</span></code></pre></div>
<p>Or maybe an aspect of what you’re doing is a bit beyond your current
capabilities, so you leave a comment like this behind hoping that someone with
the right skills will see it one day and sort it out:</p>
<div><pre><code data-lang="python"><span># TODO: Optimise for large querysets.</span></code></pre></div>
<p>It’s easy to write a TODO and tell ourselves someone will get to it sometime.
But is that what really happens once we finish working with that code? Does
someone get to it, ever? In my experience, the answer is usually “no”.</p>
<p>How often have you stumbled across a TODO in some rarely visited code, only to
ignore it and move on because it’s not relevant to the task at hand? How many
people before you have ignored that same comment, just as you did? And so there
it stays through the ages, forgotten.</p>
<p><em>TODO Zero</em> stops TODOs being forgotten because it requires us to do something
with them rather than letting them sneak into shipped code.</p>
<p>Let’s see how to put it into practice!</p>
<h2 id="rule-1-capture-every-useful-thought-in-a-todo">Rule 1: Capture every useful thought in a TODO</h2>
<p>If you’re anything like me, you’ll have thoughts and realisations about the
code you’re working on faster than you can implement them.</p>
<p>Many of these will be useful, and easily forgotten. If you try to remember
them, you’ll find that they get in the way of you focusing properly on the code
you’re writing, <em>and you’ll still forget some</em>. The less you try to remember,
the lower your <a href="https://en.wikipedia.org/wiki/Cognitive_load" target="_blank">cognitive load</a> and the more clearly you can think.</p>
<p>It’s much better to capture them in TODOs as they come to you, as if you were
jotting them down quickly on sticky notes. Do this and you can come back and
take care of each one when you have time and can give it your full attention.</p>
<p>Let’s say you’ve just finishing writing the signature of the <code>display_errors</code>
function when two edge cases it will need to handle come to mind. You can
capture them like this:</p>
<div><pre><code data-lang="python"><span>def</span> <span>display_errors</span>(error_list):
    <span># TODO: Handle a really long list. Truncate and add count of hidden items?</span>
    <span># TODO: Handle error messages with &gt;100 characters.</span></code></pre></div>
<p>It’s better to get the main path through the function fleshed out before
shifting focus to handle those edge cases, so you make them into TODOs and
forget about them for now.</p>
<p>Then let’s say you’re only two lines into <code>display_errors</code> when you have a
realisation about the thread-safety of the <code>build_pdf</code> function you wrote an
hour ago. Again, capture it in a TODO. It doesn’t matter where. You can put it
right where you’re working for the time being and move it later:</p>
<div><pre><code data-lang="python"><span>def</span> <span>display_errors</span>(error_list):
    <span>for</span> error <span>in</span> error_list:
        <span>print</span>(error)
    <span># TODO: Ensure that build_pdf function is thread-safe.</span>
    <span># TODO: Handle a really long list. Truncate and add hidden item count?</span>
    <span># TODO: Handle error messages with &gt;100 characters.</span></code></pre></div>
<p>When you use TODOs in this way, you ensure that every realisation and edge case
which occurs to you is recorded and will be dealt with. Once recorded they
can’t fall through the cracks, so your code will be more robust.</p>
<p>Because a TODO is now just a note to yourself, don’t take time making it
detailed or perfect. You’re the only one who will read it. As long as you can
understand it, that’s all that matters. Just like a sticky note.</p>
<p>Anyone familiar with <a href="https://en.wikipedia.org/wiki/David_Allen_%28author%29" target="_blank">David Allen's</a>
<a href="https://en.wikipedia.org/wiki/Getting_Things_Done" target="_blank">Getting Things Done (GTD) methodology</a> will recognise what I’ve just
described as what he calls “ubiquitous capture”. Which is really just another
way of saying that if you have a good idea, record it somewhere so you don’t
forget it.</p>
<h2 id="rule-2-leave-no-todos-in-shipped-code">Rule 2: Leave no TODOs in shipped code</h2>
<p>The TODOs you create represent tasks you need to do, problems you need to solve
or ideas you need to consider as part of the work you’re doing.</p>
<p>Every single one should be addressed and then removed before the code reaches
the branch you ship from.</p>
<p>By addressing them all, you gain the confidence of knowing that every potential
problem or issue which occurred to you has been dealt with, so your code is as
thorough as you can make it.</p>
<p>Addressing a TODO requires you to <em>do something with it</em> so that it is no
longer needed. That means applying one of the four actions – disregard it, do
it, create an issue from it or convert it to a note. I’ll explain each of them
in more detail shortly.</p>
<p>As you progress through the work you’re doing, take some time now and then to
look over the TODOs you’ve made. When the time is right for each one, do
something with it and then delete it.</p>
<p>I use this <a href="https://www.gnu.org/software/make/manual/make.html#Introduction" target="_blank">Makefile</a> target which lists all TODOs to help with that:</p>
<div><pre><code data-lang="make"><span>todos</span>:
    @grep -r -v <span>"| grep TODO"</span> . | grep TODO
</code></pre></div>
<p>You should find that as you get closer to finishing there are fewer and fewer
remaining. When you finish, ensure that there are none left at all. Your code
is not complete until they have all been addressed and removed.</p>
<p>Again, think of a TODO like a sticky note. It’s a scrappy short-term reminder
that doesn’t belong in a finished product and is disposed of when it has served
its purpose.</p>
<p>Now let’s look at each of the four actions.</p>
<h2 id="action-1-disregard-it">Action 1: Disregard it</h2>
<p><em>Sometimes you’re wrong.</em></p>
<p>When you record all the thoughts and ideas that cross your mind, once you come
back later to give them your full attention, it’s inevitable that some will
turn out to be junk, or mistakes, or just not worth doing.</p>
<p>Maybe you thought you saw an edge case where there wasn’t one. Maybe what
seemed like a good idea turns out to be a bad idea. Maybe you saw an
opportunity for an optimisation which would actually be too time-consuming to
be worth doing.</p>
<p>Not to worry. When you come across a TODO like this, disregard it, delete it,
and move on.</p>
<h2 id="action-2-do-it">Action 2: Do it</h2>
<p><em>Sometimes you’re right.</em></p>
<p>Often a TODO contains a good idea that’s worth doing, and worth doing now.</p>
<p>Maybe it’s an easy optimisation. Maybe it’s dealing with an edge case.</p>
<p>If it’s necessary to complete your work, or if it’s not but you think it’s
worth doing now anyway, do it. Then once you’ve done it, delete that TODO.</p>
<h2 id="action-3-create-an-issue-or-ticket-from-it">Action 3: Create an issue (or ticket) from it.</h2>
<p><em>Sometimes it can wait for later.</em></p>
<p>There will be some TODOs which describe something which will need to be done
eventually, but which can wait until after your code is shipped.</p>
<p>For each of these, create an issue from it in the project’s issue tracker, then
delete the TODO.</p>
<p>Although some people argue that in cases like this leaving TODOs in shipped
code is an effective way to track tasks that need to be done, I disagree. I’m a
believer in the benefits of having a single source of truth for work to be
done. When an issue tracker isn’t tracking <em>all</em> the work for a project, you
undermine its effectiveness, and I say that because my experience is that
what’s not in the issue tracker doesn’t get done.</p>
<h2 id="action-4-convert-it-to-a-note">Action 4: Convert it to a note.</h2>
<p><em>Sometimes it’s just not going to happen.</em></p>
<p>Some TODOs fall into the category of “in a perfect world we’d address that, but
it’s never likely to be important enough to worry about”.</p>
<p>In my experience, these are often the ones which flag edge cases which are
either very unlikely to arise, or won’t have worrying consequences when they
do, or both.</p>
<p>It’s not appropriate to create issues about these in your issue tracker,
because you don’t actually intend to do anything about them.</p>
<p>But it is helpful to convert them into NOTEs which point out the shortcomings
of the code for the benefit of people who will work with it in the future.</p>
<p>As an example, you …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://redandblack.io/blog/2020/todo-zero/">https://redandblack.io/blog/2020/todo-zero/</a></em></p>]]>
            </description>
            <link>https://redandblack.io/blog/2020/todo-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015723</guid>
            <pubDate>Fri, 31 Jul 2020 23:45:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an Electron App with Bazel]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24015649">thread link</a>) | @grahar64
<br/>
July 31, 2020 | https://maori.geek.nz/building-an-electron-app-with-bazel-d124ed550957 | <a href="https://web.archive.org/web/*/https://maori.geek.nz/building-an-electron-app-with-bazel-d124ed550957">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://maori.geek.nz/@GrahamJenson?source=post_page-----d124ed550957----------------------" rel="noopener"><img alt="Graham Jenson" src="https://miro.medium.com/fit/c/96/96/0*1bdqD2hM_lzBk_GT.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="dd4a">I want to build a desktop app with:</p><ol><li id="927b"><a href="https://www.electronjs.org/" target="_blank" rel="noopener">Electron.js</a>: A framework to build a desktop application using a <a href="https://nodejs.org/en/" target="_blank" rel="noopener">Node.js</a> and the <a href="https://www.chromium.org/" target="_blank" rel="noopener">Chromium</a> browser</li><li id="c20f"><a href="https://bazel.build/" target="_blank" rel="noopener">Bazel</a>: a build system to quickly build, test and run applications</li></ol><p id="353d">They seem like they might go well together, so let’s see. <em>Note: we will be focusing on </em><strong><em>macOS only </em></strong><em>for simplicity.</em></p><p id="af3d"><strong><em>All code is located at </em></strong><a href="https://github.com/grahamjenson/bazel-electron" target="_blank" rel="noopener"><strong><em>https://github.com/grahamjenson/bazel-electron</em></strong></a></p><h2 id="dc3c">The Electron Application</h2><p id="1c72">An electron app (in macOS) is a folder with the electron binaries (Node.js Chromium, and libraries downloaded from <a href="https://github.com/electron/electron/releases" target="_blank" rel="noopener">https://github.com/electron/electron/releases</a>) and three application files located at:</p><pre><span id="337c">electron/Electron.app/Contents/Resources/app/<br>├── package.json<br>├── main.js<br>└── index.html</span></pre><p id="c409"><code>package.json</code> can just be <code>{"main":"main.js"}</code> to reference the main entry point for the Node.js app <code>main.js.</code> <code>main.js</code> must initialize the main Chromium window of the frontend application defined in <code>index.html</code>.</p><p id="1347">A simple <code>main.js</code> starts with some definitions:</p><pre><span id="57b0">const {app, BrowserWindow} = require('electron')<br>let mainWindow = null</span></pre><p id="97c1">Then set up an <code>initialize</code> function for the <code>app</code>:</p><pre><span id="1a7b">function initialize () {<br>  app.setName('Electron Simple App')<br>  app.on('ready', () =&gt; {<br>    createWindow()<br>  })<br>  app.on('window-all-closed', () =&gt; {<br>      app.quit()<br>  })<br>  app.on('activate', () =&gt; {<br>    if (mainWindow === null) {<br>      createWindow()<br>    }<br>  })<br>}</span></pre><p id="6c83">Then write the <code>createWindow</code> function:</p><pre><span id="f494">function createWindow () {<br>  const windowOptions = {<br>   width: 600,<br>   minWidth: 600,<br>   height: 500,<br>   title: app.getName()<br>  }<br>  mainWindow = new BrowserWindow(windowOptions)<br>  mainWindow.loadURL('file://' + __dirname + '/index.html')<br>  mainWindow.webContents.openDevTools()<br>  mainWindow.on('closed', () =&gt; {<br>  mainWindow = null<br> })<br>}</span></pre><p id="d2f4">Finally call the <code>initialize()</code> function.</p><p id="cf18">The <code>index.html</code> is the entry point into your frontend application linked above with <code>loadURL</code>. This can be as simple as:</p><pre><span id="72f5">&lt;html&gt;<br> &lt;body&gt; Hello &lt;/body&gt;<br> &lt;script&gt; console.log("World") &lt;/script&gt;<br>&lt;/html&gt;</span></pre><p id="38f6">This electron app renders as:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1422/1*vS_SKcJKTrHzCySM_hpMVA.png" width="711" height="291" srcset="https://miro.medium.com/max/552/1*vS_SKcJKTrHzCySM_hpMVA.png 276w, https://miro.medium.com/max/1104/1*vS_SKcJKTrHzCySM_hpMVA.png 552w, https://miro.medium.com/max/1280/1*vS_SKcJKTrHzCySM_hpMVA.png 640w, https://miro.medium.com/max/1400/1*vS_SKcJKTrHzCySM_hpMVA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*vS_SKcJKTrHzCySM_hpMVA.png?q=20"></p></div></div></div></figure><h2 id="6b71">Bazel bits</h2><p id="5349">I got the above working by just writing and copying files around in the electron folders, but I want Bazel to do that for me. I want a Bazel rule like:</p><pre><span id="55f7">load(":electron.bzl", "electron_app")<br>electron_app(<br>  name = "simple-app",<br>  app_name = "simple-app",<br>  index_html = ":index.html",<br>  main_js = ":main.js",<br>)</span></pre><p id="9f84">So that I can run <code>bazel run :simple-app</code> to build then start the electron app.</p><p id="d57f">The first step is to download the electron binaries in the <code>WORKSPACE</code> file:</p><pre><span id="0870">http_file(<br>  name = "electron_release",<br>  sha256 = "594326256...ca1f41ec",<br>  urls = ["<a href="https://github.com/electron/electron/releases/download/v8.4.1/electron-v8.4.1-darwin-x64.zip" target="_blank" rel="noopener">https://github.com/electron/electron/releases/download/v8.4.1/electron-v8.4.1-darwin-x64.zip</a>"],<br>)</span></pre><p id="e680"><strong><em>Note:</em></strong><em> I would like to use the </em><code><em>http_archive</em></code><em> rule instead, but the app uses symlinked folders that confuse Bazel’s </em><code><em>glob</em></code><em> function. To fix this the rule unzips the file (which is not optimal but it works)</em></p><p id="c689">So the rule will look like:</p><pre><span id="1a42">electron_app = rule(<br>  implementation = electron_app_,<br>  executable = True,<br>  attrs = {<br>    "app_name": attr.string(),<br>    "main_js": attr.label(allow_single_file = True),<br>    "index_html": attr.label(allow_single_file = True),<br>    "_electron_release": attr.label(<br>      allow_single_file = True,<br>      default = Label("<a href="http://twitter.com/electron_release" target="_blank" rel="noopener">@electron_release</a>//file"),<br>    ),<br>    "_electron_bundle_tool": attr.label(<br>      executable = True,<br>      cfg = "host",<br>      allow_files = True,<br>      default = Label("//:bundle"),<br>    ),<br>    "_electron_app_script_tpl": attr.label(<br>      allow_single_file = True,<br>      default = Label("//:run.sh.tpl"),<br>    ),<br>  },<br>  outputs = {<br>    "apptar": "%{name}.tar",<br>    "run": "%{name}.sh",<br>  },<br>)</span></pre><p id="c721">This takes the <code>app_name</code>, <code>main.js</code> and <code>index.html</code> from the user. It then uses</p><ol><li id="248c"><code>_electron_release</code>: downloaded release from github</li><li id="dc32"><code>_electron_bundle_tool</code>: a golang script to create the electron app</li><li id="7083"><code>_electron_app_script_tpl</code>: the script used to run the application</li></ol><p id="d99e">The <code>_electron_bundle_tool</code>golang script <code>bundle.go:</code></p><ol><li id="ceb0">Unzip the Electron release, add those files to <code>tar</code></li><li id="15b9">copy <code>package.json</code> <code>main.js</code> and <code>index.html</code> add those files to <code>tar</code></li><li id="18a2">write <code>tar</code></li></ol><p id="9c89">This looks like:</p><pre><span id="d4e5">func main() {<br> outputFile := os.Args[1]<br> name := os.Args[2]<br> mainJS := os.Args[3]<br> indexHTML := os.Args[4]<br> electronZIP := os.Args[5]<br> appName := name + ".app/"</span><span id="f6e8"> // Unzip<br> rawFiles, _ := Unzip(electronZIP, "electronZIP")</span><span id="10d6"> tarFiles := map[string]string{}</span><span id="ab2a"> // Add Electron Files to tar<br> for _, f := range rawFiles {<br>  zipPrefix := "electronZIP/Electron.app/"<br>  if strings.HasPrefix(f, zipPrefix) {<br>   tarFiles[f] = appName + strings.TrimPrefix(f, zipPrefix)<br>  }<br> }</span><span id="044f"> // Add App files to tar<br> appFolder := "Contents/Resources/app/"<br> tarFiles[mainJS] = appName + appFolder + "main.js"<br> tarFiles[indexHTML] = appName + appFolder + "index.html"<br> ioutil.WriteFile("package.json", []byte(PACKAGE_JSON), 0644)<br> tarFiles["package.json"] = appName + appFolder + "package.json"</span><span id="1807">// Write Tar File<br> writeTar(outputFile, tarFiles)<br>}</span></pre><p id="0ee2">The <code>_electron_app_script_tpl</code> is the script to run to open the electron app, which just un-tars the app, then opens it, i.e.:</p><pre><span id="780f">tar -xf {{app}}<br>// Open app and wait for exit<br>open -W {{name}}.app</span></pre><p id="11e0"><strong>All together</strong></p><p id="6580">With this all setup <code>bazel run :simple-app</code> will start the application up. There is no live reload or other nice dev tools, so there is lots to improve about this workflow. The nice thing is that the built tar is easy to distribute as a completed app immediately.</p><h2 id="feeb">Bazel to Electron</h2><p id="baee">Bazel is a pretty useful tool and electron is surprisingly simple to get a basic application built. Next steps would be adding tools like <code><a href="https://github.com/maxence-charriere/go-app" target="_blank" rel="noopener">go-app</a></code> to build applications using golang or maybe use <code><a href="https://github.com/zserge/lorca" target="_blank" rel="noopener">lorca</a></code> instead of electron to reduce the final tar size to something more easily distributable.</p><p id="349d"><strong><em>Again, all code is located at </em></strong><a href="https://github.com/grahamjenson/bazel-electron" target="_blank" rel="noopener"><strong><em>https://github.com/grahamjenson/bazel-electron</em></strong></a></p></div></div></section></div></div>]]>
            </description>
            <link>https://maori.geek.nz/building-an-electron-app-with-bazel-d124ed550957</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015649</guid>
            <pubDate>Fri, 31 Jul 2020 23:37:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero-Cost References with Regions]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24015581">thread link</a>) | @verdagon
<br/>
July 31, 2020 | https://vale.dev/blog/zero-cost-refs-regions | <a href="https://web.archive.org/web/*/https://vale.dev/blog/zero-cost-refs-regions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://vale.dev/blog/zero-cost-refs-regions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015581</guid>
            <pubDate>Fri, 31 Jul 2020 23:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Free word/sentence vectorizer as an API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24015393">thread link</a>) | @theo31
<br/>
July 31, 2020 | https://app.inferrd.com/packages/glovevectors | <a href="https://web.archive.org/web/*/https://app.inferrd.com/packages/glovevectors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://app.inferrd.com/packages/glovevectors</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015393</guid>
            <pubDate>Fri, 31 Jul 2020 23:12:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tree Who Set Healthy Boundaries]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24015116">thread link</a>) | @jaden
<br/>
July 31, 2020 | https://www.topherpayne.com/giving-tree | <a href="https://web.archive.org/web/*/https://www.topherpayne.com/giving-tree">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div tabindex="-1" data-is-mobile="false" data-is-mesh="true" data-site-width="980" data-state="" id="PAGES_CONTAINER"><div id="PAGES_CONTAINERcenteredContent"><div id="PAGES_CONTAINERinlineContent"><div><div data-ismobile="false" data-is-mesh-layout="true" id="b5xc1"><div id="b5xc1inlineContent"><div id="b5xc1inlineContent-gridWrapper" data-mesh-internal="true"><div id="b5xc1inlineContent-gridContainer" data-mesh-internal="true"><p data-packed="true" data-vertical-text="false" id="comp-kd0ugimg"><h2><span><span>the tree who set</span></span></h2>

<h2><span><span>healthy boundaries</span></span></h2></p><div data-packed="true" data-vertical-text="false" id="comp-kd0ugimz"><p><span><span>an alternate ending for</span></span></p>

<p><span><span>Shel Silverstein's "The Giving Tree"</span></span></p>

<p><span><span>part of the <span>"Topher Fixed It"</span> series for young people</span></span></p>

<p><span>​</span></p>

<p>Just read "The Giving Tree" as usual, right up to the point where the Boy comes hustling for a house. Then feel free to print these pages and paste them over everything that follows.</p>

<p><span>​</span></p>

<p>The alternate endings are available for you to print for free. If you enjoy them, I hope you'll consider a donation to <span><span><span><a href="https://www.atlartsrelief.org/" target="_blank" data-content="https://www.atlartsrelief.org/" data-type="external" rel="noopener">The Atlanta Artist Relief Fund</a></span></span></span>, which is providing crucial assistance to my colleagues during the COVID crisis.</p>

<p><span>​</span></p></div><div title="How about another story?" data-is-responsive="false" data-display-mode="fill" data-content-padding-horizontal="0" data-content-padding-vertical="0" data-exact-height="125" id="comp-kdaz5axp"><a href="https://www.topherpayne.com/rainbow-fish" target="_self" id="comp-kdaz5axplink"><wix-image data-has-bg-scroll-effect="" data-image-info="{&quot;imageData&quot;:{&quot;type&quot;:&quot;Image&quot;,&quot;id&quot;:&quot;dataItem-kdaz5b5b&quot;,&quot;metaData&quot;:{&quot;pageId&quot;:&quot;b5xc1&quot;,&quot;isPreset&quot;:false,&quot;schemaVersion&quot;:&quot;1.0&quot;,&quot;isHidden&quot;:false},&quot;title&quot;:&quot;How about another story?&quot;,&quot;uri&quot;:&quot;91bb14_8535834c540b4f35b9f6b2ace38a1e37~mv2.jpg&quot;,&quot;description&quot;:&quot;&quot;,&quot;width&quot;:2400,&quot;height&quot;:3150,&quot;alt&quot;:&quot;Rainbow Fish Alternate Ending&quot;,&quot;name&quot;:&quot;Cover.jpg&quot;,&quot;link&quot;:{&quot;type&quot;:&quot;PageLink&quot;,&quot;id&quot;:&quot;dataItem-kdaz639r&quot;,&quot;metaData&quot;:{&quot;pageId&quot;:&quot;b5xc1&quot;,&quot;isPreset&quot;:false,&quot;schemaVersion&quot;:&quot;1.0&quot;,&quot;isHidden&quot;:false},&quot;pageId&quot;:{&quot;type&quot;:&quot;Page&quot;,&quot;id&quot;:&quot;toknp&quot;,&quot;metaData&quot;:{&quot;pageId&quot;:&quot;masterPage&quot;,&quot;isPreset&quot;:false,&quot;schemaVersion&quot;:&quot;2.0&quot;,&quot;isHidden&quot;:false},&quot;title&quot;:&quot;rainbow fish&quot;,&quot;hideTitle&quot;:true,&quot;icon&quot;:&quot;&quot;,&quot;descriptionSEO&quot;:&quot;An alternate ending to the beloved but problematic book by Marcus Pfister&quot;,&quot;metaKeywordsSEO&quot;:&quot;&quot;,&quot;pageTitleSEO&quot;:&quot;&quot;,&quot;pageUriSEO&quot;:&quot;rainbow-fish&quot;,&quot;hidePage&quot;:true,&quot;isMobileLandingPage&quot;:false,&quot;underConstruction&quot;:false,&quot;tpaApplicationId&quot;:0,&quot;pageSecurity&quot;:{&quot;requireLogin&quot;:false,&quot;passwordDigest&quot;:&quot;&quot;,&quot;dialogLanguage&quot;:&quot;&quot;},&quot;isPopup&quot;:false,&quot;indexable&quot;:true,&quot;isLandingPage&quot;:false,&quot;pageBackgrounds&quot;:{&quot;desktop&quot;:{&quot;custom&quot;:true,&quot;isPreset&quot;:true},&quot;mobile&quot;:{&quot;custom&quot;:true,&quot;isPreset&quot;:true,&quot;mediaSizing&quot;:&quot;viewport&quot;}},&quot;translationData&quot;:{&quot;uriSEOTranslated&quot;:false},&quot;advancedSeoData&quot;:&quot;{\&quot;tags\&quot;:[{\&quot;type\&quot;:\&quot;meta\&quot;,\&quot;props\&quot;:{\&quot;property\&quot;:\&quot;og:image\&quot;,\&quot;content\&quot;:\&quot;91bb14_51f0ba32a0814acab3ae923d2f186dd5~mv2.jpg\&quot;},\&quot;meta\&quot;:{\&quot;width\&quot;:2251,\&quot;height\&quot;:1217}}]}&quot;},&quot;target&quot;:&quot;_self&quot;},&quot;displayMode&quot;:&quot;fill&quot;},&quot;containerId&quot;:&quot;comp-kdaz5axp&quot;,&quot;displayMode&quot;:&quot;fill&quot;}" data-has-ssr-src="true" data-is-svg="false" data-is-svg-mask="false" id="comp-kdaz5axpimg"><img id="comp-kdaz5axpimgimage" alt="Rainbow Fish Alternate Ending" data-type="image" itemprop="image" src="https://static.wixstatic.com/media/91bb14_8535834c540b4f35b9f6b2ace38a1e37~mv2.jpg/v1/fill/w_95,h_125,al_c,q_80,usm_0.66_1.00_0.01,blur_3/Cover.jpg"></wix-image></a></div><p><span>Topher fixed this too</span></p></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.topherpayne.com/giving-tree</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015116</guid>
            <pubDate>Fri, 31 Jul 2020 22:44:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introverts are excluded unfairly in an extraverts’ world]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24015012">thread link</a>) | @__ka
<br/>
July 31, 2020 | https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Life as an introvert</strong> is rarely easy. Ever since I graduated, Iâ€™ve been compelled to work in open-plan offices. Itâ€™s exhausting. Imagine being engaged in a task that requires high concentration, such as looking for a lost earing in the middle of a tennis court. Now imagine that an automatic ball launcher keeps shooting balls directly at you. Wouldnâ€™t you get tired quickly, and be much less efficient in your search? This is how I feel during my work, when sudden and repeating distractions are â€˜shotâ€™ at or near my desk.</p><p>The struggle of an introvert doesnâ€™t end in the office. Networking at conferences, some with thousands of attendees, is a central part of an academic career. Picture yourself entering a huge hall, with bright neon lights, hundreds of people in each aisle, and a background din that forces you to yell to be heard. In a typical two-hour poster session, youâ€™re expected to acquire the information you need while also efficiently introducing your own work to colleagues. As an introvert, the experience is equal to riding a terrifying rollercoaster while having to maintain a big smile on your face.</p><p>I wish I could say these types of challenge are limited to the work environment, but thatâ€™s not the case. For my most recent birthday, a friend bought me a dinner at EatWith â€“ a meal-sharing platform. Youâ€™re invited to dine in the house of strangers who cook for you and other participating guests. I would enjoy the food and cultural experience if I didnâ€™t have to go through the excruciating labour of small talk with random people. â€˜Sounds like fun,â€™ I said politely to my friend, but privately my immediate sense was that this was yet another ill-designed platform for introverts.</p><p>Today, as a psychologist, I know that introversion is a <a href="https://www.pewresearch.org/science/2015/12/11/personality-and-interest-in-science-health-topics/" target="_blank">common</a> trait. Unlike shyness, which is more about a fear of being judged negatively, introversion is defined as a preference for quiet, less stimulating environments. The Swiss psychoanalyst Carl Jung was the first to propose differentiating individuals along an introvert-extravert axis. Writing in the 1920s, he <a href="http://www.cyjack.com/cognition/(ebook%20pdf)%20jung,%20carl%20-%20the%20psychological%20types.pdf" target="_blank">described</a> introverts as preferring to direct their attention inward, to their own feelings and thoughts, and how they lose energy during social interactions. Extraverts, by contrast, direct their attention outward, gain energy from social interactions, and lose energy during periods of solitude.</p><p>Beginning in the 1950s, the German-born psychologist Hans Eysenck proposed a physiological explanation for the difference between introverts and extraverts. Extraverts, he <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.1964.tb00912.x" target="_blank">said</a>, have a lower baseline level of cortical arousal relative to introverts, leading them to search for external stimulation to increase their motivation, attention and alertness. Introvertsâ€™ higher baseline arousal levels, in contrast, lead them to withdraw. Contemporary psychology still considers the introversion-extraversion distinction a core aspect of personality (it is one of the <a href="https://psycnet.apa.org/record/1991-09869-001" target="_blank">so-called</a> â€˜Big Fiveâ€™ traits), although it is seen as a continuous spectrum along which we are all positioned, rather than a dichotomous state.</p><p>Although thereâ€™s no definitive way of identifying the proportion of introverts in the population, Susan Cain, an influential thinker in the field, has made a reasonable <a href="https://www.penguin.co.uk/books/296/296443/quiet-power/9780241977910.html" target="_blank">estimate</a> that at least a third of people are at one end of this spectrum. The third on the other end are extraverts, and the final third fall somewhere in between â€“ some <a href="https://www.tandfonline.com/doi/abs/10.1207/s15327752jpa4305_14" target="_blank">call</a> these people â€˜ambivertsâ€™. Knowing that introverts comprise an approximately equal share of the population as extraverts, I keep wondering about the missing 33 per cent â€“ where are all the introverts in the ocean of extraverts that surround me in my daily life?</p><p>Many of the decisions relating to the daily life of introverts are in the hands of extraverts</p><p><strong>While I have introverted</strong> friends, they seem to be vastly outnumbered by my extraverted friends and acquaintances. I have to remind myself that this apparent absence from my daily landscape is not surprising: we introverts are much harder to notice. Introverts probably wonâ€™t be the ones sharing a joke with the entire office, waiting by the coffee machine for a chance to chat, or appearing on television screens as rising reality-show stars. On the contrary, theyâ€™re more likely to enjoy some quiet time by themselves or with a few selected friends, to process their thoughts silently before saying them out loud, and to retreat to their quiet-place to recharge after social interactions.</p><p>While the higher visibility of extraverts is self-explanatory, it is far from trivial. Not only does it mean introversion is perceived as less common than it really is, but also introverts are less likely to be evenly represented in influential social groups, including in politics. We risk missing the immense contribution of a large percentage of our employees, students, trainees and friends.</p><p>For <a href="https://journals.sagepub.com/doi/10.1177/0894439312462802" target="_blank">example</a>, extraverts are more likely to take part in political engagements, such as disseminating political messages and signing petitions, both on the internet and offline. Negative political messages, which seem so common nowadays, <a href="https://jspp.psychopen.eu/article/view/280" target="_blank">deter</a> introverts from participating in politics, while having the opposite influence on extraverts, including increasing their likelihood of voting, rallying or volunteering for a political campaign. Extraverts are more <a href="https://www.sciencedirect.com/science/article/pii/S0747563209001472" target="_blank">active</a> on social media. They also have easier access to higher corporate ranks, due to the high attention they draw to themselves and to social <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/fire.12173" target="_blank">stereotypes</a> that associate extravert characteristics with leadership. This state of affairs leaves many of the decisions relating to the daily life of introverts in the hands of the extraverts.</p><p>Unfortunately, the greater representation of extraverts in social and political life is self-perpetuating. Working conditions chosen by extraverts to suit extraverts increase the burden on introverts. For instance, group meetings, in which each participant contributes thoughts in a disorganised, dominance-based manner, can put introverts at a disadvantage. The overabundance of extraverts in managing and recruitment roles also decreases the likelihood of introverts winning promotion due to whatâ€™s <a href="https://psycnet.apa.org/record/2016-02267-014" target="_blank">called</a> the â€˜similarity biasâ€™ â€“ our tendency to prefer people who are similar to ourselves. This is not only unfair to introverts, itâ€™s to the detriment of organisations.</p><p>Leadership is commonly associated with extraversion, but history teaches us that introverts can serve as powerful leaders. Rosa Parks, a leading activist in the American civil rights movement, was quiet and reserved. Her brave actions, more than her words, led to a crucial turning-point in the struggle. Similarly, while serving as US president, Barack Obama eagerly protected his solitude in the evenings, spending the time reading and concentrating on work decisions. His preference for small group outings rather than big social events didnâ€™t deprive him of extraordinary communication skills and the ability to make bold decisions. In <a href="https://www.tandfonline.com/doi/abs/10.1080/10904018.2016.1202770" target="_blank">contrast</a> to the mistaken perception of introverts as snobbish, misanthropic or depressed, we can be highly empathic, with strong communicative skills.</p><p>But itâ€™s not a case of establishing whether introverts or extraverts make better leaders, rather each brings something different, and diversity is often key to effective leadership. For <a href="https://link.springer.com/article/10.1007/s11365-014-0334-3" target="_blank">instance</a>, entrepreneurial teams perform better when leadership is shared between individuals, but only if they have diverse personality traits. Moreover, teams dominated by extraverted members <a href="https://psycnet.apa.org/record/2011-15936-006" target="_blank">actually</a> perform better under introverted leaders, possibly due to their greater responsiveness to their employeesâ€™ ideas.</p><p>Introversion is not something to be fixed â€“ but a blessed source of human diversity</p><p>The main cultural problem is that introverts are widely seen as not adapted to the environment, instead of it being acknowledged that the environment is designed to profit extraverts. Societyâ€™s praise and acceptance of extraversion as the norm has led many introverts, along with many ambiverts, to suppress different aspects of their personality, or to see them as flaws. This state of affairs is bad not only for introverts, but for society as a whole.</p><p><strong>The bias begins already</strong> in the first grade of school. Learning in a big classroom environment might be cost-efficient, but is by no means the best model for everyone. Some kids, especially the introverts, will struggle in the continuous company of a large number of others and the constant requirement to engage in group work. The same misconception â€“ placing the onus on introverts to change â€“ is also reflected in the recent <a href="https://psycnet.apa.org/record/2011-18181-001" target="_blank">proposal</a> that introverts would be happier if only they â€˜acted more extravertedâ€™, even if acting this way counteracts their natural tendencies.</p><p>Simple changes across society could be made to mitigate the inequities faced by introverts. In the educational system, for example, designated private spaces in schools could enable periodic shelter for those introverted kids and others who need a place to recharge. Introverts could also profit from greater access to online learning and sharing platforms, with asynchronous communication <a href="https://link.springer.com/chapter/10.1007/978-1-4471-0625-8_15" target="_blank">enabling</a> them to think and research an area without the pressure to respond immediately. Creating equal opportunities for participation in class, such as giving students time to think, the autonomy to decide to work alone or to write their ideas instead of presenting them verbally, could also help rebalance the traditional inequity.</p><p>In business and academic settings, workers should have more autonomy in choosing their working conditions. In meetings, stating the topics to be discussed in advance could allow more time for introverts to prepare and process the information. Allocating time for each attendee to speak could also give introverts the chance to express their thoughts. There should be more questioning of whether group meetings are necessarily the best platform for disseminating knowledge, brainstorming …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world">https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015012</guid>
            <pubDate>Fri, 31 Jul 2020 22:34:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Anatomy of Open Data Projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24014777">thread link</a>) | @oscar-batori
<br/>
July 31, 2020 | https://www.dolthub.com/blog/2020-07-30-anatomy-of-open-data-projects/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-07-30-anatomy-of-open-data-projects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>A core motivation for building DoltHub was to empower organizations to collaboratively create and maintain high quality data assets that they could collectively depend on. This is very much analogous to GitHub. Analogies are powerful ways to articulate an idea when an appropriate one is already widely understood. In our case a large community of developers, and technology adjacent businesses more broadly, understand GitHub, and how it enabled a revolution in open source software. It's therefore straightforward for us to explain our product in terms of an analogy.</p>
<p>The balance of this article is about the, relatively nascent, open data ecosystem, and the similarities and differences with the the open source software ecosystem.</p>
<h2>Open Source Software</h2>
<p>Collaborative public development of software is not necessary for it to be considered "open source", this is a characteristic of the distribution licensing, but when one uses the term "open source" that is normally what is implicitly understood. Indeed at various points in my career assessing whether to adopt a tool often involved gauging how "vibrant" the "community" around that tool was. What does this mean in specifically?</p>
<ul>
<li>gauging the level of mailing list activity, JIRA board back and forth, or GitHub issues to see a healthy interest in the tool, that is a user base</li>
<li>checking Git commit logs to see if there is a healthy base of contributors</li>
</ul>
<p>The fundamental thing this kind of analysis seeks to establish is a qualitative sense of whether a <em>healthy</em> dynamic exists around the project. At a fundamental level marginal users must see value in the project, and some fraction of them must be willing to convert to contributors in order to sustain the project. If significant investment is attracted, then the user base can grow as the project in creases in scope and quality, thus becoming a solution to more and more problems. This is the "flywheel" that sustains open source projects that allow companies to drop in pieces of software infrastructure that they might otherwise have to buy or maintain. The existence of the open source alternative allows these companies to compare the cost of buying or building to having a stake in a free to use tool, usually outside their core competency.</p>
<p>This is not a scientific, or exhaustive, theory of open source software project dynamics, but it seems a reasonable first approximation of the dynamic that drives companies to seek to employ open source contributors to projects that constitute a critical part of their infrastructure.</p>
<h2>Open Data</h2>
<p>To start to gauge the relevance of this analogy at the level of "project dynamics", I performed a quick Google search:
<a href="https://www.dolthub.com/blog/images/open-data-project-google-search.png">Open Data Projects Google Search</a></p>
<p>The first, non-paid, article is a blog by a SaaS business focused on "spatial data science", and so while data sources may be interesting, they are picked because they compliment Carto's business thesis of the value of geo spatial data. Furthermore, most of the identified "projects" are the work of an individual or organization publishing, rather than the kind of distributed collaboration we identified as the core of the open source software development model.</p>
<p>The next two links are initiatives by the government to make data publicly available. While government data can be great, the existence of single publisher is the essence of its value. We then have Kaggle, a well known platform for machine learning competitions. Since a necessary prerequisite for a machine learning competition is a dataset, Kaggle hosts a lot of free datasets. However, they tend to be tailored toward the competition, and most are not updated, nor is there any concept of collaboration on a single dataset. We then reach some summary articles, probably what we were really looking for, that identify interesting and compelling "open data." However, again these data sources are mostly organizations and governments, or quasi government, entities <em>publishing</em>.</p>
<p>It seems pretty clear that the term "open data" often just means "available data", a one directional relationship where individuals and organizations can consume a data source passively. But how are organizations that have a shared interest in a dataset that is necessary but not a core competitive advantage supposed to collaborate?</p>
<p>Let's dig into an example.</p>
<h2>Open Elections</h2>
<p>One interesting open data project that looks bit like open source software is Open Elections. We have <a href="https://www.dolthub.com/blog/2020-07-01-open-elections/">blogged about</a> the project in the past. Recapping, the goal of the project is simple:</p>
<blockquote>
<p>Our goal is to create the first free, comprehensive, standardized, linked set of election data for the United States, including federal and statewide offices.</p>
</blockquote>
<p>Interest in voting data is broad, and is driven by both professional and personal motivations. Furthermore, many organizations have an interest in voting data, but lack the financial resources to buy it. Many commercial grade solutions, such as the associated press, are tailored to large media organizations with big budgets and low latency tolerance. This is not a good trade off for researchers or campaigns. Open Elections seeks to democratize access to this data by making high quality precinct level results available.</p>
<p>Perhaps because of wide interest in the data there is a sizable base of contributors. It's not hard to imagine that a researcher or enthusiast sees the Open Elections <a href="http://openelections.net/">homepage</a>, and realizes that with a small outlay of effort they can extend the dataset to meet their needs. They <em>convert from a user to a contributor</em>. This looks much more like open source software than random quasi-governmental agencies pushing out collections of CSVs whenever they see fit. To be clear, this is not to be scoffed at, but it's an entirely different model of data distribution.</p>
<p>Open Elections is managed via GitHub, which makes sense as that's the most notable platform around for administering a project with this dynamic. It's also free to use, widely understood, and the product is mature and well executed. However, one shortcoming of using data in a format such as CSV is that the format itself is "loose", it is after all a file format. Databases are a file format in a sense, but differ hugely in they require a program to edit the format. In essence that program, the query engine, "gates" interactions with the format, which in turn enables much stronger "guarantees" to be presented. These guarantees are described by a schema, and enable the use of a query language. Dolt uses SQL. Datasets store in a database are much more work to build than collections of data files separated by commas, but when data arrives in a database the time to value is radically compressed. We published a subset of the Open Elections data as a <a href="https://www.dolthub.com/repositories/open-elections/voting-data">Dolt repository</a>, which does a nice job of illustrating the power of the distribution model.</p>
<p>This is the core value proposition of Dolt to the open data community, it offers mechanism for building high quality production grade resources, and delivering a uniquely seamless consumption experience to users of the data.</p>
<h2>Moving Forward</h2>
<p>Putting data in relational databases is hard. The analogy to open source software would be unit tests. While the existence of such a "forcing function" to quality makes the life of the contributor harder by raising the barrier to creating a successful contribution, it also greatly elevates the experience of the marginal user.</p>
<p>That forcing function, using a database with Git-like features for managing open data project, is essential to our vision for Dolt and DoltHub in the open data world. We see Dolt the database, and the collaboration features built on top of it for DoltHub, as having the potential to elevate the quality of the data assets that come out of open data projects such that businesses are more willing to rely on them, and therefore invest in the projects themselves.</p>
<h2>Conclusion</h2>
<p>To recap, we have used the analogy of open source code, and Git and GitHub, to articulate the goals of Dolt and DoltHub in many places, including this blog. While the analogy is a powerful communication tool, it does tend to gloss over the key differences between the dynamics at play in collaborative process design, open source software, and collaborative fact assembly, open data.</p>
<p>One reason that we believe open data projects have not taken off is lack of tools that make it easy for contributors to publish high quality data assets that clear the threshold of quality such that commercial enterprises see them as viable alternatives to proprietary and paid solutions. Dolt and DoltHub represent our attempt to facilitate collaboration that creates high quality data assets that can become reliable dependencies.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-07-30-anatomy-of-open-data-projects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24014777</guid>
            <pubDate>Fri, 31 Jul 2020 22:06:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Introduction to Securing Applications with JWT]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24014566">thread link</a>) | @bajcmartinez
<br/>
July 31, 2020 | https://livecodestream.dev/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/ | <a href="https://web.archive.org/web/*/https://livecodestream.dev/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <figure>
                
                <img alt="Feature Image" width="1200" height="675" src="https://livecodestream.dev/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/featured_huc77c418b483b98e9dff0266318d11aa5_126761_680x0_resize_q75_box.jpg">
            </figure>
            <p>JSON Web Tokens has become the favorite choice among modern developers when implementing user authentication. JWT’s popularity is clearly justified by what it brings to application development. In this post, we are looking deep into JWTs and why they stand out among other authentication options, as well as what you should be concerned about when using them.</p>
<h2 id="what-is-a-jwt-token">What is a JWT token?</h2>
<p>A JWT is a self-contained method that can be used securely transmit data between two endpoints. JWTs are most commonly used for user authentication. They can also be used to securely exchange information. In this post, we are covering how JWTs are used for user authentication. However, information exchange using JWT follows roughly the same steps as user authentication.</p>
<p>The authentication process involving JWTs follows these steps. When a user first logs into the application, system backend issues a JWT to the user and sends it to the client-side. This token contains a special signature that validates the token as a one issued by the system. The client stores the token in the browser and sends it with every request to the server, where the token is used to verify the user’s authentication.</p>
<p>A JWT consists of 3 strings separated by periods. The 3 of them are the header, payload, and the signature. Follows is an example JWT token made of these 3 parts.</p>
<div><pre><code data-lang="text">eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJteXdlYnNpdGUuY29tIiwiaWF0IjpudWxsLCJleHAiOjUxNDM3ODA4MDAwLCJhdWQiOiIiLCJzdWIiOiIiLCJpZCI6IjEyMzQ1OTEiLCJuYW1lIjoiTWFyeSBQb3BwaW5zIiwicm9sZSI6ImVkaXRvciJ9.LYKHdyKj6SnxYaRZH_ZhiW6yk31zaBQehYm4BgawH_o
</code></pre></div>






    
        
        
    


<figure data-src="/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/jwt_sections_hue96f0b140e8b7146d188088ad71eec65_2934_700x0_resize_box_2.png">
<img src="https://livecodestream.dev/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/jwt_sections_hue96f0b140e8b7146d188088ad71eec65_2934_b7bd711f4eaf2942320bb437adb2d39a.png" width="700" height="30"> 
</figure>

<p>Let’s see what each of these parts contributes to the overall makeup of the token.</p>

<p>JWT header contains metadata about the token in JSON format. Two fields present in the header are alg and typ. ’alg’ specifies the algorithm used to sign the token when generating the signature, which we will talk about in a moment. ’typ’ specifies the type of the token, which is ’JWT’. A typical token header is shown in the following example.</p>
<div><pre><code data-lang="json">{
    <span>"alg"</span>: <span>"RS256"</span>,
    <span>"typ"</span>: <span>"JWT"</span>
}
</code></pre></div><p>Here, the header states the algorithm used to sign the token is RS256.</p>
<p>The header is stored as the first part of the token after being encoded in base64url.</p>
<h3 id="payload">Payload</h3>
<p>The payload of a JWT stores information about the token and any other entity in JSON format. Usually, a JWT used for authentication stores some crucial information about the user, such as the user ID and user role. Token storing user information usually looks like this.</p>
<div><pre><code data-lang="json">{
    <span>"id"</span>: <span>"1234591"</span>,
    <span>"name"</span>: <span>"Mary Poppins"</span>,
    <span>"role"</span>: <span>"editor"</span>
}
</code></pre></div><p>These JSON fields stored in the payload are known as claims.</p>
<p>In addition, there are some claims that are defined by the JWT standard. It’s not necessary to include all these claims in a JWT, but including at least some of them will be beneficial in most situations. Here are a few standard claims that we can use.</p>
<ul>
<li>iss: Defines the issuer of the token.</li>
<li>exp: Provides an expiration time to the token. Once this expiration time is passed, the token is no longer valid.</li>
<li>aud: Defines the audience of the token.</li>
<li>iat: Stores the time the token was issued at.</li>
</ul>
<p>Let’s see how a payload with some standard claims looks like.</p>
<div><pre><code data-lang="json">{
    <span>"id"</span>: <span>"1234591"</span>,
    <span>"name"</span>: <span>"Mary Poppins"</span>,
    <span>"role"</span>: <span>"editor"</span>,
    <span>"iss"</span>: <span>"mywebsite.com"</span>,
    <span>"exp"</span>: <span>3600</span>
}
</code></pre></div><p>The payload of a JWT can include as many fields of information as you want, but it’s recommended to keep the size as small as possible. Also, you should not store sensitive information like user passwords in the payload since it is not encrypted. It’s simply encoded in base64url encoding.</p>
<h3 id="signature">Signature</h3>
<p>The last part of a JWT token, the signature, is a Message Authentication Code that is used to verify the token was not modified or generated by an outsider except the authorized application servers.</p>
<p>Signature is generated by signing the combined JWT header and payload using an encryption algorithm and a secret stored in the server. Only someone who has the token’s header and payload and the secret can generate a sign accepted by the server. So, it is important to use a strong secret to encrypt tokens and securely store it in the server.</p>
<p>If we use a symmetric algorithm like HMAC SHA-256, the server issuing the JWT and the server validating the JWT should have secure access to the secret. If an asymmetric algorithm like RS256 is used, we can use a public-private key system, where a private key is used to sign the token and a public key is used to validate it.</p>
<p>As you have already guessed, the signature is the most crucial part of a JWT token. It keeps unauthenticated sources out of the application and keeps everything secure. When the issued JWT is sent back to the server with every request from the client-side, the server checks the signature to validate that it’s a token issued by the system itself and then proceed to serve the client request.</p>







    
        
        
    


<figure data-src="/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/request_huf196d12aafba2d37f77afb10df1a32fc_9484_700x0_resize_box_2.png">
<img src="https://livecodestream.dev/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/request_huf196d12aafba2d37f77afb10df1a32fc_9484_a5f5d6661905cbe5df15bf10769c4879.png" width="700" height="435"> 
</figure>

<hr>
<h2 id="what-is-so-special-about-jwt">What is so special about JWT?</h2>
<p>As we got to know the makeup of a JWT token, you might have been thinking about what makes it so special compared to other authentication methods, especially session-based authentication.</p>
<p>The most important characteristic of JWT that makes it special is its statelessness. We saw what sort of data can be stored in a JWT in the previous section, and all the data that are needed to verify the token and identify the user are stored in the token itself. There is no need to maintain any record of the token in the server, like store the token in a database as we do with sessions. This makes JWTs stateless.</p>
<p>This stateless nature gives us the biggest benefit that comes with JWTs: The server that issues the JWT and the server that validates it does not have to be the same. One server can issue JWTs and carry out authentication tasks, while the other server that implements application logic can validate the JWT independent of the first server.</p>
<p>In the age of API backends and microservices-architecture applications, this allows the developers to delegate all authentication tasks to one server while the others implement application logic, and decouple the system as much as possible.</p>
<p>When JWT issuing and validating is carried out by separate servers, using a public-private key system is the best approach to take. In this case, the private key should be stored securely in the authentication server.</p>
<hr>
<h2 id="how-to-send-jwt-tokens-from-client-side-to-the-server-and-vice-versa">How to send JWT tokens from client-side to the server and vice-versa?</h2>
<p>When sending the JWT back and forth between the server and the client, we can send it along with the Authorization HTTP header. However, sending tokens over HTTP connections makes them susceptible to Man-In-The-Middle (MITM) attacks and stolen tokens. Therefore, it is essential to use secure HTTP connections when using JWTs.</p>
<p>Another problem with sending the token in the HTTP header is, in this approach, the token is usually stored in the local storage of the client-side browser. This exposes the tokens to being stolen using Cross-Site Scripting (XSS) attacks.</p>
<p>As a solution to this, you can send the token inside a cookie instead of inside the Authorization header. It’s essential to set HttpOnly and secure flags of the cookie to prevent attackers from stealing tokens using XSS attacks.</p>
<hr>
<h2 id="expire-your-jwt-tokens">Expire your JWT tokens</h2>
<p>If in some way a JWT token is stolen by a third-party, they can use the stolen token to access the application and gain the token owner’s privileges. As a solution to this problem, we can set a short expiration time for the JWTs. This way, even if an attacker steals a token, they cannot make use of it for a time long enough to make an undesirable impact.</p>
<p>We can set the exp claim inside the payload to give a short expiration time to the token. However, this action does not eliminate the threat of stolen tokens, just reduces the chances of it leading to a serious attack.</p>
<p>In real-world applications, setting a short expiration time to JWTs is not as simple as it sounds. If we created tokens that expire after ten minutes of creation, it will drastically reduce the user experience of your application’s users. How likely are the users to tolerate having to re-login every 10 minutes they spend on your application?</p>
<p>But there is a solution to this: refresh tokens.</p>
<hr>
<h2 id="refresh-tokenswhat-are-they">Refresh tokens—what are they?</h2>
<p>Since asking the users to log in again after every time a JWT token expires within a short time is not a good solution, developers have found a solution to this in refresh tokens.</p>
<p>The refresh token is a JWT token with a longer expiration time. It is used to issue a new access token, which is also a JWT token but with a shorter expiration time, every time the old access token expires.</p>
<p>In this situation, the access token is the token that is sent back and forth between the client and the server and has a short expiration time. However, when the access token expires within a short time, instead of asking the user to log in again, the server uses the refresh token to generate a new access token. Refresh token stores data needed to create a new access token.</p>







    
        
        
    


<figure data-src="/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/jwt_refresh_hueb0266c7bdf0d6b3156eda2d402fdf7f_57584_700x0_resize_box_2.png">
<img src="https://livecodestream.dev/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/jwt_refresh_hueb0266c7bdf0d6b3156eda2d402fdf7f_57584_b94cc3f6284cd5ef66274bdd417434e9.png" width="700" height="438"> 
</figure>

<p>Since refresh token has a long expiration time and it is not being passed to the client-side in any case, we should store them in a backend database. If an attacker somehow gets access to a refresh token, it’s a serious security threat to the system and the owner of the refresh token given their long expiration time. So, refresh tokens must be stored under maximum security measures.</p>
<p>A user first receives a refresh token when they login to the system. Then, the token is stored in a secure database. Issuing a new refresh token every time a new access token is generated is something you can do to ensure that the security impact of stolen refresh tokens is low.</p>
<p>When a refresh token expires, the user has to log in to the application again and get a new refresh token.</p>
<p>If JWT issuing and validating are handled by separate servers, …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://livecodestream.dev/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/">https://livecodestream.dev/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/</a></em></p>]]>
            </description>
            <link>https://livecodestream.dev/post/2020-07-31-a-brief-introduction-to-securing-applications-with-jwt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24014566</guid>
            <pubDate>Fri, 31 Jul 2020 21:46:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pebkac: I Spent 2 Days Fixing a Bug That Didn't Exist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24014565">thread link</a>) | @figbert
<br/>
July 31, 2020 | https://figbert.com/posts/pebkac-txtodo/ | <a href="https://web.archive.org/web/*/https://figbert.com/posts/pebkac-txtodo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><a href="https://figbert.com/posts/pebkac-txtodo" rel="me">FIGBERT</a> <section> <p>Published by  on <time datetime="2020-07-28">7/28/2020</time></p> </section> <p>Post-<a href="https://developer.apple.com/wwdc20/" rel="noopener noreferrer" target="_blank">WWDC2020</a>, I decided to rewrite the backend of txtodo in SwiftUI using the new <a href="https://developer.apple.com/videos/play/wwdc2020/10037/" rel="noopener noreferrer" target="_blank">App and Scene structure</a>. Rebuilding the app from scratch may have not been the best choice, but during that process I have massively simplified the app's data structure, despaghettified some messy UI code, and spent two full days trying to solve a problem that didn't exist. This is the story of that last bit.</p>  <section><p>Post-<a href="https://developer.apple.com/wwdc20/" rel="noopener noreferrer" target="_blank">WWDC2020</a>, I decided to rewrite the backend of txtodo in SwiftUI using the new <a href="https://developer.apple.com/videos/play/wwdc2020/10037/" rel="noopener noreferrer" target="_blank">App and Scene structure</a>. Rebuilding the app from scratch may have not been the best choice, but during that process I have massively simplified the app's data structure, despaghettified some messy UI code, and spent two full days trying to solve a problem that didn't exist. This is the story of that last bit.</p> <h2 id="-structural-changes">## Structural Changes</h2> <p>The new app, so far, was mostly the same as the old version but without the <code>AppDelegate.swift</code> or <code>SceneDelegate.swift</code> files (using the new XCode 12 multiplatform app template). I also combined the Core Data <code>FloatingTask</code> and <code>DailyTask</code> entities into one <code>Task</code> entity. By this point, everything was running well enough so I started to migrate more code into the new codebase starting with the fetch request:</p> <pre><code>@FetchRequest(
    entity: Task.entity(),
    sortDescriptors: [
        NSSortDescriptor(keyPath: \Task.completed, ascending: true),
        NSSortDescriptor(keyPath: \Task.priority, ascending: false),
        NSSortDescriptor(keyPath: \Task.name, ascending: true)
    ]
) var tasks: FetchedResults&lt;Task&gt;</code></pre> <h2 id="-breaking-taskview">## Breaking TaskView</h2> <p>Tasks are displayed as <code>TaskView</code>s in a <code>ForEach</code> loop on the homescreen, which is simple enough. The <code>TaskView</code> struct, however, is relatively complicated. The purpose of <code>TaskView</code> is to represent and manipulate a single <code>Task</code>. In the previous version of the app (I'm going to call the original version 2.0 and the rewrite 3.0 from now on), this involved passing a number of attributes individually to be manipulated as the view's <code>@State</code>. When migrating the view, I reduced this to a single <code>@ObservedObject</code>. I also removed some of the text styling, which I planned to port over after I got the UI functional.</p> <p>I ran the app on my device, and this happened:</p> <p><video controls="" src="https://figbert.com/content/posts/pebkac-txtodo-rewrite/ascending-checkmarks-error.webm"><a href="https://figbert.com/content/posts/pebkac-txtodo-rewrite/ascending-checkmarks-error.webm">As you check off any task in the vertical stack, instead of checking off the task that you selected, tasks are checked off starting from the bottom and moving upwards in an ascending order.</a></video></p> <p>Well that was unexpected. Instead of checking off the tasks I selected, tasks were checked off starting from the bottom and ascending – obviously not the intended behavior! My first thought was that it was caused by the use of <code>@ObservedObject</code> to declare the view's task property –&nbsp;I haven't seen it used to manipulate a Core Data entity before, but it's worked fine so far in txtodo – so I rewrote the variables to match version 2.0.</p> <p><img alt="The variables declared before the UI of version 3.0 and version 2.0. Version 3.0 has two variables, task and config, but version 2.0 has nine: task, completed, name, priority, deleted, editingText, editingPriority, viewingNotes, and confirmingDelete." src="https://figbert.com/content/posts/pebkac-txtodo-rewrite/variable-comparison.webp"></p> <p>Still no change. It was getting pretty late at this point, but I decided to stick it out for just a bit longer. I rewrote the <code>TaskView</code> struct from scratch <em>two more times</em> to no avail. Something was wrong, but I had no idea where it was and there was no way I was going to figure it out at two in the morning by coding it again the exact same way.</p> <h2 id="-fantastic-bugs-and-where-to-find-them">## Fantastic Bugs and Where to Find Them</h2> <p>The next morning, I took a look at the code again. If the problem wasn't in <code>TaskView</code>, where was it? The only other thing in the UI was the button to make a new task, which looked something like this:</p> <pre><code>Button(action: {
    let newTask = Task(context: self.managedObjectContext)
    newTask.name = "test"
    newTask.priority = 3
    newTask.notes = [String]() as NSObject
    newTask.id = UUID()
    newTask.date = Date.init()
    newTask.daily = true
    do {
        try self.managedObjectContext.save()
    } catch {
        print(error.localizedDescription)
    }
}) {
    Text("Add")
}</code></pre> <p>Some of you may have figured it out by this point. At the time, I was still confused – this was the exact method I was using in my previous app, but with preset values – how could it be broken? I modified the generation slightly so I could tell the difference between tasks, and hopefully get to the bottom of the issue:</p> <pre><code>let newTask = Task(context: self.managedObjectContext)
newTask.name = String(UUID().uuidString.prefix(Int.random(in: 5..&lt;9)))
newTask.priority = Int16.random(in: 1..&lt;4)
newTask.notes = [String]() as NSObject
newTask.id = UUID()
newTask.date = Date.init()
newTask.daily = Bool.random()</code></pre> <p>I ran the app again and saw this:</p> <p><video controls="" src="https://figbert.com/content/posts/pebkac-txtodo-rewrite/randomized-test-values.webm"><a href="https://figbert.com/content/posts/pebkac-txtodo-rewrite/randomized-test-values.webm">The tasks were not being marked off in ascending order – rather, they were being moved to the bottom when completed, which I couldn't tell before because they were all identical.</a></video></p> <h2 id="-intentional-behavior">## Intentional Behavior</h2> <p>The tasks weren't being marked off in ascending order. They were being moved to the bottom automatically when marked as complete, which I couldn't see because a) all the tasks were identical and b) there were no animations to indicate that was happening. They were sorted by the <code>FetchRequest</code> with a <code>NSSortDescriptor</code>, to make sure that the unfinished tasks are the first thing the user sees. The "glitch" I had spent two days chasing down was entirely by design, and I had just forgotten.</p> <p>There were two main things I learned from this experience. First, it's incredibly important to be able to take breaks. The difference between spending two days trying to fix a non-existent glitch and realizing it's a feature you implemented could be as simple as a nap – it was for me. Secondly, your test and placeholder data is more significant than you might think: <a href="https://en.wikipedia.org/wiki/Garbage_in%2C_garbage_out" rel="noopener noreferrer" target="_blank">garbage in, garbage out</a> definitely applies here. If all your test data is the same, your tests are not good tests.</p> <h2 id="-wrap-up">## Wrap-up</h2> <p>To make the sorting more clear, I randomized the tasks' priority, name, and category (as seen above) and added an animation with <code>.animation(.easeIn(duration: 0.25))</code>. The current prototype looks something like this:</p> <p><video controls="" src="https://figbert.com/content/posts/pebkac-txtodo-rewrite/update-preview.webm"><a href="https://figbert.com/content/posts/pebkac-txtodo-rewrite/update-preview.webm">Animated, randomized tasks being checked off, deleted, and delayed.</a></video></p> <p>This has been a really fun blog post to write! A got a big laugh out of this bug chase, and I hope you've enjoyed reading it.</p> <p>Till next time, FIGBERT</p> </section></article></div>]]>
            </description>
            <link>https://figbert.com/posts/pebkac-txtodo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24014565</guid>
            <pubDate>Fri, 31 Jul 2020 21:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DragonRuby, a game development toolkit using Ruby]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24013990">thread link</a>) | @zephyrfalcon
<br/>
July 31, 2020 | https://dragonruby.itch.io/dragonruby-gtk | <a href="https://web.archive.org/web/*/https://dragonruby.itch.io/dragonruby-gtk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><table><tbody><tr><td>Updated</td><td><span></span>&nbsp;Jun 08, 2020, Total updates so far: 44</td></tr><tr><td>Published</td><td><span></span>&nbsp;Apr 19, 2019</td></tr><tr><td>Status</td><td><a href="https://itch.io/tools/released">Released</a></td></tr><tr><td>Category</td><td><a href="https://itch.io/tools">Tool</a></td></tr><tr><td>Platforms</td><td><a href="https://itch.io/tools/platform-windows">Windows</a>,&nbsp;<a href="https://itch.io/tools/platform-osx">macOS</a>,&nbsp;<a href="https://itch.io/tools/platform-linux">Linux</a></td></tr><tr><td>Rating</td><td><span></span><span></span><span></span><span></span><span></span>
<span>(19)</span>
</td></tr><tr><td>Author</td><td><a href="https://dragonruby.itch.io/">DragonRuby</a></td></tr><tr><td>Tags</td><td><a href="https://itch.io/tools/tag-2d">2D</a>,&nbsp;<a href="https://itch.io/tools/tag-dragonruby">dragonruby</a>,&nbsp;<a href="https://itch.io/tools/tag-game-engine">Game engine</a>,&nbsp;<a href="https://itch.io/tools/tag-moddable">Moddable</a>,&nbsp;<a href="https://itch.io/tools/tag-ruby">ruby</a></td></tr></tbody></table><p><br>DragonRuby Game Toolkit&nbsp;is a professional grade (yet beginner friendly) 2D&nbsp;game engine. It's tiny (~3MB), fast as hell, and cross-platform (including consoles).</p>
<p><strong>Free Unrestricted License</strong></p>
<p><strong>You are eligible for a free license if any of the following items pertain to you:</strong></p>
<ul><li><strong>Your income is below $2000 (USD) per month.</strong></li><li><strong>You are under 18 years of age.</strong></li><li><strong>Y</strong><strong></strong><strong>ou are a student of any type: traditional public&nbsp;school, home schooling, college, bootcamp, or online.</strong></li><li><strong>You are a teacher, mentor, or parent who wants to teach a kid how to code.</strong></li><li><strong>You work/worked in public service or at a charitable organization: for example&nbsp;</strong><strong>public office, army, or any 501(c)(3) organization.</strong></li></ul>
<p><strong>Just contact Amir at&nbsp;ar@amirrajan.net with a short explanation of your current situation and he'll set you up. No questions asked.&nbsp;&nbsp;</strong></p>

<ul><li>Dirt simple apis&nbsp;capable of&nbsp;creating&nbsp;complex 2D games.</li><li>Fast as hell. Powered by highly optimized C code written by Ryan C. Gordon, the creator of SDL (a library that powers <em>every</em> commercial game engine in the world).</li><li>Battle tested by Amir Rajan, a critically acclaimed indie game dev.</li><li>Tiny. Like really tiny. The entire engine is a few <em>megabytes</em>.</li><li>Hot loaded, realtime coding, optimized to provide constant feedback to the dev. Productive and an absolute joy to use.</li><li>Turn key builds for Windows, MacOS, and Linux with seamless&nbsp;publishing to Itch.io.</li><li>Cross platform: PC, Mac, Linux, iOS, Android, Nintendo Switch, XBOX One, and PS4 (mobile and console compilation requires a business entity, NDA verification, and a Professional GTK License, contact us).</li></ul>
<p>Ryan put together a 5-minute intro to DragonRuby GTK, to give you a whirlwind tour of the big ideas:</p>
<p><iframe src="//www.youtube.com/embed/DYBRzglsEzU" allowfullscreen="" frameborder="0"></iframe></p>

<p>This is a tech demo sample app that ships with DragonRuby. The GTK's entire API is displayed here.</p>
<p><img src="https://img.itch.zone/aW1nLzIwMjc0NjAuZ2lm/original/nSIv4l.gif"><br></p>

<p>
This is Ryan C. Gordon (<a href="https://en.wikipedia.org/wiki/Ryan_C._Gordon" rel="nofollow noopener">Wikipedia</a>), he is one of the juggernauts behind Simple DirectMedia Layer (<a href="https://en.wikipedia.org/wiki/Simple_DirectMedia_Layer" rel="nofollow noopener">Wikipedia</a>).&nbsp;</p>
<p>Ya know...&nbsp;</p>
<p>SDL.</p>
<p>that low level library that <strong>powers literally every commercial game engine out there</strong>?&nbsp;</p>
<p>He's also worked on porting a number of games to Linux and Mac OS: such as Braid, Super Meat Boy, Dear Esther, and LIMBO.</p>
<p><img src="https://img.itch.zone/aW1nLzIwMTM3NDkucG5n/original/Z%2F%2Fpmx.png"><br></p>
<p>
And this is Amir Rajan, he is an indie game dev with titles on iOS, Android, desktop,&nbsp;and Nintendo Switch...&nbsp;<strong>amassing 4 million downloads and counting</strong> (<a href="https://www.nintendo.com/games/detail/a-dark-room-switch/" rel="nofollow noopener">Nintendo</a>, <a href="https://killscreen.com/articles/ensign/" rel="nofollow noopener">Kill Screen</a>, <a href="https://www.newyorker.com/tech/annals-of-technology/a-dark-room-the-best-selling-game-that-no-one-can-explain" rel="nofollow noopener">The New Yorker</a>). And yes, all these games are built with the DragonRuby Runtime.</p>
<p><img src="https://img.itch.zone/aW1nLzIwMTM3NTAuanBn/original/jrb8Tz.jpg"><br></p>
<p><strong>Both of these guys hate the complexity of today's engines. </strong>And as luck would have it, their paths ended up crossing. After six months and 50,000 lines of DragonRuby Runtime enhancements,&nbsp;Ryan and Amir now have a live/hot loadable, cruft-free, productive game engine&nbsp;that can target... well... any gaming device you can think of.&nbsp;<br></p>

<p>
This is all you need to create a game. One file. One method called <code>tick</code>. Here we render the&nbsp;current step value as a label: </p>
<pre>def tick args
  args.outputs.labels &lt;&lt; [100, 100, args.state.tick_count]
end
</pre>
<p>
That's it. If you know how to use the <code>array</code> datatype in <em>any</em> language, you know how to use the DragonRuby Game Toolkit. <a href="http://fiddle.dragonruby.org/" target="_blank" rel="nofollow noopener"><strong>Here's the proof right here, play around with the engine&nbsp;in your browser.</strong></a></p>

<p>Here are the six draw primitives you need to know: <code>solids, sprites, labels, lines, borders, and sounds</code>. Here is how you use them:</p>
<pre>def tick args  
  # draw a blue square that's half way faded out
  args.outputs.solids &lt;&lt; [100, 100, 50, 50, 0, 0, 255, 128]
  
  # draw a red label  
  args.outputs.labels &lt;&lt; [100, 100, "This is a label.", 255, 0, 0]
  
  # draw a sprite turned 45 degrees and half way faded out
  args.outputs.sprites &lt;&lt; [200, 200, 50, 50, 'ninja.png', 45, 128]
  
  # draw a diagonal green line from bottom left to top right
  args.outputs.lines &lt;&lt; [0, 0, 1280, 720, 0, 255, 0]
  
  # draw a black border (unfilled square)
  args.outputs.borders &lt;&lt; [100, 100, 50, 50, 0, 0, 0, 255]
  
  # play a sound every second
  args.outputs.sounds &lt;&lt; "ping.wav" if args.state.tick_count % 60 == 0
end</pre>
<p>That's it. You now know the entire render api for DragonRuby GTK.</p>
<p>
Here's a more complicated example.&nbsp;This is how you create a night time scene, with a title, and a ninja:</p>
<ol><li><code>solids</code>: A black background, and two hundred stars made of tiny squares.</li><li><code>labels</code>: Display some smokey-white text.</li><li><code>sounds</code>: Play a sound when the game starts up.</li><li><code>sprites</code>: Render a sprite on the screen.</li><li><code>lines</code>: Draw a line representing the floor</li><li><code>borders</code>: Frame the entire scene&nbsp;with a white border.</li></ol>
<pre>def tick args
  # destructure args into local variables
  state, outputs, grid = args.state, args.outputs, args.grid
  # set some default values for the game
  state.colors.background ||= [0, 0, 0]
  state.colors.star       ||= [128, 200, 255]
  state.colors.text       ||= [200, 200, 200]
  state.colors.landmarks  ||= [255, 255, 255]
  state.night             ||= [grid.rect, state.colors.background]
  state.stars             ||= 200.map do
    [rand * grid.w,
     rand * grid.h,
     rand * 2 + 2,
     rand * 2 + 2,
     state.colors.star]
  end
  # start up some background music
  outputs.sounds  &lt;&lt; "opening_fx.wav" if state.tick_count == 0
  # render the background and stars
  outputs.solids  &lt;&lt; state.night
  outputs.solids  &lt;&lt; state.stars
  # set a title for the game
  outputs.labels  &lt;&lt; [grid.left + 50, grid.top  - 50, 
                      "Ninja Game", state.colors.text]
  # set a sprite
  outputs.sprites &lt;&lt; [50, 50, 50, 50, 'ninja.png']
  # create a line that represents the ground
  outputs.lines   &lt;&lt; [grid.left, 
                      grid.bottom + 50, 
                      grid.right, 
                      grid.bottom + 50, 
                      state.colors.landmarks]
  # create a border to frame the game
  outputs.borders &lt;&lt; [grid.left + 1,
                      grid.bottom + 1, 
                      grid.right - 1, 
                      grid.top - 1, 
                      state.colors.landmarks]
end</pre>

<p>This is how you move a sprite using your gamepad:<br></p>
<pre>args.state.ninja.x ||= 100
args.outputs.sprites &lt;&lt; [args.state.ninja.x, 300,
                         50, 50,
                         'ninja.png']
if args.inputs.controller_one.key_held.right
  args.state.ninja.x += 10
elsif args.inputs.controller_one.key_held.left
  args.state.ninja.x -= 10
end
</pre>
<p>This is how you move a sprite using your mouse:<br></p>
<pre>args.state.ninja.x ||= 100
args.outputs.sprites &lt;&lt; [
   args.state.ninja.x, 
   300, 
   50, 
   50, 
   'ninja.png'
]
if args.inputs.mouse.click  
  args.state.ninja.x = args.inputs.mouse.click.point.x
end</pre>
<p>This is how you move a sprite using your keyboard:</p>
<pre>args.state.ninja.x ||= 100
args.outputs.sprites &lt;&lt; [args.state.ninja.x, 300, 50, 50, 
                         'ninja.png']
if args.inputs.keyboard.key_held.right
  args.state.ninja.x += 10
elsif args.inputs.keyboard.key_held.left
  args.state.ninja.x -= 10
end</pre>

<p>
Randomly create 500&nbsp;ninjas on the screen. Create a lookup table that contains the alpha property of ninjas that have collided. Present all ninjas with their alpha properties set.</p>
<pre>def tick args
  # destructure args into local variables
  grid, state, outputs = args.grid, args.state, args.outputs
  
  # use Game Toolkit's built in helper methods to create
  # adhoc entities
  state.ninjas ||= 500.map do
    state.new_entity(:ninja,
                    { rect: [grid.w.-(50) * rand,
                             grid.h.-(50) * rand,
                             50,
                             50] })
  end
  # use Ruby's powerful apis to determine collision
  state.collisions ||= state.ninja
                            .product
                            .reject { |n, n2| n == n2 }
                            .find_all { |n, n2| n.rect.intersects_rect?(n2.rect) }
                            .map { |n, _| [n.entity_id, 128] }
                            .pairs_to_hash
  #render everything to the screen
  outputs.sprites &lt;&lt; state.ninjas.map do |n|
    [n.rect, 'dragonruby.png', 0,
     state.collisions[n.entity_id] || 255]
  end
end</pre>

<p>Need a bit more guidance in learning how to program?&nbsp;We're starting to build training videos for DragonRuby GTK. Check those out at <a href="http://dragonruby.school/" target="_blank" rel="nofollow noopener">dragonruby.school</a>.<br></p>
</div></div>]]>
            </description>
            <link>https://dragonruby.itch.io/dragonruby-gtk</link>
            <guid isPermaLink="false">hacker-news-small-sites-24013990</guid>
            <pubDate>Fri, 31 Jul 2020 20:57:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to play audio from Docker containers over the web]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24013764">thread link</a>) | @amasad
<br/>
July 31, 2020 | https://blog.repl.it/audio | <a href="https://web.archive.org/web/*/https://blog.repl.it/audio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Audio brings games and projects to life! Web developers have it easy, they can publish their apps on the web and play audio using the browser API no problem. However, what about those of us that are command-line and graphics apps in other languages? Repl.it is a special place on the web where you can publish any app in any language, but so far it’s been missing audio capabilities because code executes in a container on the backend. This summer, for my internship I set out to solve this problem and make it possible to play audio in any repl in any language. In this post I’ll show you how to play audio in your repl and then I will chronicle the journey that got us here. </p>
<p><img src="https://repl.art/music-01.png" alt="music art"></p>
<h2 id="how-you-play-audio">How you play audio</h2>
<p>Before we get to the technical parts, let's talk about how you can use audio in your app or game.</p>
<p>As of this writing we support two libraries: Python and JavaScript. The Python library is built right in so you shouldn't need to install it. However, the JavaScript library you'll have to install and you can do that by simple importing (<code>@replit/audio</code>).</p>
<p>You can learn more on our <a href="https://docs.repl.it/repls/audio">docs for audio</a>.</p>
<p>Let’s take a look at a quick demo before I tell how it all works:</p>


<h2 id="how-it-works">How it works</h2>
<p>It started out with an idea, I wanted to add audio to Repl.it because I wanted to use it and many users were asking for it, so it seemed like a good project to take on.  To be honest, I thought it was going to be a lot easier than it turned out to be. I thought I’d just throw in a Pulseaudio stream over TCP, play it in the browser, and be done with it. I was wrong. But who would’ve thought that real-time audio streaming from an isolated Docker container using fake audio devices without the use of an always-on daemon would be difficult? I sure didn’t.</p>
<p>At first, my goal was to get something simple that worked. My first attempt was to use a combination of portaudio and loopback devices native to the host machine but isolated to each container but that didn’t end up working because the infrastructure was far too complicated to be maintainable and we’d have to install C libraries for each language so they could play audio. Moving on.</p>
<p>My second attempt was to prototype something so I could see how I could build the client. I wanted to make sure that I had at least one part of the setup correct.  For this attempt, I just searched for files named “PlayMeAudio.wav (or .aiff)” which would be decoded and sent to the client in a buffer when the client opened the repl. Although this worked, it was only a prototype and we didn’t ship it.</p>
<p>For my third attempt, I figured I’d decode the audio and relay that to the client via a pipe file. Although this worked, it was using a ridiculous amount of CPU in Python and just simply not fast enough. I had concerns it might be an issue in other languages as well.</p>
<p>For my final and fourth attempt, I made a request based system. Instead of decoding the audio files in userland and putting a strain on resources, I’d have the user language tell me which files to play, and we’d do the heavy lifting in Go, which is the language that we write the container service in, which we call PID1.  Although the code was a mess, it worked and ended up being the first version of audio we released to explorers, despite its many shortcomings.</p>
<p>Although it worked, this attempt had three issues: 
All files had to be at a sample rate of <code>44,000</code> hertz
All files had to have a bit depth of <code>32</code>
Only <code>.aiff</code> and <code>.wav</code> files were supported.</p>
<p>The reason for the first issue was that I couldn't find a good polyphase filter (for sample rate conversion) and I needed a C library to cross compile. This proved to be challenging, as we needed to static link it and it had libm as a dependency, which means we’d have to static link all of libc -- more on that later.  I ended up having to dynamically build it. Including its source wasn't an option because it had very large generated files, so I had to build it before we built PID1, more on this later on.</p>
<p>For the second issue, I really didn’t have an excuse other than not really understanding bit depth, but once I did I was able to quickly fix it.</p>
<p>For the third one, it wasn't so much that those files were the only ones supported - it was more so that we didn’t support <code>.mp3</code> files- for this, I ended up needing to use C again. I used minimp3 library and its Go bindings.</p>
<p>I also had plans to include <code>.opus</code> file support, so I was going to need another C library… Well to clarify, I needed both opus and opusfile. Opusfile requires opus, which requires OpenSSL, so I had to build OpenSSL the build opus and opusfile, without root. Well needless to say, this was starting to get a bit ridiculous to do more than once. I made a <a href="https://github.com/repl-it-discord/audio/">github repo</a> which would serve as a repo to house all the C libraries we needed along with the Go bindings, and I included a file I found from a source that would let me static link libm without all of libc. </p>
<p>After all of this, we have the dependencies resolved, and everything sounds good - except for one thing: Changes in audio take <code>~.74</code> -  <code>~1.48</code> seconds to take effect. Why? Well we were sending audio in chunks, instead of streaming. Every <code>~.74</code> seconds, we prepare audio and send exactly <code>32,768</code> samples (<code>2^15</code>, no particular reason for this magic number other than the buffer rarely runs out and the latency isn't unbearable) but this wasn't enough.  </p>
<p>The client was designed to append audio samples at the end of what it had scheduled, so what I did was send audio initially and then immediately send it again, so we’d give the client  <code>65,536</code> samples at the start, and send an additional <code>32,768</code> samples every <code>~.74</code> seconds. Where did I get <code>.74</code> seconds from? As we are playing the audio at <code>44,100</code> hertz, we play <code>44,100</code> samples per second - so <code>32,768/44,100</code>. </p>
<p>This setup was great for smooth audio, but I felt that the latency makes your repl experience feel rather shoddy. I mean, imagine you’re playing a game, you open the chest and go through a door. Once you go through the door, the sound from the chests plays because you as a user have that <code>.74</code> - <code>1.48</code> second buffer, which just makes using audio for games useless for anything other than background music.</p>
<p>So we had to rewrite this and unfortunately to solve the timing issue we had to complicate the solution. We made the server send overlapping buffers of samples and the client used a timing system along with a sample index the server sent to calculate and compensate for latency and try to make it “real-time” streaming.</p>
<p>Now I know this is hard to understand, in fact I was told it was also hard to code review, so I’ll do my best to illustrate it. </p>
<p>Normally, this is how our makeshift stream would look:</p>
<pre><code>Message 1: 1 2 3 4 5
Message 2:         5 6 7 8 9 
Message 3:                 9 10 11 12 13
...</code></pre><p>This keeps us from audio cutting out due to (network) latency (to an extent), allowing us for smaller buffer sizes without as much (audio) latency</p>
<p>That alone isn't very special, what's really the star of the show is for the server to be able to send:</p>
<pre><code>Message 1: 1 2 3 4 5  
Message 2:   2 3 4 5 6
Message 3:           6 7 8 9 10</code></pre><p>The client is where the difficult processing for this takes place, when we receive new samples we immediately stop playing and start playing those samples… well… mostly. </p>
<p>You see, there's still the one thing that we can’t control. Networking.  Maybe there's a <code>.1</code> second delay for one of the messages, well now look - we’re playing audio we already played!</p>
<p>So now the client has to calculate LATENCY too, which is even MORE difficult. At this point, we’re on multiple devices, and we need less than a <code>1/44,100</code> second difference in time in order to figure this out! That seemed too hard. Instead, what I did was give each message in the protocol the sample index of the first sample, i.e. the first message would have sample index <code>0</code>.  The client then determines how many samples the player has played in total and if that's greater than the sample index it will compensate for that by skipping samples. </p>
<p>Now too get back to the request system I mentioned earlier -- how does one use that? As I mentioned, there’s two libraries above for Python and JavaScript, however this should work for any language, and you’re free to implement your own libraries.</p>
<h2 id="how-do-libraries-work">How do libraries work?</h2>
<p>As mentioned above, users can determine what is played via requests to a named pipe which PID1 reads.  I opted for a simple approach for encoding - json. While making libraries is fun and all, I can’t update libraries for many languages every time I change the requests, so I figured I’d make the request system pretty simple.</p>
<p>The user’s script must only write json data to <code>/tmp/audio</code> (a named pipe) and the go script will then parse the data and fulfill the request.  However, this might error - for example the file isn't found or has invalid encoding. Since we’re sending requests through a named pipe, we can't get errors very easily.
This means that the library the client uses must determine when there’s an issue with a source being created - the setup I made for the libraries which I used would wait up to a set amount of time then if the source wasn’t created in time it times out - while this isn’t always perfect, it's better than nothing.</p>
<p>A typical request to play a tone might look like this:</p>
<pre><code>{
  <span>"Paused"</span>: <span>false</span>,
  <span>"Name"</span>: <span>"My tone"</span>,
  <span>"Type"</span>: <span>"tone"</span>,
  <span>"Volume"</span>: <span>1</span>,
  <span>"DoesLoop"</span>: <span>false</span>,
  <span>"LoopCount"</span>: <span>0</span>,
  <span>"Args"</span>: {
    <span>"Pitch"</span>: <span>400</span>,
    <span>"Seconds"</span>: <span>5</span>,
    <span>"Type"</span>: <span>1</span>,
    <span>"Path"</span>: <span>""</span>
  }
}</code></pre>
<p>A quick explanation of the above fields: </p>
<ul>
<li><code>Paused</code> - Whether the source is paused or not - this can only be set when updating the source.</li>
<li><code>Name</code> - the name of the source - this can be used to identify the source when it's being created - if it's not set the name will be set by pid1.</li>
<li><code>Type</code> - the type of the source, supported types when I wrote this are:<ul>
<li><code>wav</code> - A <code>.wav</code> file</li>
<li><code>aiff</code> - A <code>.aiff</code> file </li>
<li><code>mp3</code> - A <code>.mp3</code> file</li>
<li><code>tone</code> - A generated tone.</li>
</ul>
</li>
<li><code>Volume</code> - The volume of the source as a floating point number - <code>1</code> would be <code>100</code>%</li>
<li><code>DoesLoop</code> - Whether the source should loop or not …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.repl.it/audio">https://blog.repl.it/audio</a></em></p>]]>
            </description>
            <link>https://blog.repl.it/audio</link>
            <guid isPermaLink="false">hacker-news-small-sites-24013764</guid>
            <pubDate>Fri, 31 Jul 2020 20:42:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Trackable QR Codes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24013630">thread link</a>) | @TimLeland
<br/>
July 31, 2020 | https://tdotly.com/blog/how-to-create-trackable-qr-codes/ | <a href="https://web.archive.org/web/*/https://tdotly.com/blog/how-to-create-trackable-qr-codes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary">
<main id="main">
<article id="post-224">
<div><div><p>QR Codes are a great way to point users to specific web pages, promoting your program or event, or providing the user with additional information. Most smartphones now include QR code readers in the default camera app which makes QR codes much easier to use. A “trackable” QR Code contains embedded information that allows you to track how many visits to your web page resulted from the code on a specific poster, brochure, etc.</p>
<p>Trackable QR codes are easy to create using <a href="https://t.ly/">T.LY</a>. Whenever you shorten a link, you get a QR code automatically create ready to be used anywhere you like.</p>
<h2>Homepage</h2>
<p><a href="https://t.ly/"><img src="https://i0.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qrcodes.png?resize=633%2C195&amp;ssl=1" alt="" width="633" height="195" srcset="https://i0.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qrcodes.png?w=1201&amp;ssl=1 1201w, https://i0.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qrcodes.png?resize=300%2C92&amp;ssl=1 300w, https://i0.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qrcodes.png?resize=1024%2C315&amp;ssl=1 1024w, https://i0.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qrcodes.png?resize=768%2C237&amp;ssl=1 768w, https://i0.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qrcodes.png?resize=320%2C99&amp;ssl=1 320w, https://i0.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qrcodes.png?resize=450%2C139&amp;ssl=1 450w, https://i0.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qrcodes.png?resize=720%2C222&amp;ssl=1 720w" sizes="(max-width: 633px) 100vw, 633px" data-recalc-dims="1"></a></p>

<h2>Dashboard<a href="https://t.ly/links"><br>
<img src="https://i2.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qr-codes-2.png?resize=497%2C249&amp;ssl=1" alt="" width="497" height="249" srcset="https://i2.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qr-codes-2.png?w=889&amp;ssl=1 889w, https://i2.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qr-codes-2.png?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qr-codes-2.png?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qr-codes-2.png?resize=320%2C160&amp;ssl=1 320w, https://i2.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qr-codes-2.png?resize=450%2C225&amp;ssl=1 450w, https://i2.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/qr-codes-2.png?resize=720%2C360&amp;ssl=1 720w" sizes="(max-width: 497px) 100vw, 497px" data-recalc-dims="1"></a></h2>

<h2>Extension</h2>
<p><a href="https://t.ly/extension"><img src="https://i1.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/extenson-qr-tracking.png?resize=285%2C547&amp;ssl=1" alt="" width="285" height="547" srcset="https://i1.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/extenson-qr-tracking.png?w=636&amp;ssl=1 636w, https://i1.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/extenson-qr-tracking.png?resize=156%2C300&amp;ssl=1 156w, https://i1.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/extenson-qr-tracking.png?resize=534%2C1024&amp;ssl=1 534w, https://i1.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/extenson-qr-tracking.png?resize=320%2C614&amp;ssl=1 320w, https://i1.wp.com/tdotly.com/blog/wp-content/uploads/2020/07/extenson-qr-tracking.png?resize=450%2C863&amp;ssl=1 450w" sizes="(max-width: 285px) 100vw, 285px" data-recalc-dims="1"></a></p>


</div></div>
</article>

</main>
</div></div>]]>
            </description>
            <link>https://tdotly.com/blog/how-to-create-trackable-qr-codes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24013630</guid>
            <pubDate>Fri, 31 Jul 2020 20:32:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Features Acceptance by Client]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24013048">thread link</a>) | @Gen1us
<br/>
July 31, 2020 | https://blog.maddevs.io/software-features-acceptance-process-by-clients-49948f783756?source=friends_link&sk=75e7b63f7086c00e389dc83c3d426c8e | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/software-features-acceptance-process-by-clients-49948f783756?source=friends_link&sk=75e7b63f7086c00e389dc83c3d426c8e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="8f96">Project Management</h2><h2 id="6dc1">What problems can arise and how to avoid them</h2><div><div><div><div><a href="https://blog.maddevs.io/@tamaramun?source=post_page-----49948f783756----------------------" rel="noopener"><div><p><img alt="Tamara Mun" src="https://miro.medium.com/fit/c/96/96/1*kYv_s7Yqw5w34iwqYxKzww.jpeg" width="48" height="48"></p></div></a></div></div></div></div><p id="4c2c">Feature acceptance by the client is one of the important phases in the project’s life cycle, which ultimately determines the product’s functionality delivered to the end-users. The whole point of this step is to successfully sign off the feature with the client and make the release, but to achieve it you have to make sure that all the objectives are met. Sometimes not everything goes so smoothly. It often happens when just before the deadline you discover that some functions are acting up or stop working at all. As a result, you get stressed teams and unsatisfied clients. Let’s work out why these problems occur and the ways you can ensure stressful-free feature completion.</p><p id="daaa">One of the most frequent problems is when teams <strong>do not think through feature requirements</strong>.</p><figure><div><div><div><p><img alt="Two yellow robots opposite board." src="https://miro.medium.com/max/2734/0*S1fMRKsH_35nUCld" width="1367" height="912" srcset="https://miro.medium.com/max/552/0*S1fMRKsH_35nUCld 276w, https://miro.medium.com/max/1000/0*S1fMRKsH_35nUCld 500w" sizes="500px" data-old-src="https://miro.medium.com/max/60/0*S1fMRKsH_35nUCld?q=20"></p></div></div></div></figure><p id="90eb">For example, you implemented a feature for the web page, however, you did not think it through and forgot to adjust it for the mobile version, which results in a jagged page layout or faulty feature. Or you developed a customer service feature for end-users but did not consider adding a control panel for admin staff. Such small things, which can easily slip your mind will have a big impact on the quality of the user experience.</p><p id="98f3">The previous issue can be avoided by focusing on creating a high-quality and comprehensive plan in the early stages, which will help you and your team to avoid any last-minute hustles.</p><figure><div><div><div><p><img alt="Two girls communicating." src="https://miro.medium.com/max/1824/0*L6Vb1fPH7ZwCex3t" width="912" height="912" srcset="https://miro.medium.com/max/552/0*L6Vb1fPH7ZwCex3t 276w, https://miro.medium.com/max/1000/0*L6Vb1fPH7ZwCex3t 500w" sizes="500px" data-old-src="https://miro.medium.com/max/60/0*L6Vb1fPH7ZwCex3t?q=20"></p></div></div></div></figure><p id="ad23">The main objective of feature planning lies in determining the value it will deliver to a user; however, it also includes in itself everything from function capabilities and to the way it will look like. When you are working on big projects, it is essential for a team to carefully consider each feature from<strong> the perspectives of different users</strong> as it is greatly affecting the characteristics it should deliver. It is also important to organize enough testing before the project completion, to identify any defects in the early stages.</p><p id="b307">Another common problem is when<strong> clients' wishes are being misread</strong> and it is usually a product of poor communication. It happens that at the planning stage technical team misunderstands the client’s needs and as a result, the final product is not meeting their expectations.</p><p id="0182">Sometimes both parties are the ones to blame. For example, the client has given a vague presentation of their idea, while developers did not clarify confusing parts and proceeded to an execution stage. Nevertheless, I believe that we should encourage a customer to be more open and give us the bigger and more detailed picture, especially if he/she is not really tech-savvy and can have a difficult time trying to explain something out of their expertise. It is more sensible to ensure that all the time and effort you are about to put in this project is not going to be put to waste and met with disapproval in the end.</p><p id="4498">Afterward no matter if the idea was coming from the main stakeholder or product manager and despite how good it may sound; it has to go through a feature validation process. Essentially it will help to make sure it solves the right problems, fits the needs of your target audience, and has a potential for future business success. Only then you can proceed to the implementation stage. It is more sensible to ensure that all the time and effort the team is about to put in this project is not going to be put to waste for an idea that was bound to fail from the beginning.</p><p id="cb73">Making sure that your client is actively engaged in the project should be the top priority for the whole team.</p><figure><div><div><div><p><img alt="Man thinks." src="https://miro.medium.com/max/1824/0*w229I5OLXD7ltkxY" width="912" height="912" srcset="https://miro.medium.com/max/552/0*w229I5OLXD7ltkxY 276w, https://miro.medium.com/max/1000/0*w229I5OLXD7ltkxY 500w" sizes="500px" data-old-src="https://miro.medium.com/max/60/0*w229I5OLXD7ltkxY?q=20"></p></div></div></div></figure><p id="432c">It’s important to show the customer the progress of your work, making sure he/she sees what they are paying for and having a say in the process of development. Ensuring these aspects might save you from future troubles, such as when the client is not keeping track of the work and by the end is not satisfied with the outcome. These can be avoided by establishing a timetable for check-ups, it can be once in 1–2 months basically whatever will be fitting with your team’s pace. I find that it works better when such regular check-ups are more about visuals and testing the website or app itself, rather than looking at pure statistics and reports. It’s also great when a technical team doesn’t fully rely on the project manager but is ready to present the progress by themselves. It positively impacts both clients and teams involvement.</p><p id="e898">If you will be able to provide the client with regular review of the project, I can assure you that they will be more excited about the final product as the process will keep them more invested and curious.</p><p id="a871">Piling up the stack of work until the last minutes before the deadline. We all love it, don’t we? Yes, it might have worked with your school assignments and you were even getting A’s, but these habits should be better forgotten in the university days.</p><figure><div><div><div><p><img alt="Woman boring." src="https://miro.medium.com/max/2734/0*FL0fvCiqYJWxlonG" width="1367" height="912" srcset="https://miro.medium.com/max/552/0*FL0fvCiqYJWxlonG 276w, https://miro.medium.com/max/1000/0*FL0fvCiqYJWxlonG 500w" sizes="500px" data-old-src="https://miro.medium.com/max/60/0*FL0fvCiqYJWxlonG?q=20"></p></div></div></div></figure><p id="9132">You have to remember that in a business environment, your mistakes are not solely affecting you, but your inconsiderate actions will cost the whole company money and spoiled reputation. In such cases, when you start hurriedly finishing your tasks in consequence you end up with a raw and incomplete product.</p><p id="a841">Putting on your plate more than you can handle. It is common for a team to dive into the task solving without doing proper scheduling ahead. Whether it is feature planning or any other stage, before actually starting to work on something you have to take a step back and analyse your future steps. What you should do is break one big task in smaller subdivisions. Firstly, it helps with an accurate estimation of the time and setting realistic deadlines.</p><p id="e5d0">Secondly, if you look at the problem as one big and endless bundle of tasks you tend to overcomplicate the difficulty level. So, sub-tasking also brings you a better understanding of the problem you are trying to solve. Moreover, it will bring more clarity to the client of the work you are doing and deeper insight into the progress you make.</p><p id="01d8">A good and professional project manager or a developer won’t put up with any uncertainties and missed deadlines. If you don’t want to cause unnecessary stress in the future implementation stage, then you better not overlook the sub-tasking point.</p><p id="fc6c">Finally, you will face different kinds of problems at each stage of the project. But your job is to minimize the number of such encounters to the best of your ability. As we saw in the listed above examples planning is key. Whether it is for something more specific like features planning or more generic concerning the organization of the whole project. Ensuring that you have a comprehensive plan which will come handy to every member of the group is very important, i.e. it will help your co-workers to stay on track and meet all the deadlines.</p><p id="d13a">Apart from that, you should not forget to communicate with your client, the main stakeholder of the project. By listening to your customer’s enquiries and providing them with a regular overview of the work you will be able to address any arising misunderstandings on time. Without driving them to the last minute and providing your team will end up with unnecessary headache and stress.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.maddevs.io/software-features-acceptance-process-by-clients-49948f783756?source=friends_link&amp;sk=75e7b63f7086c00e389dc83c3d426c8e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24013048</guid>
            <pubDate>Fri, 31 Jul 2020 19:44:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Automate Tasks Estimation in Jira]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24013045">thread link</a>) | @Gen1us
<br/>
July 31, 2020 | https://blog.maddevs.io/how-to-automate-tasks-estimation-in-jira-720bacf6d75d?source=friends_link&sk=f57cc9a52560108f1a045e4a60e63281 | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/how-to-automate-tasks-estimation-in-jira-720bacf6d75d?source=friends_link&sk=f57cc9a52560108f1a045e4a60e63281">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="46e5">Project Management</h2><div><div><div><div><p><a href="https://blog.maddevs.io/@earthur_?source=post_page-----720bacf6d75d----------------------" rel="noopener"><img alt="Arthur Elizavetenkov" src="https://miro.medium.com/fit/c/96/96/2*4kZIGfRKTvxdq8xsJazHPw.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Mad Devs Time Tracking with Jira Software." src="https://miro.medium.com/max/8000/1*9EXM3IcfihDTOBG2284wKw.jpeg" width="4000" height="2172" srcset="https://miro.medium.com/max/552/1*9EXM3IcfihDTOBG2284wKw.jpeg 276w, https://miro.medium.com/max/1104/1*9EXM3IcfihDTOBG2284wKw.jpeg 552w, https://miro.medium.com/max/1280/1*9EXM3IcfihDTOBG2284wKw.jpeg 640w, https://miro.medium.com/max/1400/1*9EXM3IcfihDTOBG2284wKw.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*9EXM3IcfihDTOBG2284wKw.jpeg?q=20"></p></div></div></div></figure><h2 id="473c"><strong>Planning means more than just “staying organized”</strong></h2><p id="f337">IT project management is hard to imagine without planning. Planning orchestrates the work of different project departments (<a href="https://maddevs.io/services?utm_source=blog&amp;utm_medium=task-estimation" target="_blank" rel="noopener">software development</a>, marketing, sales, etc.). Having a plan enables business decision-makers to stay focused on where they go and see the vector of product development clearly. Planning cannot work without estimating the time of execution for each of your tasks. Developing a habit of splitting your tasks into subtasks while defining the estimated time of execution for all of them is not easy. This sin can be common not only with Junior developers but more experienced professionals can also avoid estimates.</p><p id="2cc2">In this article, I’ll explain how we encourage our developers to estimate tasks using simple &amp; smart Jira configuration.</p><h2 id="5b9a"><strong>Where the problem originates from?</strong></h2><p id="e435">To quickly start a new project in JIRA, our PMs often use the default settings for workflow, fields, screens, etc. These settings are a good fit for a broad variety of projects, which is excellent! However, if you have a more specific task to complete, you’ll need to go deeper into configurations, like in our example. You will have to learn something new, too.</p><figure><div><div><div><p><img alt="The Default Workflow and the Advanced Workflow Configured in Jira for One of Mad Devs Projects." src="https://miro.medium.com/max/3000/1*xZ3XrvuYRQ0muY--dmqAxw.png" width="1500" height="844" srcset="https://miro.medium.com/max/552/1*xZ3XrvuYRQ0muY--dmqAxw.png 276w, https://miro.medium.com/max/1104/1*xZ3XrvuYRQ0muY--dmqAxw.png 552w, https://miro.medium.com/max/1280/1*xZ3XrvuYRQ0muY--dmqAxw.png 640w, https://miro.medium.com/max/1400/1*xZ3XrvuYRQ0muY--dmqAxw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*xZ3XrvuYRQ0muY--dmqAxw.png?q=20"></p></div></div></div><figcaption>The default workflow and the advanced workflow configured for one of our projects.</figcaption></figure><p id="0015">At the sprint planning stage, our PMs ask developers to fracture and estimate their tasks. This enables us not to overload the sprint and stay committed to what we can deliver on time. However, at times a developer may drill into an unestimated task which may let the entire team down. This person may be unaware of the full scope of work that he or she needs to do. This is the reason behind such actions.</p><blockquote><p id="ada6">The developer’s estimate is their personal commitment to complete the task on time.</p></blockquote><p id="38d3">The manager can surely control estimates manually by checking out every ticket, but this is not what we really want. We need to save time. A project manager can automate their routine tasks by picking the existing tool or even creating one from scratch. This principle is driving the entire IT industry forward.</p><p id="2a30">Now let’s have a look at the simple and elegant solution to the problem with the tasks estimating.</p><h2 id="728e"><strong>JIRA can do more than you think</strong></h2><p id="b59e">To solve the problem, I needed to make developers fill the <strong>Original Estimate</strong> field before they start working on a task (this is important). I’ve been working with JIRA for over a year now. Thanks to the <a href="https://www.atlassian.com/university" target="_blank" rel="noopener">Atlassian University</a> courses I took, I came up with a solution fast. I assigned a task in JIRA to myself and started as follows:</p><p id="11c7"><strong>Prevent developers from moving an issue to the <em>In Progress</em> status until the issue has Original Estimate field filled</strong></p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3998/1*-d1B6G45hH3hYYwHlqVAIQ.png" width="1999" height="1137" srcset="https://miro.medium.com/max/552/1*-d1B6G45hH3hYYwHlqVAIQ.png 276w, https://miro.medium.com/max/1104/1*-d1B6G45hH3hYYwHlqVAIQ.png 552w, https://miro.medium.com/max/1280/1*-d1B6G45hH3hYYwHlqVAIQ.png 640w, https://miro.medium.com/max/1400/1*-d1B6G45hH3hYYwHlqVAIQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*-d1B6G45hH3hYYwHlqVAIQ.png?q=20"></p></div></div></div></figure><p id="339c">By default, JIRA allows you to start working on a task freely, without providing an estimate. So let’s fix this!</p><p id="438c"><strong>Step one. </strong>Go to the workflow of your project and find the <em>transition</em> from <strong>To Do</strong> to the <strong>In Progress</strong> status.</p><figure><div><div><div><p><img alt="The transition from To Do to the In Progress Status in Jira Software." src="https://miro.medium.com/max/3388/1*osq5d4VeVCsXfAwhn5Y8_g.png" width="1694" height="930" srcset="https://miro.medium.com/max/552/1*osq5d4VeVCsXfAwhn5Y8_g.png 276w, https://miro.medium.com/max/1104/1*osq5d4VeVCsXfAwhn5Y8_g.png 552w, https://miro.medium.com/max/1280/1*osq5d4VeVCsXfAwhn5Y8_g.png 640w, https://miro.medium.com/max/1400/1*osq5d4VeVCsXfAwhn5Y8_g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*osq5d4VeVCsXfAwhn5Y8_g.png?q=20"></p></div></div></div><figcaption>The transition from <strong>To Do</strong> to the <strong>In Progress</strong> status in Jira Software</figcaption></figure><p id="bffc"><strong>Step two. </strong>Add validation to the <strong>Original Estimate</strong> in the <strong>Field Required Validator</strong>. Add the error text explaining why a developer cannot proceed with the task. Apply the changes to your workflow.</p><figure><div><div><div><p><img alt="How to Add Validation to the Original Estimate in the Field Required Validator in Jira Software." src="https://miro.medium.com/max/1600/1*XdGepnVqCapzKH4p8yfqWA.gif" width="800" height="460" srcset="https://miro.medium.com/max/552/1*XdGepnVqCapzKH4p8yfqWA.gif 276w, https://miro.medium.com/max/1104/1*XdGepnVqCapzKH4p8yfqWA.gif 552w, https://miro.medium.com/max/1280/1*XdGepnVqCapzKH4p8yfqWA.gif 640w, https://miro.medium.com/max/1400/1*XdGepnVqCapzKH4p8yfqWA.gif 700w" sizes="700px" data-old-src="https://miro.medium.com/freeze/max/60/1*XdGepnVqCapzKH4p8yfqWA.gif?q=20"></p></div></div></div><figcaption>Add Validation <strong>Original Estimate</strong> in the <strong>Field Required Validator</strong></figcaption></figure><p id="9e5a"><strong>Step Three. </strong>Testing. Let’s try to move the task to the <strong>In Progress</strong> status with and without an estimate.</p><figure><div><div><div><p><img alt="Moving the Task to the In Progress Status With and Without an Estimate in Jira Software." src="https://miro.medium.com/max/1600/1*KHsybQD2CJHsO0xHyT5ZMg.gif" width="800" height="472" srcset="https://miro.medium.com/max/552/1*KHsybQD2CJHsO0xHyT5ZMg.gif 276w, https://miro.medium.com/max/1104/1*KHsybQD2CJHsO0xHyT5ZMg.gif 552w, https://miro.medium.com/max/1280/1*KHsybQD2CJHsO0xHyT5ZMg.gif 640w, https://miro.medium.com/max/1400/1*KHsybQD2CJHsO0xHyT5ZMg.gif 700w" sizes="700px" data-old-src="https://miro.medium.com/freeze/max/60/1*KHsybQD2CJHsO0xHyT5ZMg.gif?q=20"></p></div></div></div><figcaption>Moving the task to the <strong>In Progress</strong> status with and without an estimate</figcaption></figure><p id="927f">Perfect! Now no one on your team is able to start working on a task that hasn’t been estimated. (Bear in mind that this configuration applies to<em> all</em> tasks going through the transition <strong>To Do</strong><em> →</em><strong><em> </em>In Progress</strong>. If you need to set up the estimation required for certain <em>issuetypes</em>, you will need to set additional steps in <strong>Conditions</strong>).</p><h2 id="8361"><strong>Conclusion</strong></h2><p id="9989">This simple &amp; smart configuration will help you as a manager to always see how long all tasks take to be completed. Such a condition makes your developers think about the number of tasks taken into work. The estimation process is automated with zero micromanagement!</p><p id="666c">Do you want to know about Project Management more?</p></div></div></section></div>]]>
            </description>
            <link>https://blog.maddevs.io/how-to-automate-tasks-estimation-in-jira-720bacf6d75d?source=friends_link&amp;sk=f57cc9a52560108f1a045e4a60e63281</link>
            <guid isPermaLink="false">hacker-news-small-sites-24013045</guid>
            <pubDate>Fri, 31 Jul 2020 19:43:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: We're a bootstrapped B2B SaaS company that made and shipped “hardware”]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24012790">thread link</a>) | @cowllin
<br/>
July 31, 2020 | https://www.watercoolertrivia.com/blog/trophies | <a href="https://web.archive.org/web/*/https://www.watercoolertrivia.com/blog/trophies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>‍<strong>Here’s the one(ish)-sentence summary: </strong>we took a goofy idea with some crummy designs made in Google Slides and ended up contract manufacturing custom bobblehead trophies. We send these trophies to every team that subscribes to Water Cooler Trivia. <br></p><h2><strong>How it all began</strong><br></h2><p>In January 2019, our team met to talk goals for the upcoming year. We had laid the foundations for a product that brings work teams closer together and builds office culture, and we wanted to keep improving the product and bringing it to more teams.<br></p><p>One of our goals: <strong>Delight users through new customer-centric innovations. </strong>We’re a platform for customizable weekly trivia quizzes. The quizzes and results are sent via email or Slack. Naturally, most of our “customer-centric innovations” are software based, like redesigning our <a href="https://app.watercoolertrivia.com/demo/results">quiz results</a> or building a<a href="https://www.watercoolertrivia.com/blog/features-slack-app"> Slack app</a>.<br></p><p>However, with only a single-person engineering department, we couldn’t bite off much more than one big feature each quarter.&nbsp;So we started thinking about a customer-centric feature that didn’t require a single line of code: <strong>a Water Cooler Trivia bobblehead trophy.&nbsp;</strong></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f23668c73efdd4882767e82_IMG_0918.jpg" alt=""></p><figcaption>Yes, those are the trophies posed in my kitchen.</figcaption></figure><h2><strong>From idea to design</strong></h2><p>Back in 2019, there was a little old institution known as the office. This is where coworkers would spend much of their waking week, working in non-socially-distant proximity.&nbsp;<br></p><p>This is also where teams would discuss the weekly Water Cooler Trivia results. The winner is celebrated in the results email each week, but that fleeting sense of accomplishment, well, fleets.&nbsp;<br></p><p>We wanted to create a new way to celebrate the winner. Stealing the idea of a roaming championship totem like the <a href="https://www.google.com/search?q=stanley+cup+filled+with+skittles&amp;rlz=1C5CHFA_enUS879US879&amp;sxsrf=ALeKk01N4_N6R1iLOS5J_sNWKjo3ynVPPA:1596144974172&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=2ahUKEwjTy8ex9_XqAhXKQc0KHdcjBx0Q_AUoAXoECA4QAw&amp;biw=1440&amp;bih=749">Stanley Cup</a> or a WWE belt, we wanted to send a trophy to each team. <strong>The winner would proudly display the trophy on their desk for the duration of their reign</strong> -- typically one week but longer if they had back-to-back victories.&nbsp;<br></p><p>Rather than imitation-chrome over a faceless figurine like the soccer participation trophies of our past, we wanted <strong>a trophy that reflected the quirky, fun tone of Water Cooler Trivia</strong>. After all, the goal here is team-building fun, so the trophy might as well be fun.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f23602980e22bd77a756d05_Group%2050%20(2).png" alt=""></p><figcaption>There's enough of these faux-metallic-finished trophies in the world.</figcaption></figure><p>What’s more fun than a trophy? A bobblehead. What’s more fun than a faceless gold figurine? Our “blue brain” mascot.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f23609fc91bd60af1a7d087_collage%201.png" alt=""></p><figcaption>We love the brains.</figcaption></figure><p>I had a clear vision in my head of what these trophies would look like, but no design skills or manufacturing experience. <strong>My design toolkit? Google Slides.</strong> It’s free, super easy to share, and it has a crop button.<br></p><p>I searched for a few inspiration images: <strong>blue brains</strong>, <strong>water cooler renderings</strong>, and <strong>brain trophies</strong>. The results were pretty much exactly what you would expect.&nbsp;<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f3f49ec631774ca9422_hl75CU-kzTBo4_7r8jgUb2N8qc0Qw5isQu2pzmqlcHxo3zsOE7ge9pZJZ8GPuOOSho4quQe03VPjzZU8NMiNZxjrByIc5GMmJqLP99lFup3xD7WJ1pyreymPrxgyUYH4isDsRLbO.png" alt=""></p><figcaption>Design building blocks via Google Images.</figcaption></figure><p>Next up, I played with a few iterations of what this trophy might look like by overlaying text blocks and smashing two images together. <strong>These looked bad.&nbsp;</strong><br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f3fa79a46074dcddffa_Gu4Z_2uchCr5yiSgMknGu-nYorXoS3MiytTGaoHUpEoE1cnIwZhNa7fKO_beOtjIa6kVTBx4Fllbdp_SVW9YNRVpkx7HY9ve5UmbZzDd7qqbae7FjngA2yYyXaMGakAalD5ALlLA.png" alt=""></p><figcaption>First attempts at a trophy design.</figcaption></figure><p>So I iterated a few more times. I noodled with the concept of putting the brain in a water cooler (basically a 3D version of our boringly 2D logo).&nbsp;I toggled the transparency and saturation, hoping that I would magically stumble upon a not-totally-horrible-looking combination. <br></p><p><strong>It turned out fine.</strong><br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f245e1f6d93f82c6667f72d_Screen%20Shot%202020-07-31%20at%2012.08.20%20PM.png" alt=""></p><figcaption>My final Google Slides design of the trophy.</figcaption></figure><h2><strong>From design to manufacturing partner</strong></h2><p>Quick aside: a friend of a friend owns a business that sells Bitcoin socks. You read that right: socks, not stocks. Black foot-and-lower-leg coverings dotted with yellow BTC logos. I was amazed that the design, manufacturing, and shipping were all through <a href="https://en.wikipedia.org/wiki/Alibaba">Alibaba</a>, the Chinese conglomerate often compared to Amazon. </p><p>Critically, he clued me in to the fact that Alibaba has a super-accessible RFP (request for proposal) feature.</p><p><strong>You enter a description, an image, a quantity, and a price point. Within hours you are flooded with offers from manufacturers. </strong>This was extremely convenient. <br></p><p><strong>Five vendors reached out within 48 hours</strong> in various mixes of Chinese and English. I wasn’t quite sure how to decide, so I went with the vendor that was most responsive to my questions and had the most robust English.</p><p>Our contract manufacturer? <a href="https://xfdbobble.en.alibaba.com/">Xiamen Xinfade Trade Co</a> with Jonas from their team as our touchpoint throughout the process.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f245fb1dd15c16aa68b3ffc_Screen%20Shot%202020-07-31%20at%2012.15.02%20PM.png" alt=""></p><figcaption>Dog Custom bobblehead was the closest category.</figcaption></figure><h2><strong>From manufacturing partner to bobblehead trophies</strong></h2><p>The email back-and-forth with Jonas began in earnest when I sent my “designs” (Google Slides screenshots) in March 2019.<br></p><p>We discussed project timing, and in less than two weeks he sent pictures of the mold.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f4041f47b7113ec4f25_HT8B54ZCk_wm8pWpAzzq5DaBl9ViC-JS4Y2cCE9xGvXP1pPbvsDqLgjaZe4QREMBi2A_OxtqCVx9F4uLdG-HUe0MoA_CQapNoGtoTHAWrzMKJCatr-u1Y2SUpAM7BDLOa9Dp_XGr.gif" alt=""></p><figcaption>The mold of the trophy from different angles.</figcaption></figure><p>At this point, we'd agreed to 300 trophies for $3.50 each, but we hadn't signed a contract or paid a single cent. So when Jonas sent through the mold images I was floored: <strong>this was actually happening.</strong><br></p><p>The molds looked good enough that we locked in the deal with a signed and paid invoice.&nbsp;<br></p><p>By April 11, Jonas sent me painted versions of the molds so we could get a sense of the colors. He asked about box details, colors, stickers, size, and more fine tuning.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f3f680645a36ea7f2ec_P7_uon-XtgJW6KHv4xzCgkMbcCvyQNsq4XhoDOVf-xOd5E-LQ3V_B1-wLxrfB-mGO8lNkupe5fl1CFZr57yhkRLx82KDDNDWlJdD6jW0vkF5Fieny-8CSTC9sP665J_gUOYBfAdP.png" alt=""></p><figcaption>Painted versions of the mold. Still just a sticker version of the logo.</figcaption></figure><p>We asked for a lighter resin to make the cooler more transparent. Jonas made it happen. By mid-May, Jonas sent the picture of hundreds of bobbleheads coming off the assembly line. <strong>We were ecstatic.</strong></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f41e63c203678cfd7f0_lhd5l-_H4iikMusOv844lY3tWLENxFn5CyPE6mh8nrARa2XutbHet_-H356eKmkpMx9dd-lOQ9dz75iKCIalsrH4LX0QZkHak0WPmJqF9_BoYL95F6R_rHNFuFw8TJ9Kiqi5i9SQ.png" alt=""></p><figcaption>Fresh off the assembly line.</figcaption></figure><h2><strong>From China to Brooklyn</strong></h2><p>Turns out shipping across an ocean with a small quantity of low-cost items is… expensive.<br></p><p>Jonas asked who our freight-forwarder was. We had no idea what he was talking about. He asked about our customs and import licenses. We were still clueless.&nbsp;<br></p><p><strong>We solved those boring logistics, but the cost was quickly escalating.</strong></p><ul role="list"><li>That initial quote of $3.50 per bobblehead trophy had risen to $4.00</li><li>There was $400 in setup fees</li><li>Another $150 surcharge because of our small order size</li><li>Freight was almost $750 to get them sent halfway around the world&nbsp;<br></li></ul><p><strong>Total price: $2,492 ($8.31 per trophy) </strong>to turn my crummy design into boxes and boxes of bobbleheads.<br></p><p>One small issue: that price only got the trophies to us. We would still need to mail out each one individually to each customer, adding another $3-6 per trophy.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f24616d27b61804384eaefd_Group%2059.png" alt=""></p><figcaption>Money fleeing our pockets.</figcaption></figure><h2><strong>Tearing them down to build them up again</strong></h2><p>After an early July vacation, I returned to my fourth-floor walkup Brooklyn apartment with quite the surprise: 12 large, heavy boxes stacked neatly in the atrium. I didn't know how long the boxes had been there (I’d been out of town for over a week), but I was sure it'd confused my neighbors.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f40a79a463e49cddffb_jYbXUPrTvTKK3a8IJHNei2HidUvHJYD_Z60f33c0gfdzwNaSWQ7sg8yyO1Y0pXsjpVbSzZDzJHZh4nir8Kx2NtFKH8wGiS8e9bo70otXHOihTjPcrxdxQyQPk1rpzglmSXwLCQFj.jpeg" alt=""></p><figcaption>Much of the atrium was taken up with trivia trophy boxes.</figcaption></figure><p>With the help of two roommates, we carried the boxes up to our apartment. <strong>We unboxed the trophies, excited to see the outcome of the quixotic quest.</strong> They looked great! The brain was on a spring-loaded cylinder so it did indeed bobble, the transparency on the cooler allowed for easy observation of the richly-colored blue brain. It worked out better than I could have expected.&nbsp;</p><p>Except... </p><p>When I bobbled the bobblehead for a second time, the cooler separated from its circular base, sliding right off, and thusly <strong>decapitating the trophy.&nbsp;</strong></p><p>The glue that attached the open cooler cylinder to the circular cardboard base was shoddy. As bobbleheads, we fully expected them to receive regular rattling.</p><p>I hoped I’d pulled a bad apple out of the barrel, but <strong>quality control checks on the next five trophies confirmed the problem was widespread.</strong> It was simply a weak point in the construction.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f3f0544bd5651c0cbd0_C25G_MkoXsmSSgJagtb83H09Y1nECSOFa20tDsF49FGMSo4PgeGyRKj9TCt3A5W5jtooAoiRwpUK2369TgnCLTH_qo9fQpX2GxbZhoVjxC5eTFo0upGfua3XHAYPNUWsoc-29wAI.png" alt=""></p><figcaption>Actually there were two weak points.</figcaption></figure><p><strong>The glue did not hold the resin and the cardboard together nearly enough for a trophy meant to bobble.</strong> After confirming the worst, we acknowledged that it was going to take serious elbow grease and human power to get the trophies in customer-ready shape.<br></p><p>Before undertaking the crafty project, we fixed a handful and took them on a quick photoshoot around New York City.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f423227a4684e5a1aa4_mAPl9kF4d7Y-7A8c00uxYUVjSlReiPVk0u-bPp1KLFY7XHcnUlD0EWfq-KYey7NfXRQYFkaJQQAbCXWTMkaFCy34NBTVmuNTe-nHiYnB5ijfyPIcN3kV3XBC7OfITeuT7RPMsEIH.png" alt=""></p><figcaption>We call it the "poor man's photoshoot."</figcaption></figure><p>The process of precisely breaking 300 bobbleheads and re-gluing them in two different places with Gorilla Glue is not a quick one. Especially when you add in the time of unboxing and re-boxing each individual trophy. My partner, my roommate, even my sister visiting New York all generously chipped in their time. <strong>In total, we spent about 30 hours fixing up the trophies.</strong><br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f40be075e716de512c6_szmo0tDw4evHQO38Am7oYvL3LxscMU9jQJYxsR3iH0PSxUxdYFfxnqOB5OSRUfaUmG6jU3W2vjAYdFoV8VW6J6mHZd99b9nwEVcT0vduh7slhZWiSMcCImIFMWlr41Hn5WJ6SDab.jpeg" alt=""></p></figure><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f413227a489155a1aa3_4UNLDXSbdfeSvaO1Mn39bH51Stoov0wdxX-Ct3cyE2klQfOo_4ZsGFy6fwrEE_Fwa-F1JtRSdFT_igsbtnI5DJMQDiaALP418hApTCDbAO0Lz5Lt0MCsZyyQCgEax98ASz-o0AXJ.jpeg" alt=""></p></figure><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f40e762e79eb6d96dfe_iv7bHadxbLn_BnrWBepDqLbbEorOsEjSgBH4FPX2c1hmxpq4WtjK5GfKQ1gbcbnr4Eion6apmH4heWraFTJBqSFd9-O2xmT4jTC_tSE-jphn_I0KBG1_amel7hP9hoUUnuf_aMP8.jpeg" alt=""></p><figcaption>The real MVP.</figcaption></figure><p>Not exactly scintillating work, but we didn’t want to make it to the finish line only to send our customers a knowingly-busted object.</p><h2><strong>Lessons learned?</strong></h2><p><strong>Customers seem to genuinely like and appreciate the trophies.</strong> It gives our whimsical, fun-loving brand a more physical presence for hundreds of teams around the world.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f41d45976e1588c8c02_P37-ZeibsPwed0EDZpx_tgN41PuVZmSTffCrehHhU1u_eDKlYKaYjpH5xaXYasWMCypFZO5lJ4D7EnD8q5VbzEXFOeMMMAgHbr0r_MamQY3_Hoc3oFTYfsb44qYMw9BJuT_jn_cp.png" alt=""></p><figcaption>Happy customers after a weekly trivia win.</figcaption></figure><p>We’re a pragmatic team here at Water Cooler Trivia HQ. We don’t think these trophies are going to make-or-break our success as a team, product, and company. But it was one hell of a fun project. And we’re going to keep producing more to send to all of our customers (the first batch is nearly gone!)<br></p><p><strong>Paul Graham would be proud, we did something that </strong><a href="http://paulgraham.com/ds.html"><strong>doesn't scale</strong></a><strong>. </strong>We shipped “hardware” to each customer.<br></p><p>Plus, I learned. I learned that obscenely rudimentary design skills plus the power of Alibaba’s RFP system can get anything built. It was a cool learning that I’ve since re-applied exactly zero times (...yet).<br></p><p>Want one of these limited-edition Water Cooler Trivia bobblehead trophies? We’ll send you one for free when your office <a href="http://app.watercoolertrivia.com/signup">signs up</a> for a Water Cooler Trivia subscription :)<br></p></div></div>]]>
            </description>
            <link>https://www.watercoolertrivia.com/blog/trophies</link>
            <guid isPermaLink="false">hacker-news-small-sites-24012790</guid>
            <pubDate>Fri, 31 Jul 2020 19:22:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Glucosamine Supplementation Reduces All-Cause Mortality: Study]]>
            </title>
            <description>
<![CDATA[
Score 254 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24012587">thread link</a>) | @mrfusion
<br/>
July 31, 2020 | https://www.lifespan.io/news/glucosamine-supplementation-reduces-all-cause-mortality/ | <a href="https://web.archive.org/web/*/https://www.lifespan.io/news/glucosamine-supplementation-reduces-all-cause-mortality/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																
								
								
<p>It is one of the most commonly used supplements frequently taken to address joint pain, but there might be more to this dietary supplement than first meets the eye.</p>
<p>Glucosamine was originally discovered during the 1960s in Italy by pharmacologist Professor Luigi Rovati. Glucosamine is one of the most commonly used dietary supplements and is typically taken to help with the joint pain and inflammation associated with aging.</p>
<p>Glucosamine is a polysaccharide that is found naturally in cartilaginous joint tissues, bones, skin, ligaments, and nails, and it is involved in protein and lipid synthesis. In the context of joints, synovial fluid contains glucosamine and occupies the space between joints, helping to reduce the friction of joint surfaces.</p>
<p>Despite it being frequently taken for arthritis, the evidence for its effectiveness is limited, although, there is data for it being anti-inflammatory, as suggested by the results of a randomized clinical trial in 2015 [1].</p>
<p>However, glucosamine supplementation seems to correlate with lower all-cause mortality and other mortality risks, such as cardiovascular disease (CVD), cancer, respiratory and digestive diseases. A recent <a href="https://ard.bmj.com/content/79/6/829" target="_blank" rel="noopener noreferrer">analysis</a> published in the journal BMJ showed that glucosamine supplementation conveys around a 15% reduction of all-cause mortality [2]. This is a considerable amount when compared to other lifestyle interventions as well as other supplements. The data gathered is from a large number of people, and the trend of reduced mortality is unmistakable.</p>


<blockquote>
<p>This population-based prospective cohort study included 495 077 women and men (mean (SD) age, 56.6 (8.1) years) from the UK Biobank study. Participants were recruited from 2006 to 2010 and were followed up through 2018. We evaluated all-cause mortality and mortality due to cardiovascular disease (CVD), cancer, respiratory and digestive disease. HRs and 95% CIs for all-cause and cause-specific mortality were calculated using Cox proportional hazards models with adjustment for potential confounding variables.</p>
<p>Regular glucosamine supplementation was associated with lower mortality due to all causes, cancer, CVD, respiratory and digestive diseases.</p>
</blockquote>
<p><strong>Conclusion</strong></p>
<p>The exact reasons for this correlation with the reduction of various mortality risks is as yet unknown, but given the large patient group in this and in other analyses along with the popularity of this supplement, it is impossible to deny that there is a definite trend here.</p>
<p>We are not suggesting that you take this supplement, but given that it is cheap and freely available with an excellent safety profile, it may be worth your consideration and further research to evaluate if you wish to take it or not.</p>
			
		
<p><strong>Literature</strong></p>
<p>[1] Navarro, S. L., White, E., Kantor, E. D., Zhang, Y., Rho, J., Song, X., … &amp; Lampe, J. W. (2015). Randomized trial of glucosamine and chondroitin supplementation on inflammation and oxidative stress biomarkers and plasma proteomics profiles in healthy humans. PloS one, 10(2), e0117534.</p>
<p>[2] Li, Z. H., Gao, X., Chung, V. C., Zhong, W. F., Fu, Q., Lv, Y. B., … &amp; Li, F. R. (2020). Associations of regular glucosamine use with all-cause and cause-specific mortality: a large prospective cohort study. Annals of the Rheumatic Diseases, 79(6), 829-836.</p>
																	
															</div></div>]]>
            </description>
            <link>https://www.lifespan.io/news/glucosamine-supplementation-reduces-all-cause-mortality/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24012587</guid>
            <pubDate>Fri, 31 Jul 2020 19:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slack Is Fumbling Developers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24012496">thread link</a>) | @gregdoesit
<br/>
July 31, 2020 | https://www.swyx.io/writing/slack-fumble/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/writing/slack-fumble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="sapper"> <div>  <main> <div>  <h2 id="postSubtitle">and the Rise of Developer Discords</h2> <p>A few days ago <a href="https://twitter.com/swyx/status/1260929975454056449">I had a sudden realization</a>: I hadn't been active in Slack in the 2 months since <a href="https://www.swyx.io/writing/farewell-netlify/">I left Netlify</a>. Those of you who live and work in Slack know how big this is - I personally went from opening Slack practically <em>every day</em> from 2015 - 2020, to zero meaningful usage whatsoever.</p> <p>In its place, I am now active in a ton of Developer Discord channels. I feel like this is a <em>meaningful</em> shift this year, and based on responses, <a href="https://twitter.com/jkup/status/1260936175172419590?s=20">I'm</a> <a href="https://twitter.com/1Marc/status/1261960701666623488?s=20">not</a> <a href="https://twitter.com/stolinski/status/1260943494635352066?s=20">alone</a>.</p> <section> <h2 id="but-they-didnt-want-developers">But They Didn't Want Developers?</h2> <p>The obvious proximate cause of course, is that I am professionally and personally highly attuned to developer communities, and Slack has actively pushed away developer communities. <a href="https://twitter.com/harry_hedger/status/1261967137989513216?s=20">Quote Harry Hedger</a>:</p> <blockquote> <p>Slack lost <a href="https://www.reactiflux.com/">Reactiflux</a> bc they wanted $70k/month to support them.</p> </blockquote> <p>Sure, I get that this was a deliberate decision. Storage costs money. But <em>how much</em> are we talking? Further, every company understands the logic of running "loss leaders" in order to seed stickiness and future growth. <strong>While literally every other company on Earth is throwing all sorts of free benefits to attract developers</strong>, Slack found developer communities growing like a weed on it, and flicked them away like so much dandruff. Stewart Butterfield is like the anti-<a href="https://www.youtube.com/watch?v=VM-2OVNt-eQ">Ballmer</a>.</p> <p>I'm not here to argue that Slack lost developers because it didn't want developers. That's a tautology. I'm here to argue that <strong>this is a strategic fumble</strong> that opened up the field to whatever will eventually replace Slack for startups (Microsoft Teams' success is difficult to assess so I will ignore it here).</p> </section> <section> <h2 id="slack-losing-its-way">Slack Losing Its Way</h2> <p><strong>Developers are your canary in the coalmine</strong> for user experience - because they create the damn things!</p> <p>Slack's original appeal was that it had a much better user experience than prior work chat/email/collaboration tools including the now-dead HipChat and Campfire. Reams of VC pitch decks were made about the "Consumerization of the Workplace" thanks to Slack's approachable design (as <a href="https://medium.com/@awilkinson/slack-s-2-8-billion-dollar-secret-sauce-5c5ec7117908">MetaLab never fails to remind you</a>) and early touches like emoji reactions and bots. The theory was that we demand the UX polish that we see in our personal lives, in our professional lives as well.</p> <p>Fast forward to today: "I’ve been using Discord a ton lately. Slack for work and Discord for hobbies." That's from <a href="https://twitter.com/1Marc/status/1261960701666623488">Marc Grabanski</a>, who knows a thing or two about developer trends.</p> <p>I'll raise you another point: In 2016, Slack was originally backronym'ed into the <a href="https://www.businessinsider.com/where-did-slack-get-its-name-2016-9">Searchable Log of All Conversation and Knowledge</a>.</p> <p>Fast forward to today and advice from the curiously high amount of "how to work from home" content you've undoubtedly been receiving is overwhelmingly <a href="https://about.gitlab.com/blog/2015/04/08/the-remote-manifesto/#2-communicate-asynchronously">Communicate Asynchronously</a> and <a href="https://knowyourteam.com/m/lessons/161-managing-remote-teams/topics/1331-process-and-tools-how-to-collaborate-effectively-when-your-team-is-remote#but-are-there-tools-you-just-cant-live-without">Use Anything But Slack for Long Lived Knowledge</a>.</p> </section> <section> <h2 id="the-game-is-changing">The Game is Changing</h2> <p>Meanwhile the UX bar has risen in the past 5 years:</p> <ul> <li>Slack makes you create a email and password anew every time you join a new Slack. Clicking a Discord invite immediately lands you in the channel as long as you're logged in.</li> <li>Slack walks you through the full onboarding experience every time you join a new Slack. I've joined probably 80 Slacks, I'm tired of the "👋 Hi, Slackbot here!" welcome messages on how to use Slack, or the downright <em>buggy</em> step through guide that prompts me to put in my profile picture even though Slack clearly figured out that I use the same damn picture every time and is already displaying it. Discord does exactly none of this.</li> <li>You need to repeat the whole email and signup song and dance when you move to your phone. Discord is cross-platform-first - sign in on desktop and you're also signed in on mobile.</li> <li>(Developer specific) The new WYSIWYG editor rolled out last year <a href="https://www.vice.com/en_us/article/pa7nbn/slacks-new-rich-text-editor-shows-why-markdown-still-scares-people">made it annoying</a> for developers accustomed to What We Type Is What We Get Thank You Very Much. Not only does Discord not get in the way of your typing, it offers <strong>SYNTAX HIGHLIGHTING</strong> if you add <a href="https://help.github.com/en/github/writing-on-github/creating-and-highlighting-code-blocks#syntax-highlighting">language identifiers</a> to your code fenced blocks!</li> </ul> <p>The past year or so in Office Productivity has been a free-for-all as other companies moved into Slack's open flanks. Notion has torn it up as the Searchable Knowledge Base to beat today. Zoom has overwhelmingly captured video chat, despite Slack also offering it natively. Even a bootstrapped startup like <a href="http://tuple.app/">Tuple</a> has become successful despite Slack buying the literal <a href="https://techcrunch.com/2015/01/28/slack-buys-screenhero-to-add-screen-sharing-and-voice-chat-to-its-work-messaging-platform/">category maker</a> in the space. And of course Discord and even Telegram have made inroads in real time chat.</p> <p>My intuition is that <a href="https://stratechery.com/2017/the-great-unbundling/">the Great Unbundling</a> has come for Slack. Whether or not it survives will probably depend on this: Is text chat really <a href="https://jtbd.info/feature-vs-product-42bf2dad2764">a feature or a product</a>? Either way, having to answer that question is an undesirable strategic position for Slack to be in. There is no victory in this fight.</p> <blockquote> <p>Note: if you feel lost right about here, I released the <a href="https://www.swyx.io/writing/dev-guide-to-tech-strategy/">Developer's Guide to Tech Strategy</a> chapter of <a href="https://twitter.com/coding_career">my upcoming book</a> recently, feel free to pause and check it out.</p> </blockquote> </section> <section> <h2 id="not-over-yet">Not Over Yet</h2> <p>Slack has fumbled a ball, but it still has a strong lead. Two features still make Slack a strong fit for realtime workplace communication: <a href="https://www.theverge.com/2017/1/18/14305528/slack-threads-threaded-messages">threaded messages</a>, which Discord refuses to build, and <a href="https://slackhq.com/shared-channels-growth-innovation">Shared Channels</a>, which <a href="https://twitter.com/swyx/status/1096347638696267778?s=20">I've gone on record</a> as saying will add years' worth and billions of dollars of revenue. Both were introduced in 2017, probably the peak year of innovation for Slack before creating <a href="https://www.google.com/search?q=slack+fund&amp;oq=slack+fund&amp;aqs=chrome..69i57l2j69i59l2j69i65l2j69i61j69i60.843j0j7&amp;sourceid=chrome&amp;ie=UTF-8">the Slack fund</a> in 2018 and then its 2019 IPO.</p> <p>From my limited anecdata, the no-code <a href="https://venturebeat.com/2019/04/24/slack-launches-workflow-builder-for-businesses-to-make-apps-without-code/">Workflow Builder</a> hasn't yet had significant adoption, but I would be happy to see this change over time. All great platforms eventually add low/no-code automation.</p> <p>Slack has also made heavy investments for Enterprise Adoption, with things like <a href="https://slackhq.com/introducing-slack-enterprise-grid">Enterprise Grid</a> (also in 2017! hmm...). I of course don't have any insight into Slack's growth in the Enterprise. I'm fully aware of the economic incentives of going upmarket and forsaking low end customers.</p> </section> <section> <h2 id="communities-over-teams">Communities Over Teams</h2> <p>The net result of all this is that Slack is now very much not <a href="https://www.bloomberg.com/features/2016-design/a/stewart-butterfield/">the operating system for your team</a> that it set out to be. However its entire user experience is tied to teams.</p> <p>More specifically - having one single home team, interacting with that team on one device, and the assumption that you don't join or change teams very often. Perhaps this is the disconnect we are sensing.</p> <p> Slack's focus on teams may be becoming outdated in this new world we live in, where Deep Work and organized knowledge bases come at a premium, and our professional work crosses professional and personal boundaries, and spans across multiple devices, modalities and even multiple communities we both lead and participate in. Discord's focus on communities may win hearts and eventually wallets. Here's <a href="https://twitter.com/kurtkemple/status/1260947289436303367?s=20">Kurt Kemple on Discord's community features</a>, for thought: </p> <blockquote> <p>Discord is more community friendly IMO. Things like moderation, roles, boosting, group A/V, all make it a great place for a more democratized and scaleable platform.</p> </blockquote> <p>By focusing on communities instead of siloed teams, Discord becomes a friend of community leaders. In other words, <strong>Discord aggregates aggregators</strong>. In a world of <a href="https://stratechery.com/aggregation-theory/">Aggregation Theory</a>, this is a very good thing.</p> <p>I thought it was Paul Graham or Benedict Evans who said this, but am unable to find the source: "What hackers do for fun today, we will do at work tomorrow".</p> <p><strong>Hackers are deserting Slack in droves</strong>. Slack should be on high alert.</p> <hr> <p>Recommended reads:</p> <ul> <li>Mule's Dark Horse Discord: How a gaming chat platform is secretly connecting the internet, and defining the future of work: <a href="https://mule.substack.com/p/dark-horse-discord">https://mule.substack.com/p/dark-horse-discord</a></li> <li>Kevin Kwok's The Arc of Collaboration: <a href="https://kwokchain.com/2019/08/16/the-arc-of-collaboration/">https://kwokchain.com/2019/08/16/the-arc-of-collaboration/</a></li> </ul> </section> <hr>  </div> </main>  </div></div></div>]]>
            </description>
            <link>https://www.swyx.io/writing/slack-fumble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24012496</guid>
            <pubDate>Fri, 31 Jul 2020 19:01:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What makes Paul Graham a great writer?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24012259">thread link</a>) | @ellenrhymes
<br/>
July 31, 2020 | https://ellenrhymes.com/paul-graham/ | <a href="https://web.archive.org/web/*/https://ellenrhymes.com/paul-graham/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>In the last few months, I’ve heard these 4 statements from 4 different people:</p>
<ul>
<li>“I wish I could write like Paul Graham.”</li>
<li>“If I had to pick one writer to imitate, it would be Paul Graham.”</li>
<li>“Paul Graham’s writing is the epitome of clarity.”</li>
<li>“Paul Graham inspired me to start writing.”</li>
</ul>
<p>This widespread sentiment motivated me to dive deeper into Graham’s writing, with help from my collaborator &amp; writing mentor <strong><a href="https://www.writing.coach/jaworski" target="_blank" rel="noopener noreferrer">Dr. William Jaworski</a>.</strong> What’s Paul Graham doing that’s so special? In the world of writing, what do his fingerprints look like?</p>
<p>Here’s what we’ve observed.</p>
<h2><b>He organizes each essay around a razor-sharp core idea.</b><b><br>
</b><b></b></h2>
<center><img src="https://2.bp.blogspot.com/-A7eI-qYNuw8/Uj4ShMr5GVI/AAAAAAABtlA/3rCowIs3EmA/s1600/blood+of+a+poet+6.gif" alt="" width="499" height="374"></center>
<p><em>All imagery in this blog post comes from the 1930 film <a href="https://www.imdb.com/title/tt0021331/" target="_blank" rel="noopener noreferrer"><strong>The Blood of a Poet.</strong></a></em></p>
<p>Every essay needs a core idea. Maybe you think of it as the focal point, the thesis, or the argument you’re making. Dr. Jaworski frames it as “a pithy one-liner that serves as an organizing principle for the whole essay.”</p>
<p>When you’re in tune with a core idea, writing feels easier. Intrusive thoughts soften and recede. You’re able to slow down and think more systematically. You start to see where your essay will end (and where a different one might begin—another day). You have a bullseye in your sights.</p>
<p>Usually, you can grasp the core idea of a Paul Graham essay by reading the title. My favorite examples are <a href="http://paulgraham.com/mod.html" target="_blank" rel="noopener noreferrer">The Two Kinds of Moderate</a>, <a href="http://paulgraham.com/genius.html" target="_blank" rel="noopener noreferrer">The Bus Ticket Theory of Genius</a>, and <a href="http://paulgraham.com/talk.html" target="_blank" rel="noopener noreferrer">Write Like You Talk</a>. As you read any of those, you’ll see how every paragraph, and in fact every sentence, connects with the core idea. His focus is sharp and unwavering.</p>
<p>Admire that commitment &amp; focus, but realize that even for Graham, essay ideas aren’t sharp from the get-go. Don’t let hazy vision dissuade you: a blurry bullseye is better than no bullseye. The important thing is to not give up—and also to avoid falling in love with any particular idea.</p>
<p>…which brings me to a new point about Paul Graham’s writing!</p>
<h2><b>He doesn’t fall in love with his ideas.</b></h2>
<center><img src="https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-2-1024x576.jpeg" alt="" width="700" height="394" srcset="https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-2-1024x576.jpeg 1024w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-2-300x169.jpeg 300w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-2-768x432.jpeg 768w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-2-434x244.jpeg 434w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-2-868x488.jpeg 868w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-2.jpeg 1200w" sizes="(max-width: 700px) 100vw, 700px"></center>
<p>From experience, Paul Graham knows even <a href="http://www.paulgraham.com/bronze.html" target="_blank" rel="noopener noreferrer">smart people have bad ideas.</a> That’s why it’s important not to get caught up in your own. Some of your ideas will be good; some won’t. That’s fine. In fact, it’s completely inevitable: if you want to have good ideas, you have to accept the reality of having bad ones.</p>
<p>In <a href="http://paulgraham.com/useful.html" target="_blank" rel="noopener noreferrer">How to Write Usefully</a>, Paul Graham states this principle about as point-blank as it gets:</p>
<p><i>If you write a bad sentence, you don’t publish it. You delete it and try again. Often you abandon whole branches of four or five paragraphs. Sometimes a whole essay. You can’t ensure that every idea you have is good, but you can ensure that every one you publish is, by simply not publishing the ones that aren’t.</i></p>
<p>Graham’s essay <a href="http://paulgraham.com/13sentences.html" target="_blank" rel="noopener noreferrer">Startups in 13 Sentences</a> is a subtler illustration of the same idea. There’s no fancy technical footwork—structurally, it’s a plain-Jane listicle. Yet, there’s real insight in it. There’s the feeling that these ideas have weight and presence. That’s because those 13 ideas have been curated from a wide range of options. The essay is not the product of 13 ideas; it’s the product of 1,000+ ideas, narrowed down to 13. Before that essay ever saw the light of day, Paul Graham sifted through many good, bad, and half-decent ideas, and selected the best.</p>
<p>When Paul Graham starts thinking, he often finds dead ends. He explores the twists &amp; turns his thoughts can take, and eventually he finds the path down which he most wants to guide his readers. Choosing that path to the exclusion of the others requires being a ruthless self-editor—someone who can step back &amp; observe his own writing from a healthy distance. This process is the mark of a good thinker, and it’s also a mark of a good writer.</p>
<h2><b>He couples concepts with concrete examples.</b></h2>
<center><img src="https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-3.jpg" alt="" width="700" height="537" srcset="https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-3.jpg 808w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-3-300x230.jpg 300w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-3-768x589.jpg 768w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-3-434x333.jpg 434w" sizes="(max-width: 700px) 100vw, 700px"></center>
<p>About 70% of Paul Graham’s essays contain the word “example,” usually within the phrase “for example.” When he introduces an abstract idea, you’re never more than a sentence or two away from a well-picked example.</p>
<p>For example, in <a href="http://paulgraham.com/copy.html" target="_blank" rel="noopener noreferrer">Copy What You Like</a>, Graham writes, “<b><i>It’s easy to be drawn into imitating flaws,</i></b><i> because they’re easier to see, and of course easier to copy too.”</i></p>
<p>On its own, that sentence isn’t too useful. But immediately, Graham supplies a real example:</p>
<p><b><i>For example,</i></b><i> most painters in the eighteenth and nineteenth centuries used brownish colors. They were imitating the great painters of the Renaissance, whose paintings by that time were brown with dirt. Those paintings have since been cleaned, revealing brilliant colors; their imitators are of course still brown.</i></p>
<p>Thanks to that follow-up, I have a better sense of what Graham means.</p>
<p>Graham uses lots of examples because he knows <b>concepts are tools</b> used for thinking about the world. But a tool is helpful only if you know how to use it, and you learn how to use a concept by applying it to real things.</p>
<p>Paul Graham’s examples show you how to apply concepts to real life. Applying unfamiliar concepts to familiar examples makes those concepts easier to master.</p>
<p>Here are three more short meta-examples:</p>
<h5>From <a href="http://paulgraham.com/noob.html" target="_blank" rel="noopener noreferrer">Being a Noob</a>:</h5>
<p><b><i>The more of a noob you are locally, the less of a noob you are globally.</i></b> <b><i>For example</i></b><i>, if you stay in your home country, you’ll feel less of a noob than if you move to Farawavia, where everything works differently. And yet you’ll know more if you move.</i></p>
<h5>From <a href="http://www.paulgraham.com/stuff.html" target="_blank" rel="noopener noreferrer">Stuff</a>:</h5>
<p><b><i>Nothing owns you like fragile stuff. For example,</i></b><i> the “good china” so many households have, and whose defining quality is not so much that it’s fun to use, but that one must be especially careful not to break it.</i></p>
<h5>From <a href="http://paulgraham.com/work.html" target="_blank" rel="noopener noreferrer">What Doesn’t Seem Like Work</a>:</h5>
<p><b><i>If something that seems like work to other people doesn’t seem like work to you, that’s something you’re well suited for. For example,</i></b><i> a lot of programmers I know, including me, actually like debugging. It’s not something people tend to volunteer; one likes it the way one likes popping zits. But you may have to like debugging to like programming, considering the degree to which programming consists of it.</i></p>
<h2><b>He creates rhythm by varying sentence length.</b></h2>
<center><img src="https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-3.jpeg" alt="" width="550" height="394" srcset="https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-3.jpeg 550w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-3-300x215.jpeg 300w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-3-434x311.jpeg 434w" sizes="(max-width: 550px) 100vw, 550px"></center>
<p>When people talk about a writer’s “voice,” they’re largely talking about the rhythm of the writing. Is it choppy? Is it droning? Does it feel conversational? Much of this comes down to the lengths of your sentences, and especially how you mix and match them.</p>
<p>Paul Graham rarely uses long sentences, but he mixes and matches short and medium-length sentences to create a rhythm that mirrors the pace of real conversation.</p>
<p>A well-placed short sentence creates a pause. The key expression here is <i>well-placed</i>: you wouldn’t want to listen to a speaker who follows every sentence with a dramatic pause. Paul Graham tends to taper the lengths of his sentences down until he reaches a key point—something he wants to emphasize. That’s where he pauses.</p>
<p>Here’s a perfect example from <a href="http://paulgraham.com/vb.html" target="_blank" rel="noopener noreferrer">Life is Short</a>. Notice how Paul Graham uses the two shortest sentences in the paragraph (bolded), nestled among longer ones, to create points of salience.</p>
<p><i>If life is short, we should expect its shortness to take us by surprise. And that is just what tends to happen. You take things for granted, and then they’re gone. You think you can always write that book, or climb that mountain, or whatever, and then you realize the window has closed. The saddest windows close when other people die. </i><b><i>Their lives are short too.</i></b><i> After my mother died, I wished I’d spent more time with her. I lived as if she’d always be there. And in her typical quiet way she encouraged that illusion. </i><b><i>But an illusion it was.</i></b><i> I think a lot of people make the same mistake I did.</i></p>
<p>During our review of Paul Graham’s writing, <a href="https://www.writing.coach/jaworski" target="_blank" rel="noopener noreferrer">Dr. Jaworski</a> identified this technique and explained it to me. As part of his explanation, he wrote this awesome paragraph that I can’t help but share:</p>
<p>“Imagine you and I are taking a leisurely stroll, conversing as we go—the pace of our words matching the pace of our strides. Then something happens. There’s something I want to say, but I have trouble saying it. It’s important. We slow down. We stop. I struggle to find the words. I utter them. One. By. One. For emphasis. See? I’m being waggish, of course, but I trust you see the point: when you want to emphasize something, you need to slow the reader’s pace with shorter sentences and bolder punctuation. Conversely, when you’ve covered what’s important, you need to regain momentum using longer sentences and lighter punctuation, and might even forgo full stops entirely in favor of commas, conjunctions, semi-colons, dashes, and other devices that keep the reader moving.”</p>
<p>For me, Dr. Jaworski’s illustration is the most intuitive way to understand this technique. Of course, that doesn’t mean I’ll master it overnight—it takes practice and patience. But now, I have an effective metaphor to guide me.</p>
<h2><b>He doesn’t underestimate your intelligence.</b></h2>
<p>Yes, Paul Graham prefers short sentences and short words—his essays pass <strong><a href="http://www.hemingwayapp.com/" target="_blank" rel="noopener noreferrer">the Hemingway test</a></strong> with flying colors. But that doesn’t mean he’s dumbing his writing down. Quite the opposite: Graham knows he’s talking about sophisticated ideas, so he presents them cleanly, getting his writing out of the way. He avoids over-explaining things, which is a great way to evade rabbit holes.</p>
<p>Basically, he knows how to put himself in a smart reader’s shoes, and as soon as he starts thinking, “Yep, I get it”—he stops.</p>
<h2><b>He’s codified his own rules, and he follows them.</b></h2>
<center><img src="https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-4.jpeg" alt="" width="640" height="480" srcset="https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-4.jpeg 640w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-4-300x225.jpeg 300w, https://ellenrhymes.com/wp-content/uploads/2020/07/blood-of-a-poet-4-434x326.jpeg 434w" sizes="(max-width: 640px) 100vw, 640px"></center>
<p>In 2005, Paul Graham codified <a href="http://www.paulgraham.com/writing44.html" target="_blank" rel="noopener noreferrer">his own rules</a> for writing, and they’re exquisite. Get this: on my team of experienced writers, none of us had seen Graham’s rules before—but in our own separate ways, we’d each already learned to follow them.</p>
<p>So, straight from the horse’s mouth, here they are:</p>
<ul>
<li>Write a bad version 1 as fast as you can; rewrite it over and over.</li>
<li>cut out everything unnecessary.</li>
<li>write in a conversational tone.</li>
<li>develop a nose for bad writing, so you can see and fix it in yours.</li>
<li>imitate writers you like.</li>
<li>if you can’t get started, tell someone what you plan to write about, then write down what you said.</li>
<li>expect 80% of the ideas in an essay to happen after you start writing it, and 50% …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ellenrhymes.com/paul-graham/">https://ellenrhymes.com/paul-graham/</a></em></p>]]>
            </description>
            <link>https://ellenrhymes.com/paul-graham/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24012259</guid>
            <pubDate>Fri, 31 Jul 2020 18:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evolution Simulator in Vue + WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24011967">thread link</a>) | @KhoomeiK
<br/>
July 31, 2020 | https://labs.minutelabs.io/evolution-simulator/ | <a href="https://web.archive.org/web/*/https://labs.minutelabs.io/evolution-simulator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://labs.minutelabs.io/evolution-simulator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011967</guid>
            <pubDate>Fri, 31 Jul 2020 18:29:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Releasing on Product Hunt vs. Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24011607">thread link</a>) | @shahahmed
<br/>
July 31, 2020 | https://failflow.com/blog/my-first-product-hunt | <a href="https://web.archive.org/web/*/https://failflow.com/blog/my-first-product-hunt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://failflow.com/blog/my-first-product-hunt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011607</guid>
            <pubDate>Fri, 31 Jul 2020 18:06:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does Having an Anime Profile Picture Make You a Better Programmer?]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24011583">thread link</a>) | @wh313
<br/>
July 31, 2020 | https://h313.info/blog/github/anime/google-cloud/2020/07/31/does-having-an-anime-profile-picture-make-you-a-better-programmer.html | <a href="https://web.archive.org/web/*/https://h313.info/blog/github/anime/google-cloud/2020/07/31/does-having-an-anime-profile-picture-make-you-a-better-programmer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
<div>
<article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p>In her 2001 book <em>Anime from Akira to Princess Mononoke</em>, Professor Napier showed that many fans of
anime work in computer science and its related fields. The survey also happened to show that “over
70 percent had a grade point average of 3.0 or higher, which is especially impressive when one
considers the academic rigor of scientific fields.”</p>
<p>Anime has a pretty well-known reputation for creating <a href="https://youtu.be/755BDwzxv5c?t=3">men of culture</a>. That’s a clear
indication that anime fans can be profoundly affected by the medium. In addition, many prolific
open source contributors have anime characters as their profile picture. So that got me to thinking,
does being a fan of anime also make you a more intelligent person?</p>
<p><img src="https://raw.githubusercontent.com/laynH/Anime-Girls-Holding-Programming-Books/master/C%2B%2B/Sakura_Nene_CPP.jpg" alt="sakura nene cpp"></p>
<p>Of course, a question like that is nearly impossible to answer directly. After all, there’s
countless ways to measure intelligence, and anime fandom is so broad that no one definition can fit
all cases. For example, should we consider someone who has only watched <em>Spirited Away</em>, and liked
it very much, but has no exposure to other forms of anime, to be an anime fan? What about people who
only read manga? Or those who exclusively watch <a href="https://en.wikipedia.org/wiki/The_Leader_(web_series)">whatever this is supposed to be</a>?</p>
<p>A smaller question that’s easily answerable would be to see if having an anime profile picture
correlates with you being a better programmer. After all, if someone takes the effort to set their
profile picture to a waifu, they clearly have some fondness for anime. As for being a “better
programmer,” we’ll just equate being better with having more activity on GitHub. And being good at
programming does require an amount of critical reasoning at logic skill, which should equate to a
higher intelligence. Of course, this metric could be easily abused by having a <code>cron</code> job making a
ton of commits, but it’s a measure of programming activity that should be Good Enough™.</p>
<p>Luckily, Google provides their <a href="https://cloud.google.com/vision/">image labelling API</a> for very cheap (or free, if you
have GCP credit). As an example, putting in an image of best girl Mai Sakurajima from <em>Rascal Does
Not Dream of Bunny Girl Senpai</em> into the demo provided, I’ll get this list of labels back from it:</p>
<p><img src="https://h313.info/blog/assets/img/mai_google_vision.png" alt="mai"></p>
<p>Notice how one of the labels is “Anime”? That’s a surprise tool that will help us later :) Google
also provides a Python API, which makes it even easier to check images, since all you have to do now
is check if “Anime” is one of the tags:</p>
<div><div><pre><code><span>anime_or_not</span><span>(</span><span>image</span><span>):</span>
    <span>response</span> <span>=</span> <span>client</span><span>.</span><span>label_detection</span><span>(</span><span>image</span><span>=</span><span>image</span><span>)</span>
    <span>labels</span> <span>=</span> <span>response</span><span>.</span><span>label_annotations</span>

    <span>for</span> <span>item</span> <span>in</span> <span>labels</span><span>:</span>
        <span>if</span> <span>item</span><span>.</span><span>description</span> <span>==</span> <span>"Anime"</span><span>:</span>
            <span>return</span> <span>True</span>
</code></pre></div></div>
<p>As for GitHub commits, we can use the <a href="https://docs.github.com/v3/activity/event_types/">events API</a> that’s roughly analogous to the
contribution history graph of a user. We’ll be measuring user activity just by the number of events
for each user, so each event (opening a PR, creating a repo, etc.) is given equal weight. That’s
roughly analogous to how green a user’s contribution heatmap is.</p>
<p><img src="https://h313.info/blog/assets/img/github_contribution_graph.png" alt="contribution map"></p>
<p><a href="https://pygithub.readthedocs.io/en/latest/">PyGitHub</a> wraps the GitHub API into an easy to use library, so getting the number of
events for a user, as well as their profile picture’s URL, is pretty simple:</p>
<div><div><pre><code><span>users</span> <span>=</span> <span>g</span><span>.</span><span>get_users</span><span>()</span>

<span>for</span> <span>user</span> <span>in</span> <span>users</span><span>:</span>
    <span>event_count</span> <span>=</span> <span>0</span>
    <span>for</span> <span>event</span> <span>in</span> <span>user</span><span>.</span><span>get_events</span><span>():</span>
        <span>event_count</span> <span>+=</span> <span>1</span>

    <span>is_anime_image</span> <span>=</span> <span>check_if_weeb</span><span>(</span><span>user</span><span>.</span><span>avatar_url</span><span>)</span>
</code></pre></div></div>
<p>GitHub does rate limit the API to 5000 requests per hour for authenticated users. That’s enough to
run about 2000 requests per hour. To get around that, we can take advantage of how GitHub profile
IDs are numbered sequentially and process profiles in batches of 1000:</p>
<div><div><pre><code><span>for</span> <span>github_id</span> <span>in</span> <span>range</span><span>(</span><span>1200000</span><span>,</span> <span>1201000</span><span>):</span>
    <span>try</span><span>:</span>
        <span>user</span> <span>=</span> <span>g</span><span>.</span><span>get_user</span><span>(</span><span>github_id</span><span>)</span>
    <span>except</span> <span>Exception</span><span>:</span>
        <span>continue</span>

    <span># do user stuff here
</span></code></pre></div></div>
<p>I’ve modified the <code>get_user</code> function here to use the undocumented <code>/user/:id</code> endpoint. This hasn’t
been implemented in PyGitHub yet, but <a href="https://github.com/PyGithub/PyGithub/issues/1615">this issue</a> seems to be tracking it.</p>
<p>All that’s left is to link these APIs up and save the data. It’s trivial to just loop through all
users using the <code>/users</code> GitHub API endpoint, send their image over to the Google Vision API, note
down whether they had an anime profile picture and the number of events for that user, and finally
log it into a CSV for analysis later. That’s exactly what I did, and you can see my code
<a href="https://github.com/h313/anime-face">here</a>. It’s very research quality, so don’t expect much.</p>
<p>So now I’ve got a table of 3497 GitHub profiles, of which only 23 have anime profile pictures.
Here’s a box plot that displays the distribution of user activity by profile picture type:</p>
<p><img src="https://h313.info/blog/assets/img/github_boxplot.png" alt="box plot"></p>
<p>Hmm, the users with an anime profile picture do seem to have a higher average number of
activities. But we can’t stop here. Keep in mind that there’s way more samples of users without
anime profile pictures compared to those with, as well as the comparatively high amount of
outliers in both groups. To be sure that the difference here is statistically significant,
we’ll need to do a T-test:</p>
<div><div><pre><code><span>from</span> <span>scipy.stats</span> <span>import</span> <span>ttest_ind</span>

<span>cat1</span> <span>=</span> <span>df</span><span>[</span><span>df</span><span>[</span><span>'is_anime_face'</span><span>]</span> <span>==</span> <span>True</span><span>]</span>
<span>cat2</span> <span>=</span> <span>df</span><span>[</span><span>df</span><span>[</span><span>'is_anime_face'</span><span>]</span> <span>==</span> <span>False</span><span>]</span>

<span>ttest_ind</span><span>(</span><span>cat1</span><span>[</span><span>'contribs'</span><span>],</span> <span>cat2</span><span>[</span><span>'contribs'</span><span>])</span>
</code></pre></div></div>
<p>That provides a p-value of <code>0.2371</code>. We now have to conclude that the higher average we got isn’t
statistically significant, since our p-value of 23.7% doesn’t meet the traditional 5% cutoff.
Therefore, we must once again acquiesce to <a href="https://en.wikipedia.org/wiki/Betteridge's_law_of_headlines">Betteridge’s law</a>, and adopt our null
hypothesis, that having an anime profile picture does not necessarily correlate with your abilities
as a programmer.</p>
<p>Further work into this topic can be done, however. Since this project only looked at a small
number of users, who were among the first to register, it is not a representative slice of the
GitHub user population. In addition, it may also be enlightening to include the inactive users
skipped in this experiment.</p>
</div>

</article>
</div>
</div></div>]]>
            </description>
            <link>https://h313.info/blog/github/anime/google-cloud/2020/07/31/does-having-an-anime-profile-picture-make-you-a-better-programmer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011583</guid>
            <pubDate>Fri, 31 Jul 2020 18:04:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Niklaus Wirth was right and that is a problem]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 169 (<a href="https://news.ycombinator.com/item?id=24011573">thread link</a>) | @bowero
<br/>
July 31, 2020 | https://bowero.nl/blog/2020/07/31/niklaus-wirth-was-right-and-that-is-a-problem/ | <a href="https://web.archive.org/web/*/https://bowero.nl/blog/2020/07/31/niklaus-wirth-was-right-and-that-is-a-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-226">
	

	<div>
		
<p>Wirth’s law is not really a law. Actually, none of them ever are laws. They are adages:</p>



<blockquote><p><em>a proverb or short statement expressing a general truth.</em></p><cite><a href="https://www.lexico.com/en/definition/adage">https://www.lexico.com/en/definition/adage</a></cite></blockquote>



<p>Here is another law that is not a real law:&nbsp;<em>Moore’s law is the observation that the number of transistors in a dense integrated circuit (IC) doubles about every two years.</em></p>



<p>This means that we can expect the speed and capability of computers to increase while lowering the costs. Sadly, this is where Wirth’s law comes in:</p>



<blockquote><p><em>Wirth’s law is an adage on computer performance which states that software is getting slower more rapidly than hardware is becoming faster.</em></p><cite><a href="https://en.wikipedia.org/wiki/Wirth%27s_law">https://en.wikipedia.org/wiki/Wirth%27s_law</a></cite></blockquote>



<p>And while Moore’s law has proven to be true since 1975, Wirth’s law seems to be true as well. Niklaus Wirth, the designer of Pascal, wrote an article in 1995:</p>



<blockquote><p>About 25 years ago, an interactive text editor could be designed with as little as 8,000 bytes of storage. (Modern program editors request 100 times that much!) An operating system had to manage with 8,000 bytes, and a compiler had to fit into 32 Kbytes, whereas their modern descendants require megabytes. Has all this inflated software become any faster? On the contrary. Were it not for a thousand times faster hardware, modern software would be utterly unusable.</p><cite>Niklaus Wirth – A Plea for Lean Software</cite></blockquote>



<p>The problem of modern software development is manyfold. Wirth points out one crucial aspect: time.</p>



<blockquote><p>Time pressure is probably the foremost reason behind the emergence of bulky software.</p><cite>Niklaus Wirth – A Plea for Lean Software</cite></blockquote>



<p>And while that was true back in 1995, that is no longer the most important factor. We now have to deal with a much bigger problem: abstraction. Developers never built things from scratch, and that has never been a problem, but now they have also become lazy.</p>



<p>It was Edsger W. Dijkstra who tried to improve the quality of code and coined the concept of <em>structured programming</em>. He tried to get programming out of the state of crisis it was in, and he found support in programmers like Harlan D. Mills, Richard C. Linger and Bernard I. Witt. For a short period of time, programming was seen as a real craftmanship. Programmers cared about the quality of their programs, and that included clarity and efficiency.</p>



<p>Those times have passed. With the introduction of higher-level languages such as Java, Ruby, PHP and Javascript all in 1995, the same year in which Wirth wrote his article, programming became more abstract. </p>



<p>Languages like these made programming a lot easier and took many things out of the programmer’s hands. They were object-oriented and came with things as an IDE and garbage collection.</p>



<p>This meant that programmers had fewer things to worry about, which is of course great. Sadly, everything comes with a price. Having fewer things to worry about, also means having fewer things to think about. 1995 was the year in which programmers stopped thinking about the quality of their programs.</p>



<p>It also marked the beginning of the widespread use of libraries, probably one of the bigger problems. Don’t get me wrong, I love libraries. They are the only reason I am able to get things done. However, a library never comes with the exact things that you need.</p>



<p>Because a library is not made for one specific project, it probably has a bit more functionalities than you really needed. No problem, you would say. However, things pile up pretty quickly. Even the people who like libraries, don’t want to reinvent the wheel. This results in what we call dependency hell. <a href="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html">Nikola Duza wrote a post about that issue in Javascript</a>.</p>



<p>The problem does not seem that big, but try to grasp what is happening here. In another tutorial that Nikola wrote, he built a simple todo-list. It works in your browser with HTML and Javascript. How many dependencies did he use? <a href="https://blog.appsignal.com/2020/05/14/javascript-growing-pains-from-0-to-13000-dependencies.html">13,000.</a></p>



<p>These numbers are insane, but this problem will only keep increasing. As new, very useful libraries keep being built, the number of dependencies per project will keep growing as well.</p>



<p>That means that the problem Niklaus was warning us about in 1995, only gets bigger over time. </p>



<p>And no, you don’t have to learn assembly and start writing your web application in that. A good way to start would be to split up libraries. Instead of creating one big library that does everything you could ever possibly need, just create many libraries. Your god-like library could still exist, but solely as a wrapper. </p>



<p>This way a programmer only has to select the libraries he really requires, while ignoring the functionalities he is not going to use in his application. Not only are his dependencies smaller, but they will also use less of their dependencies because the dependencies of the unused functionalities do not have to be installed.</p>



<blockquote><p><strong>Note: </strong>The proposed solution obviously is not <em>the</em> solution. It would for example require a good way of versioning software to avoid a new dependency hell.</p></blockquote>
	</div>

	
</article></div>]]>
            </description>
            <link>https://bowero.nl/blog/2020/07/31/niklaus-wirth-was-right-and-that-is-a-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011573</guid>
            <pubDate>Fri, 31 Jul 2020 18:03:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Covid-19 notification app rolls out in Ontario]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24011206">thread link</a>) | @PieUser
<br/>
July 31, 2020 | https://www.cbc.ca/news/politics/covid-pandemic-app-ontario-1.5670239 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/covid-pandemic-app-ontario-1.5670239">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Residents of Ontario can now download a new app that can tell them whether they have been around someone who has tested positive for COVID-19 over the previous two weeks. But while government officials say the goal is to make the contact notification app available across the country, they can't say yet when it will be available in other provinces.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5670967.1596224769!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/covid-cda-20200731.jpg"></p></div><figcaption>The COVID Alert app, launched Friday in Ontario, tracks the locations of phones relative to other phones, and notifies users if they have been in proximity to another app user who has been confirmed to have COVID-19.  <!-- --> <!-- -->(Justin Tang/The Canadian Press)</figcaption></figure><p><span><p>Residents of Ontario can now download a new app that can tell them whether they have been near someone who has tested positive for COVID-19 over the previous two weeks.</p>  <p>But while government officials say the goal is to make <a href="https://apps.apple.com/ca/app/covid-alert/id1520284227">the COVID Alert contact notification app</a> available across the country and are&nbsp;in talks with other provinces, they can't&nbsp;state yet when it will be available outside Ontario. The Android version can be found&nbsp;<a href="https://play.google.com/store/apps/details?id=ca.gc.hcsc.canada.stopcovid">here</a>.</p>  <p>They also haven't explained&nbsp;why only one province has agreed to adopt what was supposed to be a national app.</p>  <p>COVID Alert is the federal government's latest move in the battle to prevent the spread of COVID-19 as Canada's economy gradually reopens. Here's how it works:</p>  <ul>   <li>You start by downloading the app to your smartphone.</li>   <li>That will allow the phone to use Bluetooth technology to exchange signals with nearby phones.</li>   <li>If someone tests positive for COVID, their public health authority will give them a one-time key to enter into&nbsp;the app.</li>   <li>The app will then send out notices to every phone that has been within two metres of the infected person's&nbsp;phone for at least 15 minutes over the previous 14 days — as long as those other phones also&nbsp;carry&nbsp;the app.</li>   <li>Those who receive a notification will receive instructions on what to do next.</li>  </ul>  <p>Officials say that the app will become more effective as&nbsp;more people download it — and they stress&nbsp;that it's a notification app, not a contact-tracing app.</p>  <h2>App is voluntary</h2>  <p>Prime Minister Justin Trudeau has downloaded the app.</p>  <p>"I want to be clear — this app isn't mandatory," he told reporters. "It's completely voluntary to download and to use."</p>  <p><strong>Watch: Prime Minister Justin Trudeau explains new COVID&nbsp;Alert app</strong></p>  <p><span><span><span></span><span>Prime Minister Justin Trudeau told reporters in Ottawa how the new federal COVID app will warn Canadians if they have been near someone who has tested positive for the virus.<!-- --> <!-- -->2:32</span></span></span></p>  <p>Other provinces, such as <a href="https://www.cbc.ca/news/canada/new-brunswick/covid-19-contact-tracing-app-new-brunswick-national-1.5618973" target="_blank">New Brunswick</a>, have worked to develop their own apps. Alberta launched a contact tracing app called <a href="https://www.alberta.ca/ab-trace-together.aspx">ABTraceTogether</a> on May 1.</p>  <p>Trudeau said the federal government is close to working out an agreement with the Atlantic provinces to integrate their systems with the app. The federal government says it&nbsp;is also talking with other provinces and territories about integrating their systems&nbsp;but hasn't indicated when other provinces might adopt the app.</p>  <p>While anyone across Canada can download the app, they will receive alerts only&nbsp;if they have been near someone who has tested positive&nbsp;in a province that has integrated the app with its testing&nbsp;system, and who has downloaded the app.</p>  <p>While the Android version requires users to turn on their location settings, officials maintain the app will not know a user's location, name or address. It also won't track exactly when the user was near someone who tested positive,&nbsp;or whether they&nbsp;are currently near someone who has tested positive.</p>  <p>For users of Apple devices, the app works on the iOS 13.5 operating system&nbsp;and newer systems. That means the app might not work on some older smartphones, and some users might&nbsp;have to upgrade their operating systems or purchase new phones. Several readers contacted CBC News Friday to say they were unable to download the app on an&nbsp;iPhone 5&nbsp;or iPhone 6.</p>  <p>Officials said the government has been working with federal Privacy Commissioner Daniel Therrien's office to address any privacy concerns.</p>  <p>Therrien endorsed the app on Friday, saying that he plans to download it himself.&nbsp;</p>  <p>"Canadians can opt to use this technology, knowing it includes very significant privacy protections," he wrote in a statement.</p>    <p>Ontario Information and Privacy Commissioner Patricia Kosseim&nbsp;agreed, saying her office's review found strong measures to protect privacy.</p>  <p>"I support the use of exposure notification technology to help control the spread of COVID-19, provided it is used in the way it's been designed to respect the privacy of Ontarians," said Kosseim. "This app will only work if people trust their personal information will be protected and choose to use the technology."</p>  <p>Therrien&nbsp;and Kosseim said, however, that&nbsp;their endorsements are conditioned on the app's use being voluntary and the government continuing to monitor it.</p>  <p>Cybersecurity expert Steve Waterhouse said Canada joins about 40 countries around the world that have launched apps&nbsp;to help curb the spread of COVID-19.</p>  <p>He said Canada's Bluetooth-based app is less invasive than the GPS-based tracking apps&nbsp;some other countries have adopted.</p>  <p>"It is designed to simply detect how close we are to another device and then report if we have been so much time in close proximity of that device,"&nbsp;Waterhouse told Radio Canada.</p>  <p>He said some questions remain unanswered —&nbsp;such as how portable the app will be.</p>  <p>"If one travels across Canada with different provinces, will the application be supported by all of the various jurisdictions across the country?"</p>  <p><em>Elizabeth Thompson can be reached at <a href="mailto:elizabeth.thompson@cbc.ca">elizabeth.thompson@cbc.ca</a></em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/covid-pandemic-app-ontario-1.5670239</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011206</guid>
            <pubDate>Fri, 31 Jul 2020 17:35:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Africa lending app publicly shames you when you’re late on loan payment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24011201">thread link</a>) | @srameshc
<br/>
July 31, 2020 | https://restofworld.org/2020/okash-microlending-public-shaming/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/okash-microlending-public-shaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>he only person David Kiragu lied to about the texts was his mom. To those close to him, like his partner, friends, former schoolmates, and work colleagues, he explained what was going on. To more distant contacts, including annoying relatives, he said nothing.</p>



<p>His mother probably knew he was lying — mothers often do — but she let it slide.</p>



<p>“I couldn’t tell her the truth,” Kiragu said to me last December. “So I told her it was one of those prison scams and she should ignore it.”</p>



<p>He owed money. Not a lot of it, but that didn’t matter. His fintech creditor was still telling everyone in Kiragu’s inner circle that he was a deadbeat.</p>



<p>It happened like this: Toward the end of March 2018, Kiragu found himself in a bind. At 32, he earned a solid income as a manager at an iNGO in Nairobi. But for the first time in his life, he couldn’t make rent.</p>



<p>His choices were limited. He could always borrow the remainder from friends, family, or somebody else in his network. The problem was that if he did, people would know he was living beyond his means.</p>



<p>But then one morning Kiragu logged into his Facebook account and saw an ad for a fintech app called OKash that promised to be the discreet friend who would spot him some cash and never mention it again. Offering the ability to “process loans in seconds,” OKash is one of many fintech apps that have sprung up in Kenya since 2012. All he needed to do was download the app, enter his financial details, and let the algorithm generate a credit rating. He would get the money he needed and could pay it back once he was liquid.</p>



<p>He doesn’t remember that day too well now, but Kiragu thinks it took just minutes to apply for his loan. His money arrived right away, so he paid his bills and moved on. “I started with about $15, which I repaid [on time], and my loan limit expanded. Then I borrowed about $35, which I also repaid,” he told me as we sat on the balcony of a chic restaurant in a mall outside Nairobi.</p>



<p>It was the third loan that upended his life. He needed it to top up his rent, because by then a vicious cycle had begun, wherein he would pay off his loan then borrow again to fill the hole that the last payment had left in his finances.</p>



<p>Kiragu started getting calls even before that deadline passed.</p>



<p>“Will you repay your OKash loan?” Kiragu remembers a caller asking him, before warning that if he missed a payment, the company would notify everyone on his contact list. In texts he showed me on his phone, an OKash representative had written an hour before the deadline lapsed, “Despite several polite reminders on your OKash loan . . . No PAYMENT received yet . . . Note that we are going to invade your privacy according to Terms of Service clause 8, IF NOT CLEARED BY 4PM.” The clause in question reads as follows: “In the event we cannot get in contact with you or your emergency contact, you also expressly authorise us to contact any and all persons in your contact list.”</p>



<p>In the days after the deadline, debt collectors hounded Kiragu, calling three to four times every hour. They also cast a wide net. “They texted just about everyone I know,” Kiragu says. His parents and many friends got messages. One of his colleagues even shared a screenshot of a text from OKash in an office-wide WhatsApp Group.</p>



<p>“Some [people] sympathized with me,” Kiragu wrote in a Facebook post about the experience. “Some were laughing at me and some were actually very annoyed that OKash is exposing and shaming me . . . Even my boss called me to ask if everything is okay.”</p>



<p>But his colleagues weren’t his main concern. What worried him more was what his parents would think. After an estranged aunt shared the message within his village, Kiragu’s father accused him of bringing shame on the family.</p>



<p>This was nearly two years ago, but the memory is still raw, so much so that Kiragu asked to use a pseudonym for this article. “If you pay on time, they are angels,” Kiragu said as he sipped his tea and stared at a potted plant behind me. “They keep texting you to take out another loan with them. If you do and won’t or can’t pay, then it’s pretty simple: Pay or we damage what you value most.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/05/h_21.00183863-scaled-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/05/h_21.00183863-scaled-1-648x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/05/h_21.00183863-scaled-1-2560x1575.jpg 2560w, https://restofworld.org/wp-content/uploads/2020/05/h_21.00183863-scaled-1-648x432.jpg 648w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="A M-Pesa kiosk in Nairobi in 2014.

Credit:
Sven Torfinn/Panos Pictures Panos/Redux

Naomi Wanjiku, a M-Pesa agent, arranges a customer's transaction at a M-Pesa kiosk in South B, a residential area of the city. M-Pesa, (M for mobile, pesa is Swahili for money), is a Kenyan cellphone-based money transfer service. The majority of its customers have no bank accounts, but they withdraw cash and make payments or send money using their cell phones. A network of appointed agents, scattered all over the country, provide the cashing handling services. 
 
Creation Date: Kenya">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Sven Torfinn/Panos Pictures Panos/Redux</span>
			</figcaption>
		</figure>


<hr>



<p><strong>In 2007, Safaricom</strong>, Kenya’s biggest telecoms provider, launched M-Pesa, a mobile wallet that allowed users to send and receive money and buy airtime. Smartphones were just becoming popular, so Safaricom tailored its fintech product to the basic cell phones most Kenyans already owned. It was immediately hailed as a revolutionary way to bring millions of “unbanked” customers into the formal financial sector. The Clinton Global Initiative and other major philanthropic organizations were vocal supporters, and it was soon being taught as a case study in business schools around the world. It was also a success on the ground: Safaricom aimed to sign up 350,000 M-Pesa users by the end of 2007, but by November it had already attracted over 1 million. From there, it only continued to grow. As of last September, 23.6 million Kenyans — nearly half of the country’s population — were using it regularly.</p>



<p>M-Pesa was initially meant to be a microfinance project; its first sales pitch to users was “Send Money Home.” It was banking on the fact that while working-class Kenyans who lived away from home wanted to support their families, cash is expensive. This was not a new concept; among Somalis, the Hawala system exists to address this same problem. If you want to send money to someone, you give it to a local agent, who then contacts a second agent located in the same area as the intended recipient, and that agent then disburses the money. Both agents earn a small commission, and they sort each other out.</p>



<p>In Kenya, there were several factors behind M-Pesa’s rapid ascent. One was that 2007 was an election year, and when violence erupted over the results, having a way to transfer money without leaving the house felt to Kenyans like a godsend. Another, more structural, reason was that before M-Pesa, the country’s banking sector served only a portion of the population. Kenya’s economy collapsed four times between the mid-1980s and the early 2000s, by which point the banks were heavily regulated. It was nearly impossible for low-income Kenyans, including millennials, to get loans. No such legal barriers applied to fintech.</p>



<p>When fintech took off, banks, Silicon Valley–backed products, private-equity products, and Kenyan companies all began competing for the same clients. One of the first savings-and-lending apps, called M-Shwari, was launched in 2012 through a partnership between a local bank and Safaricom. Some of its earliest users were Kenyans in the informal economy. In a 2017 social media post, for example, a business journalist noted that “up to a third of loans are taken between the hours of 3am and 5am. Most are repaid within twenty-four hours.” When the Central Bank looked into what was going on, they discovered that a typical user was a market seller who would wake up early and borrow enough money to pay everybody in her supply chain that day. She would then work until evening, pay back the loan, and repeat the cycle again the next morning.</p>



<p>Within a few years, credit-app use had started to spread throughout Kenyan society. Over a 13-year period, financial inclusion<a href="https://fsdkenya.org/publication/finaccess2019/"> jumped</a> from nearly 27 percent, in 2006, to almost 83 percent. And the product side grew as well. As of September 2018, according to a report from Financial Sector Deepening Kenya (FSD), the two main app stores offered 110 credit apps.</p>



<p>Almost all of these companies make their money by providing short-term loans with high interest rates. But that’s often where transparency around the business model ends. Since there is no regulatory framework governing fintech, it is hard to know who exactly owns an app or even where the money is coming from. The absence of regulation has many perks for the sector and one major liability: As companies soon discovered, if a user does not pay back what they have borrowed, plus interest, there is little a digital lender can do. Users can simply delete the app and move on. One solution to this problem has been to flag defaulters to one of Kenya’s three credit reference bureaus (CRBs), effectively locking them out of the credit market. It’s unclear how effective this strategy is, but it’s frequently used. Between 2014 and 2017, about 2.7 million Kenyans were negatively listed with a CRB, 15 percent of them for defaulting on loans of less than about $2. Last year, “how to check CRB status” was among the most-Googled questions in Kenya, between “how to be successful in life” and “how to get pregnant.”</p>



<p>Before long, digital lenders started looking into other methods of recouping their investments. Skip tracing, the ancient art of finding someone who owes you money and making them pay, was virtually nonexistent among fintech companies until early 2018. Coincidentally, that was the same year that Opay, a fintech company partially owned by the software-maker Opera, launched OKash in Kenya. The majority of Opera’s operations had been bought by a consortium of Chinese investors two years earlier, and shortly afterward, the company went on an expansion spree, announcing plans to invest $100 million in East Africa. While Opera’s then managing director, a former banker&nbsp; named Edward Ndichu, said at the time that the app would protect users’ personal information, he never explained how the company planned to safeguard its financial investment. But the answer was buried in OKash’s terms and conditions: When users download the app, they give it permission to access their contacts.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/03/Contact-List-2-40x29.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/03/Contact-List-2-590x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/03/Contact-List-2-590x432.png 590w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="https://www.simoulalva.com/" target="_blank" rel="noopener noreferrer">Simoul Alva for Rest of World</a></span>
			</figcaption>
		</figure>


<hr>



<p><strong>Reports of OKash</strong> using social shaming started to surface almost as soon as the app went live. And people immediately felt the fallout. A University of Nairobi …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/okash-microlending-public-shaming/">https://restofworld.org/2020/okash-microlending-public-shaming/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/okash-microlending-public-shaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011201</guid>
            <pubDate>Fri, 31 Jul 2020 17:35:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SETL – The Set Programming Language (2010)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24011047">thread link</a>) | @todsacerdoti
<br/>
July 31, 2020 | http://www.hakank.org/arrays_in_flux/2010/04/setl_the_set_programming_language.html | <a href="https://web.archive.org/web/*/http://www.hakank.org/arrays_in_flux/2010/04/setl_the_set_programming_language.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
                              The last weeks I have played with the programming language <a href="http://setl.org/">SETL</a> (<b>Set L</b>anguage). I like learning these kind of "paradigmatic" programming language even if they are not very much in use anymore. There is almost always new things to learn from them, or they make one to see well known things in a new light.
</p><p>
SETL was created in the late 1960's and is to be considered one early very high level language (VHLL) using sets as the bearing principle (like mathematical formulation) together with a PASCAL-like syntax. Some trivia:
</p><ul>
 <li> The first validating ADA compiler was written in SETL.
 </li><li> ABC, one of the inspirations of Python was inspired by SETL.
 </li><li> SETL is attributed as the first programming language that supported list (set/array) comprehensions. A very handy concept. Haskell's list comprehensions was inspired by SETL. 
</li></ul><p>

For more about the history of SETL, see <a href="http://cs.nyu.edu/~bacon/phd-thesis/diss/node7.html">A Brief History of SETL</a> in David Bacon's dissertation "SETL for Internet Data Processing". David Bacon is the person behind GNU SETL. In the section <a href="http://cs.nyu.edu/~bacon/phd-thesis/diss/node52.html">Comparison with Other Languages</a> Bacon compares SETL with some other languages (Perl, Icon, Functional Languages, Python, Rexx, and Java).
</p><p>
I like SETL, much for its handling of sets and tuples (arrays) which make prototyping of some kinds of problem easy, especially those with a mathematical bent. However, the advantages SETL once had as been a VHLL, prior to the "agile" languages - e.g. Perl, Python, Ruby, Haskell, etc - is not so big anymore. (I should probably mention that I'm at least acquainted with these mentioned languages..)
</p><p>
In case I forgot it: See my <a href="http://www.hakank.org/setl/">SETL page</a> with links and my SETL programs (and maybe some not mentioned here).

</p><h3>Different versions of SETL</h3><p>
There are some the different versions (or off springs) of SETL:
 </p><ul>
   <li> <a href="http://setl.org/">GNU SETL</a>. This is the version I use here, and seems to be the only public available and working version.
   </li><li> SETL2. Documented as a draft at <a href="http://www.settheory.com/">The Restored Eye</a> (settheory.com).
   </li><li> ISETL. See <a href="http://raider.muc.edu/~kirchmjf/isetlj/isetlj.html">ISETLJ</a>, ISETL in Java which is to released in May/June this year. ISETL has been used in teaching mathematics, e.g. abstract algebra.
 </li></ul>


<h2>Examples of SETL</h2><p>
I will not go through all features of SETL here, just show some example of what I have done and like about the language. See <a href="http://www.settheory.com/">Programming in SETL. (Draft in Progress)</a> (at settheory.com) for an in-depth tutorial of the language (SETL2 but much is also applied to SETL), or Robert B. K. Dewar's <a href="http://www.setl-lang.org/docs/setlprog.pdf">The SETL Programming Language</a> (PDF) for an overview, or <a href="http://www.linuxjournal.com/article/6805?page=0,2">An Invitation to SETL</a>.

</p><p>
All the examples below works with GNU SETL. Many of the smaller examples is shown as a command one-liner, since I often test different features this way. And as you may notice, quite a few of the examples are not very unlike programs written in Python or Haskell.
</p><p>
The mandatory <b>prime generation</b> program:
</p><pre> primes2 := {p in {2..10000} | forall i in {2..fix(sqrt(p))} | p mod i /= 0};
 print(primes2);
</pre><p>

One feature I like (and use a lot) is test things from the command line:
</p><pre>$ setl 'time0:=time();primes:= {p in {2..100000} | forall i in {2..fix(sqrt(p))} | p mod i /= 0}; 
   print("Num primes:",#primes);print("It took", (time()-time0)/1000,"seconds");'
Num primes: 9592
It took 2.222 seconds
</pre><p>

A variant of <b>prime number generation</b> using <code>not exists</code> instead of <code>forall</code>:
</p><pre>$ setl 'print({n in {2..100} | (not (exists m in{2..n - 1} | n mod m = 0))}); '
{2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97}
</pre><p>

Still another variant using intersection of <code>{2..n}</code> and the compound numbers:
</p><pre>$ setl 'n := 150; print({2..n} - {x : x in {2..n} | exists y in {2..fix(sqrt(x))} | x mod y = 0});'
{2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97 101 103 107 109 113 127 131 137 139 149}
</pre><p>
Here are some other examples of set/array comprehensions.</p><p>
<b>Fibonacci sequence</b>
As a one liner:
</p><pre>$ setl 'f:= [1,1]; r := [f(i) := f(i-1)+f(i-2) : i in [3..10]];  print(f);'
</pre>

<p><b>Pythagorean triplets</b> as a "one-liner" (not very fast for say [1..300]).
</p><pre>$ setl 'print({[a, b, h]: b in {1..30}, a in {1..b - 1} | 	
		(exists h in {2..a + b} | (a*a + b*b = h*h)) and 
		(not (exists d in {2..b - 1} | ((b mod d) = 0 and (a mod d) = 0)))}); '
{[3 4 5] [5 12 13] [7 24 25] [8 15 17] [20 21 29]}
</pre><p>

Creation of a <b>power set</b> (all subsets of a set), with the intermediate values printed; 
</p><pre>$ setl 'a := {1,2,3}; p := { {}}; (for x in A, y in P) p with:= Y with x; print(p); end; print(p);'
{{} {1}}
{{} {1} {2}}
{{} {1} {2} {1 2}}
{{} {1} {2} {3} {1 2}}
{{} {1} {2} {3} {1 2} {1 3}}
{{} {1} {2} {3} {1 2} {1 3} {2 3}}
{{} {1} {2} {3} {1 2} {1 3} {2 3} {1 2 3}}
{{} {1} {2} {3} {1 2} {1 3} {2 3} {1 2 3}}
</pre>

<p><b>Collect</b> values from a tuple to a map (hash table).<br>
A map is represented as a set of tuples of <code>[key, value]</code>. 
<br>
First a slow solution:
</p><pre>a := [1,1,2,2,3,3,3,4,4,4,4];
m:={ [i, #[j : j in [1..#a] | a(j) = i ]] :  i in { i : i in a}};
</pre><p>
Then a faster version:
</p><pre>$ setl 'a := [1,1,2,2,3,3,3,4,4,4,4];  m:= {}; for i in a loop m(i) +:= 1; end loop; print(m);'
{[1 2] [2 2] [3 3] [4 4]}
</pre>

<p><b>Index and value of a map</b><br>
The construct <code>for x = s(i) in ...</code> in a map (hash table) loop gives both the index (i) and the value (x). Here we also see how to represent ranges with increment other than 1 (much like Haskell).
</p><pre>setl 's := {[i,i**2] : i in [1,3..15]}; for x = s(i) loop print(i,x); end loop;'
1 1
3 9
5 25
7 49
9 81
11 121
13 169
15 225
</pre>

<p><b>Multi-map</b> (<code>m{value}</code>)<br>
SETL has a special syntax for multi-maps, i.e. where a key has more than one values: use "{}" instead of using the parenthesis "()" for accessing. Here the key <i>1</i> has two values (<i>a</i> and <i>c</i>). Using a "single-map" access (<code>a(2)</code> gives <code>OM</code>, the special undefined value (represented as "*" i GNU SETL).
</p><pre>setl 'a := {[1,["a"]], [2, ["b"]], [1, ["c"]]}; print(a);print(a(2));print(a(1));print(a{1});'
{[1 [a]] [1 [c]] [2 [b]]}
[b]
*
{[a] [c]}
</pre>


<p><b>Compound operators</b><br>
With a compound operators (as <code><b>op</b>/tuple</code> or <code><b>op</b>/map</code>) makes it possible to write quite sparse code (somewhat akin to APL and <a href="http://www.jsoftware.com/">J</a>). Here is the factorial of 100, also showing the support for arbitrary precision.
</p><pre>$ setl 'print(*/[1..20]);'
2432902008176640000
</pre><p>

There is no built-in <code>max</code> for tuples. Instead we use the compound operator version, which is possible since <code>max</code> is a binary operator:
</p><pre>$ setl 'setrandom(0); print(<b>max</b>/[random(10000) : i in [1..100]]);'
9898
</pre><p>

Another example of compound operators is from Project Euler problem #5 (<i>the smallest number that is evenly divisible by all of the numbers from 1 to 20</i>). In my solution (<a href="http://www.hakank.org/setl/project_euler5.setl">project_euler5.setl</a>) lcm and gcd is defined as operators (in contrast to procedures):
</p><pre>print(lcm/[2..20]); -- Prints the answer.

op lcm(a,b);
  g := a gcd b;
  return (a*b) div g;
end op lcm;

op gcd(u, v);
  return if v = 0 then abs u else v gcd u mod v end;
end op;
</pre><p>

Speaking of Project Euler problems, here is the SETL program for the first problem (<i>Find the sum of all the multiples of 3 or 5 below 1000</i>):
</p><pre>print(+/{i : i in [1..999] | i mod 3 = 0 or i mod 5 = 0});
</pre><p>

In <a href="http://www.hakank.org/setl/averages_pythagorean_means.setl">averages_pythagorean_means.setl</a>, three different version of mean are defined (as procedures) using compound operators (maybe not the most efficient way).
</p><pre>-- arithmetic mean
proc mean_A(x);   
  return +/x/#x; 
end proc;

-- geometric mean
proc mean_G(x); 
  return (*/x)**(1/#x);
end proc;

-- harmonic mean
proc mean_H(x);
  return #x/+/[1/i:i in x];
end proc;
</pre>

<p><b>Randomization</b>
The <code>setrandom(0)</code> is for creating random variables starting with an "arbitrary" seed. 
</p><pre>setl 'setrandom(0); s := [1,3,5,8]; print([random(s) : i in [1..10]]);'
[5 1 8 8 5 3 3 1 5 3]
</pre><p>

With a set we get a value only once:
</p><pre>$ setl 's1 := {1..10}; setrandom(0); print({ random(s1) : i in [1..10]});'
{3 5 6 7 8}
</pre><p>

In GNU SETL the <b>order</b> of the set is always presented as sorted, but this is not a requirement in the SETL language.

</p><p>
<b>Regular expressions</b><br>
GNU SETL has built in support for regular expressions (which standard SETL has not). Some examples:
</p><pre>$ setl 's:="nonabstractedness"; m:=s("a.*b.*c*.d*.e*"); print(s);print(m);'
nonabstractedness
abstractedness
</pre><p>

Also see <a href="http://www.hakank.org/setl/read_test2.setl">read_test2.setl</a> that search for words like this in a word file.
</p><p>
Substitution (cf. <code>gsub</code> for global substitution):
</p><pre>$ setl 's:="nonabstractedness"; m:=sub(s,"a.*b.*c*.d*.e*",""); print(s);print(m);'
non
abstractedness
</pre><p>

Note that GNU SETL don't support non-greedy regular expressions (i.e. the ".+?" constructs from Perl etc), so the plain old <code>[^...]</code> construct must be used.:
</p><pre>$ setl 's:="nonabstractedness"; m:=s("a[^s]+s"); print(s);print(m);'
nonabstractedness
abs
</pre><p>

A small drawback is that GNU SETL don't have support for national characters in strings. The only acceptable characters are the "plain ASCII".

</p><p>
<b>SNOBOL like pattern matching</b><br>
SETL also has SNOBOL/SPITBOL like patterns (but not as nicely integrated as in SNOBOL). Except as experiments, I tend to use regular expression rather than these functions.
</p><p>
Example: <a href="http://cs1.cs.nyu.edu/~bacon/setl-doc.html#any">any</a> is used like this:
</p><pre>$ setl 'x := "12345 12345 12345"; print(any(x, "123"));print(x);'
1
2345 12345 12345
</pre><p>

However, I miss the <code>many</code> function which takes <b>many</b> characters from the beginning, not just the first and it is quite easy to create it. First let's see how it works, where we will take all the characters from the beginning of the string if they are any of "123":
</p><pre>$ setl 'x := "12345 12345 12345"; print(x); while any(x, "123") /= "" loop print(x); end;;print(x);'
12345 12345 12345
2345 12345 12345
345 12345 12345
45 12345 12345
45 12345 12345
</pre><p>

(The corresponding regular expression for this is, of course <code>^[123]+</code>.)

</p><p>
A SETL procedure for <code>many</code> is defined below. The first argument is defined as read-write (<code>rw</code>) so we can modify the string <code>s</code>. The value returned (<code>z</code>) contains all the matched characters.
</p><pre>proc many(rw s,p); 
   z := "";
   while (zz := any(s,p)) /= "" and zz /= "" loop 
        z +:= zz; 
   end loop; 
   return z; 
end proc;'
</pre><p>

And here is <code>many</code> in action. Note: procedures must always be placed last in a program.
</p><pre>x := "12345 12345 12345";
print(x);
z:=many(x, "123");
print("x",x);
print("z",z);
proc many(rw s,p);
   print(s); print(p);
   while (zz := any(s,p)) /= "" and zz /= "" loop
   z …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.hakank.org/arrays_in_flux/2010/04/setl_the_set_programming_language.html">http://www.hakank.org/arrays_in_flux/2010/04/setl_the_set_programming_language.html</a></em></p>]]>
            </description>
            <link>http://www.hakank.org/arrays_in_flux/2010/04/setl_the_set_programming_language.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011047</guid>
            <pubDate>Fri, 31 Jul 2020 17:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Malka Older on the Future of Democracy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24011013">thread link</a>) | @eliotpeper
<br/>
July 31, 2020 | https://www.eliotpeper.com/2019/08/malka-older-on-future-of-democracy.html | <a href="https://web.archive.org/web/*/https://www.eliotpeper.com/2019/08/malka-older-on-future-of-democracy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
The best science fiction writers can bring down the most powerful of institutions with a single sentence, and erect new ones in a paragraph. In her debut science fiction thriller <i><a href="https://www.amazon.com/gp/product/0765392364/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=eliotpeper-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0765392364&amp;linkId=ea04f87955358c624a47ab958e39b490" target="_blank">Infomocracy</a></i>, Malka Older mines her extensive experience in governance research to craft not only a nuanced vision for the future of democracy, but a globe-trotting adventure with a diverse cast that explores electioneering, information warfare, and human ambition.</p><p>

The story takes place a few decades from now in a world where Information, a theoretically nonpartisan internet monopoly, controls the network infrastructure for global micro-democracy. Instead of today’s nation states, <i>Infomocracy</i>’s political units are groups of 100,000 people (dubbed “centenals”) who can choose their respective governments from a large menu of potential options with their own unique policy priorities. At the height of the election cycle, a campaign staffer for one of the leading parties finds himself entangled with a subversive activist and a special agent from the implacable Information. What follows will make you rethink our own embattled institutions.</p><p>

Politics is a hard problem, and Older doesn’t oversimplify into utopia or dystopia. The complexity <i>Infomocracy</i> portrays is refreshing and grounded in Older’s personal history. Before turning novelist, she spent a decade as a humanitarian aid worker supervising major programs, implementing economic development initiatives, and responding to natural disasters and complex emergencies in Sri Lanka, Uganda, Darfur, Indonesia, Japan, and Mali. She is a Senior Fellow for Technology and Risk at the Carnegie Council for Ethics in International Affairs and her doctoral research examines the unique challenges and paradoxes that acute crises pose for good governance. Writers of hard science fiction pride themselves on the technical credibility of the inventions their stories document. Older brings that attention to detail to the realm of political science, imagining a future sure to electrify policy wonks and geeks alike. The best science fiction leaves us breathless, not just because of its entertainment value, but because it changes how we see the world we inhabit. In today’s charged political climate, <i>Infomocracy</i> forces us to question our assumptions about the future of democracy.</p><p>

In the following conversation, we discuss how technology is changing political institutions and what future governments might look like.</p><div>
<p>
***</p><p>

<b>Is American democracy broken?</b></p><p>

American democracy was never quite democracy, and it was designed that way out of concern about what the democratic experiment would look like. It doesn’t only feature checks and balances on the branches of government; it’s also got checks and balances on the people (and, of course, was based on an entirely different notion of who “the people” are).</p><p>

Over the centuries since then, we’ve made it more democratic in some ways – most notably by expanding the franchise, but also, for example, by changing senate elections to a direct vote. On the other hand, (some of) those in power have also sought to adapt the system to their own needs: gerrymandering congressional districts, tweaking party rules and primaries, and finding more and more ways to make money off of political positions.</p><p>

So I’m not sure I’d say American democracy is broken. I would say we haven’t really given democracy a full try yet. We started off as a partial democracy, and have been fighting over how to expand or dilute it. Right now does feel like a particularly low ebb as institutions are being weakened, but at the same time we see that civil society is growing stronger.</p><p>

The other thing to remember is that democracy alone is not enough for good, participatory, equal government. It’s too easy for a democracy to become oppression by the majority, or devolve into demagoguery. Democracy requires, at a minimum, a solid basis in human rights that the majority can’t overrule and an educated electorate. The former is always under debate, and the latter is a major problem for us right now.</p><p>

<b>How do we evaluate the success or failure of the ongoing experiment that is our political system?</b></p><p>

In terms of evaluating our system, again I think we have to look beyond democracy. Democracy is a tool for achieving good governance and its many benefits, not an end in itself. We need to ask first if our system is inclusive, equal, participatory, because democracy is founded on the idea that the more people actively involved in government, the better that government will be.</p><p>

If we don’t believe that any more than we should stop calling ourselves democratic and come up with something new, but so far those principles seem to be borne out (as far as we can tell, given that we haven’t really tried them completely) and democracy is the best system we’ve developed as yet.</p><p>

Then we need to look at whether the system is functioning on a basic level – are decisions being made, are programs being implemented and evaluated? Checking on the conditions faced by the most vulnerable (whether through poverty, disability, age, marginalization, or some other status) is a good start for evaluating both types of criteria.</p><p>

<b>How is technology changing politics and policy?</b></p><p>

While technology is changing our politics somewhat, I think the more intriguing question is why isn’t it changing our politics more?</p><p>

One answer is that our government has largely fallen behind on tech, and isn’t devoting enough time or attention to it, with cybersecurity as just the most basic example. But part of the reason for that is that technological disruption is threatening to those in power, and particularly to those who don’t like to see change of any kind.</p><p>

There are all sorts of interesting democratic experiments we could do with current technology. While we see some of them in the private sector, for example in the form of new apps to help people learn about candidates and issues or share experiences across the political divide, more fundamental changes are going to be hard to push through people who have spent their careers honing their political skills for a certain playing field, and who don’t want to see it change now.</p><p>

<b>Where do we go from here?</b></p><p>

There are a couple of answers, along the axes realistic &lt;-&gt; idealistic (I’m trying not to do depressing right now, realism is already there) and short-term &lt;-&gt; long-term.</p><p>

In the most immediate, I think we can look to the current expansion of civil society as a positive new avenue for deepening our democracy. Democracy is, fundamentally, about people being involved in politics, and that has been weakening for many decades, both from the top (voter suppression, lobbyists, etc.) and from the bottom (apathy, cynicism, etc.) in ways that interact.</p><p>

It would be lovely if, going forward, some of the energy and renewed interest got channeled into structural and systemic ways to increase and enrich participation. Some of that should be legal – so, real pushes on voter rights and enlarging the franchise (for example, to felons) – but some of it can be less formal, around norms instead of laws.</p><p>

For example, we’re seeing a lot of amazing engagement at congressional town halls, and there’s a risk there that politicians will start avoiding the town hall format. Making sure that it’s an expected norm for politicians to participate in unfiltered town halls throughout both campaigns and terms could become important. We also really need to find ways to expand civic knowledge, from a basic level of how our (partial) democracy works through media literacy.</p><p>

Longer term, I’d like to see more creativity and experimentation focused on improving our democracy. As I said above, we see some of that happening in the private sector and sometimes in local governments, both here and abroad, but at a large scale it’s going to be difficult to push through significant changes, because the system is designed to prevent them.</p><p>

There’s some merit in that—think about how difficult policy and policy evaluation is made when we change direction every four years—but also a lot of risk in missing chances to improve, or save, or democratic principles.</p><p>

<b>What is micro-democracy? How is the political future depicted in <i>Infomocracy</i> structured? Is it purely a thought experiment or is it a concept you want to see implemented?</b></p><p>

Micro-democracy (in <a href="https://arstechnica.com/tech-policy/2016/12/microdemocracy-is-a-high-tech-solution-to-americas-current-system/" target="_blank">my definition</a>; there are others) is a system of government that shrinks the population for the basic jurisdictional unit; in theory this lessens the risks of oppression by majority, since smaller groups are more likely to find common ground and majorities are likely to be less overwhelming. Note that it doesn’t solve the problem, although the overall system also favors relatively free immigration, which will also help.</p><p>

The micro-democracy in <i>Infomocracy</i> is based on units of roughly 100,000 people each. So imagine if those county-based electoral maps you see with scattered dots of blue and red were actually maps of two different countries with different laws, budgets, governments.</p><p>

In <i>Infomocracy</i>, however, these units have far more choice. There are some 2000 governments worldwide, offering different collections of policies and laws. So someone living in Boston could be a co-citizen, living under the same system of government, with people living in Oslo and in Dakar and Hue, while their neighbors a couple of blocks over in Boston might have an entirely different set of laws and leaders.</p><p>

This may sound farfetched, but in fact similar set-ups exist today, in places like Alaska and Gibraltar and Réunion, although those are determined by the history of colonialism rather than by choice. We can also look at urban areas or rural counties that comprise several municipal governments, in which driving over an invisible boundary gives you different traffic laws, school systems, and local taxes.</p><p>

My purpose was never to propose micro-democracy as the single best way to evolve democracy, although I do think it has a lot of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.eliotpeper.com/2019/08/malka-older-on-future-of-democracy.html">https://www.eliotpeper.com/2019/08/malka-older-on-future-of-democracy.html</a></em></p>]]>
            </description>
            <link>https://www.eliotpeper.com/2019/08/malka-older-on-future-of-democracy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011013</guid>
            <pubDate>Fri, 31 Jul 2020 17:23:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sending SMS Messages Through the International Space Station]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24011011">thread link</a>) | @NaughtRobot
<br/>
July 31, 2020 | https://www.kj7nzl.net/blog/sending-sms-messages-through-iss/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/sending-sms-messages-through-iss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <p>On Sunday July, 12 2020 at 06:00 UTC I sent myself three SMS messages through the International Space Station’s APRS digipeater. Here’s how I did it, but first a little background on my motivation for this project.</p>
<figure>
    <img src="https://www.kj7nzl.net/img/aprs/aprs-iss-sms-0001.webp" alt="Confirmation of SMS messages forwarded by ISS."> <figcaption>
            <p>Confirmation of SMS messages forwarded by ISS</p>
        </figcaption>
</figure>

<h2 id="why-even-bother">Why Even Bother?</h2>
<p>The ISS has carried an amateur radio payload since its early beginnings. Part of this payload includes a radio that serves as a digipeater for APRS. Hams within the footprint ISS as it orbits can send and receive data packets containing messages that can be used to make contact with each other. There exists a number of various stations transmitting during any given pass. Some of these stations are just automatic beacons transmitting ever few minutes and some are actually other hams trying to make contact through the ISS. It’s been my experience in my location within the United States that there have been mostly automated stations clogging up the airwaves with there stupid beacon transmissions. As a result trying to make a contact with another human through the ISS has been fruitless. As a result I wanted to make use of the ISS’s digipeater as it traversed through space over my home. One day I discovered you could send SMS messages using APRS to the SMSGTE station. This station was attached to the internet and acted as a gateway for SMS messages onto the cellular networks. Curious I tried sending a message to myself with terrestrial stations receiving my transmission and routing my data packets onto the SMS gateway. Honestly, this was intriguing for only a minute or two since terrestrial stations are relatively common and the process was no more difficult than sending a SMS using my cell phone. One night while trying to establish a contact through the ISS’s digipeater with another human (Seriously, is there anyone in the Mountain West area besides me even attempting ISS contacts?) I had the brilliant idea of sending myself a SMS message through the ISS. It’s hard enough actually having your beacon APRS packets heard by the ISS, so I figured why not up the difficultly level by trying to send myself a message. Besides, I have to do something on those solitary nights when the ISS is flying over my house.</p>
<h2 id="aprs-sms-gateway">APRS SMS Gateway</h2>
<figure>
    <img src="https://www.kj7nzl.net/img/aprs/aprs-sms-flow.svg" alt="SMS message flow between ISS and mobile phone."> <figcaption>
            <p>SMS message flow between ISS and mobile phone.</p>
        </figcaption>
</figure>

<p>The glue that hold this whole experiment together are APRS Satellite I-Gates and the SMSGTE APRS cellular gateway. Without these two an APRS packet could not be relayed by the ISS and sent to my phone. APRS Satellite I-Gates listen on the 145.825 Mhz frequency for APRS packets that are relayed by the ISS as it flys over. These packets are then routed through the APRS network to SMSGTE gateway, onto a SMS cellular gateway, and finally through the cellular network to my phone. To use the SMSGTE gateway, it’s relatively straightforward. All you need to do is transmit a message to SMSGTE in the following format: <code> @&lt;number&gt; &lt;message&gt;</code></p>
<div><pre><code data-lang="text">To: SMSGTE
@1235551234 Hello from space! </code></pre></div>
<p>When the message is delivered, it will be display on the mobile phone like so:</p>
<div><pre><code data-lang="text">@KJ7NZL-6 Hello from space!</code></pre></div>
<p>This is all you really require do to start using the SMSGTE gateway, but if you want to mask a person’s phone number within your APRS packets you can achieve this by using an alias. You can set these up by registering as user on <a href="https://smsgte.org/">smsgte.org</a>.</p>
<h2 id="sending-a-sms-message-through-the-iss">Sending A SMS Message Through the ISS</h2>
<p>The key to sending a SMS message through the ISS is preparation. For me a Typical ISS pass for me is about six minutes and thirty seconds long. In that time I have to locate the ISS, queue up my message to the SMSGTE gateway, and transmit my message to the ISS. I don’t have a fancy setup with an azimuth and elevation rotor and circular polarized beam antennas; I’m merely working with my trusty Yaesu FT3D and handheld Arrow II antenna. As a result it takes a minute or two find the ISS and you can easily loose track of it while navigating through the menus on the FT3D with one hand. To help shortcut some of the process I actually construct the message on the FT3D prior to the upcoming ISS pass and transmit on 145.825 MHz just before the ISS appears on the horizon. Since this message isn’t received by anything an acknowledgement isn’t sent to the FT3D. This adds the message to a queue of unsent messages the FT3D will try a resend after a minute or two. I’m able to manually try and resend these messages while they are in the queue. This allows me to focus on tracking the ISS while barely needing to check the radio’s screen, only needing to for a few seconds at a time to make sure I click on the message transmit button. Once the ISS receives my APRS message a confirmation message from RS0ISS will display on my screen and I’ll receive the SMS message on my phone a second or two later. This sounds relatively straightforward, but in practice it took me a few weeks of trying to get the process down.</p>
<figure>
    <img src="https://www.kj7nzl.net/img/satellites/amsat-fm-0001.webp" alt="KJ7NZL using the Arrow II antenna."> <figcaption>
            <p>KJ7NZL using the Arrow II antenna.</p>
        </figcaption>
</figure>

<h2 id="next-steps">Next Steps</h2>
<p>Now that I’ve accomplished my goal of sending a SMS through the International Space Station’s APRS digipeater, I need to try something new. When I sent my first messages I used five watts of power. The lowest power setting on my FT3D is 300 milliwatts, and I’m curious to know if I can actually reach the ISS with that little amount of power. I believe it’s possible, but I’m going to need to make sure I’m aiming my antenna directly as the thing as it passes overhead. The next goal I have is to actually reply to my SMS message once it’s received. This may be more difficult if not impossible. It’s possible to reply to an SMS message and receive the response as an APRS packet from your radio. However, I’m unsure what digi path the SMSGTE gateway uses, but I suspect it’s not setup to relay packets to the ISS. Even if it were, this may require me to be under the same ISS footprint as the SMSGTE gateway. I’ll have to reach out to the owner of the gateway to find out more information.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/sending-sms-messages-through-iss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011011</guid>
            <pubDate>Fri, 31 Jul 2020 17:23:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Parent’s Internet – The Misinformation Problem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24010872">thread link</a>) | @lanecwagner
<br/>
July 31, 2020 | https://qvault.io/2020/07/31/your-parents-internet-solving-misinformation/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/31/your-parents-internet-solving-misinformation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>The age of information is not what we all hoped it would be. We successfully digitized the majority of human knowledge, and we even made it freely accessible to most. Now the problem is different, we have <em>too much</em> information. Answers to most questions can be found in thousands of distinct places online, and the new problem is <em>“whos information can we trust?”</em></p>



<h2>What Platforms Think They Should Do About Fake News</h2>



<p>Twitter and Facebook have recently been under scrutiny for their censorship of coronavirus related misinformation. For example, a <a aria-label="undefined (opens in a new tab)" href="https://www.bbc.com/news/53559938" target="_blank" rel="noreferrer noopener">video claiming Hydroxychloroquine is a Corona cure</a> recently went viral on Facebook, and the video keeps getting taken down. The video contains some wild assertions, made by Stella Immanuel, who also believes that gynecological problems are the result of <a aria-label="undefined (opens in a new tab)" href="https://www.youtube.com/watch?v=9yCXCP3evAg" target="_blank" rel="noreferrer noopener">spiritual relationships</a>.</p>



<p>By removing content they believe to be dubious, Twitter and Facebook have made themselves arbiters of truth. Anecdotally, all the posts I’ve seen them remove HAVE contained misinformation, but the fact remains… these platforms have become self-appointed authorities on the veracity of our information.</p>



<p><strong>This is a problem.</strong></p>



<h2>So We Can’t Censor?</h2>



<p>We certainly can, and we certainly should in some cases. Let’s get some obvious ones out of the way:</p>



<ul><li>Child Pornography</li><li>Death Threats</li><li>Doxing</li></ul>



<p>There may be some other clear examples where censoring is unquestionably the right choice, though I doubt there are many. Let’s look at some more controversial examples:</p>



<ul><li>Hate Speech</li><li>Misinformation</li></ul>



<p>I would posit that here the answer is contingent on <em>who </em>is doing the censoring. While hate speech and misinformation are disgusting, I don’t want a government deciding <em>what </em>is hate speech, or deciding <em>what </em>is truth.</p>



<div><figure><img src="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg" alt="war is peace 1984 orwell" srcset="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg 300w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace-768x576.jpg 768w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace.jpg 877w" sizes="(max-width: 300px) 100vw, 300px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg 300w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace-768x576.jpg 768w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace.jpg 877w" data-src="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>George Orwell, 1984</figcaption></figure></div>



<p>That said, I certainly want an online system where hate speech and misinformation are effectively filtered out of the conversation. Ideally, every online participant is a virtuous, educated, and concerned conversationalist. If this were the case, posts of an undesirable nature would effectively be ignored due to not receiving the likes, shares, upvotes, and comments they need to spread.</p>



<p>In reality, we can’t have such a pacifistic approach. We need to <a href="https://www.lesswrong.com/posts/tscc3e5eujrsEeFN4/well-kept-gardens-die-by-pacifism" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">protect our gardens</a>.</p>



<h2>Misinformation – What Should Platforms Do?</h2>



<p>It starts here. All online platforms are responsible for the tools they provide for moderation, if not for the moderation itself.</p>



<p>Platforms <strong>should</strong>:</p>



<ul><li>Remove dangerous content such as doxing, threats, child trafficking, etc</li><li>Provide tools for users to mark content as harmful or misleading</li><li>Mark content as dubious</li></ul>



<p>Platforms <strong>should not:</strong></p>



<ul><li><em>Remove </em>misleading content</li></ul>



<p>By removing misleading content, platforms run the risk of fueling an <a aria-label="undefined (opens in a new tab)" href="https://rationalwiki.org/wiki/Argumentum_ad_martyrdom" target="_blank" rel="noreferrer noopener">argumentum ad martyrdom</a> mentality. Removing information can have an adverse effect, causing people to suspect we have a nefarious reason for removing it.</p>



<blockquote><p>But the fact that some geniuses were laughed at does not imply that all who are laughed at are geniuses. They laughed at&nbsp;Columbus, they laughed at Fulton, they laughed at the Wright brothers. But they also laughed at Bozo the Clown.</p><cite>– Carl Sagan, Probably</cite></blockquote>



<h2>What Should Users Do About Misinformation and Fake News?</h2>



<p>Users <strong>should</strong>:</p>



<ul><li>Read entire articles before liking, sharing, or commenting</li><li>Deploy extra skepticism to information with a clear political or monetary agenda</li><li>Be self-aware about their preconceived notions and confirmation biases</li><li>Look for the primary source of information</li><li>Ensure information is up-to-date</li></ul>



<p>Users <strong>should not:</strong></p>



<ul><li>Reward clickbait titles with engagement</li><li>Exclusively follow, subscribe, or search for content that aligns with their current beliefs</li><li>Assume your position is valid because people are trying to remove your content</li><li>Trust articles and posts coming from sites that appear <a aria-label="undefined (opens in a new tab)" href="https://www.sitelock.com/blog/is-this-website-safe/" target="_blank" rel="noreferrer noopener nofollow">unsafe</a></li></ul>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/31/your-parents-internet-solving-misinformation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010872</guid>
            <pubDate>Fri, 31 Jul 2020 17:14:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Projecting Bitcoin's Price with Popularity (Google Trends)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24010763">thread link</a>) | @webcerfer2020
<br/>
July 31, 2020 | https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong><span>A Tale of Two Charts</span></strong></p>



<p>The chart below shows the monthly average <a href="https://www.coindesk.com/price/bitcoin">price of bitcoin</a> since October 2013.</p>



<figure><img data-attachment-id="1238" data-permalink="https://blogofjake.com/image-26/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png" data-orig-size="782,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-26" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" src="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-26.png 782w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=768 768w" sizes="(max-width: 782px) 100vw, 782px"></figure>



<p>This second chart shows the <a href="https://trends.google.com/trends/explore?date=all&amp;q=bitcoin">Google Trends Score</a> by month for the search term “bitcoin”, also since October 2013.</p>



<figure><img data-attachment-id="1239" data-permalink="https://blogofjake.com/image-27/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-27" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-27.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>When I first saw the second chart, I thought it looked remarkably similar to the first. Sure enough, it does. Below are the two charts together. The darker line shows the price according to the left-side axis and the lighter line shows the Google Trends Score according to the right-side axis.</p>



<figure><img data-attachment-id="1240" data-permalink="https://blogofjake.com/image-28/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-28" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-28.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>It turns out that bitcoin’s price and its Google Trends Score are quite correlated.</p>



<p>Specifically, they have had a 72% positive correlation since October 2013. This compares favorably to bitcoin’s <a href="https://cointelegraph.com/news/bitcoins-correlation-with-gold-is-weakening-says-new-kraken-report">26% correlation with the stock market and 24% correlation with gold</a> over the last year.</p>



<p>I should note that the correlation between bitcoin’s price and its Google Trends Score was much stronger up until both price and score peaked in December 2017 (98%) than it has been since (59%).</p>



<p>Nonetheless, the purpose of this analysis is not to argue about the level of correlation nor to assert causation one way or another (though it seems logical that the price and popularity feed off of each other). Rather, the purpose of this analysis is to make a speculative projection regarding what bitcoin’s price could be if and when its popularity (as measured by its Google Trends Score) returns to and surpasses its previous all-time high.</p>



<p>In order to make this projection, we first must consider the historical ratio between bitcoin’s average price and its Google Trends Score on a monthly basis. Let us refer to this as the <em><strong>price:score ratio</strong></em><strong> </strong>for short.</p>



<p><strong><span>Bitcoin’s Price:Score Ratio</span></strong></p>



<p>The chart below shows how bitcoin’s price:score ratio has increased over the last several years.</p>



<figure><img data-attachment-id="1241" data-permalink="https://blogofjake.com/image-29/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-29" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-29.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>For a ratio that has been relatively volatile historically, it has remained unusually consistent for the last two months (June &amp; July) at 729, just 4% short of its all-time high of 758 in November 2019.</p>



<p>Bitcoin’s price:score ratio has been above 645 for 9 of the last 12 months after having only reached such a level once before, and barely (646 in October 2018).</p>



<p>The 3 months in the last year during which the ratio was lower than 645 can be fairly easily explained. They took place this past March, April, and May as hype grew in anticipation of bitcoin’s once every four years halving event on May 11, 2020. Additionally, people perhaps were searching more than usual for information about alternative assets (including bitcoin) when the stock market crashed ~30% in the early days of the lockdown resulting from the pandemic. Those two factors together seem sufficient to explain the uptick in bitcoin’s Google Trends Score over that period. On the other side of the price:score ratio, bitcoin’s price fell along with the market, and so with the price going down and the score going up, the decreased price:score ratio over those few months makes sense.</p>



<p>Since the stock market substantially recovered and the halving event came and went without materially moving bitcoin’s price, the Google Trends Score has returned to the pre-pandemic, pre-halving-hype range. For the last two months (June &amp; July), bitcoin’s monthly Google Trends Score has stayed steady at 13, which is equal to its average from April 2018 (after the peak) through February 2020 (before the halving hype and market crash).</p>



<p>For some additional context, it should be noted that bitcoin’s Google Trends Score has only been equal to or greater than 21 in 7 months since bitcoin’s inception and they all took place consecutively surrounding bitcoin’s last major surge from September 2017 through March 2018 (with scores chronologically of 21, 22, 44, 100, 55, 39, and 23).</p>



<p><strong><span>Flying Under The Radar</span></strong></p>



<p>Sufficed to say, bitcoin’s average score of 13 since the last surge, excluding the three aforementioned months from earlier this year (14 if we include them), shows objectively that bitcoin is flying under the radar (in terms of its popularity as a search term at least). Of course, it may not seem this way to people who follow crypto closely and daily but the algorithmic and mass-data collecting Google Trends Score should be trusted over any single person’s speculative and subjective observation about the current level of hype and attention.</p>



<p>If you, like me, believe that bitcoin is and has been flying under the radar for more than two years now, the natural question to ask is this. What do we expect to happen when that is no longer the case? In other words, what happens to bitcoin’s price if and when it reaches the pinnacle of its next hype cycle? How high might bitcoin fly the next time we see a situation similar to that of December 2017?</p>



<p><strong><span>Projecting Bitcoin’s Price</span></strong></p>



<p>I believe a reasonable response to this question can be made by applying bitcoin’s average price:score ratio over the last twelve months (643) to a Google Trends Score of 100 to estimate what bitcoin’s price would be if the price:score ratio stays about constant and bitcoin’s popularity in terms of search returns to its all-time high. The price implied by this projection is about $65,000 as is demonstrated by the maximum value in the top right corner of the chart below. Basically, if one believes that bitcoin will at least at some point return to the level of popularity it attained in December 2017, this methodology would lead that person to expect bitcoin to attain a price of at least $60,000 at that time.</p>



<figure><img data-attachment-id="1242" data-permalink="https://blogofjake.com/image-30/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png" data-orig-size="783,308" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-30" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-30.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>This estimate can be made less conservative in two ways. The first is to assume that the price:score ratio will continue to increase as it has all along (6% month-over-month), rather than calculating the price using the LTM average of the ratio. The second is to assume that bitcoin’s popularity as a search term will well surpass its previous all-time high set in December 2017 just as that all-time was more than twice as great as any high before it and more than 8 times greater than the all-time high before May 2017 (which was set in December 2013, perhaps not coincidentally exactly 4 years or one halving period prior to the latest all-time high). I hesitate to call either of these two less conservative assumptions aggressive because they are not only reasonable but actually probable if one is to simply assume that the historical trends will continue in terms of the score and the ratio.</p>



<p>As such, I will close by presenting a chart which one can use to approximate the price implied by their own inputs for the Google Trends Score and the price:score ratio. In this chart, I show the ratio for the last 12 months, 2 years, 3 years, and so on, and use the average year-over-year growth rate between those figures (16%) to project the next twelve months (“NTM”), next two years (“N2Y”), and next three years (“N3Y”) ratios.</p>



<p>The highest price projected on the chart is right around $300,000 based on a Google Trends Score of 3 times the previous all-time high (300) and a projected N3Y price:score ratio of 996 (the LTM average of 643 increased 16% 3 times for 3 years). Of course, this maximum price projection is limited only arbitrarily by the maximums I have decided to present on this chart for both the score and the ratio.</p>



<figure><img data-attachment-id="1243" data-permalink="https://blogofjake.com/image-31/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-31" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-31.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p><strong><span>To Be Continued…</span></strong></p>



<p>Many people have employed many methodologies in attempting to accurately project bitcoin’s price. For example, <a href="https://medium.com/@100trillionUSD">PlanB</a>‘s stock to flow ratio looks at scarcity to make one of the more convincing price projections I’ve seen. My price:score ratio looks at popularity in endeavoring to do the same. This analysis was not intended to be totally comprehensive. My intention was merely to introduce this methodology for others to critique. As such, my hope is that this becomes widely enough read so that I may receive ample critical feedback for further consideration and refinement of the methodology.</p>



<p><em>As always, I welcome all outreach to jake@blogofjake.com and any comments on Twitter <a href="https://twitter.com/blogofjake">@blogofjake</a></em></p>
	</div></div>]]>
            </description>
            <link>https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010763</guid>
            <pubDate>Fri, 31 Jul 2020 17:05:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cracking the Developer Code: Flow]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24010663">thread link</a>) | @discodave
<br/>
July 31, 2020 | https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html | <a href="https://web.archive.org/web/*/https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>I’ve been thinking a lot lately about what motivates software developers. If
you believe that <a href="https://thenewkingmakers.com/">Developers are the new
Kingmakers</a>, then this is an important subject!</p>
<p>It's certainly true that developers can be opinionated, but I’m not sure I
agree with statements like the following;</p>
<blockquote>
<p>“[a developer] typically just wants to use the best
tool for the job”<sup>1</sup>.</p>
</blockquote>
<p>Throughout my career I’ve seen it over and over that developers want to
reinvent the wheel instead of talking to another team, or using a pre-existing
solution. Sometimes it seems like the primary goal of developers is to find
excuses to write a lot of code. There are
<a href="https://en.wikipedia.org/wiki/Boondoggle">so</a>
<a href="https://en.wikipedia.org/wiki/Not_invented_here">many</a>
<a href="https://kubernetes.io/">examples</a> of developers picking things that let them
muck around with code, instead of making the best choice for the business.</p>
<p>Code, rather than results has this mythical status in the industry. Candidates
for highly-paid developer jobs, like the one I used to hold, are tested on
their coding ability first, and other skills second. These skills, like
communication, and listening are often derisively referred to as soft skills.
I've seen interview debriefs where interviewers act like being able to code
trumps all other skills.  The reality is that those "soft" skills are the most
important skills, and they only get more important as you progress in your
career. The technical leaders that I admire the most, like <a href="https://www.youtube.com/watch?v=BOYdKht1YwE">James
Hamilton</a>, or <a href="https://www.youtube.com/watch?v=Pqc6X3sj6q8">Heidi
Howard</a> are great communicators
above all. Those are the people who change industries, and upend the
<a href="https://fortune.com/2015/10/21/hp-public-cloud/">status</a>
<a href="https://www.forbes.com/sites/benkepes/2013/10/29/ibm-capitulates-amazon-gains-cia-contract/#60d44d204bbf">quo</a>.</p>
<p>So why is it code and coding that holds this mythical status? Why are all the
hopeful university and bootcamp graduates studying <a href="http://www.crackingthecodinginterview.com/">Cracking the Coding
Interview</a> in the hopes of landing
a six-figure salary at a tech company?</p>
<p>Two things finally made it click for me. Firstly, I listened to a podcast
about achieving <a href="https://anchor.fm/curiousclimberpodcast/episodes/Cameron-Norsworthy---The-Path-to-Flow-eboqkc">flow state, and how it applies to
climbing</a>.
Secondly, I finally watched the 1995 cult-classic Hackers. In that movie, the
main character Dade is basically addicted to his computer. He stays up all
night, much to his mother’s distress.</p>
<blockquote>
<p>In positive psychology, a flow state, also known colloquially as being in the
zone, is the mental state in which a person performing an activity is fully
immersed in a feeling of energized focus, full involvement, and enjoyment in
the process of the activity. In essence, flow is characterized by the complete
absorption in what one does, and a resulting transformation in one's sense of
time. (<a href="https://en.wikipedia.org/wiki/Flow_(psychology)">Wikipedia</a>)</p>
</blockquote>
<p><img alt="Hacking movie collage" src="https://blog.drgriffin.com.au/hacking-collage-v2.jpeg">
A selection of scenes involving coding, or 'hacking', from War Games, Hackers,
The Matrix , Swordfish , The Girl With The Dragon Tattoo, and Halt and Catch
Fire.</p>
<p>People like me love to deride ‘hacking’ scenes in hollywood movies as being
unrealistic.  But after watching Hackers I realised... I have behaved like
Dade, many times; and not just recently during this
<a href="https://www.goodreads.com/quotes/6344-time-is-an-illusion-lunchtime-doubly-so">pandemic</a>.</p>
<p><img alt="Me playing my GameBoy" src="https://blog.drgriffin.com.au/gameboy.jpeg">
That's me engrossed in a GameBoy sometime in the 90s.</p>
<p>When I think about it, that search for flow has had a huge impact on my life
and career. It was while I had some spare time<sup>2</sup> as a ski-bum that I
did Zed Shaw's <a href="https://shop.learncodethehardway.org/">Learn Python the Hard
Way</a>.  That, along with my Electrical
Engineering degree is what lead me down the path towards Amazon, and Seattle.
You could argue that I spent two (Australian) summers as a ski-bum, and learned
a new programming language in search of that flow state.  Some other examples
of things I've done over the years perhaps in search of flow are sailing,
hiking, climbing, and weightlifting. In that context, those hollywood scenes of
caffeinated hackers staying up all night don't seem so far off the mark.</p>
<p>This got me thinking about a stereotypical software developer, what were they
like as a child? Did they love LEGO? Did they play computer games? Did they
read lots of books? Are they into comic books? Did they excel at math? The list
goes on.</p>
<p><img alt="My first lego set?" src="https://blog.drgriffin.com.au/bob-lego-and-me.jpeg">
How many engineers began their journey with a set of LEGO?</p>
<p>It turns out that the people who defined and researched flow, like Mihaly
Csikszentmihályi, and Jeanne Nakamura outlined some specific conditions that
need to be met to achieve the flow state, again from
<a href="https://en.wikipedia.org/wiki/Flow_(psychology)">Wikipedia</a>: </p>
<blockquote>
<ol>
<li>
<p>One must be involved in an activity with a clear set of goals and
   progress.  This adds direction and structure to the task. </p>
</li>
<li>
<p>The task at hand must have clear and immediate feedback. This helps the
   person negotiate any changing demands and allows them to adjust their
   performance to maintain the flow state.</p>
</li>
<li>
<p>One must have a good balance between the perceived challenges of the task
   at hand and their own perceived skills. One must have confidence in one's
   ability to complete the task at hand.</p>
</li>
</ol>
</blockquote>
<p>These principles have been used pretty heavily by games, and the techniques of
game designers are now common in <a href="https://en.wikipedia.org/wiki/Gamification">everyday
life</a>, sometimes with <a href="https://www.washingtonpost.com/news/monkey-cage/wp/2018/08/06/its-no-accident-that-facebook-is-so-addictive/">questionable
outcomes</a>.
But bringing it back to developers, many things you can see in the software
industry look like attempts to find flow.</p>
<p>Firstly, a clear set of goals and progress?  Hello <em>tasks</em>. From Agile,
to Scrum, to Kanban, most software development methodologies are built around
the <em>task</em>.  <em>Tasks</em> are created precisely to set goals and measure progress.</p>
<p>Secondly, feedback. One of the key things that attracted me to software, over
the other branches of electrical engineering was the immediate, almost
addictive feedback loops you can get while coding.</p>
<p>And thirdly, endless ink has been spilled over the years about aligning
challenges with skills. Every discussion you’ve ever seen about organizational
structure has some element of trying to align the challenges of the
organization with the skills of it's people. All the work I've done around
mentoring and growth, from when I was a 14 year old Patrol Leader in Scouts, to
Amazon, was about finding the right level of challenge for people.</p>
<h2>Maybe they weren't crazy after all</h2>
<p>So now when I think back to my first job, the way I ended up owning a bespoke
"distributed lock service" built on top of NFS<sup>3</sup> makes much more
sense to me. It makes sense why my predecessor chose to build this instead of
using some simpler, or off-the-shelf solution. When Csikszentmihályi describes
flow state as the “optimal experience”, he's giving us a clue. People probably
aren’t optimizing for making money, or increased feature velocity, or more
reliable software, or better customer experiences, and your employees are
especially not optimizing for shareholder value. People are optimizing for
their <em>own</em> happiness, which often involves finding ways to reach a flow state.
Of course, often we pop out of that state to align our work with the customer,
with making money, or other external factors. Just like whales, we must come up
for air. But people certainly enjoy it more when they get to spend as much time
as possible approaching flow.</p>
<p>Hopefully by now you’re convinced that the flow state, or optimal experience is
a real thing, and that many developers are searching for this state through
coding. Being in a state of flow has the potential to make people both happier,
and more productive. If you’re an employer, it can be a win-win.</p>


<p>But I'm not (currently) an employer. Although I am building some things aimed
at developers.</p>
<h2>Can we design for flow?</h2>
<p>I think the answer is yes. A slightly bolder claim would be that developers
only truly <em>love</em> products that help them reach a state of flow.</p>
<p>There are two extremes from which developers will critizise most products. Some
lucky products manage to get both criticisms at the same time.</p>
<p>The first is if the product is incomplete, too low-level, or difficult to use.
This often results in large amounts of <a href="https://en.wiktionary.org/wiki/Talk:yak_shaving">yak
shaving</a> to get anything
useful done. You can't get into a flow state if you're staring into the
abyss of errors, or constantly having to
<a href="https://en.wikipedia.org/wiki/RTFM">RTFM</a>. Here are some examples of things
that fit into this category, from my personal experience:</p>
<ul>
<li>Configuration languages like CloudFormation, or TerraForm.</li>
<li>Compiling from source (think Linux WiFi and graphics drivers<sup>4</sup>).</li>
<li>Deciding which of the 200+ AWS services are right for my use case.</li>
<li>Programming in assembly (Motorola HC11) at university many years ago.</li>
<li>A certain internal Amazon <a href="https://aws.amazon.com/cdk/">tool</a>, that I can't
  name for fear of breaking my NDA (and also causing PTSD in current and former
  Amazon engineers reading this).</li>
</ul>
<p>The other extreme from which developers will critizise products is being too
high-level, restrictive, or not having enough options. You can't get into that
flow state if you don't get to engage your brain! As an example, the Wikipedia
page for <a href="https://en.wikipedia.org/wiki/Software_framework#Rationale">software
frameworks</a> has
some hilarious "<em>[citation needed]</em>" back-and-forth about the pros-and cons of
frameworks. The interesting thing is that <em>both sides</em> of this debate want to
write lots of code and be productive. They're just looking at it differently.
The <a href="https://www.youtube.com/watch?v=Gzj723LkRJY">OG framework demo</a> was all
about how quickly you could start writing code. Meanwhile opponents of
frameworks say that they spend more time learning how to use the framework than
coding. </p>
<p>Another area where I wonder if the products are too high-level, or restrictive
is the so-called <em>NoCode</em> space.  There are a bevy of well-funded startups,
like AirTable, ReTool, and Webflow that claim to eliminate the need for coding
to build websites. The thing is, I have tried a couple of them, and the UIs
aren't as intuitive as you might hope. I also can't imagine myself achieving a
state of flow with them. I've spent many, many hours in my life writing things
like this blog post, or programming in Java and Python. To me, graphical UIs
don't get you that feeling of <em>building</em> that you get from typing at a command
line, or even typing up a document.</p>
<p>I can imagine people reaching a flow state if they're really proficient users
of, say, Photoshop. But I'm not sure that these NoCode tools encourage the high
level of mastery that a professional photographer, or editor might have. As
such, while they're interesting tools, I struggle to see them catching on in a
way that justifies the kind of valuations that VCs are looking for.  But it's
still early in this space, the jury is still out.  Maybe I'll …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html">https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html</a></em></p>]]>
            </description>
            <link>https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010663</guid>
            <pubDate>Fri, 31 Jul 2020 16:56:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Educational Colonialism]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24010601">thread link</a>) | @mjirv
<br/>
July 31, 2020 | https://americancompass.org/our-educational-colonialism/ | <a href="https://web.archive.org/web/*/https://americancompass.org/our-educational-colonialism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img data-src="https://americancompass.org/wp-content/uploads/2020/07/DSC_1111-scaled.jpg" src="https://americancompass.org/wp-content/uploads/2020/07/DSC_1111-scaled.jpg"></p><p>I get criticized for not talking about policy enough, so here we go: No Child Left Behind is a disaster, the spearhead of our misguided attempt to funnel everyone to college.</p><p>It has hurt the working class, because it devalues their worldview, leaving them feeling humiliated and labeled dumb hicks or lazy hoodlums. It has hurt the “aspirational professionals” by producing too many college graduates, leaving them to compete over a few high-paying high-status jobs in a few expensive cities. All while charging an arm and a leg that piles debt on them.</p><p>It has hurt everyone, with the exception of a few tenured literary critics who get increased status, and the CEOs of conglomerates, who get more resumes to choose from.</p><p><span id="more-1765"></span>Federalization is about imposing a dominant ideology and worldview, and in the case of our educational policy it is about imposing “front rowness”— the idea that everyone should aspire to becoming a tenured professor or a widget engaged in a resume arms race with the rest of the world.</p><p>It is a system built by intellectual elites who want everyone to be like them, and humiliates everyone else. It is a system that says anything that can’t be learned in an advanced placement class isn’t that important, like being a good member of the community, or family, or church. Those things are impediments to success. Staying home to care for your parents rather than rushing off to Princeton is an unnecessary speed bump on your way to having your best career!</p><p>Those who fundamentally don’t buy into this ideology, which is most of the working class, end up sitting in the back row of whatever school, distracted and frustrated. Throwing spitballs at whoever because they don’t take easily to set theory, or Algebra, or Henry James or Nathaniel Hawthorne. Because they don’t enjoy memorizing whatever they have to memorize for the next standardized test.</p><p>They are kids who just want to learn a skill to get a job. Because they are really good with their hands and good with tinkering, always have been. Or they are really good with animals, or good at getting stuff to grow, or they have ‘always been good at caring for people, noticing when someone is a little off and need to be checked on. Like, I always been good that way, especially with my Grandma, who shines up when she sees me come to play checkers. So maybe I will go into nursing you know. But I keep getting D’s in math and history, but if I can get over that hurdle, I sure would love to be a nurse.’</p><p>What we need is an educational system that values these kids’ particular world view, their particular skill set, their particular interests, and encourages and trains them in it. The back row kids who are not great at test taking and who don’t really want to go to college. So they can stay close to their parents, grandparents, uncles, aunts, and cousins, and eventually make a decent enough wage to buy a Tundra, a home, start a family, go to church, and eventually host the weekly backyard get togethers their cousins, aunts, uncles, nieces, friends come to. All without being sneered at as a dumb, uncurious, closed-minded provincial hick or hoodlum, because Shakespeare ain’t their thing.</p><p>Right now they are sneered at, directly and indirectly. The whole system is constantly probing, measuring, and gauging them. Constantly making them jump over one standardized hurdle after another, and sneering when they fall. So when they finally put it all behind them (thank god!), if they bother to focus on politics at all, they aren’t going to embrace the same group of people pushing the same policies that made them take test after test after test, while telling them their C’s and D’s were because they needed more self discipline, more curiosity, more openness, and more interest in the scientific method. You simple minded kid, vote for me!</p><p>Ahead of them, at the front of the classroom, are the clever curious kids who love running off to the library to read whatever and memorize whatever else. For twelve years they are in heaven because we have built a system for them, that embraces them, encourages them, and then whooshes them off to college, and then more college, and then even more college! But when they eventually emerge, maybe after graduating from 19th grade, they discover that although they were the best debater in Portsmouth, Ohio, and at Kenyon College, and one of the better thinkers in grad school, they are only the 75th best debater vying for that one job in Manhattan or that one tenure-track position at Columbia, and the poorest of the 200 people vying for that third-floor walk up in Williamsburg.</p><p>So the dream that everyone from their Head Start teacher to their high school guidance counselor, to their literary or intellectual hero on YouTube urged them to follow, of running off to see the world while making a difference, isn’t going so well, and now they are deep in debt from the last masters program that was supposed to make the difference and solve all of this.</p><p>Rightfully frustrated, they are now doing what they have been trained to do all their life, which is embracing politics and arguing, loudly and forcefully, to change the world. Which mostly means tinkering with the system that produced them, rather than tearing it all down. Because that is what they know.</p><p>So they focus their energies into making the system less painful, to them and their university friends. Like getting rid of college debt, or building more affordable apartments in Williamsburg, or providing more affordable public transportation because they take the damn subway every day and it is fucking crowded.</p><p>Some of them recognize that maybe we should throw fewer resources at education, maybe we should funnel fewer people into Philosophy PhD’s, and fewer young professionals into Williamsburg. Certainly their working class Brooklyn neighbors whose rent is skyrocketing agree with that.</p><p>These aspirational professionals running from one adjunct gig to the next have my complete sympathy, regardless of the policies they want changed, as do their back row counterparts running from one fast food gig to the next. Both have been chewed up and spit out by a system that chews up and spits out a lot of people. Just in different ways.</p><p><img src="https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-300x200.jpg" alt="" width="822" height="548" srcset="https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-300x200.jpg 300w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-1024x683.jpg 1024w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-768x513.jpg 768w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-1536x1025.jpg 1536w" sizes="(max-width: 822px) 100vw, 822px"></p><p>Yet it is the kids sitting in middle row I have the deepest sympathy for because they are the most harmed, and the ones you hear the least about. They are mostly working class kids who don’t really fit into the back row because they are very disciplined, eager, and want do what they are told, and especially want to do the right thing. Which now means going off to college to better themselves, so they go off to college to better themselves, regardless of the cost.</p><p>They buy into our faux educational meritocracy the most, swallowing it hook, line, and sinker. They buy the dream peddled by every successful person they have ever run across or heard, from Obama down to the middle school guidance counselor: Education is the pathway to a successful and meaningful life.</p><p>So they work super hard to get A-’s and B+’s in their classes and 80’s on standardized tests, and then take the next step and go off to the the best college available.</p><p>But they don’t really fit into the front row either, because they don’t know anybody who has ever been to college. Not their parents, or grandparents, or uncles or aunts. Not even a cousin. But all of those relatives are encouraging, even giddy about the idea. They want the best for their child, so they help them apply, to the degree they can help. And when the acceptance letter comes from that far away college with ivy covered buildings (oh my god, real ivy, just like in the movies!), they are so happy they throw a party, complete with mylar balloons, and post the picture on Facebook or Instagram.</p><p>They are a little shocked when they see that the cost is like 40K a year, which is a super lot of money, more than dad makes, but mom makes some money too, and they will figure it out, because their wonderful child is going to have the American Dream.</p><p>So they apply for loans and eight years later that child is a young adult with 100K in debt working in a government bureaucracy five hundred miles away and missing the weekly family backyard BBQs .</p><p>Or maybe it didn’t work, and they are back home in the job they would have gotten straight out of high school, but now four years behind in seniority and 20K in debt.</p><p><img src="https://americancompass.org/wp-content/uploads/2020/07/DSC_1200-300x200.jpg" alt="" width="838" height="558" srcset="https://americancompass.org/wp-content/uploads/2020/07/DSC_1200-300x200.jpg 300w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1200-1024x683.jpg 1024w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1200-1536x1025.jpg 1536w" sizes="(max-width: 838px) 100vw, 838px"></p><p>Education is wonderful, so is bettering yourself by getting as much of it as possible. But done on your terms and because you want it for your reasons. Not because you, your community, and everyone else you know, is competing with the Chinese, or the Germans, or the Indians. So you have to take countless standardized tests so you can win a golden ticket to ship off to Princeton and hang with others who are good at taking standardized tests, to then be taught more stuff, to then go to grad school to learn even more stuff, so you might, if you are lucky, get to go to San Francisco and live in an a small room hundreds of miles from your family to start in a firm trading bonds, or helping Google sue someone, or running from teaching one introductory writing course at one school to another introductory oratory course at another school, or maybe so you can write papers for a non-profit funded by a billionaire arguing that we need more education. That isn’t good.</p><p>What we have now is a top-down educational system that intellectually strip mines America and humiliates everyone. What we need is a democratic educational system that provides pathways to dignified lives for everyone. That provides Shakespeare and differential topology to those who see the beauty of each, but also provides skills to those who would rather focus on things like music, mechanics, nursing, parenting, farming, or whatever.</p><p>We need educational freedom, not educational colonialism.</p> <p><a href="https://americancompass.org/the-commons/">Return to the Commons</a></p></div></div>]]>
            </description>
            <link>https://americancompass.org/our-educational-colonialism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010601</guid>
            <pubDate>Fri, 31 Jul 2020 16:52:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to push forward your diversity and inclusion efforts with purpose]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24010486">thread link</a>) | @mlboykin
<br/>
July 31, 2020 | https://www.range.co/blog/getting-diversity-inclusion-right-when-wfh | <a href="https://web.archive.org/web/*/https://www.range.co/blog/getting-diversity-inclusion-right-when-wfh">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p>Building a culture of belonging is vital to the success of any organization. Efforts to make companies more diverse and more inclusive have a profound impact on shaping culture for the better.</p><p>But for most, the sudden changes to working environments due to COVID-19 have disrupted these efforts. Many leaders are trying to understand how to maintain the momentum of their diversity and inclusion programs, and how they can recalibrate to this new normal and even accelerate progress.</p><p>To help leaders and teams find success here, we invited industry luminaries Nicole Sanchez of <a href="https://vayaconsulting.com/" rel="noopener" target="_self">Vaya Consulting</a> and Ellen Pao of <a href="https://projectinclude.org/" rel="noopener" target="_self">Project Include</a> to join Range co-founder Jennifer Dennard for an online discussion (<a href="https://docs.google.com/presentation/d/1OwawfySY59imwnNsBK9hM_a6cfhCTUz11qEkAHFuCyY/edit#slide=id.p" rel="noopener" target="_self">slides here</a>). During this webinar, our speakers explored:</p><ul><li>The state of diversity and inclusion in the workplace</li><li>The future of diversity at work</li><li>Fostering inclusion</li><li>Building on today’s momentum</li></ul><p>Here are some of the highlights of what we learned over the course of the discussion.</p><h2><strong>A greater purpose fuels today’s diversity and inclusion efforts</strong></h2><p>Given all of what’s been happening in America today, it comes as no surprise that there is a renewed interest and focus on diversity, equity, and inclusion (DEI) in the workplace. As Nicole sees it, we go through this every few years. However, one big difference this time around is that, thanks to the Black Lives Matter movement, champions for diversity and inclusion don’t have to spend as much time explaining and justifying the work they do.</p><blockquote>I think people feel the pain of what it means to get it wrong inside their organizations. And they are either surprised or pleasantly relieved to find out that there are people who work on this full-time. —Nicole Sanchez</blockquote><p>It’s because of the moment — this period in time where we’ve been more vigilantly focused on racial injustices — the conversation is landing differently with predominantly white leadership. But it’s not just them.</p><p>“I would also add that white employees are hearing it differently, too,” Ellen shared. “Not just the management, but the employees. And they’re speaking up.” As a result, management isn’t getting away with employing the same old tactics of donating money or making a statement. Employees are voicing their unhappiness, causing companies to look inward and fix their own issues.</p><h2><strong>Getting DEI right isn’t just going to happen on its own</strong></h2><p>For many of us, working from home every day of the week was thrust upon us. And not surprisingly, many of us — individuals, teams, and organizations — were not prepared. Some of our lives are just not set up for that. Some of our colleagues need to commute into a shared workspace to get work done, while some of us are thriving while working from home. With this in mind, Nicole notes that “As we figure out how to reassemble a workforce, we have to remember that nothing is automatically better.”</p><blockquote>The other thing that’s going to happen is that as we hire people from parts of the country where the cost of living is lower — and that increases our racial and ethnic diversity — we have to remember to not reproduce redlining in our own companies. —Nicole Sanchez</blockquote><p>There are a lot of things companies have to balance in the name of equity and inclusion if diversifying via a remote workforce is going to be a strategy. “It’s not simple, and we cannot assume our companies are going to be automatically good at it without putting the resources in.”</p><p>Jen, who wears many hats at Range, including people operations, has found it interesting to see the dialogue happening within many companies around equal pay for equal work. When we ask “How do you have a financially responsible balance sheet and pay people fairly?” we have to consider diversity and inclusion if we hope to come up with an equitable solution. They are not two separate topics and recognizing this reality changes how we approach the challenge.</p><h2><strong>How to build diversity into your hiring practices</strong></h2><p>For a long time, a lot of the dialogue around diversity and inclusion has been about finding ways to promote equal access and opportunity. While the dialogue today has shifted to “You’re either racist or anti-racist,” equality remains a top goal. As Jen points out, as companies work to develop programs that are anti-racist, some are running into legal constraints (i.e., establishing hiring quotas for individuals belonging to groups not well-represented within a company). So, she asked how companies can build diversity into the hiring process without running into legal trouble.</p><p>“There are a bunch of ways to do it that don’t run afoul of the law,” says Nicole, “and actually uphold the spirit of trying to diversify, especially around race and gender lines.” Here’s what she recommends starting:</p><ol><li><strong>Get clear about your values and value proposition for diversity</strong> (i.e., identify what you hope to gain by diversifying that you couldn’t have otherwise had)</li><li><strong>Start with improving racial and ethnic diversity</strong>, as it’s the hardest for most companies, and once you get it right it becomes easier to attract folks</li><li><strong>Widen the definition of what “good” looks like for your company</strong></li></ol><h2><strong>You need support from the very top</strong></h2><p>Prioritizing and improving diversity and inclusion at your company is the responsibility of <em>everyone</em>. And yes, having an executive leader (a Chief Diversity Officer or Chief People Officer) specifically focused on DEI 100 percent of the time is important. However, at the end of the day, the person who is ultimately responsible for this work is the CEO.</p><blockquote>At the end of the day, the person who is ultimately responsible for inclusion work is the CEO. And if the CEO is inclusive and cares, you will have an inclusive company. If the CEO has delegated because they don’t care, you will not have an inclusive company. —Ellen Pao</blockquote><p>Employees look at how their CEO makes decisions. When bad behavior is overlooked and excuses are made, the importance and value placed on DEI is undermined, and it’s undermined from the very top.</p><h2><strong>Building on today’s momentum</strong></h2><p>While sheltering-in-place has caused us all to reevaluate how we approach our diversity and inclusion work while working remotely, America’s continued national focus on issues of race has generated momentum enough to enact long-lasting change within companies.</p><p>The response from the C-suite today on these issues is markedly different from what it was in the past. Not only are the voices of employees being heard, but their messages are landing differently with executive leadership. So how do you capitalize on that opportunity?</p><ul><li>Revisit the values of your company, and update them if necessary</li><li>Stop focusing on growth regardless of the cost</li><li>Establish committees focused on support diversity</li><li>Push for changes to how your company recruits and interviews</li><li>Consider how you can track D&amp;I work as a business metric</li></ul><hr><h2><strong>Resources shared during the webinar</strong></h2><ul><li><a href="https://docs.google.com/presentation/d/1OwawfySY59imwnNsBK9hM_a6cfhCTUz11qEkAHFuCyY/edit#slide=id.p" rel="noopener" target="_self">Webinar slides</a></li><li><a href="http://thereadyset.co/blog/social-justice-anti-racism-and-blm-resources" rel="noopener" target="_self">ReadySet’s Social Justice, Anti-Racism, and #BLM Resources</a></li><li><a href="https://projectinclude.org/recommendations/" rel="noopener" target="_self">Project Include Recommendations</a></li><li><a href="https://firstround.com/review/eight-ways-to-make-your-dandi-efforts-less-talk-and-more-walk/" rel="noopener" target="_self">First Round’s 8 Ways to Make Your D&amp;I Efforts Less Talk and More Walk</a></li><li><a href="https://generalassemb.ly/blog/diversity-inclusion-equity-differences-in-meaning/" rel="noopener" target="_self">General Assembly’s The difference between diversity, inclusion, and equity</a></li></ul></div></div></section></div>]]>
            </description>
            <link>https://www.range.co/blog/getting-diversity-inclusion-right-when-wfh</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010486</guid>
            <pubDate>Fri, 31 Jul 2020 16:44:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Records and Tuples for React]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24010282">thread link</a>) | @slorber
<br/>
July 31, 2020 | https://sebastienlorber.com/records-and-tuples-for-react | <a href="https://web.archive.org/web/*/https://sebastienlorber.com/records-and-tuples-for-react">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p><strong>Records &amp; Tuples</strong>, a very interesting <a href="https://github.com/tc39/proposal-record-tuple" target="_blank" rel="noreferrer">proposal</a> for the JavaScript language, has just reached <strong><a href="https://twitter.com/robpalmer2/status/1286040041089904640" target="_blank" rel="noreferrer">stage 2</a></strong> at <strong>TC39</strong>.</p><p>A whole category of <strong>React bugs</strong> are related to <strong>unstable object identities</strong>:</p><ul><li><strong>Performance</strong>: can trigger re-renders that could be avoided</li><li><strong>Behavior</strong>: can trigger useless effect re-executions, and lead to infinite loops</li><li><strong>API surface</strong>: we don’t have a way to express when a stable object identity matters</li></ul><p>I will explain the basics of <strong>Records &amp; Tuples</strong>, and how they can solve <strong>real world React issues</strong>.</p><hr><h2 id="records--tuples-101">Records &amp; Tuples 101</h2><p>This article is about Records &amp; Tuples <strong><u>for React</u></strong>. I’ll only cover the basics here.</p><p>They look like regular <strong>Objects and Arrays</strong>, with a <strong>#</strong> prefix.</p><div><pre><p><span>1</span><span>const</span><span> record </span><span>=</span><span> #</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> </span><span>2</span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> updatedRecord </span><span>=</span><span> #</span><span>{</span><span>...</span><span>record</span><span>,</span><span> b</span><span>:</span><span> </span><span>3</span><span>}</span><span>;</span><span></span></p><p><span>4</span><span></span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>const</span><span> tuple </span><span>=</span><span> #</span><span>[</span><span>1</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>;</span><span></span></p><p><span>7</span><span></span></p><p><span>8</span><span></span><span>const</span><span> filteredTuple </span><span>=</span><span> tuple</span><span>.</span><span>filter</span><span>(</span><span>num</span><span> </span><span>=&gt;</span><span> num </span><span>&gt;</span><span> </span><span>2</span><span>)</span><span></span></p><p><span>9</span><span></span></p></pre></div><p>They are <strong>deeply immutable</strong> by default.</p><div><pre><p><span>1</span><span>const</span><span> record </span><span>=</span><span> #</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> </span><span>2</span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span>record</span><span>.</span><span>b </span><span>=</span><span> </span><span>3</span><span>;</span><span></span></p><p><span>4</span><span></span></p></pre></div><p>They can be seen as <strong>“compound primitives”</strong>, and can be compared by value.</p><p><strong>VERY IMPORTANT</strong>: two deeply equal records will <strong>ALWAYS</strong> return <code>true</code> with <code>===</code>.</p><div><pre><p><span>1</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> </span><span>[</span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>}</span><span> </span><span>===</span><span> </span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> </span><span>[</span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>}</span><span></span></p><p><span>2</span><span></span><span></span></p><p><span>3</span><span></span></p><p><span>4</span><span>#</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> #</span><span>[</span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>}</span><span> </span><span>===</span><span> #</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> #</span><span>[</span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>}</span><span></span></p><p><span>5</span><span></span></p></pre></div><p>They are interoperable with JSON:</p><div><pre><p><span>1</span><span>const</span><span> record </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>parseImmutable</span><span>(</span><span>'{a: 1, b: [2, 3]}'</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span><span></span></p><p><span>3</span><span></span></p><p><span>4</span><span></span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>record</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p></pre></div><p>They can only contain other records and tuples, or primitive values.</p><div><pre><p><span>1</span><span>const</span><span> record </span><span>=</span><span> #</span><span>{</span><span></span></p><p><span>2</span><span>  a</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    regular</span><span>:</span><span> </span><span>'object'</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>5</span><span>  b</span><span>:</span><span> </span><span>new</span><span> </span><span>Date</span><span>(</span><span>)</span><span>,</span><span></span></p><p><span>6</span><span>  c</span><span>:</span><span> </span><span>new</span><span> </span><span>MyClass</span><span>(</span><span>)</span><span>,</span><span></span></p><p><span>7</span><span>  </span><span>d</span><span>:</span><span> </span><span>function</span><span> </span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>8</span><span>    </span><span>alert</span><span>(</span><span>'forbidden'</span><span>)</span><span>;</span><span></span></p><p><span>9</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>10</span><span></span><span>}</span><span>;</span><span></span></p><p><span>11</span><span></span></p></pre></div><p><strong>Note</strong>: you could somehow add such mutable values to a Record by using Symbols as WeakMap keys (<a href="https://github.com/tc39/proposal-symbols-as-weakmap-keys" target="_blank" rel="noreferrer">separate proposal</a>), and <a href="https://github.com/tc39/proposal-record-tuple#could-i-box-a-pointer-to-an-object-and-put-that-in-a-record-or-tuple" target="_blank" rel="noreferrer">reference</a> the symbols in records.</p><p>Want more? Read the <a href="https://github.com/tc39/proposal-record-tuple" target="_blank" rel="noreferrer">proposal</a> directly, or this <a href="https://2ality.com/2020/05/records-tuples-first-look.html" target="_blank" rel="noreferrer">article</a> from Axel Rauschmayer.</p><hr><h2 id="records--tuples-for-react">Records &amp; Tuples for React</h2><p>React developers are now used to <strong>immutability</strong>.</p><p>Every time you update some piece of state in an immutable way, you create <strong>new object identities</strong>.</p><p>Unfortunately, this immutability model has introduced a whole new class of bugs, and performance issues in React applications.
Sometimes, a component works correctly and in a performant way, <strong>only under the assumption that props preserve identities</strong> as most as they can over time.</p><p>I like to think about Records &amp; Tuples as a convenient way to <strong>make object identities more “stable”</strong>.</p><p>Let’s see how this proposal will <strong>impact your React code</strong> with practical use cases.</p><p><strong>Note</strong>: there is a <a href="https://rickbutton.github.io/record-tuple-playground/#eyJjb250ZW50IjoiaW1wb3J0IFJlYWN0IGZyb20gXCJodHRwczovL2Nkbi5za3lwYWNrLmRldi9yZWFjdFwiO1xuaW1wb3J0IFJlYWN0RE9NIGZyb20gXCJodHRwczovL2Nkbi5za3lwYWNrLmRldi9yZWFjdC1kb21cIjtcblxuXG5jb25zdCBIZWxsbyA9ICh7dXNlcn0pID0+IHtcbiAgcmV0dXJuIDxwPkhlbGxvIHt1c2VyLm5hbWV9PC9wPlxufTtcblxuY29uc3QgdXNlciA9ICN7bmFtZTogXCJTZWJhc3RpZW5cIn1cblxuUmVhY3RET00ucmVuZGVyKFxuICAgIDxIZWxsbyB1c2VyPXt1c2VyfS8+LFxuICAgIGRvY3VtZW50LmJvZHksXG4pO1xuXG4iLCJzeW50YXgiOiJoYXNoIiwiZG9tTW9kZSI6dHJ1ZX0=" target="_blank" rel="noreferrer">Records &amp; Tuples playground</a>, that can run React.</p><h3 id="immutability">Immutability</h3><p>Enforcing immutability can be achieved with recursive <code>Object.freeze()</code> calls.</p><p>But in practice, we often use the immutability model without enforcing it too strictly, as it’s not convenient to apply <code>Object.freeze()</code> after each update. Yet, mutating the React state directly is a common mistake for new React developers.</p><p>The Records &amp; Tuples proposal will <strong>enforce immutability</strong>, and prevent common state mutation mistakes:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>Hello</span><span> </span><span>=</span><span> </span><span>(</span><span>{</span><span> profile </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span></span></p><p><span>3</span><span>  profile</span><span>.</span><span>name </span><span>=</span><span> </span><span>'Sebastien updated'</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>p</span><span>&gt;</span><span>Hello </span><span>{</span><span>profile</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>p</span><span>&gt;</span><span>;</span><span></span></p><p><span>6</span><span></span><span>}</span><span>;</span><span></span></p><p><span>7</span><span></span></p><p><span>8</span><span></span><span>function</span><span> </span><span>App</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>  </span><span>const</span><span> </span><span>[</span><span>profile</span><span>,</span><span> setProfile</span><span>]</span><span> </span><span>=</span><span> React</span><span>.</span><span>useState</span><span>(</span><span>#</span><span>{</span><span></span></p><p><span>10</span><span>    name</span><span>:</span><span> </span><span>'Sebastien'</span><span>,</span><span></span></p><p><span>11</span><span>  </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span></span></p><p><span>13</span><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>    </span><span></span></p><p><span>15</span><span>    profile</span><span>.</span><span>name </span><span>=</span><span> </span><span>'Sebastien updated'</span><span>;</span><span></span></p><p><span>16</span><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>17</span><span></span></p><p><span>18</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>Hello</span><span> </span><span>profile</span><span>=</span><span>{</span><span>profile</span><span>}</span><span> </span><span>/&gt;</span><span>;</span><span></span></p><p><span>19</span><span></span><span>}</span></p></pre></div><h3 id="immutable-updates">Immutable updates</h3><p>There are <a href="https://dev.to/sebastienlorber/insight-3-use-immerjs-over-lodash-set-immutablejs-or-plain-js-36bl" target="_blank" rel="noreferrer">many ways</a> to perform immutable state updates in React: vanilla JS, Lodash set, ImmerJS, ImmutableJS…</p><p>Records &amp; Tuples support the same immutable update patterns that you use with Objects and Arrays:</p><div><pre><p><span>1</span><span>const</span><span> initialState </span><span>=</span><span> #</span><span>{</span><span></span></p><p><span>2</span><span>  user</span><span>:</span><span> #</span><span>{</span><span></span></p><p><span>3</span><span>    firstName</span><span>:</span><span> </span><span>"Sebastien"</span><span>,</span><span></span></p><p><span>4</span><span>    lastName</span><span>:</span><span> </span><span>"Lorber"</span><span></span></p><p><span>5</span><span>  </span><span>}</span><span></span></p><p><span>6</span><span>  company</span><span>:</span><span> #</span><span>{</span><span></span></p><p><span>7</span><span>    name</span><span>:</span><span> </span><span>"Lambda Scale"</span><span>,</span><span></span></p><p><span>8</span><span>  </span><span>}</span><span></span></p><p><span>9</span><span></span><span>}</span><span>;</span><span></span></p><p><span>10</span><span></span></p><p><span>11</span><span></span></p><p><span>12</span><span></span><span>const</span><span> updatedState </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>  </span><span>...</span><span>initialState</span><span>,</span><span></span></p><p><span>14</span><span>  company</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>15</span><span>    </span><span>...</span><span>initialState</span><span>.</span><span>company</span><span>,</span><span></span></p><p><span>16</span><span>    name</span><span>:</span><span> </span><span>'Freelance'</span><span>,</span><span></span></p><p><span>17</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>18</span><span></span><span>}</span><span>;</span></p></pre></div><p>So far, <a href="https://github.com/immerjs/immer" target="_blank" rel="noreferrer">ImmerJS</a> has won this battle, due to its simplicity to handle nested attributes, and interoperability with regular JS code.</p><p>It is not clear how Immer could work with Records &amp; Tuples yet, but it’s something the proposal authors are exploring.</p><p>Michael Weststrate himself has <a href="https://twitter.com/mweststrate/status/1263482177934819329" target="_blank" rel="noreferrer">highlighted</a> that a <a href="https://github.com/tc39/proposal-deep-path-properties-for-record" target="_blank" rel="noreferrer">separate but related proposal</a> could <strong>make ImmerJS unnecessary for Records &amp; Tuples</strong>:</p><div><pre><p><span>1</span><span>const</span><span> initialState </span><span>=</span><span> #</span><span>{</span><span></span></p><p><span>2</span><span>  counters</span><span>:</span><span> #</span><span>[</span><span></span></p><p><span>3</span><span>    #</span><span>{</span><span> name</span><span>:</span><span> </span><span>"Counter 1"</span><span>,</span><span> value</span><span>:</span><span> </span><span>1</span><span> </span><span>}</span><span>,</span><span></span></p><p><span>4</span><span>    #</span><span>{</span><span> name</span><span>:</span><span> </span><span>"Counter 2"</span><span>,</span><span> value</span><span>:</span><span> </span><span>0</span><span> </span><span>}</span><span>,</span><span></span></p><p><span>5</span><span>    #</span><span>{</span><span> name</span><span>:</span><span> </span><span>"Counter 3"</span><span>,</span><span> value</span><span>:</span><span> </span><span>123</span><span> </span><span>}</span><span>,</span><span></span></p><p><span>6</span><span>  </span><span>]</span><span>,</span><span></span></p><p><span>7</span><span>  metadata</span><span>:</span><span> #</span><span>{</span><span></span></p><p><span>8</span><span>    lastUpdate</span><span>:</span><span> </span><span>1584382969000</span><span>,</span><span></span></p><p><span>9</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>10</span><span></span><span>}</span><span>;</span><span></span></p><p><span>11</span><span></span></p><p><span>12</span><span></span></p><p><span>13</span><span></span><span></span></p><p><span>14</span><span></span><span></span></p><p><span>15</span><span></span><span>const</span><span> updatedStateNative </span><span>=</span><span> #</span><span>{</span><span></span></p><p><span>16</span><span>  </span><span>...</span><span>initialState</span><span>,</span><span></span></p><p><span>17</span><span>  counters</span><span>[</span><span>0</span><span>]</span><span>.</span><span>value</span><span>:</span><span> </span><span>2</span><span>,</span><span></span></p><p><span>18</span><span>  counters</span><span>[</span><span>1</span><span>]</span><span>.</span><span>value</span><span>:</span><span> </span><span>1</span><span>,</span><span></span></p><p><span>19</span><span>  metadata</span><span>.</span><span>lastUpdate</span><span>:</span><span> </span><span>1584383011300</span><span>,</span><span></span></p><p><span>20</span><span></span><span>}</span><span>;</span></p></pre></div><h3 id="usememo">useMemo</h3><p>In addition to memoizing expensive computations, <code>useMemo()</code> is also useful to <strong>avoid creating new object identities</strong>, that might <strong>trigger useless computations, re-renders, or effects executions deeper in the tree</strong>.</p><p>Let’s consider the following use-case: you have an UI with multiple filters, and want to fetch some data from the backend.</p><p>Existing React code-bases might contain code such as:</p><div><pre><p><span>1</span><span></span></p><p><span>2</span><span></span><span></span></p><p><span>3</span><span></span><span></span></p><p><span>4</span><span></span><span></span></p><p><span>5</span><span></span><span>const</span><span> apiFilters </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span></span></p><p><span>6</span><span>  </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>7</span><span>  </span><span>[</span><span>userFilter</span><span>,</span><span> companyFilter</span><span>]</span><span>,</span><span></span></p><p><span>8</span><span></span><span>)</span><span>;</span><span></span></p><p><span>9</span><span></span></p><p><span>10</span><span></span><span>const</span><span> </span><span>{</span><span> apiData</span><span>,</span><span> loading </span><span>}</span><span> </span><span>=</span><span> </span><span>useApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>;</span></p></pre></div><p>With Records &amp; Tuples, this simply becomes:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>{</span><span>apiData</span><span>,</span><span>loading</span><span>}</span><span> </span><span>=</span><span> </span><span>useApiData</span><span>(</span><span>#</span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>)</span></p></pre></div><h3 id="useeffect">useEffect</h3><p>Let’s continue with our api filters use-case:</p><div><pre><p><span>1</span><span>const</span><span> apiFilters </span><span>=</span><span> </span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>fetchApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>.</span><span>then</span><span>(</span><span>setApiDataInState</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>apiFilters</span><span>]</span><span>)</span><span>;</span></p></pre></div><p>Unfortunately, the fetch effect gets <strong>re-executed</strong>, because the identity of the <code>apiFilters</code> object changes every time this component re-renders. <code>setApiDataInState</code> will trigger a re-render, and you will end up with an infinite fetch/render loop.</p><p>This mistake is so common across React developers that there are thousand of Google search results for <strong><a href="https://www.google.com/search?q=useEffect+%2B+%22infinite+loop%22" target="_blank" rel="noreferrer">useEffect + “infinite loop”</a></strong>.
Kent C Dodds even created <a href="https://github.com/kentcdodds/stop-runaway-react-effects" target="_blank" rel="noreferrer">a tool</a> to break such infinite loops in development.</p><p>Very common solution: create <code>apiFilters</code> directly in the effect’s callback:</p><div><pre><p><span>1</span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> apiFilters </span><span>=</span><span> </span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>fetchApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>.</span><span>then</span><span>(</span><span>setApiDataInState</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>userFilter</span><span>,</span><span> companyFilter</span><span>]</span><span>)</span><span>;</span></p></pre></div><p>Another creative solution (not very performant, found on <a href="https://twitter.com/acutmore/status/1256533631914426369" target="_blank" rel="noreferrer">Twitter</a>):</p><div><pre><p><span>1</span><span>const</span><span> apiFiltersString </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span></span></p><p><span>2</span><span>  userFilter</span><span>,</span><span></span></p><p><span>3</span><span>  companyFilter</span><span>,</span><span></span></p><p><span>4</span><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>  </span><span>fetchApiData</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>apiFiltersString</span><span>)</span><span>)</span><span>.</span><span>then</span><span>(</span><span></span></p><p><span>8</span><span>    setApiDataInState</span><span>,</span><span></span></p><p><span>9</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>10</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>apiFiltersString</span><span>]</span><span>)</span><span>;</span></p></pre></div><p>The one I like the most:</p><div><pre><p><span>1</span><span></span></p><p><span>2</span><span></span><span>const</span><span> apiFilters </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span></span></p><p><span>3</span><span>  </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>[</span><span>userFilter</span><span>,</span><span> companyFilter</span><span>]</span><span>,</span><span></span></p><p><span>5</span><span></span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span></span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>8</span><span>  </span><span>fetchApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>.</span><span>then</span><span>(</span><span>setApiDataInState</span><span>)</span><span>;</span><span></span></p><p><span>9</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>apiFilters</span><span>]</span><span>)</span><span>;</span></p></pre></div><p>There are many fancy ways to solve this problem, but they all tend to <strong>become annoying</strong>, as the number of filters increase.</p><p>They are much <strong>more verbose and less idiomatic</strong> than their Records &amp; Tuples counterpart:</p><div><pre><p><span>1</span><span>const</span><span> apiFilters </span><span>=</span><span> #</span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>fetchApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>.</span><span>then</span><span>(</span><span>setApiDataInState</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>apiFilters</span><span>]</span><span>)</span><span>;</span></p></pre></div><h3 id="props-and-reactmemo">Props and React.memo</h3><p>Preserving object identities in props is also very useful for React performances.</p><p>Another very common performance mistake: create new objects identities in render.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>Parent</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>useRerenderEverySeconds</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>4</span><span>    </span><span>&lt;</span><span>ExpensiveChild</span></p><p><span>5</span><span>      </span><span></span></p><p><span>6</span><span>      someData</span><span>=</span><span>{</span><span>{</span><span> attr1</span><span>:</span><span> </span><span>'abc'</span><span>,</span><span> attr2</span><span>:</span><span> </span><span>'def'</span><span> </span><span>}</span><span>}</span><span></span></p><p><span>7</span><span>    </span><span>/</span><span>&gt;</span><span></span></p><p><span>8</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>9</span><span></span><span>}</span><span>;</span><span></span></p><p><span>10</span><span></span></p><p><span>11</span><span></span><span>const</span><span> ExpensiveChild </span><span>=</span><span> React</span><span>.</span><span>memo</span><span>(</span><span>(</span><span>{</span><span> someData </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>12</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>expensiveRender</span><span>(</span><span>someData</span><span>)</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span>;</span><span></span></p><p><span>13</span><span></span><span>}</span><span>)</span><span>;</span></p></pre></div><p>Most of the time, this is not a problem, and React is fast enough.</p><p>But sometimes you are looking to optimize your app, and this new object creation makes the <code>React.memo()</code> useless. Worst, it actually <strong>makes your application a little bit slower</strong> (as it now has to run an additional shallow equality check, always returning false).</p><p>Another pattern I often see in client code-bases:</p><div><pre><p><span>1</span><span>const</span><span> currentUser </span><span>=</span><span> </span><span>{</span><span> name</span><span>:</span><span> </span><span>'Sebastien'</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span><span>const</span><span> currentCompany </span><span>=</span><span> </span><span>{</span><span> name</span><span>:</span><span> </span><span>'Lambda Scale'</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>3</span><span></span></p><p><span>4</span><span></span><span>const</span><span> </span><span>AppProvider</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>  </span><span>useRerenderEverySeconds</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>8</span><span>    </span><span>&lt;</span><span>MyAppContext.Provider</span><span></span></p><p><span>9</span><span>      </span><span>value</span><span>=</span><span>{</span><span>{</span><span> currentUser</span><span>,</span><span> currentCompany </span><span>}</span><span>}</span><span></span></p><p><span>10</span><span>    </span><span>/&gt;</span><span></span></p><p><span>11</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>12</span><span></span><span>}</span><span>;</span></p></pre></div><p>Despite the fact that <code>currentUser</code> or <code>currentCompany</code> <strong>never gets updated</strong>, your context value changes every time this provider re-renders, which trigger re-renders of all context subscribers.</p><p>All these issues can be solved with memoization:</p><div><pre><p><span>1</span><span>const</span><span> someData </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span></span></p><p><span>2</span><span>  </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>{</span><span> attr1</span><span>:</span><span> </span><span>'abc'</span><span>,</span><span> attr2</span><span>:</span><span> </span><span>'def'</span><span> </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>4</span><span></span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>&lt;</span><span>ExpensiveChild</span><span> </span><span>someData</span><span>=</span><span>{</span><span>someData</span><span>}</span><span> </span><span>/&gt;</span><span>;</span></p></pre></div><div><pre><p><span>1</span><span>const</span><span> contextValue </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span></span></p><p><span>2</span><span>  </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>{</span><span> currentUser</span><span>,</span><span> currentCompany </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>[</span><span>currentUser</span><span>,</span><span> currentCompany</span><span>]</span><span>,</span><span></span></p><p><span>4</span><span></span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>&lt;</span><span>MyAppContext.Provider</span><span> </span><span>value</span><span>=</span><span>{</span><span>contextValue</span><span>}</span><span> </span><span>/&gt;</span><span>;</span></p></pre></div><p>With Records &amp; Tuples, it is <strong>idiomatic to write performant code</strong>:</p><div><pre><p><span>1</span><span>&lt;</span><span>ExpensiveChild</span><span> </span><span>someData</span><span>=</span><span>{</span><span>#</span><span>{</span><span> attr1</span><span>:</span><span> </span><span>'abc'</span><span>,</span><span> attr2</span><span>:</span><span> </span><span>'def'</span><span> </span><span>}</span><span>}</span><span> </span><span>/&gt;</span><span>;</span></p></pre></div><div><pre><p><span>1</span><span>&lt;</span><span>MyAppContext.Provider</span><span> </span><span>value</span><span>=</span><span>{</span><span>#</span><span>{</span><span> currentUser</span><span>,</span><span> currentCompany </span><span>}</span><span>}</span><span> </span><span>/&gt;</span><span>;</span></p></pre></div><h3 id="fetching-and-re-fetching">Fetching and re-fetching</h3><p>There are many ways to fetch data in React: <code>useEffect</code>, HOC, Render props, Redux, SWR, React-Query, Apollo, Relay, Urql, …</p><p>Most often, we hit the backend with a request, and get some JSON data back.</p><p>To illustrate this section, I will use <a href="https://github.com/slorber/react-async-hook" target="_blank" rel="noreferrer">react-async-hook</a>, my own very simple fetching library, but this applies to other libraries as well.</p><p>Let’s consider a classic async function to get some API data:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>fetchUserAndCompany</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> response </span><span>=</span><span> </span><span>await</span><span> </span><span>fetch</span><span>(</span><span></span></p><p><span>3</span><span>    </span><span>`https://myBackend.com/userAndCompany`</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>return</span><span> response</span><span>.</span><span>json</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span><span>}</span><span>;</span></p></pre></div><p>This app fetches the data, and ensure this data stays “fresh” (non-stale) over time:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>App</span><span> </span><span>=</span><span> </span><span>(</span><span>{</span><span> id </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> </span><span>{</span><span> result</span><span>,</span><span> refetch </span><span>}</span><span> </span><span>=</span><span> </span><span>useAsync</span><span>(</span><span></span></p><p><span>3</span><span>    fetchUserAndCompany</span><span>,</span><span></span></p><p><span>4</span><span>    </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>5</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span>  </span><span></span></p><p><span>8</span><span>  </span><span>useInterval</span><span>(</span><span>refetch</span><span>,</span><span> </span><span>10000</span><span>)</span><span>;</span><span></span></p><p><span>9</span><span>  </span><span>useOnReconnect</span><span>(</span><span>refetch</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>useOnNavigate</span><span>(</span><span>refetch</span><span>)</span><span>;</span><span></span></p><p><span>11</span><span></span></p><p><span>12</span><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>result</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>    </span><span>return</span><span> </span><span>null</span><span>;</span><span></span></p><p><span>14</span><span>  </span><span>}</span><span></span></p><p><span>15</span><span></span></p><p><span>16</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>17</span><span>    </span><span>&lt;</span><span>div</span><span>&gt;</span><span></span></p><p><span>18</span><span>      </span><span>&lt;</span><span>User</span><span> </span><span>user</span><span>=</span><span>{</span><span>result</span><span>.</span><span>user</span><span>}</span><span> </span><span>/&gt;</span><span></span></p><p><span>19</span><span>      </span><span>&lt;</span><span>Company</span><span> </span><span>company</span><span>=</span><span>{</span><span>result</span><span>.</span><span>company</span><span>}</span><span> </span><span>/&gt;</span><span></span></p><p><span>20</span><span>    </span><span>&lt;/</span><span>div</span><span>&gt;</span><span></span></p><p><span>21</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>22</span><span></span><span>}</span><span>;</span><span></span></p><p><span>23</span><span></span></p><p><span>24</span><span></span><span>const</span><span> User </span><span>=</span><span> React</span><span>.</span><span>memo</span><span>(</span><span>(</span><span>{</span><span> user </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>25</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>user</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span>;</span><span></span></p><p><span>26</span><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>27</span><span></span></p><p><span>28</span><span></span><span>const</span><span> Company </span><span>=</span><span> React</span><span>.</span><span>memo</span><span>(</span><span>(</span><span>{</span><span> company </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>29</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>company</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span>;</span><span></span></p><p><span>30</span><span></span><span>}</span><span>)</span><span>;</span></p></pre></div><p>Problem: you have used <code>React.memo</code> for performance reasons, but every time the re-fetch happens, you end up with a new JS object, with a <strong>new identity</strong>, and <strong>everything re-renders</strong>, despite the fetched data being the <strong>same as before</strong> (deeply equal payloads).</p><p>Let’s imagine this scenario:</p><ul><li>you use …</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sebastienlorber.com/records-and-tuples-for-react">https://sebastienlorber.com/records-and-tuples-for-react</a></em></p>]]>
            </description>
            <link>https://sebastienlorber.com/records-and-tuples-for-react</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010282</guid>
            <pubDate>Fri, 31 Jul 2020 16:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Drawing Every Day]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24010265">thread link</a>) | @irontinkerer
<br/>
July 31, 2020 | https://tylersticka.com/journal/drawing-every-day/ | <a href="https://web.archive.org/web/*/https://tylersticka.com/journal/drawing-every-day/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><p><a href="https://tylersticka.com/journal/drawing-every-day/"><time datetime="2018-05-30">May 30, 2018</time></a></p></header><p>Halfway through 2017, I transitioned <a href="https://cloudfour.com/thinks/cloud-four-again/">from employee to partner at Cloud&nbsp;Four</a>. The change has been really positive: It’s a privilege to lead an organization that truly <a href="https://cloudfour.com/believes/">believes in the web</a>.</p><p>But big changes have a way of destabilizing one’s work-life balance. This became especially clear to me when, later that year, I returned to my sketchbook after an unintentionally long absence.</p><p>Drawing was a struggle. Nothing came out right. Glaring down my nose at the page, a slow sense of panic set in. I’d spent thirty years drawing nearly every day… had I really squandered all that in only a month or two away?</p><h2 id="skills-can-atrophy">Skills Can Atrophy</h2><p>A lot of people scoff when I tell them anyone can draw with enough practice. “I can barely draw a stick figure,” they reply. “I could practice every day and I’d never improve.”</p><p>But they’re wrong. Talent may be a factor, but I <em>know</em> it’s mostly practice.</p><p>I know because when I stop practicing, I get worse at it.</p><p>It isn’t like riding a bike. It’s like trying to write with the wrong hand. You <em>know</em> how the words are supposed to look, you <em>remember</em> how they’re written, but your digits are clumsy and uncooperative.</p><p>Drawing’s been my most direct form of self-expression for as long as I can remember. It’s the starting point of every website, app, game, icon or presentation I’ve ever made. To pick up a pen or pencil after months away and feel that sense of disconnect between my thoughts and gestures was truly alarming.</p><p>Luckily, I had an idea for how to fix it.</p><h2 id="discipline-restored">Discipline Restored</h2><p><a href="http://www.atinyrocket.com/">Erika Lee Sears</a> is a painter based here in Portland. She also helps <a href="https://twitter.com/u2elan">her husband</a> and I manage the business aspects of <a href="http://backabit.com/">Backabit</a>. And she’s been sharing a new oil painting <a href="http://www.atinyrocket.com/2017/12/making-art-every-day-in-2018.html">every day for the past four years</a>!</p><p>I decided to follow her example, and the basic rules she set for herself:</p><blockquote><ol><li>Make art every day, no matter how big or small. Any medium counts. Even if I draw a stick person or just snap a blurry photo, the point is just to make art.</li><li>I am not allowed to give up. This is very important.</li><li>I am not allowed to throw away any artwork or rip out any pages in my sketch book. I am allowed to start over. I am not allowed to start painting over canvases or ripping out pages in my sketchbook.</li></ol></blockquote><p>I started on January 1 of this year. It’s nearly 150 days later and <a href="http://tylersticka.tumblr.com/tagged/makeart2018">I’m still going strong</a>!</p><figure><img src="https://tylersticka.com/journal/drawing-every-day/01-01-yoda-480.jpg" srcset="https://tylersticka.com/journal/drawing-every-day/01-01-yoda-480.jpg 480w, https://tylersticka.com/journal/drawing-every-day/01-01-yoda-960.jpg 960w, https://tylersticka.com/journal/drawing-every-day/01-01-yoda-1920.jpg 1920w" sizes="(max-width: 479px) 100vw, 800px" alt=""><figcaption>“Do. Or do not. There is no try.” Yoda felt like an appropriate start to the project.</figcaption></figure><h2 id="thoughts-so-far">Thoughts So Far</h2><p>The experience has been incredibly rewarding. I feel a renewed sense of confidence in my ability. My speed has improved. And I feel it’s had a positive impact on my mental wellbeing and my overall creative output. (I’m not just drawing more… I’m writing more, too!)</p><p>Occasionally the daily requirement will feel confining, but more often I find that it lowers the pressure. No matter how wonky or slap-dash today’s drawing may be, there’s always another chance tomorrow!</p><p>Sharing the work has been crucial. As silly as it sounds, sometimes a “like” or supportive comment from the previous day’s drawing can carry you through the next.</p><p>I can never predict which drawings will be well-received, so I try not to worry about it. Anyone but me liking them is just a nice bonus!</p><p><img src="https://tylersticka.com/journal/drawing-every-day/02-22-480.jpg" srcset="https://tylersticka.com/journal/drawing-every-day/02-22-480.jpg 480w, https://tylersticka.com/journal/drawing-every-day/02-22-960.jpg 960w, https://tylersticka.com/journal/drawing-every-day/02-22-1920.jpg 1920w" sizes="(max-width: 479px) 100vw, 800px" alt="Drawing of a happy duck"></p><h2 id="questions-i-ve-been-asked">Questions I’ve Been Asked</h2><h3 id="how-do-you-find-time-">How do you find time?</h3><p>Most of the drawings I share take a half-hour or less, though it can range from a few minutes to a few hours. I try to pick subjects I know I can finish in whatever time I have. Artists will be able to spot the corners I’m cutting pretty easily (partial figures, no backgrounds, etc.).</p><p>It probably helps that I’ve always admired illustrators who can speak volumes <a href="https://www.youtube.com/watch?v=dS0vUbWdNxg">with very few lines</a>.</p><figure><p><iframe src="https://player.vimeo.com/video/272269757?title=0&amp;byline=0&amp;portrait=0" width="640" height="347" allowfullscreen=""></iframe></p><figcaption>This screen recording of one of my early digital drawings has been shortened from a couple of hours to a couple of minutes. I think I’d finish this one faster today!</figcaption></figure><h3 id="what-tools-do-you-use-">What tools do you use?</h3><p>Digitally, I draw in Photoshop using a Wacom Intuos tablet. Otherwise, I usually draw in a Canon Mix Media sketchbook with <a href="https://tylersticka.com/journal/a-pencil-named-excalibur/">my trusty Pentel Twist-Erase 0.9mm pencil</a>, Faber-Castell pens and Prismacolor markers.</p><p>But I try not to sweat the tools I’m using too much. I’ve shared drawings in my Moleskine, on sticky notes, in ballpoint pen. Sometimes I don’t have time to scan a drawing so I’ll just snap a quick photo. The process is more important than the result.</p><h3 id="do-you-have-a-favorite-drawing-so-far-">Do you have a favorite drawing so far?</h3><p>As of this writing, I still like the simple, gestural lines of the Wonder Woman profile I drew on <a href="https://en.wikipedia.org/wiki/International_Women%27s_Day">March 8</a>:</p><p><img src="https://tylersticka.com/journal/drawing-every-day/03-08-480.jpg" srcset="https://tylersticka.com/journal/drawing-every-day/03-08-480.jpg 480w, https://tylersticka.com/journal/drawing-every-day/03-08-960.jpg 960w, https://tylersticka.com/journal/drawing-every-day/03-08-1920.jpg 1920w" sizes="(max-width: 479px) 100vw, 800px" alt="Drawing of Wonder Woman's face in profile"></p><h2 id="june-and-beyond">June and Beyond</h2><p>I’ve got seven more months till I meet my goal! Unless I get around to adding a sketchbook section to <a href="https://tylersticka.com/">tylersticka.com</a>, you can find my latest drawings on <a href="https://www.instagram.com/tylersticka/">Instagram</a>, <a href="https://tylersticka.tumblr.com/">Tumblr</a>, <a href="https://twitter.com/tylersticka">Twitter</a> or <a href="https://www.facebook.com/tylersticka">Facebook</a>.</p><p>If you’re thinking of starting a daily art project, I say “do it!” It’s a fun and challenging way to freshen your creative synapses.</p></div></div>]]>
            </description>
            <link>https://tylersticka.com/journal/drawing-every-day/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010265</guid>
            <pubDate>Fri, 31 Jul 2020 16:22:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should web apps use PAKEs?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009979">thread link</a>) | @arkadiyt
<br/>
July 31, 2020 | https://emilymstark.com/2020/07/30/should-web-apps-use-pakes.html | <a href="https://web.archive.org/web/*/https://emilymstark.com/2020/07/30/should-web-apps-use-pakes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>My colleague
<a href="https://twitter.com/jyasskin/status/1288308864786419713">Jeffrey Yasskin</a>
asked an interesting question on Twitter:</p>

<figure>
  <img src="https://emilymstark.com/assets/jyasskin_pake_tweet.png" alt="Tweet asking why we advise developers to use password hashing functions instead of PAKEs to check the password without sending it">
  <figcaption><i></i></figcaption>
</figure>

<p>Jeffrey is referring to Password Authenticated Key Exchange (PAKE) protocols.
PAKEs allow two parties to negotiate a cryptographic key based on a password,
which might be known by one or both of the parties. When people talk about using
PAKEs in the web setting, however, they usually aren’t directly interested in
negotiating a cryptographic key. Instead, they’re interested in using a PAKE to
authenticate a user, and they’re specifically interested in PAKEs because some
PAKEs allow a client to prove to a server that the client knows the correct
password without revealing the password to the server. In contrast, when using
traditional password-based authentication, the client sends the password to the
server, and the server compares it with a value stored in its database
(hopefully hashed with a strong password hashing function).</p>

<p>Not sending the password to a server is appealing for two reasons:</p>
<ul>
  <li>The server can’t leak the password if it never sees the password. In
traditional password-based authentication, we partially mitigate this risk by
hashing the password when it’s stored in a database, so that a database breach
won’t leak the password. Some developers worry about leaking passwords before
they reach the database – for example, passwords might get accidentally
written to frontend log files that get leaked – and using a PAKE could
mitigate this risk.</li>
  <li>A malicious server can’t steal the password if it never sees the password.
However, this goal is irrelevant to Jeffrey’s question about web apps
implementing PAKEs. The web server provides the JavaScript code that
implements the PAKE, so a malicious server could just steal the password
directly on the client. (However, it is interesting to think about how the
browser itself might intervene to stop malicious servers from obtaining the
password; see <a href="#browser-mediated-pakes">Browser-mediated PAKEs</a> below.)</li>
</ul>

<p>If web apps were to use PAKEs, the security gain would be via the first
property: the server can’t leak the password. My position is that PAKEs provide
a very marginal security gain in the web app setting (funnily enough, many years
ago I was to <a href="https://twitter.com/estark37/status/1288319710744834049">blame</a>
for exorcising one of the few PAKE implementations on the web), but to argue
that position coherently, I first need to discuss why web developers care about
leaking passwords in the first place.</p>



<p>I’m not talking about <em>how</em> we hash passwords – e.g., which password hashing
function to use, how many rounds, etc. I’m talking about a much more basic
question: why do we bother hashing passwords rather than just sticking them in
the database like other data? (Sidenote: I think this would make a great warm-up
interview question for a security engineer… of course now that I’m blogging
about, I won’t be able to use it.)</p>

<p>At first glance, it might seem obvious that websites hash passwords so that a
database breach doesn’t yield long-term access to all the site’s users’
accounts. But, if an attacker gains read access to a website’s database, the
attacker can likely leak session cookies or other bearer tokens as well as all
the other sensitive user data that the website handles. The main reason we hash
passwords is to mitigate users’ tendency to reuse passwords across different
services (in other words, to protect against
<a href="https://en.wikipedia.org/wiki/Credential_stuffing">credential stuffing attacks</a>
in which a leaked password at one service is reused at another). If a website’s
database gets breached, it is a catastrophic security incident for that website
regardless of whether the attacker leaks plaintext passwords or other data. But
if the attacker leaks plaintext passwords, the breach is also a catastrophic
security incident for other websites. The value of hashing passwords is to
prevent a security incident at one service from spreading laterally across huge
swaths of the web.</p>



<p>That’s why my answer to Jeffrey’s question was that, in the web setting, PAKEs
don’t buy you much that client-side password hashing doesn’t also buy you (and
client-side password hashing is much simpler). Both protect against credential
stuffing attacks in the event of any server data leak, which, as I argued above,
is the main threat that password protections aim to mitigate. A PAKE is stronger
in that it prevents a server data leak from yielding long-term access to users’
accounts. In contrast, leaked client-side-hashed passwords do give the attacker
access to users’ accounts on that service, because the hashed password
effectively is the password. But I just don’t find that very compelling in light
of all the other interesting data (session cookies, sensitive user data, etc.)
that an attacker would be able to access with a server data leak.</p>

<p>This is not to say that I recommend client-side password hashing – just that
any web developer considering implementing a PAKE should take a close look at
their threat model and consider if client-side hashing is a much simpler way to
get what they want. Personally I’d recommend that web developers focus their
cycles on moving users towards stronger auth in the form of
<a href="https://webauthn.io/">WebAuthn</a>, rather than investing in either a PAKE or
client-side password hashing.</p>



<p>Reasonable people can disagree on the answer to Jeffrey’s question, and another
reasonable answer might be “historical accident.” PAKEs were patent-encumbered
for some period of time, and some had <a href="https://blog.cryptographyengineering.com/should-you-use-srp/">less than ideal security
properties</a>.
Furthermore, until the
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API">WebCrypto</a> API
came along and offered native implementations of cryptographic algorithms to
JavaScript, implementing a PAKE would have involved hand-rolling cryptographic
primitives in a slow language that isn’t particularly well-suited to it. So it
could be that the advice to use a strong password hashing function took root in
the web developer community and wasn’t easy to overturn once
<a href="https://eprint.iacr.org/2018/163.pdf">stronger PAKEs</a> and native crypto
implementations came along.</p>



<p>PAKEs don’t provide protection against malicious servers in the web setting,
because a malicious server could serve evil JavaScript that reads the plaintext
password off the page as the user is typing it. This problem invites an
alternative design to implementing a PAKE in JavaScript. What if the PAKE was
implemented in the browser itself and exposed via JavaScript API, with
trustworthy browser UI collecting the password from the user so that malicious
JavaScript can’t steal it?</p>

<p>At first glance, a browser-mediated PAKE appears to be a powerful anti-phishing
tool as well as a protection against server data leaks. But there are some
problems with this idea:</p>

<ul>
  <li>It poses a usable security and ecosystem challenge. The vast majority of
websites would have to migrate to the browser-mediated PAKE in order for users
to get out of the habit of typing passwords directly into webpages. Otherwise,
users wouldn’t notice anything amiss as they type their password directly into
a phishing webpage, even if the victim website used the browser-mediated PAKE.
Even if all websites magically migrated away from plaintext passwords to a
browser-mediated PAKE, a phishing website could likely convincingly spoof the
browser password entry UI to trick the user into typing the password into the
page, where it is accessible to JavaScript.</li>
  <li>Historically, browser-mediated authentication hasn’t seen widespread adoption
on the consumer web. Browser developers tend to view
<a href="https://en.wikipedia.org/wiki/Basic_access_authentication">HTTP Basic Auth</a>
as legacy cruft that we’re stuck with due to entrenchment in enterprises. The
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Credential_Management_API">Credential Management API</a>
was a more recent attempt, and not many websites use it. I’m not sure why this
is<sup id="fnref:1"><a href="#fn:1">1</a></sup>, but one hypothesis is that web developers don’t like to have the
browser mediate user authentication and prefer to integrate it into the look
and feel of their website. <a href="https://github.com/WICG/WebID">WebID</a> is a
brand-new attempt aimed at moving federated login into the browser to prevent
cross-site tracking, so it will be interesting to see if and how that gains
adoption.</li>
  <li>If we could solve these usable security challenges, particularly the challenge
of training users to not type passwords directly into webpages, then browsers
could defend against phishing with much simpler means, e.g. by getting users
to log in to websites exclusively using a password manager that refuses to
fill credentials on the wrong sites. The marginal value of adopting PAKEs then
reduces to the same question I discussed above: is the complexity of a PAKE
worth the benefits in the event of a server data leak when you consider all
the other sensitive data that could be leaked?</li>
</ul>

<p>One final approach I’ll mention: TLS includes
<a href="https://tools.ietf.org/html/draft-barnes-tls-pake-04">PAKE ciphersuites</a>.
One could imagine browsers using this feature as a way of implementing a
browser-mediated PAKE. I think this is unlikely to achieve widespread adoption
in browsers and web servers, or solve any of the security problems I’ve
discussed. It suffers from all the usability and adoption challenges I just
mentioned, plus it’s implemented at the wrong layer for web applications:
TLS-terminating frontends don’t typically know about application authentication
state. Similarly, TLS client certificates aren’t widely used outside of
enterprises (though client certs suffer from other problems that further inhibit
their adoption). I think TLS PAKE ciphersuites are probably designed for
non-browser use cases.</p>

<p>Overall, one can construct various theories as to why web apps don’t implement
PAKEs, but my personal theory is that the marginal security gain is just not
worth the effort and complexity, and I predict that we won’t see widespread PAKE
adoption on the web.</p>

<p><small><em>Many thanks to Zakir Durumeric, Chris Palmer, and Mike West for their
feedback on this post.</em></small></p>



  </div></div>]]>
            </description>
            <link>https://emilymstark.com/2020/07/30/should-web-apps-use-pakes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009979</guid>
            <pubDate>Fri, 31 Jul 2020 15:57:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A web developer walks into a game jam...]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009840">thread link</a>) | @jakeboxer
<br/>
July 31, 2020 | https://beesknees.games/blog/a-web-developer-walks-into-a-game-jam | <a href="https://web.archive.org/web/*/https://beesknees.games/blog/a-web-developer-walks-into-a-game-jam">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <p>Here's a super hot take for ya: making video games is hard, especially when you're new to it. Even though we each have a decade of experience developing software and we picked the simplest possible idea, it still took us multiple months to finish <a href="https://beesknees.games/blog/our-first-little-game">our first little game</a>!</p>

<p>As we started planning for our next game, we realized there was one big unknown floating around: how much had we actually learned from building Boba Simulator 2020? We certainly <em>felt</em> like we'd learned a lot, but we couldn't quantify it. We started Bee's Knees Games with the assumption that our years of development experience would allow us to pick up game development more quickly, but with only a single point of reference so far, we weren't sure if we'd need to reevaluate our various business timelines to account for a longer ramp-up time.</p>

<p>Right around this time, <a href="https://pigsquad.com/">Portland Indie Game Squad</a> announced an upcoming game jam: <a href="https://itch.io/jam/ssjturnbased">Summer Slow Jams 2020</a>. We'd never done a game jam before, we both love turn-based games, and we were excited to use everything we'd learned on Boba Simulator 2020 to build another quick game and compare the development processes of the two games. We felt like finishing a second small game would give us a much more concrete idea of our ramp-up time, and allow us to estimate the development time of our next game with greater accuracy.</p>

<p>In case you'd just like to play: we ended up creating a game with <a href="https://twitter.com/alexbenson">Alex Benson</a> called <a href="https://beeskneesgames.itch.io/oxo"><strong>OXO</strong></a>!</p>

<p><img src="https://bees-knees-games-blog.s3.us-west-2.amazonaws.com/image-uploads/promo-screenshot-1596067670064.png" alt="OXO screenshot"></p>

<p>You can <a href="https://beeskneesgames.itch.io/oxo">download OXO on itch.io</a>, and if you stick around, you can read our thoughts on the development.</p>

<h2>We got an idea for a gardening game</h2>

<p>The initial game jam announcement said that all games must be turn-based, but they didn't announce the creative theme, so we started a brainstorm on what types of things we'd like to see in a turn-based game. As the Bee's Knees Games CPO (Chief Plant Officer), Jessica immediately gravitated towards a gardening game, where weeds spread every turn and you have to prune them before they overtaking your garden.</p>

<p>We got very excited coming up with different ideas for weed-spreading algorithms and the pruning tools that you could use. We also felt like we could pretty easily swap gardens and weeds for a lot of other possible themes (a virus spreading across a network, a fire spreading through a forest, etc.), so we felt comfortable thinking deeply about the idea even without knowing what the creative theme would be.</p>

<h2>We got extremely lucky</h2>

<p>A couple days before the official start of the game jam, <a href="https://twitter.com/alexbenson">Alex Benson</a> reached out â€“ he's a 3D animator and musician who had also never done a game jam and was looking for a team to join. We'd nervously agreed on doing the graphics and music ourselves, but when Alex reached out, we felt so lucky. I mean, just check out his <a href="https://stuffalexmakes.com/">work</a>.</p>

<p>Not to spoil the rest of the blog post, but Alex was an amazing teammate. We'll go into greater detail later, but it's hard to imagine the game we all made together without Alex's artwork and music. Alex brought a style and a level of quality to the project that ultimately let us go far beyond what we thought we could accomplish in two weeks.</p>

<h2>We got our creative theme</h2>

<p>A few days later, PIGSquad announced the creative theme: "alternate timelines". The three of us met on Discord and discussed whether our initial weed-spreading idea was adaptable or not.</p>

<p>Ultimately, we decided our game would have a whole multiverse of different timelines, and the walls between the timelines would be breaking down, and the player's job would be to fix the cracks between the timelines before the whole universe collapses in on itself. Which, if you think about it, is pretty much just pruning weeds with some fancy shaders.</p>

<h2>We organized ourselves</h2>

<p>While we were still unsure on how well our web development experience was translating to game development, we knew how to organize ourselves when developing software, and we felt confident that this knowledge would work well for game development. We used:</p>

<ul>
<li>A GitHub repository for version control.</li>
<li>A Trello board for tracking work and sharing assets.</li>
<li>A Discord channel for synchronous communication between the three of us. We'd normally use Slack, but Discord is better when collaborating with someone outside our company.</li>
</ul>

<p>These tools worked great for us, and we'd highly recommend them to other teams participating in a game jam.</p>

<h2>We started building the game</h2>

<p>With our team organized and our game idea laid out, we started work on the actual game. Our first task was planning a simple very simple version of the gameplay to get the game's foundations in place. In web development, we call this concept "minimum viable product" (MVP for short), and we felt like this idea would translate well to game development.</p>

<p>We started work on our MVP by brainstorming about how the timeline damage would spread across the board, and what options the player would have for fighting it. We did our earliest prototypes using some super high-tech tools:</p>

<p><img src="https://bees-knees-games-blog.s3.us-west-2.amazonaws.com/image-uploads/postit-board-1596067798934.jpg" alt="Prototype using post-it notes"></p>

<p>This was super useful for quickly figuring out what options might make sense and ruling out non-starters. After a couple hours, we took what we'd learned and started coming up with algorithms that would translate well to a computer.</p>

<h3>The damage spread algorithm</h3>

<p>We wanted the timeline damage to start out feeling minor, but to get "out of control" as it spreads across the board. To enable this, we came up with an idea we called "damage heads".</p>

<p><img src="https://bees-knees-games-blog.s3.us-west-2.amazonaws.com/image-uploads/damage-spread-1596068647567.gif" alt="Damage spread GIF"></p>

<p>On turn 1, there is a single damage head in a corner of the board. Every turn, this head moves to a random adjacent cell, leaving behind a trail of damage on all the cells it previously touched.</p>

<p>Alone, this simple algorithm never gives the feeling of the board getting out of control, since only one new cell is damaged each turn. However, we also included a second rule: every 3 turns, all damage heads split in two.</p>

<p>This gave us the feeling we were looking for. Now, if you dilly dally around fixing up damage without a plan, the damage heads will grow exponentially and you won't be able to fix things fast enough. This algorithm evolved to be a bit <a href="https://github.com/beeskneesgames/June2020Jam/blob/43b63d5859db938136e41d7b1fc632a61be81a61/Assets/Scripts/DamageManager.cs#L47">more complicated over time</a>, but its roots remained the same.</p>

<h3>The player's options</h3>

<p>We decided to start the player out with just two simple options: "move" and "fix". The player gets three "action points" per turn, and can spend them moving to a different cell, fixing the damage on a cell, or some combination of the two. Moving and fixing cost the same amount: one action point per cell traveled. For example, fixing (or moving to) the cell directly on your left costs one action point, while fixing the cell that's two steps to your left costs two action points.</p>

<p>While these options are extremely simple, we felt like they were great for an MVP, and we'd be able to expand on them later on. Like the damage algorithm, these rules evolved over time, and the final game has slightly modified rules. You can see our final rules list on <a href="https://beeskneesgames.itch.io/oxo">the game's itch.io page</a>.</p>

<h2>We built a solid foundation and iterated on it</h2>

<p>With only two weeks to build the game, it was tempting to start hacking something onto the screen right away and throw any semblance of foundational planning out the window. However, we still decided to still spend some time building a solid foundation. We really wanted to build something that was at least somewhat fun, and we knew this would require a lot of tweaking of various aspects of the game (board dimensions, action point costs, etc.). Our experience with web development taught us that small tweaks like this are easy in a well-architected system, but in a hastily-thrown-together one, each tweak can take a very long time. We predicted that spending some up-front time on architecture would save us time in the long run, and we turned out to be right. Here are a couple examples of this foundational work.</p>

<h3>The grid. A multi-coordinate-system frontier.</h3>

<p>All game logic took place on a square grid, which meant the game would inherently contain two coordinate systems:</p>

<ul>
<li>The Unity coordinate system, which gives each object a 3D floating point coordinate specifying where that object lives in the scene. An object living in the absolute center of the scene has a Unity coordinate system position of <code>(0.0f, 0.0f, 0.0f)</code>, while an object that's supposed to be 2.5 meters above the center will be at <code>(0.0f, 2.5f, 0.0f)</code></li>
<li>The grid's own coordinate system, where each cell has a 2D integer coordinate. On our 16x16 board, the bottom-left cell has a grid coordinate of <code>(0, 0)</code>, while the bottom-right cell is at <code>(15, 0)</code>, and the top-right cell is at <code>(15, 15)</code>.</li>
</ul>

<p>We knew we'd need to do a lot of translations between these two coordinate systems. For example, if we wanted to move the player from cell <code>(2, 2)</code> to cell <code>(2, 3)</code>, we'd need to figure out the Unity coordinate system position for each of those cells, so that we could animate the movement between them correctly. Our experience building Boba Simulator 2020 taught us that we really want to limit how much Unity position math is spread throughout the system, so we decided to encapsulate all the coordinate system translation logic in our <a href="https://github.com/beeskneesgames/June2020Jam/blob/main/Assets/Scripts/Grid.cs">Grid</a> class. Much of this work was done by the <a href="https://github.com/beeskneesgames/June2020Jam/blob/43b63d5859db938136e41d7b1fc632a61be81a61/Assets/Scripts/Grid.cs#L329-L331"><code>Grid.PositionForCoords()</code></a> method.</p>

<p>For example, instead of manually calculating the player object's Unity position during a move, we can just call <code>Grid.PositionForCoords()</code> in the <a href="https://github.com/beeskneesgames/June2020Jam/blob/43b63d5859db938136e41d7b1fc632a61be81a61/Assets/Scripts/Player.cs#L316-L317">player movement method</a>, and then do a <a href="https://github.com/beeskneesgames/June2020Jam/blob/43b63d5859db938136e41d7b1fc632a61be81a61/Assets/Scripts/Player.cs#L321-L327">simple lerp</a> between the positions. This lets us keep the translation math out of the Player code entirely.</p>

<h3>The debug menu</h3>

<p>Early in the development of Boba Simulator 2020, we found that we had certain parameters we wanted to tweak frequently during development. Once this became bothersome enough, we added a "debug mode" that would toggle between debug-friendly values and the values we intended for players. For example, the tapioca balls in the game should normally fall randomly across the screen, but this made it slow to test the ball-catching logic, so we made the tapioca balls fall down in a straight line in debug mode. This toggle proved useful in Boba …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beesknees.games/blog/a-web-developer-walks-into-a-game-jam">https://beesknees.games/blog/a-web-developer-walks-into-a-game-jam</a></em></p>]]>
            </description>
            <link>https://beesknees.games/blog/a-web-developer-walks-into-a-game-jam</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009840</guid>
            <pubDate>Fri, 31 Jul 2020 15:47:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remotely working: All remote or all office. Hybrids are problematic]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009592">thread link</a>) | @snird
<br/>
July 31, 2020 | https://snir.dev/blog/remotely/all-remote-or-all-office/ | <a href="https://web.archive.org/web/*/https://snir.dev/blog/remotely/all-remote-or-all-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Remote work isn't harder than working in the office, It’s actually easier. The transition is difficult. Changing all the patterns you are used to from the office as an employee/manager is never easy. </p> <p>When I moved a startup to be completely remote as its CTO in 2015 I discovered the hard way that I had to change how I personally communicate and how the team communicates. I had to adopt new ways of team bonding, conveying company culture, etc. </p> <p>For remote work to be effective every aspect had to be fundamentally different. One example is the need for <a href="https://snir.dev/blog/remote-async-communication">written async communication</a> which I wrote an extensive essay about. </p>  <p>When I tell people remote will work much better if everyone is remote, I get called dogmatic. “It’s not all black and white”. I’m sure some companies will be able to roll out hybrid models, but they need to know what they lose. </p> <p>Remote work practices are so fundamentally different from the office, that using a hybrid model of some people remote some are in the office will eventually lead to 2 separate companies within the company. </p> <p>The remote company communicates through written communication, so their work is transparent and easily accessible to everyone. The office company relies on meetings and in-person talk, so their work is inaccessible and making the remote employees left out. </p> <p>The remote company relies on online activities to get to know and trust each other, which the office people can take a part of too. The office people in the meantime sit down for a beer only with other office people. </p> <p>Those who claim remote work will stifle your progress as an employee, usually refer to this kind of hybrid company. And rightfully so, you will usually be at a political disadvantage to those working in the office. </p> <p>In a remote company that takes remote seriously, and manage remote as an important part of the company, this is not an issue.</p>  <p>If a company wants the benefits of remote work it has to truly commit it. Don’t leave anyone behind. One way around it that seems to work well enough though, is logical separation by departments. </p> <p>For example - having all the R&amp;D working remotely, and all the sales in office. This still works as it does not stifle the progress of someone within his department and unify the communication methods within each department. </p> <hr> <p>There’s a lot more to be said on the topic and the implementation details. But I think this clears out most of the recent criticism for remote work I saw that is actually criticizing the hybrid model. </p> <form action="https://snir.substack.com/api/v1/free?nojs=true" method="post" min-width="400 500 600 700 800"> <div data-style="minimal">  <ul data-element="errors" data-group="alert"></ul>  <p>I wont send you spam. Unsubscribe at any time.</p></div></form></article></div>]]>
            </description>
            <link>https://snir.dev/blog/remotely/all-remote-or-all-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009592</guid>
            <pubDate>Fri, 31 Jul 2020 15:28:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public-Key Cryptosystems and Digital Signatures]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009587">thread link</a>) | @keyboardman
<br/>
July 31, 2020 | https://leimao.github.io/blog/Public-Key-Cryptosystem-and-Digital-Signature/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Public-Key-Cryptosystem-and-Digital-Signature/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Sometimes I would get some interesting questions from my friends about internet security, such as whether it is possible to leak the bank account password when logging to the online bank via an untrusted network, whether it is possible that the message you received from someone via an untrusted network got modified maliciously, and whether it is possible that someone pretends to be you and send messages in your name. My answers to those questions are as long as your computer and cell phone are uncontaminated they are almost impossible thanks to our modern public-key crytosystems and digital signatures.</p>



<p>There are a couple of introductions to the public-key crystosystems and digital signature available online. However, I think most of them are incomplete or hard to understand. In this blog post, I am going to describe the public-key crystosystems and digital signatures using extremely simple math, so that there would be no ambiguity at all.</p>

<h3 id="usages">Usages</h3>

<p>The modern cryptosystems are public-key encryption systems in which everyone has a public-key for encryption and a private key for decryption. The public-key is seen by everyone, but the private is only accessible by the owner. The public-key encryption systems could also generate digital signatures which could be used to verify whether the message you received is unmodified and truly sent from the sender.</p>



<p>RSA (Rivest–Shamir–Adleman) is a typical algorithm for the public-key cryptosystems used by modern computers to encrypt and decrypt messages. However, we are not going to introduce the RSA algorithm in this blog post. Instead, we would describe the public-key cryptosystems and digital signatures at a high level.</p>

<h3 id="essential-features">Essential Features</h3>

<p>Each user has their own encryption and decryption functions, $E$ and $D$, using public-key and private key respectively. We use $M$ to represent the message to be encrypted and sent. There are four features that are essential to a public-key cryptosystem.</p>

<ul>
  <li>Decrypting an encrypted message gives you the original message (Of course!). Specifically,</li>
</ul>



<ul>
  <li>Encrypting a decrypted message gives you the original message (Hmm…). Specifically,</li>
</ul>



<ul>
  <li>
    <p>$E$ and $D$ are easy to compute. This means the encryption and decryption process should be fast.</p>
  </li>
  <li>
    <p>The publicity of $E$ does not compromise the secrecy of $D$. This means you could hardly find a way to decrypt the encrypted message, even if you know how to encrypt the message.</p>
  </li>
</ul>

<p>We would ignore how to satisfy the four features in this blog post.</p>

<h3 id="message-encryption-and-decryption">Message Encryption and Decryption</h3>

<p>Suppose we have two people, Alice and Bob. Both of them are using the same public-key cryptosystems. This means Alice and Bob both have their private keys stored secretly and have their public key published to some authorities. From the authorities, we could find the public keys of Alice and Bob unambiguously. We denote encrypting the message using Alice and Bob’s public keys to be $E_A$ and $E_B$ respectively, and decrypting the message using Alice and Bob’s private keys to be $D_A$ and $D_B$ respectively.</p>



<p>One day, Alice wanted to send a private message $M$ to Bob. Alice found the public key of Bob, encrypted the message $M$ using Bob’s public key. The encrypted message for Bob is denoted as $C$.</p>



<p>Once Bob received the encrypted message $C$, he could decrypt $C$ using his private key.</p>



<p>Even if the network was compromised and someone intercepted $C$, it is still almost impossible to decrypt $C$ because of that $D_B$ is unknown and the feature “the publicity of $E$ does not compromise the secrecy of $D$” for public-key cryptosystems.</p>



<p>The message content is safe because of the public-key encryption systems. However, it does not provide any assurance about the sender. For example, James could send Bob a message $M^\prime$ which specifically says the message is from Alice, encrypt it using $E_B$, and send it to Bob. If there is no author verification procedure and Bob is not careful enough, Bob might actually think the message is sent from Alice. In some other scenarios, James might have intercepted the encrypted message $C$ sent out from Alice to Bob, prevented the message transmission to Bob, replaced the original message to $M^\prime$ which specifically says the message is from Alice, encrypt it using $E_B$, and send it to Bob. Bob might also be convinced that the message content $M^\prime$ was actually the original message Alice has sent. Specifically,</p>



<p>Digital signatures, derived from the public-key cryptosystems, are designed to solve these authentication problems.</p>

<h3 id="digital-signatures">Digital Signatures</h3>

<p>In addition to the encrypted message $C$ that Alice sent to Bob, Alice would also have to send her digital signature $S$ to Bob. Namely,</p>



<p>Alice could find $E_B$ using Bob’s public key and $D_A$ using her private key.</p>



<p>Once Bob received both $S$ and $C$, he could decrypt both $S$ and $C$ using his private key and Alice’s public key. Specially,</p>



<p>We found actually the two decrypted messages from $S$ and $C$ are exactly the same. This is expected if the message was sent from Alice and the content of the message was not modified. Let’s further see what will happen if someone pretends to be Alice to send a message to Bob, or the content of the message has been modified.</p>



<p>James, again, wanted to send Bob a message $M^\prime$ which specifically says the message is from Alice, or had intercepted an encrypted message $C$ from Alice, blocked it and created a message $M^\prime$ which specifically says the message is from Alice. To make the message readable by Bob, James encrypted $M^\prime$ using $E_B$, send the encrypted message $C^\prime$ to Bob.</p>



<p>Because Bob does not accept any message without a signature, James had to make up a signature. However, because James knew nothing about Alice’s private key, he used a decryption function $D_J$ which is different from Alice’s secrete $D_A$. The signature James generated would be</p>



<p>Once Bob received both $S^\prime$ and $C^\prime$, he could decrypt both $S$ and $C$ using his private key and Alice’s public key as usual. Specially,</p>



<p>In this case, Bob would see the two decrypted messages are not the same. Bob would then realize that there is something unusual happened and he should not trust anything about the message.</p>

<h3 id="hacking-the-public-key-cryptosystems">Hacking the Public-Key Cryptosystems</h3>

<p>As long as the four features of the public-key cryptosystems hold, cracking it is almost impossible. If somedayy, when the almighty quantum computer is available, the feature “the publicity of $E$ does not compromise the secrecy of $D$” would be compromised, therefore the modern public-key cryptosystems would no longer be reliable. I may talk about this topic in the future.</p>



<p>There is another way to send fake messages to Bob in name of Alice, without using a quantum computer. If James could somehow crack the account name and password of Alice on the web application, replace the Alice’s public encryption function from $E_A$ to $E_J$, when Bob tried to retrieve Alice’s encryption function, he would get $E_J$ instead of $E_A$. The decryption of signature $S^\prime$ would become $M^\prime$ instead of $M^{\prime\prime}$ then. Concretely,</p>



<p>In this case the two decrypted messages match. Bob would be convinced that the message is from Alice and it has not been modified.</p>



<p>It should be noted that James was replacing Alice’s public encryption function from $E_A$ to $E_J$, instead of replacing his private decryption function from $D_J$ to $D_A$. In principle, $D_A$ would only be kept on Alice local computer and not anywhere else. Even if James has Alice’s account name and password on the web application, he would not get a copy of $D_A$ unless he specifically hacked Alice’s physical computer.</p>



<p>This reminds us that actually keeping our password safe is the most important.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://sites.math.washington.edu/~morrow/336_09/papers/Yevgeny.pdf">The RSA Algorithm</a></li>
  <li><a href="https://www.youtube.com/watch?v=JR4_RBb8A9Q">What are Digital Signatures and How Do They Work?</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Public-Key-Cryptosystem-and-Digital-Signature/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009587</guid>
            <pubDate>Fri, 31 Jul 2020 15:28:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trancept Systems TAAC-1 – The first board-level GPGPU product]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009514">thread link</a>) | @magoghm
<br/>
July 31, 2020 | http://www.graphics-history.org/trancept/ | <a href="https://web.archive.org/web/*/http://www.graphics-history.org/trancept/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<ul>
  <li>
  Also see the <a href="http://www.graphics-history.org/index.htm">Computer
  Graphics History page</a> under construction</li>
  <li>Please <a href="mailto:nick@graphics-history.org?subject=Trancept%20Page">send
    me email</a> with corrections, additions, etc,</li>
</ul>
<h3>
 <a href="http://www.youtube.com/watch?v=9dHYdhE4-Gk">Video</a> - June
  1987 TAAC demo (no sound)<br>
 <a href="http://youtu.be/HPkBPwOujS4">Video Part 1</a>, <a href="https://www.youtube.com/watch?v=uHHOx2F9KGo">Part
2</a> - August 1987 TAAC demo<br>
 <a href="http://youtu.be/bBNQJe3EzWc"> Video Part 1</a>, <a href="https://www.youtube.com/watch?v=zl_LDstt-3w"> Part
2</a>, <a href="https://www.youtube.com/watch?v=Bpd-PsTxUA4"> Part 3</a>, <a href="http://youtu.be/GuTzBG4h22E">
  Part 4</a> - 1989 TAAC demo<br>
 <a href="http://youtu.be/kGS2K3UZPaU">Video</a> - 1989 TAAC Volume
  Rendering Movies<br>
 <a href="http://youtu.be/Sph4S8XxQTs">Video</a> - 1990 TAAC and VX/MVX
  Volume Rendering Movies<br>
 <a href="http://youtu.be/BHPNrvyap3k"> Video Part 1</a>, <a href="http://youtu.be/UGvmJ_odFC4"> Part 2</a> - September 1990 VX and MVX demo reel
</h3>
<table>
  <tbody><tr>
    <td><img src="http://www.graphics-history.org/trancept/trancept.jpg" width="305" height="381"></td>
    <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
    <td>
Trancept Systems Inc. was founded in January 1986 by Tim Van Hook, Mary Whitton,
and Nick England. Our goal was to develop a flexible, user-programmable, high performance
graphics and imaging accelerator for computer workstations.&nbsp; <p>

In the Spring of 1987 we introduced the TAAC-1 (Trancept Application
Accelerator) product for Sun Microsystems
workstations. The TAAC-1 consisted of two sandwiched PC boards, one full of video
RAM, the other full of a micro-programmed wide-instruction-word (200 bits)
processor optimized for graphics and imaging operations. The TAAC-1 was plugged
into and memory mapped onto the Sun's VME bus. The TAAC-1 was probably the world's first board-level GPGPU product.
Tim Van Hook was the chief architect and hardware designer and also wrote a ray
tracer and lots of other software for the processor. Paul Ramsey created the C
compiler and other tools that we used for creating TAAC programs. </p><p>

We had a brief but exciting life as a start-up company, developing the hardware
and demo software during 1986, introducing the product at the NCGA conference
in Spring 1987, and selling ourselves to Sun Microsystems in May 1987. At the time, Trancept consisted of the original trio
plus 7 other talented (and brave) souls who'd joined our start-up effort.
</p><div><p>The TAAC-1 continued to be marketed by Sun for several years and I'd guess almost 400 TAACs were sold. Sun's North Carolina
group went on to develop the <a href="http://www.graphics-history.org/trancept/sunvision-01.pdf"> SunVision</a> visualization toolkit, the <a href="http://www.graphics-history.org/trancept/mvx.htm">VX/MVX
accelerator</a>, and various video capture and compression boards before Sun
pulled the plug in 1994. </p><p>

There were lots of great people who were part of Trancept and Sun's North
Carolina group and we had lots of great (and patient) customers.&nbsp;Thanks
for the wonderful experience!</p></div>
    </td>
  </tr>
</tbody></table>
<hr>
<table>
  <tbody><tr>
    <td colspan="4">
      <h3>1987 - <a href="http://www.graphics-history.org/trancept/taac-87.pdf">download pdf </a>of this brochure</h3>
    </td>
  </tr>
  <tr>
    <td><a href="http://www.graphics-history.org/trancept/taac-br-1.JPG"><img src="http://www.graphics-history.org/trancept/taac-br-1_small.JPG" alt="taac-br-1.JPG (221651 bytes)" width="240" height="314"></a></td>
    <td><a href="http://www.graphics-history.org/trancept/taac-br-2.JPG"><img src="http://www.graphics-history.org/trancept/taac-br-2_small.JPG" alt="taac-br-2.JPG (342064 bytes)" width="240" height="314"></a></td>
    <td><a href="http://www.graphics-history.org/trancept/taac-br-3.JPG"><img src="http://www.graphics-history.org/trancept/taac-br-3_small.JPG" alt="taac-br-3.JPG (396836 bytes)" width="240" height="314"></a></td>
    <td><a href="http://www.graphics-history.org/trancept/taac-br-4.JPG"><img src="http://www.graphics-history.org/trancept/taac-br-4_small.JPG" alt="taac-br-4.JPG (335235 bytes)" width="240" height="314"></a></td>
  </tr>
  <tr>
    <td><a href="http://www.graphics-history.org/trancept/taac-br-5.JPG"><img src="http://www.graphics-history.org/trancept/taac-br-5_small.JPG" alt="taac-br-5.JPG (331473 bytes)" width="240" height="314"></a></td>
    <td><a href="http://www.graphics-history.org/trancept/taac-br-6.JPG"><img src="http://www.graphics-history.org/trancept/taac-br-6_small.JPG" alt="taac-br-6.JPG (109575 bytes)" width="240" height="314"></a></td>
    <td><a href="http://www.graphics-history.org/trancept/taac-br-7.JPG"><img src="http://www.graphics-history.org/trancept/taac-br-7_small.JPG" alt="taac-br-7.JPG (46891 bytes)" width="240" height="314"></a></td>
    <td>More stuff later</td>
  </tr>
</tbody></table>
<hr>
<h3>Sun's North Carolina development group - 1990?<br>
(Where's Tim? In Mountain View probably)</h3>
<p><a href="http://www.graphics-history.org/trancept/sun-nc-01.JPG"><img src="http://www.graphics-history.org/trancept/sun-nc-01_small.JPG" alt="sun-nc-01.JPG (654068 bytes)" width="480" height="338"></a></p>
<hr>
<h2>TAAC-1 Application Accelerator</h2>
<p>
For a summary of the system, see the <a href="http://www.graphics-history.org/trancept/taac-arch.pdf">TAAC-1 Technical Notes</a> 
 and for details, see the <a href="http://www.graphics-history.org/trancept/taac-user-01.pdf">TAAC-1 User's Guide</a> 
</p><p>
I wrote an <a href="http://www.graphics-history.org/trancept/sun-tech-TAAC1.pdf">overview article</a> for the Winter 1988
issue of Sun Technology Magazine.<br>
Mary Whitton wrote overview papers for <a href="http://www.graphics-history.org/trancept/ncga-mcw-87.pdf">NCGA '87</a>
and <a href="http://www.graphics-history.org/trancept/ncga-mcw-89.pdf">NCGA '89</a><br>

</p><p>
Results (from 1987 probably)
</p><p>
<img src="http://www.graphics-history.org/trancept/taac-timing.JPG" width="704" height="278">
</p><hr>
<p>
Lots of interesting and innovative code for the TAAC-1 processor got developed
by Tim Van Hook and other sharp Trancept and Sun folks, including:
</p><ul>
  <li>
    anti-aliased ray tracer
  </li><li>
    real-time 2D electric potential field simulator
  </li><li>
    real-time 2-D FFT
  </li><li>
    real-time image decoding animation (DCT before MPEG)
  </li><li>
    an extensive real-time 3-D graphics library
  </li><li>
    an extensive image processing package
  </li><li>
    volume rendering and other visualization tools
  </li><li>
    Renderman(tm) compatible photo-realistic renderer
</li></ul>
<p>
We provided customers with a C language microcode compiler and were strongly encouraged
(!) to develop their own code. They came up with all sorts of interesting
and imaginative ways to use the TAAC-1.<br>

</p><address>
  &nbsp;
</address>
<address>
  Jack Billman's memorial tree - 09/13/14<a href="http://www.graphics-history.org/trancept/billman-tree-1409.JPG"><br>
  <img src="http://www.graphics-history.org/trancept/billman-tree-1409_small.JPG" alt="billman-tree-1409.JPG (2891045 bytes)" width="240" height="180"></a>
</address>
<address>
  &nbsp;
</address>
<address>
  Back to Nick's Personal Home Page - <a href="http://www.virhistory.com/nick/">Nick England</a>
</address>
<address>
Last modified:&nbsp; <!--webbot bot="Timestamp" S-Type="EDITED"
  S-Format="%d %b %Y" startspan -->19 Mar 2020<!--webbot bot="Timestamp" endspan i-checksum="14895" -->
</address>

</div>]]>
            </description>
            <link>http://www.graphics-history.org/trancept/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009514</guid>
            <pubDate>Fri, 31 Jul 2020 15:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Think About Chess]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009477">thread link</a>) | @FailMore
<br/>
July 31, 2020 | https://taaalk.co/t/how-to-think-about-chess#r | <a href="https://web.archive.org/web/*/https://taaalk.co/t/how-to-think-about-chess#r">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <div id="tlk-section-read">
    



<div>

    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I'm a keen, but not very accomplished, chess player. I'm looking to understand the basics of good chess strategy.</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I started playing chess when I was 6, and played seriously until the age of 18. My career highlights include 30th in the European U18s, captaining/vice-captaining England at most age groups, playing for Oxford in 3 Varsity matches and achieving rankings of 195 ECF and 2200 FIDE. I'm a software engineer at <a href="https://stripe.com/">Stripe</a> and blog at <a href="https://robertheaton.com/">robertheaton.com</a>.</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    

</div>

  </div>







  <div>

      <div id="1">
        <div>
          
          <p>Admin</p>
          <p>13:27, 06 May 20 (edit: 13:28, 13 May 20)</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>This Taaalk was written on the first version of Taaalk in 2016.</p></div><div><p>The archive.org version is available <a href="https://web.archive.org/web/20160427012637/http://taaalk.co/taaalk/chess/robert-heaton-josh-summers">here</a>.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="2">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:08, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>A lot of people write about chess as having an opening game, a middle game and an endgame. When you're playing is that what's going through your head?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="3">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:08, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Everyone has an opening repertoire. Many people just have one answer for each question they might reasonably expect their opponents to ask, which means they get very good at playing those answers, but equally become very predictable. There are some openings that are razor sharp and precise, and require knowing many 15-20 move variations in order to not get destroyed without the game even starting. I personally prefer openings that are more conceptual, which tend to be slightly more flexible, require much less knowledge, but arguably lead to somewhat more boring positions because of this.</p></div><div><p>So when the middlegame comes around, it's probably the kind of position I've played many times before. My strategy is usually to throw lots of pieces at their king and hope they die or I can win some material. Since I'm hoping to win at this point, I probably don't start thinking explicitly about the endgame until little suggestions of things that might become relevant start cropping up. So if pawns become isolated or doubled, or we end up with opposite colored bishops, or with a bishop on the same color square as most of our pawns, etc. If I can take one of these small positional advantages then I will, and then effectively "bank" it until the endgame actually comes around. Having one or more of these might make me more likely to head towards an endgame too.</p></div><div><p>Endgames are really hard and require a lot of technique that I don't really have. Fortunately most other people don't either, because you just don't get to play that many of them.</p></div><div><p>It probably is fair to say that I'm pretty aware of the opening/middlegame/endgame distinction. The opening is where I'm playing pretty much from memory, the middlegame is where I try and win, and the endgame is what I might head towards if I think I have a tangible advantage but try and avoid otherwise.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="4">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:08, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So when you say that the endgame is what you might head towards - is the endgame not just the 'end of the game'? In which case won't most games have one? I know in the extremely amateur world of chess that I play in that most games come to a end where one side is actively checkmated. Is the endgame more unusual the higher up you go because a party will often resign when one side is in a dominant position?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="5">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:10, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>I guess this is a question for statistics to answer properly, but my gut says that there possibly are fewer endgames in higher level play. If you lose a bishop or a knight without any obvious compensation, you will almost definitely resign on the spot. That said, it's probably also true that fewer boneheaded mistakes mean that neither side may have had much of a chance to win before the endgame. Overall I'm not sure!</p></div><div><p>But when I say "might head towards the endgame", I mean that I might deliberately choose to swap off pieces and accelerate progress towards the end of the game. If I'm a pawn up then trading off pieces is likely a huge win for me, because whilst a queen + 2 rooks + 1 bishop + 2 knights + 7 pawns v the same but 6 pawns is not a huge advantage, a bishop + 5 pawns v a bishop + 4 pawns probably is. Small material advantages are a much bigger deal in the endgame and leave less room for your opponent to generate compensation, so if you are slightly ahead then deliberately swapping off pieces is very important. Games can naturally meander towards an endgame where neither side is too psyched about their chances, or they can be forced.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="6">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:10, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>OK - that makes a lot of sense. You mentioned that you like to keep your openings of a 'conceptual' nature. What kind of concepts are you basing your openings on?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="7">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:10, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Honestly I like openings that allow you to put your pieces on nice squares without thinking too hard, and then throw them all at your opponent's king. This is not a very sophisticated strategy, but it can be very hard to deal with if you aren't prepared (this is a good example). If you can get off the beaten track without doing anything too insane then you become much more familiar with the kinds of positions that result than your opponents, and develop a big box of patterns that have worked in the past.</p></div><div><p>This becomes somewhat less effective the higher level and more famous you get, as you start to become notorious for particular openings, and opponents can start preparing counters to them. This is where a degree of flexibility and unpredictability becomes invaluable, so that your opponents can't just put all their time into preparing for your Stonewall Dutch or Trompowsky, and also have to keep in mind that you might throw in a Benko Gambit or English Opening. It can be worthwhile playing these alternatives in high profile tournaments that will get their games into databases that your future opponents will see and get confused and upset by.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="8">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:11, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>The part on variation makes a lot of sense. So what are nice squares and what makes them nice?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="9">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:11, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>"Nice" squares is obviously a super-vague concept, but in this situation I mostly just mean:</p></div><div><p>Knights in the middle of the board</p></div><div><p>Bishops pointing towards the king</p></div><div><p>Rooks on open files or behind pawns that are marching towards their king</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="10">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:11, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>OK - now we're warming up!! A few things to deal with:</p></div><div><p>1) Why is it good to have knights in the middle of the board?</p></div><div><p>2) Why is it good to have bishops pointing at the king?</p></div><div><p>3) And i) what is an open file? and ii) why do I want my rook on it?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="11">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:12, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>1) Knights on the edge of the board don't attack many squares, knights in the centre of the board do. Because of their uniquely short range, they are the one piece that really benefits from being in the centre. A rook or bishop in the corner can still rake across the entire board, but a knight in the same spot looks pretty dumb.</p></div><div><p>2) If you want to attack the king (I do), you need to have your pieces attacking him and the squares around him! Even if you aren't planning on immediately checkmating anytime soon, you may be able to use threats against him to force smaller concessions or weaknesses.</p></div><div><p>3) An open file is one that isn't blocked by any of your pawns or pieces, and so if you put a rook at one end of it you'll be probing into some part of their position (hopefully a weak part!). This is the most direct way for your rooks to influence the game. As mentioned above, you don't necessarily need to be destroying or capturing anything in order for your pieces to be making your opponents' life awkward, so principles like "rooks on open files" will almost always be good things to at least look out for.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="12">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:14, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Right. Would you say you're setting yourself up in the strongest position possible to deal with the largest number of variations down your opponents end (defensive) or setting yourself up to maximise your attacking options? Or a balance of the two?</p></div><div><p>When I'm playing with friends sometimes it feels like there is an unspoken agreement to let the other player 'set up' so to speak. To get their pieces into the strongest structural position before the WAR takes place. When you're playing is this something that happens? Or are you looking to start WAR while you set up your …</p></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://taaalk.co/t/how-to-think-about-chess#r">https://taaalk.co/t/how-to-think-about-chess#r</a></em></p>]]>
            </description>
            <link>https://taaalk.co/t/how-to-think-about-chess#r</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009477</guid>
            <pubDate>Fri, 31 Jul 2020 15:19:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing Between ActiveMQ and Kafka based on messaging semantics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009298">thread link</a>) | @bibryam
<br/>
July 31, 2020 | http://www.ofbizian.com/2020/07/choosing-between-activemq-and-kafka-for.html | <a href="https://web.archive.org/web/*/http://www.ofbizian.com/2020/07/choosing-between-activemq-and-kafka-for.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The term asynchronous means “not occurring at the same time” and in the context of distributed systems and messaging it implies that the processing of a request occurs at an arbitrary point in time. There are many advantages of asynchronous interactions over synchronous ones but also new challenges introduced by it. In this post, we will focus on a few specific considerations for choosing a suitable asynchronous messaging infrastructure for implementing <a href="https://developers.redhat.com/topics/event-driven/" target="_blank">event-driven</a> systems. Let’s see a few of the subtle differences between asynchronous interaction styles.<br></p><h2>Message Business Value</h2><p>Not all messages are created equal. Some are valid and valuable only for a short period of time and obsolete later. Some are valuable until they are consumed regardless of the time passed. And some messages are valid and useful for repeated consumption. Considering the validity and the value of messages relative to time and consumption rate, we can qualify interaction styles between services into the following categories:</p><div><p><a href="https://1.bp.blogspot.com/-p9AE1uCT-lY/XyQrM2kw2LI/AAAAAAAAOi8/9VSsF63jc_0u3NSab9nn5nYwCtS4fce_QCLcBGAsYHQ/s2576/business_value.png"><img alt="Message types by business value" height="136" src="https://1.bp.blogspot.com/-p9AE1uCT-lY/XyQrM2kw2LI/AAAAAAAAOi8/9VSsF63jc_0u3NSab9nn5nYwCtS4fce_QCLcBGAsYHQ/d/business_value.png" title="Message types by business value" width="400"></a><br><i>Message types by business value</i></p><h4>Volatile</h4><p>These are ephemeral messages where the value is time-bound. Valuable now, but not in the short future. There is no point in storing events that are useless in the future and using messaging systems with such characteristics gives the best performance with the lowest latency possible as the disk is skipped. In such a scenario, the system is aware of the connected consumers and the event disseminated to all consumers online at the time of publication. If a consumer is disconnected, the messaging system forgets about these consumers. What is important in such a system is the ability to handle a large number of dynamic clients with low latency interaction needs such as IoT devices.</p><h4>Durable</h4><p>However, in some situations you want the messaging system to be aware of the consumers and store the messages while the consumer is not available. That is a traditional message broker which will hold on to the messages for the consumers that he knows about and allow the consumers to re-connect and consume the events that were produced in his absence. Once an event is consumed by all the interested parties, it will discard the messages. Here the broker knows about registered consumers and messages are stored durably until read by all registered consumers. Here the goal is to do reliable messaging among services with strong ordering and delivery guarantees.</p><h4>Replayable</h4><p>Here, the messaging system is not aware of the consumers that are interested in the event. It simply stores the events published to a stream for some time or until capacity is reached. Then a consumer can come along at any time, connect and consume the events and perhaps replay the stream from the beginning. Consumers can move back and forth in the stream as required and replay the messages repeatedly. Here, the driving force is extreme scalability combined with the ability to replay messages for existing or new consumers.</p><h2>Message Semantics</h2><p>Apart from the technical characteristics of the messages, it is important to distinguish the language we use, the semantic aspects, and the intent of the interactions. Some messages are targeted for a specific consumer and demand concrete actions. Some are querying the latest state of a system without requiring a state change. And some notify the world about a change that has happened in the source system. From a messaging semantic perspective, there are the following types of messages:</p><p><a href="https://1.bp.blogspot.com/-RMxJzN21Bbk/XyQrihOt9FI/AAAAAAAAOjE/3jg_mU4oqN0WB1G8OOqQ43FC2JNmt5yMACLcBGAsYHQ/s2568/Screenshot%2B2020-07-28%2Bat%2B07.39.01.png"><img alt="Message types by semantics" height="135" src="https://1.bp.blogspot.com/-RMxJzN21Bbk/XyQrihOt9FI/AAAAAAAAOjE/3jg_mU4oqN0WB1G8OOqQ43FC2JNmt5yMACLcBGAsYHQ/d/Screenshot%2B2020-07-28%2Bat%2B07.39.01.png" title="Message types by semantics" width="400"></a><i><br></i></p></div><p><i>Message types by semantics</i></p><div><h4>Command</h4><p>A command is a request for action that usually leads to a state change on a known target system. Typically there is a response indicating that action was completed and even there might be a result associated with it. When a response is expected, commands are typically implemented over synchronous protocols such as HTTP, but it is possible to implement request/response or fire and forget style commands over asynchronous messaging systems. With a command based asynchronous messages, there is some coupling between the source and the target systems in the form of command semantics.</p><h4>Query</h4><p>A query is like a command, but it is a read-only interaction that does not lead to a state change. By its very nature, a query expects a response, and it is common to see synchronous implementations here. But asynchronous and non-blocking implementations over messaging systems and even fire and forget style interactions for long-running operations where a response is written to a different location are common too.</p><h4>Event</h4><p>An event is a notification that something has changed. A system sends event notifications to notify other systems for a change in its domain. An event is different from a command in that often the event emitting system doesn’t expect an answer at all. In addition to being asynchronous, event messages are not targeted to a specific recipient and thus, they enable even further decoupling. Similar to other asynchronous interactions, events are implemented as messages on queues, which are often called streams. Martin Fowler covers in-depth the different types of events in <a href="https://www.youtube.com/watch?v=STKCRSUsyP0" target="_blank">this</a> talk.</p><h2>Summary</h2></div><div><p>One approach you can take is to follow the <a href="https://en.wikipedia.org/wiki/Law_of_the_instrument" target="_blank">Law of the Instrument</a> approach defined by Maslow as “If the only tool you have is a hammer, treat everything as if it were a nail." You could certainly use a classic message broker such as Apache ActiveMQ to implement the different interaction styles. It would be a familiar technology to many and easier to start with, but hard to implement some use cases such as replayable messaging. Or you could take the other extreme and try to use Apache Kafka for everything. It would require a larger amount of hardware resources and human effort to manage it, but it would cover the replayable messaging and extreme scalability needs. While both of the above approaches are fine to start with, when you have a large number of services with different messaging needs, using the right tool for the right job is a better option. We can map the above-described messaging patterns to see what messaging infrastructure is best suited for each.</p><p><a href="https://1.bp.blogspot.com/-MTuOiuBjh48/XyQr8TVfwuI/AAAAAAAAOjQ/JwY1yhgOkGY8l-upOVl2vqR9kvYdXh9tQCLcBGAsYHQ/s2768/Screenshot%2B2020-07-28%2Bat%2B07.39.17.png"><img alt="Mapping messaging subtleties to different messaging infrastructures" height="135" src="https://1.bp.blogspot.com/-MTuOiuBjh48/XyQr8TVfwuI/AAAAAAAAOjQ/JwY1yhgOkGY8l-upOVl2vqR9kvYdXh9tQCLcBGAsYHQ/d/Screenshot%2B2020-07-28%2Bat%2B07.39.17.png" title="Mapping messaging subtleties to different messaging infrastructures" width="400"></a><br><i>Mapping messaging subtleties to different messaging infrastructures</i></p><p>We at Red Hat love any open source technology. That is why we included Apache Qpid, Apache ActiveMQ Artemis, and Apache Kafka in our <a href="https://www.redhat.com/en/technologies/jboss-middleware/amq" target="_blank">Red Hat AMQ</a> product and let the customer choose the right tool for the right job. There are many other aspects to consider when choosing the right tool, I hope this post will help you get there one step closer.</p></div><p><i>This post was originally published on Red Hat Developers. To read the original post, check <a href="https://developers.redhat.com/blog/2020/07/31/choosing-the-right-asynchronous-messaging-infrastructure-for-the-job/" target="_blank">here</a>.</i></p>



</div></div>]]>
            </description>
            <link>http://www.ofbizian.com/2020/07/choosing-between-activemq-and-kafka-for.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009298</guid>
            <pubDate>Fri, 31 Jul 2020 15:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compile Time, Binary Size Reductions and C++’s future for sol3]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009272">thread link</a>) | @flipchart
<br/>
July 31, 2020 | https://thephd.github.io/sol3-compile-times-binary-sizes | <a href="https://web.archive.org/web/*/https://thephd.github.io/sol3-compile-times-binary-sizes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>This is going to be a practical overview of how I reduced the compilation time and binary sizes of Release Mode (-O3 or /Ox) C++ software. The goal of this will be to review some of the things that help with the goal, and some of the things that C++ as a language is fundamentally incapable of producing satisfactory answers to. Let’s<!--more--> dig in!</p>



<p>We were able to save some things for a project with 2.5K class bindings:</p>

<table>
  <tbody>
    <tr>
      <td>Version</td>
      <td>sol2</td>
      <td>sol3 (patron-only alpha)</td>
      <td>sol3 (now)</td>
    </tr>
    <tr>
      <td>Build Time</td>
      <td>2 hours, 3 minutes</td>
      <td>2 hours, 11 minutes</td>
      <td>1 hour, 53 minutes</td>
    </tr>
    <tr>
      <td>Binary Size</td>
      <td>119.0 MB</td>
      <td>138.0 MB</td>
      <td>103.0 MB</td>
    </tr>
  </tbody>
</table>



<p>I added 3 new core template types that all abstractions get milled through. I also committed some of the sins below in improving the functionality and streamlining the code. To be honest, I’m actually surprised it only cost me 7 more minutes over sol2! But, let’s talk about the things I did in order to get to where we are now, and what I needed to identify as problem points…</p>



<p>This was a combination of intuition and empirical evidence. I had suspicions about what increased my compile time, but I did not want to go off on a wild hunt trying to figure out what was going on. Much as Templight and other tracers exist (and are <a href="http://aras-p.info/blog/2019/01/16/time-trace-timeline-flame-chart-profiler-for-Clang/">currently being worked on</a>) I kept my assumptions in the back of my mind but checked them by asking a few companies and individual users of sol2 to send me their largest object files VIA Discord and other means:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/biggest-you-have.png" alt="Mmmn, girthy."></p>

<p>In doing so, I could confirm my suspicions by seeing what was serialized into the object file. Note that while this does not perfectly translate to the final code (especially in release builds), it is a good proxy for (1) link times, due to having to resolve all of the (possibly non-unique) definitions from a single object file with all the others in the project; and (2) compile times, because the compiler has to vomit all of this stuff into these object files to begin with.</p>

<p>One of the object files I studied was 14 megabytes big from a Visual Studio 2017 Release build. the fun started when I expanded the <code>.7z</code> file:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/file-sizes.png" alt="Goodness...!"></p>

<p>Mama mia that’s a spicy 16.4x file size increase!</p>

<p>This is a screaming red flag that we have a LOT of redundancy (because it compresses so obscenely well under default settings). Duplicate symbols are rife in any TU that heavily uses templates, and sol3 <em>is</em> a template-heavy, header-only library. But, this probably doesn’t explain the absolute ballooning in size when going from the packed 7zip I was sent to the big thing in the actual binary.</p>

<p>To help me dig in, I <a href="https://twitter.com/chieltbest">relied on someone else</a> who did all the hard work for benchmarking what were the more expensive operations one could perform in relation to templates. I also use this brilliant person’s Rule of Chiel:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/rule-of-chiel.png" alt="The Rule of Chiel"></p>

<p>Armed with this knowledge and a bunch of object files, I set off to find the worst offenders in my code. I targeted what was either SFINAE + types, or SFINAE + function templates, since those were my typical things that destroyed my code. sol2 uses a lot of struct specialization SFINAE, which is probably the most damaging to compile-times right now. Coupled with some very gnarly function template SFINAE and other things, I figured that this and other things were probably the root of the cause.</p>

<p>Just where I found that bloat – asides from the obvious places where I used exactly those techniques – was even more of a surprise…</p>



<p>Lambdas are ultra convenient and – in some cases – even more powerful than structs you declare locally (for example, you can’t template function-local structs but you can do it with a lambda and <code>auto</code>/Concept function argument types!) But, I needed to tear them down in several places where I had capturing lambdas inside of templated code. I only did this in a handful of places – 6 or 7 total in the whole library, up from 1 or 2 in sol2 – and it did a fair amount of to save me the mental overhead when programming. They’re just Immediately Invoked Function Expressions, right? How costly can they be?</p>

<p>It turns out capturing Lambdas – even entirely local ones – don’t optimize out cleanly in terms of <em>code size</em> for C++ and a lot of it gets dumped into the object file and the resulting executable. I used <code>dumpbin</code> to get me all the symbols in a text file (an 11 megabyte text file) and then proceeded to just goof around and scroll through it. Some things there was nothing I could do about, like all the string spam for my Compile-Time Type Strings work I was doing. But, for this 1 object file where only 1 class was being bound using an alpha of sol3, I ran a count for the times <code>lambda</code> showed up:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/lambda-count.png" alt="Goodness Gracious..."></p>

<p>Sheesh… a few more pointed searches for certain identifiers with the lambda revealed that most of those belonged to my detail namespaces and inner workings. Remember, this is just for binding one class! All this symbol spam from the template-capturing lambdas revealed one thing, though: <em>each lambda, when inlined, results in a fat slab of code that is different per-instantiation</em> (I mean, duh, that’s the point of a template, right?). The compiler marks all of this code inline and dumps it into the resulting function instantiation, which is expected. The problem is that capturing all the variables in a templated function means that any time you have enough variable initializations and function declarations that depend on said templates, it is impossible for the optimizer to combine these bits of code together, even if its fundamentally the same code for all invocations!</p>

<p>The solution here was to roll up my sleeves and get out the dough, because it was time for…!</p>

<p><img src="https://thephd.github.io/assets/img/pexels/baked-baking-chef.jpg" alt="Only the best ingredients for your code base."></p>

<p>
🥖🥖 A R T I S A N A L 🥖 H A N D - C R A F T E D 🥖 L A M B D A S 🥖🥖
</p>


<p>Since the 1990s, like your mothers and their mother’s mothers, and your fathers and their father’s fathers, I took to the oven to bake only the freshest lambda to trump them all, taking advantage of the fact that all of the routines were identical and that I could use some of Grandma’s <code>void*</code> and Great Aunt Mary’s function pointers. To top that off, Lua is a runtime ingredient so all the compile-time shenanigans weren’t exactly necessary at the point of my lambda. I lowered down my <code>if constexpr</code> spices into regular <code>if</code> statement herbs, powered by runtime booleans initialized with constant expressions. The result was a creamy yet spicy French struct with so many delicious members. Ultimately a reduction but the culinary blend saved me quite a bit of symbol spam in the object file and lambda-based template spew by quite a bit, making for some <em>chef kiss</em> nice improvements:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/artisanal-lambda.png" alt="Artisanal hand-crafted lambdas"></p>

<p>Food silliness aside, this helped a lot. To recap the point in a more clear way, though, here are some snippets illustrating the various degrees of (non-)trouble you can get yourself into.</p>

<p>Good:</p>

<div><div><pre><code><span>void</span> <span>func</span> <span>()</span> <span>{</span>
	<span>auto</span> <span>iife</span> <span>=</span> <span>[]()</span> <span>{</span>
		<span>/* work */</span>
	<span>};</span>
	<span>iife</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Also good:</p>

<div><div><pre><code><span>void</span> <span>func</span> <span>(</span><span>int</span> <span>arg</span><span>,</span> <span>my_class</span><span>&amp;</span> <span>foo</span><span>)</span> <span>{</span>
	<span>auto</span> <span>iife</span> <span>=</span> <span>[</span><span>&amp;</span><span>]()</span> <span>{</span>
		<span>/* work */</span>
	<span>};</span>
	<span>iife</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Okay, but be careful…:</p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>void</span> <span>func</span> <span>(</span><span>T</span> <span>arg</span><span>,</span> <span>my_class</span><span>&amp;</span> <span>foo</span><span>)</span> <span>{</span>
	<span>auto</span> <span>iife</span> <span>=</span> <span>[</span><span>&amp;</span><span>]()</span> <span>{</span>
		<span>/* work */</span>
	<span>};</span>
	<span>iife</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Worse:</p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>,</span> <span>typename</span><span>...</span> <span>Args</span><span>&gt;</span>
<span>void</span> <span>func</span> <span>(</span> <span>my_class</span><span>&amp;</span> <span>foo</span><span>,</span> <span>Args</span><span>&amp;&amp;</span><span>...</span> <span>args</span><span>)</span> <span>{</span>
	<span>auto</span> <span>iife</span> <span>=</span> <span>[</span><span>&amp;</span><span>]()</span> <span>{</span>
		<span>/* work */</span>
	<span>};</span>
	<span>iife</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p><em>Screaming in the distance:</em></p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>Binding</span><span>&gt;</span>
<span>struct</span> <span>binding</span> <span>{</span>
	<span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>,</span> <span>typename</span><span>...</span> <span>Args</span><span>&gt;</span>
	<span>void</span> <span>func</span> <span>(</span><span>my_class</span><span>&amp;</span> <span>foo</span><span>,</span> <span>Args</span><span>&amp;&amp;</span><span>...</span> <span>args</span><span>)</span> <span>{</span>
		<span>auto</span> <span>iife</span> <span>=</span> <span>[</span><span>&amp;</span><span>]()</span> <span>{</span>
			<span>/* work */</span>
		<span>};</span>
		<span>iife</span><span>();</span>
	<span>}</span>
<span>};</span>
</code></pre></div></div>

<p>Of course, this is easy to see in these examples. But when working with complex template functions, it’s very easy to just make a fully-capturing lambda that gets you all the local variables and arguments you need with very little fuss. Just be careful if it’s a common use point in your API, and especially if there is a forwarding capture reference and you are expected to have string literals come into your API. String literals are actually the worst offenders for the bloat, because <code>"set"</code> is not the same type as <code>"super_set"</code> (they’re both different-sized C-style arrays).</p>

<p>Having a (imaginary) <code>std::c_string_view</code> or some <code>std::string_literal</code> <code>constexpr</code> type be the default here might help that out but I doubt the C++ Committee will ever bite on a <code>std::string_literal</code>-by-default type anytime soon. (After all, backwards compatibility etc. etc. – someone is bound to be broken if we change the fundamental type of <code>"blah"</code> in C++!) But, what may happen is a <code>std::string_literal</code> type that can <em>only</em> be created magically by the compiler. This will give us some interesting information to work with (read-only, string is interned, etc.), and from there we could probably at least fix some of C++’s strange warts, even if we still get <code>const char[N]</code> and <code>const char*</code> from template deduction and <code>auto</code>-deduction.</p>

<p>The point being, if you expect <code>my_template_f("blah")</code> to be a thing your users write, be careful!</p>



<p>Is anyone really surprised this shows up?</p>

<p>Parsing stuff in C++ is its own particularly special nightmare. I provided a <code>sol_forward.hpp</code> to ease on this parsing adventure. But I didn’t really put enough stuff in there. So I added some more forward declarations in there for sol3, and now the single header generates a proper <code>sol/sol.hpp</code> and a <code>sol/forward.hpp</code> for users to include. The result was pretty good gains:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/forward-declarations.png" alt="forward.hpp bringing huge benefits."></p>

<p>Forward declarations are good. Honestly, we should probably be providing very small Modules for the standard library, and also be providing incredibly fine-tuned headers too. <code>&lt;functional&gt;</code> alone is absolutely enormous, and it would be nice if we just had <code>&lt;functional_fwd&gt;</code> when we really don’t need the whole thing. I have some ideas in this space, but it’s going to take some time before I can let it manifest. (I have a lot to do over the next 3 years…!)</p>



<p>Tag dispatching – while a good technique – results in the compiler having to pick between overloads, even if its only 2. The worst part about any overload set is that the compiler cannot short circuit what it finds: it needs to walk over all of the possible function entities in an overload set before selecting the right one.</p>

<p>My tag dispatching code was …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/sol3-compile-times-binary-sizes">https://thephd.github.io/sol3-compile-times-binary-sizes</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/sol3-compile-times-binary-sizes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009272</guid>
            <pubDate>Fri, 31 Jul 2020 15:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Creating a Board Game Is Like Writing Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009223">thread link</a>) | @ddorosz93
<br/>
July 31, 2020 | https://nerdstack.io/creating-board-game-is-like-writing-software/ | <a href="https://web.archive.org/web/*/https://nerdstack.io/creating-board-game-is-like-writing-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-94" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>For the past month or two, my brother, a friend of ours, and I have been working on creating a new board game. All three of us are extremely into board games and have always wanted to create one. It’s been really fun, but definitely not easy.&nbsp;</p>



<p>When making a board game, there are a ton of edge cases and variables you have to consider. You have to run tests, fix issues and iterate on things that may need some improvement. This entire process made me realize that making a board game is a lot like writing software. It’s so similar in fact, that I believe creating a board game should be an activity done in schools to teach younger (and older) students the benefits of planning, thinking about edge cases, extensibility, iteration and probably more that isn’t popping into my head right now.&nbsp;</p>



<p>The first step in board game creation was thinking of an idea and refining it into a general set of rules. This is very similar to software where once you think of an idea, you have to define a set of features and acceptance criteria. There are many things that we originally wanted to include but felt didn’t offer enough benefit, maybe even added confusion, so we left them out. We also had to think about whether the board game was fun at each step of the process, similar to thinking about if your software is adding value.</p>



<p>Once we had our general idea, we started thinking about edge cases. What happens if a player does this, what happens if they do that. In software you have to do the same thing. The difference is that in software (at least nowadays) you usually have the opportunity to go back and fix some of the edge cases after releasing it. With the board game, our goal is to fund it and release it. Once you release a board game, you can’t just patch it whenever you like. Any edge cases you may have missed are now there for people to run into (or exploit).&nbsp;</p>



<p>Ok, so you finished writing your software… I mean… finished creating your first board game prototype. Now what? Well you have to test it. There’s no such thing as automated testing for board games, so you have to play test it. This is the most lengthy process of the creation process (At least so far. This is the stage we’re at now.). As you test, you’ll notice certain mechanics that don’t work, and have to patch them. This is similar to fixing bugs or improving on certain features in software.</p>



<p>Once you’ve finished play testing it and feel confident in your board game, that’s when you can start releasing it to the public. This requires you to write the rules in a way that is understandable to your target audience. Similar to software, documentation is very important. In software, documentation can take many different forms; API docs, instruction manuals, etc. Each of these documents has a different target audience and should be written with that target audience in mind. When writing the rule book for your board game, know your target audience.&nbsp;</p>



<p>There is one other aspect of board game creation that might not apply to all board games but is a good thing to keep in mind. Expansions. A lot of board games come with expansion packs. The only way you can create an expansion pack is if you created your board game in a way that allows for this sort of extensibility. This is very similar to how in software you don’t want to write spaghetti code and should always keep extensibility in mind.&nbsp;</p>



<p>Creating a board game has been super fun and rewarding. It made me realize that I can put my software engineering skills to use in other areas seemingly unrelated. I believe that creating a board game, and maybe even converting it to code should be an activity done in schools in software courses.&nbsp;Especially for younger students who may not be interested in software yet.</p>



<p>This is my insight into board game creation and how it relates to software. Feel free to email me at <a href="mailto:ddorosz@katsudo.io">ddorosz@katsudo.io</a> if you have any questions, want to chat, or are interested in finding out more about the board game and when we plan on releasing it.&nbsp;</p>

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://nerdstack.io/creating-board-game-is-like-writing-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009223</guid>
            <pubDate>Fri, 31 Jul 2020 14:56:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collections: Bread, How Did They Make It? Part II: Big Farms]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24009134">thread link</a>) | @jrott
<br/>
July 31, 2020 | https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the second part of our look at the basic structure of food production (particularly grains to make bread) in the pre-modern world.  <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">Last week</a>, we began by looking at the great majority of our rural population, the little farmers.  Now I know everyone is eager to get to the mechanics of planting, harvesting, threshing, milling, baking and so on, but we have one more group of people in the countryside to talk about: the much smaller group of larger landholders, or as they are often generally referred to, the ‘big men.’</p>



<p>Now I should begin by noting that not all of our ‘big men’ are, in fact, men – though most were.  Exactly how many large rural landholders are women varies from one pre-modern society to the next (though it is almost always a minority), but it was generally not zero, save in a relative handful of societies which specifically <em>completely </em>barred women from independent landholdings by law (some Greek <em>poleis</em> did this, for instance); even in sharply patriarchal societies like Rome, there would always be a handful of great estates run by women, particularly widows.  Nevertheless ‘big man’ (or ‘big person’) is a fairly common way to refer to these fellows across languages (for instance, magnates from Latin <em>magnati</em>, literally ‘big men,’ mirrored by the Greek μεγιστᾶνες (‘big men’) which has the same meaning; ‘grandees’ has the same sense, coming from Portuguese).  I don’t want to use many of the language-specific terms because they often come with additional meaning – we could call these fellows ‘nobles’ or ‘aristocrats’ or ‘the gentry’ in various times and places, but these terms often imply rigid social classes which don’t apply cross-culturally (and in many cases might have no real equivalent in societies which still have recognizable rural ‘big men’).  Almost all of these traditional terms for the ‘big men’ (who again, are not all men) are loaded with some sort of meaning which won’t do for our very general look at the basic structures of pre-modern cereal agriculture.</p>



<p><strong>So instead, I am going to go with the somewhat clinical and bland “large landholders”</strong> most of whom are men (but some of whom are women), but <strong>all of whom hold lots of land</strong>.  But what I want to stress is that these fellows were understood as being ‘big’ in the sense that they held a lot of agricultural <em>capital</em> but <em>also</em> generally ‘big’ in the sense that they dominated, socially and politically, their societies (notice though how the words used to describe them above often <em>also</em> imply ‘bigness’ of ability or character – like ‘noble’ – they certainly <em>believed this about themselves</em> and they write most of our sources; one assumes the  peasantry viewed the matter quite differently, though they only infrequently get a chance to say it to us).  Now I know that capital is a scary word in some quarters, worry not.  We are going to use it in a fairly simple, direct way just to mean all of the things – land, animals, equipment, infrastructure – which make farming productive.  While these large landholders <em>almost always</em> represent a legally or socially privileged class,<strong> what matters for us is how their large landholdings and capital reshaped farming in the countryside</strong>.  I am not going to get too deep into the landholders themselves beyond these effects – they already get <em>quite enough</em> attention in their role as military, political and cultural elites as it is (<a href="https://acoup.blog/2020/05/22/collections-the-battle-of-helms-deep-part-iv-men-of-rohan/">even </a><a href="https://acoup.blog/2019/12/12/collections-a-trip-through-cicero-natural-law/">elsewhere </a><a href="https://acoup.blog/2019/12/05/collections-a-trip-through-thucydides-fear-honor-and-interest/">on </a><a href="https://acoup.blog/2020/04/16/collections-a-trip-through-bertran-de-born-martial-values-in-the-12th-century-occitan-nobility/">this </a><a href="https://acoup.blog/2020/03/27/a-trip-through-dhuoda-of-uzes-carolingian-values/">blog</a>).</p>



<p><strong>So how do these large landholders function in a countryside mostly composed of small subsistence farmers?</strong>  Let’s walk out of the village and up to the manor and find out.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>(Also as a reminder, the selected bibliography for all of this is back <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">in the first post</a>.)</p>



<figure><img data-attachment-id="3985" data-permalink="https://acoup.blog/104852001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg" data-orig-size="2500,1931" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="104852001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Via the British Museum (<a href="https://www.britishmuseum.org/collection/object/P_1858-0626-227">inv. 1858,0626.227</a>), a c. 1720 drawing of Italian farmers working their fields outside of the ruins of the Baths of Caracalla at Rome.</figcaption></figure>



<h2>Farming Capital</h2>



<p>What generally defines our large landholders is their greater access to <em>capital</em>.  Now we don’t want to think of capital in the sort of money-denominated, fungible sense of modern finance, but in a very concrete sense: land, infrastructure, animals, and equipment.  As we’ll see, it isn’t just that the big men hold more of this capital, but that they hold fundamentally different <em>sorts</em> of capital and often use it very differently.</p>



<p>Of course this begins with <strong>land</strong>.  The thing to keep in mind is that prior to the modern period (really, later still – we might equally say prior to the industrial revolution; c. 1760 instead of c. 1500) the vast majority of economic activity was the production of the land.  That meant that land was both the primary form of holding wealth but also the main income-producing asset.  <strong>Consequently, larger land holdings are the assets that <em>enable</em> the accumulation of all of the other kinds of capital we’re discussing</strong>.  By having more land – typically <em>much</em> more land – than is required to feed a single household, these larger farmers can (as we’ll discuss in a bit) produce for markets and trade, enabling them to afford to acquire labor, animals, equipment and so on.  Our subsistence farmers of the last post, focused on producing for survival, would be hard-pressed to acquire much further in the way of substantial capital.</p>



<p>The next most important category is generally <strong>animals</strong>, particularly a <strong>plow team</strong> (typically two oxen, but sometimes draft horses and sometimes four instead of two).  I realize I didn’t spell this out explicitly in the previous piece, <strong>but while our small subsistence farmers may keep chickens or pigs on some small part of the pasture they have access to, they probably <em>do not</em> have a complete plow-team for their own farm</strong> (but I should note there is a <em>lot</em> of variability in this; my impression is that moving forward chronologically, you tend to see more plow-teams in the middle ages compared to the ancient world, and more in the early modern compared to the middle ages, occasionally held in common by villages).  Oxen and horses are <em>hideously</em> expensive, both to acquire but also to feed and for a family barely surviving one year to the next, they simply cannot afford them.  They also do not have herds of animals (because their small farms absolutely cannot support acres of pasturage) and they probably have limited access to <em>herdsmen</em> generally (that is, <a href="https://acoup.blog/2019/07/12/collections-the-lonely-city-part-i-the-ideal-city/">transhumant pastoralists</a> moving around the countryside) because those fellows will tend to want to interact with the community <em>leaders</em> who are, as noted above, the large landholders.  All of which is to say that while the small farmers may keep a few animals, they do not have access to significantly large numbers of animals (or humans), which matters, as we’ll see.</p>



<figure><img data-attachment-id="3981" data-permalink="https://acoup.blog/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg" data-orig-size="1280,834" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>From the ‘Tomb of Sennedjem” in Deir el-Medina, Egypt, a mural showing a farmer plowing his field with a pair of oxen as a plow-team, with his wife sowing behind him, dating to c. 1200 BC (New Kingdom). Apologies for poor quality of the image, getting a decent picture that is of the painting itself and not a reproduction is difficult; this one is from <a href="https://commons.wikimedia.org/wiki/Category:Tomb_of_Sennedjem#/media/File:Deir_el-Medina-20-Grab_1-Sennedjem-Pflueger-Saeerin-1982-gje.jpg">wikipedia</a>.</figcaption></figure>



<p>The first impact of having a plow-team is fairly obvious: <strong>a plow drawn by a couple of oxen is more effective than a plow pushed by a single human</strong>.  That means that a plow-team lets the same amount of farming <em>labor</em> sow a larger area of land (and if your thought is, “ok, but what about the <em>harvest</em>” – good, keep a pin in that, we’ll come back to it). <strong> It also allows for a larger, deeper plow, which in turn plows at a greater depth, which<a href="https://pubmed.ncbi.nlm.nih.gov/19093521/"> can improve yields </a></strong>(we’ll get into why and how plowing works next week).  You can easily see why, for a landholder with a large farm, having a plow-team is so useful: whereas the subsistence farmer struggles by having too much labor (and too many mouths to feed) and too little land, the big landholder has a lot of land they are trying to get farmed with as little labor as possible.  And of course, more to the point, the large landholder has the wealth and acreage necessary to buy and then pasture the animals in the plow-team.</p>



<p>The second major impact is <strong>manure</strong>.  Remember that our farmers live before the time of artificial fertilizer.  Crops, especially bulk cereal crops, wear out the nutrients in the soil quite rapidly after repeated harvests, which leaves the farmer two options.  The first, standard option, is that the farmer can fallow the field (which also has the advantage of disrupting certain pest life-cycles); depending on the farming method, fallowing may mean planting specific plants to renew the soil’s nutrients when those plants are uprooted and left to return to the soil in the field or it may mean simply turning the field over to wild plants with a similar effect.  The second option is using fertilizer, which in this case means manure.  Quite a lot of it.  Aggressive manuring, particularly on rich soils which have good access to moisture (because cropping also dries out the soil; fallowing can restore that moisture) allows the field to be fallowed less frequently and thus farmed more intensively.  In some cases it allowed rich farmland to be <em>continuously</em> cropped, with fairly dramatic increases in returns-to-acreage as a result.  And by increasing the nutrients in the soil, it also produces higher yields in a given season.</p>



<p>Now the humans in a farming household aren’t going to generate enough manure on their own to make a meaningful contribution to soil fertility.  But the larger landholders generally have two advantages in this sense.  <strong>First, because their landholdings are large, they can afford to turn over marginal farming ground to pasture for horses, cattle, sheep and so on</strong>; these …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009134</guid>
            <pubDate>Fri, 31 Jul 2020 14:51:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uploading the vendor/ folder to your repo? ️ A GitHub action can help]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008933">thread link</a>) | @leoloso
<br/>
July 31, 2020 | https://leoloso.com/posts/github-action-to-release-wp-plugin/ | <a href="https://web.archive.org/web/*/https://leoloso.com/posts/github-action-to-release-wp-plugin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The <a href="https://github.com/GraphQLAPI/graphql-api">GraphQL API for WordPress</a> plugin (<a href="https://leoloso.com/posts/introducing-the-graphql-api-for-wordpress/">launched last week</a>) has plenty of PHP dependencies, managed through Composer. These dependencies, which are located under <code>vendor/</code>, are not stored in the GitHub repo, because they do not belong there.</p><p>However, these dependencies must be inside the .zip file when installing the plugin in the WordPress site. Then, when and how do we add them into the release?</p><p>The answer is to create a <a href="https://github.com/features/actions">GitHub action</a> which, upon tagging the code, will automatically create the .zip file and upload it as a release asset.</p><p>The end result looks like this: In addition to the <code>Source code (zip)</code> (which does not contain the PHP dependencies), the release assets contain a <code>graphql-api.zip</code> file, which does have the PHP dependencies, and is the actual plugin to install in the WordPress site:</p><figure><img src="https://leoloso.com/images/release-assets.png" alt="Release assets after tagging code" loading="lazy" width="1699" height="740"><figcaption>Release assets after tagging code</figcaption></figure><p>In this post, I'll demonstrate step-by-step the GitHub action to build the plugin.</p><h2 id="heading-exploring-existing-actions">Exploring existing actions<a href="#heading-exploring-existing-actions"><span> permalink</span></a></h2><p>Before attempting to create my own action, I tried the following ones:</p><ul><li>10up's <a href="https://github.com/10up/action-wordpress-plugin-deploy">WordPress.org Plugin Deploy</a></li><li><a href="https://github.com/actions/upload-release-asset"><code>upload-release-asset</code></a></li></ul><p>None of them worked for my case. Concerning 10up's action, its purpose is to upload the plugin release from GitHub to WordPress' SVN. This can be very useful, saving us plenty of time by avoiding to do this bureaucratic conversion manually. However, I can't use it, because my plugin is not in the WordPress plugin directory yet (for the time being, it's available only through GitHub). I attempted to use it just to generate the .zip file, without uploading to the SVN, but nope, it doesn't work.</p><p><code>upload-release-asset</code> should have been suitable for my use case, however I couldn't make it work properly, because this action creates a release, which is then uploaded as an asset. However, when tagging the source code (say, with <code>v0.1.5</code>), the release is already created! Hence, this tool would create yet-another release, which is far from ideal. And even worse, it requires parameter <code>tag_name</code>, but this tag can't be the same used for tagging the source code, or it gives a <code>duplicated</code> error. Then, my source code was being tagged twice: first manually as <code>v0.1.5</code>, and then automatically as <code>plugin-v0.1.5</code>. Very far from ideal.</p><p>So, I created my own action.</p><h2 id="heading-creating-the-action">Creating the action<a href="#heading-creating-the-action"><span> permalink</span></a></h2><p>The action is <a href="https://github.com/GraphQLAPI/graphql-api/blob/d820f4aa63e42780ea6ce19a8b52cb0261c1052f/.github/workflows/main.yml">this one</a>:</p><pre><code><span><span>name</span><span>:</span> Generate Installable Plugin<span>,</span> and Upload as Release Asset</span><br><span><span>on</span><span>:</span></span><br><span>  <span>release</span><span>:</span></span><br><span>    <span>types</span><span>:</span> <span>[</span>published<span>]</span></span><br><span><span>jobs</span><span>:</span></span><br><span>  <span>build</span><span>:</span></span><br><span>    <span>name</span><span>:</span> Upload Release Asset</span><br><span>    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest</span><br><span>    <span>steps</span><span>:</span></span><br><span>      <span>-</span> <span>name</span><span>:</span> Checkout code</span><br><span>        <span>uses</span><span>:</span> actions/checkout@v2</span><br><span>      <span>-</span> <span>name</span><span>:</span> Build project</span><br>        <span>run</span><span>:</span> <span>|</span><span><br><span>          composer install --no-dev --optimize-autoloader</span><br>          mkdir build</span><br><span>      <span>-</span> <span>name</span><span>:</span> Create artifact</span><br><span>        <span>uses</span><span>:</span> montudor/action<span>-</span>zip@v0.1.0</span><br><span>        <span>with</span><span>:</span></span><br><span>          <span>args</span><span>:</span> zip <span>-</span>X <span>-</span>r build/graphql<span>-</span>api.zip . <span>-</span>x *.git* node_modules/\* .* "*/\.*" CODE_OF_CONDUCT.md CONTRIBUTING.md ISSUE_TEMPLATE.md PULL_REQUEST_TEMPLATE.md *.dist composer.* dev<span>-</span>helpers** build**</span><br><span>      <span>-</span> <span>name</span><span>:</span> Upload artifact</span><br><span>        <span>uses</span><span>:</span> actions/upload<span>-</span>artifact@v2</span><br><span>        <span>with</span><span>:</span></span><br><span>            <span>name</span><span>:</span> graphql<span>-</span>api</span><br><span>            <span>path</span><span>:</span> build/graphql<span>-</span>api.zip</span><br><span>      <span>-</span> <span>name</span><span>:</span> Upload to release</span><br><span>        <span>uses</span><span>:</span> JasonEtco/upload<span>-</span>to<span>-</span>release@master</span><br><span>        <span>with</span><span>:</span></span><br><span>          <span>args</span><span>:</span> build/graphql<span>-</span>api.zip application/zip</span><br><span>        <span>env</span><span>:</span></span><br><span>          <span>GITHUB_TOKEN</span><span>:</span> $<span>{</span> <span>{</span> secrets.GITHUB_TOKEN <span>}</span> <span>}</span></span></code></pre><p>Please notice that <code>${ { secrets.GITHUB_TOKEN } }</code> in the code above must not have a space between <code>{ {</code>, and between <code>} }</code>, but for some reason my Eleventy site fails compiling it 🤷🏻‍♂️.</p><p>The workflow is like this:</p><p>The action, called <code>"Generate Installable Plugin, and Upload as Release Asset"</code>, is executed whenever a new release is created, i.e. whenever I tag my code, as defined in the <code>on</code> entry:</p><pre><code><span><span>name</span><span>:</span> Generate Installable Plugin<span>,</span> and Upload as Release Asset</span><br><span><span>on</span><span>:</span></span><br><span>  <span>release</span><span>:</span></span><br><span>    <span>types</span><span>:</span> <span>[</span>published<span>]</span></span></code></pre><p>The computer (called a "runner") where it runs is a Linux:</p><pre><code><span><span>jobs</span><span>:</span></span><br><span>  <span>build</span><span>:</span></span><br><span>    <span>name</span><span>:</span> Upload Release Asset</span><br><span>    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest</span></code></pre><p>The first step is to check out the source code from the repo:</p><pre><code><span>    <span>steps</span><span>:</span></span><br><span>      <span>-</span> <span>name</span><span>:</span> Checkout code</span><br><span>        <span>uses</span><span>:</span> actions/checkout@v2</span></code></pre><p>Then, it builds the WordPress plugin, by having Composer download the PHP dependencies and store them under <code>vendor/</code>. This is the crucial step, for which this action exists.</p><p>Because this is the plugin for production, we can attach options <code>--no-dev --optimize-autoloader</code> to optimize the release:</p><pre><code><span>      <span>-</span> <span>name</span><span>:</span> Build project</span><br>        <span>run</span><span>:</span> <span>|</span><span><br>          composer install --no-dev --optimize-autoloader</span></code></pre><p>Next, we will create the .zip file, stored under a <code>build/</code> folder. We first create the folder:</p><pre><code><span>          mkdir build</span></code></pre><p>And then make use of <a href="https://github.com/montudor/action-zip"><code>montudor/action-zip</code></a> to zip the files into <code>build/graphql-api.zip</code>.</p><p>In this step, I also exclude those files and folder which are needed when coding the plugin, but are not needed in the actual final plugin:</p><ul><li>All hidden files and folders (<code>.git</code>, <code>.gitignore</code>, etc)</li><li>Any <code>node_modules/</code> folder (there should be none, but just in case...)</li><li>Development files ending in .dist (such as <code>phpcs.xml.dist</code>, <code>phpstan.neon.dist</code> and <code>phpunit.xml.dist</code>)</li><li>Composer files <code>composer.json</code> and <code>composer.lock</code></li><li>Markdown files for managing the repo: <code>CODE_OF_CONDUCT.md</code>, <code>CONTRIBUTING.md</code>, <code>ISSUE_TEMPLATE.md</code> and <code>PULL_REQUEST_TEMPLATE.md</code></li><li>Folder <code>build/</code>, which is created only to store the .zip file</li><li>Folder <code>dev-helpers/</code>, which contains helpful scripts for development</li></ul><pre><code><span>      <span>-</span> <span>name</span><span>:</span> Create artifact</span><br><span>        <span>uses</span><span>:</span> montudor/action<span>-</span>zip@v0.1.0</span><br><span>        <span>with</span><span>:</span></span><br><span>          <span>args</span><span>:</span> zip <span>-</span>X <span>-</span>r build/graphql<span>-</span>api.zip . <span>-</span>x *.git* node_modules/\* .* "*/\.*" CODE_OF_CONDUCT.md CONTRIBUTING.md ISSUE_TEMPLATE.md PULL_REQUEST_TEMPLATE.md *.dist composer.* dev<span>-</span>helpers** build**</span></code></pre><p>After this step, the release will have been created as <code>build/graphql-api.zip</code>. Next, as an optional step, we upload it as an artifact to the action:</p><pre><code><span>      <span>-</span> <span>name</span><span>:</span> Upload artifact</span><br><span>        <span>uses</span><span>:</span> actions/upload<span>-</span>artifact@v2</span><br><span>        <span>with</span><span>:</span></span><br><span>            <span>name</span><span>:</span> graphql<span>-</span>api</span><br><span>            <span>path</span><span>:</span> build/graphql<span>-</span>api.zip</span></code></pre><p>And finally, we make use of <a href="https://github.com/JasonEtco/upload-to-release"><code>JasonEtco/upload-to-release</code></a> upload the .zip file as a release asset, under the release package which triggered the GitHub action. The secret <code>secrets.GITHUB_TOKEN</code> is implicit, GitHub already sets it up for us:</p><pre><code><span>      <span>-</span> <span>name</span><span>:</span> Upload to release</span><br><span>        <span>uses</span><span>:</span> JasonEtco/upload<span>-</span>to<span>-</span>release@master</span><br><span>        <span>with</span><span>:</span></span><br><span>          <span>args</span><span>:</span> build/graphql<span>-</span>api.zip application/zip</span><br><span>        <span>env</span><span>:</span></span><br><span>          <span>GITHUB_TOKEN</span><span>:</span> $<span>{</span> <span>{</span> secrets.GITHUB_TOKEN <span>}</span> <span>}</span></span></code></pre><p>When tagging the source code with tag <code>v0.1.20</code>, the action is triggered, and we can see in real-time what the process is doing. Once finished, if everything went fine, all the steps executed in the workflow will have a beautiful ✅ mark:</p><figure><img src="https://leoloso.com/images/action-run.png" alt="GitHub action run and succeeded" loading="lazy" width="2570" height="1512"><figcaption>GitHub action run and succeeded</figcaption></figure><p>Now, heading to the <a href="https://github.com/GraphQLAPI/graphql-api/releases/tag/v0.1.20">releases for tag <code>v0.1.20</code></a>, it displays a link to the newly-create release <code>graphql-api</code>:</p><figure><img src="https://leoloso.com/images/release-assets.png" alt="Release asset success" loading="lazy" width="1699" height="740"><figcaption>Release asset success</figcaption></figure><p>Hurray!</p></div></div>]]>
            </description>
            <link>https://leoloso.com/posts/github-action-to-release-wp-plugin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008933</guid>
            <pubDate>Fri, 31 Jul 2020 14:35:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacBook Air is the best personal computer for iOS Developers in 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008815">thread link</a>) | @dolesch
<br/>
July 31, 2020 | https://getonthestore.com/macbook-air/ | <a href="https://web.archive.org/web/*/https://getonthestore.com/macbook-air/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	
	

	
	
	<div>
		




<p>Don’t be fooled by the 13-inch MacBook <em>Pro</em>. It is <strong>not worth</strong> paying an extra $200 for the word <em>Pro</em>. Instead you should get the quad-core i5 MacBook Air with 16GB of memory for $1299.<br></p>



<figure><a href="https://getonthestore.com/?attachment_id=176" target="_blank" rel="noopener noreferrer"><img src="https://getonthestore.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-29-at-9.57.29-AM.png" alt="" width="505" height="409" srcset="https://getonthestore.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-29-at-9.57.29-AM.png 1010w, https://getonthestore.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-29-at-9.57.29-AM-300x243.png 300w, https://getonthestore.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-29-at-9.57.29-AM-768x622.png 768w" sizes="(max-width: 505px) 100vw, 505px"></a><figcaption>Click to enlarge</figcaption></figure>



<p>You can get a Mac mini with similar specs for $1000, but most people prefer the portability of a laptop so that’s what I cover here. If your budget is under $1000 you should buy a used Mac. Get one with a quad-core i5 processor, at least 8GB of memory and a solid state drive. </p>



<h2><br>How I picked</h2>



<p><br>The most important metrics for a personal development machine are the number of years you can upgrade to the latest Xcode and the build time for incremental builds. If your employer is paying, you can convince them that any extra performance is worth it, but when you’re paying you realize it’s not. Spending twice the money will probably make the difference between getting 8 years or 9 years out of a computer.</p>



<p>Other important factors to consider are the project size and number of storyboard scenes the computer can handle and the time it takes to launch a simulator. A computer with short build times will do well at all of these.</p>



<p>The MacBook Air has the newest generation of keyboard which is a big improvement over the keyboards of the last four years. If you are buying a used MacBook make sure you try out the keyboard to see if you like it before you buy.</p>



<p>Selecting the 8GB model would be fine for now, but upgrading memory is not an option in any of the MacBooks that work with Xcode 12. At some time in the next 8 years you will need 16GB of memory, so get it now.</p>



<h2><br>The Research</h2>



<div><figure><img src="https://getonthestore.com/wp-content/uploads/2020/07/dan-dimmock-3mt71MKGjQ0-unsplash-300x169.jpg" alt="" srcset="https://getonthestore.com/wp-content/uploads/2020/07/dan-dimmock-3mt71MKGjQ0-unsplash-300x169.jpg 300w, https://getonthestore.com/wp-content/uploads/2020/07/dan-dimmock-3mt71MKGjQ0-unsplash-1024x576.jpg 1024w, https://getonthestore.com/wp-content/uploads/2020/07/dan-dimmock-3mt71MKGjQ0-unsplash-768x432.jpg 768w, https://getonthestore.com/wp-content/uploads/2020/07/dan-dimmock-3mt71MKGjQ0-unsplash-1536x864.jpg 1536w, https://getonthestore.com/wp-content/uploads/2020/07/dan-dimmock-3mt71MKGjQ0-unsplash-373x210.jpg 373w, https://getonthestore.com/wp-content/uploads/2020/07/dan-dimmock-3mt71MKGjQ0-unsplash.jpg 1920w" sizes="(max-width: 300px) 100vw, 300px"></figure></div>



<p><br>I work full time as an iOS developer and have used nine consecutive versions of Xcode. I run Xcode on my personal late 2012 MacBook Pro Retina which has a dual-core i5 processor with 8GB of memory. I also run Xcode on my work MacBook Pro which has an 8-core i9 processor with 32GB of memory. After 8 years my personal Mac still works great, but it does feel a bit under-powered compared to the work computer. The price and performance of my personal Mac was right in the middle of Apple’s product line when I bought it. The MacBook Air I recommend today falls in the same place.</p>



<p>I’m only considering an upgrade now because I won’t be able to update to macOS Big Sur. My computer doesn’t get the update because Intel stopped supporting firmware updates for 2012 processors. Today’s MacBook Air has the 10th generation i5 processor, while MacBook Pro is still on the 8th Generation. The 8th generation of processors is a year older, so it’s likely to be dropped a year before the 10th generation. Another strike against MacBook Pro.</p>



<h3>Should you get more memory or a better processor?</h3>



<p>I analyzed <a rel="noreferrer noopener" href="https://github.com/ashfurrow/xcode-hardware-performance" target="_blank">community sourced</a> incremental build times to answer that question. This data was gathered by building the same project on many different computers. My analysis showed that incremental build time does not improve on computers with more than 4 cores or on computers with more than 16GB of memory.</p>



<p>The standard 256GB drive should also be enough. The latest version of macOS plus Xcode and the iOS Simulator only take up 36GB.</p>



<h3><br>Should you wait for Apple Silicon?</h3>



<p>Apple Silicon are Apple’s new processors. We don’t know what they will cost, but you don’t need to wait on them because the better the new chips are the more they will cost. The MacBook Air with an Intel chip is already going to give you 8 years of great performance. I don’t expect Apple to start selling an affordable Apple Silicon Mac before late 2022. </p>



<p>A new processor type doesn’t destroy the value of the old type. I resold my PowerPC based iMac four years after Apple started the PowerPC to Intel transition. I sold it for 60% of the new price and had no trouble finding a buyer. But you don’t need to take my word for it.</p>



<blockquote><p> “We plan to continue to support and release new versions of macOS for Intel-based Macs for years to come. In fact, we have some new Intel-based Macs in the pipeline that we’re really excited about.”</p><cite>Tim Cook</cite></blockquote>



<h2>When should you upgrade?</h2>



<p>Improvements in computers come very slowly so there’s few reasons to upgrade as long as you can run the latest version of macOS. Once you can’t do that you know that you only have about 18 months until that computer can no longer submit apps to the App Store. Only then is it time to look for an upgrade.</p>



<figure><img src="https://getonthestore.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-30-at-2.37.19-PM.png" alt="" srcset="https://getonthestore.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-30-at-2.37.19-PM.png 617w, https://getonthestore.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-30-at-2.37.19-PM-300x203.png 300w" sizes="(max-width: 617px) 100vw, 617px"><figcaption><a href="https://buyersguide.macrumors.com/#MacBook_Air" target="_blank" rel="noreferrer noopener">https://buyersguide.macrumors.com/#MacBook_Air</a></figcaption></figure>



<p>It’s unlikely that we will see a better development computer come to the market any time soon. For that reason I think it’s a great time to get the $1299 MacBook Air.</p>




	</div>

	
	
	

	</article></div>]]>
            </description>
            <link>https://getonthestore.com/macbook-air/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008815</guid>
            <pubDate>Fri, 31 Jul 2020 14:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3 on Web Performance]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008755">thread link</a>) | @mostlystatic
<br/>
July 31, 2020 | https://www.debugbear.com/blog/gpt-3-on-web-performance | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/gpt-3-on-web-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>I interviewed OpenAI's GPT-3 on how to measure and improve website performance.</p>
<p>This article contains the interview, additional performance tips from GPT-3, and a guide to using GPT-3 on <a href="https://play.aidungeon.io/">AIDungeon</a>. I added notes to the interview when I thought GPT-3 got something wrong.</p>
<blockquote><p lang="en" dir="ltr">I used <a href="https://twitter.com/AiDungeon?ref_src=twsrc%5Etfw">@AiDungeon</a> to interview GPT-3 about measuring and improving web performance. It had some pretty good advice!<a href="https://t.co/ILG3UJf7fU">https://t.co/ILG3UJf7fU</a> <a href="https://twitter.com/hashtag/webperf?src=hash&amp;ref_src=twsrc%5Etfw">#webperf</a> <a href="https://t.co/HuhdQufgzC">pic.twitter.com/HuhdQufgzC</a></p>— DebugBear (@DebugBear) <a href="https://twitter.com/DebugBear/status/1289199671311654913?ref_src=twsrc%5Etfw">July 31, 2020</a></blockquote> 

<h2 id="the-interview">The Interview</h2>
<p><span></span>Can you tell me a bit about why web performance is important?</p>
<p><span></span>Web performance is important because it's one of the few things that can affect our users' experience in real time. <strong>If we don't get this right, then our users will be frustrated and leave our sites.</strong></p>
<p><span></span>Do you think websites have been getting slower over the years?</p>
<p><span></span>I think most people would say websites have been getting slower over the years. Perhaps this is due to <strong>increasing expectations from users</strong>, or maybe the <strong>proliferation of larger and more media-intensive sites</strong>.</p>
<p><span></span>What are some factors that affect how fast a website loads?</p>
<p><span></span>A number of things can affect how fast a website loads. In this case, let's talk about network conditions and how the code of the website is optimized.</p>
<p><span></span>How do network conditions affect site performance?</p>
<p><span></span>Network conditions affect site performance because the internet isn't fast everywhere. If your connection is slow then the website will be slower to load, but it doesn't mean that it won't eventually fully load.</p>
<p><span></span>What are some good ways to measure website performance?</p>
<p><span></span>There are many different ways to measure website performance. One of the more common ones is called <strong><a href="https://developers.google.com/speed/pagespeed/insights/">PageSpeed Insights</a></strong>. It's provided by Google and gives you a quick and easy look into how optimized your website is.</p>
<p><span></span>I regenerated this response twice, because I for now I wanted to talk about tools rather than metrics.</p>
<p><span></span>When would you use <a href="https://www.webpagetest.org/">WebPageTest</a> rather than Lighthouse?</p>
<p><span></span><strong>I personally use WebPageTest when I need more detailed information about network performance</strong> or when Lighthouse gives me an inconsistent score and I want to understand why.</p>
<p><span></span>Is the Lighthouse performance score you get from PageSpeed Insights a good indicator of the website's performance?</p>
<p><span></span>It's a decent starting point. The higher the score, the better, but keep in mind that this is just one measure of performance.</p>
<p><span></span>What other metrics do you look at when investigating website performance?</p>
<p><span></span>Besides the Largest Contentful Paint, <strong>I also look at First Input Delay and First Meaningful Paint</strong>.</p>
<p><span></span>Can you explain what the Largest Contentful Paint measures?</p>
<p><span></span>The Largest Contentful Paint measures when the largest bit of content first appears on the page. This means that the user will have something to look at, typically text or an image.</p>
<p><span></span>GPT-3 seems to talk about the First Contentful Paint in the second sentence. It's description of the LCP is basically right, it's the time at which the largest block of content renders.</p>
<p><span></span>Do you think the shift to client-side apps is hurting web performance?</p>
<p><span></span>Yes, I do. But it's not because of the performance, it's because it's harder to enforce consistent UX patterns.</p>
<p><span></span>I think "it" here refers to the shift to client side apps. If some of your site needs to be a React app then it's easier to make everything a React app, rather than maintaining separate code and keeping the two in sync.</p>
<p><span></span>What can I do to speed up my client-side app?</p>
<p><span></span>There are a few different approaches you can take, each with their own benefits and drawbacks. One is to <strong>'<a href="https://reactjs.org/docs/react-dom.html#hydrate">hydrate</a>' the app once the markup and assets are done downloading</strong>.</p>
<p><span></span>What GPT-3 is talking about here is rendering static HTML on the server, so the page content instantly appears when the user opens the page. Once your client-side JavaScript code has been downloaded, the HTML is then made interactive. This process on the client is called hydration.</p>
<p><span></span>How can I reduce the size of my JavaScript bundles?</p>
<p><span></span>One of the easiest things you can do is <strong>remove any modules or packages that you aren't using</strong>. For instance, let's say you're building a React.js app and aren't using routing.</p>
<p><span></span>Basically, split your bundle so you can load just the modules you actually need on the page requested by the user. I guess GPT-3 is using routing on a different page and that's why it's in the bundle?</p>
<p><span></span>What else can I do?</p>
<p><span></span>If you're building a single page app, make sure you're asynchronously loading your scripts. This way, the page doesn't have to wait for all of the JS to be downloaded before rendering any of it.</p>
<p><span></span>How do <strong>third-party scripts</strong> affect performance?</p>
<p><span></span>The worst ones are ad providers, like Google's AdSense. They <strong>can slow down your entire site just by being included</strong>.</p>
<p><span></span>What image format should I use if I want my website to load quickly?</p>
<p><span></span>While there are a lot of image formats, the two main ones are JPEG and PNG. The quickest to load are the WebP image format, but browsers don't natively support them yet.</p>
<p><span></span>GPT-3 initially said "GIF and JPEG are more or less the same", so I gave it another chance and regenerated this response.</p>
<p><span></span>WebP is supported in Chrome, Edge, and Firefox. The next version of iOS Safari will also support WebP.</p>
<p><span></span>What's the difference between JPEG and PNG?</p>
<p><span></span>PNG is a lossless format, so it produces the exact same image quality as the original, but it can be larger in size compared to JPEG.</p>
<p><span></span>What can I do about slow response times from my server?</p>
<p><span></span>The most common issue is that your server isn't configured properly to handle the load. You need to make sure that you have enough RAM, and that your CPU isn't overworked.</p>
<p><span></span>What other common causes are there?</p>
<p><span></span>The next most common issue is that your database isn't configured properly to handle the load. Slow database queries can cause your site to feel really slow, as it has to wait for the responses.</p>
<p><span></span>What's an example of an improperly configured database?</p>
<p><span></span>The most common issue is that <strong>database queries are too complex, and need to be simplified</strong>.</p>
<p><span></span>I was kinda hoping it would bring up column indexes when talking about database configuration.</p>
<p><span></span>What are some of the advantages of using <strong>HTTP/2</strong>?</p>
<p><span></span>It can significantly improve the performance of your site if configured properly. It <strong>allows for multiple requests to be made at the same time</strong>, and requires less requests to load a web page.</p>
<p><span></span>It's right that HTTP/2 can make multiple simulatenous requests on the same connection, but I don't see how it would require fewer requests. A big advantage of HTTP/2 is that making a large number of requests is much less of a problem than before.</p>
<p><span></span>What browser is the fastest?</p>
<p><span></span>Fastest isn't necessarily the same as most responsive, but as far as raw speed, Google Chrome generally has the fastest JavaScript engine.</p>
<p><span></span>What is a performance optimization that people don't use often enough?</p>
<p><span></span>You can <strong>use web workers to offload intensive processing</strong> from the main UI thread. It's important to use these only for intensive processing, as it can lead to poor responsiveness if misused.</p>
<p><span></span>Doing low-intensity processing in a web worker wouldn't give you any benefit, but I don't think the overhead is large enough to make your site unresponsive.</p>
<h2 id="performance-optimizations-that-arent-used-often-enough">Performance optimizations that aren't used often enough</h2>
<p>I kept regenerating the answer to the last question. Here are a few more performance tips from GPT-3</p>
<p><img src="https://www.debugbear.com/public/blog/gpt-3-on-web-performance/perf-tips.png" alt="GPT performance tips"></p>
<h3 id="general-performance-tips">General performance tips</h3>
<ul>
<li><strong>The best optimization you can do is to minimize the amount of code you need to write.</strong> The less code you have, the less potential problems it can have, and the faster it will be.</li>
<li>The best way to see if your website is fast enough is to just load it and see how it feels. If it doesn't feel fast enough, you can make adjustments until it does.</li>
</ul>
<h3 id="serving-assets">Serving assets</h3>
<ul>
<li>Probably the single best thing you can do to improve page load times is implement a CDN. While it requires setting up, it has a huge effect on your site's performance.</li>
<li>People don't take advantage of transfer encoding. Transfer encoding is used to compress the data that's being sent, which allows for more information to be transferred in a given amount of time.</li>
</ul>
<h3 id="image-optimization">Image optimization</h3>
<ul>
<li>Using data URIs instead of embedding images is a very easy way to increase performance, but not many people know about it.</li>
<li>Using vector images (like SVG) instead of bitmap images (like PNG) as they're typically smaller in size and faster to render.</li>
<li>Using spritesheets to load icons is a great way to decrease the number of HTTP requests that your page needs, as well as reducing the amount of time that it takes for the user to download everything.</li>
</ul>
<p>My understanding is that with HTTP/2 reducing the number of requests isn't as important any more, so I'd personally avoid spritesheets.</p>
<h3 id="css-amp-java-script">CSS &amp; JavaScript</h3>
<ul>
<li>Minification is the process of compressing your code so it requires less bytes to send to the browser. This reduces the amount of data that has to be transferred over the network and speeds up load time.</li>
<li>Using CSS animations rather than JavaScript animations.</li>
</ul>
<h2 id="using-gpt-3-on-ai-dungeon">Using GPT-3 on AIDungeon</h2>
<p>I used AIDungeon to generate the interview, as the OpenAI API is currently invite-only.</p>
<p>To use GPT-3 you need a Pro account, which costs $10/mo. Otherwise AIDungeon will use GPT-2. After upgrading you need to change to the Dragon model in the settings.</p>
<p><img src="https://www.debugbear.com/public/blog/gpt-3-on-web-performance/ai-model-type.png" alt="AIDungeon model type"></p>
<p>Next, start a single-player game and choose the "custom" option.</p>
<p><img src="https://www.debugbear.com/public/blog/gpt-3-on-web-performance/aidungeon-settings.png" alt="AIDungeon settings"></p>
<p>You now need to provide a <strong>prompt</strong>. This is the prompt I used:</p>
<blockquote>
<p>You're a web developer trying to improve the performance of your website. You talk to a colleague about front-end performance metrics, how to speed up your site, and how to measure and improve performance.</p>
</blockquote>
<blockquote>
<p>You say "Can you explain what the First Contentful Paint measures?"</p>
</blockquote>
<blockquote>
<p>"The First Contentful Paint measures when content first starts rendering on a web page. This means the user has something to look at, usually text or an image."</p>
</blockquote>
<blockquote>
<p>You say "Can you tell me a bit about why web performance is important?"</p>
</blockquote>
<p>If things go well you'll get a good answer right away. In this example GPT-3 doesn't quite understand the interview format yet, so you get …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.debugbear.com/blog/gpt-3-on-web-performance">https://www.debugbear.com/blog/gpt-3-on-web-performance</a></em></p>]]>
            </description>
            <link>https://www.debugbear.com/blog/gpt-3-on-web-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008755</guid>
            <pubDate>Fri, 31 Jul 2020 14:14:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rogue Wave of Enterprise SaaS]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008717">thread link</a>) | @gmays
<br/>
July 31, 2020 | https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://staysaasy.com/assets/rogue-wave/freakwave.jpg" alt="Freak wave"></p>

<p>During the pandemic, I’ve done my civic duty and spent lockdown reading a ton of random stuff on the internet. In the midst of a Wikipedia binge, I went down a rabbit hole on <a href="https://en.wikipedia.org/wiki/Rogue_wave">rogue waves</a>: massive waves that occur in the middle of the ocean, endangering ships and generating <a href="https://www.youtube.com/watch?v=pu4ogCy5d4k">kickass Youtube content</a>.</p>

<p>The concept of a rogue wave reminded me of a particularly challenging stage in the life of many venture-backed enterprise SaaS startups. Similar to how a rogue wave forms, during this phase many Small Problems coincide and create a Big Problem. Also like rogue waves, this moment in the life of a high-growth enterprise SaaS business is uncommon – it seems to occur around $5-20 million ARR, which relatively few companies reach, and can seem almost mythical. And finally, the effects of both rogue waves and this challenging startup stage are predictable: if you spend long enough on the high seas, they’re waiting for you.</p>

<p>I’ve seen this phenomenon both in-person as an operator and as an observer of other companies, and I do believe it’s real. I’m writing this essay in order to:</p>

<ul>
  <li>Share what I’ve seen</li>
  <li>Provide some opinions on what you can do about it</li>
</ul>

<p>Hopefully I can be the crusty old mariner bringing back tales that others find useful.</p>

<h2 id="hitting-the-wall">Hitting the Wall</h2>

<p><img src="https://staysaasy.com/assets/rogue-wave/boat.jpg" alt="Big boat, bigger wave">
Startups can be stressful</p>

<p>The rogue wave typically seems to hit between $5M and $20M in ARR. If you’re operating with a common venture-backed SaaS model of <a href="https://www.saastr.com/how-to-figure-out-your-competitors-revenues-in-about-70-seconds/">$1-200k ARR per employee</a>, this is around where you’ll hit the <a href="https://www.bbc.com/future/article/20191001-dunbars-number-why-we-can-only-maintain-150-relationships">Dunbar number</a> of ~150 people: the point where you can no longer operate as a large family, and need to start acting like a corporation. <em>(Note that the post linked is from 2012 – SaaS has since exploded, and more companies are raising huge rounds and hiring more on less revenue)</em></p>

<p>Crossing the 150-person barrier is both operationally and emotionally difficult:</p>

<ul>
  <li>Operational: We have so many teams, we need regular status reports!</li>
  <li>Emotional: Why do I need to send <em>you</em> a status report all of a sudden, I thought we were all friends here?!</li>
</ul>

<p>This transition point is also when many leaders who excelled in scrappy startup mode <a href="https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html">struggle to level up</a> in a larger organization. Some successfully scale themselves (slow, painful) and others will leave the company (fast, but often even more painful).</p>

<p>Many of the first contracts that you closed post-traction come up for renewal around this point (in the enterprise – SMB SaaS has less predictable growth profiles). If you’re following a <a href="https://www.battery.com/powered/helping-entrepreneurs-triple-triple-double-double-double-to-a-billion-dollar-company/">triple-triple-double-double-double</a> growth path, you’ll be at roughly your second triple. There will be too many customers for the founding team to personally visit and retain everyone.</p>

<p>At this point you’ll need to renew “real” customers, not just friends who took a flyer on your infant product. These aren’t the earliest adopters who will be with you through thick and thin and are really closer to partners. These are real live paying customers who will leave if your product is screwed up. As these renewals approach, a mature post-sales motion becomes essential.</p>

<p>The expectations around your revenue also become more real at this stage. Under about $10M ARR, your revenue projections can be a mild shitshow. But the expectation that you’ll have at least some semblance of predictability steadily increases.</p>

<p>And through it all you need to continue to scale the product. Your code is no longer a series of never-ending green fields rolling off into the distance, and non-trivial parts of your product will need to be meaningfully restructured. You’re burdened by decisions made years ago, often by people who are no longer on the team.</p>

<p>This is especially true for enterprise SaaS. Enterprise products are much more unwieldy than jewel-box consumer products, as they have to support many more users and workflows. Consumer products are like Chipotle: a small, carefully curated set of menu items, built for elegance and efficiency. Enterprise products are like the Cheesecake Factory: you can get steak, pasta, a milkshake and 4 kinds of margarita in the same meal. You need to level up how your team builds products.</p>

<h2 id="cresting-the-wave">Cresting the Wave</h2>

<p>I’m writing about this phenomenon because if you haven’t seen or heard about it, there isn’t really a good way to realize that it might be coming. Even if it isn’t preventable, it’s better to know what’s on the horizon. After all, being able to see around corners is why many companies hire experienced operators.</p>

<p>I won’t claim to be an expert on how to react, but I can share a few things that I think work well and a few that don’t, and what I would do if I had to go through this phase again.</p>

<h3 id="the-crew">The Crew</h3>

<p>First, I would do my best to get the right team in place in advance. In particular, I would make sure that I had very strong functional heads for the functions that will be strained the most: Product, Engineering, Marketing, Sales, Support, and Customer Success. You don’t need every role covered, but it saves headaches to know that some parts of the team are bulletproof. This isn’t the time for unforced errors.</p>

<p><img src="https://staysaasy.com/assets/rogue-wave/pirate-crew.jpg" alt="Pirates of the Caribbean crew">
You want a senior crew. You can tell that Sharkman here has experience and won’t freak out when the database goes down or a large account churns.</p>

<p>I also recommend hiring senior team members who can help see around corners and anticipate issues. This is a taxing time period because it’s so damn busy, and raw, well-directed horsepower tends to carry the day in those situations. More importantly, seasoned operators have typically seen challenging times before, and have the composure to handle them calmly because they know that things are always on fire.</p>

<p>It’s tempting during these busy times to make very junior hires such as new college graduates or coding bootcamp grads just to put butts in seats. These folks can be excellent hires in calmer times, but the chaos caused by too many inexperienced employees is very difficult while you’re cresting the wave.</p>

<h3 id="steering-the-ship">Steering the Ship</h3>

<p>Startups are generally fairly stressful, and that’s heightened in this time period. When operational problems strike in stressful times, it’s common to blame the people involved rather than processes – in reality, bad processes or incentives are usually the root cause.</p>

<p>Generally speaking, the faster you’re growing, the more lightweight your processes should be. When you’re in rapid scaling mode your operational tempo is constantly changing, so there’s no point boiling the ocean to create a perfect process when next month so much will have changed.</p>

<p>For example: when confronting a startup rogue wave, I would not choose to reinvent a completely new system for launching new features. Instead, use 20% of the time to set up a simple, predictable process that gives you 80% of the value. Example: set up a recurring check-in meeting where upcoming releases are discussed by PMs and Tech Leads + a Slack thread where all new releases are announced when they go-live. It won’t be perfect, but you can get this up and running in 15 minutes.</p>

<h3 id="commit">Commit</h3>

<p>This is not the time to hedge your decisions or waffle on strategy.</p>

<p>For example: in general, I prefer to give people a generous window of time to grow into stretch roles. Promoting from within builds continuity, leads to a more invested team, and motivates others by demonstrating that you’re creating strong career paths. But in this phase it’s especially important that you commit to keeping or replacing leaders fast, as there’s just too much going on.</p>

<p>If you’re 30% of the way up a 100 foot wall of water and decide to adjust course, you’re going to get slammed.</p>

<h3 id="keeping-calm">Keeping Calm</h3>

<p>Whatever you do, <em>don’t freak out</em>. When it feels like shit is hitting the fan everywhere, it’s easy to want to react and search for magic solutions. Hire a new Head of X! Spend less! No wait, spend <em>more</em>! Pause development and focus on tech debt! Actually our largest customer needs more features, cancel all tech debt projects!</p>

<p>In reality, to take a line from The Sopranos, <a href="https://www.youtube.com/watch?v=_po7So0MKq4">it won’t be cinematic</a>. Life isn’t a movie. There are no magic fixes – this challenging phase gets resolved by showing up and executing in an unflashy way for months. Magic fixes never really exist, and that’s especially true since this crucible stems from several medium-sized problems amplifying one another.</p>

<p>Searching for a unified solution to your troubles risks distraction. The road is reasonably straightforward and the challenges are tractable: there are just a lot of them. Just like an actual rogue wave, you can’t flee or dodge the factors that make crossing these rogue waves so difficult. You succeed by pointing your boat right at the problem and hitting the gas. Keeping calm doesn’t mean being stubborn or refusing to change, but it does mean that you can’t second guess your decisions – especially when it feels like you’re climbing a wall of water.</p>

<h2 id="takeaways">Takeaways</h2>

<p>Not everyone makes it over the wave – of the roughly 10 cases that I’ve observed, roughly half had their growth stunted for at least several years after hitting this stage. In my opinion this SaaS rogue wave should be taken seriously.</p>

<p>But the good news is that once you’ve crossed the wave, you can speed up again. As you’re rising up the wall everything goes into slow motion; but once you’ve crested the top, your acceleration can increase again as you’ve set yourself up with a more stable operating model and a hardened team.</p>

<p>This is a wonderful time, as there’s so much opportunity. Your team is still in place. The market opportunity is there, and people are buying. And once you’re over the top, the water is much calmer towards the horizon.</p>

<p>In conclusion:</p>

<ul>
  <li>Many challenging situations tend to arise simultaneously when high growth enterprise SaaS companies hit roughly $5-20 million ARR.</li>
  <li>The good news is that after this phase things get easier – the bad news is that it’s not easily avoidable.</li>
  <li>The best way to move forward is to focus on executing – and don’t be overly reactive.</li>
</ul>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008717</guid>
            <pubDate>Fri, 31 Jul 2020 14:09:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Katie Gamanji on Kubernetes Tooling DX, GitOps, and the Cluster API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008701">thread link</a>) | @crmccormick
<br/>
July 31, 2020 | https://www.getambassador.io/podcasts/katie-gamanji-on-kubernetes-tooling-dx-gitops-and-the-cluster-api/ | <a href="https://web.archive.org/web/*/https://www.getambassador.io/podcasts/katie-gamanji-on-kubernetes-tooling-dx-gitops-and-the-cluster-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><main><div><p>In the fourteenth episode of the Ambassador Livin’ on the Edge podcast, <a target="_blank" href="https://www.linkedin.com/in/katie-gamanji/" rel="noopener noreferrer">Katie Gamanji</a>, Cloud Platform Engineer at American Express and TOC member of the CNCF, discusses the building blocks of developer experience related to interacting with Kubernetes clusters. She covers the evolution of tooling from the kubectl that we all know and love, to UI-driven tooling like k9s and Octant, and ultimately to ApplicationOps and GitOps.</p><p>Katie also talks about the evolving ClusterAPI and how this is becoming integrated with the Kubernetes developer experience. She discusses if the tooling is currently good enough to allow engineers to treat Kubernetes clusters as resources themselves, and treat them as “cattle, not pets”.</p><p>Be sure to check out the additional episodes of the "<a href="https://www.getambassador.io/podcasts/" target="_blank"> <!-- -->Livin' on the Edge<!-- --> </a>" podcast.</p><h3>Key takeaways from the podcast included: </h3><ul><li>Automation and transparency are key to creating an effective continuous delivery pipeline. Siloing based on teams or technical verticals (e.g. networking, security) leads to inefficiencies via the introduction of uncertainty who is responsible, increased handoffs, and delays in verification.</li><li>Creating an application platform that is focused on self-service operation for development teams decreases friction when building, deploying, and releasing applications.</li><li>Platform and ops teams can provide expertise, support, and consultation to dev teams when required, but they should not be on the critical path for daily work.</li><li>Platform teams should recognise that developers are their customers. Platform and operations teams must empathise with and understand the needs of developers in order to build an effective developer experience.</li><li>There are typically three personas involved in building and releasing applications on Kubernetes: application developers, application operators, and infrastructure operators.</li><li>Each persona has differing requirements for interacting with a Kubernetes cluster. As the <a target="_blank" href="https://medium.com/@kgamanji/the-building-blocks-of-dx-k8s-evolution-from-cli-to-gitops-a7a574ac10eb" rel="noopener noreferrer">developer experience of Kubernetes cluster tooling has evolved</a>, a series of categories and techniques have emerged: cluster CLI e.g. kubectl, including plugins and wrappers; and ApplicationOps, such as ClickOps, <a target="_blank" href="https://www.weave.works/technologies/gitops/" rel="noopener noreferrer">GitOps</a>, and SheetOps.</li><li>Engineers are increasingly using kubectl "wrapper" tools to view and interact with a Kubernetes cluster. These tools provide a richer user interface than traditional CLI tools.</li><li><a target="_self" href="https://github.com/derailed/k9s" rel="noopener noreferrer">K9s</a> provides a useful terminal-driven user interface. <a target="_blank" href="https://github.com/vmware-tanzu/octant" rel="noopener noreferrer">Octant</a> provides a useful web-based UI onto a cluster and associated resources. <a target="_blank" href="https://github.com/spekt8/spekt8" rel="noopener noreferrer">Spect8</a> provides an interesting view onto the networking components of a k8s cluster.</li><li>GitOps enables engineers to specify the desired state of a cluster, typically via declarative YAML configuration, and use tooling like Flux or ArgoCD to ensure that the cluster state matches this specification. All configuration is stored in version control, and this enables easy rollout and rollback, and also provides an audit trail.</li><li>The Kubernetes founding team, the community, and the CNCF have worked to define useful abstractions and APIs for all of the personas listed above. These are now becoming a standard, and moving forward the innovation will focus on techniques on top of Kubernetes.</li><li>The <a target="_blank" href="https://medium.com/condenastengineering/clusterapi-a-guide-on-how-to-get-started-ff9a81262945" rel="noopener noreferrer">Cluster API</a> is potentially allowing infrastructure operators to treat clusters as "cattle, not pets". When engineers can think of a cluster as a Kubernetes resource, this opens up new possibilities. For example, clusters can be created and managed via well-established practices like <a target="_blank" href="https://twitter.com/k_gamanji/status/1270107207716175873" rel="noopener noreferrer">GitOps via ArgoCD or Flux</a>.</li><li>The Cluster API can also allow engineers to easily visualise what's "underneath their clusters", such as VMs, network attached storage etc. This will help with provisioning and upgrading, for example, engineers can easily look via the Kubernetes API to see the progress of each node during a K8s update</li></ul><p><strong>Subscribe: <a target="_blank" href="https://podcasts.apple.com/us/podcast/ambassador-labs-all-things-cloud-devex-and-apis/id1508879101" rel="noopener noreferrer">Apple Podcasts</a> | <a target="_blank" href="https://open.spotify.com/show/4A8w8qB4ogp9JAk6tEqQn9" rel="noopener noreferrer">Spotify</a> | <a target="_blank" href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5zb3VuZGNsb3VkLmNvbS91c2Vycy9zb3VuZGNsb3VkOnVzZXJzOjc5NjEzMzc0My9zb3VuZHMucnNz" rel="noopener noreferrer">Google Podcasts</a> | <a target="_blank" href="https://overcast.fm/itunes1508879101/ambassador-labs-all-things-cloud-devex-and-apis" rel="noopener noreferrer">Overcast.fm</a> | <a target="_blank" href="https://soundcloud.com/ambassador-labs" rel="noopener noreferrer">SoundCloud</a></strong></p><p>false</p><h3>This week's guest</h3><p>Katie Gamanji is a Cloud Platform Engineer at American Express. She was formerly a cloud platforms engineer at Condé Nast, and contributed to the creation of a centralized, globally distributed platform, with Kubernetes as its centerpiece. In the past she has worked on maintaining and automating site delivery on OpenStack based infrastructure, which transitioned into a role that focuses on designing, deploying and evolving cloud-native infrastructure.</p><p>Katie is a strong advocate for women in STEM, and a public speaker that focuses on topics that gravitate towards cloud-native tools and the Kubernetes ecosystem.<br></p><div><h2>Share this episode with your networks</h2><a rel="noopener noreferrer" target="_blank" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.getambassador.io%2Fpodcasts%2Fkatie-gamanji-on-kubernetes-tooling-dx-gitops-and-the-cluster-api%2F" aria-label="Share on Twitter" title="Share on Twitter"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24"><path d="M24 4.557c-.883.392-1.832.656-2.828.775 1.017-.609 1.798-1.574 2.165-2.724-.951.564-2.005.974-3.127 1.195-.897-.957-2.178-1.555-3.594-1.555-3.179 0-5.515 2.966-4.797 6.045-4.091-.205-7.719-2.165-10.148-5.144-1.29 2.213-.669 5.108 1.523 6.574-.806-.026-1.566-.247-2.229-.616-.054 2.281 1.581 4.415 3.949 4.89-.693.188-1.452.232-2.224.084.626 1.956 2.444 3.379 4.6 3.419-2.07 1.623-4.678 2.348-7.29 2.04 2.179 1.397 4.768 2.212 7.548 2.212 9.142 0 14.307-7.721 13.995-14.646.962-.695 1.797-1.562 2.457-2.549z"></path></svg></a><a rel="noopener noreferrer" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.getambassador.io%2Fpodcasts%2Fkatie-gamanji-on-kubernetes-tooling-dx-gitops-and-the-cluster-api%2F" aria-label="Share on Facebook" title="Share on Facebook"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24"><path d="M9 8H6v4h3v12h5V12h3.642L18 8h-4V6.333C14 5.378 14.192 5 15.115 5H18V0h-3.808C10.596 0 9 1.583 9 4.615V8z"></path></svg></a><a rel="noopener noreferrer" target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.getambassador.io%2Fpodcasts%2Fkatie-gamanji-on-kubernetes-tooling-dx-gitops-and-the-cluster-api%2F" aria-label="Share on LinkedIn" title="Share on LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 24 24"><path d="M4.98 3.5c0 1.381-1.11 2.5-2.48 2.5s-2.48-1.119-2.48-2.5c0-1.38 1.11-2.5 2.48-2.5s2.48 1.12 2.48 2.5zm.02 4.5h-5v16h5v-16zm7.982 0h-4.968v16h4.969v-8.399c0-4.67 6.029-5.052 6.029 0v8.399h4.988v-10.131c0-7.88-8.922-7.593-11.018-3.714v-2.155z"></path></svg></a></div><h3>Full transcript</h3><p>Daniel Bryant (00:03):</p><p>Hello everyone. I'm Daniel Bryant and I'd like to welcome you to the Ambassador Livin' On the Edge podcast, the show that focuses on all things related to cloud-native platforms, creating effective developer workflows, and building modern APIs. Today, I'm joined by Katie Gamanji, Cloud Platform Engineer at American Express and TOC member of the CNCF. Katie has recently been writing and talking about the building blocks of developer experience with interacting with Kubernetes clusters, from the kubectl or kubectl that we all know and love to other GUI driven tooling and more.</p><p>Daniel Bryant (00:31):</p><p>One of her fantastic recent blog posts discussed the use of kubectl UI wrappers, like K9s and Octant, in addition to covering cloud platform web based portal approaches using ClickOps, and also YAML driven approaches such as GitOps. I was keen to hear Katie's analysis of the strengths and weaknesses of each approach and also understand her recommendations as to what to use and when.</p><p>Daniel Bryant (00:51):</p><p>Additionally, I've learned a lot from Katie recently around the evolving cluster API and I was keen to understand how this is becoming integrated with the Kubernetes developer experience. And for example, I was keen to understand, is the tooling mature enough to allow us to treat Kubernetes clusters as cattle and not pets?</p><p>If you like what you hear today, I would definitely encourage you to pop over to our website. That's www.getambassador.io where we have a range of articles, white papers, and videos that provide more information for engineers working in the Kubernetes and cloud space. You can also find links there to our latest releases, such as the Ambassador Edge Stack, our open source Ambassador API gateway, and also our CNCF-hosted Telepresence tool too. So hi Katie, welcome to the podcast. Thanks for joining us today.</p><p>Katie (01:31):</p><p>Hello, Daniel, happy to be here.</p><p>Daniel Bryant (01:33):</p><p>Could you briefly introduce yourself for the listeners please and share a recent career highlight?</p><p>Katie (01:37):</p><p>Yes. So my name is Katie Gamanji and I am one of the cloud platform engineers for American Express. I've joined American Express six months ago, so quite recently, and I am part of the team that aims to transform the current platform by embracing the cloud native principles and making the best use of the open source tools. In terms of my career highlights, quite recently I've been elected as one of the TOC for the CNCF. So this has been quite a new and quite grand event in my career development, I would say. Being part of the CNCF as a TOC is, I think quite a good opportunity to really influence and leverage how the CNCF landscape should be constructed. So we have the power to leverage different projects and to move them through the pipeline all the way to graduations, such as, for example, quite recently, Helm graduated or of course Kubernetes which has been graduated for quite a while now.</p><p>Daniel Bryant (02:34):</p><p>Brilliant. Brilliant. You've got so many highlights Katie, at QCon, keynoting, you were keynoting some other stuff online. You got so many to choose from, right?</p><p>Katie (02:41):</p><p>Absolutely. Yeah. I'm enjoying it though.</p><p>Daniel Bryant (02:44):</p><p>Good on you. Yeah. Brilliant. So first the traditional question in the podcast is around developer experiences and developer loops. So that capability of being able to rapidly have an idea, code, test, deploy, release, and verify. And I ask folks to share their worst developer experience, you don't have to name names, protect the guilty and the innocent, right? But can you share your worst developer experience?</p><p>Katie (03:06):</p><p>Oh, I think I've had quite a few bad experiences when it comes to deploying an application and troubleshooting an application. And I think that's why actually I'm in this industry, I want to improve all of these methods around deployment. So I think one of, I wouldn't say the worst, but quite generic was when we'd like to deploy an application through our pipelines, or a team would like to deploy their application through our pipelines. Unfortunately, we had verticals when it comes to, for example, networking and security and the CI and CD, there was all divided across different teams. It wasn't one unified manner. So what actually happens if something would, for example, fail at the networking level in the pipeline, imagine the stress to actually understanding why it failed. As an end user you don't really understand that, so you have to go through every single team. There were so many points of contacts to potentially troubleshoot any bug in your application. And I think that's definitely the worst.</p><p>Katie (04:05):</p><p>Why I'm saying it's the worst, sometimes it can take days and it's very overwhelming. And I think that's definitely one of the worst DX that we can provision for any kind of engineers. And that's why, as I mentioned, I'm in this industry, in this area of technology where we can really close the gap between all of these functionalities, but at the same time, bring automation around them, bring transparency around them. So the power would be with the developers. Of course they would need to be up skilled, but they would have an understanding of how to troubleshoot and connect to the application and how to properly debug it and just reach us when they need to. So, yeah, that's my motivation, why I'm in this position. But when I started in this area, it was that, pretty …</p></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.getambassador.io/podcasts/katie-gamanji-on-kubernetes-tooling-dx-gitops-and-the-cluster-api/">https://www.getambassador.io/podcasts/katie-gamanji-on-kubernetes-tooling-dx-gitops-and-the-cluster-api/</a></em></p>]]>
            </description>
            <link>https://www.getambassador.io/podcasts/katie-gamanji-on-kubernetes-tooling-dx-gitops-and-the-cluster-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008701</guid>
            <pubDate>Fri, 31 Jul 2020 14:07:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Types in Ruby 3, RBS, and Sorbet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008520">thread link</a>) | @bradleybuda
<br/>
July 31, 2020 | https://sorbet.org/blog/2020/07/30/ruby-3-rbs-sorbet | <a href="https://web.archive.org/web/*/https://sorbet.org/blog/2020/07/30/ruby-3-rbs-sorbet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>Yesterday Square <a href="https://developer.squareup.com/blog/the-state-of-ruby-3-typing/">posted an article</a> to their blog introducing
<a href="https://github.com/ruby/rbs">RBS</a> (Ruby Signature), a type syntax format for Ruby 3.</p>
<p>We’d like to take a second to speak to how RBS relates to Sorbet. The short
version: Sorbet will happily incorporate RBS as a way to specify type
annotations, in addition to the existing syntax Sorbet supports. Stripe still
has a very strong commitment to Sorbet’s continued progress and success. While
the Ruby core team has been working on syntax, we’ve been working on features
that build on top of that syntax.</p>
<p>With that in mind, I’d love to start a discussion of some of the finer points of
what this announcement means for Ruby, and for Sorbet.</p>
<!--truncate-->
<h2>RBI? RBS?</h2>
<p>As <a href="https://youtu.be/2g9R7PUCEXo?t=2076">Matz announced at RubyConf 2019</a>, Ruby 3 plans to ship type
annotations for the standard library in a particular format. We’ve been meeting
with Matz and the Ruby core team to provide input on our experience and learn
from them how they’re thinking about types so that Sorbet wil be ready. We’re
<a href="https://sorbet.org/docs/faq#when-ruby-3-gets-types-what-will-the-migration-plan-look-like">committed</a> to supporting Ruby 3’s type syntax.</p>
<p>In the mean time, we’ve kept busy. While the Ruby core team has been working on
the RBS syntax over the past year, the Sorbet team has delivered tons of other
features. A sampling of features that didn’t exist a year ago:</p>
<ul>
<li>Go to Definition (Aug 2019)</li>
<li><a href="https://sorbet.org/docs/exhaustiveness">Exhaustiveness checking</a> (Aug 2019)</li>
<li><a href="https://sorbet.org/docs/tenum">Typed enums</a> (Nov 2019)</li>
<li>Autocompletion (Nov 2019)</li>
<li>Step-function improvements in IDE speed (Feb 2020, June 2020)</li>
</ul>
<p>These features make Sorbet users more productive, empowering them to do more
with Sorbet. We’ll happily incorporate any other syntax the Ruby core team wants
to build.</p>
<h2>Wait, a wholly separate file?</h2>
<p>RBS type signatures are placed in a separate file. While Sorbet also offers
inline syntax (more later), we believe that supporting type signatures in a
separate file is necessary. Consider: most of the Ruby standard library is
implemented in C for performance (e.g., all <code>Array</code> and <code>Hash</code> functions, and
many others). There must be a way to ascribe types to these internally defined
classes and methods.</p>
<p>Providing types for the standard library is incredibly important! In completely
untyped, unannotated Ruby codebases, people who try out Sorbet for the first
time find that about 25% of call sites already have static type coverage. Why?
Everyday Ruby code uses the standard library abundantly, and Sorbet includes
type definitions for the standard library out of the box!</p>
<p>Additionally, there will always be libraries that prefer not using type
annotations. To integrate an untyped library into a typed Ruby codebase, there
must be a place for these types to live outside of that project. In fact, we
already have the <a href="https://github.com/sorbet/sorbet-typed">sorbet-typed</a> repo for this purpose.</p>
<p>Thus, both Sorbet and Ruby 3 support type annotations in separate files (via RBI
files and RBS files, respectively).</p>
<h2>What about inline type annotations?</h2>
<p>There are people using Ruby who still prefer type annotations to live in the
code itself. We’ve built Sorbet to cater to both groups: those who <strong>like and
don’t like</strong> type annotations benefit from Sorbet.</p>
<p>How? Sorbet implements a <a href="https://sorbet.org/docs/gradual">gradual type system</a>. Without any type annotations,
Sorbet will do its best to understand and offer feedback on your code. With type
annotations exclusively in separate files, Sorbet will understand more and offer
better feedback. With inline type annotations, people can tell Sorbet every
little detail about their code so Sorbet can offer incredible feedback. For
these people, reading the types is as valuable as reading the code itself.</p>
<p>Sorbet has always provided syntax for inline type annotations. Annotations
aren’t required by Sorbet—they’re there for the people who want to empower
Sorbet to help them even more. Whether you love type annotations or not, Sorbet
still provides value.</p>
<h2>Why are inline type annotations useful?</h2>
<p>As we mentioned above, for those teams and projects who really want static
typing, inline type annotations become essential. Types carry intent, and there
are frequently places where inferring the intent could be ambiguous. Consider
this snippet:</p>
<pre><code>xs = [<span>1</span>, <span>2</span>, <span>3</span>]
xs &lt;&lt; <span>nil</span>


</code></pre>
<p><a href="https://sorbet.run/#%23%20typed%3A%20true%0A%0Axs%20%3D%20%5B1%2C%202%2C%203%5D%0Axs%20%3C%3C%20nil">→ View on sorbet.run</a></p>
<p>A type checker could infer one of two types here:</p>
<ol>
<li>either the programmer meant for <code>xs</code> to be an array of <code>Integer</code>'s and
<code>nil</code>'s (i.e., <code>T::Array[T.nilable(Integer)]</code> in Sorbet’s syntax), or</li>
<li>the programmer made a mistake, and didn’t intend to allow <code>nil</code>'s in <code>xs</code>
(i.e., it was intended to be a <code>T::Array[Integer]</code>, and this code should
report a static error).</li>
</ol>
<p>Any static checker must assume one of these outcomes, but there are times when
either might make sense. Explicit annotations resolve these ambiguities. In this
case, Sorbet assumes (2) by default, but other type systems do other things. For
example, Flow <a href="https://flow.org/try/#0MYewdgzgLgBAHhGBeGBtAjAGhgJmwZgF0BuAKAQDoAHAVwgAsAKMGgG1YEpig">assumes (1) by default</a>.</p>
<p>Here’s how to use an inline annotation in Sorbet to explicitly declare that (1)
is intended:</p>
<pre><code>xs = T.let([<span>1</span>, <span>2</span>, <span>3</span>], T::Array[T.nilable(Integer)])
xs &lt;&lt; <span>nil</span>


</code></pre>
<p><a href="https://sorbet.run/#%23%20typed%3A%20true%0A%0Axs%20%3D%20T.let(%5B1%2C%202%2C%203%5D%2C%20T%3A%3AArray%5BT.nilable(Integer)%5D)%0Axs%20%3C%3C%20nil">→
View on sorbet.run</a></p>
<h2>Inline type annotations must be Ruby syntax</h2>
<p>For the time being, Matz and the Ruby core team want to experiment with type
annotations without changing Ruby syntax, because that would require everyone to
upgrade to a specific Ruby version to benefit. Because Sorbet values inline type
annotations, we embedded a type annotation language in Ruby with no syntax
changes needed:</p>
<pre><code>extend T::Sig

sig {params(<span>strings:</span> T::Array[String]).returns(Integer)}
<span><span>def</span> <span>count_letters</span><span>(strings)</span></span>
  strings.map(&amp;<span>:length</span>).sum
<span>end</span>
</code></pre>
<p><a href="https://sorbet.run/#%23%20typed%3A%20true%0A%0Aextend%20T%3A%3ASig%0A%0Asig%20%7Bparams(strings%3A%20T%3A%3AArray%5BString%5D).returns(Integer)%7D%0Adef%20count_letters(strings)%0A%20%20strings.map(%26%3Alength).sum%0Aend">→
View on sorbet.run</a></p>
<p>Sorbet’s syntax is 100% valid Ruby, which has tons of benefits!</p>
<ul>
<li>Syntax highlighting for type annotations already works in 100% of Ruby
editors.</li>
<li>There’s no transpiler step required—Ruby code with Sorbet type annotations
runs directly.</li>
<li>Every RuboCop rule ever written works with Sorbet type annotations.</li>
<li>Any Ruby IDE with Go to Definition already has Go to Definition on type
annotations.</li>
<li>Sorbet’s RBI files are just Ruby code with empty method bodies, reusing the
inline syntax.</li>
<li>It’s backwards compatible with all supported versions of Ruby.</li>
</ul>
<p>The obvious downside is that there are prettier inline type annotation syntaxes
that are not valid Ruby. The Ruby grammar is not so complicated that it couldn’t
be changed to support type annotations. But again, this syntax does so well
<strong>because</strong> it doesn’t fracture the Ruby community with incompatible syntax
changes.</p>
<h2>Sorbet is committed to improving</h2>
<p>At the end of the day, it’s not a choice between Ruby 3 or Sorbet—you can have
both at the same time. We love that the Ruby core team is bringing types to
Ruby, and we’re happy to incorporate their work into Sorbet. We plan to give
back too: it’s likely that the initial release of RBS files for the Ruby
standard library will be created by converting Sorbet’s already extensive
standard library annotations into the RBS format.</p>
<p>At the same time, we’re hard at work improving Sorbet. Stripe has millions of
lines of Ruby code and that number is only growing. We’re nearing our <a href="https://en.wikipedia.org/wiki/High_availability#Percentage_calculation">second
nine</a> of percentage of files at <code># typed: true</code> or above—which is to say, those
millions of lines of Ruby use a lot of types. We have hundreds of engineers
writing Ruby and using our Sorbet-powered IDE every day.</p>
<p>Sorbet type checks these millions of lines of Ruby code in seconds, helps
prevent countless production incidents, and helps new Stripe engineers spin up
fast. And it does all this today! If you want to try it out, check out the docs:</p>
<p><a href="https://sorbet.org/docs/adopting">→ Adopting Sorbet in an Existing Codebase</a></p>
<p>or play around with small Sorbet examples online:</p>
<p><a href="https://sorbet.run/">→ Sorbet playground</a></p>
<p>Sorbet already has extensive type annotations for the Ruby standard library,
thanks in large part to the nearly 200 contributors to Sorbet that you can find
<a href="https://github.com/sorbet/sorbet/graphs/contributors">on GitHub</a>, the vast majority of whom come to Sorbet from outside
of Stripe and the Sorbet team.</p>
<p>We’re happy that the Ruby core team is focused on continually improving Ruby,
because we are too. ❤️</p>
<p>— Jake “jez” Zimmerman, on behalf of the Sorbet team</p>
<p><em>Thanks to Dmitry Petrashko, James Iry, Trevor Elliott, and Soutaro Matsumoto
for reading early drafts of this post.</em></p>
</span></p></div></div></div>]]>
            </description>
            <link>https://sorbet.org/blog/2020/07/30/ruby-3-rbs-sorbet</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008520</guid>
            <pubDate>Fri, 31 Jul 2020 13:48:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Parent’s Internet – Solving the Misinformation Problem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008470">thread link</a>) | @lanecwagner
<br/>
July 31, 2020 | https://qvault.io/2020/07/31/fake-news-misinformation-fix/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/31/fake-news-misinformation-fix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>The age of information is not what we all hoped it would be. We successfully digitized the majority of human knowledge, and we even made it freely accessible to most. Now the problem is different, we have <em>too much</em> information. Answers to most questions can be found in thousands of distinct places online, and the new problem is <em>“whos information can we trust?”</em></p>



<h2>What Platforms Think They Should Do About Fake News</h2>



<p>Twitter and Facebook have recently been under scrutiny for their censorship of coronavirus related misinformation. For example, a <a aria-label="undefined (opens in a new tab)" href="https://www.bbc.com/news/53559938" target="_blank" rel="noreferrer noopener">video claiming Hydroxychloroquine is a Corona cure</a> recently went viral on Facebook, and the video keeps getting taken down. The video contains some wild assertions, made by Stella Immanuel, who also believes that gynecological problems are the result of <a aria-label="undefined (opens in a new tab)" href="https://www.youtube.com/watch?v=9yCXCP3evAg" target="_blank" rel="noreferrer noopener">spiritual relationships</a>.</p>



<p>By removing content they believe to be dubious, Twitter and Facebook have made themselves arbiters of truth. Anecdotally, all the posts I’ve seen them remove HAVE contained misinformation, but the fact remains… these platforms have become self-appointed authorities on the veracity of our information.</p>



<p><strong>This is a problem.</strong></p>



<h2>So We Can’t Censor?</h2>



<p>We certainly can, and we certainly should in some cases. Let’s get some obvious ones out of the way:</p>



<ul><li>Child Pornography</li><li>Death Threats</li><li>Doxing</li></ul>



<p>There may be some other clear examples where censoring is unquestionably the right choice, though I doubt there are many. Let’s look at some more controversial examples:</p>



<ul><li>Hate Speech</li><li>Misinformation</li></ul>



<p>I would posit that here the answer is contingent on <em>who </em>is doing the censoring. While hate speech and misinformation are disgusting, I don’t want a government deciding <em>what </em>is hate speech, or deciding <em>what </em>is truth.</p>



<div><figure><img src="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg" alt="war is peace 1984 orwell" srcset="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg 300w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace-768x576.jpg 768w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace.jpg 877w" sizes="(max-width: 300px) 100vw, 300px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg 300w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace-768x576.jpg 768w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace.jpg 877w" data-src="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>George Orwell, 1984</figcaption></figure></div>



<p>That said, I certainly want an online system where hate speech and misinformation are effectively filtered out of the conversation. Ideally, every online participant is a virtuous, educated, and concerned conversationalist. If this were the case, posts of an undesirable nature would effectively be ignored due to not receiving the likes, shares, upvotes, and comments they need to spread.</p>



<p>In reality, we can’t have such a pacifistic approach. We need to <a href="https://www.lesswrong.com/posts/tscc3e5eujrsEeFN4/well-kept-gardens-die-by-pacifism" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">protect our gardens</a>.</p>



<h2>Misinformation – What Should Platforms Do?</h2>



<p>It starts here. All online platforms are responsible for the tools they provide for moderation, if not for the moderation itself.</p>



<p>Platforms <strong>should</strong>:</p>



<ul><li>Remove dangerous content such as doxing, threats, child trafficking, etc</li><li>Provide tools for users to mark content as harmful or misleading</li><li>Mark content as dubious</li></ul>



<p>Platforms <strong>should not:</strong></p>



<ul><li><em>Remove </em>misleading content</li></ul>



<p>By removing misleading content, platforms run the risk of fueling an <a aria-label="undefined (opens in a new tab)" href="https://rationalwiki.org/wiki/Argumentum_ad_martyrdom" target="_blank" rel="noreferrer noopener">argumentum ad martyrdom</a> mentality. Removing information can have an adverse effect, causing people to suspect we have a nefarious reason for removing it.</p>



<blockquote><p>But the fact that some geniuses were laughed at does not imply that all who are laughed at are geniuses. They laughed at&nbsp;Columbus, they laughed at Fulton, they laughed at the Wright brothers. But they also laughed at Bozo the Clown.</p><cite>– Carl Sagan, Probably</cite></blockquote>



<h2>What Should Users Do About Misinformation and Fake News?</h2>



<p>Users <strong>should</strong>:</p>



<ul><li>Read entire articles before liking, sharing, or commenting</li><li>Deploy extra skepticism to information with a clear political or monetary agenda</li><li>Be self-aware about their preconceived notions and confirmation biases</li><li>Look for the primary source of information</li><li>Ensure information is up-to-date</li></ul>



<p>Users <strong>should not:</strong></p>



<ul><li>Reward clickbait titles with engagement</li><li>Exclusively follow, subscribe, or search for content that aligns with their current beliefs</li><li>Assume your position is valid because people are trying to remove your content</li><li>Trust articles and posts coming from sites that appear <a aria-label="undefined (opens in a new tab)" href="https://www.sitelock.com/blog/is-this-website-safe/" target="_blank" rel="noreferrer noopener nofollow">unsafe</a></li></ul>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/31/fake-news-misinformation-fix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008470</guid>
            <pubDate>Fri, 31 Jul 2020 13:43:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stripe Checkout with Django]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008425">thread link</a>) | @bhoey
<br/>
July 31, 2020 | https://bhoey.com/blog/stripe-checkout-with-django/ | <a href="https://web.archive.org/web/*/https://bhoey.com/blog/stripe-checkout-with-django/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><a href="https://stripe.com/">Stripe</a> is one of the most developer-friendly payment processors available today, having extensive and well-documented <a href="https://stripe.com/docs/api">APIs</a> and <a href="https://stripe.com/docs/development">SDKs</a> enabling you to finely customize your customer payment flow. If you have a simple use-case or would prefer to offload the majority of the checkout process, Stripe also provides <a href="https://stripe.com/payments/checkout">Stripe Checkout</a> where Stripe themselves will directly handle collecting the payment information and charging the customer.</p>
<p>There are several benefits to using Stripe Checkout instead of custom developing checkout pages, among them:</p>
<ul>
<li><b>Reduces internal development and maintenance</b></li>
<li><b>Multiple language support</b></li>
<li><b>Regulation Compliance including <a href="https://en.wikipedia.org/wiki/Payment_Card_Industry_Data_Security_Standard">PCI DSS</a> and <a href="https://en.wikipedia.org/wiki/Strong_customer_authentication">Strong Customer Authentication (SCA)</a></b></li>
<li><b>Better fraud detection</b></li>
</ul>
<p>One of the biggest downsides of using Stripe Checkout is that customers need to be redirected to Stripe's website in order to complete the transaction, which has the potential to be a sub-optimal user experience. These are trade-offs that you'll need weigh when choosing an approach, however it should be noted that you're not locked in forever. It's perfectly reasonable to start processing customer orders with Stripe Checkout, and then at a later date switch to using a custom, streamlined checkout flow.</p>
<h2>Stripe Checkout Overview</h2>
<p>Regardless of whether you choose client-only or client/server approaches (we'll cover these in a moment), the the general Stripe Checkout flow is as follows:</p>
<p><img src="http://bhoey.com/blog/wp-content/uploads/2020/07/StripeCheckout-Overview2.jpg" alt="Stripe Checkout Overview" width="449" height="471" srcset="https://bhoey.com/blog/wp-content/uploads/2020/07/StripeCheckout-Overview2.jpg 449w, https://bhoey.com/blog/wp-content/uploads/2020/07/StripeCheckout-Overview2-286x300.jpg 286w" sizes="(max-width: 449px) 100vw, 449px"></p>
<p><b>1.</b> Starting from your product page, you'll call stripe.redirectToCheckout() JavaScript function with the appropriate parameters. This will redirect the user from your website to Stripe's to complete the payment process.</p>
<p><b>2.</b> Stripe will call any webhooks registered for related events. This is an important part since Stripe recommends not depending only on the arrival at the success URL as confirmation (for example the customer could land on the success URL somehow without going through the Stripe payment process). Instead you should monitor the webhook events to confirm the payment was completed successfully.</p>
<p><b>3.</b> Stripe will then redirect the user back to your site when they have either completed or canceled the checkout process. The URLs to redirect them to would have either been specified in the redirectToCheckout() call or specified on a checkout session beforehand (explained later).</p>
<h2>Client-Only Vs Client/Server</h2>
<p>There are two ways to invoke Stripe Checkout from your website: <b>client-only</b> and <b>client/server</b>.</p>
<p>The <b>Client-Only</b> approach is where all parameters are set in the frontend via Javascript and will be passed to Stripe Checkout on redirect. This method is the quickest to implement however is limited in what details you can pass to Stripe and the use-cases you can support versus the Client/Server approach. For example you aren't able to specify the Stripe customer id or handle the single-customer multiple subscriptions use-case using this approach. Stripe has <a href="https://github.com/stripe-samples/checkout-single-subscription/tree/master/client-only/client">example code on GitHub</a> demonstrating the client-only approach.</p>
<p><b>Client/Server</b> on the other hand is a staged approach where you first prepare a Checkout Session for the user on the backend and then reference it by id in the Stripe Javascript call on the frontend. This allows for much more control and is what the remainder of this post will cover.</p>
<h2>Client/Server: Preparing the Checkout Session On The Backend</h2>
<p>The first step in the client/server approach is to set up the mechanisms that will create a Checkout Session on the backend. This will be called by the frontend product page right before redirecting the user to Stripe.</p>
<p>First we define a <b>create_checkout_session</b> view that will handle requests from the frontend. Several of the details will be dependent on your particular environment, but the broad strokes are as follows:</p>
<pre>&nbsp;
# views.py

import stripe
from django.http import HttpRequest, JsonResponse
...
@login_required
def create_checkout_session(request: HttpRequest):

    customer = ... # get customer model based off request.user

    if request.method == 'POST':

        # Assign product price_id, to support multiple products you 
        # can include a product indicator in the incoming POST data
        price_id = ... # 

        # Set Stripe API key
        stripe.api_key = settings.STRIPE_SECRET_KEY

        # Create Stripe Checkout session
        checkout_session = stripe.checkout.Session.create(
            payment_method_types=["card"],
            mode="subscription",
            line_items=[
                {
                    "price": price_id,
                    "quantity": 1
                }
            ],
            customer=customer.id,
            success_url=f"https://YOURDOMAIN.com/payment/success?sessid={{CHECKOUT_SESSION_ID}}",
            cancel_url=f"https://YOURDOMAIN.com/payment/cancel", # The cancel_url is typically set to the original product page
        )

    return JsonResponse({'sessionId': checkout_session['id']})
&nbsp;
</pre>
<p>One thing to note is that {CHECKOUT_SESSION_ID} template text will be replaced by Stripe when it calls back to the success_url. (The text in this case has double curly braces on each side since I am using python f-strings and to escape a curly brace you double it).</p>
<p>Then we associate a URL path to this view in our urls.py file:</p>
<pre>&nbsp;
# urls.py
...
path('stripe/create-checkout-session', views.create_checkout_session, name="stripe_create_checkout_session"),
&nbsp;
</pre>
<h2>Client/Server: Frontend Product Page</h2>
<p>On the frontend, we'll add a Buy button and register an event listener for when its clicked. On a click event, we'll send a request to the backend to create the Checkout Session and wait for the response to get the new session's id. Finally we'll call redirectToCheckout with that session id, thereby allowing Stripe to connect the redirect request with the session previously created.</p>
<p>*Note the below code assumes the product page was rendered and supplied with context variables such as STRIPE_PUB_KEY and crsf_token.</p>
<pre>&nbsp;

    &lt;script src="https://js.stripe.com/v3/"&gt;&lt;/script&gt;

...

    &lt;button type="button" id="buy-btn"&gt;Buy&lt;/button&gt;

...

    &lt;script&gt;
      var DOMAIN = window.location.origin;

      var stripe = Stripe("{{ STRIPE_PUB_KEY }}");

      // Handle any errors from Checkout
      var handleResult = function (result) {
        if (result.error) {
          var displayError = document.getElementById("error-message");
          displayError.textContent = result.error.message;
        }
      };

      // Create a Checkout Session with the selected plan ID
      var createCheckoutSession = function() {
        return fetch("/stripe/create-checkout-session", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "X-CSRFToken":  '{{csrf_token}}',
          },
          // ... body section if you want to pass the product or price_id to the backend
        }).then(function(result) {
          return result.json();
        });
      };

    // Setup event handler to create a Checkout Session when button is clicked
      document
        .getElementById("buy-btn")
        .addEventListener("click", function (evt) {
          createCheckoutSession().then(function(data) {
            // Call Stripe.js method to redirect to the new Checkout page
            stripe
              .redirectToCheckout(
                {
                    sessionId: data.sessionId
                }
              )
              .then(handleResult);
          });
        });
    &lt;/script&gt;
</pre>
<h2>Client/Server: Finalizing The Checkout</h2>
<p>The final step would be to listen for the <b>'checkout.session.completed'</b> webhook event and update the user status on your backend. The webhook payload looks similar to the following:</p>
<pre>{
  "id": "evt_123abc",
  "object": "event",
  "api_version": "2020-03-02",
  "created": 1596139528,
  "data": {
    "object": {
      "id": "cs_test_1234",
      "object": "checkout.session",
      "amount_subtotal": 1499,
      "amount_total": 1499,
      "cancel_url": "https://YOURDOMAIN.com/payment/cancel",
      "currency": "usd",
      "customer": "cus_1234",
      "livemode": false,
      "metadata": {
      },
      "mode": "subscription",
      "payment_method_types": [
        "card"
      ],
      "subscription": "sub_1234",
      "success_url": "https://YOURDOMAIN.com/payment/success?sessid={CHECKOUT_SESSION_ID}",
    }
  },
  "request": {
    "id": "req_1234",
    "idempotency_key": null
  },
  "type": "checkout.session.completed"
}
</pre>
<p>Then when the user gets redirected to your success URL, you can verify the (now replaced) <b>sessid={CHECKOUT_SESSION_ID}</b> URL parameter value against what was received via the webhook to confirm payment was successful.</p>
<h2>Extra: What About djstripe?</h2>
<p><a href="https://dj-stripe.readthedocs.io/en/stable/">djstripe</a> is a Django app with additional functionality and models that aims to ease the integration between Django and Stripe.</p>
<p>There's nothing above that interferes with incorporating djstripe, in fact it would be a good fit for getting the customer object in the <b>create_checkout_session</b> view and relaying webhook events as Django signals. The instructions above were mainly intended to focus on common parts that can be implemented with or without djstripe.</p>
</div></div>]]>
            </description>
            <link>https://bhoey.com/blog/stripe-checkout-with-django/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008425</guid>
            <pubDate>Fri, 31 Jul 2020 13:37:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What every developer should know about consistency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008416">thread link</a>) | @MindGods
<br/>
July 31, 2020 | https://robertovitillo.com/what-every-developer-should-know-about-consistency/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/what-every-developer-should-know-about-consistency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>July 31, 2020</p></header><p>If you make a request to a database to update some data, the change won’t necessarily be visible to other clients right away, even if your request has completed successfully. Whether it becomes visible sooner rather than later depends on the consistency guarantees offered by the database.</p><p>“But wait, aren’t databases supposed to take care of consistency issues for me?” I hear you ask. Some databases come with counter-intuitive consistency guarantees to provide high availability and performance. Others have knobs that allow you to chose whether you want better performance or stronger consistency guarantees, like <a href="https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels">Azure’s Cosmos DB</a>. Because of that, you need to know what the trade-offs are, and whether there are knobs you can use to tune your database to your specific use-case.</p><p>Let’s take a look at what happens when you send a request to a database. In an ideal world, your request executes instantaneously:</p><p><span>
      <a href="https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/807a0/ideal.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="ideal" title="ideal" src="https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/fcda8/ideal.png" srcset="https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/12f09/ideal.png 148w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/e4a3f/ideal.png 295w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/fcda8/ideal.png 590w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/efc66/ideal.png 885w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/c83ae/ideal.png 1180w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/807a0/ideal.png 1652w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>But we don’t live an ideal world - your request needs to reach the data store, which then needs to process the request and finally send back a response to you. All these actions take time and are not instantaneous:</p><p><span>
      <a href="https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/807a0/cones.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cones" title="cones" src="https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/fcda8/cones.png" srcset="https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/12f09/cones.png 148w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/e4a3f/cones.png 295w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/fcda8/cones.png 590w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/efc66/cones.png 885w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/c83ae/cones.png 1180w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/807a0/cones.png 1652w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>The best guarantee a database can provide is that the request executes somewhere between its invocation and completion time. You might think that this doesn’t look like a big deal - after all, it’s what you are used to when writing single-threaded applications - if you assign 1 to x and read its value right after, you expect to find 1 in there, assuming there is no other thread writing to the same variable. But, once you start dealing with data stores that replicate their state on multiple machines for high availability and scalability, all bets are off. To understand why that’s the case, we will explore the trade-offs a system designer has to make to implement reads in a simplified model of a distributed database.</p><p>Suppose we have a distributed key-value store, which is composed of a set of replicas. The replicas elect a leader among themselves, which is the only node that can accept writes. When the leader receives a write request, it broadcasts it asynchronously to the other replicas. Although all replicas receive the same updates in the same order, they do so at different times. </p><p>You are tasked to come up with a strategy to handle read requests - how would you go about it? Well, a read can potentially be served by the leader or a replica. If all reads were to go through the leader, the throughput would be limited by what a single node can handle. Alternatively, any replica could serve any read request - that would definitely scale, but then two clients, or observers, could have a different view of the system’s state, as replicas can lag behind the leader and between them.</p><p>Intuitively, there is a trade-off between how consistent the observers’ views of the system are, and the system’s performance and availability. To understand this relationship, we need to define precisely what we mean by consistency. We will do so with the help of <a href="https://jepsen.io/consistency">consistency models</a>, which formally define the possible views of the system’s state observers can experience. </p><h2 id="strong-consistency"><a href="#strong-consistency" aria-label="strong consistency permalink"></a>Strong Consistency</h2><p>If clients send writes and reads exclusively to the leader, then every request appears to take place atomically at a very specific point in time as if there was a single copy of the data. No matter how many replicas there are or how far behind they are lagging, as long as the clients always query the leader directly, from their point of view there is a single copy of data.</p><p>Because a request is not served instantaneously, and there is a single node serving it, the request executes somewhere between its invocation and completion time. Another way to think about it is that once a request completes, it’s side-effects are visible to all observers:</p><p><span>
      <a href="https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/95fa1/linearizability.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="linearizability" title="linearizability" src="https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/fcda8/linearizability.png" srcset="https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/12f09/linearizability.png 148w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/e4a3f/linearizability.png 295w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/fcda8/linearizability.png 590w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/efc66/linearizability.png 885w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/c83ae/linearizability.png 1180w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/95fa1/linearizability.png 1816w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>Since a request becomes visible to all other participants between its invocation and completion time, there is a real-time guarantee that must be enforced - this guarantee is formalized by a consistency model called <a href="https://jepsen.io/consistency/models/linearizable">linearizability</a>, or strong consistency. Linearizability is the strongest consistency guarantee a system can provide for single-object requests. </p><p>What if the client sends a read request to the leader, but by the time the request gets there, the server that received the request thinks it’s still the leader, but it actually was deposed? If the ex-leader was to process the request, the system would no longer be strongly consistent. To guard against this case, the presumed leader first needs to contact a majority of the replicas to confirm whether it still is the leader. Only then is it allowed to execute the request and send back the response to the client. This considerably increases the time required to serve a read.</p><h3 id="sequential-consistency"><a href="#sequential-consistency" aria-label="sequential consistency permalink"></a>Sequential Consistency</h3><p>So far, we have discussed serializing all reads through the leader. But doing so creates a single chokepoint, which limits the system’s throughput. On top of that, the leader needs to contact a majority of replicas to handle a read. To increase the read performance, we could allow the replicas to handle requests as well.</p><p>Even though a replica can lag behind the leader, it will always receive new updates in the same order as the leader. If a client A only ever queries replica 1, and client B only ever queries replica 2, the two clients will see the state evolving at different times, as replicas are not entirely in sync:</p><p><span>
      <a href="https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/555cf/sequential.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="sequential" title="sequential" src="https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/fcda8/sequential.png" srcset="https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/12f09/sequential.png 148w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/e4a3f/sequential.png 295w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/fcda8/sequential.png 590w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/efc66/sequential.png 885w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/c83ae/sequential.png 1180w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/555cf/sequential.png 1960w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>The consistency model in which operations occur in the same order for all observers, but doesn’t provide any real-time guarantee about when an operation’s side-effect becomes visible to the observers, is called <a href="https://jepsen.io/consistency/models/sequential">sequential consistency</a>. The lack of real-time guarantees is what differentiates sequential consistency with linearizability. </p><p>A simple application of this model is a producer/consumer system synchronized with a queue - a producer node writes items to the queue, which a consumer reads. The producer and the consumer see the items in the same order, but the consumer lags behind the producer.</p><h3 id="eventual-consistency"><a href="#eventual-consistency" aria-label="eventual consistency permalink"></a>Eventual Consistency</h3><p>Although we managed to increase the read throughput, we had to pin clients to replicas - what if a replica goes down? We could increase the availability of the store by allowing a client to query any replica. But, this comes at a steep price in terms of consistency. Say there are two replicas 1 and 2, where replica 2 lags behind replica 1. If a client queries replica 1 and right after replica 2, it will see a state from the past, which can be very confusing. The only guarantee a client has is that eventually, all replicas will converge to the final state if the writes to the system stop. This consistency model is called eventual consistency. </p><p>It’s challenging to build applications on top of an eventually consistent data store because the behavior is different from the one you are used to when writing single-threaded applications. Subtle bugs can creep up that are hard to debug and to reproduce. Yet, in eventual consistency’s defense, not all applications require linearizability. You need to make the conscious choice whether the guarantees offered by your data store, or lack thereof, satisfy your application’s requirements. An eventually consistent store is perfectly fine if you want to keep track of the number of users visiting your website, as it doesn’t really matter if a read returns a number that is slightly out of date. But for a payment processor, you definitely want strong consistency.</p><p>There are more <a href="https://jepsen.io/consistency">consistency models</a> than the ones presented in this post. Still, the main intuition behind them is the same: the stronger the consistency guarantees are, the higher the latency of individual operations is, and the less available the store becomes when failures happen. This relationship is formalized by the <a href="https://en.wikipedia.org/wiki/PACELC_theorem">PACELC theorem</a>. It states that in case of network partitioning (P) in a distributed computer system, one has to choose between availability (A) and consistency (C), but else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C). </p><p>In my <a href="https://systemdesignmanual.com/">system design book</a>, I explore other tunable trade-offs data stores make to guarantee high availability and performance, like the isolation guarantees that prevent a group of operations within a transaction from interfering with other concurrently running transactions. </p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/what-every-developer-should-know-about-consistency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008416</guid>
            <pubDate>Fri, 31 Jul 2020 13:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sasa Juric on Static Typing and Beam Languages]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008358">thread link</a>) | @ancatr
<br/>
July 31, 2020 | https://gotopia.tech/bookclub/episodes/how-to-start-with-the-elixir-programming-language | <a href="https://web.archive.org/web/*/https://gotopia.tech/bookclub/episodes/how-to-start-with-the-elixir-programming-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<nav x-data="{ open: false }">
  <div>
    <div>
      <div>
        <p><a href="https://gotopia.tech/">
            <img src="https://gotopia.tech/images/gotopia_logo_white.svg" alt="GOTOpia logo">
          </a>
        </p>
        
      </div>

      
    </div>

    <!--
    Mobile menu, toggle classes based on menu state.

    Menu open: "block", Menu closed: "hidden"
  -->
    
  </div>
</nav>
  

<div>
  <div>
    <div>
    <article>
    <header>
        
        
    </header>
    <main>
    

         <div>
<div data-phx-session="SFMyNTY.g2gDaAJhBHQAAAAHZAACaWRtAAAAFHBoeC1GaWZCa3dDWm1vTFlqVTN5ZAAKcGFyZW50X3BpZGQAA25pbGQACHJvb3RfcGlkZAADbmlsZAAJcm9vdF92aWV3ZAAnRWxpeGlyLkNvbmZXZWIuT3JnYW5pc2F0aW9uLllvdXR1YmVMaXZlZAAGcm91dGVyZAADbmlsZAAHc2Vzc2lvbnQAAAABbQAAAAh2aWRlb19pZG0AAAALMFl4TTh6TVdIZTRkAAR2aWV3ZAAnRWxpeGlyLkNvbmZXZWIuT3JnYW5pc2F0aW9uLllvdXR1YmVMaXZlbgYAGCxHtHMBYgABUYA.OA6Gj5ljgOZFap-I0koRmvnb9YVnVshI6ofBJAOOc70" data-phx-static="SFMyNTY.g2gDaAJhBHQAAAADZAAKYXNzaWduX25ld2pkAAVmbGFzaHQAAAAAZAACaWRtAAAAFHBoeC1GaWZCa3dDWm1vTFlqVTN5bgYAGCxHtHMBYgABUYA.IYOqmsWSzi6qQjH-4gOMCy24uKKRld4xa58aAFm-S2Q" data-phx-view="Organisation.YoutubeLive" id="phx-FifBkwCZmoLYjU3y"><div x-data="{ playing: false }">
    <div>

<a href="#" phx-click="play-video" phx-value="0YxM8zMWHe4">                <img src="https://img.youtube.com/vi/0YxM8zMWHe4/hqdefault.jpg">
                
</a>

    </div>

</div>
</div>         </div>

<p>Check out this excerpt from the upcoming Book Club episode with <a href="https://www.linkedin.com/in/sa%C5%A1a-juri%C4%87-21b23186/">Saša Jurić</a> and <a href="https://www.linkedin.com/in/erikschon/">Erik Schön</a>&nbsp;where they explore whether Elixir could be the right tool for your job. In the interview, Erik Schön, managing director at Nordic, also explores key benefits and practices with <a href="https://elixir-lang.org/">Elixir</a>, a functional language with over 20k commits on Git Hub. The upcoming interview is based on Saša's book <em><a href="https://amzn.to/3iaGv5l">Elixir in Action</a></em>.</p>
<!-- wp:paragraph -->

<!-- /wp:paragraph -->
<!-- wp:paragraph -->

<!-- /wp:paragraph -->
<!-- wp:paragraph -->
<p><strong>Erik Schön</strong>:I was listening to and watching another episode on <a href="https://gotopia.tech/bookclub/episodes/upgrade-your-frontend-game-be-an-elm-wizard">Elm in Action</a>. Elm is a totally different beast, of course. But what I found interesting in there is the approach taken to static typing. Which is very, very rigid. What are your thoughts on static typing for the BEAM and BEAM languages?</p>
<!-- /wp:paragraph -->
<!-- wp:paragraph -->

<!-- /wp:paragraph -->
<!-- wp:paragraph -->

<!-- /wp:paragraph -->
<!-- wp:paragraph -->
<p><strong>Saša Jurić</strong>: In my view, the lack of static typing is the biggest deficiency in BEAM languages. I know that there are like camps dynamic versus static. I've personally done both for like many, many years. For the past 15 years, I've been mostly using dynamic languages. I'm now pretty much certain to say that I believe that static is definitely a better option. I still love Erlang and Elixir. These are like my first languages, regardless of the lack of static typing because they offer something that I cannot find anywhere else, but I would love to see static typing stories on BEAM languages.</p>
<!-- /wp:paragraph -->
<!-- wp:paragraph -->

<!-- /wp:paragraph -->
<!-- wp:paragraph -->
<p>Unfortunately, mostly, it hasn't been available. So what we have for Erlang and Elixir is what is called the success typing through the tool called Dialyzer, which I like to say is far from perfect but it's the best we got. However, there are initiatives, very interesting initiatives. There's one language called Alpaca and another language called Gleam, which looked very, very promising. They basically are aimed to bring static typing into the BEAM world, like, proper on static typing. This is something I'm super excited about. I still didn't have the chance to try them out but I will definitely love to see how this story unfolds.<br></p>
<!-- /wp:paragraph -->
<!-- wp:paragraph -->

<!-- /wp:paragraph -->
<!-- wp:heading {"level":3} -->
<h3>Stay tuned for the entire Book Club episode "Ripping Out the Benefits of Elixir: How to Start" with Saša Jurić and Erik Schön </h3>
<!-- /wp:heading -->
<!-- wp:paragraph -->

<!-- /wp:paragraph -->
<figure><p>
<iframe title="Join the GOTO Book Club to Learn From the Brightest Minds in Tech" width="500" height="281" src="https://www.youtube.com/embed/xQ4XBBPancI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>
<!-- wp:spacer -->

<!-- /wp:spacer -->
<!-- wp:paragraph -->

<!-- /wp:paragraph -->
<!-- wp:acf/media-text {"id":"block_5f214b3ee2846","name":"acf/media-text","data":{"media_type":"image","_media_type":"field_5d8dd1b2fe79e","media_position":"left","_media_position":"field_5d481f02ad2a2","media_size":"50","_media_size":"field_5e8a09386d05c","image":90585,"_image":"field_5d481f2ead2a3","text":"Elixir in Action teaches you to apply the new Elixir programming language to practical problems associated with scalability, concurrency, fault tolerance, and high availability.","_text":"field_5d481f4ead2a4","cta":{"title":"Buy the book","url":"https://amzn.to/3iaGv5l","target":""},"_cta":"field_5d5a6aa281a00"},"align":"","mode":"edit"} /-->
<!-- wp:acf/media-text {"id":"block_5ef599cec936e","name":"acf/media-text","data":{"media_type":"image","_media_type":"field_5d8dd1b2fe79e","media_position":"left","_media_position":"field_5d481f02ad2a2","media_size":"50","_media_size":"field_5e8a09386d05c","image":90585,"_image":"field_5d481f2ead2a3","text":"Elixir in Action teaches you to apply the new Elixir programming language to practical problems associated with scalability, concurrency, fault tolerance, and high availability.","_text":"field_5d481f4ead2a4","cta":{"title":"Buy the book","url":"https://amzn.to/3iaGv5l","target":""},"_cta":"field_5d5a6aa281a00"},"align":"","mode":"edit"} /-->
<div>
    <div>
        <div>
            <p>Elixir in Action teaches you to apply the new Elixir programming language to practical problems associated with scalability, concurrency, fault tolerance, and high availability.</p>
                            <p><a href="https://amzn.to/3iaGv5l" target="_self">Buy the book</a>
                    </p></div>
        <p><img src="https://blog.gotocon.com/wp-content/uploads/2020/06/Juric-Elixir-2ed-HI.jpg" alt="Elixir in action">
                        </p>
    </div>
</div>
    </main>
</article>

    </div>

    
  </div>
</div>
        <section>
        <h2>
Recent <strong>Episodes</strong>        </h2>

    </section>
 



     <section>
    <h2>
        Our <strong>  Books </strong>
    </h2>

</section>
 

  
</div>
  </div></div>]]>
            </description>
            <link>https://gotopia.tech/bookclub/episodes/how-to-start-with-the-elixir-programming-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008358</guid>
            <pubDate>Fri, 31 Jul 2020 13:30:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microservices Architecture versus SOA]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008284">thread link</a>) | @sirkarthik
<br/>
July 31, 2020 | https://blog.codonomics.com/2020/07/microservices-architecture-versus-soa.html | <a href="https://web.archive.org/web/*/https://blog.codonomics.com/2020/07/microservices-architecture-versus-soa.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4885813950905166203" itemprop="description articleBody">
<p>
This is my take on differences between <b>Microservices Architecture (MSA)</b> and <b>Services Oriented Architecture (SOA)</b> based on my experience of working with these architectural styles thus far. I do understand that there are companies that doesn't distinguish between these two architecture lingos and use them interchangeable. And then there are also companies that have their own definitions of how each of these architectural styles are modeled. There is no right or wrong definition here (Ouch!, the world became chaotic even before we realized). What truly matters is that knowing our audience as we speak to them. It is unwarranted chaos when our mental models are different.
</p>
<p>So, at the very outset let me state clearly that I see these models differently by virtue of my experience. So this post is my perspective on the difference between these two architectural patterns as I had experienced it.&nbsp;</p>

<p><img data-original-height="720" data-original-width="1280" src="https://1.bp.blogspot.com/-oZyFTlkVYck/XyQUKprpuyI/AAAAAAAAEwE/NaLxhQs0bcEdTADEKHc4RyYjfOXI8wv1gCLcBGAsYHQ/s640/lion-vs-wild-dogs.jpg" width="640"></p>
<div>
	<ul>
		<br>
		<li>SOA is monolithic solution like a big lion in the jungle; how it works would be pretty evident for a pair of eyes.
			<br>MSA is distributed system constituting a set of services working together as one, like a pack of wild dogs working together to attack its target; how it works together would seem like a magic for a pair of eyes.<br></li>
		<br>
		<li>SOA is layered. The app is broken into independent functional modules owned by respective teams. In the Java EE world, each team owning the module builds and publishes its artifacts as libraries for consumption by the core app. The application thus remains monolithic, so any changes to a module meant building and deploying the entire application. This also means that the release of functional modules needs to be coordinated with that of the main application. At least that is how the teams I had been in had build the big monolithic enterprise application, the SOA way.
			<br>MSA is about breaking the large monolithic app into independently deploy-able application where the teams owning it can have its own release cadence; although the larger release of the application still requires some bit of coordinated efforts.</li>
		<br>
		<li>SOA standardizes on shared release cadence requiring larger project planning to keep teams occupied and syncing efforts across teams.
			<br>MSA liberates teams to have its own release cadence to meet the needs of the larger release cycle of the application.</li>
		<br>
		<li>SOA is externally focussed. It was intended to solving communication gaps with 3rd-party heterogeneous systems in a safe, secure and vendor neutral way. More often than not, the communication was outside of the trusted networks.
			<br>MSA is internally focussed. It lays emphasis on building small and independently deployable applications that work together, for faster development and deployment of business needs. The inter-app communication challenge was a consequence of this decision. Typically, the coordinating apps are within the trusted network of the company.</li>
      <br>
		<li>Refactoring across bounded context is relatively simpler with SOA.
          	<br>Refactoring across bounded context is harder with MSA. This is one of the key reasons I don't recommend Microservices First Architecture, but yeah, you can always hit a middle ground that is there somewhere.&nbsp;</li>
		<br>
		<li>SOA embraced SOAP as the de-facto communication protocol and later went on to support REST protocol too.
			<br>MSA embraced REST as the de-facto communication protocol, but is pretty open to embracing other newer protocols for good. Inherently though, there is a dislike for SOAP/XML within the MSA community :)</li>
		<br>
		<li>SOA solved the integration challenges for businesses primarily in the B2B space.<br>MSA solved the delivery challenges for businesses that wanted to be nimble with faster release cycles; historically, to respond to its B2C customers.&nbsp;</li>
	</ul>
</div>

</div></div>]]>
            </description>
            <link>https://blog.codonomics.com/2020/07/microservices-architecture-versus-soa.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008284</guid>
            <pubDate>Fri, 31 Jul 2020 13:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zuckerberg expects 50% of employees to go “remote long term, within 5-10 years”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008242">thread link</a>) | @RayMan1
<br/>
July 31, 2020 | http://alugy.com/tech/zuckerberg-expects-that-50-of-employees-will-stay-remote-long-term-within-5-10-years/ | <a href="https://web.archive.org/web/*/http://alugy.com/tech/zuckerberg-expects-that-50-of-employees-will-stay-remote-long-term-within-5-10-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><p><a href="http://alugy.com/wp-content/uploads/2020/04/startup-849804_640.jpg" data-caption=""><img width="640" height="457" src="http://alugy.com/wp-content/uploads/2020/04/startup-849804_640.jpg" srcset="http://alugy.com/wp-content/uploads/2020/04/startup-849804_640.jpg 640w, http://alugy.com/wp-content/uploads/2020/04/startup-849804_640-300x214.jpg 300w, http://alugy.com/wp-content/uploads/2020/04/startup-849804_640-588x420.jpg 588w, http://alugy.com/wp-content/uploads/2020/04/startup-849804_640-100x70.jpg 100w" sizes="(max-width: 640px) 100vw, 640px" alt="" title="startup-849804_640"></a></p>
            <!-- content -->
<p>The shares of Alphabet , Amazon (AMZN) , Apple (AAPL) and Facebook (FB) responded to the announcement of unexpectedly good quarterly figures for the four tech companies in pre-market trading session on Friday. As a result, the shares were close to their respective record highs (Amazon and Alphabet) or even higher (Apple and Facebook).</p>



<p>And during the FB earnings conference call from Thursday, July 30, CEO of Facebook Inc talked, among other things, about the future of remote work within the Company. He said that even before COVID Facebook had a long-term goal of enabling more remote work since the ability to feel present even when you’re remote is a core aspect of their own product work on video presence, workplace and virtual and augmented reality. </p>



<blockquote><p>“the reason why we’re shifting to more remote work is that we think that culturally, it will allow us to attract more talented people. We’re not doing this primarily as a cost-saving measure.”-Mark ZuckeRberg</p></blockquote>



<p>He added that Facebook is:”using this moment to accelerate these plans. And I expect that up to 50% of our employees will be remote long term within the next 5 to 10 years. This will enable us to attract and retain broader pools of talent regardless of where they live.”</p>



<p>David Wehner, Facebook CFO also touched this topic and said:”We had our <strong>strongest hiring quarter ever in Q2</strong>, adding over 4,200 net new hires, primarily in technical functions. We ended the quarter with over 52,500 full-time employees, up 32% year-over-year.” and continued on remote work “The main thing we’re trying to do is access a greater talent pool, which ultimately might give us more opportunity to grow head count. So I think there’s an effect there that’s, I think, in addition to cost in the sense that we would have a greater pool of people that we could recruit from.”.</p>



<p>Facebook, Inc. Common Stock (NASDAQ: FB) price went up 7% in the pre-amrket session on Friday which is more than $16.00 higher then Thursday afternoon.</p>



<p>At the same time, the number of users continued to rise rapidly: in the past quarter, FB added more than 100 million monthly active user – and now there are a total of 2.6 billion. At nearly $ 5.2 billion, the profit was about twice as high as in the same quarter of the previous year.</p>

 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>http://alugy.com/tech/zuckerberg-expects-that-50-of-employees-will-stay-remote-long-term-within-5-10-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008242</guid>
            <pubDate>Fri, 31 Jul 2020 13:12:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can Brian Hall fix what ails Google Cloud?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008133">thread link</a>) | @noahl
<br/>
July 31, 2020 | https://www.platformonomics.com/2020/07/can-brian-hall-fix-what-ails-google-cloud/ | <a href="https://web.archive.org/web/*/https://www.platformonomics.com/2020/07/can-brian-hall-fix-what-ails-google-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2104">
	<!-- .entry-header -->

	<div>
		
<figure><img src="https://www.platformonomics.com/wp-content/uploads/2020/07/image-134.png" alt="" srcset="https://www.platformonomics.com/wp-content/uploads/2020/07/image-134.png 936w, https://www.platformonomics.com/wp-content/uploads/2020/07/image-134-300x146.png 300w, https://www.platformonomics.com/wp-content/uploads/2020/07/image-134-768x374.png 768w" sizes="(max-width: 936px) 100vw, 936px"></figure>



<p>Google Cloud sits a distant third in the cloud wars (ignoring the Chinese cloud companies, which are pretty much irrelevant to Western markets as they face a Huawei-or-the-highway reckoning). With a cloud infrastructure business generally estimated to be between a quarter or a third the size of Microsoft Azure, which in turn is about half the size of Amazon Web Services, Google has a lot of ground to make up. And they’ve been tilting at the infrastructure space since 2008.</p>



<p>You’d think AWS would have bigger worries than Google Cloud. Yet the recent AWS lawsuit against Brian Hall built up Google Cloud as a serious competitive threat to the industry leader. A thin-skinned AWS <a href="https://www.geekwire.com/2020/amazon-sues-former-aws-marketing-vp-brian-hall-accepts-google-cloud-job/">sued</a> Hall, claiming he violated his non-compete agreement by joining Google Cloud after leaving AWS. The suit exalted Brian as a god-like marketer (he is pretty good). But it got ridiculous, focusing on Brian’s slide creation skills (which was ironic for a company that prides itself on <a href="https://www.inc.com/carmine-gallo/jeff-bezos-bans-powerpoint-in-meetings-his-replacement-is-brilliant.html">not</a> using slides – except when they <a href="https://aws.amazon.com/blogs/developer/aws-reinvent-slides-posted/">do</a> for hours on end, and then <a href="https://twitter.com/QuinnyPig/status/1272737141424963585?s=20">struggle</a> with some of the basics), and conjectured (under oath) that just a few of Brian’s slides could radically reshape what is apparently a very precarious cloud industry.</p>



<p>The suit also highlighted the overly broad non-competes Amazon asks employees to sign and its haphazard enforcement of those agreements. After a month of terrible press for AWS that broadcast the risks any potential employee takes working for the company, they came to an undisclosed <a href="https://www.geekwire.com/2020/amazon-settles-lawsuit-former-aws-marketing-vp-joined-google-cloud/">settlement</a> and Brian promptly assumed his job at Google working for Thomas Kurian (Google Cloud’s newish leader and now recovering Oracle lifer).</p>



<p>I know and have worked with Brian (and am sure he’s horrified by this post), and supported him during the lawsuit (amicus Twitter). He’s an outstanding executive, a creative and clear-thinking marketer, and a high-integrity human. And his slide chops live up to their acclaim – I’ve seen him conjure up over $50 billion in value with slides on a Saturday afternoon that came to fruition and then some.</p>



<p>I’m increasingly fixated on deciphering company cultures (strategy becomes culture at successful technology companies, and then that culture inhibits the evolution of strategy) and using that perspective to handicap future prospects. Google Cloud is as good a place to start as any, as it has some deep and perhaps intractable cultural issues. As Brian tries to get Google Cloud out of their third-place rut, lets see what he is up against.</p>



<h2><strong>It’s a Hobby</strong></h2>



<p>Steve Jobs <a href="https://www.vanityfair.com/news/2019/03/how-an-argument-with-steve-jobs-explains-the-future-of-apple">introduced</a> the idea that trillion-dollar technology behemoths can have hobbies. By describing Apple TV as a hobby, the company restrained expectations and signaled it wasn’t core to Apple’s business. Apple TV was merely something to putter around with in the Apple Park garden after a particularly arduous week in the smartphone wars.</p>



<p>Google Cloud Platform is also a hobby, even if Google doesn’t admit it (they may not even realize it). When Google CEO Sundar Pichai gets up in the morning, the broader Google Cloud business (including G Suite) is, on a really good day, a distant fifth on his list of concerns. The four business segments ahead of it collectively constitute Google’s advertising franchise – search, YouTube, AdSense and Android – which are a mutually reinforcing magical money machine that generated about $150 billion in revenue last year (with very attractive margins).</p>



<p>Sundar’s attention is disproportionately on the advertising franchise as he circles the wagons against a pandemic ravaging (among other things) advertising spending, his fellow members of the avaricious online advertising oligopoly, and a barrage of regulatory and antitrust actions. The broader Google Cloud –both G Suite and Google Cloud Platform infrastructure services – was less than 7% of Google’s overall revenue in the first quarter of 2020. It just isn’t existential for the company.</p>



<p>Despite being a hobby, Apple TV exploits the same skill set and assets Apple employs in its day job. It is an integrated hardware and software product that leverages the company’s silicon, software, and services platforms. Apple TV sells to the same consumers through the same distribution channels, and deepens the customer’s ecosystem attachment to Apple.</p>



<p>Google Cloud not so much: it is an outlier and disjoint in almost every way from the rest of Google. It targets an alien and difficult to please customer in enterprise IT. It requires a completely different partner ecosystem and a completely different business model that is almost antithetical to the advertising business model. It requires dissimilar talent to build, sell, and support that is not particularly fungible with the rest of the company. Google Cloud even requires infrastructure increasingly divergent from Google’s alien mothership infrastructure.</p>



<p>The degree of difficulty to build an enterprise cloud business, never mind a market leader, is very high. It is even harder to build one within an advertising company. Expensive hobbies that cost real money by even Google standards are hard to sustain, so material progress is required. Google management appears to have put Google Cloud on a PIP, giving them a limited window in which to <a href="https://www.theinformation.com/articles/google-brass-set-2023-as-deadline-to-beat-amazon-microsoft-in-cloud">become a market leader or risk defunding</a>. Can this peripheral business for Google rise to the top in cloud infrastructure? After over a decade in this market that hasn’t’t lived up to Google’s ambitions, what has to change and what can change to deliver a different result?</p>



<h2><strong>Losing Their “Googleyness”</strong></h2>



<p>Google in many ways invented cloud computing for their search business. And they did it in bold and unconventional fashion – not by using what were considered the most advanced computing technologies of the day – but by taking a greenfield and sui generis approach to construct an entirely new computing model melding novel software like containers, Borg, and MapReduce with commodity hardware.</p>



<p>What is the point of a Google Cloud that is losing its iconoclastic approach and turning into a me-too amalgam of AWS and Oracle slavishly chasing the market leaders? A product portfolio that increasingly <a href="https://cloud.google.com/docs/compare/aws/">sees itself</a> through the lens of the atomistic AWS product line combined with an Oracle sales culture is – to put it mildly – hard to get excited about. And GOracle may be overindexing on databases at the expense of everything else. The last thing the world needs is another also-ran cloud company whose use of the word “enterprise” is inversely correlated with their market performance (after all, we already have both <a href="https://www.platformonomics.com/2020/07/follow-the-capex-clown-watch/">IBM and Oracle</a>).</p>



<p>The “Googleyness” of the early Google Cloud was pioneering and unique enough to perhaps warrant overlooking their very <a href="https://www.platformonomics.com/2016/03/googles-scalability-day/">underdeveloped customer skills</a>, at least for a while. They might have matured beyond simply telling customers to get smarter and found a distinctive and complementary go-to-market approach, instead of remaking themselves in Oracle’s image. But that “we-come-from-the-future” inventiveness seems largely in the past, particularly amid an exodus of engineers out of the cloud group. The platitudinous new Google Cloud <a href="https://twitter.com/caro_milanesi/status/1283073424924057600/photo/1">mission statement</a> seems unlikely to uncork a deep well of future innovation (did someone win a bet for getting “digitally transform” into the final version or was that a placeholder they forgot to update or what?).</p>



<p>Google these days seems more focused on relitigating historical battles than pushing the infrastructure frontier. They are grappling with deep neuroses from both Hadoop and Kubernetes, having failed to reap the associated credit and financial rewards they believe they deserved. The company’s previous open source idealism has run <a href="https://thenewstack.io/op-ed-kubernetes-may-be-googles-last-great-open-project/">smack</a> into both ego and the financial constraints under which Google Cloud now operates.</p>



<p>Between Google Cloud’s hobby status and being in the midst of an identity crisis, Brian has his work cut out for him. But cloud infrastructure is an enormous market with lots of growth still ahead of it, Google is investing heavily, and perhaps with better slides, they could move up in the standings?</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

		<!-- .entry-auhtor -->
	</article></div>]]>
            </description>
            <link>https://www.platformonomics.com/2020/07/can-brian-hall-fix-what-ails-google-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008133</guid>
            <pubDate>Fri, 31 Jul 2020 12:55:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best open-source IoT frameworks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008129">thread link</a>) | @DanaStartupNews
<br/>
July 31, 2020 | https://www.byteant.com/blog/5-best-open-source-iot-frameworks/ | <a href="https://web.archive.org/web/*/https://www.byteant.com/blog/5-best-open-source-iot-frameworks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <ol>
            <li>
                    <a href="https://www.byteant.com/">Home</a>
            </li>
            <li>
                    <a href="https://www.byteant.com/blog/">Blog</a>
            </li>
            <li>5 Best Open Source IoT Frameworks</li>
        </ol>
    </div>

    <section>
        <div>
            <div>
                

                <div>
                            
    

    <div>
        <div>
    <div>
        <div>
            <div>
                <div>
                    
    
    <figure>
        <img src="https://www.byteant.com/media/1417/5-best-open-source-iot-frameworks.jpg" alt="">
    </figure>


                    
    
<h2>Overview</h2>
<p>The <a rel="noopener" href="https://www.byteant.com/internet-of-things-development-services" target="_blank">Internet of Things, or IoT for short</a>, is a promising branch of technology that together withÂ&nbsp;<a rel="noopener" href="https://www.byteant.com/blog/7-ways-how-big-data-can-supercharge-your-business/" target="_blank">Big Data</a> is conquering the digital world now. The idea of smart interrelated gadgets and consumer electronics able to work independently has been evolving since the end of the 20th century. This technology has successfully resulted in a highly-developed far-reaching system of middleware between the devices and user applications. The universal popularity of the IoT strategy is easily explained by the fact that there are billions of devices worldwide in all aspects of human life: medicine, industry, commerce, farming, lifestyle, to name just a few.</p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
                        <div>
                <div>
                    
    
    <figure>
        <img src="https://www.byteant.com/media/1320/the-internet-of-things-2025.png" alt="">
    </figure>


                </div>
            </div>                    </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<p>Â&nbsp;</p>
<p>You should bear in mind, though, that open source solutions are not totally equal to free software. The terms may mean the same and are used interchangeably sometimes. However, open source software (OSS) goes both ways: it can come to you at no cost as well as offer you quite expensive price tags. The difference lies in its open nature of the software development approach as it allows side code enthusiasts to easily join the programming process.</p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <p>Needless to say, the majority of businesses treat <a rel="noopener" href="https://www.byteant.com/blog/top-10-technology-trends-2019/" target="_blank">emerging tech trends</a> as an invaluable asset with an eye on their subsequent monetization. Quite obviously, some organizations opt for having the competitive IoT-backed solutions integrated with their processes, like these actionable use cases for <a href="https://www.byteant.com/blog/case-study-iot-and-saas-solutions-for-auto-repair-startup/">Automobile</a> and <a rel="noopener" href="https://www.byteant.com/blog/case-study-how-iot-and-bigdata-transform-sports-industry/" target="_blank">Sports </a>industries. Some decide to double down on buying out or creating their own open source platforms to maximize revenues. Either way, it leads us to the exponential increase of software development initiatives driven by IoT. Hereâ€™s a list of some facts that just add fuel to the fire of IoT-based potential. Â&nbsp;Â&nbsp;</p>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<ul>
<li><a rel="noopener" href="https://www.gartner.com/en/newsroom/press-releases/2018-11-07-gartner-identifies-top-10-strategic-iot-technologies-and-trends" target="_blank">Gartner forecasts</a> the rapid growth of connected things from 14.2 billion in 2019 and 20.4 billion in 2020 up to 25 billion by 2021.</li>
<li>Many advanced technologies, like AI, ML, clouds, IoT, blockchains, are developed within open software platforms. In 2018 <a rel="noopener" href="https://www.redhat.com/en/about/press-releases/ibm-acquire-red-hat-completely-changing-cloud-landscape-and-becoming-worlds-1-hybrid-cloud-provider" target="_blank">IBM buys Red Hat</a> and <a rel="noopener" href="https://news.microsoft.com/2018/06/04/microsoft-to-acquire-github-for-7-5-billion/" target="_blank">Microsoft buys GitHub</a> â€“ the homes of contemporary software innovations for all branches of business.</li>
<li>According to <a rel="noopener" href="https://www.redhat.com/en/enterprise-open-source-report/2019" target="_blank">the Red Hat report</a>, 77% of surveyed IT leaders plan to expand the usage of open source solutions in the next 12 months. 75% of respondents consider it very or extremely important.</li>
<li>Open source-based business solutions are among the most discussed<a rel="noopener" href="https://jaxenter.com/2019-open-source-battles-cloud-war-154174.html" target="_blank">Â&nbsp;technological topics of 2019</a> alongside with cryptocurrency and self-driving cars.</li>
</ul>
<p>Here is an in-depth guide on how open-source software is used by major organizations like Google.</p>


                    
    

<p>
	<iframe width="640" height="360" src="https://www.youtube.com/embed/SpeDK1TPbew?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>


                    
    
<h2>Open source IoT frameworks to consider</h2>
<p>Many companies look for the out-of-the-box open source platforms, while trying to find the best IoT tools that can provide robust analytics and interoperability between their connected devices. Letâ€™s get a brief overview of the 5 most deployed open source IoT frameworks to see if they meet your business needs.</p>
<ol>
<li>
<h3><a rel="noopener" href="https://devicehive.com/" target="_blank">DeviceHive</a></h3>
</li>
</ol>


                    
    
    <figure>
        <img src="https://www.byteant.com/media/achnmp4o/devicehive_.jpg" alt="">
    </figure>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<p><br>Price: by request</p>
<p>Documentation: <a rel="noopener" href="https://docs.devicehive.com/docs" target="_blank">https://docs.devicehive.com/docs</a></p>
<p>DeviceHive is an open-source IoT cloud service management platform, licensed under the Apache License Version 2.0, with a particular focus on big data analytics. This function-rich technology can:</p>
<ul>
<li>support Python, Node.js, Java and other client libraries</li>
<li>provide scalable public, private or hybrid cloud resources</li>
<li>support Docker and Kubernetes deployment options</li>
<li>handle single and multiple production volumes at scale</li>
<li>deprive of minor technical peculiarities</li>
<li>connect any devices with REST API, WebSockets or MQTT protocols</li>
<li>leverage the benefits of Apache Kafka, Spark and Cassandra solutions for big data analytics</li>
</ul>
<div><p>What is more prominent about DeviceHive is that it is mostly free to use and change, though also having fixed price services. Both professional developers and consultants support the platformâ€™s implementation.</p><p>DeviceHive offers robust tools to set up communication between smart IoT devices. It fills the gap between cloud development, embedded, and mobile app development.Â&nbsp;Â&nbsp;</p></div>
<ol start="2">
<li>
<h3><a rel="noopener" href="https://thingspeak.com/" target="_blank">ThingSpeak</a></h3>
</li>
</ol>


                    
    
    <figure>
        <img src="https://www.byteant.com/media/d4pdlnh0/thingspeak.png" alt="">
    </figure>


                    
    
<p><a rel="noopener" href="https://www.byteant.com/portfolio/automotive-iot-and-multitenant-saas-solution/?utm_source=Blog&amp;utm_medium=IoT%20Frameworks&amp;utm_campaign=IoT" target="_blank"><img src="https://www.byteant.com/media/531bxanz/iot-automotive-solution.png" alt="IoT Automotive Solution"></a></p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<p><br>Price: from $ 650 /unit</p>
<p>Documentation: <a rel="noopener" href="https://www.mathworks.com/help/thingspeak/" target="_blank">https://www.mathworks.com/help/thingspeak/</a></p>
<p>ThingSpeak is a relatively young IoT platform that tightly collaborates with MathWorks. This gives the possibility to leverage from timely MATLAB data analysis from numberless sensors. The platform comprises:</p>
<ul>
<li>live data streams aggregation and analytics;</li>
<li>data recording from public channels to be further used in newly created private channels;</li>
<li>assignment ofÂ&nbsp; public channels to share data;</li>
<li>visualization of collected data;</li>
<li>updates of channel feed via the REST and MQTT APIs;</li>
<li>MATLABÂ® online analytical tools for exploring patterns and relationships;</li>
<li>TimeControl function that enables event-triggered alerts.</li>
</ul>
<p>To sum up, this frameworkâ€™s biggest advantage is that it really makes things communicate with you.</p>
<ol start="3">
<li>
<h3><a href="https://www.mainflux.com/">Mainflux</a></h3>
</li>
</ol>
<h3><img src="https://www.byteant.com/media/irplzuhy/mainfluxiotframework.png?width=734&amp;height=354&amp;mode=max" alt="" width="734" height="354" data-udi="umb://media/d0ac5f42abf84466ab8c380ae8ecc4c6"></h3>
<p>Price: from $500 /month</p>
<p>Documentation: <a href="https://mainflux.readthedocs.io/en/latest/">https://mainflux.readthedocs.io/en/latest/</a></p>
<p>Mainflux is an open-source and patent-free IoT platform that has a rich number of advantageous tools for data collection and management, core analytics, and event scheduling. No matter the industry, Mainflux provides:</p>
<ul>
<li>connectivity of things and users via HTTP, MQTT, WebSocket, CoAP protocols;</li>
<li>device management and provisioning;</li>
<li>container-based deployment by Docker;</li>
<li>container orchestration by Kubernetes;</li>
<li>enhanced data security with customizable API keys and scoped JWT;</li>
<li>low OPEX (operating expense) benefits;</li>
<li>Both protocol and device agnostic.</li>
</ul>
<p>This platform is written in Golang and can be deployed as an on-premises, hybrid or cloud-based model. Prices may vary, starting from absolutely free-of-charge installation modes and support plans to fully-managed business and custom variants.</p>
<ol start="4">
<li>
<h3><a rel="noopener" href="https://thinger.io/" target="_blank">Thinger.io</a></h3>
</li>
</ol>
<h3><img src="https://www.byteant.com/media/cnpdbuue/thingerio.png?width=731&amp;height=212&amp;mode=max" alt="" width="731" height="212" data-udi="umb://media/d2205f1565844a08900f2b7b2dd221f3"></h3>
<p>Price: from â‚¬ 3.95 / month</p>
<p>Documentation: <a rel="noopener" href="http://docs.thinger.io/" target="_blank">http://docs.thinger.io/</a></p>
<p>Thinger.io is an open source ready-to-go platform for cloud IoT projects. This software enables deployment through Docker containerization methods. Among its beneficial features there are:</p>
<ul>
<li>smooth multi-hardware integration;</li>
<li>hardware support of Arduino IDE, Linux, Sigfox andARM Mbed boards;</li>
<li>easy-to-use cloud admin console;</li>
<li>live data streaming to websockets;</li>
<li>device data visualization in the cloud via real-time dashboards;</li>
<li>support of both iOS and Android mobile apps;</li>
<li>IFTTT event-triggered settings for multiple IoT devices</li>
</ul>
<p>This OSS tool is highly sensible, easy-to-use, scalable and secure. Both free and paid subscription plans are available.</p>
<ol start="5">
<li>
<h3><a rel="noopener" href="http://www.zettajs.com/" target="_blank">Zetta</a></h3>
</li>
</ol>
<h3><img src="https://www.byteant.com/media/53edcxyy/zettaiotframework.png?width=734&amp;height=408&amp;mode=max" alt="" width="734" height="408" data-udi="umb://media/5f2149f9091841699da13956160fffe0"></h3>
<p>Price: Free</p>
<p>Documentation: <a rel="noopener" href="https://github.com/zettajs/zetta/wiki" target="_blank">https://github.com/zettajs/zetta/wiki</a></p>
<p>Zetta is the first API-oriented open source IoT framework that basically serves for non-stop streaming loads of data. This technology is deprived of vivid data visualization but its main advantage remains â€œreactive programmingâ€�. The feature list consists of both commonplace and unique characteristics:Â&nbsp;</p>
<ul>
<li>smooth integration with customerâ€™s business logic</li>
<li>based on Node.js;</li>
<li>harnesses Reactive Hypermedia patterns for data streaming;</li>
<li>uses Siren Format to build a solid API for IoT devices;</li>
<li>network protocol agnostic ;</li>
<li>secured connection between peering servers;</li>
<li>consistent data transition over websockets;</li>
<li>ability to send data to other analytical platforms;</li>
<li>A SQL syntax for queries and notifications.</li>
</ul>
<p>No matter the Zetta community is comparatively small, this IoT dashboard open source counts a great number of devoted followers.</p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<h2>Utilizing OSS: Some benefits and drawbacks explained</h2>
<p>At first glance, the IoT tools mentioned above may seem quite similar and enlist homogeneous features but these platforms can come in handy going far beyond. Alternatively to proprietary software, open source technologies are completely customizable and scalable â€“ as the code is open it can be adjusted and modified to the businesses needs. OSS allows developers and enterprises to move between different frameworks without complications â€“ the necessary toolkit provided.</p>
<p>With a great number of automated protocols and functions, open source frameworks save much time of IoT engineers and tech-professionals. This IoT solution is better for handling deployment flexibility issues and reducing expenses. Being of the major priority, data privacy and security is the main standpoint of any business, so you may choose from diverse open source framework vendors worldwide.</p>
<p>There are still some challenges you can face on this far-reaching way:</p>
<ul>
<li>Open means free access, i.e. contributors are not always specialists.</li>
<li>Secure maintenance is always vulnerable.</li>
<li>Data privacy gains a growing legal interest.</li>
<li>A number of best open source platforms may cost a fortune.</li>
<li>Bugs happen.</li>
<li>The set of available standard features doesnâ€™t fit all your business needs.</li>
<li>Open source IoT platforms are not for a mediocre user.</li>
</ul>
<p><em><strong>Whateve…</strong></em></p></div></div></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.byteant.com/blog/5-best-open-source-iot-frameworks/">https://www.byteant.com/blog/5-best-open-source-iot-frameworks/</a></em></p>]]>
            </description>
            <link>https://www.byteant.com/blog/5-best-open-source-iot-frameworks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008129</guid>
            <pubDate>Fri, 31 Jul 2020 12:55:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Built a Serverless Search for My Blog]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24008083">thread link</a>) | @kiyanwang
<br/>
July 31, 2020 | https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/ | <a href="https://web.archive.org/web/*/https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
			

			<div>
				<p><em>I have built a custom search functionality for this blog,
based on Java and the Apache Lucene full-text search library,
compiled into a native binary using the Quarkus framework and GraalVM.
It is deployed as a Serverless application running on AWS Lambda,
providing search results without any significant cold start delay.
If you thought Java wouldn’t be the right language for this job, keep reading;
in this post I’m going to give an overview over the implementation of this feature and my learnings along the way.</em></p>
<p>Having a search functionality for my blog has been on my mind for quite some time;
I’d like to give users the opportunity to find specific contents on this blog right here on this site, without having to use an external search engine.
That’s not only nice in terms of user experience, but also having insight into the kind of information readers look for on this blog should help me to identify interesting things to write about in the future.</p>
<p>Now this blog is a static site — generated using <a href="https://gohugo.io/">Hugo</a>, hosted on <a href="https://pages.github.com/">GitHub Pages</a> — which makes this an interesting challenge.
I didn’t want to rely on an external search service
(see "Why No External Search Service" below for the reasoning),
and also a purely client-side solution as described in this <a href="https://endler.dev/2019/tinysearch/">excellent blog post</a> didn’t seem ideal.
While technically fascinating, I didn’t like the fact that it requires shipping the entire search index to the client for executing search queries.
Also things like result highlighting, customized result scoring, word stemming, fuzzy search and more seemed a bit more than I’d be willing to implement on the client.</p>
<p>All these issues have largely been solved on the server-side by libraries such as <a href="https://lucene.apache.org/">Apache Lucene</a> for quite some time.
Using a library like Lucene means implementing a custom server-side process, though.
How to deploy such service?
Operating a VM 24/7 with my search backend for what’s likely going to be not more than a few dozen queries per month seemed a bit like overkill.</p>
<p>So after some consideration I decided to implement my own search functionality,
based on the highly popular Apache Lucene library,
deployed as a Serverless application,
which is started on-demand if a user runs a query on my website.
In the remainder of this post I’m going to describe the solution I came up with and how it works.</p>
<p>If you like, you can try it out right now, this post is about this little search input control at the top right of this page!</p>
<div>
<table>
<tbody><tr>
<td>
<i title="Note"></i>
</td>
<td>
<p>Why No External Search Service?</p>
<p>When <a href="https://twitter.com/gunnarmorling/status/1284925378868518913">tweeting</a> about my serverless search experiment, one of the questions was "What’s wrong with <a href="https://www.algolia.com/">Algolia</a>?".
To be very clear, there’s nothing wrong with it at all.
External search services like Algolia, <a href="https://developers.google.com/custom-search">Google Custom Search</a>, or an Elasticsearch provider such as <a href="https://bonsai.io/">Bonsai</a> promise an easy-to-use, turn-key search functionality which can be a great choice for your specific use case.</p>
<p>However, I felt that none of these options would provide me the degree of control and customizability I was after.
I also ruled out any "free" options, as they’d either mean having ads or paying for the service with the data of myself or that of my readers.
And to be honest, I also just fancied the prospect of solving the problem by myself, instead of relying on an off-the-shelf solution.</p>
</td>
</tr>
</tbody></table>
</div>
<div>
<h2 id="_why_serverless">Why Serverless?</h2>
<div>
<p>First of all, let’s discuss why I opted for a Serverless solution.
It boils down to three reasons:</p>
<div>
<ul>
<li>
<p><em>Security:</em> While it’d only cost a few EUR per month to set up a VM with a cloud provider like Digital Ocean or Hetzner, having to manage a full operating system installation would require too much of my attention; I don’t want someone to mine bitcoins or doing other nasty things on a box I run, just because I failed to apply some security patch</p>
</li>
<li>
<p><em>Cost:</em> Serverless does not only promise to scale-out (and let’s be honest, there likely won’t be millions of search queries on my blog every month), but also scale-to-zero.
As Serverless is pay-per-use and there are free tiers in place e.g. for AWS Lambda,
this service ideally should cost me just a few cents per month</p>
</li>
<li>
<p><em>Learning Opportunity:</em> Last but not least, this also should be a nice occasion for me to dive into the world of Serverless, by means of designing, developing and running a solution for a real-world problem, exploring how Java as my preferred programming language can be used for this task</p>
</li>
</ul>
</div>
</div>
</div>
<div>
<h2 id="_solution_overview">Solution Overview</h2>
<div>
<p>The overall idea is quite simple: there’s a simple HTTP service which takes a query string,
runs the query against a Lucene index with my blog’s contents and returns the search results to the caller.
This service gets invoked via JavaScript from my static blog pages,
where results are shown to the user.</p>
<p>The Lucene search index is read-only and gets rebuilt whenever I update the blog.
It’s baked into the search service deployment package,
which that way becomes fully immutable.
This reduces complexities and the attack surface at runtime.
Surely that’s not an approach that’s viable for more dynamic use cases,
but for a blog that’s updated every few weeks, it’s perfect.
Here’s a visualization of the overall flow:</p>
<div>
<p><img src="https://www.morling.dev/images/serverless_search_overview.png" alt="Serverless Search Solution Overview">
</p>
</div>
<p>The search service is deployed as a Serverless function on <a href="https://aws.amazon.com/lambda/">AWS Lambda</a>.
One important design goal for me is to avoid lock-in to any specific cloud provider:
the solution should be portable and also be usable with container-based Serverless approaches like <a href="https://knative.dev/">Knative</a>.</p>
<p>Relying on a Serverless architecture means its start-up time must be a matter of milli-seconds rather than seconds,
so to not have a user wait for a noticeable amount of time in case of a cold start.
While <a href="https://www.morling.dev/blog/building-class-data-sharing-archives-with-apache-maven/">substantial improvements</a> have been made in recent Java versions to improve start-up times,
it’s still not ideal for this kind of use case.
Therefore, the application is compiled into a native binary via <a href="https://quarkus.io/">Quarkus</a> and <a href="https://www.graalvm.org/">GraalVM</a>,
which results in a start-up time of ~30 ms on my laptop, and ~180 ms when deployed to AWS Lambda.
With that we’re in a range where a cold start won’t impact the user experience in any significant way.</p>
<p>The Lambda function is exposed to callers via the <a href="https://aws.amazon.com/api-gateway/">AWS API Gateway</a>,
which takes incoming HTTP requests, maps them to calls of the function and converts its response into an HTTP response which is sent back to the caller.</p>
<p>Now let’s dive down a bit more into the specific parts of the solution.
Overall, there are four steps involved:</p>
<div>
<ul>
<li>
<p><em><a href="#_data_extraction">Data extraction:</a></em> The blog contents to be indexed must be extracted and converted into an easy-to-process data format</p>
</li>
<li>
<p><em><a href="#_search_backend_implementation">Search backend implementation:</a></em> A small HTTP service is needed which exposes the search functionality of Apache Lucene, which in particular requires some steps to enable Lucene being used in a native GraalVM binary</p>
</li>
<li>
<p><em><a href="#_wiring_things_up">Integration with the website:</a></em> The search service must be integrated into the static site on GitHub Pages</p>
</li>
<li>
<p><em><a href="#_deployment_to_aws_lambda">Deployment:</a></em> Finally, the search service needs to be deployed to AWS API Gateway and Lambda</p>
</li>
</ul>
</div>
</div>
</div>
<div>

<div>
<p>The first step was to obtain the contents of my blog in an easily processable format.
Instead of requiring something like a real search engine’s crawler,
I essentially only needed to have a single file in a structured format which then can be passed on to the Lucene indexer.</p>
<p>This task proved rather easy with Hugo;
by means of a <a href="https://gohugo.io/templates/output-formats/#output-formats-for-pages">custom output format</a> it’s straight-forward to produce a JSON file which contains the text of all my blog pages.
In my <em>config.toml</em> I declared the new output format and activate it for the homepage
(largely inspired by this <a href="https://xdeb.org/post/2017/06/11/make-hugo-generate-a-json-search-index-and-json-feed/">write-up</a>):</p>
<div>
<div>
<pre><code data-lang="toml"><span>[outputFormats.SearchIndex]</span>
<span>mediaType</span> <span>=</span> <span>"application/json"</span>
<span>baseName</span> <span>=</span> <span>"searchindex"</span>
<span>isPlainText</span> <span>=</span> <span>true</span>
<span>notAlternative</span> <span>=</span> <span>true</span>

<span>[outputs]</span>
<span>home</span> <span>=</span> <span>[</span><span>"HTML"</span><span>,</span><span>"RSS"</span><span>,</span> <span>"SearchIndex"</span><span>]</span></code></pre>
</div>
</div>
<p>The template in <em>layouts/_default/list.searchindex.json</em> isn’t too complex either:</p>
<div>
<div>
<pre><code>{{- $.Scratch.Add "searchindex" slice -}}
{{- range $index, $element := .Site.Pages -}}
  {{- $.Scratch.Add "searchindex" (dict "id" $index "title" $element.Title "uri" $element.Permalink "tags" $element.Params.tags "section" $element.Section "content" $element.Plain "summary" $element.Summary "publicationdate" ($element.Date.Format "Jan 2, 2006")) -}}
{{- end -}}
{{- $.Scratch.Get "searchindex" | jsonify -}}</code></pre>
</div>
</div>

<div>
<div>
<pre><code data-lang="json"><span>[</span><span>
  </span><span>...</span><span>
  </span><span>{</span><span>
    </span><span>"content"</span><span>:</span><span> </span><span>"The JDK Flight Recorder (JFR) is an invaluable tool..."</span><span>,</span><span>
    </span><span>"id"</span><span>:</span><span> </span><span>12</span><span>,</span><span>
    </span><span>"publicationdate"</span><span>:</span><span> </span><span>"Jan 29, 2020"</span><span>,</span><span>
    </span><span>"section"</span><span>:</span><span> </span><span>"blog"</span><span>,</span><span>
    </span><span>"summary"</span><span>:</span><span> </span><span>"</span><span>\u</span><span>003cdiv class=</span><span>\"</span><span>paragraph</span><span>\"\u</span><span>003e</span><span>\n\u</span><span>003cp</span><span>\u</span><span>003eThe </span><span>\u</span><span>003ca href=</span><span>\"</span><span>https://openjdk.java.net/jeps/328</span><span>\"\u</span><span>003eJDK Flight Recorder</span><span>\u</span><span>003c/a</span><span>\u</span><span>003e (JFR) is an invaluable tool..."</span><span>,</span><span>
    </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span>
      </span><span>"java"</span><span>,</span><span>
      </span><span>"monitoring"</span><span>,</span><span>
      </span><span>"microprofile"</span><span>,</span><span>
      </span><span>"jakartaee"</span><span>,</span><span>
      </span><span>"quarkus"</span><span>
    </span><span>],</span><span>
    </span><span>"title"</span><span>:</span><span> </span><span>"Monitoring REST APIs with Custom JDK Flight Recorder Events"</span><span>,</span><span>
    </span><span>"uri"</span><span>:</span><span> </span><span>"https://www.morling.dev/blog/rest-api-monitoring-with-custom-jdk-flight-recorder-events/"</span><span>
  </span><span>},</span><span>
  </span><span>...</span><span>
</span><span>]</span></code></pre>
</div>
</div>
<p>This file gets automatically updated whenever I republish the blog.</p>
</div>
</div>
<div>
<h2 id="_search_backend_implementation">Search Backend Implementation</h2>
<div>
<p>My stack of choice for this kind of application is Quarkus.
As a <a href="https://quarkus.io/guides/kafka-streams-guide">contributor</a>, I am of course biased, but Quarkus is ideal for the task at hand:
built and optimized from the ground up for implementing fast-starting and memory-efficient cloud-native and Serverless applications,
it makes building HTTP services, e.g. based on JAX-RS, running on GraalVM a trivial effort.</p>
<p>Now typically a Java library such as Lucene will not run in a GraalVM native binary out-of-the-box.
Things like reflection or JNI usage require specific configuration,
while other Java features like method handles are only supported partly or not at all.</p>
<div>
<h3 id="_apache_lucene_in_a_graalvm_native_binary">Apache Lucene in a GraalVM Native Binary</h3>
<p>Quarkus enables a wide range of popular Java libraries to be used with GraalVM,
but at this point there’s no extension yet which would take care of Lucene.
So I set out to implement a small Quarkus extension for Lucene.
Depending on the implementation details of the library in question, this can be a more or less complex and time-consuming endeavor.
The workflow is like so:</p>
<div>
<ul>
<li>
<p>compile down an application using the library into a native image</p>
</li>
<li>
<p>run into some sort of …</p></li></ul></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/">https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/</a></em></p>]]>
            </description>
            <link>https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008083</guid>
            <pubDate>Fri, 31 Jul 2020 12:47:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Relational SQL Databases]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008050">thread link</a>) | @yarapavan
<br/>
July 31, 2020 | https://stribny.name/blog/2020/07/scaling-relational-sql-databases | <a href="https://web.archive.org/web/*/https://stribny.name/blog/2020/07/scaling-relational-sql-databases">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainContentOfPage">
		
<p>Many applications today still rely on traditional SQL databases like MySQL, MariaDb or PostgreSQL for data storage and data processing. With the growing amount of data and new workloads that are made with this database systems, we often find ourselves in situations where we need to think about scaling such systems.</p>



<p>When it comes to scaling, we might need to think about:</p>



<ul><li>data storage, if we store more and more data and it becomes expensive or slow working with them</li><li>fast INSERTs and UPDATES for write-heavy workloads</li><li>making SELECT queries faster because of their complexity or because they need to query huge amounts of data</li><li>concurrency if we have many clients interacting with the database</li></ul>



<p>In this article, I will present some basic ideas and starting points on scaling traditional SQL databases.</p>



<h3>Update the database</h3>



<p>Newer versions of MySQL, PostgreSQL and other traditional SQL databases typically come with performance improvements. Even if the newer database system is not faster as a direct replacement, there might be new features available that we can take advantage of. Keeping our database system up to date expands our options on what we can do with our data and gives us the best out of the box performance. It is a basic enabler for scaling.</p>



<h3>Scale vertically</h3>



<p>The most intuitive idea of scaling is to use better hardware to scale vertically (on one database server). When it comes to hardware we typically look at CPUs, disk and RAM:</p>



<ul><li>The number of CPUs affects how many queries the database can run and therefore how many clients can be served</li><li>The size of RAM gives us space for indexes, temporary tables and caches the database can store in a fast memory which makes our system faster due to minimizing IO access to disk</li><li>Disk IO speed highly affects the query times, especially for full scan reads (when indexes cannot be used) or for write-heavy systems</li><li>Disk size allows us to store more data</li></ul>



<h3>Leverage application cache</h3>



<p>If the application’s code is in our control we can cache data in a memory store like <a href="https://redis.io/">Redis</a> or <a href="https://memcached.org/">Memcached</a> to avoid querying the database. We don’t have to just cache database reads, but we can also use such systems as buffers for writes, e.g. when we are collecting analytical data and a possible delay is not a problem.</p>



<h3>Use efficient data types</h3>



<p>When it comes to data, it all starts with data types, in other words how individual pieces of information are physically stored in memory. Choosing appropriate data types is always a balance between efficiency and functionality, affecting the required memory, query performance and number of operations we can do with the specific data type.</p>



<p>There are two basic ways to think about optimal data types:</p>



<ul><li>logical: how to store general information like a telephone number or an IP address; for instance we can store color as a string, enum or as a collection of RGB integers and we can store IP address as a string or as bytes</li><li>physical: what specific data types we choose for strings, integers or time since we typically have multiple options; e.g. date and time can be typically stored as a timestamp (faster but with limited date range and functionality) or as a more complex datetime which is more developer friendly and flexible, allowing to store timezone etc.</li></ul>



<p>Using an appropriate type for a database column is especially important when we want to index the column, use it in the WHERE clause, use it for joins or when we have a lot of data.</p>



<h3>Data normalization and denormalization</h3>



<p>We are often trained to normalize data for relational databases in order to reduce data redundancy and improve data integrity. While this is generally useful, we might want to reconsider it for some of our data when it comes to scaling.</p>



<p>Generally speaking the simpler we make our data to be retrieved or saved, the more of it we can have.</p>



<h3>Precompute data</h3>



<p>A lot of SELECT queries can be optimized by having the data already in the requested form. This can be handy for analyzing large amounts of data. For instance, instead of aggregating data every time, we can aggregate them beforehand. Of course this isn’t always possible, e.g. we cannot aggregate other average aggregates because we would lose precision.</p>



<h3>Leverage materialized views</h3>



<p>Materialized views are continuously updated data that are updated on write operations or on scheduled time and can be seen as an extension of the previous point. Unlike classic views, materialized views are physically stored and don’t need to be computed when needed. This is useful for situations where a SELECT query would take a long time to produce the result.</p>



<p>As an example, look at <a href="https://www.pipelinedb.com/">PipelineDB</a> extension for PostgreSQL that produces aggregates on real-time data, allowing us to keep aggregated statistics on a write-heavy systems.</p>



<h3>Use proper indexes</h3>



<p>Using the right indexes on tables can be a huge performance changer. Typically, we should index the columns by which we want to query the data or which we want to use to perform joins. However, adding indexes can also reduce performance for write-heavy workloads, since indexes have to be updated on every INSERT and UPDATE. Also it doesn’t make sense to use indexes on some data types. So it is all about finding the right balance.</p>



<h3>Leverage the execution plan for query optimization</h3>



<p>For optimizing reads we need to know how the database query planner will execute our queries. We can use EXPLAIN statement to obtain the execution plan that the SQL server will use for our query.</p>



<p>Here we should look if the database plans to use any of the existing indexes on the tables or plans to make a full table scan. It can give us hints whether we should change the structure of our data, add indexes or rewrite the query in a different way. Please note however that full table scan can be also faster or necessary for some queries so it is not a black and white situation.</p>



<h3>Choose correct transaction isolation level</h3>



<p>The most common relational databases use multi-version concurrency control and make locking very granular (instead of locking the whole table, like MyISAM storage engine does). However, we still need to tell the database how exactly should the concurrency control behave and we can do so by setting appropriate transaction isolation level. There are 4 basic isolation levels in SQL:1992 standard and they will greatly affect how our database system behaves.</p>



<h3>Bulk INSERTs and UPDATEs</h3>



<p>Writing or updating individual rows in a table is not efficient, but databases like MySQL or PostgreSQL have ways to insert or modify data in bulk. We should leverage this every time we can.</p>



<h3>Compress data for storage</h3>



<p>Many times we don’t need to query the data by all the columns in a table. If this is the case, we can further optimize the storage size by storing some of the columns in a compressed form. This is especially useful for strings or some types of binary data.</p>



<p>Some databases or their extensions might be already compressing data under the hood so it always makes sense to look first how the data are stored and whether adding compression on the application layer would bring the desired benefit.</p>



<h3>Make ALTER TABLEs work</h3>



<p>When the amount of data or the workload grows we will experience slower and slower ALTER TABLEs to the point where some of them might not finish in a reasonable time. The first important thing to know is that there are typically two ways of changing the structure of the database tables. One is INPLACE, modifying the original table and the other one is COPY, creating a new table and moving the data afterwards. Databases typically try to modify tables INPLACE if possible, but it might make sense sometimes to explicitly ask for the COPY operation.</p>



<p>When adding a new column, it is better to add it at the end of the table, since inserting a column at a specific place is slow.</p>



<p>When changing existing column it might be a good idea to create a new column first, copy the data and remove the column afterwards.</p>



<p>If the write operations on the table make it difficult to perform ALTER TABLE, it makes sense to stop clients from writing into the table first. This is not always possible, but e.g. collection of analytical data can be postponed using an ingestion buffer in front of the database or we can temporarily pause our ETL jobs working with the table.</p>



<p>The last resort is to simply not do any ALTER TABLEs on large and write-heavy tables, opting for creating a new table to store the new data instead.</p>



<h3>Manage concurrent connections</h3>



<p>Every database server comes with some basic configuration on the maximum number of concurrent connections. When we need more, we typically need to reconfigure this value. Just increasing the value is not enough though – we need to make sure that our system can actually run well with our desired number of connections.</p>



<h3>Add read replicas</h3>



<p>Traditional SQL databases can’t typically scale horizontally for write operations by adding more servers, but we can still add other machines in the form of read-only replicas. The way this works is that all write operations are done on the main server and propagated to other machines using Write Ahead Log. All the replicas will therefore apply the same operations in the same order to the underlying storage as the main server. This ensures that the data will be in sync.</p>



<p>Replicas can be then used for scaling the number of read queries and number of connected clients if they only need read operations.</p>



<h3>Disk partitioning</h3>



<p>Partitioning allows us to distribute one single table across the filesystem and store individual partitions based on some specific rules. When such rules are chosen well, SQL queries don’t have to query all partitions but can limit their search only to a subset of them. This will cut the time the query will run since not the whole database table needs to be looked into.</p>



<h3>Use specialized extensions</h3>



<p>When we need to store and work with geospatial, time series and other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stribny.name/blog/2020/07/scaling-relational-sql-databases">https://stribny.name/blog/2020/07/scaling-relational-sql-databases</a></em></p>]]>
            </description>
            <link>https://stribny.name/blog/2020/07/scaling-relational-sql-databases</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008050</guid>
            <pubDate>Fri, 31 Jul 2020 12:42:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Everything” Is Done]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008049">thread link</a>) | @AlchemistCamp
<br/>
July 31, 2020 | https://questinglog.com/everything-is-done/ | <a href="https://web.archive.org/web/*/https://questinglog.com/everything-is-done/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>It's not unusual to see people on entreprenurial subreddits or message boards make a claim along the lines of, "Your tech (software) choices don't matter. It's all about the sales and marketing." Many of the same people will say things like, "software is easy... the hard part is marketing".</p> <p>It's generally easy to dismiss these claims. Not only is it clear that organizations such as governments and banks often spend great deal of money <em>completely</em> fail to make decent web apps, but the other half of the statement fails as well. Rand Fishin's excellent book <a href="https://sparktoro.com/book" target="_blank" rel="noopener noreferrer">Lost &amp; Founder</a> goes into detail about just how difficult it can be for even a world-class marketer to compete with more technical rivals.</p> <p>A truer claim would be, "the hard part" is whatever isn't in the founder's skill set.</p> <h2 id="tech-is-done"><a href="#tech-is-done">#</a> Tech is done</h2> <p>One reason why many people see less value in technical talent or a "good tech stack", whatever that may mean, is the belief that tech is "done". Many people are building the same kinds of B2B SaaS web apps or consumer-focused content sites in 2020 that were being built in 2007. There absolutely are deeper technology challenges being tackled, but that's a topic for another day.</p> <p>There really <em>isn't</em> much challenging in building a Reddit clone or a Zendesk clone in 2020. Using a productive framework like Rails, Laravel or Phoenix, a mid-level full-stack dev could crank out an MVP in a day. Even without a such a framework, shipping it over a weekend wouldn't be uncommon.</p> <p>A week ago, I saw an interesting <a href="https://news.ycombinator.com/item?id=23923104" target="_blank" rel="noopener noreferrer">comment</a> from an startup-employee and entrepreneur that took the idea a step further:</p> <blockquote><p>I work in early stage product startups.</p> <p>What R&amp;D do you need? CRUD is solved, hosting is solved, UX is solved, scaling is solved, marketing is solved ...</p> <p>Everything to do with web and mobile is very solved at this point. Most problems come from tripping over ourselves and cobbling things together to fit new domains.</p> <p>All real hard R&amp;D happens inside faang these days. At least for web/mobile consumer stuff.</p></blockquote> <h2 id="marketing-is-done"><a href="#marketing-is-done">#</a> Marketing is done</h2> <p>Not only are there frameworks and playbooks for <em>building</em> a polished CRUD web app and/or mobile app, but there frameworks and playbooks for marketing them and selling them, too!</p> <p>Knowledge of how to effectively design an email funnel or run Facebook ads may have been relatively scarce a decade ago, but it sure isn't now! "Everybody" knows how important it is to build an email list, test landing pages, talk to early customers, etc, etc, etc.</p> <p>The secret isn't locked up in a few expensive members-only communities or Silicon Valley-based startups. It's out. It's gone global. There are even fantastic books about getting <a href="https://medium.com/@yegg/78-takeaways-from-traction-book-1b44d2a03dda" target="_blank" rel="noopener noreferrer">Traction</a></p> <h2 id="financing-is-done"><a href="#financing-is-done">#</a> Financing is done</h2> <p>It used to be expensive to build a web app. There weren't many investors willing to put up the money it took. The few that were tended to be highly credentialist.</p> <p>Now it's so cheap that founders are building on the side and keeping their jobs until reaching a replacement salary. Fundraising options have also exploded—traditional investors have multiplied, crowd funding is a force, blockchain-based models are popping up and there are even <a href="https://earnestcapital.com/" target="_blank" rel="noopener noreferrer">some investors</a> who fund bootstrappers with no intention of <em>ever</em> building a gigantic business.</p> <p>It still doesn't hurt to have gone to Stanford, Harvard or similarly elite institution but it's far less of an uphill struggle for those who haven't in 2020 than it was in the past.</p> <h2 id="the-remaining-question"><a href="#the-remaining-question">#</a> The remaining question</h2> <p>If the skills that were an unfair advantage in the aughts are now widespread, then what <em>is</em> the edge in 2020?</p>  <h2 id=""><a href="#">#</a> <br></h2> <p><a href="http://news.ycombinator.com/submitlink?t=%22Everything%22%20is%20done.%20&amp;u=https://questinglog.com/everything-is-done" target="_blank" rel="noopener noreferrer">Comment on HN</a></p></div></div>]]>
            </description>
            <link>https://questinglog.com/everything-is-done/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008049</guid>
            <pubDate>Fri, 31 Jul 2020 12:42:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse engineering an Android Application (intro)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008045">thread link</a>) | @otobrglez
<br/>
July 31, 2020 | https://epic.blog/reverse-engineering/2020/07/27/reverse-engineering-android-app.html | <a href="https://web.archive.org/web/*/https://epic.blog/reverse-engineering/2020/07/27/reverse-engineering-android-app.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Hello, a good reader of my <a href="https://epic.blog/">epic.blog</a>!</p>

<p>On this lovely and streaming hot July day, I wish to take you on a journey of my reverse engineering trip across the mountains of Android and the valleys of decompilers. Pour yourself a cold drink and enjoy this voyage.</p>

<p>So; I wanted to demonstrate how to reverse engineer an Android Application and what tools you can use to achieve this - even without owning an Android Phone.</p>

<p>The app used for this demonstration is called <a href="https://play.google.com/store/apps/details?id=hr.molekula.bikekrk">Krk Bike</a>, and it is a mobile application that you can download from <a href="https://play.google.com/store/apps/details?id=hr.molekula.bikekrk">Google Play store</a>, and it will show you many of bike trails on <a href="http://www.krk.hr/en/">Croatia’s island of Krk</a>. <em>I wanted to see all of this bike trails in a single, un-cluttered map.</em> How could we get such data out of this app?</p>

<p>When you open up this app on your phone, it looks something like this:</p>

<p><img src="https://epic.blog/assets/2020-07-27-reverse-engineering-android-app/krk-bike-in-play-store.png" alt="krk-bike-in-play-store"></p>

<p>The app itself has detailed trails with paths and pictures plus contacts, and it even comes with small “navigation module” that will guide you through the track while while you are on the route. Pretty decent and slick app. Obviously - dear reader - you’ll choose your own target at some point, but this one is interesting to me. It is definitely a good first step to be familiar with the app as much as possible.</p>

<h2 id="how-are-android-apps-built">How are Android apps built?</h2>

<p>Well. First, you need to understand how Android apps are <strong>built</strong> and <strong>distributed</strong>. Usually, Android developers develop their apps with the help of <a href="https://developer.android.com/studio">Android Studio</a>, compile them, sign them and upload the “apks” to Google Play Store. The more detailed explanation about the process of building Android apps for beginners and getting them to end-users can be found on <a href="https://developer.android.com/training/basics/firstapp/creating-project">Android documentation page (Create an Android project)</a>.</p>

<p>Hold on, mister! ✋How are apps compiled, and how do they even run?</p>

<p>Now that you’ve asked. In a nutshell. Usually, Android apps are compiled in a few stages. The first stage; depending on your source code gets compiled either with Java compiler or Kotlin compiler to Java bytecode. These compilers spit-out <code>*.class</code> files. The <code>*.class</code> files are then fed into DX (<a href="https://developer.android.com/studio/command-line/d8">DEX compiler - <code>d8</code></a>). DEX compiler spits out DEX bytecode that runs on Android devices, and it allows you to use Java 8 language features in your app’s code. DEX bytecode is then something that <a href="https://en.wikipedia.org/wiki/Dalvik_(software)">Dalvik Virtual Machine (DVM for short)</a> actually runs your app.</p>

<p><img src="https://epic.blog/assets/2020-07-27-reverse-engineering-android-app/android-app/compilation.png" alt="compilation"></p>

<p>Now; if you know anything about Android. You’re likely to say: “Sorry, Oto! Old news! DVM is deprecated since KitKat.” And you would be right! Dalvik has been replaced with something much more magical - called Android Runtime (ART for short). But few core concepts are the same, just better.</p>

<blockquote>
  <p>The successor of Dalvik is <a href="https://en.wikipedia.org/wiki/Android_Runtime">Android Runtime</a> (ART), which uses the same bytecode and .dex files (but not .odex files), with the succession aiming at performance improvements transparent to the end users. The new runtime environment was included for the first time in Android 4.4 “KitKat” as a technology preview, and replaced Dalvik entirely in later versions; Android 5.0 “Lollipop” is the first version in which ART is the only included runtime.</p>
</blockquote>

<p>Ok; so the next step in the building process for any Android app is to package it into something that is called <a href="https://developer.android.com/google/play/expansion-files">APK</a>. An <a href="https://developer.android.com/google/play/expansion-files">Android Package Kit (APK for short)</a> is the package file format used by the Android operating system for distribution and installation of mobile apps. Think of it as a package with some more meta-information attached, sophisticated Java <code>*.jar</code> or Debian’s <code>*.deb</code> package.</p>

<p>After developers successfully build these APK’s they “push” them to devices or to Google Play Store. If its development process, that’s usually done via <a href="https://developer.android.com/studio/command-line/adb"><code>adb</code></a> in command-line (or Android Studio will use something similar in the background for you). If its production release, people sometimes also <a href="https://developer.android.com/studio/publish/app-signing">sign these things</a> with their keys either with <a href="https://developer.android.com/studio">Android Studio</a> or with <a href="https://developer.android.com/studio/command-line/apksigner"><code>apksigner</code></a> via CLI directly. The Android system uses the certificate as a means of identifying the author of an application and establishing trust relationships between applications.</p>

<p>Ok, now that you know how apps are built, packaged and pushed to store,…</p>

<h2 id="how-can-i-get-apk-of-an-app-from-google-play-store">How can I get APK of an app from Google Play Store?</h2>

<p>There are multiple ways you can get APK of any given Android App. The most trivial is to use one of multiple “mirror” sites that collect these APKs. Sometimes they automate the process and sometimes - as I found out via my uber Googling skills - they just have people fetch populat APKs manually. To name a few of these <a href="https://apkpure.com/">apkpure.com</a>, <a href="https://apps.evozi.com/apk-downloader/">evozi APK Downlowder</a> and <a href="https://www.apkmirror.com/">apkmirror.com</a>. These sites have few disadvantages; the foremost being that not “all” apk’s that are on Google Play Store is available, and that this is a “mirror” site and there is no way of assuring that these apk’s and Apps that these belong to are untempered. Although hard, it is possible to inject malicious code and spread it via these or similar sites.</p>

<h3 id="-but-they-dont-have-my-app-there">… but they don’t have my app there!</h3>

<p>Oh, yeah. In that case, you can do what I did. You can</p>

<ol>
  <li>
    <p>Install <a href="https://www.virtualbox.org/">Oracle VirtualBox</a> on your machine.</p>
  </li>
  <li>
    <p>Get Android-x86 OS image from <a href="https://www.osboxes.org/android-x86/">OSBoxes.org (follow this link)</a>.</p>
  </li>
  <li>
    <p>Bootup the Android image and then go to Google Play Store,…</p>
  </li>
  <li>
    <p>then install the app you wanna look into.</p>
  </li>
  <li>
    <p>after app installs, download an app called <a href="https://play.google.com/store/apps/details?id=com.yschi.MyAppSharer">MyAppSharer</a>.</p>

    <p>I stored the APK of targeted app into <code>/storage/emulated/0/</code></p>
  </li>
  <li>
    <p>at this point, you can either install Android tools on your machine and then use adb to pull apk to host machine with following command. <strong>Or</strong> you can creativly just email yourself apk from MyAppSherer app in the emulator. (lol)</p>

    <div><div><pre><code>adb pull /storage/emulated/0/hr.molekula.bikekrk.apk
</code></pre></div>    </div>
  </li>
</ol>

<p>At this point, I wish to clarify a few things. Although for a given example this works; Android-x86 is an open-source effort to port Android to x86 architecture. An experiment that has now also extended beyond the primary x86 platform. Please make sure you visit their site and <a href="https://www.android-x86.org/donate.html">buy them a coffee</a> if you like the project. Second. There are also other ways where you could pull apk from an Android phone or emulator, but I found all of them to be hard or unreliable, so that’s why I’m sharing this app here.</p>

<h2 id="i-have-the-apk--now-what-">I have the APK! ✅ Now what? 🤔</h2>

<p>After you obtain the APK of an app that you wish to peek into. The next step is to decompile <code>*.apk</code> into something useful. i.e. <code>*.java</code> source code. The decompilation process of Android source code is usually a two-step process. First, you unpack raw APK back to “files”, then those dalvik codes (<code>*.smil</code>) needs to be converted back to Java classes. Note at this stage. Compilation usually means trimming some characters, names and also introducing some optimisations, so by no means expect that the decompiled code will match back to original source code. But in general, it is good enough that an expert will be able to figure out what is going on.</p>

<p><img src="https://epic.blog/assets/2020-07-27-reverse-engineering-android-app/android-app/decompilation.png" alt="decompilation"></p>

<p>In other to do that there are several open-source tools available that you can use. For this experiment, I’ve used these. Some of them are pretty basic, and very Android specific, others however, like NSA’s Ghidra are more general purpose reverse engineering tools.</p>

<h3 id="apktool">Apktool</h3>

<p>This reverse engineering tool is the most probably most sophisticated and Android specific from this list and it can disassemble resources nearly to the original; including XMLs, images and other assets.</p>

<div><div><pre><code>java <span>-jar</span> apktool_2.4.1.jar d hr.molekula.bikekrk.apk
</code></pre></div></div>

<p>If you run this tool it will spit out tree-structure of the original app that looks something like this; please note that it does not convert *.smil files back to Java source code. But it does an incredible job with other resources.</p>

<p><img src="https://epic.blog/assets/2020-07-27-reverse-engineering-android-app/apktool-files.png" alt="apktool-files"></p>

<h3 id="java-decompiler">Java Decompiler</h3>

<p>This decompiler can be used practically on any Java application. If comes in tree flaveours. JD-GUI, the variation with user interface, JD-Eclipse as an plugin for Eclipse IDE and JD-Core as an lib.</p>

<p>The small gotcha with <a href="http://java-decompiler.github.io/">Java Decompiler</a> is that you need to convert your APK to JAR before it can be decompiled and inspected by it. To do that you need to geta tool called <a href="https://github.com/pxb1988/dex2jar">dex2jar</a> that will help you construct JAR.</p>

<div><div><pre><code>./dex2jar-2.0/d2j-dex2jar.sh <span>-f</span> hr.molekula.bikekrk.apk <span># for DEX -&gt; JAR</span>
java <span>-jar</span> jd-gui-1.6.6.jar <span># to bootup Java Decompiler GUI</span>
</code></pre></div></div>

<p><img src="https://epic.blog/assets/2020-07-27-reverse-engineering-android-app/jd-gui.png" alt="jd-gui"></p>

<h3 id="jadx">JADX</h3>

<p>This tool is very likely the most “for Android” that I’ve found and managed to use. It can be used with GUI or purely from CLI. It can also run directly on APK / DEX combo without the extra step like <a href="http://java-decompiler.github.io/">Java Decompiler</a> mentioned early. It has also magical ability to deal with deobfuscation and from what I can tell the best full text search, decleartion jumping and usage lookup. When ran; it looks like this:</p>

<p><img src="https://epic.blog/assets/2020-07-27-reverse-engineering-android-app/jadx-gui.png" alt="jadx-gui"></p>

<h3 id="ghidra">Ghidra</h3>

<p>Although I originaly explored tools that are very Android or Java specific. I also get a recommendation from a friend to look into usage of <a href="https://ghidra-sre.org/">Ghidra</a>, a more general purpose software reverse engineering (SRE) suite of tools developed by NSA’s Research Directorate in support of the Cybersecurity mission.</p>

<p>Initially if feels a bit cluncky, and although it should work directly on *.APK’s I had to covert APK to JAR with <a href="https://github.com/pxb1988/dex2jar">dex2jar</a> the same way as I did with <a href="https://github.com/skylot/jadx">JADX</a> before I could use it. There are other ways you could also just load <code>classes.dex</code> via “file system” import that I later found to also works.</p>

<p><img src="https://epic.blog/assets/2020-07-27-reverse-engineering-android-app/ghidra.png" alt="ghidra"></p>

<p>Ghidra is <strong>definitly next level</strong> when it comes to reverse engineering and the toolbox seems to have everything and even more than a human might need for a simple experiment like the one I’m trying to demonstrate here.</p>

<h3 id="javadecompilerscom">javadecompilers.com</h3>

<p>In some cases you even might not need to install any of these tools and frameworks and you can just use the online solution like <a href="http://www.javadecompilers.com/">javadecompilers.com</a>. Alghouth bit cumbersone; it can still be used to look into simple Java / Android apps.</p>

<p><img src="https://epic.blog/assets/2020-07-27-reverse-engineering-android-app/javadecompilers.png" alt="javadecompilers"></p>

<h2 id="i-have-the-source--now-what-">I have the source. ✅ Now what?! 💡</h2>

<p>After you’ve successfully obtained the source code with decompilation process the next step is to probably <strong>limit the scope of your investigation</strong> and start reading the code. In my case I was looking for two things; how does the app connect to the web service that exposes “tracks” and for the coordinates of the …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://epic.blog/reverse-engineering/2020/07/27/reverse-engineering-android-app.html">https://epic.blog/reverse-engineering/2020/07/27/reverse-engineering-android-app.html</a></em></p>]]>
            </description>
            <link>https://epic.blog/reverse-engineering/2020/07/27/reverse-engineering-android-app.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008045</guid>
            <pubDate>Fri, 31 Jul 2020 12:41:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My 10 Go-To Reflection Questions (and Where I Found Them)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008026">thread link</a>) | @dickiebush
<br/>
July 31, 2020 | https://www.dickiebush.com/articles/My-10-go-to-reflection-questions | <a href="https://web.archive.org/web/*/https://www.dickiebush.com/articles/My-10-go-to-reflection-questions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-74186e655e714d161036"><div><p>For 500 days in a row, I’ve written 500 words of Morning Pages. If you’ve never heard of Morning Pages, it’s a fancy way to say journaling. Every morning, I type out anything and everything that’s on my mind.  </p><p>Most mornings are brain dumps to clear my head and get on with the day. But I sometimes like to reflect on specific questions. Over the years, I’ve found there are 10 questions that help me reflect or work through any problem. </p><p>If you’re interested, I’ve aggregated each of these questions into a nicely formatted template. If you drop your email in the box at the bottom, I’ll shoot it your way. </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596196579571_53349"><div><h3>1. How am I complicit in creating the conditions I say I don’t want?</h3><p>This question is a staple for me. On the first Sunday of every month, I’ll sit down and truthfully answer this question. </p><p>This questions helps me identify where my actions aren’t matching my words. I’ll often say I want to do things a certain way on paper, but then fail to do them that way. By answering this question, I can see where I’m lying to myself.</p><p>This question comes from <a href="https://open.spotify.com/episode/0rSG9ysPbrSu5iBfCYaRFQ?si=xmLVxlEERUKwp_U7wkOUNw"><strong>Episode #373 of the Tim Ferriss Show with professional coach Jerry Colonna</strong></a>. This episode is loaded with questions and ideas that will leave you more reflective and curious. </p><h3>2. Where am I feeling the Resistance?</h3><p>Every Monday morning, I ask myself this question. If you’ve never heard of the Resistance, you should read <a href="https://dickiebush.com/book-notes/resistance"><strong>Stephen Pressfield’s The War of Art</strong></a> today. It’s the most influential book on my productivity and motivation I’ve ever read. </p><blockquote><p>What elicits the Resistance?&nbsp;<strong>Any act that rejects immediate gratification in favor of long-term growth, health, or integrity</strong>.&nbsp;Or, expressed another way, any act that derives from our higher nature instead of our lower. Any of these will elicit Resistance.</p></blockquote><p>You can check out my notes on The War of Art <a href="https://dickiebush.com/book-notes/resistance"><strong>here</strong></a><strong>.</strong></p><h3>3. What would I do to make today horrible?</h3><p>This question leverages the <a href="https://www.dickiebush.com/articles/inversion-mental-model-munger"><strong>Inversion Principle</strong></a><strong>.</strong> Avoiding poor decisions is easier than making the right ones. So instead of thinking of everything I want to do that day, I think of everything I could do to make today horrible. Then I just avoid doing those. </p><h3>4. Where am I making things more complex than they need to be?</h3><p>I sometimes make simple things more complex than they need to be. Overcomplication creates billion-dollar industries. But most solutions are simple and deserve no more than a tweet’s worth of text.</p><p>For a deep dive into why we overcomplicate things (and how to stop doing so), check out this <a href="https://t.co/GfRs5R2hg6"><strong>deep dive blog post</strong></a><strong>. </strong></p><h3>5. What would this look like if it were easy?</h3><p>This is the first of three questions I found in Tim Ferriss’ blog post <a href="https://t.co/HxZazlVFeB"><strong>17 Questions That Changed My Life</strong></a>. </p><p>This question assumes the answer to my problem is easy. I then think of all the ways that might be true. Working backwards this way always shakes up my perspective, leading to new insights. </p><h3>6. What if I did the opposite in every area?</h3><p>I sometimes get stuck in my default way of doing things. To refresh my outlook, I’ll think about what would happen if I started doing everything opposite of how I currently am.</p><p>For example, I recently went 13 weeks on the Carnivore Diet, just to see what happened. So I asked the question - <strong>“What would happen if I went Vegan for 13 weeks?”</strong></p><p>I don’t plan on doing so, but the answers I came up with were more interesting than I thought they’d be. </p><h3>7. If I could only work for four hours this week, what would I work on?</h3><p>I occasionally feel overwhelmed with too many things. This questions helps me identify the highest leverage thing I can work on. It also leverages <a href="https://www.dickiebush.com/articles/parkinsons"><strong>Parkinson’s Law</strong></a><strong>, </strong>adding a creative constraint to better target my attention. </p><h3>8. How could I achieve my 10-year goals in six months?</h3><p>This question is the most fun to answer. On the first Saturday of every month, I’ll give it a whirl. </p><p>Thinking in extremes helps to wash aware any self-imposed limitations. The answers are usually unrealistic. But there have been plenty of times where this change in mindset lead to some insightful ideas. </p><h3>9. How would the type of person I want to become handle this?</h3><p>When faced with a big decision or problem, I ask myself this question to look for a bolder response. Thinking about the best way I could possibly handle something sets a high bar for action. </p><p>This questions comes from a blog post from one of my favorite writers, David Cain. It’s called <a href="https://t.co/AgbFPPkmGb"><strong>How to Get Out of a Rut in 20 Minutes</strong></a><strong> </strong>and is filled with even more reflection questions. </p><h3>10. What would I do if it was impossible for me to fail?</h3><p>Fear of failure is one of the most common self-imposed limitations. Eliminating failure as an option and sincerely asking “what would I do now?” helps me think bigger and bolder.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596196579571_23200"><div><h3>Now it’s your turn</h3><p>I’ve aggregated these questions into a nicely formatted template that you can copy and fill out yourself. If you’re interested, I’ll email it to you along with a few other of my favorite reflection resources. Just fill out this template below. </p></div></div></div>]]>
            </description>
            <link>https://www.dickiebush.com/articles/My-10-go-to-reflection-questions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008026</guid>
            <pubDate>Fri, 31 Jul 2020 12:37:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning's Most Important Ideas]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007965">thread link</a>) | @Anon84
<br/>
July 31, 2020 | https://dennybritz.com/blog/deep-learning-most-important-ideas/ | <a href="https://web.archive.org/web/*/https://dennybritz.com/blog/deep-learning-most-important-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The goal of this post is to review well-adopted ideas that have stood the test of time. I will present a small set of techniques that cover a lot of basic knowledge necessary to understand modern Deep Learning research. If you're new to the field, these are a great starting point.</p><div id="post-content"><p>Deep Learning is an extremely fast-moving field and the huge number of research papers and ideas can be overwhelming. Even seasoned researchers have a hard time telling company PR from real breakthroughs. The goal of this post is to review those ideas that have <strong>stood the test of time</strong>, which is perhaps the only significance test one should rely on. These ideas, or improvements of them, have been used over and over again. They're known to work.</p> <p>If you were to start in Deep Learning today, understanding and implementing each of these techniques would give you an excellent foundation for understanding recent research and working on your own projects. It's what I believe the best way to get started. Working through papers in historical order is also a useful exercise to understand where the current techniques come from and why they were invented in the first place. <strong><strong>Put another way, I will try to present a <em>minimal set</em> of ideas that most of the basic knowledge necessary to understand modern Deep Learning research.</strong></strong></p> <p>A rather unique thing about Deep Learning is that its application domains (Vision, Natural Language, Speech, RL, etc) share the majority of techniques. For example, someone who has worked in Deep Learning for Computer Vision his whole career could quickly be productive in NLP research. The specific network architectures may differ, but the concepts, approaches and code are mostly the same. I will try to present ideas from various fields, but there are a few caveats about this list:</p> <ul> <li>My goal is not to give in-depth explanations or code examples for these techniques. It's not easily possible to summarize long complex papers into a single paragraph. Instead, I will give a brief overview of each technique, its historical context, and links to papers and implementations. If you want to learn something, I <em>highly recommend</em> trying to re-produce some of these paper results from scratch in raw <a href="https://pytorch.org/">PyTorch</a> without using existing code bases or high-level libraries.</li> <li>The list is biased towards my own knowledge and the fields I am familiar with. There are many exciting subfields that I don't have experience with. I will stick to what most people would consider the popular mainstream domains of Vision, Natural Language, Speech, and Reinforcement Learning / Games.</li> <li>I will only discuss research that has official or semi-official open source implementations that are known to work well. Some research isn't easily reproducible because it involves huge engineering challenges, for example <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">DeepMind's AlphaGo</a> or <a href="https://openai.com/projects/five/">OpenAI's Dota 2 AI</a>, so I won't highlight it here.</li> <li>Some choices are arbitrary. Often, rather similar techniques are published at around the same time. The goal of this post is not be a comprehensive review, but to to expose someone new to the field to a cross-section of ideas that cover a lot of ground. For example, there may be hundreds of GAN variations, but to understand the general concept of GANs, it really doesn't matter which one you study.</li> </ul>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep Convolutional Neural Networks (2012)</a> <span data-cites="krizhevsky_imagenet_2012">Krizhevsky, Sutskever, and Hinton (2012)</span></li> <li><a href="https://arxiv.org/abs/1207.0580">Improving neural networks by preventing co-adaptation of feature detectors (2012)</a> <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span></li> <li><a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks (2014)</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/hub/pytorch_vision_alexnet">AlexNet in PyTorch</a></li> <li><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/alexnet.py">AlexNet in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/alexnet-full.png" alt=""><figcaption>Source: <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</a></figcaption> </figure> <p>AlexNet is often considered the algorithm responsible for the recent boom in Deep Learning and Artificial Intelligence research. It is a Deep Convolutional Neural Network based on the earlier LeNet developed by Yann LeCun. AlexNet beat previous methods at classifying images from the <a href="http://image-net.org/index">ImageNet dataset</a> by a significant margin through a combination of GPU power and algorithmic advances. It demonstrated that neural networks actually work! AlexNet was also one of the first times Dropout <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span> was used, which has since become a crucial component for improving the generalization ability of all kinds of Deep Learning models.</p> <p>The architecture used by AlexNet, a sequence of Convolutional layers, ReLU nonlinearity, and max-pooling, became the accepted standard that future Computer Vision architectures would extend and built upon. These days, software libraries such as PyTorch are so powerful, and compared to more recent architectures AlexNet is so simple, that it can be implemented in only a few lines of code. Note that many implementations of AlexNet, such as those linked above, use the slight variation of the network described in <a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span>.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning (2013)</a> <span data-cites="mnih_playing_2013">Mnih et al. (2013)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html">DQN in PyTorch</a></li> <li><a href="https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial">DQN in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/deep-q-learning-value.png" alt=""><figcaption>Source: <a href="https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning">https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning</a></figcaption> </figure> <p>Building on top of the recent breakthroughs in image recognition and GPUs, a team at DeepMind managed to train a network to <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">play Atari Games</a> from raw pixel inputs. What's more, the <em>same</em> neural network architecture learned to play seven different games without being told any game-specific rules, demonstrating the generality of the approach.</p> <p>Reinforcement Learning differs from Supervised Learning, such as image classification, in that an agent must learn maximize to the sum of rewards over multiple time steps, such as winning a game, instead of just predicting a label. Because the agent interacts directly with the environment and each action affects the next, the training data is not independent and identically distributed (iid), which makes the training of many Machine Learning models quite unstable. This was solved by using techniques such as experience replay <span data-cites="lin_self-improving_1992">Lin (1992)</span>.</p> <p>While there was no obvious algorithmic innovation that made this work, the research cleverly combined existing techniques, convolutional neural networks trained on GPUs and experience replay, with a few data processing tricks to achieve impressive results that most people would not have expected. This gave people confidence in extending Deep Reinforcement Learning techniques to tackle even more complex tasks such as <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">Go</a>, <a href="https://openai.com/projects/five/">Dota 2</a>, <a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii">Starcraft 2</a>, and others.</p> <p>Atari Games <span data-cites="bellemare_arcade_2013">Bellemare et al. (2013)</span> have since become a standard benchmark in Reinforcement Learning research. The initial approach only solved (beat human baselines on) seven games, but over the coming years advances built on top of these ideas would start beating humans on an ever increasing number of games. One particular game, Montezuma’s Revenge, was famous for requiring long-term planning and was considered to be among the most difficult to solve. It was only recently <span data-cites="badia_agent57_2020">Badia et al. (2020)</span> <span data-cites="ecoffet_first_2020">Ecoffet et al. (2020)</span> that techniques managed to beat human baselines on all 57 games.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a> <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span></li> <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#">Seq2Seq with Attention in PyTorch</a></li> <li><a href="https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt">Seq2Seq with Attention in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/seq2seq-cn.gif" alt=""><figcaption>Source: <a href="https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html">https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html</a></figcaption> </figure> <p>Deep Learning's most impressive results had largely been on vision-related tasks and was driven by Convolutional Neural Networks. While the NLP community had success with <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Language Modeling</a> and Translation using LSTM networks <span data-cites="hochreiter_long_1997">Hochreiter and Schmidhuber (1997)</span> and Encoder-Decoder architectures <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span>, it was not until the invention of the <strong>attention</strong> mechanism <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span> that things started to work spectacularly well.</p> <p>When processing language, each token, which could be a character, a word, or something in between, is fed into a recurrent network, such as an LSTM, which maintains a kind of memory of previously processed inputs. In other words, a sentence is very similar to a time series with each token being a time step. These recurrent models often had difficulty dealing with dependencies over long time horizons. When they process a sequence, they would easily "forget" earlier inputs because their gradients needed to propagate through many time steps. Optimizing these models with gradient descent was hard.</p> <p>The new attention mechanism helped alleviate the problem. It gave the network an option to adaptively "look back" at earlier time steps by introducing shortcut connections. These connections allowed the network to decide which inputs are important when producing a specific output. The canonical example is translation: When producing an output word, it typically maps to one or more specific input words.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a> <span data-cites="kingma_adam_2017">Kingma and Ba (2017)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://d2l.ai/chapter_optimization/adam.html">Implementing Adam in Python</a></li> <li><a href="https://pytorch.org/docs/master/_modules/torch/optim/adam.html">PyTorch Adam implementation</a></li> <li><a href="https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/optimizer_v2/adam.py#L32-L281">TensorFlow Adam implementation</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/optimizer-benchmark.png" alt=""><figcaption>Source: <a href="http://arxiv.org/abs/1910.11758">http://arxiv.org/abs/1910.11758</a></figcaption> </figure> <p>Neural networks are trained by minimizing a loss function, such as the average classification error, using an optimizer. The optimizer is responsible for figuring out how to adjust the parameters of the network to make it learn the objective. Most optimizers are <a href="https://ruder.io/optimizing-gradient-descent/">based on variations of Stochastic Gradient Descent (SGD)</a>. However, many of these optimizers contain tunable parameters such as a learning rate themselves. Finding the right settings for a specific problem not only reduces training time, but can also lead to better results due to finding a better local minimum of the loss function.</p> <p>Big resarch labs often ran expensive hyperparameter searches that came up with complex learning rate schedules to get the best out of simple but hyperparameter-sensitive optimizers such as SGD. When they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dennybritz.com/blog/deep-learning-most-important-ideas/">https://dennybritz.com/blog/deep-learning-most-important-ideas/</a></em></p>]]>
            </description>
            <link>https://dennybritz.com/blog/deep-learning-most-important-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007965</guid>
            <pubDate>Fri, 31 Jul 2020 12:25:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starting a Business Around GPT-3 Is a Bad Idea]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24007929">thread link</a>) | @paraschopra
<br/>
July 31, 2020 | https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/ | <a href="https://web.archive.org/web/*/https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GPT-3 is an amazing technology. Within a few weeks after beta API access opened, a <a href="https://twitter.com/xuenay/status/1283312640199196673" target="_blank">host of jaw-dropping demos</a> popped up, from <a href="https://twitter.com/sharifshameem/status/1282676454690451457" target="_blank">automatic code generation</a> to <a href="https://twitter.com/nicklovescode/status/1283326066338062337" target="_blank">automated therapy bots</a> to <a href="https://www.gwern.net/GPT-3" target="_blank">writing original poetry and Navy SEAL copypasta memes</a>. It does things that would have been science fiction 10 years ago.&nbsp;GPT-3 and its successor algorithms are going to change entire industries.</p><p>Naturally, tech founders and VC investors are salivating at the possibilities of turning GPT-3 applications into businesses.</p><p>But a good technology doesn’t necessarily make for a good business. <strong>The fact that GPT-3 works so well out of the box should be terrifying to founders.</strong> Here’s why:</p><ul><li>If it’s easy to make a good-enough app out of the box, the barriers to entry are mercilessly low. Dozens of competitors for your idea will spring up literally overnight, as they already have in these Twitter demos.</li><li>It’s not just about new entrants. If GPT-3 is so easy to adopt and build products with, incumbents will do it too. Thus, in Clayton Christensen’s framework, GPT-3 looks more like a <strong>sustaining innovation</strong> than a disruptive innovation. This will strengthen existing winners more than it creates openings for new startups.</li><li>If the baseline GPT-3 performance cannot be substantially improved to create a substantial (10x) proprietary edge, the competition will shift away from technology to other dimensions of competition—particularly in marketing and distribution. This is where incumbents beat startups.</li><li>Meanwhile, the profits will accrue to the true beneficiaries: 1) the algorithm owners,&nbsp; OpenAI (and, by extension, Azure), 2) to marketing platforms, particularly Google and Facebook. Both can raise pricing to the point where companies built on each are barely profitable.</li></ul><p>Let’s dive more into these ideas.</p><h2><span id="Low_Barrier_to_Entry_Fierce_Competition"><strong>Low Barrier to Entry = Fierce Competition</strong></span></h2><div><figure><img src="https://i1.wp.com/www.allencheng.com/wp-content/uploads/2020/07/image.png?w=750&amp;ssl=1" alt="" srcset="https://i1.wp.com/www.allencheng.com/wp-content/uploads/2020/07/image.png?w=471&amp;ssl=1 471w, https://i1.wp.com/www.allencheng.com/wp-content/uploads/2020/07/image.png?resize=300%2C174&amp;ssl=1 300w" sizes="(max-width: 471px) 100vw, 471px" data-recalc-dims="1"></figure></div><p><a href="https://a16z.com/2020/05/28/moats-before-gross-margins/" target="_blank">Moats provide an enduring competitive advantage</a>. The wider and deeper the moat, the higher the barrier to entry to compete with your business, and the less capably a hotshot teenager can start a new company to compete.</p><p>If a moat is shallow, hundreds of competitors can pop up overnight and provide a good-enough competing product. If you can’t build a meaningful product advantage, then the grounds of competition shift to other dimensions of competition—namely, marketing and distribution.</p><h3><strong>The Parable of Online Mattresses</strong></h3><p>The online mattress industry had shallow moats and played out predictably. A few years ago, if you wanted to start a new mattress company, you only needed to cobble together a few components:</p><ul><li>A manufacturer</li><li>A website</li><li>A marketing campaign</li></ul><p>At the peak of the industry, there were <a href="https://www.cnbc.com/2019/08/18/there-are-now-175-online-mattress-companiesand-you-cant-tell-them-apart.html" target="_blank">175 online mattress companies</a>. None had a meaningful product advantage—many used the same mattress manufacturers. (And having personally tried several of these mattresses in stores, they really did feel about the same.)</p><p>The grounds of competition thus shifted to marketing and branding, which is why a year ago you heard so many podcast ads for Casper, Purple, and the like. When product 17 and product 130 are identical, then the only way to win is to get buyers more familiar with product 17. But <strong>when competition meets a narrow dimension of competition, profits evaporate</strong>—companies bid up marketing prices to the highest that they can endure. It became a game of chicken—how much are <em>you </em>willing to spend to acquire a customer? The best-funded startups “won” this branding battle.</p><p>But this was a short-lived victory. <strong>The ultimate result: perpetually unprofitable businesses</strong>, with <a href="https://www.marketwatch.com/investing/stock/cspr/financials" target="_blank">companies spending most of their revenue on COGS and user acquisition</a>. Casper now has a market value of just $350 million, down from its peak private valuation of $1.1 billion.&nbsp;</p><p>Meanwhile, the real beneficiaries of all this funding are:&nbsp;</p><p>1) the companies selling shovels in the gold rush, including mattress manufacturers and marketing platforms (particularly Google and Facebook)</p><p>2) customers, who enjoyed rock-bottom mattress prices subsidized by venture capital.</p><p>This situation played out in meal kit companies too, and one could argue the same is true of Uber vs Lyft and the food delivery war going on now.</p><h2><span id="Can_You_Differentiate_Yourself_with_GPT-3"><strong>Can You Differentiate Yourself with GPT-3?</strong></span></h2><p>Because GPT-3 works so well out of the box, I see this playing out a similar way. To start a new AI company, you need only cobble together a few components:</p><ul><li>A product built on GPT-3’s (very easy to use) API</li><li>A website</li><li>A marketing campaign</li></ul><p>As we see with Twitter demos, the products you can make off the shelf will frankly be pretty good.</p><p>Unfortunately, most of the products built on GPT-3 will be identical to each other, and few will have a meaningful edge. We’ll dive more into this next.</p><h3><strong>Differentiated Technology</strong></h3><p><strong>To win a market with technology, your product needs to be <em>obviously</em> better to the user.</strong> When Google first came out, it delivered such better search results than other engines—possibly by a subjective factor of 10 or more—that there was little reason to use any competitor. When Dropbox first came out, its syncing and ease of use was unbeatable. Right now SpaceX has a rocket that can do what no other company’s can, at an unbeatable price. These companies have real technology moats.</p><p>In contrast, if an industry has products that are are more or less identical—like online mattresses—the grounds of competition shift elsewhere other than product (like marketing and distribution), and there is no technology moat.</p><p>So imagine: If 100 companies build an AI therapy bot with GPT-3, how different will their user experiences be? How far ahead will company #1 be above company #2, and then over company #10? <strong>Will there be a 10x difference? Or more like a 5% difference?</strong></p><p>I argue: <strong>The better GPT-3 works out of the box, the harder it will be for any single company to build meaningful differentiation.</strong> Frankly, <a href="https://twitter.com/nicklovescode/status/1283326066338062337" target="_blank">early demos already look very good</a>.</p><figure><div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I thought you made a good point so I did another run being as depressive as I could. I sampled most “John” lines only once, I think I ran one twice. I’m really impressed</p><p>The prefix makes a difference but that could be automatically prepended by an end-user therapy app <a href="https://t.co/YZmQL9EXqW" target="_blank">pic.twitter.com/YZmQL9EXqW</a></p></div>— Nick Cammarata (@nicklovescode) <a href="https://twitter.com/nicklovescode/status/1283326066338062337?ref_src=twsrc%5Etfw" target="_blank">July 15, 2020</a></blockquote> </div></figure><p>Imagine how much better it can get with just a <em>little</em> more work—a modicum of fine tuning on therapy conversations and user safeguards. This is the new baseline, the “table stakes” for any new entrant, which is going to be relatively easy to achieve.</p><p>And then from this baseline, how much better could any one company get?</p><p>Here’s one way to think about it. The pinnacle of AI therapy would be a bot that rivals the <em>best</em> human therapist. Call this the 100% experience. The <em>average</em> human therapist might be somewhere at the 85% bar. And then a human user might be willing to tolerate a “good enough” AI performing at 70%—it’s clearly worse than a human therapist, but usable enough that it can keep up a coherent conversation and remembers that you were bullied in 5th grade.</p><figure><img src="https://lh6.googleusercontent.com/d-9mr1Bo8EgQaIlWnKd4EQuSrjjJuoBmjOkpcbPwJ0h9xnyIGz832tT133eTopDQZQWr2pXAJ-lS9mhaP9KBInUCnGtSqJKAtdZV-acn55hQ25c-p7bwdHgjyl-zFJ54I9Hg4aVX" alt=""></figure><p><strong>Before GPT-3, building anything </strong><strong><em>close</em></strong><strong> to the Good Enough AI was really hard.</strong> A company would have needed to invest many millions into its own algorithms and data cleanup to get anywhere close to the human user bar.&nbsp;</p><p>In this environment, the leading company had a few advantages:</p><ul><li>The barrier to entry was high, so it faced less competition.</li><li>The spread between the #1 and #3 companies was high, meaning the leading company had a sizable moat.</li><li>It still had a lot of room to grow to get to 85%+ level—this is room in which it could carve out a meaningful edge over competition.</li><li>It owned its own technology, so it could iterate to continuously improve its experience.</li></ul><p>Here’s how the landscape might have looked:</p><figure><img src="https://lh3.googleusercontent.com/Fz675xiZWljHeS4HWUGNcrO8qbaLtjJ9zfqJNCa2HhthN84Nt7JCQpMMhC4SzO9dWfSkGpWxOwIkaz745S-XJijAd91g0JDS2A7nDXrv6ku2fckVbW5kCl-UEyZci3tRgrb4aNwl" alt=""></figure><p>(In practice, I don’t know of any <a href="https://www.healthline.com/health/mental-health/chatbots-reviews#7" target="_blank">pre-GPT-3 AI therapy bot</a> that comes anywhere close to a human therapist. So competitive lead notwithstanding, I don’t think there have been any good AI therapy businesses to date.)</p><p>Then comes GPT-3. <strong>Now <em>anyone</em> can produce a “good enough AI therapy bot,”</strong> with a modicum of fine-tuning and UX design. This outcome wouldn’t be shocking—people were producing <a href="https://twitter.com/nicklovescode/status/1283326066338062337" target="_blank">plausible demos</a> within days of accessing the private beta. Imagine what can be done with just a few weeks of work and $500,000 of investment.</p><p>The result: the range of competition narrows:</p><figure><img src="https://lh6.googleusercontent.com/BiYRcsL4EKmlGKyc5gFDCCkQ_79ijr-jBknzfVb2MVuPj-Rp-D56fLeNhVnV9F46I3tWmUgzJLfV_hh5Q-oOZuR531DWJwI11JKQWgRfFt0fDDDGybrQX7yuTvAGp0TDWmem8_K5" alt=""></figure><p>Compared to the previous situation:</p><ul><li>There are many more competitors who can offer a “good enough” product.</li><li>The range of competition is compressed into a narrower band. It becomes much harder for any single product to stand out from the median product, which is already quite good.</li><li>Because the companies don’t own the core technology behind GPT-3, their ability to improve beyond the baseline performance is limited. Yes, they can fine-tune GPT-3 with their proprietary data, but how much is this going to improve on the core algorithm, which <a href="https://venturebeat.com/2020/06/11/openai-launches-an-api-to-commercialize-its-research/" target="_blank">cost $12 million to train</a> on 40GB of Internet text? <strong>And won’t everyone else be fine-tuning like this too?</strong></li></ul><p>Again, this really gives credit to OpenAI for how well GPT-3 works—out of the gate, you can produce a pretty usable product. But for startups, this merely <em>raises the table stakes</em> instead of offering a competitive advantage, and it <strong>neutralizes the technology edge</strong> any single company can have over another. Great for OpenAI, not great for new startups.</p><p><strong>Then imagine how much worse this will get when GPT-4 comes out. And again with GPT-5. </strong>The minimum bar of quality will keep inching up inexorably, and the range of competition will be compressed further and further.</p><p>Plus, it’s likely that <strong>any proprietary progress you make on GPT-3 will be totally wiped out by GPT-4</strong>; the same way your tweaks on GPT-2 would have been wiped out by GPT-3.</p><p>We’ve talked about AI therapy here, but this argument extends easily to automated code generation, creative writing tools, chatbots, Q&amp;A services, games, and so on.</p><h3><strong>Other Avenues of Differentiation</strong></h3><p>Yes, the algorithm isn’t everything. Products can still differentiate with their user experience, product design, customer support, adding on human services, and so on.&nbsp;</p><p>But as far as AI companies typically go, this is not really the <em>hard</em> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/">https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/</a></em></p>]]>
            </description>
            <link>https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007929</guid>
            <pubDate>Fri, 31 Jul 2020 12:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clang patch makes Objective-C (objc_msgSend) twice as fast]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007916">thread link</a>) | @gelstudios
<br/>
July 31, 2020 | https://saagarjha.com/blog/2019/12/15/bypassing-objc-msgsend/ | <a href="https://web.archive.org/web/*/https://saagarjha.com/blog/2019/12/15/bypassing-objc-msgsend/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><header>
	
	<p><time>Sunday, December 15, 2019</time></p>
</header>
<section>
	<p>On its fastest path, <a href="https://developer.apple.com/documentation/objectivec/1456712-objc_msgsend"><code>objc_msgSend</code></a> can transfer execution to an <a href="https://developer.apple.com/documentation/objectivec/objective-c_runtime/imp"><code>IMP</code></a> in just over a dozen instructions:</p>

<div><div><pre><code><span>$</span><span> </span>otool <span>-tV</span> /usr/lib/libobjc.dylib <span>-p</span> _objc_msgSend | <span>head</span> <span>-n</span> 18
<span>/usr/lib/libobjc.dylib:
(__TEXT,__text) section
_objc_msgSend:
0000000000006e00	testq	%rdi, %rdi
0000000000006e03	je	0x6e78
</span><span>0000000000006e06	testb	$</span>0x1, %dil
<span>0000000000006e0a	jne	0x6e83
</span><span>0000000000006e0d	movabsq	$</span>_objc_absolute_packed_isa_class_mask, %r10
<span>0000000000006e17	andq	__objc_empty_vtable(%rdi), %r10
0000000000006e1a	movq	%rsi, %r11
0000000000006e1d	andl	0x18(%r10), %r11d
</span><span>0000000000006e21	shlq	$</span>0x4, %r11
<span>0000000000006e25	addq	0x10(%r10), %r11
0000000000006e29	cmpq	__objc_empty_vtable(%r11), %rsi
0000000000006e2c	jne	0x6e38
0000000000006e2e	movq	0x8(%r11), %r11
0000000000006e32	xorq	%r10, %r11
0000000000006e35	jmpq	*%r11
</span></code></pre></div></div>



<p>As one of the hottest, if not <em>the</em> hottest code paths on the system, it has good reason for being so optimized: even the most minimal savings here translate directly to measurable performance increases across all Objective-C applications. But even as fast as this implementation is, sometimes it’s just not good enough: Objective-C is a dynamic language, and its features come with a price even if you’re not using them. The majority of the code executed in a typical <code>objc_msgSend</code> call is not for implementation lookup: rather, it’s checks to see if execution can proceed on the fast path. But the checks are comparatively cheap: an even bigger issue is that the function largely serves as an optimization barrier to the compiler, to which it looks like nothing more than an impenetrable trampoline to an unknown target. As such, even the simplest member access cannot be inlined; every method call <em>must</em> clobber multiple registers and almost always requires a move out of the accumulator, where it is usually undesirable to leave the result.</p>

<p><a href="https://github.com/llvm/llvm-project/commit/d4e1ba3fa9dfec2613bdcc7db0b58dea490c56b1"><code>__attribute__((objc_direct))</code></a> (and the closely related <code>__attribute__((objc_direct_members))</code>) attempts to solve some of these problems by converting the method call into what’s essentially C-style static dispatch. The change was met with some controversy when it was introduced: calls would no longer go through the runtime machinery, breaking many features of Objective-C, including swizzling, KVO, and even subclassing. Luckily, there’s another way to get performance benefits without losing some of Objective-C’s best features.</p>

<h2 id="a-little-bit-of-idle-speculation">A little bit of idle speculation</h2>

<p>The key insight is that we can guess where the vast majority of method calls will go, and we can do so <em>at compile time</em> just by looking at the type of the receiver and message we’re sending to it. Most of the time, <code>objc_msgSend</code> is just confirming what we already know: the only practical difference between its fast path and a direct function call is that it needs to check, as quickly as possible, that its target is what it expects it to be before jumping there. There’s no way around this if we want to support Objective-C’s dynamism; any implementation we come up with will have to do this too. The advantage we have over <code>objc_msgSend</code> is that as humans (or as a compiler), we have static type information and an understanding of the surrounding code which lets us guess, statically and with high accuracy, what the target is. In fact, we can just <em>speculate</em> that the call will go to the predicted method, and, taking a leaf out of <code>objc_msgSend</code>’s book, wrap a direct call to it in the barest minimum of checking to make sure that we were correct in our prediction. In psuedocode, we can convert a call to <code>-[Foo bar]</code> (where the reciever is <code>foo</code>) to something like this:</p>

<div><div><pre><code>if (target is -[Foo bar]) {
	jump to -[Foo bar]
} else {
	objc_msgSend(foo, @selector(bar))
}
</code></pre></div></div>

<p>If we’re correct, not only does this skip the cache lookup that <code>objc_msgSend</code> performs, but it also makes a <em>direct</em> call to the method: one which the compiler knows about and can optimize around.</p>

<h2 id="jumping-to-an-implementation">Jumping to an implementation</h2>

<p>We’re almost done: the only question that’s left is what goes in the “target is <code>-[Foo bar]</code>” condition. As far as I can tell, if we have a <code>Foo *foo</code> and send <code>@selector(bar)</code> to it, the only cases where execution will not directly proceed to <code>-[Foo bar]</code> are if</p>

<ol>
  <li>the reciever is <code>nil</code>,</li>
  <li>the reciever is a subclass of <code>Foo</code>, or</li>
  <li><code>-[Foo bar]</code> has been swizzled.</li>
</ol>

<p>Checking for the first can be done easily; the second is a bit more complicated. In theory we’re asking <code>[foo isMemberOfClass:Foo.class]</code>, but for obvious reasons we don’t really want the overhead that comes with this. We can skip even a call to <a href="https://developer.apple.com/documentation/objectivec/1418629-object_getclass?language=objc"><code>object_getClass</code></a> by directly ripping the <code>isa</code> out of <code>foo</code> and comparing it against runtime metadata. There are some subtleties with <a href="http://www.sealiesoftware.com/blog/archive/2013/09/24/objc_explain_Non-pointer_isa.html">non-pointer <code>isa</code>s</a> and <a href="https://www.mikeash.com/pyblog/friday-qa-2012-07-27-lets-build-tagged-pointers.html">tagged pointers</a> but we can avoid them entirely by masking the <code>isa</code> appropriately and sending nonstandard cases to the slow path if we encounter them.</p>

<p>The last case, where the method has been swizzled, can’t be determined by the information available to <code>objc_msgSend</code> alone: instead, we need to keep around a side table of boolean values that we must check on each call. When a method is swizzled the runtime (or your code interposed in front of the runtime) must update the corresponding entry so subsequent calls will go through the runtime.</p>



<p>With all the checks in place, we can now call the method directly. To try this out, <a href="https://github.com/saagarjha/expresscall">I patched Clang</a> so that it would emit LLVM IR that performed the operations described above whenever it would have emitted a simple message send. I’ve never touched the LLVM project before, so my implementation is clumsy and probably incorrect; however, it works fine for the simple programs I tested it with and you can try it out yourself if compiling LLVM is your thing. Since I needed a name for the repository that wasn’t just “llvm-project”, I am henceforth naming this technique “expresscall”–as in “making an expresscall”. “swiftcall” would have been shorter, but with significantly more potential to be confusing.</p>



<h2 id="are-we-fast-yet">Are we fast yet?</h2>

<p>There’s no better way to see how fast (or slow) an optimization is than a highly synthetic benchmark. This one creates a simple Objective-C array type for integers, fills it with random numbers, and sums them. Since I’m a horrible person, you get to scroll past it:</p>

<div><div><pre><code><span>@import</span> <span>Foundation</span><span>;</span>
<span>@import</span> <span>ObjectiveC</span><span>;</span>
<span>#import &lt;algorithm&gt;
#import &lt;array&gt;
#import &lt;chrono&gt;
#import &lt;dlfcn.h&gt;
#import &lt;iostream&gt;
#import &lt;random&gt;
#import &lt;type_traits&gt;
#import &lt;unordered_map&gt;
#import &lt;utility&gt;
</span>
<span>const</span> <span>auto</span> <span>benchmark_size</span> <span>=</span> <span>1000000</span><span>;</span>
<span>const</span> <span>auto</span> <span>trials</span> <span>=</span> <span>100</span><span>;</span>

<span>@interface</span> <span>IntegerArray</span> <span>:</span> <span>NSObject</span>
<span>-</span> <span>(</span><span>instancetype</span><span>)</span><span>initWithNumbers</span><span>:(</span><span>NSUInteger</span> <span>*</span><span>)</span><span>numbers</span> <span>count</span><span>:(</span><span>NSUInteger</span><span>)</span><span>count</span><span>;</span>
<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>count</span><span>;</span>
<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>numberAtIndex</span><span>:(</span><span>NSUInteger</span><span>)</span><span>index</span><span>;</span>
<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>direct_count</span> <span>__attribute__</span><span>((</span><span>objc_direct</span><span>));</span>
<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>direct_numberAtIndex</span><span>:(</span><span>NSUInteger</span><span>)</span><span>index</span> <span>__attribute__</span><span>((</span><span>objc_direct</span><span>));</span>
<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>swizzled_count</span><span>;</span>
<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>swizzled_numberAtIndex</span><span>:(</span><span>NSUInteger</span><span>)</span><span>index</span><span>;</span>
<span>@end</span>

<span>@implementation</span> <span>IntegerArray</span> <span>{</span>
	<span>NSUInteger</span> <span>*</span><span>_numbers</span><span>;</span>
	<span>NSUInteger</span> <span>_count</span><span>;</span>
<span>}</span>

<span>-</span> <span>(</span><span>instancetype</span><span>)</span><span>initWithNumbers</span><span>:(</span><span>NSUInteger</span> <span>*</span><span>)</span><span>numbers</span> <span>count</span><span>:(</span><span>NSUInteger</span><span>)</span><span>count</span> <span>{</span>
	<span>if</span> <span>(</span><span>self</span> <span>=</span> <span>[</span><span>super</span> <span>init</span><span>])</span> <span>{</span>
		<span>_numbers</span> <span>=</span> <span>numbers</span><span>;</span>
		<span>_count</span> <span>=</span> <span>count</span><span>;</span>
	<span>}</span>
	<span>return</span> <span>self</span><span>;</span>
<span>}</span>

<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>count</span> <span>{</span>
	<span>return</span> <span>_count</span><span>;</span>
<span>}</span>

<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>numberAtIndex</span><span>:(</span><span>NSUInteger</span><span>)</span><span>index</span> <span>{</span>
	<span>return</span> <span>_numbers</span><span>[</span><span>index</span><span>];</span>
<span>}</span>

<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>direct_count</span> <span>{</span>
	<span>return</span> <span>_count</span><span>;</span>
<span>}</span>

<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>direct_numberAtIndex</span><span>:(</span><span>NSUInteger</span><span>)</span><span>index</span> <span>{</span>
	<span>return</span> <span>_numbers</span><span>[</span><span>index</span><span>];</span>
<span>}</span>

<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>swizzled_count</span> <span>{</span>
	<span>return</span> <span>0</span><span>;</span>
<span>}</span>

<span>-</span> <span>(</span><span>NSUInteger</span><span>)</span><span>swizzled_numberAtIndex</span><span>:(</span><span>NSUInteger</span><span>)</span><span>index</span> <span>{</span>
	<span>return</span> <span>index</span><span>;</span>
<span>}</span>
<span>@end</span>

<span>enum</span> <span>Benchmark</span> <span>{</span>
	<span>expresscall</span> <span>=</span> <span>0</span><span>,</span>
	<span>message_send</span><span>,</span>
	<span>direct</span><span>,</span>
	<span>swizzled_expresscall</span><span>,</span>
	<span>swizzled_message_send</span><span>,</span>
	<span>_end</span>
<span>};</span>

<span>auto</span> <span>measure</span><span>(</span><span>Benchmark</span> <span>benchmark</span><span>,</span> <span>std</span><span>::</span><span>mt19937</span> <span>&amp;</span><span>generator</span><span>)</span> <span>{</span>
	<span>std</span><span>::</span><span>array</span><span>&lt;</span><span>NSUInteger</span><span>,</span> <span>benchmark_size</span><span>&gt;</span> <span>numbers</span><span>;</span>
	<span>std</span><span>::</span><span>uniform_int_distribution</span><span>&lt;</span><span>NSUInteger</span><span>&gt;</span> <span>distribution</span><span>(</span><span>0</span><span>,</span> <span>NSUIntegerMax</span> <span>/</span> <span>benchmark_size</span><span>);</span>
	<span>std</span><span>::</span><span>generate</span><span>(</span><span>numbers</span><span>.</span><span>begin</span><span>(),</span> <span>numbers</span><span>.</span><span>end</span><span>(),</span> <span>[</span><span>&amp;</span><span>]()</span> <span>{</span>
		<span>return</span> <span>distribution</span><span>(</span><span>generator</span><span>);</span>
	<span>});</span>
	<span>IntegerArray</span> <span>*</span><span>array</span> <span>=</span> <span>[[</span><span>IntegerArray</span> <span>alloc</span><span>]</span> <span>initWithNumbers</span><span>:</span><span>numbers</span><span>.</span><span>data</span><span>()</span> <span>count</span><span>:</span><span>numbers</span><span>.</span><span>size</span><span>()];</span>
	<span>NSUInteger</span> <span>sum</span> <span>=</span> <span>0</span><span>;</span>
	<span>auto</span> <span>time</span> <span>=</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>system_clock</span><span>::</span><span>now</span><span>();</span>
	<span>switch</span> <span>(</span><span>benchmark</span><span>)</span> <span>{</span>
	<span>case</span> <span>Benchmark</span><span>:</span><span>:</span><span>expresscall</span><span>:</span>
		<span>for</span> <span>(</span><span>NSUInteger</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>array</span><span>.</span><span>count</span><span>;</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
			<span>sum</span> <span>+=</span> <span>[</span><span>array</span> <span>numberAtIndex</span><span>:</span><span>i</span><span>];</span>
		<span>}</span>
		<span>break</span><span>;</span>
	<span>case</span> <span>Benchmark</span><span>:</span><span>:</span><span>message_send</span><span>:</span>
		<span>for</span> <span>(</span><span>NSUInteger</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>reinterpret_cast</span><span>&lt;</span><span>NSUInteger</span> <span>(</span><span>*</span><span>)(</span><span>IntegerArray</span> <span>*</span><span>,</span> <span>SEL</span><span>)</span><span>&gt;</span><span>(</span><span>objc_msgSend</span><span>)(</span><span>array</span><span>,</span> <span>@selector</span><span>(</span><span>count</span><span>));</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
			<span>sum</span> <span>+=</span> <span>reinterpret_cast</span><span>&lt;</span><span>NSUInteger</span> <span>(</span><span>*</span><span>)(</span><span>IntegerArray</span> <span>*</span><span>,</span> <span>SEL</span><span>,</span> <span>NSUInteger</span><span>)</span><span>&gt;</span><span>(</span><span>objc_msgSend</span><span>)(</span><span>array</span><span>,</span> <span>@selector</span><span>(</span><span>numberAtIndex</span><span>:</span><span>),</span> <span>i</span><span>);</span>
		<span>}</span>
		<span>break</span><span>;</span>
	<span>case</span> <span>Benchmark</span><span>:</span><span>:</span><span>direct</span><span>:</span>
		<span>for</span> <span>(</span><span>NSUInteger</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>array</span><span>.</span><span>direct_count</span><span>;</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
			<span>sum</span> <span>+=</span> <span>[</span><span>array</span> <span>direct_numberAtIndex</span><span>:</span><span>i</span><span>];</span>
		<span>}</span>
		<span>break</span><span>;</span>
	<span>case</span> <span>Benchmark</span><span>:</span><span>:</span><span>swizzled_expresscall</span><span>:</span>
		<span>for</span> <span>(</span><span>NSUInteger</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>array</span><span>.</span><span>swizzled_count</span><span>;</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
			<span>sum</span> <span>+=</span> <span>[</span><span>array</span> <span>swizzled_numberAtIndex</span><span>:</span><span>i</span><span>];</span>
		<span>}</span>
		<span>break</span><span>;</span>
	<span>case</span> <span>Benchmark</span><span>:</span><span>:</span><span>swizzled_message_send</span><span>:</span>
		<span>for</span> <span>(</span><span>NSUInteger</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>reinterpret_cast</span><span>&lt;</span><span>NSUInteger</span> <span>(</span><span>*</span><span>)(</span><span>IntegerArray</span> <span>*</span><span>,</span> <span>SEL</span><span>)</span><span>&gt;</span><span>(</span><span>objc_msgSend</span><span>)(</span><span>array</span><span>,</span> <span>@selector</span><span>(</span><span>swizzled_count</span><span>));</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
			<span>sum</span> <span>+=</span> <span>reinterpret_cast</span><span>&lt;</span><span>NSUInteger</span> <span>(</span><span>*</span><span>)(</span><span>IntegerArray</span> <span>*</span><span>,</span> <span>SEL</span><span>,</span> <span>NSUInteger</span><span>)</span><span>&gt;</span><span>(</span><span>objc_msgSend</span><span>)(</span><span>array</span><span>,</span> <span>@selector</span><span>(</span><span>swizzled_numberAtIndex</span><span>:</span><span>),</span> <span>i</span><span>);</span>
		<span>}</span>
		<span>break</span><span>;</span>
	<span>default:</span>
		<span>assert</span><span>(</span><span>false</span><span>);</span>
	<span>}</span>
	<span>// Make sure the program actually does the calculation by returning the sum</span>
	<span>return</span> <span>std</span><span>::</span><span>make_pair</span><span>(</span><span>std</span><span>::</span><span>chrono</span><span>::</span><span>duration_cast</span><span>&lt;</span><span>std</span><span>::</span><span>chrono</span><span>::</span><span>microseconds</span><span>&gt;</span><span>(</span><span>std</span><span>::</span><span>chrono</span><span>::</span><span>system_clock</span><span>::</span><span>now</span><span>()</span> <span>-</span> <span>time</span><span>),</span> <span>sum</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
	<span>// Swizzle the dummy methods to point at actual implementations</span>
	<span>auto</span> <span>IntegerArray_count</span> <span>=</span> <span>class_getInstanceMethod</span><span>(</span><span>IntegerArray</span><span>.</span><span>class</span><span>,</span> <span>@selector</span><span>(</span><span>count</span><span>));</span>
	<span>class_replaceMethod</span><span>(</span><span>IntegerArray</span><span>.</span><span>class</span><span>,</span> <span>@selector</span><span>(</span><span>swizzled_count</span><span>),</span> <span>method_getImplementation</span><span>(</span><span>IntegerArray_count</span><span>),</span> <span>method_getTypeEncoding</span><span>(</span><span>IntegerArray_count</span><span>));</span>
	<span>*</span><span>static_cast</span><span>&lt;</span><span>bool</span> <span>*&gt;</span><span>(</span><span>dlsym</span><span>(</span><span>dlopen</span><span>(</span><span>NULL</span><span>,</span> <span>RTLD_LAZY</span><span>),</span> <span>"OBJC_EXPRESSCALL____IntegerArray_swizzled_count_"</span><span>))</span> <span>=</span> <span>true</span><span>;</span>
	<span>auto</span> <span>IntegerArray_numberAtIndex_</span> <span>=</span> <span>class_getInstanceMethod</span><span>(</span><span>IntegerArray</span><span>.</span><span>class</span><span>,</span> <span>@selector</span><span>(</span><span>numberAtIndex</span><span>:</span><span>));</span>
	<span>class_replaceMethod</span><span>(</span><span>IntegerArray</span><span>.</span><span>class</span>…</code></pre></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://saagarjha.com/blog/2019/12/15/bypassing-objc-msgsend/">https://saagarjha.com/blog/2019/12/15/bypassing-objc-msgsend/</a></em></p>]]>
            </description>
            <link>https://saagarjha.com/blog/2019/12/15/bypassing-objc-msgsend/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007916</guid>
            <pubDate>Fri, 31 Jul 2020 12:17:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retailers are promoting unscientific anti-cash propaganda. Banks are loving it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007827">thread link</a>) | @Gigamouse
<br/>
July 31, 2020 | https://alteredstatesof.money/retailers-not-accepting-cash-is-unscientific/ | <a href="https://web.archive.org/web/*/https://alteredstatesof.money/retailers-not-accepting-cash-is-unscientific/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://alteredstatesof.money/content/images/size/w300/2020/07/The-War-on-Cash.png 300w,
                            https://alteredstatesof.money/content/images/size/w600/2020/07/The-War-on-Cash.png 600w,
                            https://alteredstatesof.money/content/images/size/w1000/2020/07/The-War-on-Cash.png 1000w,
                            https://alteredstatesof.money/content/images/size/w2000/2020/07/The-War-on-Cash.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://alteredstatesof.money/content/images/size/w2000/2020/07/The-War-on-Cash.png" alt="Supermarkets are promoting unscientific anti-cash propaganda. And the banking sector is loving it">
            </figure>

            <section>
                <div>
                    <p>(Cover Image: <a href="https://www.garrettworld.co.uk/">Scott Garrett</a>)</p><p>In early March 2020, the World Health Organisation emailed a journalist to say ‘We did NOT say that cash was transmitting coronavirus’. This <a href="https://www.marketwatch.com/story/who-we-did-not-say-that-cash-was-transmitting-coronavirus-2020-03-06">angry rebuttal</a> came after the British Telegraph newspaper misrepresented them as being anti-cash. Days later the head of Germany's Robert Koch Institute for infectious diseases said “<a href="https://www.reuters.com/article/us-health-coronavirus-germany-banknotes/banknotes-carry-no-particular-coronavirus-risk-german-disease-expert-idUSKBN20Y2ZT">(Virus) transmission through banknotes has no particular significance</a>”. He was followed by the German central bank, who put out a release saying ‘<a href="https://www.bundesbank.de/en/tasks/topics/cash-poses-no-particular-risk-of-infection-for-public-828762">Cash poses no particular risk of infection for public</a>’, noting that “the probability of becoming ill from handling cash is smaller than from many other objects used in everyday life”. They were <a href="https://www.bis.org/publ/bisbull03.htm">followed in April</a> by the Bank for International Settlements (BIS), who noted that “Scientific evidence suggests that the probability of transmission via banknotes is low when compared with other frequently-touched objects, such as credit card terminals or PIN pads”.</p><p>Why then, am I confronted by signs like these?</p><figure><img src="https://alteredstatesof.money/content/images/2020/07/image.png" alt="" srcset="https://alteredstatesof.money/content/images/size/w600/2020/07/image.png 600w, https://alteredstatesof.money/content/images/size/w1000/2020/07/image.png 1000w, https://alteredstatesof.money/content/images/2020/07/image.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>Decathlon, where I took this photo, is a large sports chain store where people frequently make purchases over the contactless card limit (buying medium value items like running shoes, tennis raquets, and so on), which means they are telling people that pressing PIN pads (used by hundreds of others) is for their ‘protection’.</p><p>They are not alone. Almost every large supermarket chain in the UK is doing this. When I’m in Morrison’s – a large UK supermarket chain – I am asked to pay by card over a loudspeaker: the unscientific consensus in all these major stores is – <em>cash is dangerous</em>. <em>More dangerous than using card terminals or pushing the buttons on the screen of our self-service checkout counters that thousands of others have used.</em></p><div><p>Perhaps the concern is not so much for customers as for staff, who might have to handle cash handed to them by hundreds of people. Let’s be real though. Their check-out staff are handling thousands of items handed to them by hundreds of people who take them off the shelves. It’s not like cash is uniquely risky for their staff in this situation.</p><p>This practice in supermarkets is extremely worrying. During the early days of strict lock-down, they were among the only institutions allowed to stay open. The entire population of the UK would scurry out of their homes to nervously enter these stores, all of which decided to start broadcasting anti-cash messages to these anxious customers, despite the fact that major institutions like the WHO and BIS rejected the claim.</p></div><!--kg-card-begin: html--><!-- Begin Mailchimp Signup Form -->




<!--End mc_embed_signup--><!--kg-card-end: html--><h3 id="the-war-on-cash">The War on Cash</h3><p>At best this anti-cash stance is well-meaning but misguided and irresponsible. At worst it's a push to force people to use digital payments for profit-seeking reasons, disguised as a concern for public health. For the last several years I have been investigating the ‘<a href="https://alteredstatesof.money/cash-and-covid/">war on cash</a>’: banks and payments companies – who run the underlying digital payments infrastructure – have a huge interest in seeing the demise of the cash system and have actively tried to nudge society away from cash, constantly telling us to ‘prepare’ for an ‘inevitable’ end of cash whilst eroding the cash infrastructure to make it harder to use, and while publishing sob-stories about the need to ‘save’ those who will be ‘left behind’ by this imagined inevitable trajectory that they engineer.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/oZ4tfrr1Z8M?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>I made a YouTube video on this topic as well</figcaption></figure><p>While the banking sector and fintech industry clearly have a commercial agenda in demonising cash, many chain stores do too. Over the years they have tried to automate as much as possible. They invest in self-service checkout systems as a way to automate away their staff, and digital payments is how you automate the money section of a transaction. Big tech firms like Amazon have made no secret out of how they hate non-automated offline payment - they tried to <a href="https://www.inquirer.com/news/amazon-go-cashless-store-philadelphia-lobbying-20190226.html">stop pro-cash laws in US cities</a> that would require shops to accept cash - but big supermarkets also prefer to deal with banking giants than to handle physical cash.</p><p>Thus, when big chain stores suddenly start asking people to turn away from cash because of ‘safety’ reasons, we should be suspicious of whether they are – in fact – pushing the broader war on cash that has already been occurring for a long time. Every announcement that says ‘please use cards or contactless’ is them saying <em>‘please step into the arms of the banking sector’</em>. They are thus acting as huge funnels pushing people into deeper dependence on an unstable and often predatory banking system, using a marginal unproven risk as their justification, and whilst neglecting to mention all the risks that come with destroying the cash system.</p><h3 id="overkilling-cash"><br>Overkilling cash</h3><p>Consider this metaphor. When walking down a city street it is possible that a branch can fall off a beautiful oak tree and kill you, but imagine if – in response to such a death – the city authorities ordered all trees to be cut down. It may be true that they have dealt with the marginal risk of trees killing people in future, but only at the expense of severely harming the overall mental health of millions of city inhabitants (as well as destroying a source of pollution absorption).</p><p>There's a very similar thing happening right now with this cash system. Fine, cash might pose a small risk of carrying infection, along with many other things (like the cooking oil I pick up off the shelf), but the risks that come with destroying the cash system are as high, if not much higher. </p><p>The anti-cash brigade don't mention all the dangerous forms of authoritarian surveillance that accompany the end of cash. They don't mention the extreme exclusion risks, or the fact that the financial system becomes far less resilient to disasters and crises if the cash system is undermined. They do not mention that pushing people away from cash increases the concentration of power in the banking sector, which but 10 years ago was being vilified as a major source of economic crises (which <em>causes </em>destitution). </p><p>It is not ‘responsible’ to promote the end of cash, and it is not responsible to promote digital payment as if it came with no risks itself (the <a href="https://www.ft.com/video/37cb70e6-72df-471e-943d-2d32c2785650">Wirecard scandal</a> should alert us to the fact that these digital payments companies are no angels). It is outrageous that the banking sector is being promoted as something that will save us from coronavirus, and it's even more outrageous that the big retailers are pushing the banks' monetary competitor - cash - ever closer to the point of demise on the basis of fake news.</p><h3 id="the-shock-doctrine-of-automation">The Shock doctrine of Automation</h3><p>The only parties that unambiguously gain from the demise of cash are the banking sector and payments companies like Visa and Mastercard. This is why we must draw on Naomi Klein’s concept of the <a href="https://en.wikipedia.org/wiki/The_Shock_Doctrine">‘shock doctrine’ and 'disaster capitalism'</a> to explain this: when we are in situations of crises we are open to being pushed into increased dependence on powerful actors who will use the heightened social anxiety to present themselves as saviours and push forward new policies and products that will extend and entrench their dominance. Think about that next time a supermarket tells you to not use cash. They present themselves as being concerned for us, but it's extremely irresponsible for them to ask us to become increasingly dependent on a banking sector that hasn't ever shown us that has our best interests at heart. Using cash in this scenario is an act of defiance.</p><h2 id="want-to-comment-on-this-article">Want to comment on this article?</h2><p>I'd love to have a comments section, but it currently takes too much work to stop spammers from posting dodgy links in the comments. If you'd like to ask a question or post a comment to me feel free to hit me up on Twitter <a href="https://twitter.com/Suitpossum">@suitpossum</a> and I'll do my best to respond. Cheers!</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://alteredstatesof.money/retailers-not-accepting-cash-is-unscientific/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007827</guid>
            <pubDate>Fri, 31 Jul 2020 12:03:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Git as a Logbook to Improve Efficiency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007802">thread link</a>) | @svdo
<br/>
July 31, 2020 | https://unfolded.dev/posts/2020-07-21-using-git-more-effectively/ | <a href="https://web.archive.org/web/*/https://unfolded.dev/posts/2020-07-21-using-git-more-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <h2>Contents</h2>
    <ol><li><a href="#a-creative-pursuit">A Creative Pursuit</a></li><li><a href="#not-a-unique-problem">Not A Unique Problem</a></li><li><a href="#a-logbook-on-steroids">A Logbook On Steroids</a></li><ol><li><a href="#target-audience">Target Audience</a></li><li><a href="#tell-a-story">Tell A Story</a></li><li><a href="#record-frequently">Record Frequently</a></li><li><a href="#rewrite">Rewrite</a></li><li><a href="#record-failures">Record Failures</a></li></ol><li><a href="#when-to-use-it">When To Use It</a></li><li><a href="#comments"></a><a href="https://github.com/svdo/unfolded.dev/issues/1">Comments</a></li></ol>
    
    <p><em>In my daily work, I have the good fortune to work with many very talented
people. Some are professional software developers, like myself. Others are for
example researchers, scientist, project leaders, and so on. Is that you? Do you
also write software, but not as your main activity? Do you have some experience
but maybe no formal training? In <a href="https://unfolded.dev/pages/software-development-easy-to-learn-hard-to-master/">this series of blog
posts</a> I will explain
the best practices that I use, so that you may be able to benefit from them. So
that writing software hopefully takes you less effort and gives you more
pleasure.</em></p><h2 id="a-creative-pursuit">A Creative Pursuit</h2><p>A decade or so ago, I had the good fortune to work with a group of extremely
smart scientists. Without going into details, their job was to conceive
algorithms for image processing, and improve them. They had huge volumes of
data, and the ability to create more. The algorithms had to be robust in the
face of all kinds of variations in that data. Much like software development,
their work was <a href="https://iism.org/article/why-are-ceos-failing-software-engineers-56">a creative pursuit</a>.</p><p>They would have regular meetings to discuss progress, results and challenges. In
those meetings, I remember being surprised now and then. For example, you might
hear a conversation like this<sup id="fnref-1"><a href="#fn-1">1</a></sup>:</p><blockquote><p><strong>Betty</strong>: Say, John, didn't you have some progress on «some algorithm
feature» a few weeks ago? I'm running into some issues and I think your
findings may help me here.</p><p><strong>John</strong>: Yeah, that's right, I remember having some results when I was
working on «something else». I'm not sure which algorithm variant
I used exactly though, or which test data for that matter. If it's important
to you, we can sit together and see if we can reproduce that.</p></blockquote><p>While this was commendable in terms of team spirit, I always felt it wasteful
that apparently things had not been tracked and documented in such a way that it
was easy to recover what people had tried and done.</p><p>🤔</p><h2 id="not-a-unique-problem">Not A Unique Problem</h2><p>It turns out that software development is not that different from research in
the sense that they are both creative pursuits. Also software development
requires a good amount of trial-and-error, backtracking, rethinking, trying
again, going back to something that wasn't so stupid after all. The difference
is that we, software developers, are lazy to the point that we try to automate
just about anything that we can. So we use tools. And yes, nowadays probably
everybody understands that I'm going to say "git" (or "mercurial" or something
similar)<sup id="fnref-2"><a href="#fn-2">2</a></sup>. So I'm not going to explain what git is here. Plenty of
good resources out there on that topic. No, I'm going to tell you a bit about
how I use it.</p><p>🛠</p><h2 id="a-logbook-on-steroids">A Logbook On Steroids</h2><p>My version control system (e.g. git) is like a logbook. I use it to record
relevant things about my work that are not part of the code itself. For example,
in a commit message I type the reason why I'm doing things a certain way. Or I
might record that I tried something but it failed. Let's go into some details to
better explain.</p><h3 id="target-audience">Target Audience</h3><p>For any kind of writing, an important question is: who is your target audience?
Whether it's a blog post like this one, a scientific paper, a conference talk,
you always ask yourself: for whom am I writing this? For version control, the
answer is:</p><ol><li>My future self. Much like the researchers in the example above, I cannot hold
everything in my head. I forget details, I forget why I tried certain things,
I forget why other things failed. By documenting them, I can remind myself
when I need to in the near or not-so-near future.</li><li>My team. Even though I very much like pair programming, and I hope one day to
be part of a team that wants to do <a href="https://040code.github.io/2019/03/15/mob-programming">mob programming</a>, in
reality I cannot share all relevant details with the rest of my team all the
time. By documenting them, I allow my team mates to step into my shoes and
follow my reasoning.</li><li>Successors or other people who may have to work on the code when I'm not
around. Even though the average "best before" date of software is a fair
bit closer than people prefer to believe, it still happens that I write code
that others need to continue working on when I'm not available, for example
because I'm in a different department or working for a different employer.
Again, by documenting things I try to enable them to decide what pieces are
important to them and which are not.</li></ol><h3 id="tell-a-story">Tell A Story</h3><p>Well, maybe that's a bit overdoing it. My kids are going to be bored out of
their socks by these stories. But still, I do try to commit in such a way that
the sequence of all commit messages can be understood by others. They say more
than the individual commits in isolation, because the succession of commits
allows you to distill my reasoning, from where to where I'm going.</p><h3 id="record-frequently">Record Frequently</h3><p>This requires to commit frequently. "Oh but I do! I commit at least every day
before I leave the office! And sometimes even more!", you say? Well, we're
thinking of a different order of magnitude then. When I'm "<a href="https://en.wikipedia.org/wiki/Flow_(psychology)">in flow</a>" I
commit <em>many times every hour</em>. Every few minutes when I'm really on a roll. No,
of course not always. When I'm grinding on a hard problem I may have nothing to
commit for a few hours. That's ok, but it should be exceptional, not the norm.</p><p>Committing frequently also means that I make separate commits when reasonably
possible. For example, as I'm writing this blog post, I'm making a few changes
to the CSS style sheet. I could commit those as part of the blog post, or as a
separate commit. Instead, I chose to create
<a href="https://github.com/svdo/unfolded.dev/commit/3fec2de430168ad50cbdee7144b5f5f827321be4">three</a> <a href="https://github.com/svdo/unfolded.dev/commit/63c1a75a857b8c6075c9d8302535309b1857ec37">separate</a> <a href="https://github.com/svdo/unfolded.dev/commit/9fb7189a19b5d1b0f53113996d9a95259395b193">commits</a> because each
makes sense on its own, without the other two. This way I can later revert any
of the three changes by simply reverting the corresponding commit. Of course
some people find this rather extreme<sup id="fnref-3"><a href="#fn-3">3</a></sup>, and that's fine. YMMV.</p><h3 id="rewrite">Rewrite</h3><p>And like any good story, this one also needs to be polished and rewritten to be
as good as it can be. I do that all the time. When I'm working on a feature, I
may for example have ten commits that form a logical whole. Then I notice
that there was a change that should have been part of one of those commits, but
I overlooked it at that time. So I make a new commit with that single thing that
I forgot, I move that new "fixup" commit to the commit where it belongs, and I
combine the two. I look at the commit messages and edit them if needed.
I reorder commits. And then, when I'm satisfied, only then I push my commits to
the remote, so that others will only see the polished version of my story.
Obviously having a great git client tremendously helps with this. I can't
recommend anything specific on Linux or Windows, but on macOS <a href="https://gitup.co/">GitUp</a> is
extraordinary in this regard: hitting "d" moves a commit down, hitting "f" does
a fixup (combine it with the commit before it), "e" edits the commit message. I
don't know of another git client that can do this so easily.</p><h3 id="record-failures">Record Failures</h3><p>One final thing to note here: don't hesitate to also record failures. Most of
the time there is more to be learned from failures than from successes. So when
rewriting my commits before pushing, I may either delete a few commits that were
failures, but sometimes I actually decide to leave them there and explain (in
the commit messages) why. Same for "reverse commit". I try something that
doesn't work but is already committed. I may then delete that last commit before
pushing, but I can also "reverse commit" it. Again, so that it may be clear that
I tried something and that it failed, so that others don't have to try
themselves as well.</p><p>📔</p><h2 id="when-to-use-it">When To Use It</h2><p>In closing, I want to say a few words about <em>when</em> I use a version control
system. The answer may surprise you, because it is: "almost always". Yesterday
and today, I was trying out a few different crypto libraries for some finite
field arithmetic that I needed to do. So I created a few small projects to
quickly try a few libraries. And for each of those, I created a git repo. Just
on my own computer, mind you. Unless I end up creating a spike that I think has
value to others, I won't create a remote for these repos. But just typing <code>git init</code> after creating a new project doesn't cost me anything. When I don't need
it anymore, I remove the project, and the embedded <code>.git</code> folder with the
history is automatically deleted as well. So why not?</p><p>Like Woody Zuill says it: "turn up the good!" If using a version control system
like git is good, turn it up. Use it more than you used to, and then more still,
and see what happens. If committing to git is good, turn it up. Commit more
frequently, and then more frequently still. Maybe you'll be surprised. I hope it
will bring you the satisfaction it has given me!</p><p>🤠</p><p>Since this is a privacy-friendly static web site, I'm not including the ability
to post comments directly here. I do love feedback though, so I created a ticket
on GitHub that you can use to leave your comments. Tell me if it's bad, tell me
if it's good, but please don't forget to tell me <em>why</em>. So please head over
there and <a href="https://github.com/svdo/unfolded.dev/issues/1">leave your comments</a>!</p>
</div></div>]]>
            </description>
            <link>https://unfolded.dev/posts/2020-07-21-using-git-more-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007802</guid>
            <pubDate>Fri, 31 Jul 2020 11:58:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V OS using Rust: Graphics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007693">thread link</a>) | @pavehawk2007
<br/>
July 31, 2020 | https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007693</guid>
            <pubDate>Fri, 31 Jul 2020 11:37:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meat consumption is causing damage]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007355">thread link</a>) | @lcnmrn
<br/>
July 31, 2020 | https://subreply.com/trohs/ik9 | <a href="https://web.archive.org/web/*/https://subreply.com/trohs/ik9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://subreply.com/trohs/ik9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007355</guid>
            <pubDate>Fri, 31 Jul 2020 10:36:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cattle, Not Pets – A Modern Approach to Developer Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007325">thread link</a>) | @shenman
<br/>
July 31, 2020 | https://akshayeshenoi.github.io/modern-approach-dev-infra/ | <a href="https://web.archive.org/web/*/https://akshayeshenoi.github.io/modern-approach-dev-infra/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The <a href="http://cloudscaling.com/blog/cloud-computing/the-history-of-pets-vs-cattle/">Cattle, Not Pets</a> analogy has been espousing the disposability of servers notion since the early days of the cloud revolution. Treat your infrastructure as cattle: design for failure, automate deployment, and when things go wrong with a server, take it out in the back, shoot it, and replace it with another one on the line. Contrastingly, servers treated like pets seek painstaking care: they are manually built, irreplaceable and often christened with cute names.</p>

<p><img src="https://akshayeshenoi.github.io/assets/2020-05-25-modern-approach-dev-infra/pet-cattle.jpg" alt="cattle-pets"></p>

<p>The cattle approach, that Google in fact pioneered, has been bearing fruits of scalability and manageability of application infrastructure for teams across the board. Engineers today are armed with an arsenal of tools that allow them to weave together compute, network and storage infrastructure in an abstract (albeit opinionated) fashion. As a corollary, teams don’t concern themselves with the gory details of where their code is running, but can indeed turn their focus to what they do best - write application code!</p>

<p>Developer infrastructure, however, hasn’t fundamentally changed since we shifted from developing on giant room-sized mainframes to developing on compact personal machines. Sure, our laptops pack a considerably meaner punch than they did decades ago, but the innovation has largely been incremental. Embarrassingly, we continue to struggle with the same age old problems such as the abhorrent “but it works on my machine” phenomenon that pervades even the best of teams. On-boarding new members still comes with the unnecessary friction of manually setting up environments. Version conflicts are not infrequent.</p>

<p>That’s not to say the future looks grim; a fundamental shift in the way we do things is indeed underway. The explosion of Docker and orchestration tools like Kubernetes has opened up new doors and container technology has been progressively making deep in-roads into every facet of the development life-cycle.</p>

<h4 id="state-of-the-art">State of the Art</h4>

<p>Today, engineers are equipped with environments that are identical to the ones that run on production servers. On their local machine, a developer typically spawns an instance of a custom-built image downloaded from a remote repository. This image (which is the environment) is configured with just the right amount - and the right versions - of dependencies required to compile and run the application code. When the CI eventually takes the code to production, a similar image retaining only the runtime dependencies is spawned to execute it. Since everyone works on a unified environment, most of the conventional problems are mitigated.</p>

<p>This is great - but why stop at that?</p>

<h4 id="the-modern-approach">The Modern Approach</h4>

<p>If teams have embraced this unified approach to developer environments, why not go one step further and provision them on shared infrastructure to benefit from economies of scale? The power of the cloud at the developer’s fingertips! Environments can be spawned at will, utilized, and discarded when the developer logs off. (Of course, persisting state somehow).</p>

<blockquote>
  <p>Treat the modern developer infrastructure as cattle, not pets.</p>
</blockquote>

<p>Notably, our existing developer tooling would have to be minimally disrupted for this transition. We spend most of our time on our beloved editors - every extension, theme and font tuned to perfection. Departing from our sanctum sanctorum would be desecration. Our cattle would at least need to provide the <em>illusion</em> of being a pet.</p>

<p>Microsoft demonstrated a somewhat bare-bones version of this capability with <a href="https://code.visualstudio.com/blogs/2019/05/02/remote-development">Remote Development</a> on VS Code (Remote - Containers). Essentially, a component of VSCode runs inside a docker container as a server, and the UI component connects to it from the host machine. The terminal processes, extensions and debuggers run <em>inside</em> the container - which could be hosted anywhere on the network - while the UI is rendered on the developer’s machine.</p>

<p>Such a technology could form the bedrock of more complex systems that realize the notion of disposable environments. Picture a fully managed developer infrastructure platform that provides teams with the capability of curating and deploying environments in the cloud!</p>

<p><img src="https://akshayeshenoi.github.io/assets/2020-05-25-modern-approach-dev-infra/diagram.png" alt="modern-dev-infra"></p>

<p>In fact, GitHub announced <a href="https://github.com/features/codespaces/">CodeSpaces</a>: a feature so magical and game changing, it’s hard to underscore its true potential. At the click of a button, a developer can spin-up instant dev environments with all the dependencies the repository needs <strong>and work entirely on the cloud</strong>. Not only does it provide a VSCode like experience <em>in the browser</em>, but one can connect to it from a full installation of VSCode as well!</p>

<p>While GitHub has the advantage of being <em>the</em> destination for source code, making it an easy choice for a number of teams, other solutions may offer more advanced features. For instance, <a href="https://www.koding.com/">Koding</a> takes a less opinionated approach and allows configuration of powerful dev-environments on any cloud provider. This could be suitable for teams seeking finer-grained customization.</p>

<p>Indeed, these advances paint a promising future. Fiscally speaking, the economies of scale realized as we move towards environments on shared infrastructure will bring down costs. For startups and smaller enterprises with “Bring Your Own Device” policies, unified virtual environments would break down most compatibility related barriers. Further, global availability of these environments would also benefit teams distributed across continents.</p>

<p>In an ironic way, this is a modern revival of the mainframe way of doing things.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://akshayeshenoi.github.io/modern-approach-dev-infra/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007325</guid>
            <pubDate>Fri, 31 Jul 2020 10:30:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Translate GraphQL queries into SQL statements]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007316">thread link</a>) | @oczek
<br/>
July 31, 2020 | https://blog.graphqleditor.com/sqlmancer-graphql-to-sql/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/sqlmancer-graphql-to-sql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Since its open-sourcing, GraphQL keeps on gaining popularity and is becoming used by more &amp; more development teams. Why? What’s its secret? It’s simple, GraphQL makes describing the complex data dependencies easy and it can be usee with any programming language. The rising popularity created a demand for different tools and libraries facilitating GraphQL implementation &amp; usage across different technologies and vice-versa. <strong>Sqlmancer</strong> is one of them.</p>
<h2>Goals &amp; Features</h2>
<p>Sqlmancer is a Node.js library simplifying GraphQL integration with SQL by translating GraphQL queries into SQL statements in a smart way. The flexibility offered by Sqlmancer allows you to create the queries and mutations that suit your schema as well as leaving the decisions to you what types you want to expose in your schema by offering a number of convenient directives. The last but not least, Sqlmancer put annotation over transformation using directives mostly to annotate your schema rather than changing its behavior, aiming to be as aspect-oriented as possible.</p>
<p>Some of the notable features of Sqlmancer:</p>
<ul>
<li><strong>Various dialects supported</strong> - you can incorporate Sqlmancer into existing projects regardless of what flavor of SQL you’re using as it supports Postgres, MySQL, MariaDB, and SQLite.</li>
<li>
<p><strong>Advanced sorting &amp; filtering</strong> - Add complex sorting and filtering to your data-fetching, including:</p>
<ul>
<li>filtering using logical operators,</li>
<li>filtering and sorting by fields</li>
<li>filtering by aggregate fields of related models.</li>
</ul>
</li>
<li><strong>Performance</strong> - Sqlmancer makes the N+1 problem the song of the past by building a single SQL query to fetch all necessary data, regardless of query depth.</li>
<li><strong>Custom scalars &amp; Abstract types</strong> - Use the scalars that make sense and easily add unions and interfaces into your schema using views or single table inheritance features.</li>
</ul>
<h2>How it works</h2>
<p>Sqlmancer generates a type-safe database client basing on your GraphQL schema and metadata provided through a set of schema directives, giving you the ability to query your server for complex data structures with a single SQL query:</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/64560b2c8eaf8c5efb6e69382a07a51e/78363/sqlmancer_query.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Sqlmancer sample resolver" title="Sqlmancer sample resolver" src="https://blog.graphqleditor.com/static/64560b2c8eaf8c5efb6e69382a07a51e/fcda8/sqlmancer_query.png" srcset="https://blog.graphqleditor.com/static/64560b2c8eaf8c5efb6e69382a07a51e/12f09/sqlmancer_query.png 148w,
https://blog.graphqleditor.com/static/64560b2c8eaf8c5efb6e69382a07a51e/e4a3f/sqlmancer_query.png 295w,
https://blog.graphqleditor.com/static/64560b2c8eaf8c5efb6e69382a07a51e/fcda8/sqlmancer_query.png 590w,
https://blog.graphqleditor.com/static/64560b2c8eaf8c5efb6e69382a07a51e/efc66/sqlmancer_query.png 885w,
https://blog.graphqleditor.com/static/64560b2c8eaf8c5efb6e69382a07a51e/c83ae/sqlmancer_query.png 1180w,
https://blog.graphqleditor.com/static/64560b2c8eaf8c5efb6e69382a07a51e/78363/sqlmancer_query.png 1522w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://sqlmancer.netlify.app/introduction">sqlmancer.netlify.app</a></h5>
<p>while keeping your resolver as simple as possible:</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/c3d3d0c9324abd30b73f9064adb2a273/307e7/sqlmancer_resolver.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Sqlmancer sample query" title="Sqlmancer sample query" src="https://blog.graphqleditor.com/static/c3d3d0c9324abd30b73f9064adb2a273/fcda8/sqlmancer_resolver.png" srcset="https://blog.graphqleditor.com/static/c3d3d0c9324abd30b73f9064adb2a273/12f09/sqlmancer_resolver.png 148w,
https://blog.graphqleditor.com/static/c3d3d0c9324abd30b73f9064adb2a273/e4a3f/sqlmancer_resolver.png 295w,
https://blog.graphqleditor.com/static/c3d3d0c9324abd30b73f9064adb2a273/fcda8/sqlmancer_resolver.png 590w,
https://blog.graphqleditor.com/static/c3d3d0c9324abd30b73f9064adb2a273/efc66/sqlmancer_resolver.png 885w,
https://blog.graphqleditor.com/static/c3d3d0c9324abd30b73f9064adb2a273/c83ae/sqlmancer_resolver.png 1180w,
https://blog.graphqleditor.com/static/c3d3d0c9324abd30b73f9064adb2a273/307e7/sqlmancer_resolver.png 1354w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://sqlmancer.netlify.app/introduction">sqlmancer.netlify.app</a></h5>
<p>Cool, right? If you are interested in for a detailed guide on how to work with the library make sure to visit <a href="https://sqlmancer.netlify.app/introduction">official Sqlmancer documentation</a> </p>
<h2>Still in development</h2>
<p>Sqlmancer is still in development. The API is still subject to changes so be aware that there might be some breaking changes coming anytime. As mentioned by the creator feedback and suggestions from the community are more than welcome so if you find a bug, have a feature request, or just want to contribute to this awesome project, feel free to an open issue.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/sqlmancer-graphql-to-sql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007316</guid>
            <pubDate>Fri, 31 Jul 2020 10:28:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leveraging Cloudflare Workers to prevent attackers from bypassing Cloudflare]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007275">thread link</a>) | @sandm
<br/>
July 31, 2020 | https://sandrino.dev/blog/forcing-traffic-through-cloudflare | <a href="https://web.archive.org/web/*/https://sandrino.dev/blog/forcing-traffic-through-cloudflare">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><div><p>Sandrino Di Mattia<!-- --> / <!-- -->July 31, 2020</p></div><p>6 min read<!-- --> â€¢ <!-- -->â€“â€“â€“ views</p></div></div><h2 id="introduction"><p>Introduction<a aria-label="anchor" href="#introduction">#</a></p></h2><p>Over the past few years the popularity and usage of <a target="_blank" rel="noopener noreferrer" href="https://www.cloudflare.com/">Cloudflare</a> has seen a tremendous growth, really living up to their mission of building a better Internet by making it faster and more secure.</p><img alt="Cloudflare Overview" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAf/AABEIAAUACgMBEQACEQEDEQH/xAGiAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgsQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+gEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoLEQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AP7jviLo+oy+GLJI/Eeo2zy6xbqHhtNHKwnGqSNPCs+nzP8AaGiZbcmaWa1CRI62gkaVpOfEUJV8LUw9OvVwtSfNyYyhySxFBtWUqUcTHEYZyg/fj7fD1oc3xwnC0FtRnRpYmnWqUPrNGHK3hK1WcaNWUXzP2tTD+wxPJL4ZRo1qMuSyhOM1zvzFNNvkREOvak5VVUu8Gkl3KgDcxGnAFmxlsADJOAOldfMv+fcPvqf/ACZzcsv+fk/up/8AyB//2Q=="><p>And while Cloudflare adds a lot to the table from a security point of view with their Bot Detection, WAF, DDoS Protection, ... there's still a chance that all of these protections can be bypassed by attacking the Origin IP directly. This is not an issue with Cloudflare itself, but with how the actual web applications have been configured to accept traffic. Tools like <a target="_blank" rel="noopener noreferrer" href="http://www.crimeflare.org:82/cfs.html#box">CrimeFlare</a> try to map Cloudflare protected sites to their original IP address.</p><img alt="Cloudflair Bypass" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAf/AABEIAAcACgMBEQACEQEDEQH/xAGiAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgsQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+gEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoLEQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AP7xtNh8SGfSpoNQ00aGtlqkeoWU+n3M2ozajJeRGwuba+OqhIbW3ijuUntZIJGladWSZFjVF8108weNw1WliKdLLoUcRHFYCrhPbYuviJypvD1qWYRzBQw9Oio1Oag8HiHW9rf2tFwil2wlgIYLEUZ4etUx88RQnhsbDGcmGoYeMav1ihPAywUqlepWnOnKNf65RVFUnFUaim2tBbfxRtG7UdK3YGf9AmHOOeBckdfQn6mvRV2ldWdtVvZ9r+RxH//Z"><p>Ideally your applications should only accept traffic from Cloudflare, but this introduces some level of complexity depending on the implementation. There's also a lot of content available today describing techniques on how to bypass Cloudflare and find unprotected web applications where the Origin IP can be attacked:</p><ul><li><a target="_blank" rel="noopener noreferrer" href="https://rhinosecuritylabs.com/cloud-security/cloudflare-bypassing-cloud-security/">Introducing CFire: Evading CloudFlare Security Protections</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://enciphers.com/bypassing-cloudflare-waf-to-get-more-vulnerabilities/">Bypassing Cloudflare WAF to get more vulnerabilities</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://blog.detectify.com/2019/07/31/bypassing-cloudflare-waf-with-the-origin-server-ip-address/">Bypassing Cloudflare WAF with the origin server IP address</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://blog.christophetd.fr/bypassing-cloudflare-using-internet-wide-scan-data/">CloudFlair: Bypassing Cloudflare using Internet-wide scan data</a></li></ul><h2 id="existing-solutions"><p>Existing Solutions<a aria-label="anchor" href="#existing-solutions">#</a></p></h2><p>There's several solutions documented which will make it harder for attackers and in some cases will really solve the issue.</p><h3 id="keeping-the-origin-ip-hidden"><p>Keeping the Origin IP hidden<a aria-label="anchor" href="#keeping-the-origin-ip-hidden">#</a></p></h3><p>A lot of content suggests doing everything in your power to hide the Origin IP, like avoid having DNS record pointing to your IP address directly, being careful with MX records, disabling XML-RPC Pingback, ...</p><p><a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Security_through_obscurity">Security trough obscurity</a> at its best and not a true solution.</p><h3 id="only-accepting-traffic-from-cloudflare"><p>Only accepting traffic from Cloudflare<a aria-label="anchor" href="#only-accepting-traffic-from-cloudflare">#</a></p></h3><p>An other type of advice that is commonly given is restricting access to your application based on IP address ranges, only allowing traffic originating from Cloudflare:</p><ul><li><a target="_blank" rel="noopener noreferrer" href="https://community.cloudflare.com/t/force-the-traffic-through-cloudflare-even-on-direct-aws-link/151513">Force the traffic through Cloudflare even on direct AWS link</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://community.cloudflare.com/t/prevent-users-bypassing-cloudflare-to-access-my-site/4606">Prevent direct access to IP</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://community.cloudflare.com/t/prevent-users-bypassing-cloudflare-to-access-my-site/4606">Prevent Users Bypassing Cloudflare To Access My Site</a></li></ul><p>Even though this makes things slightly harder for attackers, it still doesn't solve the issue. Nothing prevents an attacker from also using Cloudflare and attacking your Origin IP through Cloudflare. Your servers would not be able to distinguish traffic coming from your Cloudflare account vs. traffic coming from the attacker's Cloudflare account.</p><p>This also introduces some complexity: you'll need to setup some automated tooling which will constantly monitor <a target="_blank" rel="noopener noreferrer" href="https://www.cloudflare.com/ips/">Cloudflare's IP Ranges</a> and change your firewall rules to make sure you don't block new IP addresses used by Cloudflare.</p><h3 id="authenticated-origin-pulls"><p>Authenticated Origin Pulls<a aria-label="anchor" href="#authenticated-origin-pulls">#</a></p></h3><p><a target="_blank" rel="noopener noreferrer" href="https://support.cloudflare.com/hc/en-us/articles/204899617-Authenticated-Origin-Pulls">Authenticated Origin Pulls</a> give you the guarantee that the request originates from Cloudflare and has been processed by the WAF.</p><img alt="Authenticated Origin Pulls" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAf/AABEIAA4ACgMBEQACEQEDEQH/xAGiAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgsQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+gEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoLEQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AP7UtK8NfGXR9V+IK+Ifi3p2oW2o+IEvPBkdv4KsrFvDGgIL2/utMkuLLVXvNYZrPUNFsmvbqOyuUm0W7ufsjw6qssr49xGEx2S5TT4RceE80wlL2ucZhi3XzqnmHLShTlyYOpTpU8K5VqVavFUZ1YKNaNNu9JxXzOW4XP8AD4jNZZlnNLHUKmJi8tpQwNHDPBYe9Wo6U506054p+zq0KTqVY05p4ec1Fqrc+jdOs9Tg0+xg1C/W+v4bO1ivr2MSWyXl5HAiXN0luGcQJcTB5VhDuIg4QM23J8vCYfMKeFw1PF4uGJxdPD0YYrEwg6EMRiIU4xrV40VzKjGrUUqkaSlJU1JQTaVz6KKqKKUpJtJJu1ru2rtbS71sYU3hRf7W1HU4oNNmbU7uS9nkmOoQ3Pm/2PpekxB9lzNZSskWmRIsv2KNY4FhX7PLcrc3V17FbE154eFGCv7LD1KMFOsoQftKtas17uHlKMOas73dWTd2pKLjCGKw0Y1a9VRp3rVY1W7TUuaNGjRV25yje1GNnGMY2snByUpz7KKKOKOOJFASJEjQYHCooVRwAOAB2rI6j//Z"><p>This capability is based on TLS client certificate authentication and will require some changes to your web server. This is also not always an option depending on where you host your application (PaaS and Serverless environments for example):</p><pre mb="4"><code>ssl_client_certificate /etc/nginx/certs/cloudflare.crt<span>;</span>
ssl_verify_client on<span>;</span>
</code></pre><p>The reason why this feature does not solve the bypass problem is because it guarantees that traffic comes from Cloudflare, but there are no guarantees that the request originated from your Cloudflare account. This is because your web server will only validate that the client certificate is signed by the Cloudflare CA chain.</p><h3 id="cloudflare-argo-tunnel"><p>Cloudflare Argo Tunnel<a aria-label="anchor" href="#cloudflare-argo-tunnel">#</a></p></h3><p>The best solution to this problem is <a target="_blank" rel="noopener noreferrer" href="https://developers.cloudflare.com/argo-tunnel/reference/how-it-works/">Argo Tunnel</a>, which creates an encrypted tunnel between your web server and your Cloudflare account. With this feature, you don't have to make your application publicly available on the internet.</p><img alt="Cloudflare Argo Tunnel" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAf/AABEIAAUACgMBEQACEQEDEQH/xAGiAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgsQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+gEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoLEQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AP7wBZ36+IPsp13UnV9NmVbhodJF1GryeYQrJpq22Vdk8tjalgsarI0h5BUpucpVY1atKLp8io03B0YzvZVlGrCpN1Er/HOUG3rBrQITjFRpypU6klU5nVnzKrKDV3RbpypxVNtL4IxnppNPU3YdL1COKKN/EGpTvHGiPNJb6UskzKoVpZBFp8cQeQguwjjSMMSERVwo3dWDbfsKS12TqWXkrzbsvNt92Zezn/z+n90f/kT/AP/Z"><p>This solution does come at an extra cost (including a cost per GB) and at might not work in all environments. Argo Tunnel currently requires to run an agent on your web server:</p><pre mb="4"><code>cloudflared tunnel --hostname www.acme.com http://localhost:8000
</code></pre><p>Running an agent like <code>cloudflared</code> might not be an option if you don't have full access to your hosting environment (PaaS and Serverless platforms).</p><h3 id="an-alternative-using-cloudflare-workers"><p>An alternative using Cloudflare Workers<a aria-label="anchor" href="#an-alternative-using-cloudflare-workers">#</a></p></h3><p>There's an alternative solution similar to <strong>Authenticated Origin Pulls</strong> which we can build using <a target="_blank" rel="noopener noreferrer" href="https://workers.cloudflare.com/">Cloudflare Workers</a>. By using Cloudflare Workers, we can change the request before it is forwarded to the origin.</p><p>What this allows us to do is to configure a secret on both sides (Cloudflare and the web application). The web application can then decide to only accept requests for which the secret is provided (in a header for example). This could be a static value, a HMAC signed request, a JWT ... In this example we're going to secure our origin using a shared secret:</p><img alt="Shared Secret" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAf/AABEIAAYACgMBEQACEQEDEQH/xAGiAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgsQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+gEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoLEQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AP7ydP0/WmfTrqDXpYdOitL+C40uSztLk3d1NexPBfNqEsX2qFrOKCe3jt4sW8q3kjzI8kVu0XB9Xxn1uhXji3SwtOjXp1cvjGjUo16tScJU8RLETofWoToKEowp0qkKMlVq+1p1ZKlKl1xq4WGErYf6rGeInXo1KWOlUrRq0KVOFRVMPGhGt9WnCvKpGc6lWE6sXRpqlOnGVWNR8EHi8QQie505pxFGJmW7VlaUIBIVI8PRAqXyQRFFkc+Wn3R1p1bK8Kd7a2qSav1s/ZK6+S9CHHC3fLWxDV3ZvDU02ul0sW0nbdJu3dn/2Q=="><p>Let's start by creating a worker which will add an additional header to the request:</p><pre mb="4"><code><span>function</span> <span>handleRequest</span><span>(</span><span>request</span><span>)</span> <span>{</span>
  <span>const</span> newRequest <span>=</span> <span>new</span> <span>Request</span><span>(</span>request<span>)</span><span>;</span>
  newRequest<span>.</span><span>headers</span><span>.</span><span>set</span><span>(</span><span>'x-cf-key'</span><span>,</span> <span>CF_SECRET</span><span>)</span><span>;</span>
  <span>return</span> <span>fetch</span><span>(</span>newRequest<span>)</span><span>;</span>
<span>}</span>

<span>addEventListener</span><span>(</span><span>'fetch'</span><span>,</span> <span>(</span><span>event</span><span>)</span> <span>=&gt;</span> <span>{</span>
  event<span>.</span><span>respondWith</span><span>(</span><span>handleRequest</span><span>(</span>event<span>.</span><span>request</span><span>)</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span>
</code></pre><p>The <code>CF_SECRET</code> will be replaced with an environment variable which we can configure on the worker. This setting will contain our shared secret:</p><img alt="Worker Secret" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAf/AABEIAAkACgMBEQACEQEDEQH/xAGiAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgsQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+gEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoLEQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AP7r9P02zulmW401c+dPFbzSaNe3RGxnUSzXS38vmRuw+SNRbZQKwSOOVNooqNrSna92lUqLfVpNydt7ae6tElZJA5Sd9IX2T9nTeysm7JXfdt3b1k22287+yJU+SSSEyL8shihmtIi68N5dq9xdPbR7gdlu9zcNCuI2nmKmRnLl5nypqN3yqUuaSjfROVo8zS3lyxu9bLYmKfLHn5XOy5nGCinK3vNRvLlTd7R5pWWnM9zzCX/kM3P/AF93f85aRR6Fa/8AHtb/APXCL/0WtAH/2Q=="><p>As a final step I'm going to enable the worker for the domain on which my application runs:</p><img alt="Enable Worker" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAf/AABEIAAkACgMBEQACEQEDEQH/xAGiAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgsQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+gEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoLEQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/APpvwX8ZPhx4i+Bf7YXjn43/APBS/wDas+Hf7Sngrx9+0pZfBr4VaN+094w0HR9VPhiyvp/hVpUfhc6NrNy2n6r4m26IUtNWsLb7JAbdH0+ONZ62hLZKMFa73knZJybV5xTdk+WKacnaKTbSMZwteTlPVpaWfvNpK9oSlFXavNqyV5SejZ90fs+fGL42a38BPghrOsfFf4j6pq+r/CH4a6nqmp6h421291DUdRv/AAZot3fX99eXF6Z7u8vLmWW4ubqYmW4mkeWQl3NZtq70W/n/APJP82Wo6L0XSP8A8ivyXojqviD/AMjN41/7GHX/AP07XNOn8cfUKnwS9D9HvAP/ACIngr/sUvDn/pns6l7v1f5lLZei/I//2Q=="><p>My application runs on Heroku (<a target="_blank" rel="noopener noreferrer" href="https://hello-world-sandrino.herokuapp.com/">https://hello-world-sandrino.herokuapp.com/</a>) and is also proxied through Cloudflare (<a target="_blank" rel="noopener noreferrer" href="https://hello.sandrino.run/">https://hello.sandrino.run</a>). I've created a simple page which lists all of the request headers and for any request served through Cloudflare we can now see the additional header with the shared secret:</p><img alt="Secret forwarded in a header" src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAf/AABEIAAcACgMBEQACEQEDEQH/xAGiAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgsQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+gEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoLEQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AP7cNKvdaibUor5Y40XUbz7H51tpcoaza4l+zhHSK7cqI9pYTJDICw3B23bfQi8PyxvG3uxvfn3tra0rfkcU1WTvGUZJt6Rt7vZPmjH8L7eh1scwaNGKwZZFJxbQAZIBOAsKqB6AKoHQADiuaThzSs3bmdtZdzWLfKr2vZX0jvbXof/Z"><p>Note: You will want to treat this header as a secret. It should not be leaked to your users.</p><p>The final step is to make sure requests are only served when a <code>X-CF-KEY</code> header is provided and it contains a valid shared secret. In the example below I'm illustrating how this can be done using a middleware in <a target="_blank" rel="noopener noreferrer" href="https://expressjs.com/">Express</a>, but this can be done in virtually any framework or web server. Most of these allow you to run logic before requests are served and that's the point where you would validate the presence of this header.</p><pre mb="4"><code><span>const</span> app <span>=</span> <span>express</span><span>(</span><span>)</span><span>;</span>

<span>...</span>

app<span>.</span><span>use</span><span>(</span><span>(</span><span>req<span>,</span> res<span>,</span> next</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> key <span>=</span> req<span>.</span><span>get</span><span>(</span><span>'x-cf-key'</span><span>)</span><span>;</span>
  <span>if</span> <span>(</span>key <span>!==</span> <span>'a618e605-fd2d-4e0e-8fe0-139a41193945'</span><span>)</span> <span>{</span>
    <span>return</span> res<span>.</span><span>sendStatus</span><span>(</span><span>404</span><span>)</span><span>;</span>
  <span>}</span>

  <span>return</span> <span>next</span><span>(</span><span>null</span><span>,</span> req<span>,</span> res<span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span>

app<span>.</span><span>get</span><span>(</span><span>'/'</span><span>,</span> <span>(</span><span>req<span>,</span> res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  res<span>.</span><span>render</span><span>(</span><span>'homepage'</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span>
</code></pre><p>Here's the final result. Requests made through Cloudflare are accepted and served as expected because Cloudflare will provide a valid <code>X-CF-KEY</code> header to our web application. Requests that are made directly to the web application will fail because the header is not present.</p><h2 id="-success"><p>âœ… Success!<a aria-label="anchor" href="#-success">#</a></p></h2><p>Through the use of Cloudflare Workers we can guarantee that the request originates from your Cloudflare account which can be used as a mechanism to prevent bypassing of your Cloudflare configuration. This is a valid solution in case you cannot leverage Argo Tunnels in your environment.</p><p>If possible you should configure Cloudflare account to use Full (strict) SSL/TLS encryption and Authenticated Origin Pulls for improved security and to prevent MITM attacks.</p></article></div>]]>
            </description>
            <link>https://sandrino.dev/blog/forcing-traffic-through-cloudflare</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007275</guid>
            <pubDate>Fri, 31 Jul 2020 10:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indexing Firebase Data in Algolia for Full-Text Search]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007071">thread link</a>) | @varunraj22
<br/>
July 31, 2020 | https://www.skcript.com/svr/indexing-firebase-data-in-algolia-for-full-text-search/ | <a href="https://web.archive.org/web/*/https://www.skcript.com/svr/indexing-firebase-data-in-algolia-for-full-text-search/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Firebase being a BaaS solution comes with a bunch of features for developers to build their app faster and with real-time capabilities. But, there is one thing that is yet to be addressed by Firebase’s feature set - the ability to perform full-text search on the data that is stored in Firebase databases (like Firestore or Realtime Database). This creates a huge bottleneck for developers since search is one of the primary user experiences for any application we build.</p><p>Thankfully we’ve got Algolia that can help us solve this problem. This is a service which helps you store the index of data from firebase, making it searchable. The important advantage of Algolia is that it’s supported in different platforms with a lot of UI components, which can be easily used to develop search modules for your apps.</p><p>In this article, I’ll walk you through how to set up your Algolia and index your data when new data is created or modified in your Firebase Firestore. This article is split into the following sections, you can skip any, in case if you’re already aware of them.</p><ol><li>Creating an account in Algolia</li><li>Setting up Firebase Cloud Function</li><li>Index data from Firebase Firestore on create and edit.</li></ol><h3 id="creating-an-account-in-algolia">Creating an account in Algolia<a href="#creating-an-account-in-algolia">#</a></h3><p>As the first step, you can navigate to Algolia and register your account by either signing up with Google or Github or just with email.</p><p><a target="_blank" href="https://www.skcript.com/svrmedia/heroes/image6-9.png"><img src="https://www.skcript.com/svrmedia/heroes/image6-9.png" alt="" loading="lazy"></a></p><p>Once you’ve created your Algolia account, go to the dashboard and find a default project created under your account. Let’s use that project for this article.</p><p>Similar to Firestore collections Algolia has an “Index” - the aggregation of data under a common umbrella. Create your index to store the data.</p><p>In this case, I have created an index called “Recipes” to save food recipes</p><p><a target="_blank" href="https://www.skcript.com/svrmedia/heroes/image1-30.png"><img src="https://www.skcript.com/svrmedia/heroes/image1-30.png" alt="" loading="lazy"></a></p><p>After creating an account, add data to the index. Among the 3 different options for adding the data, we’ll be using the API for importing data with help from the firebase cloud functions.</p><p><a target="_blank" href="https://www.skcript.com/svrmedia/heroes/image4-22.png"><img src="https://www.skcript.com/svrmedia/heroes/image4-22.png" alt="" loading="lazy"></a></p><h3 id="setting-up-firebase-cloud-functions">Setting up Firebase Cloud Functions<a href="#setting-up-firebase-cloud-functions">#</a></h3><p>Let’s assume that you’re already having a firebase project and upgraded to <strong>Blaze Plan</strong> since we have to call external APIs from functions. Then, initialize the functions in your project with the Firebase CLI tool and setup cloud functions.</p><div><pre><code data-lang="sh">cd ProjectFolder
firebase init 
</code></pre></div><p>On completion, you’ll find a folder named “<strong>functions</strong>” in your project folder. Open the project folder in a text editor like VSCode.</p><p>Now we’re going to index data in the “recipes” collection to our new Algolia index. So, let’s create two functions that listen to onCreate and onEdit of any document in the “recipes” collection.</p><p>functions/index.js</p><div><pre><code data-lang="js"><span>const</span> <span>functions</span> <span>=</span> <span>require</span>(<span>'firebase-functions'</span>);
<span>const</span> <span>onCreate</span> <span>=</span> <span>require</span>(<span>'./triggers/recipes/onCreate'</span>);
<span>const</span> <span>onEdit</span> <span>=</span> <span>require</span>(<span>'./triggers/recipes/onEdit'</span>);

<span>exports</span>.<span>onRecipeCreate</span> <span>=</span> <span>functions</span>.<span>firestore</span>
                                   .document(<span>"recipes/{recipeId}"</span>)
                                   .<span>onCreate</span>(<span>onCreate</span>);

<span>exports</span>.<span>onRecipeEdit</span> <span>=</span> <span>functions</span>.<span>firestore</span>
                                   .document(<span>"recipes/{recipeId}"</span>)
                                   .<span>onUpdate</span>(<span>onEdit</span>);
</code></pre></div><p>Create the handler functions for onCreate of recipe docs and onEdit of the same. So, I’ve created two files under the triggers folder of our functions</p><p><em>functions/triggers/recipes/onCreate.js</em></p><div><pre><code data-lang="js"><span>module</span>.<span>exports</span> <span>=</span> (<span>snap</span>, <span>context</span>) =&gt; {
}
</code></pre></div><p><em>functions/triggers/recipes/onEdit.js</em></p><div><pre><code data-lang="js"><span>module</span>.<span>exports</span> <span>=</span> (<span>change</span>, <span>context</span>) =&gt; {
}
</code></pre></div><h3 id="index-data-from-firebase-firestore-on-create-and-update">Index data from Firebase Firestore on create and update.<a href="#index-data-from-firebase-firestore-on-create-and-update">#</a></h3><p>To index the documents in Algolia, configure Algolia keys in the firebase cloud functions. The secured way is to use firebase environment variables.</p><p>To get the API keys from Algolia, go API Keys section in Algolia dashboard and copy your Application ID and the Admin API Key</p><p><a target="_blank" href="https://www.skcript.com/svrmedia/heroes/image5-18.png"><img src="https://www.skcript.com/svrmedia/heroes/image5-18.png" alt="" loading="lazy"></a></p><p>These keys need to be configured to our Firebase Cloud function’s environment variables. You can do that with the help of the firebase CLI tool</p><div><pre><code data-lang="js"><span>firebase</span> <span>functions</span><span>:</span><span>config</span><span>:</span><span>set</span> <span>algolia</span>.<span>app_id</span><span>=</span><span>"THE APP ID"</span> <span>algolia</span>.<span>admin_key</span><span>=</span><span>"THE ADMIN API KEY"</span> 
</code></pre></div><p>After updating the config, we can start using it in the ‘functions’ code. In order to use Algolia, we need to install the npm package in our functions code base.</p><div><pre><code data-lang="sh">cd functions
npm install --save algoliasearch
</code></pre></div><p>After installing the package, create a config file to setup Algolia with the API Keys</p><p><em>functions/config/algolia.js</em></p><div><pre><code data-lang="js"><span>const</span> <span>functions</span> <span>=</span> <span>require</span>(<span>'firebase-functions'</span>);
<span>const</span> <span>algoliasearch</span> <span>=</span> <span>require</span>(<span>'algoliasearch'</span>);

<span>const</span> <span>ALGOLIA_ID</span> <span>=</span> <span>functions</span>.<span>config</span>().<span>algolia</span>.<span>app_id</span>;
<span>const</span> <span>ALGOLIA_ADMIN_KEY</span> <span>=</span> <span>functions</span>.<span>config</span>().<span>algolia</span>.<span>admin_key</span>;

<span>module</span>.<span>exports</span> <span>=</span> <span>algoliasearch</span>(<span>ALGOLIA_ID</span>, <span>ALGOLIA_ADMIN_KEY</span>);
</code></pre></div><p>This file exports the Algolia Client which we can use to index data and delete the indexed data. Thus, we need to import this in our onCreate and onEdit file.</p><p>With the client, you can initialize the index, in our case “Recipes” and we use <code>saveObject</code> function to store the data inside the index.</p><p><em>functions/triggers/recipes/onCreate.js</em></p><div><pre><code data-lang="js"><span>const</span> <span>client</span> <span>=</span> <span>require</span>(<span>"../../config/algolia"</span>);
<span>const</span> <span>recipeIndex</span> <span>=</span> <span>client</span>.<span>initIndex</span>(<span>'Recipes'</span>);

<span>module</span>.<span>exports</span> <span>=</span> (<span>snap</span>, <span>context</span>) =&gt; {
 <span>let</span> <span>data</span> <span>=</span> <span>snap</span>.<span>data</span>();
 <span>data</span>.<span>objectID</span> <span>=</span> <span>snap</span>.<span>id</span>;
 <span>recipeIndex</span>.<span>saveObject</span>(<span>data</span>);
}
</code></pre></div><p><em>functions/triggers/recipes/onEdit.js</em></p><div><pre><code data-lang="js"><span>const</span> <span>client</span> <span>=</span> <span>require</span>(<span>"../../config/algolia"</span>);
<span>const</span> <span>recipeIndex</span> <span>=</span> <span>client</span>.<span>initIndex</span>(<span>'Recipes'</span>);

<span>module</span>.<span>exports</span> <span>=</span> (<span>change</span>, <span>context</span>) =&gt; {
 <span>let</span> <span>data</span> <span>=</span> <span>change</span>.<span>after</span>.<span>data</span>();
 <span>data</span>.<span>objectID</span> <span>=</span> <span>change</span>.<span>after</span>.<span>id</span>;
 <span>recipeIndex</span>.<span>saveObject</span>(<span>data</span>);
}
</code></pre></div><p>In the above two files, we’ve extracted the data from the snap (in onCreate) and changed (in onEdit) to a variable called data. In Algolia, the primary key is stored in the attribute <code>objectID</code> of data, so we’re storing the firebase document ID as the objectID.</p><p>Let’s deploy the function and test the setup. Deploy the firebase functions by executing the below command from the project’s root folder.</p><div><pre><code data-lang="sh">firebase deploy --only functions
</code></pre></div><p>After deploying, create a document under the **recipes **collection and see if it’s indexed in Algolia.</p><p><a target="_blank" href="https://www.skcript.com/svrmedia/heroes/image2-31.png"><img src="https://www.skcript.com/svrmedia/heroes/image2-31.png" alt="" loading="lazy"></a></p><p>As soon as you create the data in Firestore, the cloud functions will be triggered and the indexes will be created in your Algolia project.</p><p><a target="_blank" href="https://www.skcript.com/svrmedia/heroes/image3-21.png"><img src="https://www.skcript.com/svrmedia/heroes/image3-21.png" alt="" loading="lazy"></a></p><p>Similarly, the index will be updated every time you edit the data in Firestore. This happens realtime and thus your search will be always updated.</p><p>Thus, you can replicate the data from firebase to Algolia to create a full-text search index. Hope this article helped you to get started with Algolia setup for your firebase project.</p></div></div>]]>
            </description>
            <link>https://www.skcript.com/svr/indexing-firebase-data-in-algolia-for-full-text-search/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007071</guid>
            <pubDate>Fri, 31 Jul 2020 09:32:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-supervised representation learning on videos]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007039">thread link</a>) | @black0017
<br/>
July 31, 2020 | https://theaisummer.com/self-supervised-learning-videos/ | <a href="https://web.archive.org/web/*/https://theaisummer.com/self-supervised-learning-videos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            
                            

<p>Nowadays, transfer learning from pretrained models on Imagenet is the ultimate standard in computer vision. Self-supervised learning dominates natural language processing, but this doesn’t mean that there are no significant use-cases for computer vision that it should be considered. There are indeed a lot of cool self-supervised tasks that one can devise when she/he is dealing with images, such as jigsaw puzzles [6], image colorization, image inpainting, or even unsupervised <a href="https://theaisummer.com/gan-computer-vision-style-gan/#self-supervised-gans-via-auxiliary-rotation-loss-2018" target="_blank">image synthesis</a>.</p>

<p>But what happens when the time dimension comes into play? How can you approach the video-based tasks that you would like to solve?</p>

<p>So, let’s start from the beginning, one concept at a time. What is self-supervised learning? And how is it different from transfer learning? What is a pretext task?</p>

<h2 id="self-supervised-learning-vs-transfer-learning">Self-supervised learning VS transfer learning</h2>

<p>Transfer learning is a fair point to start.</p>

<blockquote>
  <p>Transfer learning enables us to exploit the weights of a (convolutional) neural network used for task A and apply it to another task (B), given that the input domains are somehow related.</p>
</blockquote>

<p>The training process in task A is called <strong>pretraining</strong> in machine learning terminology. The core idea behind this is that the acquired ‘knowledge’ of task A may be exploited to enhance generalization in task B. And this is usually the case, because who wants to start from a random weight initialization?</p>

<p>Obviously, transfer learning is one way to maximize the performance of your model, by <strong>pretraining</strong> on a similar <strong>supervised</strong> (video) dataset. However, in domains such as videos the problem of annotation (supervision) quickly arises. It is difficult to find video annotated data and transfer weights.</p>

<p>But even before that, let’s clarify the inherent differences of <strong>self-supervised learning VS transfer learning</strong>. I created this simple diagram to make things crystal clear:</p>

<p><img src="https://theaisummer.com/assets/img/posts/self-supervised-learning-videos/self-supervized-VS-transfer-learning.png" alt="self-supervized-VS-transfer-learning">
<em>Self-supervized VS transfer-learning</em></p>

<blockquote>
  <p>As a solution to supervision-deprived domains, self-supervised learning is one way to transfer weights, by pretraining your model on labels that are artificially produced <strong>from</strong> the data/videos.</p>
</blockquote>

<p>This can be achieved with a bunch of different (and sometimes tricking) transformations, as we will see. This is exactly what we call self-supervised representation learning.</p>

<p>Note that, for self supervised learning, <strong>you can even use just your own data, but without the provided labels</strong></p>

<blockquote>
  <p>In essence, in self-supervised learning we are trying to <strong>guess</strong> a related task A so the weight transfer to task B, would be a better initialization point than random.</p>
</blockquote>

<h2 id="notations-concepts-and-example-tasks">Notations, concepts and example tasks</h2>

<p>The devised self-supervised task A is usually called <strong>pretext</strong> or <strong>proxy</strong> task, while the desired task B we want to solve is referred in the literature as a <strong>downstream task</strong>. I usually refer to it as original task also.</p>

<p>Back in the world of videos, video-based learning fall into the category of sequential learning. These approaches can be broadly divided into two classes: sequence <strong>prediction</strong> and <strong>verification</strong>. Additionally, (image) <strong>tuples</strong> refer to a bunch of frames of a video that will be used as the input to the deep learning architecture. <strong>Siamese</strong> models or <strong>multi-branch</strong> models are used interchangeably in the different papers. It is basically <strong>independent predictions of multiple input data</strong>. You can simply think that a lot of forward passes of the siamese model have to be performed before a backward pass, while the extracted features are fused in the next layers. As a result, the loss that will be backpropagated taken into account all the forward passes.</p>

<p>Now we have a clear high-level concept of self-supervision. Let’s see why it is important, especially on video datasets!</p>

<h2 id="why-self-supervised-learning">Why Self-Supervised learning?</h2>

<p>First of all, you <strong>cannot create a new video-dataset</strong> (or any kind of dataset) <strong>for each particular task</strong>. Video annotations are also expensive and time-consuming. Secondly, in a domain such as <a href="https://theaisummer.com/medical-image-coordinates/" target="_blank">medical imaging</a>, <strong>it is hard to obtain any expert annotation at all</strong>. On the other hand, hundreds of thousands of hours of unlabeled videos are uploaded daily on youtube! If you are still not convinced that self-supervised learning is an awesome direction, let’s advise the experts:</p>

<p>“<em>Most of what we learn as humans and most of what animals learn is in a <strong>self-supervised mode</strong>, not a reinforcement mode. It’s basically observing the world and interacting with it a little bit, mostly by observation in a test-independent way.</em>” ~  Yann LeCun, Director of Facebook AI Research (FAIR)</p>

<p>Now I believe that you are convinced. However, be aware that every exciting idea comes with its assumptions and counterparts. But before that let’s clarify our terminology first.</p>

<p>Moving on, what is the <strong>core assumption</strong> of self-supervised learning on videos?</p>

<blockquote>
  <p>Intuitively, we argue that successfully solving the “pretext” task A will <strong>allow our model to learn useful visual representation to recover the temporal coherence of a video</strong>, or in general learning from the statistical temporal structure of videos.</p>
</blockquote>

<p>One example of temporal consistency might be <strong>observing how objects</strong> (cars, humans) <strong>move in the scene</strong>.</p>

<p>Some of the questions that may come in your mind, as perfectly described by Misra et al. [1]:</p>

<ol>
  <li>
    <p>“How does the model learn from the spatiotemporal structure present in the video <strong>without using supervised semantic labels</strong>?”</p>
  </li>
  <li>
    <p>“Are the representations learned using the unsupervised/self-supervised spatiotemporal information present in videos <strong>meaningful</strong>?”</p>
  </li>
  <li>
    <p>“And finally, are these representations <strong>complementary</strong> to those learned from strongly supervised image data?”</p>
  </li>
</ol>

<p>We will answer these questions by inspecting different approaches.</p>

<p>But even before that, <strong>how does one design a self-supervised task</strong>?</p>

<blockquote>
  <p>In short, a good self-supervised task is neither simple nor ambiguous [6].</p>
</blockquote>

<p>Another critical factor that we take into account is <strong>if humans can solve the pretext task</strong>. As an example, try to understand the sequence of the frames below. With a little bit of focus on the relative poses and speculations about “how a person moves”, we can predict the chronological order of these frames.</p>

<p><img src="https://theaisummer.com/assets/img/posts/self-supervised-learning-videos/example-of-permutated-sequences.png" alt="example-of-permutated-sequences">
<em>Taken from the original work [2]</em></p>

<p>Moreover, we need to choose something that <strong>if solved, would require an understanding of our data</strong>. That’s why it falls into the category of representation learning anyway :) .</p>

<blockquote>
  <p>Insight: the key idea is to leverage the inherent structure of raw images and <strong>formulate</strong> the problem as discriminative (classification) or introduce a reconstruction loss function to train the network.</p>
</blockquote>

<p>That being said, I hope you are ready to briefly examine the most influential papers for self-supervised representation learning on videos.</p>

<h2 id="1-shuffle-and-learn-unsupervised-learning-using-temporal-order-verification-eccv-2016">1. Shuffle and Learn: Unsupervised Learning using Temporal Order Verification, ECCV 2016</h2>

<p>This is one of the first works introduced by Misra et al. [1]. They formulate their pretext task as a sequence verification problem.</p>

<blockquote>
  <p>In (sequential) verification, one predicts the ‘temporal validity’ of the sequence.</p>
</blockquote>

<p>In this work, the authors explore the task of <strong>whether a sequence of video frames is in the correct temporal order</strong>. To do so, they had to use a sampling scheme in order to sample the videos. The reason this is important is of course the computational complexity.</p>

<p>To this end, <strong>they sampled images with high motion</strong>, based on the mean optical flow magnitude per frame. In order to create positive and negative tuples, samples of five frames were used as an input. <strong>Positive samples</strong> correspond to the <strong>correct order</strong>, while <strong>negative</strong> ones refer to frames in the <strong>wrong order</strong>. The following image further illustrates the difference.</p>

<p><img src="https://theaisummer.com/assets/img/posts/self-supervised-learning-videos/video-shuffling-eccv-2016.png" alt="video-shuffling-eccv-2016">
<em>An example of video shuffling, positive and negative examples. Taken from the original work [1]</em></p>

<p><strong>Training trick</strong>: During training, the authors used the same beginning and ending frame, while <strong>only changing the middle frame for both positive and negative examples</strong>. As a consequence, the network is <strong>encouraged to focus on this signal to learn the subtle difference</strong> between positives and negatives, rather than irrelevant features.</p>

<p><img src="https://theaisummer.com/assets/img/posts/self-supervised-learning-videos/shuffle-model-architecture-overview.png" alt="shuffle-model-architecture-overview">
<em>An overview of the proposed network architecture of [1]. The image is taken from the original work.</em></p>

<p>Based on the architecture scheme, it is worth noting that each frame is processed <strong>independently</strong> by the AlexNet, while the image features outputs are concatenated for the final classification.</p>

<p>Finally, they used about <strong>900k image tuples</strong>, with a balanced mini-batch ratio of positive and negative instances. As it was found out, it is critical to have a larger percentage of negative examples for order verification (75%).</p>

<h4 id="results-and-discussion">Results and discussion</h4>

<p>The question that was posed was <strong>what does the model really learn from the temporal structure</strong>? In the following image, the authors claim to display the <a href="https://theaisummer.com/receptive-field/" target="_blank">receptive fields</a> (marked in red boxes) for these units. As our network is trained on human action recognition videos, many units show a preference for human body parts and pose, since they are related to high motion. Although it is referenced in the paper as a receptive field the reality is that this is the feature activation of the layer.</p>

<p><img src="https://theaisummer.com/assets/img/posts/self-supervised-learning-videos/activation-from-pool-layer.png" alt="activation-from-pool-layer">
<em>Visualizing activations, taken from [1]</em></p>

<p>Numerically, by combining this scheme with imagenet pretrained weights, we get almost the same mean accuracy as with supervision from videos, as illustrated below (UCF sup. is the supervised database with action videos):</p>

<p><img src="https://theaisummer.com/assets/img/posts/self-supervised-learning-videos/results-eccv2016-paper-action-recognition.png" alt="results-eccv2016-paper-action-recognition">
<em>Results on action recognition, borrowerd from [1]</em></p>

<p>Finally, based on the presented results, one can validate that sequence verification requires an understanding of the video-based task at hand (action recognition).</p>

<h2 id="2-unsupervised-representation-learning-by-sorting-sequences-iccv-2017">2. Unsupervised Representation Learning by Sorting Sequences, ICCV 2017</h2>

<blockquote>
  <p>Core contribution: Lee et al 2017 [2] propose an Order Prediction Network (OPN) architecture</p>
</blockquote>

<p>to solve the sequence sorting task by <strong>pairwise feature extraction</strong>.</p>

<p>Extending the previous work, we are trying to sort the shuffled image sequence. If verification requires an understanding of the statistical …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theaisummer.com/self-supervised-learning-videos/">https://theaisummer.com/self-supervised-learning-videos/</a></em></p>]]>
            </description>
            <link>https://theaisummer.com/self-supervised-learning-videos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007039</guid>
            <pubDate>Fri, 31 Jul 2020 09:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flattening and Filtering JSON for Cleaner Types in Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006994">thread link</a>) | @technicolor
<br/>
July 31, 2020 | http://kgrz.io/go-json-flatten-filter-cleaner-types.html | <a href="https://web.archive.org/web/*/http://kgrz.io/go-json-flatten-filter-cleaner-types.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Before I grokked the <code>Unmarshaler</code> interface, it was hard to know how to parse a complex <span>JSON</span> string into a type in one-shot, with or without preprocessing. There are many good <a href="https://blog.golang.org/json">blog</a> <a href="https://blog.gopheracademy.com/advent-2016/advanced-encoding-decoding/">posts</a> on techniques to parse <span>JSON</span> in Go, but I had to learn this by experimentation to finally wrap my head around it.</p> <p>I’ll use an example from GitHub’s <code>/commits</code> REST API, using PR: <a href="https://github.com/ruby/ruby/pull/3365">ruby/ruby#3365</a>. I’ve <a href="https://github.com/kgrz/json-parsing-post/blob/master/commits.json">saved the response</a> in the <a href="https://github.com/kgrz/json-parsing-post">repo</a> where I’ve added full implementation of the example used in this post. The commits response from GitHub REST API is <em>very</em> verbose, depending on the PR size, and having depth greater than 1. In the hypothetical application that I’m writing, I need a list of “objects” that have the following information:</p> <div><div><pre><code><span>type</span> <span>MetaData</span> <span>struct</span> <span>{</span>
	<span>Author</span> <span>string</span>
	<span>Committer</span> <span>string</span>
	<span>SHA</span> <span>string</span>
	<span>Message</span> <span>string</span>
<span>}</span>
</code></pre></div></div> <p>That is, I want parse <a href="https://github.com/kgrz/json-parsing-post/blob/master/commits.json">this response</a> into a <code>[]MetaData</code> slice. I <strong>do not</strong> want to traverse the structs in the format of the responses in my main “business logic”, as that makes it hard to follow the important bits. I don’t want to use <code>interface{}</code> as a placeholder. A better trade-off, in my opinion and use case, is to do as much as possible during the parse phase to massage the data into the structure you want<sup id="fnref:1"><a href="#fn:1">1</a></sup>. I’m positive that this is a common use case. I ended up learning one way to do this cleanly almost by accident. First, the components involved:</p> <h4 id="use-anonymous-structs">Use anonymous structs</h4> <p>Anonymous structs can be used to avoid defining a concrete type and skip giving it a name for one-off use-cases. It’s heavily used in parsing and marshalling code paths, and testing. In our case, this technique can be used to define a “dirty” struct inside the <code>UnmarshalJSON</code> function on the fly, and use that for parsing the <span>JSON</span>.</p> <h4 id="implementing-unmarshaler-interface">Implementing Unmarshaler interface</h4> <p>Any type that has a <code>UnmarshalJSON</code> function on it implements the <code>Unmarshaler</code> interface. This type then can be used as the target for parsing a <span>JSON</span> sub tree or the entire <span>JSON</span> itself!</p> <h3 id="implementation">Implementation</h3> <p>First step is to mock out the main function:</p> <div><div><pre><code><span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>// This variable contains the raw json bytes that resulted from the</span>
	<span>// API call. I'm not adding the code for the actual network fetch</span>
	<span>// for now, but in the example repository, I read the commits</span>
	<span>// response from a file</span>
	<span>var</span> <span>jsonb</span> <span>[]</span><span>byte</span>
	<span>jsonb</span> <span>=</span> <span>JSONFromSomewhere</span><span>()</span>

	<span>var</span> <span>metadatas</span> <span>[]</span><span>MetaData</span>
	<span>if</span> <span>err</span> <span>:=</span> <span>json</span><span>.</span><span>Unmarshal</span><span>(</span><span>jsonb</span><span>,</span> <span>&amp;</span><span>metadatas</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
		<span>log</span><span>.</span><span>Fatalln</span><span>(</span><span>"error parsing JSON"</span><span>,</span> <span>err</span><span>)</span>
	<span>}</span>

	<span>fmt</span><span>.</span><span>Println</span><span>(</span><span>metadatas</span><span>)</span>
<span>}</span>
</code></pre></div></div> <p>The <span>JSON</span> response of <code>/commits</code> endpoint is a list of <code>commit</code> objects, and I’m using a list of <code>MetaData</code> types to match that interface. For each commit item from the <span>JSON</span> array, the raw bytes get passed as the argument to the <code>UnmarshalJSON</code> function on <code>MetaData</code>.</p> <p>Next step is to implement the <code>UnmarshalJSON</code> function using an anonymous struct to parse out the raw commit object <span>JSON</span> string into it:</p> <div><div><pre><code><span>func</span> <span>(</span><span>m</span> <span>*</span><span>MetaData</span><span>)</span> <span>UnmarshalJSON</span><span>(</span><span>buf</span> <span>[]</span><span>byte</span><span>)</span> <span>error</span> <span>{</span>
	<span>var</span> <span>commit</span> <span>struct</span> <span>{</span>
		<span>SHA</span>    <span>string</span> <span>`json:"sha"`</span>
		<span>Commit</span> <span>struct</span> <span>{</span>
			<span>Author</span> <span>struct</span> <span>{</span>
				<span>Name</span> <span>string</span> <span>`json:"name"`</span>
			<span>}</span> <span>`json:"author"`</span>
			<span>Committer</span> <span>struct</span> <span>{</span>
				<span>Name</span> <span>string</span> <span>`json:"name"`</span>
			<span>}</span> <span>`json:"committer"`</span>
			<span>Message</span> <span>string</span> <span>`json:"message"`</span>
		<span>}</span> <span>`json:"commit"`</span>
	<span>}</span>

	<span>if</span> <span>err</span> <span>:=</span> <span>json</span><span>.</span><span>Unmarshal</span><span>(</span><span>buf</span><span>,</span> <span>&amp;</span><span>commit</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
		<span>return</span> <span>errors</span><span>.</span><span>Wrap</span><span>(</span><span>err</span><span>,</span> <span>"parsing into MetaData failed"</span><span>)</span>
	<span>}</span>

	<span>// continued</span>
<span>}</span>
</code></pre></div></div> <p>Final step is to process the <code>commit</code> struct, and set the appropriate fields on <code>MetaData</code> struct:</p> <div><div><pre><code><span>func</span> <span>(</span><span>m</span> <span>*</span><span>MetaData</span><span>)</span> <span>UnmarshalJSON</span><span>(</span><span>buf</span> <span>[]</span><span>byte</span><span>)</span> <span>error</span> <span>{</span>
	<span>// same as above</span>

	<span>m</span><span>.</span><span>AuthorName</span> <span>=</span> <span>commit</span><span>.</span><span>Commit</span><span>.</span><span>Author</span><span>.</span><span>Name</span>
	<span>m</span><span>.</span><span>CommitterName</span> <span>=</span> <span>commit</span><span>.</span><span>Commit</span><span>.</span><span>Committer</span><span>.</span><span>Name</span>
	<span>m</span><span>.</span><span>SHA</span> <span>=</span> <span>commit</span><span>.</span><span>SHA</span>
	<span>m</span><span>.</span><span>Message</span> <span>=</span> <span>commit</span><span>.</span><span>Commit</span><span>.</span><span>Message</span>

	<span>return</span> <span>nil</span>
<span>}</span>
</code></pre></div></div> <p>That’s it! An additional advantage to this type of narrow types is it’s easier to test.</p> <hr> <h3 id="bonus-filtering-the-slice-further">Bonus: Filtering the slice further</h3> <p>For bonus points, I want to skip certain <code>[]MetaData</code> elements based on a condition. A way to do this, keeping the same principles as above in mind, is to define a type that covers <code>[]MetaData</code>, which implements the <code>Unmarshaler</code> interface:</p> <div><div><pre><code><span>type</span> <span>MetaDatas</span> <span>[]</span><span>MetaData</span>

<span>func</span> <span>(</span><span>ms</span> <span>*</span><span>MetaDatas</span><span>)</span> <span>UnmarshalJSON</span><span>(</span><span>buf</span> <span>[]</span><span>byte</span><span>)</span> <span>error</span> <span>{</span>
	<span>// []MetaData is not the same as MetaDatas, and this difference is</span>
	<span>// important!</span>
	<span>var</span> <span>metadatas</span> <span>[]</span><span>MetaData</span>

	<span>if</span> <span>err</span> <span>:=</span> <span>json</span><span>.</span><span>Unmarshal</span><span>(</span><span>buf</span><span>,</span> <span>&amp;</span><span>metadatas</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
		<span>log</span><span>.</span><span>Fatalln</span><span>(</span><span>"error parsing JSON"</span><span>,</span> <span>err</span><span>)</span>
	<span>}</span>

	<span>// filtering without allocations</span>
	<span>// https://github.com/golang/go/wiki/SliceTricks#filtering-without-allocating</span>
	<span>cleanedms</span> <span>:=</span> <span>metadatas</span><span>[</span><span>:</span><span>0</span><span>]</span>
	<span>for</span> <span>_</span><span>,</span> <span>metadata</span> <span>:=</span> <span>range</span> <span>metadatas</span> <span>{</span>
		<span>if</span> <span>!</span><span>strings</span><span>.</span><span>HasPrefix</span><span>(</span><span>metadata</span><span>.</span><span>Message</span><span>,</span> <span>"WIP"</span><span>)</span> <span>{</span>
			<span>cleanedms</span> <span>=</span> <span>append</span><span>(</span><span>cleanedms</span><span>,</span> <span>metadata</span><span>)</span>
		<span>}</span>
	<span>}</span>
	<span>*</span><span>ms</span> <span>=</span> <span>cleanedms</span>

	<span>return</span> <span>nil</span>
<span>}</span>
</code></pre></div></div> <p>Like before, I’m using a temporary type of the kind that matches our main type, and using that to parse into. Then I’m clean out slice based on a condition—I want to skip all the commits that start with <code>WIP</code>. Note that the <code>metadatas</code> variable defined inside the <code>UnmarshalJSON</code> function is defined as <code>[]MetaData</code> and not as <code>MetaDatas</code>, since doing that would result in a parse-loop. By design, <code>var metadatas Metadatas</code> and <code>var metadatas []MetaData</code> are not the same type.</p> <p>Finally, the filtered slice gets assigned to the underlying object that the <span>JSON</span> is getting parsed into.</p> <hr> <h4 id="a-note-about-performance">A note about performance</h4> <p>In these examples, the parse flow will create the entire <code>[]MetaData</code> slice, even though we filter out many of the elements. To my knowledge, this seems like a necessary hit to take. I’m not aware if there’s a way to avoid allocations by pre-pre-processing the incoming bytes to avoid the allocation in the first place. My thought process here is that if we didn’t filter, or cleanup the <span>JSON</span> data, it will anyway allocate all the objects, so this may not be a huge difference in allocations per se, but that’s just my opinion at this point.</p> <hr>  </div></div>]]>
            </description>
            <link>http://kgrz.io/go-json-flatten-filter-cleaner-types.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006994</guid>
            <pubDate>Fri, 31 Jul 2020 09:15:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google removes all Danish music from YouTube]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 174 (<a href="https://news.ycombinator.com/item?id=24006932">thread link</a>) | @erk__
<br/>
July 31, 2020 | https://www.koda.dk/about-us/press-release-google-removes-all-danish-music-from-youtube | <a href="https://web.archive.org/web/*/https://www.koda.dk/about-us/press-release-google-removes-all-danish-music-from-youtube">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>   
    <p>Press Release<br>July 30, 2020</p>

<h3><strong>Google removes all Danish music from YouTube </strong></h3>
<h5>While the negotiations on a new joint Nordic agreement are in full swing, Google have chosen to leverage their total dominance in the market in the strongest way possible. On the evening of Thursday 30 July, Google announced that they will soon remove all Danish music content on YouTube.</h5>

<p>Under the auspices of the Nordic alliance of collecting societies, Polaris, negotiations on a joint Nordic agreement on the use of music on YouTube are currently in full swing. The agreement will replace the local agreements of the Norwegian, Finnish and Danish composers and songwriters’ societies, combining them in a single, joint agreement with Google. In the case of Koda, the national agreement for Denmark expired in April, after which it was temporarily extended – as is standard practice in the industry while negotiating a new agreement.</p>
<p>Now, however, Google have issued a new demand: if the agreement is to be temporarily extended, Koda must agree to reduce the payment provided to composers and songwriters for YouTube’s use of music by almost 70% – despite the fact that YouTube’s use of music has increased significantly since Koda entered into its last agreement with Google.</p>
<p>Of course, Koda cannot accept these terms, and Google have now unilaterally decided that Koda’s members cannot have their content shown on YouTube and that their fans and users on YouTube will be unable to listen to Koda members’ music until a new agreement is in place.</p>
<p>Although the parties involved in the negotiations on the new joint agreement are by no means in concord yet, progress has been made in recent weeks, and Koda is puzzled by the extremely aggressive approach taken by Google in the negotiations this time.</p>
<h5><strong>Koda’s media director, Kaare Struve, says:</strong></h5>
<p>‘Google have always taken an “our way or the highway” approach, but even for Google, this is a low point. Of course, Google know that they can create enormous frustration among our members by denying them access to YouTube – and among the many Danes who use YouTube every day. We can only suppose that by doing so, YouTube hope to be able to push through an agreement, one where they alone dictate all terms’.</p>
<p>Ever since the first agreement was signed in 2013, the level of payments received from YouTube has been significantly lower than the level of payment agreed to by subscription-based services.</p>
<h5><strong>Koda’s CEO, Gorm Arildsen, says:</strong></h5>
<p>‘It is no secret that our members have been very dissatisfied with the level of payment received for the use of their music on YouTube for many years now. And it’s no secret that we at Koda have actively advocated putting an end to the tech giants’ free-ride approach and underpayment for artistic content in connection with the EU’s new Copyright Directive. The fact that Google now demands that the payments due from them should be reduced by almost 70% in connection with a temporary contract extension seems quite bizarre’.</p>
<p><strong>Media contact</strong>&nbsp;<br>Head of Communications Eva Hein /<span>&nbsp;</span><a href="mailto:eh@koda.dk">eh@koda.dk</a><span>&nbsp;</span>/ (+45) 61893233</p>
</div>
 </div></div>]]>
            </description>
            <link>https://www.koda.dk/about-us/press-release-google-removes-all-danish-music-from-youtube</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006932</guid>
            <pubDate>Fri, 31 Jul 2020 08:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[High Output Founder's Library]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006686">thread link</a>) | @sandGorgon
<br/>
July 31, 2020 | https://www.notion.so/High-Output-Founders-Library-48742928f9f149b8a777e11a1409ce0a | <a href="https://web.archive.org/web/*/https://www.notion.so/High-Output-Founders-Library-48742928f9f149b8a777e11a1409ce0a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/High-Output-Founders-Library-48742928f9f149b8a777e11a1409ce0a</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006686</guid>
            <pubDate>Fri, 31 Jul 2020 08:04:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signs of a Bad Outsource Contractor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006632">thread link</a>) | @ProArea
<br/>
July 31, 2020 | https://proarea.co/blog/6-signs-of-a-bad-outsource-contractor/ | <a href="https://web.archive.org/web/*/https://proarea.co/blog/6-signs-of-a-bad-outsource-contractor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span><span>H</span>ow to differ a bad contractor from a good partner?</span> There can be many advantages of working by the outsourced model, but also a lot of risks. Finding a good partner is difficult, but it is an ambitious and necessary task. We wrote this article to <span>differ</span> it from a bad and irresponsible contractor. What kind of mistakes do contractors make, so it`s not worth working with them?</p>
<h3><b>SIGN #1 WORK OF THE TEAM IS NOT VISIBLE</b></h3>
<p><span>The manager assured that the team was working and would show the result “in the nearest future”, and after weeks of work, it wasn`t clear what the result of the project is and whether work is underway.</span></p>
<p><span>How it is needed:</span></p>
<p><span>Use the Scrum project management methodology:</span></p>
<p><span>✓ Carry out daily calls where show the status of the tasks</span></p>
<p><span>✓ Make the result demonstration each sprint (2 weeks)</span></p>
<p><span>✓ Analyze the results of each sprint</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ You see not only the final result but also understand the progress along with the sprint</span></p>
<p><span>✓ You see delays and problems on time and keep your finger on the pulse</span></p>
<h3><b>SIGN </b><b>#2 DOUBTFUL CODE QUALITY</b></h3>
<p><span>In a rush, programmers write low-quality code that cannot be supported. Because of this, in the future, it will be necessary to rewrite the system from scratch or it will not perform the necessary tasks and functions at all. </span><span>The system may run slowly due to poor-quality and unstructured code, so it will be extremely difficult and expensive to finalize a new module.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Make and show a code quality assessment using special programs – professional tools for analysis</span></p>
<p><span>✓ Work on git-flow, where some programmers check others to avoid mistakes</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ You don’t need to overpay for alterations</span></p>
<p><span>✓ You get a working system that is easy to refine and scale</span></p>
<p><span>✓ Other programmers and teams can easily work with the code</span></p>
<h3><img src="https://proarea.co/blog/wp-content/uploads/2020/06/2.png" alt="Подрядчик в IT" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/06/2.png 800w, https://proarea.co/blog/wp-content/uploads/2020/06/2-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/06/2-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"></h3>
<h3><b>SING #3 NO DEEP UNDERSTANDING OF THE PROJECT</b></h3>
<p><span>The contractor simply performs the task pool, not wanting to delve into the subtleties of the project and study it. </span><span>Developers just write the code the way they understand the task.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Make a competitor analysis and study successful counterparts in the market to understand trends and delve deeply into the project</span></p>
<p><span>✓ Fix errors and improve the system along the way, playing the role of business analysts</span></p>
<p><span>✓ Developers write code, taking into account business requirements, think about creating a product that will be interesting and convenient for the user</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ The contractor isn’t just “hands” that build, but also a “head” that will find and come up with the best solution</span></p>
<h3><b>SING #4 JUST THE VISIBILITY OF WORK, MANY EXTRA MOVEMENTS</b></h3>
<p><span>The team creates the appearance of work – constantly there are new documents with a description, new work files. </span><span>The code is simply written just for fact and over time it turns out that the functions aren’t logical, inconvenient, or impossible to use. </span><span>Business doesn’t get results – a system that can be used.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Iteratively create a finished product that can be used after the first sprints</span></p>
<p><span>✓ Instead of 20 sheets of documentation, make one prototype and clearly show how the new module will work</span></p>
<p><span>✓ Don’t just write code but offer a solution for business – work functions that are needed</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ You get the result – a system that you can use&nbsp;</span></p>
<p><span>✓ Save time and money</span></p>
<h3><b>SING</b><b> #5 DON`T CARE ABOUT DESIGN</b></h3>
<p><span>Bad contractors focus only on functionality and don’t consider design as an important stage in product development and as a tool to achieve project goals. </span><span>Don’t reuse logic/components from already developed system modules. </span><span>Don’t use a design system – a unified style and approach to project design.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Follow the best solutions of modern UI/UX design with care for the user</span></p>
<p><span>✓ Don’t just develop functionality to the level of “everything works fine”, but make a big emphasis on the visual part to the level of “comfortable and beautiful”</span></p>
<p><span>✓ Use ready-made solutions and components from already completed system modules</span></p>
<p><span>✓ Use the design system and templates in the design to speed up the work and improve its quality</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ Time for design and engineering is allocated as efficiently as possible</span></p>
<p><span>✓ Users get a product that looks like they want to use it all the time – all because it has a responsive, understandable, convenient, inspirational design!</span></p>
<h3><img src="https://proarea.co/blog/wp-content/uploads/2020/06/1.png" alt="IT аутсорс подрядчик" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/06/1.png 800w, https://proarea.co/blog/wp-content/uploads/2020/06/1-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/06/1-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"><b></b></h3>
<h3><b>SING</b><b> #6 GO TO NEW FUNCTIONS WITHOUT COMPLETING PREVIOUS</b></h3>
<p><span>For your product, you have conceived many functions that are described in the specifications for the contractor. He began developing all the functions at once but didn’t complete any of them properly. Six months later, all the modules are “almost ready” but none can be used.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Give the revised functions – correctly working modules that take into account all the scenarios. Screens are correctly displayed on all devices and all operating systems. Pages correctly show information, even if there is no data, there is no Internet or the user entered an incorrect value</span></p>
<p><span>✓ Develop all functions in stages, bringing them to the desired result – a modified functional that you can use</span></p>
<p><span>✓ Pass to the new task only after the previous one is fully completed</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ You see how your product is formed – gradually, but with visible results</span></p>
<p><span>✓ You get working functions after the end of the current sprints, and not at the very end of the project when it turns out that something remains unfinished</span></p>
<p>We think you have found at least a couple of matches with the work of your current or ex contractor. Their mistakes and lack of professionalism can cost you the success of the entire project, so we advise you to carefully choose the company to which you are ready to entrust your business. We try to follow the principles described in the paragraphs “how it is needed”, taking care of you and the end-users of your product. Speaking of the importance of outsourcing, <span><a href="https://www.forbes.com/sites/forbesbusinesscouncil/2020/07/08/why-its-important-to-outsource-right-now/#a0dbea670e9a">Forbes wrote an excellent article</a>.</span></p>
<p>The next step after choosing a contractor will be writing a statement of work (SOW or specifications). In our article <span><a href="https://proarea.co/blog/how-to-make-correct-requirement-specifications/">“How to make correct requirement specifications”</a></span>, we have written everything you need to consider. Good luck with implementing your ambitious ideas!</p>

        
    </div></div>]]>
            </description>
            <link>https://proarea.co/blog/6-signs-of-a-bad-outsource-contractor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006632</guid>
            <pubDate>Fri, 31 Jul 2020 07:51:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adopting Kubernetes for Your Business IT Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006613">thread link</a>) | @techgiant_guy
<br/>
July 31, 2020 | https://l1n.com/adopting-kubernetes-for-your-business-it-infrastructure/ | <a href="https://web.archive.org/web/*/https://l1n.com/adopting-kubernetes-for-your-business-it-infrastructure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
		<div>
			<p><span>In this era of competition, the demand from app users is getting bigger and bigger every day. Businesses are bound to offer applications with incredible quality and which can satisfy customers on various fronts of the business. Today every large enterprise is worried about its business IT infrastructure that requires supporting such high-end apps that are advanced concerning cost, capability, security, scalability, and offers customization. This is where Kubernetes comes into the space of </span><strong><a href="https://l1n.com/cloud-computing/">cloud computing services</a>. </strong></p>
<p><b>Now you must be thinking:</b></p>
<h2><b>What is Kubernetes?</b></h2>
<p><span>An </span><span>open-source </span><span>system that divides workload through </span><span>an orchestration technique and </span><span>apps for servers that gather round in a data center is Kubernetes.</span></p>
<h2><b>What is the </b><b>Kubernetes advantage</b><b>?</b></h2>
<p><span>Over the years </span><span>Kubernetes capabilities for enterprises </span><span>have been witnessed by successful project accomplishments. It assists applications to be more functional, flexible and saves your hard-earned money as it requires lesser workforces for managing IT.</span></p>
<p><span>Kubernetes is a Google product that is a part of the </span><span>Cloud Native Computing Foundation (CNFC). CNFC brings along with itself strong engrossment and contribution from several organizations (small and large). </span></p>
<h2><b>Why Kubernetes Should Be Your Next Infrastructure</b><b>?</b></h2>
<p><span>If you are planning to take on Kubernetes for the growth of your business then you need to know its fundamental business capacities and reasons as to why it is being adopted by enterprises.</span></p>
<p><span>Let’s focus on </span><b>why enterprises prefer Kubernetes for their business IT infrastructure?</b></p>
<h3><b>Ensures Enhanced Scalability and Availability</b></h3>
<p><span>App success doesn’t depend just on its features but scalability determines the success of a particular app. Kubernetes being an orchestration system is a crucial management system to scale and enhance app performance automatically.&nbsp;Kubernetes auto-scaling is not only limited to infrastructure metrics but to custom metrics and all kinds of metric or resource usage metrics can be employed to boost the scaling procedure.</span></p>
<h3><b>Excellent for Businesses</b></h3>
<p><span>The world is incomplete without software and application development is the elementary tool for business development. </span></p>
<p><img src="https://l1n.com/wp-content/uploads/2020/07/image1.png" alt="" width="626" height="397" srcset="https://l1n.com/wp-content/uploads/2020/07/image1.png 626w, https://l1n.com/wp-content/uploads/2020/07/image1-300x190.png 300w" sizes="(max-width: 626px) 100vw, 626px"></p>
<p><span>Improving the quality of apps is a way to win many customers as reported by some of the organizations. Kubernetes directly contributes to these enhancements, with improved resource usage and reduced development cycles as reported by 53% of respondents. They are having more out of every penny spent and are building software faster than ever.</span></p>
<h3><b>Kubernetes Aids in IT Cost Optimization</b></h3>
<p><span>Kubernetes helps in reducing business infrastructure costs and can prove to be of great help for your vast scale business. It is highly competent in putting apps together which assists in optimal utilization of your cloud investments and hardware which in turn improves container-based architecture more conveniently.</span></p>
<h3><b>Solution for the Future</b></h3>
<p><b>Kubernetes is a convenient solution for many reasons like:</b></p>
<ul>
<li><span>Every prime cloud vendor is backing Kubernetes for its offering various unusual solutions for it.</span></li>
<li><span>Many other container orchestration solutions&nbsp;also support the same in terms of adoption, cloud vendors’ support, and ecosystem.</span></li>
</ul>
<h3><b>Supports Your Application Run More Stable</b></h3>
<p><span>K8s can help you out if you are looking to check whether your app is running steadily or not. What it does is that it permits you to get rolling updates to modify your software with no prevention. K8s can further be set up in such a manner that it assists in highly accessible apps.&nbsp;</span></p>
<h3><b>Highly Economical When Compared to Other Solutions</b></h3>
<p><span>Based on your application requirements, incoming traffic and load by your app Kubernetes can easily auto-scale. With auto-scaling features during the hectic times of the year, a particular app can scale up its needed resources. This in turn will automatically reduce your infrastructure during the less loaded times of the year.&nbsp;</span></p>
<h3><b>Assists In Effective and Smooth Migration to the Cloud</b></h3>
<p><span>Kubernetes is an ideal solution whether you are thinking to re-host, re-platform, and re-factory. As K8s </span><span>runs constantly across every environment, clouds like&nbsp;AWS, Azure, GCP, and on-premise it paves the way for porting your app on-premise to </span><span>cloud hosting services</span><span>&nbsp;</span><span>smoothly.</span></p>
<h3><b>Help You Boost up Your Productivity</b></h3>
<p><span>You can attain the highest level of productivity if Kubernetes is well-executed into your engineering workflow. Drone and other such tools support making CI/CD pipelines swiftly and </span><strong><a href="https://github.com/prometheus/prometheus" rel="nofollow">Prometheus</a></strong><span> makes the monitoring process easier.&nbsp;Everything is tailored precisely as per your needs with K8s massive array of technologies. Kubernetes ecosystem offers the maximum of its tools free to be used and are open-source which is a big add on benefit.</span></p>
<h3><b>Kubernetes Cloud-native Tech Stack Attracts Talents</b></h3>
<p><img src="https://l1n.com/wp-content/uploads/2020/07/image2.png" alt="" width="886" height="539" srcset="https://l1n.com/wp-content/uploads/2020/07/image2.png 886w, https://l1n.com/wp-content/uploads/2020/07/image2-300x183.png 300w, https://l1n.com/wp-content/uploads/2020/07/image2-768x467.png 768w" sizes="(max-width: 886px) 100vw, 886px"></p>
<p><span>According to reports by </span><strong><a href="https://insights.stackoverflow.com/survey/2019#most-loved-dreaded-and-wanted" rel="nofollow">Stack Overflow Developer Survey 2019</a></strong><span>, Kubernetes is ranked 3</span><span>rd</span><span> and is the most preferred platform to work on. Many software engineers demand to work in companies that deploy cutting-edge technologies.</span></p>
<p><span>Your technology stack and procedures can be very attractive with an integrated and effective workflow for possible candidates. Also, your present workforce will get inspired to work on new technology which boosts the contentment in your development teams and can reduce member turnover in the future. In short, it’s a material benefit for your company.</span></p>
<h2><b>Future of Kubernetes….</b></h2>
<p><span>Kubernetes is on the verge of rising performance at present because organizations are deploying Kubernetes and due to the development of mobile apps. This is just the commencement of the new ways to adhere to the edge computing, </span><span>managed cloud hosting services</span><span>, and </span><span>machine-learning. Kubernetes is doing a marvelous job in transforming the world and it has a long way to go.</span></p>
<p><span>The above-given piece of content suffices all the questions you had regarding implementing Kubernetes. Finally, it all depends on your specific needs and priorities whether you wish to deploy it or not.&nbsp;</span></p>
<p><a href="https://l1n.com/"><span>Layer One Networks</span></a><span> can be your best </span><span>cloud computing services</span><span> partner with well-</span><span>managed cloud hosting services</span><span>.</span></p>
<p><span>Reach out for any of your Cloud Computing needs on <a href="about:blank">361.653.6800</a>.</span></p>
<p><span>Happy Reading!!</span></p>

		</div><!-- .entry-content -->

		<!-- .entry-footer -->

					</div></div>]]>
            </description>
            <link>https://l1n.com/adopting-kubernetes-for-your-business-it-infrastructure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006613</guid>
            <pubDate>Fri, 31 Jul 2020 07:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to make correct Requirement Specifications]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006519">thread link</a>) | @ProArea
<br/>
July 31, 2020 | https://proarea.co/blog/how-to-make-correct-requirement-specifications/ | <a href="https://web.archive.org/web/*/https://proarea.co/blog/how-to-make-correct-requirement-specifications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span><span>R</span>equirement specifications are the main project document, describing all its technical and non-technical issues. Any of your ideas are just ideas until specifications developed. In this article, we will explain why this document is so important, when it`s correct to begin development and what exactly it should contain.</span></p>
<h3><b>WHY YOU NEED REQUIREMENT SPECIFICATIONS</b></h3>
<p><span>If you don’t describe the expected result, don`t formulate a clear task and project requirements, you will:&nbsp;</span></p>
<ul>
<li><span>overpay for work and edits;&nbsp;</span></li>
<li><span>waste time;</span></li>
<li><span>get not at all what you want and again overpay for edits;</span></li>
<li><span>close the project due to the fact that there are no more resources for corrections.</span></li>
</ul>
<p><span>And in order to prevent this, it is important to write requirement specifications. In order for the team to understand specific tasks and be able to implement them so that the expectation and the final product result coincide.</span></p>
<h3><strong>THE SPECIFICATIONS` ROLE IN DIFFERENT PROJECT STAGES</strong></h3>
<ol>
<li><span><b> Formation of business requirements</b></span></li>
</ol>
<p><span>This is the foundation for project implementation. At this stage goals and budgets are set. Here the requirement development begins because it determines the future product success. All further work on specifications should be based on business requirements.</span></p>
<ol start="2">
<li><span><b> MVP development</b></span></li>
</ol>
<p><span>It’s almost impossible to build the perfect product on the first try. In any case, it will change based on the feedback of the market and users. Therefore, it is logical to start with MVP – the minimum viable product. For the development of MVP, </span><span>specifications</span><span> are as important as for the development of the main product. At this stage, the </span><span>specifications</span><span> task defines:</span></p>
<ul>
<li><span>basic functions and user interface needed to test a hypothesis;</span></li>
<li><span>criteria necessary for understanding the success of the implementation and launch of the first product version on the market.</span></li>
</ul>
<p><span>So, </span><span>specifications</span><span> at the MVP development stage describe which functions are needed and how it is necessary (minimal and sufficient) to implement in order to test the hypothesis.</span></p>
<p><img src="https://proarea.co/blog/wp-content/uploads/2020/06/rlprkv.png" alt="requirement specifications" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/06/rlprkv.png 800w, https://proarea.co/blog/wp-content/uploads/2020/06/rlprkv-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/06/rlprkv-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"></p>
<ol start="3">
<li><span><b> Main product development</b></span></li>
</ol>
<p><span>After the successful launch of MVP, </span><span>requirements</span><span> for the main product are finalized based on the results: a positive market reaction, as confirmation that the business model is working. That is necessary to take into account and describe in </span><span>specifications</span><span>, we wrote in detail in the 3rd section of this document. At this stage, </span><span>requirements </span><span>play a crucial role:</span></p>
<ul>
<li><span>take into account market features (business opportunities, necessary budgets, target audience);</span></li>
<li><span>define the project objectives;</span></li>
<li><span>demonstrate use cases;</span></li>
<li><span>captures functional, non-functional, and technical requirements so that the product is properly designed.&nbsp;</span></li>
</ul>
<p><span>At this stage, </span><span>specifications</span><span> are a complete guide to action, completely describing all important points, starting from a business analysis of the market and target audience, ending with colors, fonts, and other details.</span></p>
<ol start="4">
<li><span><b> Marketing promotion</b></span></li>
</ol>
<p><span>In good </span><span>specifications,</span><span> there is a place for market research, competitors, communication channels with potential users, and resources for promotion. Marketing promotion is the logical and necessary project support at the start and after it. If you don’t initially plan marketing activity, you probably won’t take into account the resources (in particular, the money) needed for a confident release. You run the risk of being left completely without promotion since the main resources will go to development. So, without the described marketing, you can confront a lot of problems:</span></p>
<ul>
<li><span>lack of promotion resources;</span></li>
<li><span>lack of understanding of the market and its users;</span></li>
<li><span>failure to provide your product benefits to the audience;</span></li>
<li><span>and as a result – market failure.</span></li>
</ul>
<p><span>At this stage, </span><span>specifications</span><span> are the answer to the question “what to do after the release?”</span></p>
<p><img src="https://proarea.co/blog/wp-content/uploads/2020/02/fke2.png" alt="requirement specifications" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/02/fke2.png 800w, https://proarea.co/blog/wp-content/uploads/2020/02/fke2-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/02/fke2-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"></p>
<h3><strong>WHAT IS IMPORTANT TO ACCOUNT AND DESCRIBE IN SPECIFICATIONS</strong></h3>
<ol>
<li><span><b> Describe a problem</b></span></li>
</ol>
<ul>
<li><span>Why does the market need a product?</span></li>
<li><span>Whose and what problem does it solve?</span></li>
<li><span>What tasks should the product solve?</span></li>
</ul>
<ol start="2">
<li><span><b> Determine personal goals</b></span></li>
</ol>
<ul>
<li><span>Why do I need this in the long term?</span></li>
<li><span>Why do I need this in the short term?</span></li>
</ul>
<ol start="3">
<li><span><b> Describe a business model</b></span></li>
</ol>
<ul>
<li><span>Who is our target audience?</span></li>
<li><span>What is a client portrait?</span></li>
<li><span>Where to find a target audience, through which sales channels?</span></li>
<li><span>What are the communication channels with the client?</span></li>
<li><span>Who are the key competitors? What are their advantages and USP?</span></li>
<li><span>What are our value propositions?</span></li>
<li><span>What is our USP?</span></li>
<li><span>What are the product advantages?</span></li>
<li><span>What key actions do we need to perform?</span></li>
<li><span>What key resources do we need?</span></li>
<li><span>Who are our key partners?</span></li>
<li><span>What are the risks?</span></li>
</ul>
<ol start="4">
<li><span><b> Form a financial model</b></span></li>
</ol>
<ul>
<li><span>What will be the main costs?</span></li>
<li><span>What will be the main sources of income?</span></li>
<li><span>Calculate the breakeven point (optimistic, real, and pessimistic forecast).</span></li>
</ul>
<ol start="5">
<li><span><b> Describe use cases</b></span></li>
</ol>
<ul>
<li><span>Describe users by groups. For example, administrator, manager, financier, operator, driver, etc.</span></li>
<li><span>What is the use case for each group?</span></li>
<li><span>What are the features and limitations of each of these roles?</span></li>
</ul>
<ol start="6">
<li><b><span> Describe Functional / Technical requirements</span></b></li>
</ol>
<ul>
<li><span>What key target action should the user make?</span></li>
<li><span>What features need to be implemented?</span></li>
<li><span>Do you need integration with third-party services?</span></li>
<li><span>How many and what languages are needed?</span></li>
<li><span>What operating systems, browsers and their versions need to be supported?</span></li>
<li><span>What are the technology preferences for development?</span></li>
<li><span>Are there any additional requirements for safety or personal data security?</span></li>
<li><span>What legislative framework should be taken into account? For example, RGPR.</span></li>
</ul>
<ol start="7">
<li><span><b> Describe Non-Functional requirements</b></span></li>
</ol>
<ul>
<li><span>How should the product look like?</span></li>
<li><span>What screens are needed in the product, what is displayed on each of them?</span></li>
<li><span>How does each screen change in different states (there is the Internet, there is data to display, there is no data to display, an error has occurred on the server, etc.)?</span></li>
</ul>
<p><img src="https://proarea.co/blog/wp-content/uploads/2020/06/art1.png" alt="Project wireframes and flow" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/06/art1.png 800w, https://proarea.co/blog/wp-content/uploads/2020/06/art1-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/06/art1-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><span>The ideal picture is described above, which is not always needed and feasible. Depending on your goals, project size, and product complexity, some points may be skipped. <span>The main thing is to answer all the questions that are important for the project and document it at the requirement specifications. Then, you will be sure that you are moving in the right direction at all stages of development.</span></span></p>
<p><span>If you don’t have specifications or you are not sure about the current ones, we can develop it for you, just contact us using the button below. We also recommend <span><a href="https://proarea.co/blog/make-pop-ups-which-don-t-enragethe-whole-world-is-in-our-smartphones-modern-types-of-mobile-apps/">our article about application types</a></span> and <span><a href="https://proarea.co/blog/when-does-business-need-a-mobile-app/">when and why a business may need a mobile application</a></span>.</span></p>

        
    </div></div>]]>
            </description>
            <link>https://proarea.co/blog/how-to-make-correct-requirement-specifications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006519</guid>
            <pubDate>Fri, 31 Jul 2020 07:30:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS: Refactor a distributed monolith to microservices with Event Bridge and BASE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006410">thread link</a>) | @rehanvdm
<br/>
July 31, 2020 | https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html | <a href="https://web.archive.org/web/*/https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<ul><li><a data-class="popup" data-network="facebook" href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Fwww.rehanvdm.com%2Fserverless%2Frefactoring-a-distributed-monolith-to-microservices%2Findex.html" target="_blank" rel="nofollow"><i></i> </a></li><li><a data-class="popup" data-network="twitter" href="https://twitter.com/intent/tweet?text=Refactoring%20a%20distributed%20monolith%20to%20microservices&amp;url=http%3A%2F%2Fwww.rehanvdm.com%2Fserverless%2Frefactoring-a-distributed-monolith-to-microservices%2Findex.html&amp;via=der_rehan" target="_blank" rel="nofollow"><i></i> </a></li><li><a data-class="popup" data-network="linkedin" href="https://linkedin.com/shareArticle?mini=true&amp;url=http%3A%2F%2Fwww.rehanvdm.com%2Fserverless%2Frefactoring-a-distributed-monolith-to-microservices%2Findex.html&amp;title=Refactoring+a+distributed+monolith+to+microservices" target="_blank" rel="nofollow"><i></i> </a></li></ul>




<p>This article documents the thought process and steps involved in refactoring a distributed monolith to microservices. We are going to remove API GW, use Amazon Event Bridge and implement BASE consistency in the system to truly decouple our microservices.</p>



<p><em>This blog is also available as a presentation. Reach out
if you would like me to present it at an event. </em></p>



<p>I will use the codebase from the previous installment to the series that can be found <a rel="noreferrer noopener" aria-label="here (opens in a new tab)" href="https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html" target="_blank">here</a>. The first part focuses on creating the codebase and implementing AWS native observability, monitoring and alerting services. As always you can find the code that we used in the respective GitHub repositories over here: <a rel="noreferrer noopener" href="https://github.com/rehanvdm/MicroService" target="_blank">https://github.com/rehanvdm/MicroService</a>.</p>



<h2>Original System</h2>



<p>The <a rel="noreferrer noopener" aria-label="original system (opens in a new tab)" href="https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html" target="_blank">original system</a> is a distributed monolith that consists of three microservices. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture-1024x715.png" alt="" width="1024" height="715" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture-1024x715.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture-300x210.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture-768x536.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture.png 1111w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Original system (Click to enlarge)</figcaption></figure>



<p>Within each project you can find an <strong>OpenAPI </strong>(<a rel="noreferrer noopener" href="https://github.com/rehanvdm/MicroServicePerson/blob/master/part1/src/lambda/api/api-definition.yaml" target="_blank">part2/src/lambda/api/api-definition.yaml</a>) file that defines the API definition for each service.<strong> AWS CDK</strong> is used and they all follow the similar stock standard CDK project layout: Typescript for the CDK and <strong>ES6 JS</strong> for the application code. NPM commands have been written to do deployments and it also contains<strong> end-to-end tests </strong>using Mocha and Chai. In addition, each service contains a detailed README inside the /part2 path. Note that I only have a single Lambda for the API endpoint and do internal routing. Yes, I believe in a <strong>Lambalith for the API</strong> 😊 and also prefer JSON POST over REST (more about this later). </p>



<p>A <strong>problem </strong>arises as soon as these microservices start to call one another. We will focus on the creation of a new person to demonstrate how this <strong>tight coupling</strong> is working. </p>



<p>The client service stores clients and has basic <em>create-client</em> and <em>find-client</em> functionalities as well as an endpoint to increment the person count for a specific client. The person service also has basic <em>create-person</em> and <em>find-person</em> endpoints. When a person is created, it calls the common service which notifies me by email about the new person that was added using an SNS subscription. The common service first needs to do a lookup on the client service so that it can enrich the email. It also increments the counter on the client. Click on the image below to see the step-by-step path for creating a person:</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus-1024x553.png" alt="" width="1024" height="553" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus-1024x553.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus-300x162.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus-768x415.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus.png 1442w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>Original system – full create person flow (Click to enlarge) </figcaption></figure>



<p>The <em>create-person</em> call is highly dependent on the common service and does not even know that the common service is dependent on the client service. As a result, the person service is also dragged down if either the common or the client service is down. Not to mention that it now has to wait for the completion of every step in the synchronous chain. This wastes money and increases the probability of hitting the API Gateway timeout of 29 seconds.</p>



<h2>Decoupling with Amazon Event Bridge</h2>



<p>Amazon Event Bridge is a serverless event bus that makes it easy to work with <strong>event-driven architectures</strong>. It works on a basic <strong>publish and subscribe</strong> model. We use it to emit certain events like: <em>person-created </em>and <em>client-created.</em> Other services can then listen to only the events that they want and act on it. The new system is refactored to incorporate this and remove the direct HTTP API calls between services. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge-1024x522.png" alt="" width="1024" height="522" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge-1024x522.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge-300x153.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge-768x391.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge.png 1531w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system (Click to enlarge)  </figcaption></figure>



<p>The <strong>client service</strong> has not changed much. It is still
fronted with API Gateway (GW). It now emits an event onto the bus whenever a
client is created. A new Lambda function is added that listens to the <em>create-person</em> events. This increments the person counter for that specific client.
This feature was previously on the common service but has now moved to the
client service.</p>



<p>The <strong>person service</strong> is working exactly as before. Just
like the client service, it also emits an event onto the event bus,
specifically the <em>create-person</em> event.</p>



<p>The <strong>common service</strong> no longer needs to be fronted by
API GW. Instead it listens to both the <em>create-client</em> and <em>create-person</em>
events. The common service stores the client data in its own DynamoDB table. It
uses this to look the client up within itself (locally), rather than calling an
HTTP API to get the data for a specific client. The common service still sends
an email when a new person is added. </p>



<p>From an <strong>external integration point of view</strong>, all API endpoints stayed exactly the same. The diagrams below clearly illustrate that each service is only concerned with its own data and responsibilities. The event that is emitted onto the bus is also added for convenience.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson-1024x711.png" alt="" width="1024" height="711" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson-1024x711.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson-300x208.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson-768x533.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson.png 1539w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system – partial create person flow (Click to enlarge) </figcaption></figure>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient-1024x715.png" alt="" width="1024" height="715" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient-1024x715.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient-300x209.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient-768x536.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient.png 1522w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system – partial client person flow (Click to enlarge)  </figcaption></figure>



<p><strong>Internally</strong> the common service has an Event Bridge Rule with the Lambda function as target. It listens to the <em>create-client</em> events and then stores only the client-id and client name fields within its own DynamoDB table. This <strong>removes the need for it to do an HTTP API call</strong> to the client service as it can now just do the lookup locally against its own data store.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient-1024x529.png" alt="" width="1024" height="529" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient-1024x529.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient-300x155.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient-768x397.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system – full create client flow (Click to enlarge)  </figcaption></figure>



<p>The common service also listens to the <em>create-person</em> event. It <strong>looks up the client information in its own DynamoDB table</strong> and then sends the SNS message. <strong>At the same time</strong>, the client service also listens to the <em>create-person</em> events. It uses the client-id that comes with the event to increment the person counter for that specific client in the client service DynamoDB table. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson-1024x522.png" alt="" width="1024" height="522" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson-1024x522.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson-300x153.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson-768x391.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system – full create person flow (Click to enlarge)   </figcaption></figure>



<h2>What has changed?</h2>



<p>We used Event Bridge to<strong> remove direct HTTP API calls</strong> between microservices. It also allowed us to <strong>move some logic</strong> to where it belongs. The common service should not be responsible to increment the specific client’s person counter in the first place. That functionality is now contained within the client service, where it belongs. </p>



<p>We basically borrowed two principles from the <strong>SOLID OOP principles</strong>: </p>



<ul><li>Single Responsibility – Each service is only concerned with its own core functionality.</li><li>Open Closed – Each service is now open for extension, but the core functionality is closed for modification.</li></ul>







<p>Then we introduced <strong>BASE consistency</strong> into the system: </p>



<ul><li><strong>B</strong>asic <strong>A</strong>vailability – Even if the client service is down the common service can still operate as it has a copy of the data. Thus the data layer/plane is still operational.</li><li><strong>S</strong>oft State – Stores don’t have to be write-consistent or mutually consistent all the time.</li><li><strong>E</strong>ventual Consistency – The system will become consistent over time, given that the system doesn’t receive input during that time.</li></ul>







<p>A BASE system is almost always going to be an <strong>AP system</strong> if you look at the CAP theorem. Meaning it favors <strong>A</strong>vailability and <strong>P</strong>artitioning over <strong>C</strong>onsistency. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP.png" alt="" width="966" height="683" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP.png 966w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP-300x212.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP-768x543.png 768w" sizes="(max-width: 966px) 100vw, 966px"></a><figcaption>CAP theorem applied to Databases (Click to enlarge)</figcaption></figure>



<p><strong>DynamoDB </strong>is an example of an <strong>AP system</strong> as well. Your data is stored on multiple 10GB partition drives spread over multiple Availability Zones. That replication takes a few milliseconds, up to a second or two. Obviously, there are cases where you need to read the data back directly after writing. That is why you can specify a Strongly Consistent read, which just goes back to the writer node and queries the data there instead of waiting for the data to have propagated to all nodes. </p>



<p><strong>S3 </strong>has <strong>read-after-write consistency for the PUT item</strong> command but all <strong>other commands are subject to eventual consistency.</strong> This means that after updating an item, the old content may still be returned for a short amount of time until the content of that file has propagated to all the storage nodes. There are more examples such as these all over the AWS ecosystem.</p>



<p>Event-driven architectures come with their own <strong>pros and cons</strong>. Firstly, you need to <strong>approach the problem with a different distributed mindset</strong> that needs to be present within the company/team as well. Event <strong>versioning and communication</strong> between teams that own microservices are also crucial. It is a good idea to have a service that keeps a <strong>ledger of all events that happen</strong> in the system. Worst case, this history of events can be replayed to fix any processing errors in the downstream processing. </p>



<p>Event bridge, like SNS and SQS, guarantees delivery of a message at least once. This means your <strong>system needs to be idempotent</strong>. An example of an idempotent flow is when the client is created and the common service does a PUT command into the DynamoDB table. If that event gets delivered more than once, it just overwrites the current client with the exact same data.</p>



<p>An example of a non-idempotent flow is when the person is
created. If the client service gets more than one message, it increments the
client-person counter more than once. There are ways to make this call
idempotent, but we’ll leave that for a different blog. </p>



<p>Another thing to consider is that not all systems can accept the delay that eventual consistency introduces into a system. It is perfectly acceptable in our system as a person will probably not be created immediately within one second after a client has been created. Thus, whenever the common service does the client lookup locally, it can be assured that the client data is always populated. </p>



<h2>Resilience to Failure</h2>



<p>One of the benefits that we have achieved by refactoring to a microservice system is that we are now r<strong>esilient to complete services failure</strong>. The client service can still operate if the person and common service is down. Similarly, the person service can operate on its own and is not dependent on the other services.</p>



<p>We also <strong>removed any timeout problems that was introduced</strong> by the previous architecture that synchronously chained API calls. If an Event Bridge target service (like Lambda, in our case) is down, it will retry sending the message with exponential bakeoff for up to 24 hours. </p>



<p>All Lambda functions that process the asynchronous events from Event Bridge have <strong>Dead Letter Queues</strong> (DLQ) …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html">https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html</a></em></p>]]>
            </description>
            <link>https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006410</guid>
            <pubDate>Fri, 31 Jul 2020 07:07:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No-Cloning Theorem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006297">thread link</a>) | @keyboardman
<br/>
July 30, 2020 | https://leimao.github.io/blog/No-Cloning-Theorem/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/No-Cloning-Theorem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In the classical world, it is quite common that we could make an exactly the same copy of something. However, in the quantum world, the laws of physics impose a severe restriction on copying: It is impossible to make a perfect copy of an unknown state.</p>



<p>In this blog post, I would like to discuss the No-Cloning Theorem in quantum theory.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="kronecker-product-inverse-transpose-property">Kronecker Product Inverse-Transpose Property</h4>

<p>Conjugate transposition are distributive over the Kronecker product:</p>





<p>This concludes the proof.</p>

<h4 id="kronecker-product-mixed-product-property">Kronecker Product Mixed-Product Property</h4>

<p>Let $A \in \mathbb{C}^{m \times n}$, $B \in \mathbb{C}^{r \times s}$, $C \in \mathbb{C}^{n \times p}$, and $D \in \mathbb{C}^{s \times t}$, then</p>



<p>This has been proved in <a href="https://leimao.github.io/blog/Kronecker-Product-In-Circuits/">Kronecker Product In Circuits</a>.</p>

<h4 id="inner-product-expansion-property">Inner Product Expansion Property</h4>

<p>Suppose $|x\rangle$ is any unit vector whose $|x|^2 = \langle x | x \rangle = 1$. We have $\langle \phi | \psi \rangle = (\langle \phi | \otimes \langle x |) (| x \rangle \otimes | \psi \rangle)$</p>



<p>This concludes the proof.</p>

<h4 id="unitary-matrix-preserves-inner-product">Unitary Matrix Preserves Inner Product</h4>

<p>Given two complex vectors $x$ and $y$, multiplication by unitary matrix $U$ preserves their inner product.</p>



<p>Using the definition of inner product,</p>



<p>This concludes the proof.</p>

<h3 id="no-cloning-theorem">No-Cloning Theorem</h3>

<p>In quantum mechanics, copy, as it is the same to other quantum operators except measurement operators, is an reversible and linear operator.</p>



<p>Given any unknown normalized quantum state $| \phi \rangle$, and the copy operator $U$, we are supposed to have the following mathematical expression if we are going to copy the quantum state $| \phi \rangle$ to another system whose quantum state is $|x \rangle$ before copy.</p>



<p>We would like to write this transformation into equation.</p>



<p>Without loss of generality, we could have another state $| \psi \rangle$ that is applied to the copy operator.</p>



<p>Note that for $| \psi \rangle$ we also used $|x\rangle$ which $| \phi \rangle$ is using, meaning that before copy, the “vacant” system is always the same. This is something we could guarantee.</p>



<p>We examine the inner product of $| \phi \rangle$ and $| \psi \rangle$ using the copy property and all the properties in the prerequisite section.</p>



<p>Because $\langle \phi | \psi \rangle$ is scalar, we further have</p>



<p>Solving the above equation, we have $\langle \phi | \psi \rangle = 0$ or $1$.</p>



<p>Because $| \phi \rangle$ and $| \psi \rangle$ could be any arbitrary unknown states, $\langle \phi | \psi \rangle = 0$ or $1$ could never be satisfied.</p>



<p>Therefore, there is no general quantum copy operator that makes copy of any unknown state.</p>

<h3 id="more-restrict-no-cloning-theorem">More Restrict No-Cloning Theorem</h3>

<p>In quantum theory, $| \phi \rangle$ and $c | \phi \rangle$, where $c$ is a non-zero complex number, represent the same physical state. If $|c \phi|^2 = 1$, then $| \phi \rangle$ and $c | \phi \rangle$ only have phase difference.</p>



<p>For example, $| \phi \rangle$ and $| \psi \rangle$ have exactly the same probability of collapsing to $| 0 \rangle$ and $| 1 \rangle$. However, $| \phi \rangle$ has phase $\varphi_1$ while $| \psi \rangle$ has phase $\varphi_2$.</p>



<p>More restrict No-Cloning Theorem states that “copying” any unknown state while abandoning the phase is not possible either.</p>



<p>Suppose we have such “copy” operator, the mathematical expression for “copy” will be as follows.</p>



<p>Similarly, we have</p>



<p>The norm of the two sides should be equivalent.</p>



<p>Solving the above equation, we have $|\langle \phi | \psi \rangle | = 0$ or $1$.</p>



<p>Because $| \phi \rangle$ and $| \psi \rangle$ could be any arbitrary unknown states, $|\langle \phi | \psi \rangle | = 0$ or $1$ could never be satisfied.</p>



<p>Therefore, there is no general quantum “copy” operator that makes “copy” of any unknown state that has lost the phase information.</p>

<h3 id="transportation">Transportation</h3>

<p>Since it is not possible to do copy in quantum world, how about transportation?</p>



<p>Concretely, given any unknown normalized quantum state $| \phi \rangle$, and the transportation operator $U$, we are supposed to have the following mathematical expression if we are going to transport the quantum state $| \phi \rangle$ to another system whose quantum state is $|x \rangle$ before transportation.</p>



<p>Note that although it is called transportation, it is more like a switch, where the two system states, one unknown and one known, got switched.</p>



<p>Without loss of generality, we could have another state $| \psi \rangle$ that is applied to the transportation operator.</p>



<p>Similarly, we compute the inner product of $| \phi \rangle$ and $| \psi \rangle$.</p>



<p>Unlike copy, we did not find anything usual that prevents transportation.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://inst.eecs.berkeley.edu/~cs191/fa05/lectures/lecture6_fa05.pdf">No Cloning, Teleportation</a></li>
  <li><a href="https://www.physics.umd.edu/courses/Phys402/AnlageSpring09/TheNoCloningTheoremWoottersPhysicsTodayFeb2009p76.pdf">The No-Cloning Theorem</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/No-Cloning-Theorem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006297</guid>
            <pubDate>Fri, 31 Jul 2020 06:46:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anachro-PC – The Anachronistic Personal Computer]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006236">thread link</a>) | @MindGods
<br/>
July 30, 2020 | https://jamesmunns.com/blog/anachro-pc-001/ | <a href="https://web.archive.org/web/*/https://jamesmunns.com/blog/anachro-pc-001/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
  
  <p><span>2020-07-30</span></p><hr>
  <blockquote>
<p>TL;DR - These are my notes for a potential computer hobbyist personal computer architecture. Someone called it "Minix for motherboards".</p>
</blockquote>
<p>This roughly describes an architecture of off the shelf microcontroller components that can be used to create a basic standalone PC, somewhere in the neighborhood of performance of an old 286/386 DOS style PC.</p>
<p>If I build this, it will almost certainly be done in Rust. I do hope to specify the protocol/operational semantics well enough that you could create a component that was written in Micro/Circuit Python, C/C++, Ada, or maybe even as an embedded linux PC.</p>
<p>I currently am working on other projects, but I feel like this would be a fun project to stream, or maybe even write a book about learning embedded systems, or learning Rust with embedded systems?</p>
<p><strong>If you'd be interested in taking a class building/using a system like this, or would be interested in seeing this happen, <a href="mailto:james.munns@ferrous-systems.com">send me a message</a>.</strong></p>

<h2 id="project-goals">Project Goals</h2>
<p>The goal of this project is to design a PC-ish architecture that makes it easy for people learning embedded systems to build a single component. This includes:</p>
<ol>
<li>Making the system resistant to failure of a single component</li>
<li>Use only protocols/components that can be easily purchased</li>
<li>Be adaptive to allow for variety of components used</li>
<li>Value simplicity over performance</li>
<li>Make the steps to initial success very short</li>
<li>Make this fun for me and other collaborators to work on</li>
</ol>
<h2 id="project-anti-goals">Project Anti-Goals</h2>
<ol>
<li>Designing something that is wholly useful in commercial deployments</li>
</ol>
<h2 id="interesting-ideas">Interesting Ideas</h2>
<p>These are ideas that I think will help make the project successful.</p>
<h3 id="every-component-is-a-microcontroller-any-microcontroller">Every Component is a Microcontroller - Any Microcontroller.</h3>
<p>The idea is to have every part (or <strong>Component</strong>) of the system be its own standalone microcontroller system. Honestly, this is how most computers work today anyway, but the idea is to be able to use almost any microcontroller, from 8051, to Arm Cortex-M, to RISC-V parts, for any piece of the PC. At some point, I can see people even making parts of the PC out of FPGAs as well.</p>
<p>This includes all of the following PC parts:</p>
<ul>
<li>The Main CPU/Processor</li>
<li>An input controller (Keyboard/Mouse/Touch)</li>
<li>A network interface (Ethernet/Wi-Fi/LPWAN)</li>
<li>A storage controller (SSD/SD/HDD/RAMFS/USB)</li>
<li>A Sound Card</li>
<li>A graphics card (framebuffer, shaders)</li>
</ul>
<p>The system should use a protocol that almost every device has support for, and is forgiving. For that reason, I plan to use SPI for system communication.</p>
<h3 id="the-bus-protocol-spi-but-weird">The Bus Protocol - SPI, but weird.</h3>
<p>So, SPI is a simple, fast, and reliable protocol, but the trick is that it is WAY easier to write a SPI Controller, rather than a SPI peripheral. Since I want things to be simplest for the people writing the Components, they should be the SPI Controllers. But this leaves us with a problem, how do we make a PC with N SPI Controllers work with a single SPI peripheral? Here is where it gets weird.</p>
<ol>
<li>Every Component is a SPI Controller, with SCK, COPI, and CIPO pins wired to a central <strong>Arbitrator</strong>.</li>
<li>Every Component also has two GPIOs:
<ul>
<li>An output that is a "Request" line. This signals to the Arbitrator that the Component would like to talk</li>
<li>An input that is a "Go-Ahead" line. This signals to the Component to begin talking to the Arbitrator</li>
</ul>
</li>
</ol>
<p>In this system, the Arbitrator will either support being a SPI Peripheral for a lot of lines, or will handle MUXing the SCK/COPI/CIPO pins as necessary.
The Arbitrator will decide which component it wants to talk to, and for how long.
When a Component pulls its Request line low, the arbitrator will eventually acknowledge this by pulling the Component's Go-Ahead line low.
The Component can begin clocking SPI data at whatever speed it feels like, up to the maximum speed supported by the Arbitrator.
When the Component is done sending/receiving data, it checks whether the Go-Ahead line is still low.
If so, then the message was "accepted" by the arbitrator.
If the Go-Ahead line is released high before the Component releases the Request line, this means that the arbitrator has "hung up" on the Component, meaning either an error or timeout has occurred.</p>
<h3 id="the-arbitrator-basically-a-northbridge-chip">The Arbitrator - Basically a Northbridge chip</h3>
<p>The Arbitrator has two primary tasks:</p>
<ol>
<li>Arbitrating the Bus Protocol as described above, servicing and discovering components that have been connected</li>
<li>Managing memory allocations used to communicate between devices</li>
</ol>
<p>I've already described the lowest level of the protocol above - we'll use an awkward SPI communication. However I haven't described how the higher protocol layers work.</p>
<p>All devices will communicate through a mailbox system.
The arbitrator will take data from the Components, and place them in an in-memory object store.
Each created item will be assigned a UUID, which will be returned to the Component on creation.
This UUID can then be placed in a mailbox to another component, sending access to the data to that component.
Each item is read-only.</p>
<p>Example (psuedocode):</p>
<pre><span>// A binary RPC messages are sent from Component to the Arbitrator
// The format will probably be binary, but maybe with an alternative
// command to use the following REPL format?
//
// Components are also assigned a UUID on boot. This Component has
// the own-address of 9ea8b6a7-2967-4db8-98b8-d4577548ed04.

// Data can be stored to the Arbitrator memory space. Data can then be
// referenced as inter-device storage using UUIDs as a reference. Data
// is allocated on a FIFO basis, with oldest memory items becoming
// dropped.
//
// The arbitrator may choose to limit the rate, maximum size or other
// parameters of creating memory items based on configuration.
CREATE(
    // number of bytes to write, can be set to zero for dynamic
    // length using something like COBS or when the Request
    // line is de-asserted
    13,

    // The payload of the data
    "Hello, world!",

    // No UUID provided to send to another component, just return
    // the newly created UUID. If provided, this would place
    // the created UUID into the mailbox of another component
    None,
)
// The following UUID is returned to the Component on success
-&gt; Result&lt;3b2fd5d1-ae16-46af-afc1-f60241d0a5b6, CreateError&gt;

// You can send data by reference to another component you know's
// mailbox. Mailboxes are provided as a Component's address. Mailboxes
// are a FIFO queue of UUIDs that can be loaded by that Component
SEND_MAILBOX(
    // The data reference to send
    3b2fd5d1-ae16-46af-afc1-f60241d0a5b6,

    // The destination address
    56c3dbda-c762-4107-be58-855dc8e5aa92,
)

// The other device can receive messages on a FIFO basis, and can view
// the item at the top of the stack without removing it
PEEK_MAILBOX(
    // You can provide Some(usize) as a max message size, or None for
    // anymessage size. Messages larger than the usize value will
    // instead return an Error
    Some(32),
)
-&gt; Result&lt;(13, "Hello, world!"), GetError&gt;

// The other device can receive messages on a FIFO basis, and can view
// and remove the item at the top of the stack. If the Controller
// ends the message before all bytes are received, the item is still
// removed from the FIFO. Thiscan be used to simply drop the item on
// the top of the FIFO.
POP_MAILBOX(
    // You can provide Some(usize) as a max message size, or None for
    // any message size. Messages larger than the usize value will
    // instead return an Error
    Some(32),
)
-&gt; Result&lt;(13, "Hello, world!"), GetError&gt;

// TODO: How to have a "clone and modify" operation that isn't hard
// because of re-allocs? Insertions would suck unless I used some kind
//  of rope structure, which might be too complex to implement
</span></pre>
<p>You can also use the SPI interface for certain communications directly to the arbitrator</p>
<pre><span>// Register ourself using an enumerated type ID
//
// TODO: What to do when calling this more than once?
REGISTER_TYPE(
    IO_CONTROLLER,
) -&gt; Result&lt;9ea8b6a7-2967-4db8-98b8-d4577548ed04, GetError&gt;

// Get the ID of ourself. Matches ID given on registration
GET_OWN_ID()
-&gt; Result&lt;9ea8b6a7-2967-4db8-98b8-d4577548ed04, GetError&gt;

// Get limits of the arbitrator interface
GET_ARBITRATOR_LIMITS()
-&gt; {
    min_speed_hz: 125_000,     // What is the minimum SPI clock rate?
    max_speed_hz: 8_000_000,   // What is the maximum SPI clock rate?
    exp_polls_per_sec: 100,    // What is the expected poll frequency?
    request_line_shared: false,// Is the request line open drain?
    total_memory: 524288,      // 512KiB
    max_files: 512,            // Max number of records alive at once
}

// Get limits for message creation
GET_CREATE_LIMITS()
-&gt; {
    max_bytes: 512,             // Largest message can be 512 bytes
    max_bytes_per_second: 4096, // Running resource limits
    messages_per_second: 10,    // Running resource limits
}
</span></pre>
<blockquote>
<p>TODO: How to register multiple addresses/logical addressing? e.g. for keyboard that has a mouse and touchpad?
Could add a "from" field to every message, but then I'm adding a routing layer?</p>
</blockquote>
<h3 id="an-easy-bootloader">An easy bootloader</h3>
<p>Write a simple bootloader that can enumerate on the bus, take an image, and reboot? PXII boot style? Would need to enumerate type
and maybe even serial number or something to load the right firmware to the right place.</p>
<h2 id="the-first-implementation">The First Implementation</h2>
<p>These are ideas for possible first implementation of the PC architecture described above</p>
<h3 id="a-simulator-with-real-world-hooks">A Simulator with real-world hooks</h3>
<p>I could create a simulated environment for these components, using no_std libraries and using TCP over localhost to emulate the SPI target environment, basically providing an I/O library or a "HAL" for simulating each component inside of a system. Maybe even port RTIC to the simulated environment, or even just use QEMU, using Semihosting for simulated SPI/GPIOs?</p>
<p>With a little work, I could also probably have an arbitrator or even just a simple SPI controller sit outside of the PC, bridging one or more simulated components to a shared network with physical components.</p>
<p>This would allow me to bring up multiple devices quickly, both from a Component software …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmunns.com/blog/anachro-pc-001/">https://jamesmunns.com/blog/anachro-pc-001/</a></em></p>]]>
            </description>
            <link>https://jamesmunns.com/blog/anachro-pc-001/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006236</guid>
            <pubDate>Fri, 31 Jul 2020 06:30:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Under the hood webpack: library behind the event-driven architecture]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006235">thread link</a>) | @bliashenko
<br/>
July 30, 2020 | https://codecrumbs.io/stories/webpack-tapable-core | <a href="https://web.archive.org/web/*/https://codecrumbs.io/stories/webpack-tapable-core">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p><b>Quick tip:</b> click code mentions in the text (e.g.</p><!-- --> <p><a><code>file-name.js</code></a>) </p><!-- --><p>or visual elements (e.g.</p><!-- --> <a><span></span><svg height="13" width="13"><svg version="1.1" x="1" y="1" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path style="transform:rotate(360deg);transform-origin:50% 50%" d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z"></path></g></svg><svg version="1.1" x="0" y="0" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path style="transform:rotate(360deg);transform-origin:50% 50%" d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z"></path></g></svg></svg></a><p>, <a><span>4</span></a>) to highlight them on scheme above.</p></div></div></div><div><div><h2>TL;DR</h2><p>Webpack architecture is heavily based on events. Each webpack <strong>plugin</strong> is basically a <strong>set of listeners</strong> hooked on different events during compilation phases. Under the hood, webpack uses a library called <code>tapable</code> to encapsulate "publish-subscribe" implementation.  </p><p>Tapable provides different "hooks" classes (<code>SyncBailHook</code>, <code>AsyncParallelHook</code>, etc.) to "hook" on events with some extra rich functionality (e.g. interceptions or cross-listeners integration).  </p><p>For example, <code>DefinePugin</code> (used to define environment variables, e.g. <code>NODE_ENV</code>) and <code>SizeLimitsPlugin</code> (reports oversized chunks, e.g. <em>size &gt; 250kb</em>) tap into compiler instance <em>hooks</em>: the first one listens to <em>compilation</em> event in order to insert extra variables and the latter to <em>afterEmit</em> event - to proceed with assets evaluation once they were emitted.  </p><div><div><div><p>DefinePlugin</p><p>Compiler</p><p>SizeLimitsPlugin</p></div><div><div><div><p> hooks.afterEmit.callAsync  </p><svg style="left:-5px;top:-3px"><circle cx="5" cy="5" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="4" cy="4" r="3" shape-rendering="geometricPrecision"></circle></svg><svg style="left:calc(100% - 13px);top:-6px"><svg version="1.1" x="1" y="1" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path style="transform:rotate(360deg);transform-origin:50% 50%" d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z"></path></g></svg><svg version="1.1" x="0" y="0" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path style="transform:rotate(360deg);transform-origin:50% 50%" d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z"></path></g></svg></svg></div></div></div><div><p>DefinePlugin</p><p>Compiler</p><p>SizeLimitsPlugin</p></div></div></div><p> <!-- -->&nbsp;<br>Let's have a quick look under the hood of <code>webpack</code> at <code>SizeLimitsPlugin</code> integration.  </p></div><div data-snapshot-id="19"><div><svg width="1178" height="310" xmlns="http://www.w3.org/2000/svg" shape-rendering="optimizeSpeed"><rect x="0" y="0" width="1178" height="310"></rect><path d="M 63.79 201.5 L 92.5 201.5 L 92.5 49.5 Q 92.5 44.5 97.5 44.5 L 105.5 44.5"></path><polyline points="226.23,44.5, 268.5,44.5, 268.5,44.5"></polyline><path d="M 63.79 201.5 L 92.5 201.5 L 92.5 264.5 Q 92.5 269.5 97.5 269.5 L 105.5 269.5"></path><g><svg version="1.1" x="17" y="193" viewBox="0 0 276.157 276.157" width="15" height="15" shape-rendering="geometricPrecision"><rect x="50" width="270" height="270" fill="white" opacity="0.4"></rect><path d="M273.081,101.378c-3.3-4.651-8.86-7.319-15.255-7.319h-24.34v-26.47c0-10.201-8.299-18.5-18.5-18.5  h-85.322c-3.63,0-9.295-2.876-11.436-5.806l-6.386-8.735c-4.982-6.814-15.104-11.954-23.546-11.954H58.731  c-9.293,0-18.639,6.608-21.738,15.372l-2.033,5.752c-0.958,2.71-4.721,5.371-7.596,5.371H18.5c-10.201,0-18.5,8.299-18.5,18.5  v167.07c0,0.885,0.161,1.73,0.443,2.519c0.152,3.306,1.18,6.424,3.053,9.064c3.3,4.652,8.86,7.319,15.255,7.319h188.486  c11.395,0,23.27-8.424,27.035-19.179l40.677-116.188C277.061,112.159,276.381,106.03,273.081,101.378z M18.5,64.089h8.864  c9.295,0,18.64-6.608,21.738-15.372l2.032-5.75c0.959-2.711,4.722-5.372,7.597-5.372h29.564c3.63,0,9.295,2.876,11.437,5.806  l6.386,8.734c4.982,6.815,15.104,11.954,23.546,11.954h85.322c1.898,0,3.5,1.603,3.5,3.5v26.47H69.34  c-11.395,0-23.27,8.424-27.035,19.179L15,191.231V67.589C15,65.692,16.603,64.089,18.5,64.089z M260.791,113.238l-40.677,116.188  c-1.674,4.781-7.812,9.135-12.877,9.135H18.751c-1.448,0-2.577-0.373-3.02-0.998c-0.443-0.625-0.423-1.814,0.056-3.181  l40.677-116.188c1.674-4.781,7.812-9.135,12.877-9.135h188.486c1.448,0,2.577,0.373,3.021,0.998  C261.29,110.682,261.27,111.871,260.791,113.238z"></path></svg><g><rect x="21" y="204" width="11" height="4"></rect><text x="22" y="207">..</text></g><text x="35" y="206" data-path="lib">lib</text><rect x="10" y="186" width="50.29" height="30"></rect></g><g><svg version="1.1" x="112" y="36" viewBox="0 0 276.157 276.157" width="15" height="15" shape-rendering="geometricPrecision"><rect x="50" width="270" height="270" fill="white" opacity="0.4"></rect><path d="M273.081,101.378c-3.3-4.651-8.86-7.319-15.255-7.319h-24.34v-26.47c0-10.201-8.299-18.5-18.5-18.5  h-85.322c-3.63,0-9.295-2.876-11.436-5.806l-6.386-8.735c-4.982-6.814-15.104-11.954-23.546-11.954H58.731  c-9.293,0-18.639,6.608-21.738,15.372l-2.033,5.752c-0.958,2.71-4.721,5.371-7.596,5.371H18.5c-10.201,0-18.5,8.299-18.5,18.5  v167.07c0,0.885,0.161,1.73,0.443,2.519c0.152,3.306,1.18,6.424,3.053,9.064c3.3,4.652,8.86,7.319,15.255,7.319h188.486  c11.395,0,23.27-8.424,27.035-19.179l40.677-116.188C277.061,112.159,276.381,106.03,273.081,101.378z M18.5,64.089h8.864  c9.295,0,18.64-6.608,21.738-15.372l2.032-5.75c0.959-2.711,4.722-5.372,7.597-5.372h29.564c3.63,0,9.295,2.876,11.437,5.806  l6.386,8.734c4.982,6.815,15.104,11.954,23.546,11.954h85.322c1.898,0,3.5,1.603,3.5,3.5v26.47H69.34  c-11.395,0-23.27,8.424-27.035,19.179L15,191.231V67.589C15,65.692,16.603,64.089,18.5,64.089z M260.791,113.238l-40.677,116.188  c-1.674,4.781-7.812,9.135-12.877,9.135H18.751c-1.448,0-2.577-0.373-3.02-0.998c-0.443-0.625-0.423-1.814,0.056-3.181  l40.677-116.188c1.674-4.781,7.812-9.135,12.877-9.135h188.486c1.448,0,2.577,0.373,3.021,0.998  C261.29,110.682,261.27,111.871,260.791,113.238z"></path></svg><g><rect x="116" y="47" width="11" height="4"></rect><text x="117" y="50">..</text></g><text x="130" y="49" data-path="lib/performance">performance</text><rect x="105" y="29" width="117.72999999999999" height="30"></rect></g><g><svg version="1.1" x="112" y="260" width="15" height="15" viewBox="0 0 512 512" shape-rendering="geometricPrecision"><rect x="50" width="512" height="512" fill="white"></rect><path d="m436.03125 107.03125-104.601562-102.734375c-2.804688-2.753906-6.578126-4.296875-10.511719-4.296875h-264.449219c-30.859375 0-55.96875 25.105469-55.96875 55.96875v400.0625c0 30.859375 25.105469 55.96875 55.96875 55.96875h328.082031c30.859375 0 55.96875-25.105469 55.96875-55.96875v-338.296875c0-4.027344-1.617187-7.882813-4.488281-10.703125zm-100.113281-56.273438 52.921875 51.976563h-48.152344c-2.628906 0-4.769531-2.140625-4.769531-4.769531zm48.632812 431.242188h-328.082031c-14.316406 0-25.96875-11.648438-25.96875-25.96875v-400.0625c0-14.320312 11.648438-25.96875 25.96875-25.96875h249.453125v67.964844c0 19.171875 15.597656 34.769531 34.769531 34.769531h69.828125v323.296875c0 14.320312-11.648437 25.96875-25.96875 25.96875zm0 0"></path><path d="m324.644531 238h-211.453125c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h211.453125c8.285157 0 15-6.714844 15-15s-6.714843-15-15-15zm0 0"></path><path d="m113.191406 328h172.414063c8.285156 0 15-6.714844 15-15s-6.714844-15-15-15h-172.414063c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15zm0 0"></path><path d="m306.40625 358h-193.214844c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h193.214844c8.28125 0 15-6.714844 15-15s-6.71875-15-15-15zm0 0"></path></svg><g><title>lib/WebpackOptionsApply.js</title><text x="128" y="274" data-path="lib/WebpackOptionsApply.js">WebpackOptionsApply.js</text></g><rect x="105" y="254" width="210.45999999999998" height="25"></rect></g><g><svg version="1.1" x="275" y="35" width="15" height="15" viewBox="0 0 512 512" shape-rendering="geometricPrecision"><rect x="50" width="512" height="512" fill="white"></rect><path d="m436.03125 107.03125-104.601562-102.734375c-2.804688-2.753906-6.578126-4.296875-10.511719-4.296875h-264.449219c-30.859375 0-55.96875 25.105469-55.96875 55.96875v400.0625c0 30.859375 25.105469 55.96875 55.96875 55.96875h328.082031c30.859375 0 55.96875-25.105469 55.96875-55.96875v-338.296875c0-4.027344-1.617187-7.882813-4.488281-10.703125zm-100.113281-56.273438 52.921875 51.976563h-48.152344c-2.628906 0-4.769531-2.140625-4.769531-4.769531zm48.632812 431.242188h-328.082031c-14.316406 0-25.96875-11.648438-25.96875-25.96875v-400.0625c0-14.320312 11.648438-25.96875 25.96875-25.96875h249.453125v67.964844c0 19.171875 15.597656 34.769531 34.769531 34.769531h69.828125v323.296875c0 14.320312-11.648437 25.96875-25.96875 25.96875zm0 0"></path><path d="m324.644531 238h-211.453125c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h211.453125c8.285157 0 15-6.714844 15-15s-6.714843-15-15-15zm0 0"></path><path d="m113.191406 328h172.414063c8.285156 0 15-6.714844 15-15s-6.714844-15-15-15h-172.414063c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15zm0 0"></path><path d="m306.40625 358h-193.214844c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h193.214844c8.28125 0 15-6.714844 15-15s-6.71875-15-15-15zm0 0"></path></svg><g><title>lib/performance/SizeLimitsPlugin.js</title><text x="291" y="49" data-path="lib/performance/SizeLimitsPlugin.js">SizeLimitsPlugin.js</text></g><rect x="268" y="29" width="185.17" height="25"></rect></g><svg version="1.1" width="6px" height="6px" x="102.5" y="41.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><svg version="1.1" width="6px" height="6px" x="102.5" y="266.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><svg version="1.1" width="6px" height="6px" x="265.5" y="41.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><polyline points="318,269,353,269,353,186,363,186" shape-rendering="crispEdges" stroke-dasharray="2"></polyline><line x1="318" y1="267" x2="318" y2="272" shape-rendering="crispEdges" stroke-dasharray="2"></line><line x1="455" y1="44" x2="498" y2="45" shape-rendering="crispEdges" stroke-dasharray="2"></line><line x1="455" y1="42" x2="455" y2="47" shape-rendering="crispEdges" stroke-dasharray="2"></line><g><path shape-rendering="geometricPrecision" d="M 319 270 C 318 269, 338.9096974407664 256.2903755784993, 363 252"></path><path shape-rendering="geometricPrecision" d="M 318 269 C 318 269, 338.9096974407664 256.2903755784993, 363 252" data-connection-path="lib/WebpackOptionsApply.js|lib/performance/SizeLimitsPlugin.js"></path><path shape-rendering="geometricPrecision" d="M 318 269 C 318 269, 338.9096974407664 256.2903755784993, 363 252"></path><svg version="1.1" x="312.5" y="263.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-200.695deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="311.5" y="262.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-200.695deg); transform-origin: 50% 50%;"></path></g></svg></g><g><path shape-rendering="geometricPrecision" d="M 456 45 C 455 44, 479.408326913196 68.894448724536, 493 101"></path><path shape-rendering="geometricPrecision" d="M 455 44 C 455 44, 479.408326913196 68.894448724536, 493 101" data-connection-path="lib/WebpackOptionsApply.js|lib/performance/SizeLimitsPlugin.js"></path><path shape-rendering="geometricPrecision" d="M 455 44 C 455 44, 479.408326913196 68.894448724536, 493 101"></path><circle cx="456" cy="45" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="455" cy="44" r="3" shape-rendering="geometricPrecision"></circle><svg version="1.1" x="487.5" y="95.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(56.3099deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="486.5" y="94.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(56.3099deg); transform-origin: 50% 50%;"></path></g></svg></g><g><path shape-rendering="geometricPrecision" d="M 106 270 Q 209.1750773215599 172.9268337929523 268 44"></path><path shape-rendering="geometricPrecision" d="M 105 269 Q 209.1750773215599 172.9268337929523 268 44" data-connection-path="lib/WebpackOptionsApply.js|lib/performance/SizeLimitsPlugin.js"></path><path shape-rendering="geometricPrecision" d="M 105 269 Q 209.1750773215599 172.9268337929523 268 44"></path><circle cx="106" cy="270" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="105" cy="269" r="3" shape-rendering="geometricPrecision"></circle><circle cx="269" cy="45" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="268" cy="44" r="3" shape-rendering="geometricPrecision"></circle><svg version="1.1" x="192.33753866077996" y="159.21341689647616" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-54.0788deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="191.33753866077996" y="158.21341689647616" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-54.0788deg); transform-origin: 50% 50%;"></path></g></svg></g><polyline shape-rendering="geometricPrecision" points="198,164, 278,155" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="498,138, 443,124" stroke-dasharray="2" stroke-linecap="round"></polyline></svg><div><div data-scroll-top="8237"><pre><div><div><div><p><span>483</span><span>      </span><span>}</span><span></span></p><p><span>484</span><span>    </span><span>}</span><span></span></p><p><span>485</span><span></span></p><p><span>486</span><span>    </span><span>if</span><span> </span><span>(</span><span>options</span><span>.</span><span>performance</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>487</span><span>      </span><span>const</span><span> SizeLimitsPlugin </span><span>=</span><span> </span><span>require</span><span>(</span><span>"./performance/SizeLimitsPlugin"</span><span>)</span><span>;</span><span></span></p><p><span><span></span>488</span><span>      </span><span>new</span><span> </span><span>SizeLimitsPlugin</span><span>(</span><span>options</span><span>.</span><span>performance</span><span>)</span><span>.</span><span>apply</span><span>(</span><span>compiler</span><span>)</span><span>;</span><span></span></p><p><span>489</span><span>    </span><span>}</span><span></span></p><p><span>490</span><span></span></p><p><span>491</span><span>    </span><span>new</span><span> </span><span>TemplatedPathPlugin</span><span>(</span><span>)</span><span>.</span><span>apply</span><span>(</span><span>compiler</span><span>)</span><span>;</span><span></span></p><p><span>492</span><span></span></p></div></div></div></pre></div></div><div><div data-scroll-top="202"><pre><div><div><div><p><span>10</span><span></span><span></span></p><p><span>11</span><span></span><span></span></p><p><span>12</span><span></span></p><p><span>13</span><span>module</span><span>.</span><span>exports </span><span>=</span><span> </span><span>class</span><span> </span><span>SizeLimitsPlugin</span><span> </span><span>{</span><span></span></p><p><span><span></span>25</span><span>  </span><span>apply</span><span>(</span><span>compiler</span><span>)</span><span> </span><span>{</span><span></span></p><p><span><span></span>32</span><span>    compiler</span><span>.</span><span>hooks</span><span>.</span><span>afterEmit</span><span>.</span><span>tap</span><span>(</span><span>"SizeLimitsPlugin"</span><span>,</span><span> </span><span>compilation</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>33</span><span>      </span><span>const</span><span> warnings </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span><span></span></p><p><span>34</span><span></span></p><p><span>35</span><span>      </span></p></div></div></div></pre></div></div></div></div></div><div><div><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><span><span>0</span></span></td><td><a href="#codecrumbs-item-path=lib/performance/SizeLimitsPlugin.js"><code>SizeLimitsPlugin</code></a> is instantiated and assigned to <em>compiler</em>  in <a href="#codecrumbs-item-path=lib/WebpackOptionsApply.js"><code>WebpackOptionsApply</code></a> if <code>performance</code><span> option is enabled from webpack config (highlight <a data-interactive-path="lib/WebpackOptionsApply.js|lib/performance/SizeLimitsPlugin.js"><span></span><svg height="13" width="13"><svg version="1.1" x="1" y="1" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path style="transform:rotate(360deg);transform-origin:50% 50%" d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z"></path></g></svg><svg version="1.1" x="0" y="0" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path style="transform:rotate(360deg);transform-origin:50% 50%" d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z"></path></g></svg></svg></a>)</span></td></tr><tr><td><span><span>1</span></span></td><td>Then <a href="#codecrumbs-item-path=lib/performance/SizeLimitsPlugin.js"><code>SizeLimitsPlugin</code></a> taps on <code>afterEmit</code> event and will sit still until most of the compilation flow is done and that particular event is called.</td></tr></tbody></table></div><div data-snapshot-id="12"><div><svg width="1195" height="504" xmlns="http://www.w3.org/2000/svg" shape-rendering="optimizeSpeed"><rect x="0" y="0" width="1195" height="504"></rect><path d="M 63.79 201.5 L 92.5 201.5 L 92.5 49.5 Q 92.5 44.5 97.5 44.5 L 105.5 44.5"></path><path d="M 92.5 201.5 L 92.5 201.5 L 92.5 264.5 Q 92.5 269.5 97.5 269.5 L 105.5 269.5"></path><polyline points="226.23,44.5, 268.5,44.5, 268.5,44.5"></polyline><g><svg version="1.1" x="17" y="193" viewBox="0 0 276.157 276.157" width="15" height="15" shape-rendering="geometricPrecision"><rect x="50" width="270" height="270" fill="white" opacity="0.4"></rect><path d="M273.081,101.378c-3.3-4.651-8.86-7.319-15.255-7.319h-24.34v-26.47c0-10.201-8.299-18.5-18.5-18.5  h-85.322c-3.63,0-9.295-2.876-11.436-5.806l-6.386-8.735c-4.982-6.814-15.104-11.954-23.546-11.954H58.731  c-9.293,0-18.639,6.608-21.738,15.372l-2.033,5.752c-0.958,2.71-4.721,5.371-7.596,5.371H18.5c-10.201,0-18.5,8.299-18.5,18.5  v167.07c0,0.885,0.161,1.73,0.443,2.519c0.152,3.306,1.18,6.424,3.053,9.064c3.3,4.652,8.86,7.319,15.255,7.319h188.486  c11.395,0,23.27-8.424,27.035-19.179l40.677-116.188C277.061,112.159,276.381,106.03,273.081,101.378z M18.5,64.089h8.864  c9.295,0,18.64-6.608,21.738-15.372l2.032-5.75c0.959-2.711,4.722-5.372,7.597-5.372h29.564c3.63,0,9.295,2.876,11.437,5.806  l6.386,8.734c4.982,6.815,15.104,11.954,23.546,11.954h85.322c1.898,0,3.5,1.603,3.5,3.5v26.47H69.34  c-11.395,0-23.27,8.424-27.035,19.179L15,191.231V67.589C15,65.692,16.603,64.089,18.5,64.089z M260.791,113.238l-40.677,116.188  c-1.674,4.781-7.812,9.135-12.877,9.135H18.751c-1.448,0-2.577-0.373-3.02-0.998c-0.443-0.625-0.423-1.814,0.056-3.181  l40.677-116.188c1.674-4.781,7.812-9.135,12.877-9.135h188.486c1.448,0,2.577,0.373,3.021,0.998  C261.29,110.682,261.27,111.871,260.791,113.238z"></path></svg><g><rect x="21" y="204" width="11" height="4"></rect><text x="22" y="207">..</text></g><text x="35" y="206" data-path="lib">lib</text><rect x="10" y="186" width="50.29" height="30"></rect></g><g><svg version="1.1" x="112" y="36" viewBox="0 0 276.157 276.157" width="15" height="15" shape-rendering="geometricPrecision"><rect x="50" width="270" height="270" fill="white" opacity="0.4"></rect><path d="M273.081,101.378c-3.3-4.651-8.86-7.319-15.255-7.319h-24.34v-26.47c0-10.201-8.299-18.5-18.5-18.5  h-85.322c-3.63,0-9.295-2.876-11.436-5.806l-6.386-8.735c-4.982-6.814-15.104-11.954-23.546-11.954H58.731  c-9.293,0-18.639,6.608-21.738,15.372l-2.033,5.752c-0.958,2.71-4.721,5.371-7.596,5.371H18.5c-10.201,0-18.5,8.299-18.5,18.5  v167.07c0,0.885,0.161,1.73,0.443,2.519c0.152,3.306,1.18,6.424,3.053,9.064c3.3,4.652,8.86,7.319,15.255,7.319h188.486  c11.395,0,23.27-8.424,27.035-19.179l40.677-116.188C277.061,112.159,276.381,106.03,273.081,101.378z M18.5,64.089h8.864  c9.295,0,18.64-6.608,21.738-15.372l2.032-5.75c0.959-2.711,4.722-5.372,7.597-5.372h29.564c3.63,0,9.295,2.876,11.437,5.806  l6.386,8.734c4.982,6.815,15.104,11.954,23.546,11.954h85.322c1.898,0,3.5,1.603,3.5,3.5v26.47H69.34  c-11.395,0-23.27,8.424-27.035,19.179L15,191.231V67.589C15,65.692,16.603,64.089,18.5,64.089z M260.791,113.238l-40.677,116.188  c-1.674,4.781-7.812,9.135-12.877,9.135H18.751c-1.448,0-2.577-0.373-3.02-0.998c-0.443-0.625-0.423-1.814,0.056-3.181  l40.677-116.188c1.674-4.781,7.812-9.135,12.877-9.135h188.486c1.448,0,2.577,0.373,3.021,0.998  C261.29,110.682,261.27,111.871,260.791,113.238z"></path></svg><g><rect x="116" y="47" width="11" height="4"></rect><text x="117" y="50">..</text></g><text x="130" y="49" data-path="lib/performance">performance</text><rect x="105" y="29" width="117.72999999999999" height="30"></rect></g><g><svg version="1.1" x="112" y="260" width="15" height="15" viewBox="0 0 512 512" shape-rendering="geometricPrecision"><rect x="50" width="512" height="512" fill="white"></rect><path d="m436.03125 107.03125-104.601562-102.734375c-2.804688-2.753906-6.578126-4.296875-10.511719-4.296875h-264.449219c-30.859375 0-55.96875 25.105469-55.96875 55.96875v400.0625c0 30.859375 25.105469 55.96875 55.96875 55.96875h328.082031c30.859375 0 55.96875-25.105469 55.96875-55.96875v-338.296875c0-4.027344-1.617187-7.882813-4.488281-10.703125zm-100.113281-56.273438 52.921875 51.976563h-48.152344c-2.628906 0-4.769531-2.140625-4.769531-4.769531zm48.632812 431.242188h-328.082031c-14.316406 0-25.96875-11.648438-25.96875-25.96875v-400.0625c0-14.320312 11.648438-25.96875 25.96875-25.96875h249.453125v67.964844c0 19.171875 15.597656 34.769531 34.769531 34.769531h69.828125v323.296875c0 14.320312-11.648437 25.96875-25.96875 25.96875zm0 0"></path><path d="m324.644531 238h-211.453125c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h211.453125c8.285157 0 15-6.714844 15-15s-6.714843-15-15-15zm0 0"></path><path d="m113.191406 328h172.414063c8.285156 0 15-6.714844 15-15s-6.714844-15-15-15h-172.414063c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15zm0 0"></path><path d="m306.40625 358h-193.214844c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h193.214844c8.28125 0 15-6.714844 15-15s-6.71875-15-15-15zm0 0"></path></svg><g><title>lib/Compiler.js</title><text x="128" y="274" data-path="lib/Compiler.js">Compiler.js</text></g><rect x="105" y="254" width="117.72999999999999" height="25"></rect></g><g><svg version="1.1" x="275" y="35" width="15" height="15" viewBox="0 0 512 512" shape-rendering="geometricPrecision"><rect x="50" width="512" height="512" fill="white"></rect><path d="m436.03125 107.03125-104.601562-102.734375c-2.804688-2.753906-6.578126-4.296875-10.511719-4.296875h-264.449219c-30.859375 0-55.96875 25.105469-55.96875 55.96875v400.0625c0 30.859375 25.105469 55.96875 55.96875 55.96875h328.082031c30.859375 0 55.96875-25.105469 55.96875-55.96875v-338.296875c0-4.027344-1.617187-7.882813-4.488281-10.703125zm-100.113281-56.273438 52.921875 51.976563h-48.152344c-2.628906 0-4.769531-2.140625-4.769531-4.769531zm48.632812 431.242188h-328.082031c-14.316406 0-25.96875-11.648438-25.96875-25.96875v-400.0625c0-14.320312 11.648438-25.96875 25.96875-25.96875h249.453125v67.964844c0 19.171875 15.597656 34.769531 34.769531 34.769531h69.828125v323.296875c0 14.320312-11.648437 25.96875-25.96875 25.96875zm0 0"></path><path d="m324.644531 238h-211.453125c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h211.453125c8.285157 0 15-6.714844 15-15s-6.714843-15-15-15zm0 0"></path><path d="m113.191406 328h172.414063c8.285156 0 15-6.714844 15-15s-6.714844-15-15-15h-172.414063c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15zm0 0"></path><path d="m306.40625 358h-193.214844c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h193.214844c8.28125 0 15-6.714844 15-15s-6.71875-15-15-15zm0 0"></path></svg><g><title>lib/performance/SizeLimitsPlugin.js</title><text x="291" y="49" data-path="lib/performance/SizeLimitsPlugin.js">SizeLimitsPlugin.js</text></g><rect x="268" y="29" width="185.17" height="25"></rect></g><svg version="1.1" width="6px" height="6px" x="102.5" y="41.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><svg version="1.1" width="6px" height="6px" x="102.5" y="266.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><svg version="1.1" width="6px" height="6px" x="265.5" y="41.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><line x1="455" y1="44" x2="515" y2="45" shape-rendering="crispEdges" stroke-dasharray="2"></line><line x1="455" y1="42" x2="455" y2="47" shape-rendering="crispEdges" stroke-dasharray="2"></line><polyline points="225,269,421,269,421,317,431,317" shape-rendering="crispEdges" stroke-dasharray="2"></polyline><line x1="225" y1="267" x2="225" y2="272" shape-rendering="crispEdges" stroke-dasharray="2"></line><g><path shape-rendering="geometricPrecision" d="M 226 270 C 225 269, 347.1963837471001 345.61621107266683, 431 463"></path><path shape-rendering="geometricPrecision" d="M 225 269 C 225 269, 347.1963837471001 345.61621107266683, 431 463" data-connection-path="lib/Compiler.js|lib/performance/SizeLimitsPlugin.js"></path><path shape-rendering="geometricPrecision" d="M 225 269 C 225 269, 347.1963837471001 345.61621107266683, 431 463"></path><svg version="1.1" x="219.5" y="263.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-136.718deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="218.5" y="262.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-136.718deg); transform-origin: 50% 50%;"></path></g></svg></g><g><path shape-rendering="geometricPrecision" d="M 456 45 C 455 44, 486.1948071547098 57.652252802393754, 510 82"></path><path shape-rendering="geometricPrecision" d="M 455 44 C 455 44, 486.1948071547098 57.652252802393754, 510 82" data-connection-path="lib/Compiler.js|lib/performance/SizeLimitsPlugin.js"></path><path shape-rendering="geometricPrecision" d="M 455 44 C 455 44, 486.1948071547098 57.652252802393754, 510 82"></path><circle cx="456" cy="45" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="455" cy="44" r="3" shape-rendering="geometricPrecision"></circle><svg version="1.1" x="504.5" y="76.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(34.6409deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="503.5" y="75.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(34.6409deg); transform-origin: 50% 50%;"></path></g></svg></g><g><path shape-rendering="geometricPrecision" d="M 106 270 Q 209.1750773215599 172.9268337929523 268 44"></path><path shape-rendering="geometricPrecision" d="M 105 269 Q 209.1750773215599 172.9268337929523 268 44" data-connection-path="lib/Compiler.js|lib/performance/SizeLimitsPlugin.js"></path><path shape-rendering="geometricPrecision" d="M 105 269 Q 209.1750773215599 172.9268337929523 268 44"></path><circle cx="106" cy="270" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="105" cy="269" r="3" shape-rendering="geometricPrecision"></circle><circle cx="269" cy="45" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="268" cy="44" r="3" shape-rendering="geometricPrecision"></circle><svg version="1.1" x="192.33753866077996" y="159.21341689647616" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-54.0788deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="191.33753866077996" y="158.21341689647616" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-54.0788deg); transform-origin: 50% 50%;"></path></g></svg></g><polyline shape-rendering="geometricPrecision" points="198,164, 450,126" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="515,136, 493,105" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="515,204, 493,173" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="515,85, 493,54" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="431,463, 409,432" stroke-dasharray="2" stroke-linecap="round"></polyline></svg><div><div data-scroll-top="510"><pre><div><div><div><p><span>29</span><span>    </span><span>const</span><span> assetFilter </span><span>=</span><span></span></p><p><span>30</span><span>      </span><span>this</span><span>.</span><span>assetFilter </span><span>||</span><span> </span><span>(</span><span>(</span><span>name</span><span>,</span><span> source</span><span>,</span><span> info</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>!</span><span>info</span><span>.</span><span>development</span><span>)</span><span>;</span><span></span></p><p><span>31</span><span></span></p><p><span><span></span>32</span><span>    compiler</span><span>.</span><span>hooks</span><span>.</span><span>afterEmit</span><span>.</span><span>tap</span><span>(</span><span>"SizeLimitsPlugin"</span><span>,</span><span> </span><span>compilation</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>74</span><span>      </span><span>const</span><span> entrypointsOverLimit </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span><span></span></p><p><span><span></span>75</span><span>      </span><span>for</span><span> </span><span>(</span><span>const</span><span> </span><span>[</span><span>name</span><span>,</span><span> entry</span><span>]</span><span> </span><span>of</span><span> compilation</span><span>.</span><span>entrypoints</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>76</span><span>        </span><span>const</span><span> size </span><span>=</span><span> </span><span>getEntrypointSize</span><span>(</span><span>entry</span><span>)</span><span>;</span><span></span></p><p><span>77</span><span></span></p><p><span>78</span><span>        </span><span>if</span><span> </span><span>(</span><span>size </span><span>&gt;</span><span> entrypointSizeLimit</span><span>)</span><span> </span><span>{</span><span></span></p><p><span><span></span>79</span><span>          entrypointsOverLimit</span><span>.</span><span>push</span><span>(</span><span>{</span><span></span></p><p><span>80</span><span>            name</span><span>:</span><span> name</span><span>,</span><span></span></p><p><span>81</span><span>            size</span><span>:</span><span> size</span><span>,</span><span></span></p><p><span>82</span><span>            files</span><span>:</span><span> entry</span><span>.</span><span>getFiles</span><span>(</span><span>)</span><span>.</span><span>filter</span><span>(</span><span>fileFilter</span><span>)</span><span></span></p><p><span>83</span><span>          </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>84</span><span>          </span><span> </span><span>(</span><span>entry</span><span>)</span><span>.</span><span>isOverSizeLimit </span><span>=</span><span> </span><span>true</span><span>;</span><span></span></p><p><span>85</span><span>        </span><span>}</span><span></span></p></div></div></div></pre></div></div><div><div data-scroll-top="5981"><pre><div><div><div><p><span>350</span><span>    </span><span>}</span><span></span></p><p><span>351</span><span>  </span><span>}</span><span></span></p><p><span>352</span><span></span></p><p><span>353</span><span>  </span><span>emitAssets</span><span>(</span><span>compilation</span><span>,</span><span> callback</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>358</span><span>      asyncLib</span><span>.</span><span>forEachLimit</span><span>(</span><span></span></p><p><span>359</span><span>        compilation</span><span>.</span><span>getAssets</span><span>(</span><span>)</span><span>,</span><span></span></p><p><span>360</span><span>        </span><span>15</span><span>,</span><span></span></p><p><span>361</span><span>        </span><span>(</span><span>{</span><span> name</span><span>:</span><span> file</span><span>,</span><span> source </span><span>}</span><span>,</span><span> callback</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span><span></span>482</span><span>          </span><span>this</span><span>.</span><span>hooks</span><span>.</span><span>afterEmit</span><span>.</span><span>callAsync</span><span>(</span><span>compilation</span><span>,</span><span> </span><span>err</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>483</span><span>            </span><span>if</span><span> </span><span>(</span><span>err</span><span>)</span><span> </span><span>return</span><span> </span><span>callback</span><span>(</span><span>err</span><span>)</span><span>;</span><span></span></p><p><span>484</span><span></span></p><p><span>485</span><span>            </span><span>return</span><span> </span><span>callback</span><span>(</span><span>)</span><span>;</span><span></span></p></div></div></div></pre></div></div><div><div><div><pre>Using a simple "pub-sub" mechanism, performance evaluation plugin `SizeLimitsPlugin` can be loosely hooked into compilation flow.</pre></div></div></div><div><div><div><pre>`Compiler` calls (0)
 asynchronously `afterEmit` event (providing "compilation" instance).
`SizeLimitsPlugin` subscribes (1) to that to evaluate oversized chunks.</pre></div></div></div></div></div></div><div><div><p><span><span>Once the event is called <a data-interactive-path="lib/Compiler.js|lib/performance/SizeLimitsPlugin.js"><span></span><svg height="13" width="13"><svg version="1.1" x="1" y="1" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path style="transform:rotate(360deg);transform-origin:50% 50%" d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z"></path></g></svg><svg version="1.1" x="0" y="0" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path style="transform:rotate(360deg);transform-origin:50% 50%" d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z"></path></g></svg></svg></a> the plugin will do its job (collecting oversized chunks in our case </span><span>2</span><span>, <span>3</span>).  </span></span></p><p><span><p>Indeed, all plugins are assigned similarly, so then you have a pipeline of plugins performing different operations but staying very loosely coupled.  </p></span></p><h2>Slightly longer read</h2><p>Let's learn more about <code>tapable</code> library.  </p><p>Have a look at this classic events-based architecture all of us have used many times.  </p></div><div data-snapshot-id="16"><div><svg width="940" height="265" xmlns="http://www.w3.org/2000/svg" shape-rendering="optimizeSpeed"><rect x="0" y="0" width="940" height="265"></rect><polyline points="63.79,44.5, 105.5,44.5, 105.5,44.5"></polyline><g><svg version="1.1" x="17" y="36" viewBox="0 0 276.157 276.157" width="15" height="15" shape-rendering="geometricPrecision"><rect x="50" width="270" height="270" fill="white" opacity="0.4"></rect><path d="M273.081,101.378c-3.3-4.651-8.86-7.319-15.255-7.319h-24.34v-26.47c0-10.201-8.299-18.5-18.5-18.5  h-85.322c-3.63,0-9.295-2.876-11.436-5.806l-6.386-8.735c-4.982-6.814-15.104-11.954-23.546-11.954H58.731  c-9.293,0-18.639,6.608-21.738,15.372l-2.033,5.752c-0.958,2.71-4.721,5.371-7.596,5.371H18.5c-10.201,0-18.5,8.299-18.5,18.5  v167.07c0,0.885,0.161,1.73,0.443,2.519c0.152,3.306,1.18,6.424,3.053,9.064c3.3,4.652,8.86,7.319,15.255,7.319h188.486  c11.395,0,23.27-8.424,27.035-19.179l40.677-116.188C277.061,112.159,276.381,106.03,273.081,101.378z M18.5,64.089h8.864  c9.295,0,18.64-6.608,21.738-15.372l2.032-5.75c0.959-2.711,4.722-5.372,7.597-5.372h29.564c3.63,0,9.295,2.876,11.437,5.806  l6.386,8.734c4.982,6.815,15.104,11.954,23.546,11.954h85.322c1.898,0,3.5,1.603,3.5,3.5v26.47H69.34  c-11.395,0-23.27,8.424-27.035,19.179L15,191.231V67.589C15,65.692,16.603,64.089,18.5,64.089z M260.791,113.238l-40.677,116.188  c-1.674,4.781-7.812,9.135-12.877,9.135H18.751c-1.448,0-2.577-0.373-3.02-0.998c-0.443-0.625-0.423-1.814,0.056-3.181  l40.677-116.188c1.674-4.781,7.812-9.135,12.877-9.135h188.486c1.448,0,2.577,0.373,3.021,0.998  C261.29,110.682,261.27,111.871,260.791,113.238z"></path></svg><g><rect x="21" y="47" width="11" height="4"></rect><text x="22" y="50">..</text></g><text x="35" y="49" data-path="lib">lib</text><rect x="10" y="29" width="50.29" height="30"></rect></g><g><svg version="1.1" x="112" y="35" width="15" height="15" viewBox="0 0 512 512" shape-rendering="geometricPrecision"><rect x="50" width="512" height="512" fill="white"></rect><path d="m436.03125 107.03125-104.601562-102.734375c-2.804688-2.753906-6.578126-4.296875-10.511719-4.296875h-264.449219c-30.859375 0-55.96875 25.105469-55.96875 55.96875v400.0625c0 30.859375 25.105469 55.96875 55.96875 55.96875h328.082031c30.859375 0 55.96875-25.105469 55.96875-55.96875v-338.296875c0-4.027344-1.617187-7.882813-4.488281-10.703125zm-100.113281-56.273438 52.921875 51.976563h-48.152344c-2.628906 0-4.769531-2.140625-4.769531-4.769531zm48.632812 431.242188h-328.082031c-14.316406 0-25.96875-11.648438-25.96875-25.96875v-400.0625c0-14.320312 11.648438-25.96875 25.96875-25.96875h249.453125v67.964844c0 19.171875 15.597656 34.769531 34.769531 34.769531h69.828125v323.296875c0 14.320312-11.648437 25.96875-25.96875 25.96875zm0 0"></path><path d="m324.644531 238h-211.453125c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h211.453125c8.285157 0 15-6.714844 15-15s-6.714843-15-15-15zm0 0"></path><path d="m113.191406 328h172.414063c8.285156 0 15-6.714844 15-15s-6.714844-15-15-15h-172.414063c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15zm0 0"></path><path d="m306.40625 358h-193.214844c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h193.214844c8.28125 0 15-6.714844 15-15s-6.71875-15-15-15zm0 0"></path></svg><g><title>lib/webpack.js</title><text x="128" y="49" data-path="lib/webpack.js">webpack.js</text></g><rect x="105" y="29" width="109.3" height="25"></rect></g><svg version="1.1" width="6px" height="6px" x="102.5" y="41.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><line x1="217" y1="44" x2="260" y2="45" shape-rendering="crispEdges" stroke-dasharray="2"></line><line x1="217" y1="42" x2="217" y2="47" shape-rendering="crispEdges" stroke-dasharray="2"></line><polyline shape-rendering="geometricPrecision" points="260,102, 232,93" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="260,136, 232,93" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="260,170, 232,93" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="260,221, 238,190" stroke-dasharray="2" stroke-linecap="round"></polyline></svg><div><div data-scroll-top="0"><pre><div><div><div><p><span>1</span><span></span></p><p><span>2</span><span></span></p><p><span><span></span>3</span><span>pubSub</span><span>.</span><span>subscribe</span><span>(</span><span>'myEvent'</span><span>,</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> console</span><span>.</span><span>log</span><span>(</span><span>'Handled by 1st subscriber'</span><span>)</span><span>)</span><span></span></p><p><span>4</span><span></span></p><p><span><span></span>5</span><span>pubSub</span><span>.</span><span>subscribe</span><span>(</span><span>'myEvent'</span><span>,</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> console</span><span>.</span><span>log</span><span>(</span><span>'Handled by 2nd subscriber'</span><span>)</span><span>)</span><span></span></p><p><span>6</span><span></span></p><p><span><span></span>7</span><span>pubSub</span><span>.</span><span>subscribe</span><span>(</span><span>'myEvent'</span><span>,</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> console</span><span>.</span><span>log</span><span>(</span><span>'Handled by 3rd subscriber'</span><span>)</span><span>)</span><span></span></p><p><span>8</span><span></span></p><p><span>9</span><span></span></p><p><span><span></span>10</span><span>pubSub</span><span>.</span><span>publish</span><span>(</span><span>'myEvent'</span><span>)</span><span></span></p><p><span>11</span><span></span></p></div></div></div></pre></div></div></div></div></div><div><div><p>Usually, <em>Pub-Sub</em> (<em>Observer</em> or <em>Listener</em><span>) behavioral pattern is used to establish a one-to-many relationship: publisher dispatches events <span>0</span><span> and multiple subscribers can listen to them accordingly <span>1</span>.  </span></span></p><p><em>Tapable</em> is the <em>Pub-Sub</em> implementation on steroids. One key difference - instead of just string event names, uses the "Hook" class instance per event. It implements <code>tap</code>/<code>tapAsync</code> with <code>call</code>/<code>callAsync</code> methods to listen and publish events, or even <code>intercept</code> them.  </p></div><div data-snapshot-id="22"><div><svg width="946" height="282" xmlns="http://www.w3.org/2000/svg" shape-rendering="optimizeSpeed"><rect x="0" y="0" width="946" height="282"></rect><polyline points="63.79,103.5, 105.5,103.5, 105.5,103.5"></polyline><g><svg version="1.1" x="17" y="95" viewBox="0 0 276.157 276.157" width="15" height="15" shape-rendering="geometricPrecision"><rect x="50" width="270" height="270" fill="white" opacity="0.4"></rect><path d="M273.081,101.378c-3.3-4.651-8.86-7.319-15.255-7.319h-24.34v-26.47c0-10.201-8.299-18.5-18.5-18.5  h-85.322c-3.63,0-9.295-2.876-11.436-5.806l-6.386-8.735c-4.982-6.814-15.104-11.954-23.546-11.954H58.731  c-9.293,0-18.639,6.608-21.738,15.372l-2.033,5.752c-0.958,2.71-4.721,5.371-7.596,5.371H18.5c-10.201,0-18.5,8.299-18.5,18.5  v167.07c0,0.885,0.161,1.73,0.443,2.519c0.152,3.306,1.18,6.424,3.053,9.064c3.3,4.652,8.86,7.319,15.255,7.319h188.486  c11.395,0,23.27-8.424,27.035-19.179l40.677-116.188C277.061,112.159,276.381,106.03,273.081,101.378z M18.5,64.089h8.864  c9.295,0,18.64-6.608,21.738-15.372l2.032-5.75c0.959-2.711,4.722-5.372,7.597-5.372h29.564c3.63,0,9.295,2.876,11.437,5.806  l6.386,8.734c4.982,6.815,15.104,11.954,23.546,11.954h85.322c1.898,0,3.5,1.603,3.5,3.5v26.47H69.34  c-11.395,0-23.27,8.424-27.035,19.179L15,191.231V67.589C15,65.692,16.603,64.089,18.5,64.089z M260.791,113.238l-40.677,116.188  c-1.674,4.781-7.812,9.135-12.877,9.135H18.751c-1.448,0-2.577-0.373-3.02-0.998c-0.443-0.625-0.423-1.814,0.056-3.181  l40.677-116.188c1.674-4.781,7.812-9.135,12.877-9.135h188.486c1.448,0,2.577,0.373,3.021,0.998  C261.29,110.682,261.27,111.871,260.791,113.238z"></path></svg><g><rect x="21" y="106" width="11" height="4"></rect><text x="22" y="109">..</text></g><text x="35" y="108" data-path="lib">lib</text><rect x="10" y="88" width="50.29" height="30"></rect></g><g><svg version="1.1" x="112" y="94" width="15" height="15" viewBox="0 0 512 512" shape-rendering="geometricPrecision"><rect x="50" width="512" height="512" fill="white"></rect><path d="m436.03125 107.03125-104.601562-102.734375c-2.804688-2.753906-6.578126-4.296875-10.511719-4.296875h-264.449219c-30.859375 0-55.96875 25.105469-55.96875 55.96875v400.0625c0 30.859375 25.105469 55.96875 55.96875 55.96875h328.082031c30.859375 0 55.96875-25.105469 55.96875-55.96875v-338.296875c0-4.027344-1.617187-7.882813-4.488281-10.703125zm-100.113281-56.273438 52.921875 51.976563h-48.152344c-2.628906 0-4.769531-2.140625-4.769531-4.769531zm48.632812 431.242188h-328.082031c-14.316406 0-25.96875-11.648438-25.96875-25.96875v-400.0625c0-14.320312 11.648438-25.96875 25.96875-25.96875h249.453125v67.964844c0 19.171875 15.597656 34.769531 34.769531 34.769531h69.828125v323.296875c0 14.320312-11.648437 25.96875-25.96875 25.96875zm0 0"></path><path d="m324.644531 238h-211.453125c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h211.453125c8.285157 0 15-6.714844 15-15s-6.714843-15-15-15zm0 0"></path><path d="m113.191406 328h172.414063c8.285156 0 15-6.714844 15-15s-6.714844-15-15-15h-172.414063c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15zm0 0"></path><path d="m306.40625 358h-193.214844c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h193.214844c8.28125 0 15-6.714844 15-15s-6.71875-15-15-15zm0 0"></path></svg><g><title>lib/Compiler.js</title><text x="128" y="108" data-path="lib/Compiler.js">Compiler.js</text></g><rect x="105" y="88" width="117.72999999999999" height="25"></rect></g><svg version="1.1" width="6px" height="6px" x="102.5" y="100.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><polyline points="225,103,252,103,252,44,262,44" shape-rendering="crispEdges" stroke-dasharray="2"></polyline><line x1="225" y1="101" x2="225" y2="106" shape-rendering="crispEdges" stroke-dasharray="2"></line><polyline shape-rendering="geometricPrecision" points="262,240, 240,209" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="262,206, 240,175" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="262,172, 240,141" stroke-dasharray="2" stroke-linecap="round"></polyline></svg><div><div data-scroll-top="695"><pre><div><div><div><p><span>39</span></p><p><span>40</span><span></span></p><p><span>41</span><span></span></p><p><span>42</span><span></span><span>class</span><span> </span><span>Compiler</span><span> </span><span>extends</span><span> </span><span>Tapable</span><span> </span><span>{</span><span></span></p><p><span>43</span><span>  </span><span>constructor</span><span>(</span><span>context</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>44</span><span>    </span><span>super</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>45</span><span>    </span><span>this</span><span>.</span><span>hooks </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>72</span><span>      </span><span></span></p><p><span><span></span>73</span><span>      beforeCompile</span><span>:</span><span> </span><span>new</span><span> </span><span>AsyncSeriesHook</span><span>(</span><span>[</span><span>"params"</span><span>]</span><span>)</span><span>,</span><span></span></p><p><span>74</span><span>      </span><span></span></p><p><span><span></span>75</span><span>      compile</span><span>:</span><span> </span><span>new</span><span> </span><span>SyncHook</span><span>(</span><span>[</span><span>"params"</span><span>]</span><span>)</span><span>,</span><span></span></p><p><span>76</span><span>      </span><span></span></p><p><span><span></span>77</span><span>      make</span><span>:</span><span> </span><span>new</span><span> </span><span>AsyncParallelHook</span><span>(</span><span>[</span><span>"compilation"</span><span>]</span><span>)</span><span>,</span><span></span></p><p><span>78</span><span>      </span><span></span></p><p><span>79</span><span>      afterCompile</span><span>:</span><span> </span><span>new</span><span> </span><span>AsyncSeriesHook</span><span>(</span><span>[</span><span>"compilation"</span><span>]</span><span>)</span><span>,</span><span></span></p><p><span>80</span><span></span></p></div></div></div></pre></div></div></div></div></div><div><div><p><span>On top of classic "Sync" (<span>0</span><span>) events handling, it also adds "AsyncSeries" (<span>1</span><span>), "AsyncParallel" (<span>2</span>) (handlers called in a row or parallel, respectively).  </span></span></span></p><p>On the scheme below you can see another example where plugins use a few more advanced hooks sub-classes from <code>tapable</code> ("Waterfall" and "Bail").  </p></div><div data-snapshot-id="15"><div><svg width="1195" height="519" xmlns="http://www.w3.org/2000/svg" shape-rendering="optimizeSpeed"><rect x="0" y="0" width="1195" height="519"></rect><path d="M 63.79 314.5 L 92.5 314.5 L 92.5 49.5 Q 92.5 44.5 97.5 44.5 L 105.5 44.5"></path><polyline points="92.5,269.5, 105.5,269.5"></polyline><polyline points="200.94,44.5, 243.5,44.5, 243.5,44.5"></polyline><path d="M 63.79 314.5 L 92.5 314.5 L 92.5 489.5 Q 92.5 494.5 97.5 494.5 L 105.5 494.5"></path><g><svg version="1.1" x="17" y="306" viewBox="0 0 276.157 276.157" width="15" height="15" shape-rendering="geometricPrecision"><rect x="50" width="270" height="270" fill="white" opacity="0.4"></rect><path d="M273.081,101.378c-3.3-4.651-8.86-7.319-15.255-7.319h-24.34v-26.47c0-10.201-8.299-18.5-18.5-18.5  h-85.322c-3.63,0-9.295-2.876-11.436-5.806l-6.386-8.735c-4.982-6.814-15.104-11.954-23.546-11.954H58.731  c-9.293,0-18.639,6.608-21.738,15.372l-2.033,5.752c-0.958,2.71-4.721,5.371-7.596,5.371H18.5c-10.201,0-18.5,8.299-18.5,18.5  v167.07c0,0.885,0.161,1.73,0.443,2.519c0.152,3.306,1.18,6.424,3.053,9.064c3.3,4.652,8.86,7.319,15.255,7.319h188.486  c11.395,0,23.27-8.424,27.035-19.179l40.677-116.188C277.061,112.159,276.381,106.03,273.081,101.378z M18.5,64.089h8.864  c9.295,0,18.64-6.608,21.738-15.372l2.032-5.75c0.959-2.711,4.722-5.372,7.597-5.372h29.564c3.63,0,9.295,2.876,11.437,5.806  l6.386,8.734c4.982,6.815,15.104,11.954,23.546,11.954h85.322c1.898,0,3.5,1.603,3.5,3.5v26.47H69.34  c-11.395,0-23.27,8.424-27.035,19.179L15,191.231V67.589C15,65.692,16.603,64.089,18.5,64.089z M260.791,113.238l-40.677,116.188  c-1.674,4.781-7.812,9.135-12.877,9.135H18.751c-1.448,0-2.577-0.373-3.02-0.998c-0.443-0.625-0.423-1.814,0.056-3.181  l40.677-116.188c1.674-4.781,7.812-9.135,12.877-9.135h188.486c1.448,0,2.577,0.373,3.021,0.998  C261.29,110.682,261.27,111.871,260.791,113.238z"></path></svg><g><rect x="21" y="317" width="11" height="4"></rect><text x="22" y="320">..</text></g><text x="35" y="319" data-path="lib">lib</text><rect x="10" y="299" width="50.29" height="30"></rect></g><g><svg version="1.1" x="112" y="36" viewBox="0 0 276.157 276.157" width="15" height="15" shape-rendering="geometricPrecision"><rect x="50" width="270" height="270" fill="white" opacity="0.4"></rect><path d="M273.081,101.378c-3.3-4.651-8.86-7.319-15.255-7.319h-24.34v-26.47c0-10.201-8.299-18.5-18.5-18.5  h-85.322c-3.63,0-9.295-2.876-11.436-5.806l-6.386-8.735c-4.982-6.814-15.104-11.954-23.546-11.954H58.731  c-9.293,0-18.639,6.608-21.738,15.372l-2.033,5.752c-0.958,2.71-4.721,5.371-7.596,5.371H18.5c-10.201,0-18.5,8.299-18.5,18.5  v167.07c0,0.885,0.161,1.73,0.443,2.519c0.152,3.306,1.18,6.424,3.053,9.064c3.3,4.652,8.86,7.319,15.255,7.319h188.486  c11.395,0,23.27-8.424,27.035-19.179l40.677-116.188C277.061,112.159,276.381,106.03,273.081,101.378z M18.5,64.089h8.864  c9.295,0,18.64-6.608,21.738-15.372l2.032-5.75c0.959-2.711,4.722-5.372,7.597-5.372h29.564c3.63,0,9.295,2.876,11.437,5.806  l6.386,8.734c4.982,6.815,15.104,11.954,23.546,11.954h85.322c1.898,0,3.5,1.603,3.5,3.5v26.47H69.34  c-11.395,0-23.27,8.424-27.035,19.179L15,191.231V67.589C15,65.692,16.603,64.089,18.5,64.089z M260.791,113.238l-40.677,116.188  c-1.674,4.781-7.812,9.135-12.877,9.135H18.751c-1.448,0-2.577-0.373-3.02-0.998c-0.443-0.625-0.423-1.814,0.056-3.181  l40.677-116.188c1.674-4.781,7.812-9.135,12.877-9.135h188.486c1.448,0,2.577,0.373,3.021,0.998  C261.29,110.682,261.27,111.871,260.791,113.238z"></path></svg><g><rect x="116" y="47" width="11" height="4"></rect><text x="117" y="50">..</text></g><text x="130" y="49" data-path="lib/optimize">optimize</text><rect x="105" y="29" width="92.44" height="30"></rect></g><g><svg version="1.1" x="112" y="260" width="15" height="15" viewBox="0 0 512 512" shape-rendering="geometricPrecision"><rect x="50" width="512" height="512" fill="white"></rect><path d="m436.03125 107.03125-104.601562-102.734375c-2.804688-2.753906-6.578126-4.296875-10.511719-4.296875h-264.449219c-30.859375 0-55.96875 25.105469-55.96875 55.96875v400.0625c0 30.859375 25.105469 55.96875 55.96875 55.96875h328.082031c30.859375 0 55.96875-25.105469 55.96875-55.96875v-338.296875c0-4.027344-1.617187-7.882813-4.488281-10.703125zm-100.113281-56.273438 52.921875 51.976563h-48.152344c-2.628906 0-4.769531-2.140625-4.769531-4.769531zm48.632812 431.242188h-328.082031c-14.316406 0-25.96875-11.648438-25.96875-25.96875v-400.0625c0-14.320312 11.648438-25.96875 25.96875-25.96875h249.453125v67.964844c0 19.171875 15.597656 34.769531 34.769531 34.769531h69.828125v323.296875c0 14.320312-11.648437 25.96875-25.96875 25.96875zm0 0"></path><path d="m324.644531 238h-211.453125c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h211.453125c8.285157 0 15-6.714844 15-15s-6.714843-15-15-15zm0 0"></path><path d="m113.191406 328h172.414063c8.285156 0 15-6.714844 15-15s-6.714844-15-15-15h-172.414063c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15zm0 0"></path><path d="m306.40625 358h-193.214844c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h193.214844c8.28125 0 15-6.714844 15-15s-6.71875-15-15-15zm0 0"></path></svg><g><title>lib/Compilation.js</title><text x="128" y="274" data-path="lib/Compilation.js">Compilation.js</text></g><rect x="105" y="254" width="143.01999999999998" height="25"></rect></g><g><svg version="1.1" x="112" y="485" width="15" height="15" viewBox="0 0 512 512" shape-rendering="geometricPrecision"><rect x="50" width="512" height="512" fill="white"></rect><path d="m436.03125 107.03125-104.601562-102.734375c-2.804688-2.753906-6.578126-4.296875-10.511719-4.296875h-264.449219c-30.859375 0-55.96875 25.105469-55.96875 55.96875v400.0625c0 30.859375 25.105469 55.96875 55.96875 55.96875h328.082031c30.859375 0 55.96875-25.105469 55.96875-55.96875v-338.296875c0-4.027344-1.617187-7.882813-4.488281-10.703125zm-100.113281-56.273438 52.921875 51.976563h-48.152344c-2.628906 0-4.769531-2.140625-4.769531-4.769531zm48.632812 431.242188h-328.082031c-14.316406 0-25.96875-11.648438-25.96875-25.96875v-400.0625c0-14.320312 11.648438-25.96875 25.96875-25.96875h249.453125v67.964844c0 19.171875 15.597656 34.769531 34.769531 34.769531h69.828125v323.296875c0 14.320312-11.648437 25.96875-25.96875 25.96875zm0 0"></path><path d="m324.644531 238h-211.453125c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h211.453125c8.285157 0 15-6.714844 15-15s-6.714843-15-15-15zm0 0"></path><path d="m113.191406 328h172.414063c8.285156 0 15-6.714844 15-15s-6.714844-15-15-15h-172.414063c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15zm0 0"></path><path d="m306.40625 358h-193.214844c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h193.214844c8.28125 0 15-6.714844 15-15s-6.71875-15-15-15zm0 0"></path></svg><g><title>lib/FlagDependencyUsagePlugin.js</title><text x="128" y="499" data-path="lib/FlagDependencyUsagePlugin.js">FlagDependencyUsagePlugin.js</text></g><rect x="105" y="479" width="261.03999999999996" height="25"></rect></g><g><svg version="1.1" x="250" y="35" width="15" height="15" viewBox="0 0 512 512" shape-rendering="geometricPrecision"><rect x="50" width="512" height="512" fill="white"></rect><path d="m436.03125 107.03125-104.601562-102.734375c-2.804688-2.753906-6.578126-4.296875-10.511719-4.296875h-264.449219c-30.859375 0-55.96875 25.105469-55.96875 55.96875v400.0625c0 30.859375 25.105469 55.96875 55.96875 55.96875h328.082031c30.859375 0 55.96875-25.105469 55.96875-55.96875v-338.296875c0-4.027344-1.617187-7.882813-4.488281-10.703125zm-100.113281-56.273438 52.921875 51.976563h-48.152344c-2.628906 0-4.769531-2.140625-4.769531-4.769531zm48.632812 431.242188h-328.082031c-14.316406 0-25.96875-11.648438-25.96875-25.96875v-400.0625c0-14.320312 11.648438-25.96875 25.96875-25.96875h249.453125v67.964844c0 19.171875 15.597656 34.769531 34.769531 34.769531h69.828125v323.296875c0 14.320312-11.648437 25.96875-25.96875 25.96875zm0 0"></path><path d="m324.644531 238h-211.453125c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h211.453125c8.285157 0 15-6.714844 15-15s-6.714843-15-15-15zm0 0"></path><path d="m113.191406 328h172.414063c8.285156 0 15-6.714844 15-15s-6.714844-15-15-15h-172.414063c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15zm0 0"></path><path d="m306.40625 358h-193.214844c-8.285156 0-15 6.714844-15 15s6.714844 15 15 15h193.214844c8.28125 0 15-6.714844 15-15s-6.71875-15-15-15zm0 0"></path></svg><g><title>lib/optimize/SideEffectsFlagPlugin.js</title><text x="266" y="49" data-path="lib/optimize/SideEffectsFlagPlugin.js">SideEffectsFlagPlugin.js</text></g><rect x="243" y="29" width="227.32" height="25"></rect></g><svg version="1.1" width="6px" height="6px" x="102.5" y="41.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><svg version="1.1" width="6px" height="6px" x="102.5" y="266.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><svg version="1.1" width="6px" height="6px" x="102.5" y="491.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><svg version="1.1" width="6px" height="6px" x="240.5" y="41.5" shape-rendering="geometricPrecision"><circle r="2.5" cx="3" cy="3"></circle></svg><polyline points="368,494,427,494,427,382,437,382" shape-rendering="crispEdges" stroke-dasharray="2"></polyline><line x1="368" y1="492" x2="368" y2="497" shape-rendering="crispEdges" stroke-dasharray="2"></line><line x1="472" y1="44" x2="515" y2="45" shape-rendering="crispEdges" stroke-dasharray="2"></line><line x1="472" y1="42" x2="472" y2="47" shape-rendering="crispEdges" stroke-dasharray="2"></line><polyline points="250,269,487,269,487,199,497,199" shape-rendering="crispEdges" stroke-dasharray="2"></polyline><line x1="250" y1="267" x2="250" y2="272" shape-rendering="crispEdges" stroke-dasharray="2"></line><g><path shape-rendering="geometricPrecision" d="M 369 495 C 368 494, 392.8145498617046 450.78555663714997, 432 420"></path><path shape-rendering="geometricPrecision" d="M 368 494 C 368 494, 392.8145498617046 450.78555663714997, 432 420" data-connection-path="lib/Compilation.js|lib/FlagDependencyUsagePlugin.js"></path><path shape-rendering="geometricPrecision" d="M 368 494 C 368 494, 392.8145498617046 450.78555663714997, 432 420"></path><circle cx="369" cy="495" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="368" cy="494" r="3" shape-rendering="geometricPrecision"></circle><svg version="1.1" x="426.5" y="414.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-49.1446deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="425.5" y="413.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-49.1446deg); transform-origin: 50% 50%;"></path></g></svg></g><g><path shape-rendering="geometricPrecision" d="M 106 270 Q 95 381.5 105 494"></path><path shape-rendering="geometricPrecision" d="M 105 269 Q 95 381.5 105 494" data-connection-path="lib/Compilation.js|lib/FlagDependencyUsagePlugin.js"></path><path shape-rendering="geometricPrecision" d="M 105 269 Q 95 381.5 105 494"></path><circle cx="106" cy="270" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="105" cy="269" r="3" shape-rendering="geometricPrecision"></circle><circle cx="106" cy="495" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="105" cy="494" r="3" shape-rendering="geometricPrecision"></circle><svg version="1.1" x="94.5" y="376" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(90deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="93.5" y="375" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(90deg); transform-origin: 50% 50%;"></path></g></svg></g><g><path shape-rendering="geometricPrecision" d="M 473 45 C 472 44, 494.53553390593277 59.46446609406726, 510 82"></path><path shape-rendering="geometricPrecision" d="M 472 44 C 472 44, 494.53553390593277 59.46446609406726, 510 82" data-connection-path="lib/Compilation.js|lib/optimize/SideEffectsFlagPlugin.js"></path><path shape-rendering="geometricPrecision" d="M 472 44 C 472 44, 494.53553390593277 59.46446609406726, 510 82"></path><circle cx="473" cy="45" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="472" cy="44" r="3" shape-rendering="geometricPrecision"></circle><svg version="1.1" x="504.5" y="76.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(45deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="503.5" y="75.5" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(45deg); transform-origin: 50% 50%;"></path></g></svg></g><g><path shape-rendering="geometricPrecision" d="M 106 270 Q 197.01582219492965 170.61637094622353 243 44"></path><path shape-rendering="geometricPrecision" d="M 105 269 Q 197.01582219492965 170.61637094622353 243 44" data-connection-path="lib/Compilation.js|lib/optimize/SideEffectsFlagPlugin.js"></path><path shape-rendering="geometricPrecision" d="M 105 269 Q 197.01582219492965 170.61637094622353 243 44"></path><circle cx="106" cy="270" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="105" cy="269" r="3" shape-rendering="geometricPrecision"></circle><circle cx="244" cy="45" r="3.5" shape-rendering="geometricPrecision"></circle><circle cx="243" cy="44" r="3" shape-rendering="geometricPrecision"></circle><svg version="1.1" x="180.0079110974648" y="158.05818547311176" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-58.4778deg); transform-origin: 50% 50%;"></path></g></svg><svg version="1.1" x="179.0079110974648" y="157.05818547311176" viewBox="0 0 448.011 448.011" width="13" height="13" shape-rendering="geometricPrecision"><g><path d="M438.731,209.463l-416-192c-6.624-3.008-14.528-1.216-19.136,4.48c-4.64,5.696-4.8,13.792-0.384,19.648l136.8,182.4    l-136.8,182.4c-4.416,5.856-4.256,13.984,0.352,19.648c3.104,3.872,7.744,5.952,12.448,5.952c2.272,0,4.544-0.48,6.688-1.472    l416-192c5.696-2.624,9.312-8.288,9.312-14.528S444.395,212.087,438.731,209.463z" style="transform: rotate(-58.4778deg); transform-origin: 50% 50%;"></path></g></svg></g><polyline shape-rendering="geometricPrecision" points="437,423, 337,356" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="515,85, 458,97" stroke-dasharray="2" stroke-linecap="round"></polyline><polyline shape-rendering="geometricPrecision" points="497,262, 467,251" stroke-dasharray="2" stroke-linecap="round"></polyline></svg><div><div data-scroll-top="442"><pre><div><div><div><p><span>25</span><span></span><span>class</span><span> </span><span>FlagDependencyUsagePlugin</span><span> </span><span>{</span><span></span></p><p><span>26</span><span>  </span><span>apply</span><span>(</span><span>compiler</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>27</span><span>    compiler</span><span>.</span><span>hooks</span><span>.</span><span>compilation</span><span>.</span><span>tap</span><span>(</span><span>"FlagDependencyUsagePlugin"</span><span>,</span><span> </span><span>compilation</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span><span></span>28</span><span>      compilation</span><span>.</span><span>hooks</span><span>.</span><span>optimizeDependencies</span><span>.</span><span>tap</span><span>(</span><span></span></p><p><span>29</span><span>        </span><span>"FlagDependencyUsagePlugin"</span><span>,</span><span></span></p><p><span>30</span><span>        </span><span>modules</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>31</span><span>          </span><span>const</span><span> </span><span>processModule</span><span> </span><span>=</span><span> </span><span>(</span><span>module</span><span>,</span><span> usedExports</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>32</span><span>            module</span><span>.</span><span>used </span><span>=</span><span> </span><span>true</span><span>;</span><span></span></p><p><span>33</span><span>            </span><span>if</span><span> </span><span>(</span><span>module</span><span>.</span><span>usedExports </span><span>===</span><span> </span><span>true</span><span>)</span><span> </span><span>return</span><span>;</span><span></span></p><p><span>34</span><span>            </span><span>if</span><span> </span><span>(</span><span>usedExports </span><span>===</span><span> </span><span>true</span><span>)</span><span> </span><span>{</span><span></span></p></div></div></div></pre></div></div><div><div data-scroll-top="850"><pre><div><div><div><p><span>49</span><span>      </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>50</span><span>    </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>51</span><span>    compiler</span><span>.</span><span>hooks</span><span>.</span><span>compilation</span><span>.</span><span>tap</span><span>(</span><span>"SideEffectsFlagPlugin"</span><span>,</span><span> </span><span>compilation</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span><span></span>52</span><span>      compilation</span><span>.</span><span>hooks</span><span>.</span><span>optimizeDependencies</span><span>.</span><span>tap</span><span>(</span><span></span></p><p><span>53</span><span>        </span><span>"SideEffectsFlagPlugin"</span><span>,</span><span></span></p><p><span>54</span><span>        </span><span>modules</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>55</span><span>          </span><span></span></p><p><span>56</span><span>          </span><span>const</span><span> reexportMaps </span><span>=</span><span> </span><span>new</span><span> </span><span>Map</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>57</span><span></span></p><p><span>58</span><span>          </span><span></span></p></div></div></div></pre></div></div><div><div data-scroll-top="21840"><pre><div><div><div><p><span>1283</span><span>  </span><span>seal</span><span>(</span><span>callback</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>1284</span><span>    </span><span>this</span><span>.</span><span>hooks</span><span>.</span><span>seal</span><span>.</span><span>call</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>1285</span><span></span></p><p><span>1286</span><span>    </span><span>while</span><span> </span><span>(</span><span></span></p><p><span>1287</span><span>      </span><span>this</span><span>.</span><span>hooks</span><span>.</span><span>optimizeDependenciesBasic</span><span>.</span><span>call</span><span>(</span><span>this</span><span>.</span><span>modules</span><span>)</span><span> </span><span>||</span><span></span></p><p><span><span></span>1288</span><span>      </span><span>this</span><span>.</span><span>hooks</span><span>.</span><span>optimizeDependencies</span><span>.</span><span>call</span><span>(</span><span>this</span><span>.</span><span>modules</span><span>)</span><span> </span><span>||</span><span></span></p><p><span>1289</span><span>      </span><span>this</span><span>.</span><span>hooks</span><span>.</span><span>optimizeDependenciesAdvanced</span><span>.</span><span>call</span><span>(</span><span>this</span><span>.</span><span>modules</span><span>)</span><span></span></p><p><span>1290</span><span>    </span><span>)</span><span> </span><span>{</span><span></span></p><p><span>1291</span><span>      </span><span></span></p><p><span>1292</span><span>    </span><span>}</span><span></span></p><p><span>1293</span><span>    </span><span>this</span><span>.</span><span>hooks</span><span>.</span><span>afterOptimizeDependencies</span><span>.</span><span>call</span><span>(</span><span>this</span><span>.</span><span>modules</span><span>)</span><span>;</span><span></span></p></div></div></div></pre></div></div></div></div></div><div><div><p>Using them with <code>callback</code> allows us to pass data between different subscribers (Waterfall) or exit early (Bail).  </p><p><span><p>Event-driven architecture has some pros&amp;cons. Like any other architectures there is no <em>silver bullet</em>. Within <em>webpack</em>, however, it brings endless scalability and works very well with a pipeline of loosely-coupled plugins.  </p></span></p><p>To learn more about <code>tapable</code> library checkout <a href="https://github.com/webpack/tapable">tapable repository</a>.  </p></div></div><div><p><span>Stay tuned for more stories like this</span></p><div><div><div><h3>Follow me on Twitter</h3><p><img width="130" src="https://pbs.twimg.com/profile_images/1252517326047641602/8KC5OLsx_400x400.jpg"></p><div><p>Code geek. I tweet about interesting code tips and findings I am discovering under the hood of popular open source projects.</p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://codecrumbs.io/stories/webpack-tapable-core</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006235</guid>
            <pubDate>Fri, 31 Jul 2020 06:30:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Gentle Introduction to HVMI (Hypervisor Memory Introspection)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006120">thread link</a>) | @__rompy
<br/>
July 30, 2020 | https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <h2 id="introduction">Introduction</h2>

<p>Hypervisor memory introspection (HVMI) has been around for quite some time now, and there are several open-source projects utilizing virtual-machine introspection (VMI), one way or another. Generally, existing projects focus on debugging or tracing the execution of a guest VM. In this blog post, we introduce a slightly different approach to memory introspection; live protection of guest VMs. We cover the motivation behind our HVMI engine, how it was conceived, how it evolved over time, and finally, why we made it available for everyone.</p>

<p>Throughout this blog, we assume the reader has some basic knowledge about virtualization technologies (Intel VT-x specifically) and about OS internals (both Windows and Linux), although we try to cover as much ground as possible when it comes to technical details.</p>

<h2 id="what-hvmi-is">What HVMI Is</h2>

<p>Memory introspection is the technique of analyzing the contents of a guest VM from outside. The most common way to achieve this is using a hypervisor – running guest VMs are analyzed or introspected by the hypervisor. The CPU context can be viewed, the contents of the physical memory can be observed, and so on. In addition to simply analyzing the state of the VM, the introspection logic, or HVMI (how we refer to it from here on) also leverages the virtualization features provided by the CPU to provide security.</p>

<p>For example, by using the Extended Page Table (EPT) feature provided by Intel CPUs, HVMI overrides the guest OS memory protection policies. HVMI could, for example, enforce a no-execute policy for certain memory areas, and an exploit would fail even if it compromised the OS kernel. In addition to using the EPT to enforce memory access restrictions, HVMI can also use other virtualization capabilities to offer security. It can prevent modification of certain critical resources, such as control registers or model specific registers. Rootkits or exploits that rely on modifying these will fail because HVMI blocks the modifications.</p>

<p>HVMI is not about just advantages; it does have some drawbacks. One of the most important disadvantages of HVMI is the semantic gap – from outside the VM, we see only raw physical memory, with no apparent meaning. To do something useful, we must infer what those memory pages contain. Is it a process structure, is it a stack page, etc. In addition to the semantic gap, providing protection for certain system resources may prove challenging, from a performance point of view. Many legitimate accesses made inside a page that contains a protected structure may induce a severe performance overhead; this makes choosing what structures to protect a very difficult task. Finally, implementing HVMI is often very complex since it often requires reverse-engineering chunks of OS kernel, advanced knowledge about virtualization and, of course, software engineering.</p>

<h2 id="hvmi-history">HVMI History</h2>

<p>HVMI began as a research idea almost 10 years ago (late 2011). The team initially consisted of only one researcher (yours truly), who developed the initial PoC (simple driver-object protection via EPT, to block the TDL rootkit). Once the blessing from the powers that be was received, more time and effort was invested into this research, and the team began to grow. What was initially very straightforward code capable of protecting a handful of non-paged kernel memory pages on Windows 7 grew to become a beast capable of protecting all Windows versions starting with Windows 7, several Linux distros, and, on each of these, even user-mode processes, from various types of attacks.</p>

<p>HVMI was available as a commercial product in 2017, as part of the SVE package – Security for Virtualized Environments. During this time, it was polished, performance was improved, and several new features were developed. In late 2019, we decided to open-source the technology to make it available for everyone to see, use, play with, and extend with new features and capabilities.</p>

<h2 id="how-hvmi-works">How HVMI Works</h2>

<p>In essence, HVMI requires a hypervisor that provides the required API to provide protection. The required API can be explored in the official documentation TODO ref. Once such an API is provided, HVMI places several types of hooks inside the guest. For example, it can intercept control register 3 (CR3 - the register containing the address of the page-tables used for translating linear addresses to physical addresses) – this way, HVMI intercepts context switches inside the guest. By intercepting, for example, SYSCALL MSR writes, HVMI intercepts and blocks attempts to manipulate the SYSCALL entry point address. Most importantly, it uses the EPT to alter physical memory access permissions, thus overriding and restricting access to certain areas of the guest memory.</p>

<h3 id="general-architecture">General Architecture</h3>

<p>The HVMI engine is a standalone library, self-contained (it has no explicit external dependencies), and can be run in user-mode, kernel-mode, or even VMX root-mode. It is written entirely in C, with small bits and pieces written in assembly. The HVMI engine expects an interface containing several API functions to be exposed to it by whatever integrates with it. In this context, the integrator is a tool that binds the HVMI library to a particular hypervisor which provides a uniform API.</p>

<p>Supported hypervisors include our internally built Napoca hypervisor TODO ref, and the well-known open-source hypervisors Xen and KVM. Using the Napoca hypervisor, the HVMI engine runs directly inside VMX root, alongside the HV. In Xen and KVM, the HVMI engine runs as a regular user-mode process inside a special VM (or domain), or even dom0. The general architecture of HVMI is illustrated in the following image:</p>

<p><img src="https://hvmi.github.io/blog/assets/architecture.png" alt="General HVMI architecture on Xen/KVM"></p>

<p>From a functional perspective, HVMI is an event-driven library. When introspection is enabled for a guest VM, HVMI starts by identifying the guest operating system type, version, to find various important structures inside its memory. This process is asynchronous, meaning that once the initialization function returns, there’s no guarantee that HVMI has finished initialization; some parts of the guest introspection process occur when various events take place (for example, when CR3 is written). Once introspection is enabled, HVMI kicks-in when interesting events take-place within the guest; when a process is created or terminated, when a new memory region is allocated inside a protected process, or when memory accesses take place inside a protected region.</p>

<h2 id="making-use-of-hvmi">Making Use of HVMI</h2>

<p>Although we won’t go into very deep details (yet!) regarding the internals of the HVMI engine, here’s a list of the most important features HVMI exposes:</p>

<ul>
  <li>The list of loaded kernel mode drivers, with load/unload events;</li>
  <li>The list of user-mode processes, with create/terminate events;</li>
  <li>For processes that are protected, the list of loaded user-mode DLLs with load/unload events, and the list of Virtual Address Descriptors for that process with alloc/free events;</li>
  <li>On Windows, access to the Page Frame Number (PFN) Database;</li>
  <li>On Windows, the ability to parse the object tree (this is currently used to search for driver-objects inside guest memory, but it can easily be extended to handle any kind of object);</li>
</ul>

<p>As for OS agnostic features HVMI provides:</p>

<ul>
  <li>Guest hardware registers state query;</li>
  <li>Guest physical memory access;</li>
  <li>Ability to place read/write/execute hooks on physical memory;</li>
  <li>Ability to place read/write/execute hooks on virtual memory;</li>
  <li>Ability to place access hooks on control registers;</li>
  <li>Ability to place access hooks on model specific registers;</li>
  <li>Ability to place access hooks on descriptor table registers;</li>
  <li>Ability to intercept exceptions that take place inside the guest (for example, #PF, #BP, etc.);</li>
  <li>Ability inject exceptions inside the guest;</li>
  <li>Access to swapped out guest memory (by injecting #PF inside the guest);</li>
  <li>Ability to hide certain guest memory contents (reads issued inside the guest will be fed with custom values);</li>
  <li>Advanced instruction decoding and handling (the disassembler used by HVMI provides extended information about the decoded instructions, making information extraction and emulation very simple)</li>
</ul>

<h3 id="protection-features">Protection features</h3>

<p>The primary purpose of the HVMI engine is to, above all, provide protection. The following list contains the main types of threats HVMI was built to mitigate:</p>

<ul>
  <li>Binary exploits inside protected processes;</li>
  <li>Code and data injection techniques inside protected processes;</li>
  <li>Function hooks inside protected processes, on designated system DLLs;</li>
  <li>Rootkits (various techniques are blocked, such as inline hooks inside the kernel or other drivers, SSDT hooks, Driver-object hooks, system register modifications, etc.);</li>
  <li>Kernel exploits;</li>
  <li>Privilege escalation;</li>
  <li>Credentials theft;</li>
  <li>Deep process introspection (prevents process creation if the parent process has been compromised);</li>
  <li>Fileless malware (powershell command line scanning).</li>
</ul>

<h2 id="start-contributing">Start Contributing</h2>

<p>We see great potential for the HVMI project, which is why we decided to open-source it and make it available to everyone. Researchers are welcome to clone the project, run it, experiment, and add new features. We also accept pull-requests – if you think your feature is cool enough, be sure to make it available on the main HVMI repo!</p>

<p>Intel is continuously developing new virtualization technologies which make HVMI better and faster. Some of these have already been released, such as the Virtualization Exception (#VE), VM Functions (VMFUNC) and Sub Page Permissions (SPP), and HVMI makes use of them. Others, such as Hypervisor Linear Address Translations (HLAT) have recently been announced, and will make it into silicon in the upcoming years. We are sure that other technologies are yet to come, showing that both hardware vendors and software developers want to invest time and effort to create new virtualization features!</p>



<ul>
  <li>The HVMI project is located at <a href="https://github.com/hvmi">https://github.com/hvmi</a>;</li>
  <li>The documentation is available at <a href="https://hvmi.readthedocs.io/">https://hvmi.readthedocs.io</a> - it contains both a high-level documentation and the low-level source code documentation, in Doxygen format;</li>
  <li>For any …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html">https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006120</guid>
            <pubDate>Fri, 31 Jul 2020 06:00:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Realistic Portraits of Historical Figures from Paintings Using a GAN Neural Net]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24006070">thread link</a>) | @kanobo
<br/>
July 30, 2020 | https://www.basuterwijk.com/portfolio/G0000WVKM6MbiIAc | <a href="https://web.archive.org/web/*/https://www.basuterwijk.com/portfolio/G0000WVKM6MbiIAc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.basuterwijk.com/portfolio/G0000WVKM6MbiIAc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006070</guid>
            <pubDate>Fri, 31 Jul 2020 05:49:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need no Service Mesh]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24005953">thread link</a>) | @SerCe
<br/>
July 30, 2020 | https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/ | <a href="https://web.archive.org/web/*/https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Hi!</p>
<p>Service meshes have attracted an enormous amount of hype around them. With at least a few talks about service meshes during each tech conference, one can easily be convinced that having a service mesh in their infrastructure is a must. However, hype isn’t a good indicator of whether the new shiny tech is the right solution for your problems. So below, I’ll try to express an anti-hype opinion on service meshes to hopefully make it less confusing when you want to decide whether you may or may not need one.</p>
<p><span><img src="https://serce.me/img/servicemesh/rick.png" alt="rick"></span></p>
<div>
<blockquote>
<p>There’s a lesson here, and I’m not going to be the one to figure it out.</p>
</blockquote>
<p>
— Rick Sanchez
</p>
</div>
<div>
<h3 id="_the_invention">The invention</h3>
<p>Let’s take a step back in history and take a look at one of the <a href="https://eng.lyft.com/envoy-7-months-later-41986c2fd443">early articles</a> about introducing Envoy at Lyft.</p>
<div>
<blockquote>
<p>As it turns out, almost every company with a moderately-sized service oriented architecture is having the same problems that Lyft did prior to the development and deployment of Envoy:</p>
<div>
<ul>
<li>
<p>An architecture composed of a variety of languages, each containing a half-baked RPC library, including partial (or zero) implementations of rate limiting, circuit breaking, timeouts, retries, etc.</p>
</li>
<li>
<p>Differing or partial implementations of stats, logging, and ….</p>
</li>
</ul>
</div>
</blockquote>
</div>
<p>While Envoy is not a service mesh by itself, the outlined problems describe the exact reason why service meshes were invented. They add “rate limiting, circuit breaking, …” and other reliability, observability, and security features to the services by enforcing the communication to go through the service mesh proxies, a data plane. Additionally, they require a separate component, a control plane, to control the configuration.</p>
<p>However, at this point, a lot of people miss the context in which service meshes were introduced. Service meshes are able to solve the problem not because it’s impossible to solve them in any other way. There are many battle-proof RPC libraries that take on the challenges of a separate data plane layer, <a href="https://github.com/twitter/finagle">Finagle</a>, <a href="https://github.com/grpc">gRPC</a>, <a href="https://github.com/line/armeria">Armeria</a>, <a href="https://github.com/apple/servicetalk">Servicetalk</a>, to name a few. After all, the very first service mesh - Linkerd 1.0 <a href="https://github.com/linkerd/linkerd">is powered by Finagle</a>. The RPC libraries will need a component which provides service discovery and configuration management to make it a true mesh. For instance, Zookeeper, or Consul, a component that service meshes call a control plane.</p>
<p>Why introduce a new concept to solve the problems that have been solved before? The service mesh concept wasn’t introduced to address problems that hadn’t been addressed before but rather address them in a way that doesn’t require any modifications to the application code, which is incredibly convenient when it’s hard to introduce an RPC layer into an existing heterogeneous microservice environment.</p>
<p>When you hear service mesh, Istio with Envoy might be the first thing that comes to mind, but it wasn’t the first service mesh to enter the market. Linkerd authors who pioneered the space, described exactly this situation in the <a href="https://linkerd.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/#why-is-the-service-mesh-necessary">"why is the service mesh necessary"</a>. Interestingly, in many hype-y articles on the Internet this context is often forgotten, or omitted.</p>
<p>Solving a problem well, even if it’s a problem that a lot of people have, doesn’t magically provide the tech with a lot of hype. There is always a sponsor behind it. I don’t know who the sponsor was here, and I’m going to speculate, but it’s hard to sell an RPC library in the world where open source is a fundamental requirement. There is no clear business model there, that’s why most of the mature RPC libraries were open-sourced by large tech companies for which it’s not a part of the core business model. A library is just code, not a piece of infrastructure. Service meshes are a different story. It’s an isolated non-trivial piece of infrastructure. As a vendor, not only can you provide consultancy around the configuration and deployment, but you can also sell complete hosted solutions around it.</p>
</div>
<div>
<h3 id="_disillusionments">Disillusionments</h3>
<p>Now that we’ve established the problems, the solution, and most importantly, the context in which the solution was made, let’s take a look at the alternatives. The most obvious one, in the spirit of KISS, is to use an RPC library for your preferred language. Here is where the context is crucial: if you have a large fleet of services, each written in its own language/ecosystem, and the only language that they share is HTTP then having a single shared RPC library is going to be hard. Perhaps, you’ve got a fabric of deployed and running services, but everyone is afraid of touching them, no one knows how they work, and each redeploy is an adventure. A service mesh is here to help you, because at least you’ll be able to roll out new infrastructure features to the mesh regularly.</p>
<p>On the other hand, if you have a fleet of healthy services written in a single application stack, then it’s a good idea to think twice before introducing a service mesh. By simply introducing or evolving a shared RPC library, you’ll get the exact same benefits and avoid dealing with the downsides of maintaining service meshes. By studying the service mesh limitations thoroughly, you can avoid finding yourself in the trough of disillusionment.</p>
<p><span><img src="https://serce.me/img/servicemesh/curve.png" alt="Hype Cycle"></span></p>
<div>
<h4 id="_different_ecosystem">Different ecosystem</h4>
<p>The ecosystem of the service mesh of your choice will likely be different from the ecosystem of your services. Beautiful websites always make you believe that the solution is plug’n’play, always works and never goes down. In reality, sooner or later problems, bugs, quirks in behaviour will reveal themselves, as they always do. At that point, you’ll need to have engineers who work on the service-mesh’s ecosystem which when it’s different from the main app, effectively limits the set of people who can introduce changes or fix problems. This is likely to reintroduce silos, which is against the whole DevOps spirit. Yes, having a DevOps team of engineers who are doing DevOps-y things <a href="https://continuousdelivery.com/2012/10/theres-no-such-thing-as-a-devops-team/">is against DevOps</a>.</p>
</div>
<div>
<h4 id="_unnecessary_overhead">Unnecessary overhead</h4>
<p>Not only having a proxy in front of each service adds overhead (often significant, talking about <a href="https://istio.io/latest/docs/ops/deployment/performance-and-scalability/">90pt</a> rather than 99pt in the performance summary <a href="https://www.infoq.com/presentations/latency-response-time/">doesn’t make software run faster</a>) and consumes resources, but you also requires time (or rather a team of people) to manage them. Yes, it can help to make some of the tasks potentially easier - yay, you can now add canary deployments with a few lines of YAML to simple applications now. However, you still need to manage canary deployments of the proxies themselves which don’t have a proxy in front of them. The problems just get pushed up the stack.</p>
</div>
<div>
<h4 id="_limiting_your_architecture_to_what_the_proxy_supports">Limiting your architecture to what The Proxy supports.</h4>
<p>As you’re reading this paragraph, HTTP/3 is slowly being rolled out to the Internet. It uses UDP as transport. Why use UDP rather than create a completely new protocol you ask? That’s because anything but TCP and UDP is simply “blocked” by the boxes, various proxies on the internet - routers, gateways, etc. This phenomenon got named <a href="https://http3-explained.haxx.se/en/why-quic/why-ossification">ossification</a>. So, only TCP or UDP are left is the practical chose, and even UDP is partially blocked by various corporate proxies which slows down the adoption.</p>
<p>Even though your microservice environment is probably much smaller compared to the Internet, you can draw parallels with service meshes. Proxies can ossify your application architecture by limiting how your services talk to each other, and there is not much benefit in having proxies if you can bypass them. Suppose you want to build a reactive application which is using RSocket over pure tcp? Or perhaps a message-driven application using an actor model? Or maybe push the performance boundaries with Aeron? Not going to happen until the box in the middle becomes aware of the protocol.</p>
</div>
</div>
<div>
<h3 id="_do_i_need_one">Do I need one?</h3>
<p>What does it all mean for you as an engineer? The answer to whether you need to adopt the service mesh approach comes down to the state of the microservice environment you’re trying to improve. As we have established, compared to an RPC framework, service meshes allow you to:</p>
<div>
<ol>
<li>
<p>Deploy the infra changes more often than deploying your services.</p>
</li>
<li>
<p>Introduce infra changes without touching the service code.</p>
</li>
</ol>
</div>
<p>The point 1. is important when for whatever reason you can’t redeploy your services very often, e.g. maybe no one remembers how it’s done anymore, or maybe there are other restrictions. The point 2. is important when your stack is heterogeneous, e.g. some services are built in Go, some in Java, some in Haskell, etc. Where are you on the interval from a huge set of heterogeneous services with unknown deployment schedules to a set of homogenous regularly deployed services defines whether a service mesh is the best solution for you.</p>
</div>
<div>
<h3 id="_conclusion">Conclusion</h3>
<p>Service meshes have a lot of hype around them, and way too much in my opinion. However, before committing to a piece of technology, it’s crucial to understand the problems it solves, and the context in which the solution was made. A service mesh is not an ultimate “good practice” but simply one of the patterns to solve a set of issues, and it’s quite a heavy one.</p>
<p>Rather than jumping on board, look carefully - the last thing you want is to find out that you have invested in a solution for a problem that you don’t have. Service meshes are an amazing piece of tech solving a whole lot of problems. Not in every case, it is the best solution.</p>
</div>
<div>
<h3 id="_thank_you_to">Thank you to</h3>
<div>
<ul>
<li>
<p>You for reading this article.</p>
</li>
<li>
<p><a href="https://twitter.com/ptuls">Paul Tune</a> for reviewing the article.</p>
</li>
</ul>
</div>
</div>
<div>

<hr>
<blockquote><p lang="en" dir="ltr">"You don't need no Service Mesh". Just published a new blog post with an anti-hype opinion on the over-hyped topic. <a href="https://t.co/SVXS3nWKzj">https://t.co/SVXS3nWKzj</a></p>— Sergey Tselovalnikov (@SerCeMan) <a href="https://twitter.com/SerCeMan/status/1286242507664191488?ref_src=twsrc%5Etfw">July 23, 2020</a></blockquote> 
</div>

</div></div>]]>
            </description>
            <link>https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005953</guid>
            <pubDate>Fri, 31 Jul 2020 05:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Context should go away for Go 2 (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24005733">thread link</a>) | @atombender
<br/>
July 30, 2020 | https://faiface.github.io/post/context-should-go-away-go2/ | <a href="https://web.archive.org/web/*/https://faiface.github.io/post/context-should-go-away-go2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        

<p>As usual, when a new blog post comes out on <a href="https://blog.golang.org/">blog.golang.org</a>, I’m all
eager to read it as soon as possible. The most recent one, <a href="https://blog.golang.org/contributors-summit">Contributors
Summit</a>, is a nice write-up on the issues that the Go
contributors have been talking about. While reading it, I stumbled upon a sentence that made me
write this post. Here is is:</p>

<blockquote>
<p>For instance, it would be nice if io.Reader accepted a context so that blocking read operations
could be canceled.</p>
</blockquote>

<p>This gave me chills. This is what <code>io.Reader</code> would look like with a context.</p>

<pre><code>type Reader interface {
        Read(ctx context.Context, p []byte) (n int, err error)
}
</code></pre>

<p>I did some research and found that some people already <a href="https://github.com/golang/go/issues/20280">proposed this
change</a> for Go 2. Thankfully it received a decent amount
of thumbs down, so it’s likely not making it.</p>

<p>This post is about all of the things that are wrong with the <code>"context"</code> package, why it is useful
 despite that, and that Go 2 should do something about it. So, grab some popcorn and let’s get
 started!</p>

<h2 id="go-is-a-general-purpose-language">Go is a general purpose language</h2>

<p>First things first, let’s establish some ground. Go is a <em>good</em> language for writing servers, but Go
is not a <em>language for writing servers</em>. Go is a <em>general purpose programming language</em>, just like
C, C++, Java or Python. For example, I’ve been using Go for about 2 years and I’ve never written a
single server in it.</p>

<p>For this reason, when designing the Go language and it’s standard library, we need to approach it
from a general purpose language perspective. Now, I’m not trying to say that context is only useful
for server people. But mostly, it is.</p>

<h2 id="context-is-like-a-virus">Context is like a virus</h2>

<p>This is the first and most important problem with context: it spreads! As mentioned in <a href="https://blog.golang.org/context">this blog
post about the context package</a>:</p>

<blockquote>
<p>At Google, we require that Go programmers pass a Context parameter as the first argument to every
function on the call path between incoming and outgoing requests.</p>
</blockquote>

<p>Every such function also needs to propagate the context down it’s call path, or else it wouldn’t be
fully cancelable. This means that all the potentially slow functions from other libraries that are
being called from a function accepting a context should also accept a context.</p>

<p>In short, if you’re writing a library that has function which can take some significant amount of
time and your library is <em>potentially</em> going to be used by a server application, you have to accept
a context in those functions.</p>

<p>That’s how context spreads like a virus. What’s bad about that? Let’s recap:</p>

<ol>
<li>Go is a general purpose language.</li>
<li>If a library is <em>potentially</em> going to be used by a server, it should accept a context.</li>
<li>Now, everyone has to deal with the context, even the ones who don’t need it.</li>
</ol>

<p>Of course, I can just pass <code>context.TODO()</code> everywhere, but that’s just gross, it hurts readability,
makes my code look ugly and simply removes a part of fun I have with Go.</p>

<p>If the Go language ever comes to the point where I’d have to write this</p>

<pre><code>n, err := r.Read(context.TODO(), p)
</code></pre>

<p>put a bullet in my head, please.</p>

<p>You might argue: <em>A library can provide two version of each function, one with a context and one
without a context.</em> Sure, just take a look at the
<a href="https://golang.org/pkg/database/sql/"><code>"database/sql"</code></a> package. Although it does solve the problem
partially, it smells quite bad.</p>

<p>Also, imagine teaching Go to a student. You start explaining the context-equipped <code>io.Reader</code>
interface (or anything else which occasionally requires a context) to them and they ask: <em>What is
that <code>ctx context.Context</code> thingy there?</em> And the answer would probably just be: <em>Don’t worry about
that, just pass <code>context.TODO()</code> there for now.</em> Sounds a lot like <code>public static void</code> to me.</p>

<p>The message is: Context spreads like a virus and I (alongside almost everyone who doesn’t write
servers in Go) don’t want to deal with it when I don’t have to.</p>

<h2 id="the-context-package-itself-is-not-that-good">The <code>"context"</code> package itself is not that good</h2>

<p>The first thing is a personal opinion, but for me, the <code>context.Context</code> interface has too many
methods. Now, the more serious problems.</p>

<h3 id="if-you-use-ctx-value-in-my-non-existent-company-you-re-fired">If you use <code>ctx.Value</code> in my (non-existent) company, you’re fired</h3>

<p>I’m not sure who came up with this idea that context should carry a map of meaningless objects to
meaningless objects. There are just so many things that are wrong with it. Let’s list a few:</p>

<ol>
<li>An obvious one, it’s not statically typed at all.</li>
<li>It requires documenting which values (keys and their types) a certain function supports and uses.
As we all know, documentation is mostly a code that never runs.</li>
<li>It’s very similar to thread-local storage. We know how bad of an idea thread-local storage is.
Non-flexible, complicates usage, composition, testing.</li>
<li>This probably doesn’t happen often, but it’s prone to name collisions.</li>
<li>It’s just magic. An error-prone magic.</li>
</ol>

<p>I know that <code>ctx.Value</code> makes some things easier. But, I believe that designing your APIs without
<code>ctx.Value</code> in mind at all makes it always possible to come up with alternatives.</p>

<h3 id="context-is-mostly-an-inefficient-linked-list">Context is mostly an inefficient linked list</h3>

<p>The way <code>WithCancel</code>, <code>WithDeadline</code>, etc. constructors from the <code>"context"</code> package work is they
create a linked list. Among other things, this sometimes requires creating a
<a href="https://golang.org/src/context/context.go#L261">goroutine</a> for <code>WithCancel</code>, which propagates
cancelation signals from the previous context to the new one. Of course, if the context is never
canceled, this goroutine is leaked.</p>

<p>The <code>WithValue</code> constructor takes a context and returns a context which propagates the previous
context but also contains a value under the specified key. This is, obviously, achieved by creating
another node in the linked list, the purpose of which is to return the correct value for that key
and propagate the previous context otherwise. So, <code>ctx.Value</code> is not only a map of meaningless
objects to meaningless objects, it’s also a terribly slow map of meaningless objects to meaningless
objects.</p>

<h3 id="and-lastly">And lastly</h3>

<pre><code>ctx context.Context
</code></pre>

<p>is a lot like</p>

<pre><code>Foo foo = new Foo();
</code></pre>

<p>One of the things Go was <a href="https://www.youtube.com/watch?v=rKnDgT73v8s">created to avoid</a>.</p>

<h2 id="what-does-the-context-package-actually-solve">What does the <code>"context"</code> package actually solve?</h2>

<p>Despite all of the bad things described above, the <code>"context"</code> package is genuinely useful, because
it solves one thing that is kinda hard to do in Go: <strong>cancelation</strong>. That’s the only problem the
<code>"context"</code> package really solves (or attempts to solve).</p>

<p>Let’s face it, cancelation in Go is hard. There is a whole talk called <a href="https://www.youtube.com/watch?v=QDDwwePbDtw">‘Advanced Go Concurrency
Patterns’</a>, which discusses this problem in depth. This
talk happened before the <code>"context"</code> package was introduced into the Go standard library and thus it
discusses solutions to the cancelation problem which only involve simple channels.</p>

<p>There are number of reasons why solutions proposed in the talk don’t scale very well. Here are a few
of them:</p>

<ol>
<li>The cancelation channels are usually not accepted by other libraries and functions and thus
cancelation is only possible ‘in-between’ the slow operations.</li>
<li>Considering a ‘tree of goroutines’ (where children goroutines are the ones spawned by the parent
goroutines), it’s easy to cancel the whole tree (just close the cancelation channel), but it’s
harder to cancel a sub-tree (you need to introduce another channel for that, or some other
solution).</li>
</ol>

<p>The <code>"context"</code> package does solve these problems. Inefficiently and with numerous problems, but
solves them better than anything else out there. <strong>In Go, we need to be able to solve the
cancelation problem</strong>. Solving it is usually necessary anytime a decent usage of goroutines is
involved.</p>

<h2 id="go-2-should-explicitly-address-the-cancelation-problem">Go 2 should explicitly address the cancelation problem</h2>

<p>I think it’s a weakness of the Go programming language that we needed to introduce a package like
<code>"context"</code>. Go makes it very easy to create goroutines and communicate between them. However, the
<code>"context"</code> package is a proof that Go makes it hard enough to <em>arrange goroutines to finish</em>. I
believe this problem should be solved directly in the language. The language should provide a
solution, which is:</p>

<ol>
<li>Simple and elegant.</li>
<li>Optional, non-intrusive and non-infectious.</li>
<li>Robust and efficient.</li>
<li>Only solves the cancelation problem. Values can be omitted. Timeouts can also be implemented on
top of a very simple cancelation.</li>
</ol>

<p>You might argue: <em>I like context, it’s an elegant solution to the problem without changing or
complicating the language</em>. I disagree. For all the reasons described above it’s not an elegant
solution and although it’s not an integral part of the language, it is and is becoming more and more
an integral part of the libraries. In the end, it makes the language harder to use.</p>

<p>I have a few solutions in mind, but I’ll leave them for another post or a proposal, or I’ll leave
them for myself if someone comes up with a better solution. The purpose of this post is just to
point out the problem.</p>

<h2 id="conclusion">Conclusion</h2>

<p>This post was trying to point out a problem in the Go language. In short, cancelation is a problem
in Go and the <code>"context"</code> package does not solve this problem very well. I can’t think of any other
solution that would solve this problem good except for a language change. That is up for Go 2.</p>

<p>Thanks for reading and I’m looking forward to your feedback and <del>hate comments</del> objections ;).</p>

<p>Michal Štrba</p>


        


<a href="https://disqus.com/">comments powered by </a>
      </article></div>]]>
            </description>
            <link>https://faiface.github.io/post/context-should-go-away-go2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005733</guid>
            <pubDate>Fri, 31 Jul 2020 04:42:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner’s Guide to Note-Taking (For Your Life)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24005659">thread link</a>) | @hiivan
<br/>
July 30, 2020 | https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/ | <a href="https://web.archive.org/web/*/https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>  <time datetime="2020-07-29T00:00:00+00:00">July 29th, 2020 in <a href="https://www.ivan-ang.com/categories/#Posts%F0%9F%93%8C">Posts📌</a> </time> <word> 1842 words, 10 min read </word> <p>Note-taking has become a huge part of my life. It has helped me retain information better, and ensures that I am constantly learning everyday.</p> <p>Twitter user <a href="https://twitter.com/visakanv">@visakanv</a> beautifully describes journaling (though also highly applicable to note-taking in general) in this twitter thread:</p> <blockquote data-conversation="none" data-theme="light"><p lang="en" dir="ltr">So in a way journaling for yourself is a radical act! It’s an act of self-ownership, self-education. It’s about setting your own curriculum, defining your own worldview, deciding for yourself what is important. I don’t think this should be outsourced to others, but that’s my POV</p>— youtube.com/visakanv (❤️ if you subscribe!) (@visakanv) <a href="https://twitter.com/visakanv/status/1087436197410959361?ref_src=twsrc%5Etfw">January 21, 2019</a></blockquote>  <h2 id="why-i-take-notes">Why I Take Notes.</h2> <p>Oftentimes, when people think of taking notes, they associate it to <em>studying for an exam</em>.</p> <p>But the fact is, we are constantly learning new things everyday. So if you are all about living life to the fullest and improving yourself as a person, then why would you not transfer this concept of note-taking to your own personal life?</p> <p>One of the best thing <em>writing</em> things down can do for you is to <strong>sharpen your thinking</strong>. Sitting down and putting the work to synthesizing your thoughts can help to produce better quality ideas. If I find myself having an abstract thought in my head that it is hard to express in words, penning them down can help to solidify and refine the idea.</p> <p>In the rest of the article, I will be going through my note-taking journey, and the various techniques &amp; concepts I use to make my note-taking more effective.</p> <h2 id="active-recall-and-spaced-repetition">Active Recall and Spaced Repetition</h2> <p>When I was a student in junior college studying for ‘A’ Levels, the content we were learning were becoming more and more complex. So I started searching up study techniques to optimize my learning.</p> <p>I came across <a href="https://youtu.be/ukLnPbIffxE">Ali Abdaal’s YouTube videos</a> on <em>Active Recall</em> and <em>Spaced Repetition</em>, and these techniques stuck with me till this day. These were legitimate, scientifically backed<sup id="fnref:1"><a href="#fn:1">1</a></sup> advice, in contrast to the plethora of “<em>Top 101 Study Tips</em>” listicles online that sounds good but doesn’t work.</p> <p>(Spoiler alert: Active Recall trumps other study techniques like rereading, highlighting and blindly writing notes, in terms of examination performance.)</p> <p> <strong>Active Recall</strong><sup id="fnref:2"><a href="#fn:2">2</a></sup>: <em>This involves retrieving information from your brain after learning something, typically through testing yourself. The act of recalling strengthens your ability to retain your information and solidifies the connections in our brain between different concepts.</em> <br><strong>Spaced Repetition</strong><sup id="fnref:3"><a href="#fn:3">3</a></sup>: <em>The act of reviewing materials at spaced intervals. This is effective in memory retention and countering the forgetting curve.</em> </p> <p>If you ever want to learn something effectively, it is key to utilize both techniques to maximize your retention rate.</p> <h2 id="second-brain">Second Brain</h2> <p>On the never-ending quest for maximum productivity, I chanced upon an <a href="https://fortelabs.co/blog/basboverview/">article by Forte Labs</a> that explained this conundrum I had in my head:</p> <blockquote> <p>How many brilliant ideas have you had and forgotten? How many insights have you failed to take action on? How much useful advice have you slowly forgotten as the years have passed?</p> <p>We feel a constant pressure to be learning, improving ourselves, and making progress. We spend countless hours every year reading, listening, and watching informational content. And yet, where has all that valuable knowledge gone? Where is it when we need it? Our brain can only store a few thoughts at any one time. Our brain is for <em>having</em> ideas, not storing them.</p> </blockquote> <blockquote> <p>Without a little extra care to preserve these valuable resources, our precious knowledge remains siloed and scattered across dozens of different locations.</p> </blockquote> <p>Mind = Blown 🤯. This perpetual problem that has always bothered my mind (but could never find the words for it) was perfectly articulated by this excerpt.</p> <p>The article then introduced a solution: <a href="https://www.buildingasecondbrain.com/">Building A Second Brain</a>. BASB is a methodology for “preserving your ideas, and turning them into reality”. The article explains it like this:</p> <blockquote> <p>We are constantly generating ideas. Yet, without a little extra care to preserve these valuable resources, our precious knowledge remains siloed and scattered across dozens of different locations.</p> <p>By offloading our thinking onto a “second brain,” we free our biological brain to imagine, create, and simply be present.</p> </blockquote> <p>Information overload is a plague of today’s society. Building a digital system where you can deposit all your thoughts and learnings there is quintessential for knowledge workers in this day and age.</p> <p>Another similar concept is the <a href="https://en.wikipedia.org/wiki/Personal_knowledge_management">Personal Knowledge System</a>. PKM involves the bottom-up approach of <em>collecting information that a person uses to gather, classify, store, search, retrieve and share knowledge in their daily activities.</em><sup id="fnref:4"><a href="#fn:4">4</a></sup></p> <h2 id="note-taking-app-roam-research">Note-Taking App: Roam Research</h2> <p><i>(This segment talks about my favourite note-taking app, Roam Research. If you wish to skip to the next segment of the article, click <a href="#how_i_take_notes">here.</a>)</i></p> <p>In search for an appropriate medium for BASB, I discovered <a href="https://roamresearch.com/">Roam Research</a>. I have been using it ever since and have never looked back.</p> <picture> <img src="https://www.ivan-ang.com/assets/roam-showcase.png" height="100%" width="100%"> <figure> <figcaption><b>Source:</b> <a href="https://roamresearch.com/">Roam Research</a>'s official site.</figcaption> </figure> </picture> <h3 id="what-makes-roam-different-from-the-other-note-taking-apps">What makes Roam different from the other note-taking apps?</h3> <p>Note-taking apps typically function <strong>hierarchically</strong>.</p> <p>You create categories, and within each categories are sub-categories and within them contain notes. The problem with this is that we face the issue of deciding where to put these notes under, since they can belong to multiple categories.</p> <p>Roam Research is a note-taking application for <strong>networked thought</strong>.</p> <p>It seeks to make note-taking function more like how a brain processes information. Whenever you have an idea, your brain will create multiple associations to it. Thinking of linked concepts will help you recall that idea.</p> <p>Likewise, Roam seeks to associate notes with other notes via <em>bi-directional linking</em>, making it easier to connect your ideas. It becomes your second brain. Your notes do not just sit there idly like other note apps. Roam encourages serendipity and <em>Spaced Repetition</em> by letting you to continuously revisit past notes.</p> <p>For those tinkerers out there, you can even create your own custom CSS and JavaScript themes! (Shameless plug: check out my theme <a href="https://github.com/hiivan/CyanoRoam">CyanoRoam</a> on Github).</p> <h3 id="pricing">Pricing</h3> <p>The bummer is that after their 31-days free trial, they start with a whopping $15/month and $7.50/month for students afterwards. If you are not willing to spend that much money on it, I recommend looking into other <a href="https://nesslabs.com/roam-research-alternatives">Roam alternatives</a> like <a href="https://obsidian.md/">Obsidian</a> and <a href="https://giffmex.org/experiments/stroll.experiment.html">TiddlyStroll</a>.</p> <p>(I was lucky enough to have been part of their beta program so my graph is free indefinitely 😁.)</p> <p>If you are interested to know more about how Roam Research works, you can also check out <a href="https://www.youtube.com/watch?v=bpikCLhpIRY">Ali Abdaal’s video on Roam</a>.</p>  <h2 id="how-i-take-notes">How I Take Notes.</h2> <p>Personal Knowledge System/Building A Second Brain or whatever you want to call it, below are the multiple facets of how I take my notes. See and pick what works for you.</p> <h3 id="quick-capture">📸Quick Capture</h3> <p>Our brains are constantly coming up with new ideas. Sometimes, this can get very distracting and take away from what we are currently focusing on.</p> <p>A way I have come up to curb this problem is that whenever I come up with a new idea or inspiration, I will immediately <strong>capture them</strong> down on Roam.</p> <p>I keep quotes, reading highlights, podcast insights and everything you can think of. I find this very liberating as it helps to take the load off my brain so I can focus what is important presently.</p> <p>Then, at the end of the day, I can go back to review whatever I have written the entire day, and decide whether I will add them to the list of stuff to work on.</p> <h3 id="bookpodcastarticle-notes">📚Book/Podcast/Article Notes</h3> <p>This is the most obvious kind of note-taking: writing notes on stuff you read.</p> <p>Whenever I read, or other content I consume online e.g. podcasts, articles, I try my best to paraphrase and summarize every book. Especially when coming across a foreign concept that I wish to learn more on, I find it best to actively engage with the material for better learning.</p> <p>Take note <em>(pun intended)</em>: When taking notes, paraphrase and try not to refer back to the material at hand. This is the essence behind <em>Active Recall</em>.</p> <h3 id="️quantifying-my-productivity">⚖️Quantifying My Productivity</h3> <p>I subscribe to the notion of the <strong>1% Rule</strong>: if you improve yourself by 1% everyday for one year, you will end up 3800% better than where you started off a year ago. I first read this from James Clear, the author of the best-selling book, <a href="https://www.goodreads.com/book/show/40121378-atomic-habits">Atomic Habits</a>.</p> <picture> <img src="https://www.ivan-ang.com/assets/marginal-gains.jpg" height="85%" width="85%"> <figure> <figcaption><b>Source:</b> <a href="https://jamesclear.com/marginal-gains">Marginal Gains</a> by James Clear. <br><i>"Habits are the compound interest of self-improvement."</i></figcaption> </figure> </picture> <p>Of course, in reality, the metric to quantify your productivity is slightly more unclear, and you might not exactly be 38x better. But the 1% Rule proves how powerful compound interest can be and how it can do wonders to your life.</p> <p>I follow a simple system of quantifying my output to track my productivity. I have a section called <span>⏳Timeline of My Life</span>. In there, I record down the notable things that I have learnt or accomplished that day, or when I have reached a certain milestone in my life.</p> <p>This is especially useful if you wish to do <strong>weekly reviews</strong> on your personal development.</p> <p>Looking at all your past notes can give you a birds-eye view of what you have accomplished the entire week. By reviewing, you are applying <em>Spaced Repetition</em> to your learning. Occasionally looking back at the mini-achievements you have done can also do wonders to your motivation and self-esteem :P.</p> <p>I am considering using a software tool like <a href="https://airtable.com/">Airtable</a> in the future to relegate this mini-project to. Maybe one day, I will reach the level of <a href="https://julian.digital/2020/02/23/my-quantified-self-setup/">julian.digital</a>.</p> <h3 id="journaling">📝Journaling</h3> <p>As mentioned in my article on journaling, I also use Roam as a tool for writing down my thoughts and reflections. You can read the article <a href="https://www.ivan-ang.com/journaling-as-a-tool-for-self-help/">here</a>, where I talk more about how I use it to manage my emotional and mental health.</p> <h2 id="conclusion">Conclusion</h2> <p>So this is a brief overview of the theories behind how I do my note-taking. I hope you have gained some insights after reading this post, and perhaps even incorporate some of these concepts into your own life.</p> <picture> <img src="https://www.ivan-ang.com/assets/my-roam-graph.png" height="95%" width="95%"> <figure> <figcaption><b>My Roam Graph:</b> An overview of how all my notes are …</figcaption></figure></picture></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/">https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/</a></em></p>]]>
            </description>
            <link>https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005659</guid>
            <pubDate>Fri, 31 Jul 2020 04:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A Free Gatsby.js/Tailwind Theme for Business Websites]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24005615">thread link</a>) | @taphangum
<br/>
July 30, 2020 | https://planflow.dev/free-themes | <a href="https://web.archive.org/web/*/https://planflow.dev/free-themes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://planflow.dev/free-themes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005615</guid>
            <pubDate>Fri, 31 Jul 2020 04:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero-Cost References with Regions in Vale]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24005370">thread link</a>) | @verdagon
<br/>
July 30, 2020 | https://vale.dev/blog/zero-cost-refs-regions | <a href="https://web.archive.org/web/*/https://vale.dev/blog/zero-cost-refs-regions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://vale.dev/blog/zero-cost-refs-regions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005370</guid>
            <pubDate>Fri, 31 Jul 2020 03:31:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of End-to-End Machine Learning Platforms – Databaseline by Ian Hellström]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24005258">thread link</a>) | @BERTHart
<br/>
July 30, 2020 | https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/ | <a href="https://web.archive.org/web/*/https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Machine Learning (ML) is known as <a href="https://research.google/pubs/pub43146/">the high-interest credit card of technical debt</a>.
It is relatively easy to get started with a model that is good enough for a particular business problem, but to make that model work in a production environment that scales and can deal with messy, changing data semantics and relationships, and evolving schemas in an automated and reliable fashion, that is another matter altogether.
If you’re interested in learning more about a few well-known ML platforms, you’ve come to the right place!
<!--more--></p>

<p>As little as 5% of the actual code for machine learning production systems is the model itself.
What turns a collection of machine learning solutions into an end-to-end machine learning platform is an architecture that embraces technologies designed to speed up modelling, automate the deployment, and ensure scalability and reliability in production.
I talked about <a href="https://databaseline.tech/lean-dml-operations/">lean D/MLOps</a>, data and machine learning operations, before, because machine learning operations without data is pointless, so an end-to-end machine learning platform needs a holistic approach.</p>

<p>The CI/CD Foundation launched an <a href="https://cd.foundation/blog/2020/02/11/announcing-the-cd-foundation-mlops-sig/">MLOps Special Interest Group (SIG)</a>.
The steps they have identified for an end-to-end machine learning platform are shown in the next image:</p>

<p><a href="https://databaseline.tech/images/2020-02-21-ml-cicd-mlops-sig.png" title="CI/CD Foundation MLOps"><img src="https://databaseline.tech/images/2020-02-21-ml-cicd-mlops-sig.png" alt="CI/CD Foundation MLOps" title="CI/CD Foundation MLOps"></a></p>

<p>It camouflages a few not-quite-insignificant details, though.
For instance, serving may require different technologies depending on whether it’s done in real-time or not.
Scalable solutions typically have the model inside a container that runs on many machines in a serving cluster that’s behind a load balancer.
So, a single box in the aforementioned diagram does not imply a single step, container, or component of an actual platform.
That’s not a critique of the picture, but a warning: what looks simple may not be quite as easy in practice yet.</p>

<p>Model (configuration) management is absent from the chart.
You can think of things such as versioning, experiment management, run-time statistics, data lineage tracking for training, test, and validation data sets, the capability to retrain a model, either from scratch or incrementally from, say, a snapshot of the model, hyperparameter values, accuracy metrics, and so on.</p>

<p>A crucial aspect that is not listed either is the ability to check the model for bias by, for example, slicing the model’s key performance metrics by different dimensions.
Many companies need the ability to hot-swap a model or run multiple in parallel, too.
The former is important lest a user’s request go into the void as it hits the server while the model is updated in the background.
And the latter is crucial for A/B testing or model validation.</p>

<p>Another perspective from CI/CD is available <a href="https://martinfowler.com/articles/cd4ml.html">here</a>.
It mentions the need for versioning data as well as code, which is often overlooked.</p>

<h2 id="google-tfx">Google: TFX</h2>
<p>The main motivation behind Google’s development of <a href="https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/(https://www.kdd.org/kdd2017/papers/view/tfx-a-tensorflow-based-production-scale-machine-learning-platform)">TensorFlow eXtended (TFX)</a> was to reduce the time to productionize a machine learning model from months to weeks.
Their engineers and scientists struggled because ‘the actual workflow becomes more complex when machine learning needs to be deployed in production.’</p>

<p><a href="https://databaseline.tech/images/2020-02-21-ml-tfx.png" title="Google's TFX"><img src="https://databaseline.tech/images/2020-02-21-ml-tfx.png" alt="TensorFlow eXtended (TFX)" title="Google's TFX"></a></p>

<p>TensorFlow and <a href="https://www.tensorflow.org/tfx/">TFX</a> are available freely, although the latter is not as mature as the former, having been released only in 2019, two years after Google presented their ML infrastructure.</p>

<p>Model performance metrics are used to deploy safe-to-serve models.
So, if a newer model does not perform as well as an existing one, it is not pushed to production.
In TFX parlance, the model does not receive a ‘blessing’.
With TFX that whole process is automatic.</p>

<p>Here is a quick overview of open-source TFX components:</p>
<ul>
  <li><a href="https://github.com/tensorflow/tfx/blob/master/docs/guide/examplegen.md">ExampleGen</a>
ingests and splits the input dataset.</li>
  <li><a href="https://github.com/tensorflow/tfx/blob/master/docs/guide/statsgen.md">StatisticsGen</a>
calculates statistics for the dataset.</li>
  <li><a href="https://github.com/tensorflow/tfx/blob/master/docs/guide/schemagen.md">SchemaGen</a>
examines the statistics and creates a data schema.</li>
  <li><a href="https://github.com/tensorflow/tfx/blob/master/docs/guide/exampleval.md">ExampleValidator</a>
looks for anomalies and missing values in the dataset.</li>
  <li><a href="https://github.com/tensorflow/tfx/blob/master/docs/guide/transform.md">Transform</a>
performs feature engineering on the dataset.</li>
  <li><a href="https://github.com/tensorflow/tfx/blob/master/docs/guide/trainer.md">Trainer</a>
trains the model using TensorFlow.</li>
  <li><a href="https://github.com/tensorflow/tfx/blob/master/docs/guide/evaluator.md">Evaluator</a>
analyses the training results.</li>
  <li><a href="https://github.com/tensorflow/tfx/blob/master/docs/guide/modelval.md">ModelValidator</a>
ensures that the model is safe to serve.</li>
  <li><a href="https://github.com/tensorflow/tfx/blob/master/docs/guide/pusher.md">Pusher</a>
deploys the model to a serving infrastructure.</li>
  <li><a href="https://www.tensorflow.org/serving">TensorFlow Serving</a> is a C++ backend that serves a TensorFlow <a href="https://www.tensorflow.org/guide/saved_model#save_and_restore_models">SavedModel</a> file.</li>
</ul>

<p>To minimize training/serving skew, TensorFlow Transform ‘freezes’ values in the computation graph, so that the same values found during training are used when serving.
What may be several operations in the DAG when training will be a single fixed value at serving time.</p>

<h2 id="uber-michelangelo">Uber: Michelangelo</h2>
<p>Around 2015, Uber’s ML engineers noticed the <a href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems">hidden technical debt in machine learning systems</a>, or the ML equivalent of ‘But it works on my machine…’
Uber had built custom, one-off systems that integrated with ML models, which was not very scalable in a large engineering organization.
<a href="https://eng.uber.com/michelangelo/">In their own words</a>,</p>

<blockquote>
  <p>there were no systems in place to build reliable, uniform, and reproducible pipelines for creating and managing training and prediction data at scale.</p>
</blockquote>

<p>That’s why they built Michelangelo.
It relies on Uber’s data lake of transactional and logged data, and it supports both offline (batch) and online (streaming) predictions.
For offline predictions containerized Spark jobs generate batch predictions, whereas for online deployments the model is served in a prediction service cluster, which typically consists of hundreds of machines behind a load balancer, to which clients send individual or batched prediction requests as RPCs.</p>

<p>Metadata relevant to model management (e.g. run-time statistics of the trainer, model configuration, lineage, distribution and relative importance of features, model evaluation metrics, standard evaluation charts, learned parameter values, and summary statistics) are stored for each experiment.</p>

<p>Michelangelo can deploy multiple models in the same serving container, which allows for safe transitions from old to new model versions and side-by-side A/B testing of models.</p>

<p><a href="https://databaseline.tech/images/2020-02-21-ml-michelangelo-v1.png" title="Uber's Michelangelo: online vs offline"><img src="https://databaseline.tech/images/2020-02-21-ml-michelangelo-v1.png" alt="Uber's Michelangelo: online vs offline" title="Uber's Michelangelo: online vs offline"></a></p>

<p>The original incarnation of Michelangelo did not support deep learning’s need to train on GPUs, but that the team addressed that omission in the meantime.
The <a href="https://eng.uber.com/michelangelo-model-representation/">current platform</a> uses Spark’s ML pipeline serialization but with an additional interface for online serving that adds a single-example (online) scoring method that is both lightweight and capable of handling tight SLAs, for instance, for fraud detection and prevention.
It does so by bypassing the overhead of Spark SQL’s Catalyst optimizer.</p>

<p><a href="https://databaseline.tech/images/2020-02-21-ml-michelangelo-v2.png" title="Uber's Michelangelo: training vs serving"><img src="https://databaseline.tech/images/2020-02-21-ml-michelangelo-v2.png" alt="Uber's Michelangelo: training vs serving" title="Uber's Michelangelo: training vs serving"></a></p>

<p>Noteworthy is that both Google and Uber built in-house protocol buffer parsers and representations for serving, avoiding bottlenecks present in the default implementation.</p>

<h2 id="airbnb-bighead">Airbnb: Bighead</h2>
<p>Airbnb established their own ML infrastructure team in 2016/2017 for similar reasons.
First, they only had a few models in production, but building each model could take up to three months.
Second, there was no consistency among models.
And third, there were large differences between online and offline predictions.
<a href="https://www.slideshare.net/databricks/bighead-airbnbs-endtoend-machine-learning-platform-with-krishna-puttaswamy-and-andrew-hoh">Bighead</a> is the culmination of their efforts:</p>

<p><a href="https://databaseline.tech/images/2020-02-21-ml-bighead.png" title="Airbnb's Bighead"><img src="https://databaseline.tech/images/2020-02-21-ml-bighead.png" alt="Airbnb's Bighead" title="Airbnb's Bighead"></a></p>

<p>Data management is handled by the in-house tool Zipline.
Redspot is a hosted, containerized, multi-tenant Jupyter notebook service.
The Bighead library is for data transformations and pipeline abstractions, and it holds wrappers for common model frameworks.
It preserves metadata through transformations, so it is used to track lineage.</p>

<p>Deep Thought is a REST API for online predictions.
Kubernetes orchestrates the services.
For offline predictions, Airbnb use their own Automator.</p>


<p>Netflix faced, rather unsurprisingly, similar issues as the aforementioned companies.
Their solution was <a href="https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9">Metaflow</a>, a Python library for data scientists that deals with <a href="https://blog.valohai.com/three-ways-to-categorize-machine-learning-platforms">data management and model training, and not so much prediction serving</a>.
As such it is <em>not</em> an end-to-end platform for machine learning, and perhaps more geared towards company-internal instead of user-facing use cases.
It can of course be turned into a fully-fledged solution with <a href="https://www.seldon.io/">Seldon</a>, which is backed by Kubernetes, or <a href="https://aws.amazon.com/sagemaker/">AWS SageMaker</a>.
A list of further serving tools is available <a href="https://github.com/EthicalML/awesome-production-machine-learning#model-deployment-and-orchestration-frameworks">here</a>.</p>

<p><a href="https://databaseline.tech/images/2020-02-21-ml-metaflow.png" title="Netflix' Metaflow"><img src="https://databaseline.tech/images/2020-02-21-ml-metaflow.png" alt="Netflix' Metaflow" title="Netflix' Metaflow"></a></p>

<p>Data scientists write their workflow as DAG steps, much like data engineers when they use Airflow.
And like Airflow, you can use any data science library because to Metaflow it’s only Python code that’s executed.
Metaflow distributes processing and training in the background.
All code and data is automatically snapshotted to S3 to ensure there is a version history of each model and experiment.
Pickle is the default model serialization format.</p>

<p>The <a href="https://docs.metaflow.org/">open-source edition</a> does not yet have a built-in <a href="https://docs.metaflow.org/introduction/what-is-metaflow">scheduler</a>.
It also encourages users to ‘primarily rely on vertical scalability’, although they can use AWS SageMaker for horizontal scalability.
It is tightly coupled to AWS.</p>

<h2 id="lyft-flyte">Lyft: Flyte</h2>
<p>Lyft have open-sourced their cloud-native platform called <a href="https://flyte.org/">Flyte</a>, where data and machine learning operations <a href="https://static.sched.com/hosted_files/kccncna19/7f/Flyte%20Kubecon.pdf">converge</a>.
This is in line with my <a href="https://databaseline.tech/lean-dml-operations/">D/MLOps philosophy</a>—Data(Ops) is to MLOps as fuel is to a rocket: without it, ain’t nothin’ happenin’.</p>

<p>It is built on top of Kubernetes.
Since it is used internally by Lyft, it scales to at least 7,000 unique workflows with over 100,000 executions every month, 1 million tasks, and 10 million containers.</p>

<p>All entities in Flyte are immutable, so it is possible to track data lineage, reproduce of experiments, and roll back deployments.
Repeated tasks can leverage the task cache to save time and money.
Currently supported tasks include <a href="https://lyft.github.io/flyte/user/tasktypes/index.html">Python, Hive, Presto, and Spark</a> as well as <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">sidecars</a>.
From looking at the source code it seems EKS is</p>

<p><a href="https://databaseline.tech/images/2020-02-21-ml-flyte.png" title="Lyft's Flyte"><img src="https://databaseline.tech/images/2020-02-21-ml-flyte.png" alt="Lyft's Flyte" title="Lyft's Flyte"></a></p>

<p>Theirs is also <a href="https://github.com/lyft/amundsen">Amundsen</a>, a data catalogue that is not unlike Spotify’s <a href="https://labs.spotify.com/2020/02/27/how-we-improved-data-discovery-for-data-scientists-at-spotify/">Lexikon</a>.</p>

<h2 id="aws-azure-gcp-and-co">AWS, Azure, GCP, and Co.</h2>
<p>All major players in the <a href="https://cloud.google.com/gartner-cloud-infrastructure-as-a-service/">public cloud</a> space have their own offerings for machine learning platforms, save for Oracle who only offer <a href="https://www.oracle.com/artificial-intelligence/products.html">canned ML-based models</a> for certain use cases and industries.</p>

<p><strong>AWS <a href="https://aws.amazon.com/sagemaker/">SageMaker</a></strong> is a full-stack solution for machine learning that supports TensorFlow, Keras, PyTorch, and MXNet.
With <a href="https://aws.amazon.com/sagemaker/neo/">SageMaker Neo</a> it’s possible to deploy models both in the cloud and on the edge.
It has a built-in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/">https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/</a></em></p>]]>
            </description>
            <link>https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005258</guid>
            <pubDate>Fri, 31 Jul 2020 03:07:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ship Your MVP Faster with Continuous Deployment Using GitHub and Heroku]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24005153">thread link</a>) | @sssaini
<br/>
July 30, 2020 | https://saasbase.dev/how-to-set-up-continuous-deployment-on-nodejs-app-using-heroku-and-github/ | <a href="https://web.archive.org/web/*/https://saasbase.dev/how-to-set-up-continuous-deployment-on-nodejs-app-using-heroku-and-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://saasbase.dev/content/images/size/w300/2020/07/Blog-Post-Banner-01-4-1.png 300w,
                            https://saasbase.dev/content/images/size/w600/2020/07/Blog-Post-Banner-01-4-1.png 600w,
                            https://saasbase.dev/content/images/size/w1000/2020/07/Blog-Post-Banner-01-4-1.png 1000w,
                            https://saasbase.dev/content/images/size/w2000/2020/07/Blog-Post-Banner-01-4-1.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://saasbase.dev/content/images/size/w2000/2020/07/Blog-Post-Banner-01-4-1.png" alt="Ship your MVP faster with Continuous Deployment using Github and Heroku">
            </figure>

            <section>
                <div>
                    <p>Continuous Deployment is awesome because you can forget about the infrastructure part of the development and only focus on the code. Heroku makes it incredibly easy to set it up using Github and Automatic Deploys.</p><hr><h3 id="create-a-new-project">Create a new project</h3><p>Fork the simple Nodejs project <a href="https://github.com/bdcorps/serve-static-website-nodejs">here</a>. Refer to this link for a detailed walkthrough. </p><p>Run it locally using, </p><pre><code>npm install
node app.js</code></pre><p>Go to <a href="localhost:3000">localhost:3000</a> and "Goodbye World" should appear on the screen. </p><h3 id="set-up-heroku-account">Set up Heroku account</h3><p>Login to your <a href="https://dashboard.heroku.com/">Heroku account</a>. </p><p>Click on New -&gt; <a href="https://dashboard.heroku.com/new-app">Create New App</a>. Give it a name. Click Create App. </p><p>Under Deployment &nbsp;method, click Connect to Github. Search for and connect your repository. </p><figure><img src="https://saasbase.dev/content/images/2020/07/1-4.png" alt="" srcset="https://saasbase.dev/content/images/size/w600/2020/07/1-4.png 600w, https://saasbase.dev/content/images/size/w1000/2020/07/1-4.png 1000w, https://saasbase.dev/content/images/2020/07/1-4.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Choose the branch you would like to be deployed. Default to master if unsure. </p><p>Enable <code>Automatic Deployments</code>.</p><figure><img src="https://saasbase.dev/content/images/2020/07/2-5.png" alt="" srcset="https://saasbase.dev/content/images/size/w600/2020/07/2-5.png 600w, https://saasbase.dev/content/images/size/w1000/2020/07/2-5.png 1000w, https://saasbase.dev/content/images/2020/07/2-5.png 1230w" sizes="(min-width: 720px) 720px"></figure><p>Once you are ready to do an initial deploy, click Deploy Branch under Manual Deploy section.</p><figure><img src="https://saasbase.dev/content/images/2020/07/3-1.png" alt="" srcset="https://saasbase.dev/content/images/size/w600/2020/07/3-1.png 600w, https://saasbase.dev/content/images/size/w1000/2020/07/3-1.png 1000w, https://saasbase.dev/content/images/2020/07/3-1.png 1230w" sizes="(min-width: 720px) 720px"></figure><p>It will try to run the project using the Node.js buildpack. If it is successful, a "Your app was successfully deployed" message will appear. If the deployment failed, try restarting again from Step 1. </p><p>Open your app by clicking "View". The output should still be "Hello World". </p><figure><img src="https://saasbase.dev/content/images/2020/07/4-1.png" alt="" srcset="https://saasbase.dev/content/images/size/w600/2020/07/4-1.png 600w, https://saasbase.dev/content/images/2020/07/4-1.png 917w" sizes="(min-width: 720px) 720px"></figure><h2 id="deploy-changes">Deploy Changes</h2><p>Our pipeline is set up. It's time to take it out for a test drive. </p><p>Make a small change to <code>index.html</code></p><pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;

&lt;body&gt;
    &lt;h1&gt;Goodbye World&lt;/h1&gt;
&lt;/body&gt;

&lt;/html&gt;</code></pre><p>Commit and push the changes by,</p><pre><code>git add .
git commit -m "change text"
git push</code></pre><p>Once the push is successful, an automatic build is triggered on Heroku. Confirm this by going to the Overview tab of the Heroku dashboard. Under Latest Activity, there will be <code>Build in progress</code>. </p><figure><img src="https://saasbase.dev/content/images/2020/07/5.png" alt="" srcset="https://saasbase.dev/content/images/size/w600/2020/07/5.png 600w, https://saasbase.dev/content/images/2020/07/5.png 917w" sizes="(min-width: 720px) 720px"></figure><p>Once the status changes to Deployed, click on <code>Open App</code> and your changes should now be live. &nbsp;<br></p>
                </div>
            </section>

                <section>
    <h3>Subscribe to SaaSBase</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://saasbase.dev/how-to-set-up-continuous-deployment-on-nodejs-app-using-heroku-and-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005153</guid>
            <pubDate>Fri, 31 Jul 2020 02:42:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simon's Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24005073">thread link</a>) | @keyboardman
<br/>
July 30, 2020 | https://leimao.github.io/blog/Simon-Algorithm/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Simon-Algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Simon’s algorithm is a quantum computing algorithm invented to solve a contrived problem which is called Simon’s problem. Compared to one of the other quantum computing algorithms, <a href="https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">Deutsch-Jozsa algorithm</a>, which only requires to run once, Simon’s algorithm requires to run the algorithm multiple times, yet it is still able to solve Simon’s problem exponentially faster asymptotically running on quantum circuits than the best conventional probabilistic algorithm running on classical circuits.</p>



<p>In this blog post, I would like to discuss Simon’s problem and Simon’s algorithm in details.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="xor-properties">XOR Properties</h4>

<ul>
  <li><em>Commutativity</em>: $A \oplus B = B \oplus A$</li>
  <li><em>Associativity</em>: $A \oplus (B \oplus C) = (A \oplus B) \oplus C$</li>
  <li><em>Identity element</em>: $A \oplus 0 = A$</li>
  <li><em>Self-invertible</em>:  $A \oplus A = 0$</li>
</ul>

<h4 id="reducing-sum-or-difference-to-boolean">Reducing Sum or Difference to Boolean</h4>

<p>If $x$ and $y$ are binary values, $x, y \in \{0, 1\}$, we have</p>



<p>where $\oplus$ is $\text{XOR}$ (binary addition modulo 2). This could be easily verified using truth table.</p>

<h4 id="inner-product-and-inner-product-space-for-binary-vector-space">Inner Product and Inner Product Space for Binary Vector Space</h4>

<p>In the previous <a href="https://leimao.github.io/blog/Inner-Product/">blog post</a>, we have defined the inner product and inner product space for complex vector space. Similarly, we could also define the inner product and inner product space for binary vector space.</p>



<p>Given two binary vectors $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$, $\mathbf{x} = \{x_0, x_1, \cdots, x_{n-1}\}$ and $\mathbf{y} = \{y_0, y_1, \cdots, y_{n-1}\}$, the inner product of $\mathbf{x}$ and $\mathbf{y}$ is defined as</p>



<p>which is somewhat similar to the inner product definition for real vector space.</p>



<p>The bitwise exclusive-or operation $\oplus$ was also defined for binary vectors $\mathbf{x}$ and $\mathbf{y}$ of the same length. Given two binary vectors $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$, $\mathbf{x} = \{x_0, x_1, \cdots, x_{n-1}\}$ and $\mathbf{y} = \{y_0, y_1, \cdots, y_{n-1}\}$,</p>



<p>The following inner product properties are satisfied based on the above inner product definition.</p>



<p>Given $\mathbf{x}, \mathbf{x}^{\prime}, \mathbf{y}, \mathbf{y}^{\prime} \in \{0,1\}^n$, using the $\text{XOR}$ distributivity property we derived above,</p>



<p>Similarly,</p>



<p>Let $\mathbf{0} = \{ \underbrace{0, 0, \cdots, 0}_{n} \} =  0^n$, we have</p>



<h4 id="hadamard-operator">Hadamard Operator</h4>

<p>Most of the important properties of Hadamard operator have been derived in the prerequisites section of my previous blog post on <a href="https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">Deutsch-Jozsa algorithm</a>. Unlike Deutsch-Jozsa algorithm, Simon’s algorithm is only going to use a small fraction of the Hadamard operator properties that Deutsch-Jozsa algorithm has used. I would just copy the properties useful for Simon’s algorithm algorithm. For the derivation, proof, and other properties of Hadamard operator, the reader should refer to my previous blog post.</p>



<p>To extract an arbitrary column $j$ from $H^{\otimes {n}}$, we prepared a one-hot quantum system basic state vector $| \mathbf{y} \rangle = [y_0, y_1, \cdots, y_{2^n-1}]^{\top}$, where $y_j = 1$ and $y_k = 0$ for $k \neq j$.</p>



<p>where $| \mathbf{x}_i \rangle$ is a quantum system one-hot basic state vector,  $|\mathbf{x}_i\rangle = [x_0, x_1, \cdots, x_{2^{n}-1}]^{\top}$, where $x_i = 1$ and $x_k = 0$ for $k \neq i$.</p>



<p>Specifically, if $j = 0$, $| \mathbf{y} \rangle = [\underbrace{1, 0, 0, \cdots, 0}_{2^n} ]^{\top} = | \mathbf{0} \rangle$,</p>



<h3 id="simons-problem">Simon’s Problem</h3>

<p>Simon’s problem is defined as the follows. Given a black box function $f: \{0,1\}^n \rightarrow \{0,1\}^n$, we are further assured that there exists a hidden binary string $\mathbf{c} \in \{0,1\}^n$, such that, for all $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$,</p>



<p>where $\oplus$ is (bit-wise) $\text{XOR}$ (binary addition modulo 2).</p>



<p>Our goal is to find out what $\mathbf{c}$ is.</p>

<h4 id="mapping-properties">Mapping Properties</h4>

<p>There are some properties of the mapping $f$. $f$ is either a one-to-one or two-to-one mapping.</p>



<p>$\mathbf{c} = \mathbf{0}$ $\Leftrightarrow$ $f$ is a one-to-one mapping</p>



<p><em>Proof</em></p>



<p>For $f$ is a one-to-one mapping $\Rightarrow$ $\mathbf{c} = \mathbf{0}$, it is too trivial to prove.</p>



<p>For $\mathbf{c} = \mathbf{0}$ $\Rightarrow$ $f$ is a one-to-one mapping, we would like to prove by contradiction.</p>



<p>If $\mathbf{c} = \mathbf{0}$ and $f$ is not a one-to-one mapping, there must exists $\mathbf{x}$ and $\mathbf{y}$, $\mathbf{x} \neq \mathbf{y}$, and $f(\mathbf{x}) = f(\mathbf{y})$. According to the assurance, $\mathbf{y} = \mathbf{x} \oplus \mathbf{c} = \mathbf{x} \oplus \mathbf{0} = \mathbf{x}$. This raises contradiction and therefore $f$ has to be a one-to-one mapping when $\mathbf{c} = \mathbf{0}$.</p>



<p>This concludes the proof.</p>



<p>$\mathbf{c} \neq \mathbf{0}$ $\Leftrightarrow$ $f$ is a two-to-one mapping.</p>



<p><em>Proof</em></p>



<p>For $f$ is a two-to-one mapping $\Rightarrow$ $\mathbf{c} \neq \mathbf{0}$, it is too trivial to prove.</p>



<p>For $\mathbf{c} \neq \mathbf{0}$ $\Rightarrow$ $f$ is a two-to-one mapping, we would like to prove by contradiction.</p>



<p>If $\mathbf{c} \neq \mathbf{0}$, for any $\mathbf{x}$, we must have $\mathbf{y}$, where $\mathbf{y} = \mathbf{x} \oplus \mathbf{c}$ and $\mathbf{x} \neq \mathbf{y}$, $f(\mathbf{x}) = f(\mathbf{y})$. So $f$ is at least a two-to-one mapping. Assuming there exists a tuple of $\mathbf{x}$, $\mathbf{y}$, and $\mathbf{z}$, where $\mathbf{y} = \mathbf{x} \oplus \mathbf{c}$, $\mathbf{z} \neq \mathbf{x}$, and $\mathbf{z} \neq \mathbf{y}$, and $f(\mathbf{x}) = f(\mathbf{y}) = f(\mathbf{z})$. According to the assurance, $\mathbf{z} = \mathbf{x} \oplus \mathbf{c}$. But $\mathbf{x} \oplus \mathbf{c} = \mathbf{y}$ so we have $\mathbf{z} = \mathbf{y}$. This raises contradiction and therefore $f$ has to be a two-to-one mapping when $\mathbf{c} \neq \mathbf{0}$.</p>



<p>This concludes the proof.</p>

<h4 id="trivial-solution">Trivial Solution</h4>

<p>Solving Simon’s problem could be trivial.</p>



<p>If we happen to know any $\mathbf{x}$ and $\mathbf{y}$, where $\mathbf{x} \neq \mathbf{y}$ and $f(\mathbf{x}) = f(\mathbf{y})$, we immediately know $\mathbf{c} \neq \mathbf{0}$ and $\mathbf{c} = \mathbf{x} \oplus \mathbf{y}$. This is because,</p>



<p>If we have checked all $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$ and found there are no $\mathbf{x}$ and $\mathbf{y}$, where $\mathbf{x} \neq \mathbf{y}$ and $f(\mathbf{x}) = f(\mathbf{y})$, we immediately know $\mathbf{c} = \mathbf{0}$.</p>



<p>So the trivial solution for solving Simon’s problem is to evaluate $f$ using the values in $\{0,1\}^n$ one by one, and check if the newly evaluated valued has been shown in the previous evaluations.</p>

<h4 id="asymptotic-complexity-for-trivial-solution">Asymptotic Complexity for Trivial Solution</h4>

<p>Using hashing, we should be able to check if the newly evaluated valued has been shown in the previous evaluations in $O(1)$. However, most of the computational cost comes from evaluating $f$ using the values in $\{0,1\}^n$ one by one.</p>



<p>If $\mathbf{c} \neq \mathbf{0}$, if we are extremely lucky and the first two evaluated values $f(\mathbf{x}_0) = f(\mathbf{x}_1)$, then we are done and $\mathbf{c} = \mathbf{x}_0 \oplus \mathbf{x}_1$. However, in the worst scenario, we would have to have evaluate $2^{n-1} + 1$ of the values in $\{0,1\}^n$.</p>



<p>If $\mathbf{c} = \mathbf{0}$, we would know it after evaluating $2^{n-1} + 1$ of the values in $\{0,1\}^n$ by realizing that there are no two evaluated values are the same.</p>



<p>Therefore, using the trivial solution, in the worst scenario, we would have to run the evaluation $2^{n-1} + 1$ times to determine the value of $\mathbf{c}$.</p>



<p>So the question is, can we do better?</p>

<h3 id="simons-algorithm">Simon’s Algorithm</h3>

<h4 id="design-quantum-circus">Design Quantum Circus</h4>

<p>Similar to the quantum gates we used for the <a href="https://leimao.github.io/blog/Deutsch-Algorithm/">Deutsch algorithm</a> and the <a href="https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">Deutsch-Jozsa algorithm</a>, the black-box $f(\mathbf{x})$ is represented using a quantum gate $U_f$.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-07-26-Simon-Algorithm/U_f.png">
    <figcaption>$U_f$</figcaption>
</figure>
</div>

<p>The quantum gate $U_f$ is a unitary matrix which maps from $| \mathbf{x} \rangle \otimes | \mathbf{y} \rangle$ to $| \mathbf{x} \rangle \otimes | f(\mathbf{x}) \oplus \mathbf{y} \rangle$, namely $U_f (| \mathbf{x} \rangle \otimes | \mathbf{y} \rangle) = | \mathbf{x} \rangle \otimes | f(\mathbf{x}) \oplus \mathbf{y} \rangle$, for $\mathbf{x} \in \{0, 1\}^n$ and $\mathbf{y} \in \{0, 1\}^n$. When $\mathbf{y} = \mathbf{0}$, $| f(\mathbf{x}) \oplus \mathbf{y} \rangle = | f(\mathbf{x}) \oplus \mathbf{0} \rangle = | f(\mathbf{x}) \rangle $, $| \mathbf{y} \oplus f(\mathbf{x}) \rangle$ is just $| f(\mathbf{x}) \rangle$.</p>



<p>Note that the above mapping is not necessarily valid when $| \mathbf{x} \rangle$ and $| \mathbf{y} \rangle$ are superpositions.</p>



<p>Let’s further check if we could achieve fewer runs with superpositions and $U_f$.</p>



<p>We have the following quantum circus. Let’s compute the each of the quantum states in the circus. The mathematics is actually much easier compared to the ones in the <a href="https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">Deutsch-Jozsa algorithm</a>.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-07-26-Simon-Algorithm/simon-algorithm.png">
    <figcaption>$U_f$</figcaption>
</figure>
</div>









<p>Suppose $\mathbf{x}_2 = \mathbf{x}_1 \oplus \mathbf{c}$, and we also have $\mathbf{x}_1 = \mathbf{x}_2 \oplus \mathbf{c}$. Because</p>







<p>We could further rearrange $|\varphi_3\rangle $,</p>



<p>Note that $\langle \mathbf{z}, \mathbf{c} \rangle$ is a binary value. When $\langle \mathbf{z}, \mathbf{c} \rangle = 1$, $\sum_{ \mathbf{x} \in \{0,1\}^n } \frac{(-1)^{\langle \mathbf{z}, \mathbf{x} \rangle} \big( 1 + (-1)^{\langle \mathbf{z}, \mathbf{c} \rangle} \big) }{2} = 0$, which means that for the top output qubits, we have exact zero probability of observing $\mathbf{z}$. We could only observe $\mathbf{z}$ whose $\langle \mathbf{z}, \mathbf{c}\rangle  = 0$ for the top output qubits.</p>



<p>Statistically, when $\mathbf{c} = 0$, $\langle \mathbf{z}, \mathbf{c}\rangle  = 0$, for all $\mathbf{z} \in \{0,1\}^2$. This means all $\mathbf{z}$ are possible to be observed from the top output qubits. So what is the probability of observing $\mathbf{z}$, $p(\mathbf{z})$? Is it uniformly distributed?</p>





<p>Because $\mathbf{c} = 0$ and $f$ is an one-to-one mapping, we have</p>









<p>So when $\mathbf{c} = 0$, $p(\mathbf{z})$ is a uniform distribution and $p(\mathbf{z}) = \frac{1}{2^n}$.</p>



<p>How about when $\mathbf{c} \neq 0$?</p>





<p>Because $\mathbf{c} \neq 0$ and $f$ is a two-to-one mapping, we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Simon-Algorithm/">https://leimao.github.io/blog/Simon-Algorithm/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Simon-Algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005073</guid>
            <pubDate>Fri, 31 Jul 2020 02:22:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Educational Colonialism]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004811">thread link</a>) | @swinnipeg
<br/>
July 30, 2020 | https://americancompass.org/our-educational-colonialism/ | <a href="https://web.archive.org/web/*/https://americancompass.org/our-educational-colonialism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img data-src="https://americancompass.org/wp-content/uploads/2020/07/DSC_1111-scaled.jpg" src="https://americancompass.org/wp-content/uploads/2020/07/DSC_1111-scaled.jpg"></p><p>I get criticized for not talking about policy enough, so here we go: No Child Left Behind is a disaster, the spearhead of our misguided attempt to funnel everyone to college.</p><p>It has hurt the working class, because it devalues their worldview, leaving them feeling humiliated and labeled dumb hicks or lazy hoodlums. It has hurt the “aspirational professionals” by producing too many college graduates, leaving them to compete over a few high-paying high-status jobs in a few expensive cities. All while charging an arm and a leg that piles debt on them.</p><p>It has hurt everyone, with the exception of a few tenured literary critics who get increased status, and the CEOs of conglomerates, who get more resumes to choose from.</p><p><span id="more-1765"></span>Federalization is about imposing a dominant ideology and worldview, and in the case of our educational policy it is about imposing “front rowness”— the idea that everyone should aspire to becoming a tenured professor or a widget engaged in a resume arms race with the rest of the world.</p><p>It is a system built by intellectual elites who want everyone to be like them, and humiliates everyone else. It is a system that says anything that can’t be learned in an advanced placement class isn’t that important, like being a good member of the community, or family, or church. Those things are impediments to success. Staying home to care for your parents rather than rushing off to Princeton is an unnecessary speed bump on your way to having your best career!</p><p>Those who fundamentally don’t buy into this ideology, which is most of the working class, end up sitting in the back row of whatever school, distracted and frustrated. Throwing spitballs at whoever because they don’t take easily to set theory, or Algebra, or Henry James or Nathaniel Hawthorne. Because they don’t enjoy memorizing whatever they have to memorize for the next standardized test.</p><p>They are kids who just want to learn a skill to get a job. Because they are really good with their hands and good with tinkering, always have been. Or they are really good with animals, or good at getting stuff to grow, or they have ‘always been good at caring for people, noticing when someone is a little off and need to be checked on. Like, I always been good that way, especially with my Grandma, who shines up when she sees me come to play checkers. So maybe I will go into nursing you know. But I keep getting D’s in math and history, but if I can get over that hurdle, I sure would love to be a nurse.’</p><p>What we need is an educational system that values these kids’ particular world view, their particular skill set, their particular interests, and encourages and trains them in it. The back row kids who are not great at test taking and who don’t really want to go to college. So they can stay close to their parents, grandparents, uncles, aunts, and cousins, and eventually make a decent enough wage to buy a Tundra, a home, start a family, go to church, and eventually host the weekly backyard get togethers their cousins, aunts, uncles, nieces, friends come to. All without being sneered at as a dumb, uncurious, closed-minded provincial hick or hoodlum, because Shakespeare ain’t their thing.</p><p>Right now they are sneered at, directly and indirectly. The whole system is constantly probing, measuring, and gauging them. Constantly making them jump over one standardized hurdle after another, and sneering when they fall. So when they finally put it all behind them (thank god!), if they bother to focus on politics at all, they aren’t going to embrace the same group of people pushing the same policies that made them take test after test after test, while telling them their C’s and D’s were because they needed more self discipline, more curiosity, more openness, and more interest in the scientific method. You simple minded kid, vote for me!</p><p>Ahead of them, at the front of the classroom, are the clever curious kids who love running off to the library to read whatever and memorize whatever else. For twelve years they are in heaven because we have built a system for them, that embraces them, encourages them, and then whooshes them off to college, and then more college, and then even more college! But when they eventually emerge, maybe after graduating from 19th grade, they discover that although they were the best debater in Portsmouth, Ohio, and at Kenyon College, and one of the better thinkers in grad school, they are only the 75th best debater vying for that one job in Manhattan or that one tenure-track position at Columbia, and the poorest of the 200 people vying for that third-floor walk up in Williamsburg.</p><p>So the dream that everyone from their Head Start teacher to their high school guidance counselor, to their literary or intellectual hero on YouTube urged them to follow, of running off to see the world while making a difference, isn’t going so well, and now they are deep in debt from the last masters program that was supposed to make the difference and solve all of this.</p><p>Rightfully frustrated, they are now doing what they have been trained to do all their life, which is embracing politics and arguing, loudly and forcefully, to change the world. Which mostly means tinkering with the system that produced them, rather than tearing it all down. Because that is what they know.</p><p>So they focus their energies into making the system less painful, to them and their university friends. Like getting rid of college debt, or building more affordable apartments in Williamsburg, or providing more affordable public transportation because they take the damn subway every day and it is fucking crowded.</p><p>Some of them recognize that maybe we should throw fewer resources at education, maybe we should funnel fewer people into Philosophy PhD’s, and fewer young professionals into Williamsburg. Certainly their working class Brooklyn neighbors whose rent is skyrocketing agree with that.</p><p>These aspirational professionals running from one adjunct gig to the next have my complete sympathy, regardless of the policies they want changed, as do their back row counterparts running from one fast food gig to the next. Both have been chewed up and spit out by a system that chews up and spits out a lot of people. Just in different ways.</p><p><img src="https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-300x200.jpg" alt="" width="822" height="548" srcset="https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-300x200.jpg 300w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-1024x683.jpg 1024w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-768x513.jpg 768w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1724-1536x1025.jpg 1536w" sizes="(max-width: 822px) 100vw, 822px"></p><p>Yet it is the kids sitting in middle row I have the deepest sympathy for because they are the most harmed, and the ones you hear the least about. They are mostly working class kids who don’t really fit into the back row because they are very disciplined, eager, and want do what they are told, and especially want to do the right thing. Which now means going off to college to better themselves, so they go off to college to better themselves, regardless of the cost.</p><p>They buy into our faux educational meritocracy the most, swallowing it hook, line, and sinker. They buy the dream peddled by every successful person they have ever run across or heard, from Obama down to the middle school guidance counselor: Education is the pathway to a successful and meaningful life.</p><p>So they work super hard to get A-’s and B+’s in their classes and 80’s on standardized tests, and then take the next step and go off to the the best college available.</p><p>But they don’t really fit into the front row either, because they don’t know anybody who has ever been to college. Not their parents, or grandparents, or uncles or aunts. Not even a cousin. But all of those relatives are encouraging, even giddy about the idea. They want the best for their child, so they help them apply, to the degree they can help. And when the acceptance letter comes from that far away college with ivy covered buildings (oh my god, real ivy, just like in the movies!), they are so happy they throw a party, complete with mylar balloons, and post the picture on Facebook or Instagram.</p><p>They are a little shocked when they see that the cost is like 40K a year, which is a super lot of money, more than dad makes, but mom makes some money too, and they will figure it out, because their wonderful child is going to have the American Dream.</p><p>So they apply for loans and eight years later that child is a young adult with 100K in debt working in a government bureaucracy five hundred miles away and missing the weekly family backyard BBQs .</p><p>Or maybe it didn’t work, and they are back home in the job they would have gotten straight out of high school, but now four years behind in seniority and 20K in debt.</p><p><img src="https://americancompass.org/wp-content/uploads/2020/07/DSC_1200-300x200.jpg" alt="" width="838" height="558" srcset="https://americancompass.org/wp-content/uploads/2020/07/DSC_1200-300x200.jpg 300w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1200-1024x683.jpg 1024w, https://americancompass.org/wp-content/uploads/2020/07/DSC_1200-1536x1025.jpg 1536w" sizes="(max-width: 838px) 100vw, 838px"></p><p>Education is wonderful, so is bettering yourself by getting as much of it as possible. But done on your terms and because you want it for your reasons. Not because you, your community, and everyone else you know, is competing with the Chinese, or the Germans, or the Indians. So you have to take countless standardized tests so you can win a golden ticket to ship off to Princeton and hang with others who are good at taking standardized tests, to then be taught more stuff, to then go to grad school to learn even more stuff, so you might, if you are lucky, get to go to San Francisco and live in an a small room hundreds of miles from your family to start in a firm trading bonds, or helping Google sue someone, or running from teaching one introductory writing course at one school to another introductory oratory course at another school, or maybe so you can write papers for a non-profit funded by a billionaire arguing that we need more education. That isn’t good.</p><p>What we have now is a top-down educational system that intellectually strip mines America and humiliates everyone. What we need is a democratic educational system that provides pathways to dignified lives for everyone. That provides Shakespeare and differential topology to those who see the beauty of each, but also provides skills to those who would rather focus on things like music, mechanics, nursing, parenting, farming, or whatever.</p><p>We need educational freedom, not educational colonialism.</p> <p><a href="https://americancompass.org/the-commons/">Return to the Commons</a></p></div></div>]]>
            </description>
            <link>https://americancompass.org/our-educational-colonialism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004811</guid>
            <pubDate>Fri, 31 Jul 2020 01:42:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning's Most Important Ideas – A Brief Historical Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004790">thread link</a>) | @jonbaer
<br/>
July 30, 2020 | https://dennybritz.com/blog/deep-learning-most-important-ideas/ | <a href="https://web.archive.org/web/*/https://dennybritz.com/blog/deep-learning-most-important-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The goal of this post is to review well-adopted ideas that have stood the test of time. I will present a small set of techniques that cover a lot of basic knowledge necessary to understand modern Deep Learning research. If you're new to the field, these are a great starting point.</p><div id="post-content"><p>Deep Learning is an extremely fast-moving field and the huge number of research papers and ideas can be overwhelming. Even seasoned researchers have a hard time telling company PR from real breakthroughs. The goal of this post is to review those ideas that have <strong>stood the test of time</strong>, which is perhaps the only significance test one should rely on. These ideas, or improvements of them, have been used over and over again. They're known to work.</p> <p>If you were to start in Deep Learning today, understanding and implementing each of these techniques would give you an excellent foundation for understanding recent research and working on your own projects. It's what I believe the best way to get started. Working through papers in historical order is also a useful exercise to understand where the current techniques come from and why they were invented in the first place. <strong><strong>Put another way, I will try to present a <em>minimal set</em> of ideas that most of the basic knowledge necessary to understand modern Deep Learning research.</strong></strong></p> <p>A rather unique thing about Deep Learning is that its application domains (Vision, Natural Language, Speech, RL, etc) share the majority of techniques. For example, someone who has worked in Deep Learning for Computer Vision his whole career could quickly be productive in NLP research. The specific network architectures may differ, but the concepts, approaches and code are mostly the same. I will try to present ideas from various fields, but there are a few caveats about this list:</p> <ul> <li>My goal is not to give in-depth explanations or code examples for these techniques. It's not easily possible to summarize long complex papers into a single paragraph. Instead, I will give a brief overview of each technique, its historical context, and links to papers and implementations. If you want to learn something, I <em>highly recommend</em> trying to re-produce some of these paper results from scratch in raw <a href="https://pytorch.org/">PyTorch</a> without using existing code bases or high-level libraries.</li> <li>The list is biased towards my own knowledge and the fields I am familiar with. There are many exciting subfields that I don't have experience with. I will stick to what most people would consider the popular mainstream domains of Vision, Natural Language, Speech, and Reinforcement Learning / Games.</li> <li>I will only discuss research that has official or semi-official open source implementations that are known to work well. Some research isn't easily reproducible because it involves huge engineering challenges, for example <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">DeepMind's AlphaGo</a> or <a href="https://openai.com/projects/five/">OpenAI's Dota 2 AI</a>, so I won't highlight it here.</li> <li>Some choices are arbitrary. Often, rather similar techniques are published at around the same time. The goal of this post is not be a comprehensive review, but to to expose someone new to the field to a cross-section of ideas that cover a lot of ground. For example, there may be hundreds of GAN variations, but to understand the general concept of GANs, it really doesn't matter which one you study.</li> </ul>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep Convolutional Neural Networks (2012)</a> <span data-cites="krizhevsky_imagenet_2012">Krizhevsky, Sutskever, and Hinton (2012)</span></li> <li><a href="https://arxiv.org/abs/1207.0580">Improving neural networks by preventing co-adaptation of feature detectors (2012)</a> <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span></li> <li><a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks (2014)</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/hub/pytorch_vision_alexnet">AlexNet in PyTorch</a></li> <li><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/alexnet.py">AlexNet in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/alexnet-full.png" alt=""><figcaption>Source: <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</a></figcaption> </figure> <p>AlexNet is often considered the algorithm responsible for the recent boom in Deep Learning and Artificial Intelligence research. It is a Deep Convolutional Neural Network based on the earlier LeNet developed by Yann LeCun. AlexNet beat previous methods at classifying images from the <a href="http://image-net.org/index">ImageNet dataset</a> by a significant margin through a combination of GPU power and algorithmic advances. It demonstrated that neural networks actually work! AlexNet was also one of the first times Dropout <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span> was used, which has since become a crucial component for improving the generalization ability of all kinds of Deep Learning models.</p> <p>The architecture used by AlexNet, a sequence of Convolutional layers, ReLU nonlinearity, and max-pooling, became the accepted standard that future Computer Vision architectures would extend and built upon. These days, software libraries such as PyTorch are so powerful, and compared to more recent architectures AlexNet is so simple, that it can be implemented in only a few lines of code. Note that many implementations of AlexNet, such as those linked above, use the slight variation of the network described in <a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span>.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning (2013)</a> <span data-cites="mnih_playing_2013">Mnih et al. (2013)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html">DQN in PyTorch</a></li> <li><a href="https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial">DQN in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/deep-q-learning-value.png" alt=""><figcaption>Source: <a href="https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning">https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning</a></figcaption> </figure> <p>Building on top of the recent breakthroughs in image recognition and GPUs, a team at DeepMind managed to train a network to <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">play Atari Games</a> from raw pixel inputs. What's more, the <em>same</em> neural network architecture learned to play seven different games without being told any game-specific rules, demonstrating the generality of the approach.</p> <p>Reinforcement Learning differs from Supervised Learning, such as image classification, in that an agent must learn maximize to the sum of rewards over multiple time steps, such as winning a game, instead of just predicting a label. Because the agent interacts directly with the environment and each action affects the next, the training data is not independent and identically distributed (iid), which makes the training of many Machine Learning models quite unstable. This was solved by using techniques such as experience replay <span data-cites="lin_self-improving_1992">Lin (1992)</span>.</p> <p>While there was no obvious algorithmic innovation that made this work, the research cleverly combined existing techniques, convolutional neural networks trained on GPUs and experience replay, with a few data processing tricks to achieve impressive results that most people would not have expected. This gave people confidence in extending Deep Reinforcement Learning techniques to tackle even more complex tasks such as <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">Go</a>, <a href="https://openai.com/projects/five/">Dota 2</a>, <a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii">Starcraft 2</a>, and others.</p> <p>Atari Games <span data-cites="bellemare_arcade_2013">Bellemare et al. (2013)</span> have since become a standard benchmark in Reinforcement Learning research. The initial approach only solved (beat human baselines on) seven games, but over the coming years advances built on top of these ideas would start beating humans on an ever increasing number of games. One particular game, Montezuma’s Revenge, was famous for requiring long-term planning and was considered to be among the most difficult to solve. It was only recently <span data-cites="badia_agent57_2020">Badia et al. (2020)</span> <span data-cites="ecoffet_first_2020">Ecoffet et al. (2020)</span> that techniques managed to beat human baselines on all 57 games.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a> <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span></li> <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#">Seq2Seq with Attention in PyTorch</a></li> <li><a href="https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt">Seq2Seq with Attention in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/seq2seq-cn.gif" alt=""><figcaption>Source: <a href="https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html">https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html</a></figcaption> </figure> <p>Deep Learning's most impressive results had largely been on vision-related tasks and was driven by Convolutional Neural Networks. While the NLP community had success with <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Language Modeling</a> and Translation using LSTM networks <span data-cites="hochreiter_long_1997">Hochreiter and Schmidhuber (1997)</span> and Encoder-Decoder architectures <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span>, it was not until the invention of the <strong>attention</strong> mechanism <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span> that things started to work spectacularly well.</p> <p>When processing language, each token, which could be a character, a word, or something in between, is fed into a recurrent network, such as an LSTM, which maintains a kind of memory of previously processed inputs. In other words, a sentence is very similar to a time series with each token being a time step. These recurrent models often had difficulty dealing with dependencies over long time horizons. When they process a sequence, they would easily "forget" earlier inputs because their gradients needed to propagate through many time steps. Optimizing these models with gradient descent was hard.</p> <p>The new attention mechanism helped alleviate the problem. It gave the network an option to adaptively "look back" at earlier time steps by introducing shortcut connections. These connections allowed the network to decide which inputs are important when producing a specific output. The canonical example is translation: When producing an output word, it typically maps to one or more specific input words.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a> <span data-cites="kingma_adam_2017">Kingma and Ba (2017)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://d2l.ai/chapter_optimization/adam.html">Implementing Adam in Python</a></li> <li><a href="https://pytorch.org/docs/master/_modules/torch/optim/adam.html">PyTorch Adam implementation</a></li> <li><a href="https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/optimizer_v2/adam.py#L32-L281">TensorFlow Adam implementation</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/optimizer-benchmark.png" alt=""><figcaption>Source: <a href="http://arxiv.org/abs/1910.11758">http://arxiv.org/abs/1910.11758</a></figcaption> </figure> <p>Neural networks are trained by minimizing a loss function, such as the average classification error, using an optimizer. The optimizer is responsible for figuring out how to adjust the parameters of the network to make it learn the objective. Most optimizers are <a href="https://ruder.io/optimizing-gradient-descent/">based on variations of Stochastic Gradient Descent (SGD)</a>. However, many of these optimizers contain tunable parameters such as a learning rate themselves. Finding the right settings for a specific problem not only reduces training time, but can also lead to better results due to finding a better local minimum of the loss function.</p> <p>Big resarch labs often ran expensive hyperparameter searches that came up with complex learning rate schedules to get the best out of simple but hyperparameter-sensitive optimizers such as SGD. When they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dennybritz.com/blog/deep-learning-most-important-ideas/">https://dennybritz.com/blog/deep-learning-most-important-ideas/</a></em></p>]]>
            </description>
            <link>https://dennybritz.com/blog/deep-learning-most-important-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004790</guid>
            <pubDate>Fri, 31 Jul 2020 01:39:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering the PLA Chip in the Commodore 128]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24004640">thread link</a>) | @segfaultbuserr
<br/>
July 30, 2020 | https://c128.se/posts/silicon-adventures/ | <a href="https://web.archive.org/web/*/https://c128.se/posts/silicon-adventures/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h2 id="backstory-and-first-attempts">Backstory and first attempts</h2>
<p>As I mentioned in my last post I’ve been working on reverse engineering the PLA chip in the C128.
I’m now mostly done with this process so I think it’s time to share some of the findings.</p>
<p>This has been a very interesting project as I did not really know much about semiconductor design
and manufacturing. My existing knowledge extended to having seen some die shots and admiring the pretty
looking pictures.</p>
<p>It all started with me buying a cheap microscope to help with soldering surface mount components.</p>

<p><a href="https://c128.se/posts/silicon-adventures/cheapo-microscope.jpg" data-mediabox="gallery" data-title="Cheap microscope">
    <img src="https://c128.se/posts/silicon-adventures/cheapo-microscope.jpg" alt="Cheap microscope">
</a>
</p>
<p>Some time later I ended up watching a video on youtube showing a simpler way of getting silicon dies out
of the packaging.</p>


<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ZQeHHYJYWXo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>This looked simple enough to try at home as I already had all the equipment needed. Decapping an IC usually involves heated sulphuric acid or
other similar nasty chemicals which I do not really want to play with at home. So I dug out a couple of broken MOS chips I had lying around
(never throw things away, could come in handy). After fiddling around a bit I ended up with two 8521R0 dies and one 8721 PLA.
The first real photo was the one show in the last post.</p>

<p><a href="https://c128.se/posts/now-available/pla-die.png" data-mediabox="gallery" data-title="Full 8721 PLA die photo">
    <img src="https://c128.se/posts/now-available/pla-die.png" alt="Full 8721 PLA die photo">
</a>
</p>
<h2 id="better-microscope">Better microscope</h2>
<p>While this was a success I quickly realised that this microscope did not have enough resolution for me to be able to capture images of high
enough quality. The maximum magnification is 90x, when using a 2x barlow lens. Additionally it does not have a stage so I had to place the die
on a table and then move the whole microscope, which is very unstable and makes it hard to capture the bits you want to see.</p>
<p>As such a better microscope was sourced and purchased, still within reasonable money.</p>

<p><a href="https://c128.se/posts/silicon-adventures/amscope-me580t.jpg" data-mediabox="gallery" data-title="AmScope ME580-T microscope">
    <img src="https://c128.se/posts/silicon-adventures/amscope-me580t.jpg" alt="AmScope ME580-T microscope">
</a>
</p>
<p>This proved to be much better at taking pictures of decent quality, I was however not happy with the camera I bought with it. It’s a cheap camera with no capability for me to manage it remotely except using the AmScope application. Around this time, the Raspberry Pi foundation
released the new High Quality camera for the Raspberry Pi. This camera has a C-mount on it which matches the microscope so I quickly bought
one and put in on the microscope. This camera is fantastic for this job, full control of the whole process from the comfort of linux.</p>

<p><a href="https://c128.se/posts/silicon-adventures/8521r0-detail.jpg" data-mediabox="gallery" data-title="Silicon die detail from 8521R0">
    <img src="https://c128.se/posts/silicon-adventures/8521r0-detail.jpg" alt="Silicon die detail from 8521R0">
</a>
</p>
<p>All in all a vast improvement to the previous setup. With the higher resolution I started needing to stitch the photos together to make
larger pictures. This sounded simple at the start and ended up being (as you can probably guess) not very easy at all. I’m still struggling
with the stitching, but slowly improving. One of the key things for a successful panorama stitch is to have consistent photos when it comes
to panning, focus, white balance etc. etc. The more even the photos, the easier and better the stitching becomes.</p>
<h2 id="motorizing">Motorizing</h2>
<p>This led me to start working on motorizing the table. It was getting really tiresome having to manually move the table around and the photos
ended up being moved in multiple axis etc.</p>
<p>Lots of design work, 3D printing and research into CNC firmwares later I ended up with the following setup:</p>

<p><a href="https://c128.se/posts/silicon-adventures/modded-me580t.jpg" data-mediabox="gallery" data-title="Modified AmScope ME580-T microscope">
    <img src="https://c128.se/posts/silicon-adventures/modded-me580t.jpg" alt="Modified AmScope ME580-T microscope">
</a>
</p>
<p>Going from the top we have a Raspberry 7” display, with a Raspberry Pi4 mounted on the back. Not see is also the RPi HiQ camera mounted on
the microscope. The RPi takes photos, displays previews on the display and also runs the python code that controls the CNC board.</p>
<p>The stage and the levelling table is motorized with 28BYJ-48 steppers controlled using a small board with an ESP32 running <a href="https://github.com/bdring/Grbl_Esp32">Grbl_Esp32</a> and four AD4498 stepper motor controllers.</p>
<p>This whole setup has some issues both in software and hardware but it works well enough for now to enable me to do some work.</p>

<p>With the logistics now sorted out I returned to the work of reverse engineering the chip itself. My initial focus was on the PLA chip
as this should be one of the simpler ones to figure out. PLA stands for <a href="https://en.wikipedia.org/wiki/Programmable_logic_array">Programmable Logic Array</a> and is a very common structure in designs from this era.</p>
<p>Looking at the schematic diagram from wikipedia we should expect to see two main arrays, AND and OR. Inputs are connected to AND and
outputs from the OR array.</p>
<p>Going back to the previous die shot with can improve it with some annotations for the pins and the general areas of the chip. Once we
have established the pins we can see that all the inputs are connected to one array and all the outputs to the other array, just as
expected. This also helps us establish which array is which.</p>

<p><a href="https://c128.se/posts/silicon-adventures/pla-annotated.png" data-mediabox="gallery" data-title="Annotated die shot of 8721 PLA">
    <img src="https://c128.se/posts/silicon-adventures/pla-annotated.png" alt="Annotated die shot of 8721 PLA">
</a>
</p>
<p>Here we see the I/O pins marked up with how they are connected to the lead frame and the pins on the DIP itself. We can also see the two main
areas that make up a PLA structure, the AND array and the OR array. Additionally there is some extra logic at the bottom marked with a question
mark. The function of this was unknown to me but as all the output pins are passing through it I was guessing that it was an output stage of
some kind.</p>
<h2 id="and-array">AND array</h2>
<p>So, if we take a closer look at the AND matrix to start with we will see the following. The colours are a bit off as this was still done
using the AmScope camera and I didn’t figure out how to set the white balance on it.</p>

<p><a href="https://c128.se/posts/silicon-adventures/and-matrix-metal.jpg" data-mediabox="gallery" data-title="AND matrix with metal layer">
    <img src="https://c128.se/posts/silicon-adventures/and-matrix-metal.jpg" alt="AND matrix with metal layer">
</a>
</p>
<p>This was not very helpful to understand what was going on as all the interesting bits are covered up by the top-most metal layer. This was
early on when I was still learning a lot so to remove the metal I took a very brute force approach. I use heavy mechanical scrubbing to
remove the metal which I also learned once I put it back in the microscope had removed everything but the substrate itself. Oops.</p>
<p>Fortunately, the details that I needed were in the diffusion embedded into the substrate:</p>

<p><a href="https://c128.se/posts/silicon-adventures/and-matrix-delayer.jpg" data-mediabox="gallery" data-title="AND matrix substrate">
    <img src="https://c128.se/posts/silicon-adventures/and-matrix-delayer.jpg" alt="AND matrix substrate">
</a>
</p>
<p>Looking closely at this image we can see little squiggly lines where a transistor is located to create a connection within the matrix.</p>
<h2 id="or-array">OR array</h2>
<p>Moving on to the OR array we see the exact same pattern. Hard to tell with the metal layer in place, though easier compared to the AND
matrix. Much easier with just the substrate and diffusion left.</p>


<h2 id="full-matrix-decode">Full matrix decode</h2>
<p>Armed with this knowledge we can now proceed with extracting the full PLA logic matrix from the images.</p>
<p>I marked all transistors in each matrix with a dot and got the following picture:</p>

<p><a href="https://c128.se/posts/silicon-adventures/decoded-matrix.jpg" data-mediabox="gallery" data-title="AND matrix with metal layer">
    <img src="https://c128.se/posts/silicon-adventures/decoded-matrix.jpg" alt="AND matrix with metal layer">
</a>
</p>
<p>All inputs are horizontal in the AND matrix, with each line having a normal and an inverted signal being fed in.
All outputs are horizontal in the OR matrix and they are connected with vertical lines called product terms.</p>
<p>By looking at the dots, we can decode the product terms by doing logic and for all vertical lines in the AND matrix, for example</p>
<pre><code>    p0 = CHAREN &amp; HIRAM &amp; BA &amp; !MS3 &amp; GAME &amp; RW &amp; AEC &amp; A12 &amp; !A13 &amp; A14 &amp; A15
</code></pre><p>For the outputs we instead look horizontal for each output and combine with or, for example</p>
<pre><code>    SDEN = p42 | p43 | p66 | p69
</code></pre><p>So now we have the entire set of logic equations. Hooray!</p>
<h2 id="output-stage">Output stage</h2>
<p>Going back to the full die picture, we now have everything but the box marked with a question mark in the output path.</p>
<p>Looking at higher resolution photos of this we can see similar structures for each output. In all cases except two the structure
is bypassed and the output from the OR matrix goes directly to the output pin. This is however not the case for the two pins <code>DWE</code> and <code>CASENB</code>.</p>
<p><code>DWE</code> is the Write Enable signal going to the main system DRAM chips, CASENB is gating the CAS signal towards the RAM. These two signals are
processed in some form using these output gate structures, so I had to reverse engineer this block.</p>


<p>After quite some time reading up on silicon chip design and manufacturing and a lot of attempts I managed to come up with a schematic
for this that makes sense. I’m not going to go into the whole process here but I will document and post it later. Here I would also like
to thank <a href="https://www.patreon.com/androSID">Frank Wolf</a> for his help, please support his project if you can!</p>

<p><a href="https://c128.se/posts/silicon-adventures/output-schematic.png" data-mediabox="gallery" data-title="Output block schematic">
    <img src="https://c128.se/posts/silicon-adventures/output-schematic.png" alt="Output block schematic">
</a>
</p>
<p>Going a bit further, the way this is used in the <code>DWE</code> and <code>CASENB</code> outputs makes it a normal D-latch. The latch enable for this also comes
for the PLA matrix in a pair of lines in the OR matrix.</p>
<h2 id="result">Result</h2>
<p>So as a final result we can now write down the full HDL code for the C128 PLA chip. I’m using verilog for this. Mind you this is the first
verilog I’ve ever written so it’s probably suboptimal. Using a D-latch for the output in verilog is normally seen as a bad thing, however
in this case I am doing it to replicate the logic and function of the existing chip.</p>
<p>I have validated this to the best of my knowledge, but if I’ve missed anything please let me know!</p>
<p>In difference to the C64 PLA the C128 PLA can not be replaced with just an EPROM or similar due to the presence of the output latches.</p>
<div><pre><code data-lang="verilog"><span>module</span> pla_8721(
    <span>input</span> rom_256,
    <span>input</span> va14,
    <span>input</span> charen,
    <span>input</span> hiram,
    <span>input</span> loram,
    <span>input</span> ba,
    <span>input</span> vma5,
    <span>input</span> vma4,
    <span>input</span> ms0,
    <span>input</span> ms1,
    <span>input</span> ms2,
    <span>input</span> ms3,
    <span>input</span> z80io,
    <span>input</span> z80en,
    <span>input</span> exrom,
    <span>input</span> game,
    <span>input</span> rw,
    <span>input</span> aec,
    <span>input</span> dmaack,
    <span>input</span> vicfix,
    <span>input</span> a10,
    <span>input</span> a11,
    <span>input</span> a12,
    <span>input</span> a13,
    <span>input</span> a14,
    <span>input</span> a15,
    <span>input</span> clk,

    <span>output</span> sden,
    <span>output</span> roml,
    <span>output</span> romh,
    <span>output</span> clrbnk,
    <span>output</span> from,
    <span>output</span> rom4,
    <span>output</span> rom3,
    <span>output</span> rom2,
    <span>output</span> rom1,
    <span>output</span> iocs,
    <span>output</span> dir,
    <span>output</span> <span>reg</span> dwe,
    <span>output</span> <span>reg</span> casenb,
    <span>output</span> vic,
    <span>output</span> ioacc,
    <span>output</span> gwe,
    <span>output</span> colram,
    <span>output</span> charom);

<span>wire</span> p0;
<span>wire</span> p1;
<span>wire</span> p2;
<span>wire</span> p3;
<span>wire</span> p4;
<span>wire</span> p5;
<span>wire</span> p6;
<span>wire</span> p7;
<span>wire</span> p8;
<span>wire</span> p9;
<span>wire</span> p10;
<span>wire</span> p11;
<span>wire</span> p12;
<span>wire</span> p13;
<span>wire</span> p14;
<span>wire</span> p15;
<span>wire</span> p16;
<span>wire</span> p17;
<span>wire</span> p18;
<span>wire</span> p19;
<span>wire</span> p20;
<span>wire</span> p21;
<span>wire</span> p22;
<span>wire</span> p23;
<span>wire</span> p24;
<span>wire</span> p25;
<span>wire</span> p26;
<span>wire</span> p27;
<span>wire</span> p28;
<span>wire</span> p29;
<span>wire</span> p30;
<span>wire</span> p31;
<span>wire</span> p32;
<span>wire</span> p33;
<span>wire</span> p34;
<span>wire</span> p35;
<span>wire</span> p36;
<span>wire</span> p37;
<span>wire</span> p38;
<span>wire</span> p39;
<span>wire</span> p40;
<span>wire</span> p41;
<span>wire</span> p42;
<span>wire</span> p43;
<span>wire</span> p44;
<span>wire</span> p45;
<span>wire</span> p46;
<span>wire</span> p47;
<span>wire</span> p48;
<span>wire</span> p49;
<span>wire</span> p50;
<span>wire</span> p51;
<span>wire</span> p52;
<span>wire</span> p53;
<span>wire</span> p54;
<span>wire</span> p55;
<span>wire</span> p56;
<span>wire</span> p57;
<span>wire</span> p58;
<span>wire</span> p59;
<span>wire</span> p60;
<span>wire</span> p61;
<span>wire</span> p62;
<span>wire</span> p63;</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://c128.se/posts/silicon-adventures/">https://c128.se/posts/silicon-adventures/</a></em></p>]]>
            </description>
            <link>https://c128.se/posts/silicon-adventures/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004640</guid>
            <pubDate>Fri, 31 Jul 2020 01:11:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s bulls**t narrative on the App Store]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004538">thread link</a>) | @invig
<br/>
July 30, 2020 | https://scrambleuphill.com/2020/07/31/apples-bullst-narrative-on-the-app-store/ | <a href="https://web.archive.org/web/*/https://scrambleuphill.com/2020/07/31/apples-bullst-narrative-on-the-app-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-77">
			<!-- .entry-header -->		<!-- .entry-meta -->
	
	<div>
		
<figure><blockquote><p>“The only apps that are subject to a commission are those where the developer acquires a customer on an Apple device and where the features or services would be experienced and consumed on an Apple device,” Cook states. </p><p>Cook references <a href="https://www.zdnet.com/article/apple-releases-study-to-justify-app-store-business-model/">a study it commissioned and released last week</a> that compared Apple App Store’s commissions with cuts taken by Google Play Store, Amazon App Store, Samsung Galaxy Store, and Microsoft Store, as well as marketplaces from Airbnb, Uber, and Epic Games.  </p><p>The study concluded that Apple’s guidelines for in-app purchases are necessary to prevent users and developers from ‘free-riding’ on the App Store and that all digital marketplaces “routinely forbid behaviors aimed at avoiding fees”. </p><cite><a rel="noreferrer noopener" href="https://www.zdnet.com/article/tim-cook-defends-app-store-if-apple-is-a-gatekeeper-we-just-opened-the-gate-wider/" target="_blank">ZDNet</a>  – July 29 2020</cite></blockquote></figure>



<p>Apple makes the argument that developers should have to pay for the running of the App Store, but it’s not the largest developers using by  far the most App Store resources who are paying.</p>



<p>Apps by Facebook surely account for some huge percentage of all downloads on the entire App Store. Facebook pays just $99 per year for this service.</p>



<p>Google – $99 per year. Amazon – $99 per year + a special deal for video that no one else gets.  Netflix – $99 per year.</p>



<p>Funny how small developers have to pay 30/15%, and have no way to work around it, but there’s exceptions everywhere for other monopolies and mega-corporations.</p>



<p>“The only apps that are subject to a commission are those where the developer acquires a customer on an Apple device and where the features or services would be experienced and consumed on an Apple device” says Tim Cook. </p>



<p>Tim, how is it possible given todays rules for a small developer to write an app where the developer could prove that they did not “acquire the customer on an Apple device” but instead acquired them via advertising the developer had to pay for (e.g. ads on Google, or via their own website) and therefor should not pay 30%? I’d like to see the steps on how to do that.</p>



<p><em>Note to non-technical audience members: Apple is not providing some kind of amazing technical service here. If you build and distribute an app via the App Store that sells a t-shirt instead of a digital photo you don’t have to use Apple payments and you don’t pay 30%. They have just drawn a line in the sand where they want it to be.</em></p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]>
            </description>
            <link>https://scrambleuphill.com/2020/07/31/apples-bullst-narrative-on-the-app-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004538</guid>
            <pubDate>Fri, 31 Jul 2020 00:53:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Today's B2B startups turned their users into paying customers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004496">thread link</a>) | @abouelatta
<br/>
July 30, 2020 | https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-startups | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Part two in our series on B2B growth strategy</h3></div><div><p><em>Hello and welcome to a<strong>&nbsp;🔒 subscriber-only edition 🔒&nbsp;</strong>of my weekly newsletter. I’m&nbsp;<a href="https://www.lennyrachitsky.com/subscribe">Lenny</a>, and each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing you out at the office.&nbsp;<a href="https://www.lennyrachitsky.com/subscribe">Send me your questions</a>&nbsp;and in return, I’ll offer actionable real-talk advice<strong>.</strong></em></p><p>If you find this newsletter valuable, co…</p></div></div>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004496</guid>
            <pubDate>Fri, 31 Jul 2020 00:46:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Convert Numeric Words into Numbers Using Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004404">thread link</a>) | @aogl
<br/>
July 30, 2020 | https://ao.gl/how-to-convert-numeric-words-into-numbers-using-python/ | <a href="https://web.archive.org/web/*/https://ao.gl/how-to-convert-numeric-words-into-numbers-using-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<h2>Challenge</h2>
<p>Using Python, we want to convert words to numbers. In this challenge, we will explore how to convert a string into an integer.</p>
<p>The strings simply represent the numbers in words.</p>
<h3>Examples:</h3>
<ul><li>“one” =&gt; 1</li><li>“twenty” =&gt; 20</li><li>“two hundred forty-six” =&gt; 246</li><li>“seven hundred eighty-three thousand nine hundred and nineteen” =&gt; 783919</li></ul>
<h3>Additional Notes:</h3>
<ul><li>The minimum number is “zero” (inclusively)</li><li>The maximum number, which must be supported is 1 million (inclusively)</li><li>The “and” in e.g. “one hundred and twenty-four” is optional, in some cases it’s present and in others, it’s not</li><li>All tested numbers are valid, you don’t need to validate them</li></ul>
<h2>Test cases</h2>
<pre title="">Test.assert_equals(parse_int('one'), 1)
Test.assert_equals(parse_int('twenty'), 20)
Test.assert_equals(parse_int('two hundred forty-six'), 246)
</pre>
<h2>The solution in Python</h2>
<pre title="">def parse_int(textnum, numwords={}):
    # create our default word-lists
    if not numwords:

      # singles
      units = [
        "zero", "one", "two", "three", "four", "five", "six", "seven", "eight",
        "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen",
        "sixteen", "seventeen", "eighteen", "nineteen",
      ]

      # tens
      tens = ["", "", "twenty", "thirty", "forty", "fifty", "sixty", "seventy", "eighty", "ninety"]

      # larger scales
      scales = ["hundred", "thousand", "million", "billion", "trillion"]

      # divisors
      numwords["and"] = (1, 0)

      # perform our loops and start the swap
      for idx, word in enumerate(units):    numwords[word] = (1, idx)
      for idx, word in enumerate(tens):     numwords[word] = (1, idx * 10)
      for idx, word in enumerate(scales):   numwords[word] = (10 ** (idx * 3 or 2), 0)

    # primary loop
    current = result = 0
    # loop while splitting to break into individual words
    for word in textnum.replace("-"," ").split():
        # if problem then fail-safe
        if word not in numwords:
          raise Exception("Illegal word: " + word)

        # use the index by the multiplier
        scale, increment = numwords[word]
        current = current * scale + increment
        
        # if larger than 100 then push for a round 2
        if scale &gt; 100:
            result += current
            current = 0

    # return the result plus the current
    return result + current
</pre>



</div></div>]]>
            </description>
            <link>https://ao.gl/how-to-convert-numeric-words-into-numbers-using-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004404</guid>
            <pubDate>Fri, 31 Jul 2020 00:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prefer having technical discussions in public]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004351">thread link</a>) | @markl42
<br/>
July 30, 2020 | https://blog.larah.me/prefer-having-discussions-in-public/ | <a href="https://web.archive.org/web/*/https://blog.larah.me/prefer-having-discussions-in-public/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>July 30, 2020</p></header><section><p>In general, prefer having technical conversations in a public forum, such as a
public team Slack channel, Google Doc comment or a GitHub pull request comment
thread.</p>
<p>This applies to:</p>
<ul>
<li><a href="https://blog.larah.me/asking-for-help-on-slack">asking the onpoint a technical question</a> (<em>this one in particular!</em>)</li>
<li>asking your code reviewer about something they commented in a Pull Request</li>
<li>talking with coworkers to decide a technical approach for something</li>
<li>a conversation started in a google doc for scoping a project</li>
</ul>
<p>Instead of a <em>private</em> Slack chat, consider having the conversation in the
same forum that the question first came up (the team slack channel, Google Doc
or Pull Request).</p>
<h2>Why?</h2>
<ul>
<li>
<p><strong>Public forums let others weigh in.</strong></p>
<ul>
<li>It’s not unlikely that someone else on the team has an opinion or knows the
answer.</li>
<li>You might get an answer from someone else quicker!</li>
<li>Asking the question where others can see it leads to more knowledge sharing.</li>
</ul>
</li>
<li>
<p><strong>Private channels are private.</strong></p>
<ul>
<li>There’s no searchable paper trail for future teammates to refer back to
later about the surrounding context in which a decision was made.</li>
<li>(Yes this is also true of equivalent in-person meetings, but that’s a
seperate blog post for another day)</li>
</ul>
</li>
<li>
<p><strong>Private Slack channel message history may be ephemeral by default.</strong></p>
<ul>
<li>Depending on your Slack plan - you might have to remember to set the private
slack thread message history beyond some default. Otherwise the message
history and context may get deleted after some time!</li>
</ul>
</li>
</ul>
<h2>What should I do if someone DMs me a technical question anyway?</h2>
<p>Don’t be afraid to gently respond something like “hey, let’s take this back to
&lt;team channel&gt; so others can weigh in!” and move the conversation over.</p>
<p>(Or feel free to link to this post for the motivation and let me be the killjoy
:P)</p></section><p><a href="https://mobile.twitter.com/search?q=https%3A%2F%2Fblog.larah.me%2Fprefer-having-discussions-in-public%2F" target="_blank" rel="noopener noreferrer">Discuss on Twitter</a> • <a href="https://github.com/magicmark/blog.larah.me/edit/master/content/blog/prefer-having-discussions-in-public/index.md" target="_blank" rel="noopener noreferrer">Edit on GitHub</a></p><hr></article></div>]]>
            </description>
            <link>https://blog.larah.me/prefer-having-discussions-in-public/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004351</guid>
            <pubDate>Fri, 31 Jul 2020 00:21:40 GMT</pubDate>
        </item>
    </channel>
</rss>
